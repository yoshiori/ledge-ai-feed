<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>OpenAI、2028年に「完全自動AI研究者」実現を目指すロードマップを公開</title>
      <link>https://ledge.ai/articles/openai_future_roadmap_fully_automated_ai_researcher_2028</link>
      <description><![CDATA[<p>OpenAIは2025年10月30日（米国時間）、同社の構造改革と今後の展望をテーマにしたライブ配信「Sam, Jakub, and Wojciech on the future of OpenAI with audience Q&amp;A」を実施し、研究・製品・インフラの中長期計画を<a href="https://www.youtube.com/watch?v=ngDCxlZcecw">公表</a>した。
登壇は、CEOのサム・アルトマン氏（Sam Altman）、チーフサイエンティストのヤクブ・パホツキ氏（Jakub Pachocki）、共同創業者のウォイチェフ・ザレンバ氏（Wojciech Zaremba）の3名。</p>
<p>配信では、OpenAIが掲げる中長期の研究ロードマップが初めて詳細に共有され、2028年3月までに「完全自動AI研究者（fully automated AI researcher）」を実現するという社内目標が明らかにされた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/we_did_a_livestream_ce2df3ba24/we_did_a_livestream_ce2df3ba24.jpg" alt="we did a livestream.jpg" /></p>
<h2>研究ロードマップ：2026年に“AI研究インターン”、2028年に“完全自動研究者”へ</h2>
<p>パホツキ氏は、OpenAIの研究プログラムが「科学的発見の加速と新技術開発の促進」を目的に構築されていると説明し、次の二段階のマイルストーンを示した。</p>
<ul>
<li><strong>2026年9月まで</strong> ： 意味のある計算資源を活用し、研究者の生産性を大幅に高められる有能なAI研究インターン（AI research intern）を開発。</li>
<li><strong>2028年3月まで</strong> ： 大規模な研究プロジェクトを自律的に遂行できる完全自動AI研究者（fully automated AI researcher）を実現。</li>
</ul>
<p>パホツキ氏は「これらの日付は絶対ではない」と前置きしながらも、現時点での社内目標を共有。「科学の発見速度を劇的に高める可能性がある」と語った。</p>
<p>アルトマン氏は、「この取り組みこそがOpenAIの研究プログラムの核心（core thrust）だ」と述べ、GPT-4のリリース（2023年）から約5年後に当たる2028年を重要な節目と位置づけた。同氏はさらに、AIによる科学的発見の進展について「2026年には小さな発見が現れ、2028年には中規模あるいはそれ以上の発見が生まれるだろう」と言及した。</p>
<h2>スーパーインテリジェンスへの接近</h2>
<p>パホツキ氏は、OpenAIが「ディープラーニングを理解する研究所」であり、トレーニング規模を拡大することで何が起こるかを探ることが本質的だと説明した。そのうえで、ディープラーニングシステムが多くの領域で人間を超える“スーパーインテリジェンス”に到達するまで10年を切っている可能性があるとの見方を示した。</p>
<p>指標のひとつとして、モデルが人間と同等の成果を上げるまでに要する時間を挙げ、現在のモデルは国際情報オリンピックなどでトップ人類と肩を並べる水準に達していると説明。今後はアルゴリズム革新とスケーリングによって、その「時間的水平線」が急速に拡大すると予測した。</p>
<h2>OpenAIのミッションと戦略的柱</h2>
<p>アルトマン氏は、OpenAIのミッションは非営利法人と公益法人（PBC）の双方において「AGI（汎用人工知能）が全人類に利益をもたらすことを保証する」ことであると改めて表明した。かつてAGIは「神託のような存在」と見なされていたが、現在は「人々が未来を創造するためのツールを構築し、AIで力を与えること」が明確な方向性だと説明した。</p>
<p>OpenAIの戦略は、次の三つの柱で構成されている。</p>
<ol>
<li><strong>研究（Research）</strong> ： AGI構築に必要な研究の成功。</li>
<li><strong>プロダクト（Product）</strong> ： 誰もが簡単かつ強力にAIを使えるようにする。</li>
<li><strong>インフラストラクチャ（Infrastructure）</strong> ： 低コストで高性能なAIを提供できる基盤の整備。</li>
</ol>
<p>アルトマン氏は「AIが科学の発見を支援することで、社会全体がより良くなり、個人の創造性も飛躍的に向上するだろう」と述べた。</p>
<p>パホツキ氏は、強力なシステム開発に向けた準備の中で安全性と価値観の整合性（value alignment）を最重視しているとし、「AIが根本的に何を気にかけるのかを理解することが、スーパーインテリジェンス時代の長期的安全性の核心だ」と語った。</p>
<p>ザレンバ氏も加わり、質疑応答では研究の方向性や安全性、社会的インパクトに関する質問に答えながら、OpenAIが今後も透明性をもって議論を続けていく姿勢を示した。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、約1万4千人の従業員削減を発表──AI時代に合わせた「俊敏な組織」へ再構築</title>
      <link>https://ledge.ai/articles/amazon_layoffs_14000_ai_organization_restructure_oct2025</link>
      <description><![CDATA[<p>米Amazonは2025年10月28日（現地時間）、企業全体の効率化と俊敏性の向上を目的として、約1万4,000人の従業員を削減すると<a href="https://www.aboutamazon.com/news/company-news/amazon-workforce-reduction">発表</a>した。
この発表は、人事担当シニア・バイスプレジデントのベス・ガレッティ（Beth Galetti）氏が公式ブログ「Staying nimble and continuing to strengthen our organisations」で明らかにしたもの。</p>
<p>同氏は声明の中で、「Amazonはこれまでも、変化の速い環境の中で俊敏に進化してきた。今回の再編も、よりフラットでスピード感のある組織を築くための一歩だ」と述べた。削減は主にコーポレート部門の職務約14,000件（roles）を対象とし、各国の法的手続きや労働慣行に基づいて順次進められる。</p>
<p>Amazonは、影響を受ける従業員に対し、90日間の社内再配置期間（Internal Job Search Period）を設ける。期間中に社内の他部門で新たな職務を見つけられなかった場合、退職金・転職支援・医療保険の延長などを提供する方針だ。
ガレッティ氏は、「この決定は決して軽いものではない。影響を受ける社員には最大限のサポートを行う」と強調している。</p>
<p>同社は、今回の削減を「単なるコスト削減ではなく、組織のレイヤーを減らし、意思決定を迅速化するための取り組み」と位置づける。ガレッティ氏は、「私たちは“世界最大のスタートアップ”として、責任とスピードを両立する構造を目指す」と記し、AIや自動化を含む新技術を活用した効率化を進めていく方針を示した。</p>
<p>今後もAmazonは、AI・クラウド・物流などの「戦略的重点領域」では採用を継続しつつ、その他の部門では組織構造の見直しを行うという。同氏は最後に、「これによりAmazonは、よりシンプルで、所有権を持って行動できる組織になる」と述べ、長期的な競争力と持続的成長への意欲を示した。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>声の権利をAIで守る、NTT西日本の新事業「VOICENCE」開始──声優・俳優らの音声IPを安全に活用へ</title>
      <link>https://ledge.ai/articles/ntt_west_voicence_voice_ai_rights_launch</link>
      <description><![CDATA[<p>NTT西日本は2025年10月27日、声優・俳優・タレントなど実演家の“声の権利（音声IP）”を保護し、AI技術によってその価値を高める新事業「VOICENCE（ヴォイセンス）」を開始したと<a href="https://www.ntt-west.co.jp/news/2510/251027b.html">発表</a>した。
音声の真正性を保証するデジタル基盤を整備し、生成AI時代における“声の知的財産”の新たな活用モデルを目指す。</p>
<h2>声の権利を守り、AIで価値を高める</h2>
<p>「VOICENCE」は、声優や俳優、タレントなどの声を個人の知的財産として捉え、デジタル技術で権利を守りながら安全に活用するための仕組み。声の利用には本人の同意を前提とし、権利者・制作側・利用者の三者が安心して取引できる音声流通プラットフォームを構築する。</p>
<p>同社は、音声の発話者を証明する技術を組み合わせることで“声のトレーサビリティ”を実現。AI合成や音声変換などが進む中で、無断利用やフェイク音声の拡散を防ぐ狙いだ。</p>
<h2>ブロックチェーンとAI音声技術を活用</h2>
<p>プラットフォームでは、音声データの真正性を担保するためにブロックチェーン技術を活用。改ざん防止と権利情報の一元管理を行い、利用履歴を透明化する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251027bc_bfdd13602b/251027bc_bfdd13602b.png" alt="251027bc.png" /></p>
<p>さらに、NTTグループが開発するAI音声技術を組み合わせ、登録された声のAI合成や多言語化、印象制御なども可能とする。これにより、声優や俳優の声を“公認AI音声”として多分野で展開できる。</p>
<h2>実演家と連携し、新たな音声市場を創出</h2>
<p>NTT西日本は今後、実演家・制作会社・タレント事務所などと連携し、音声広告、ナレーション、教育、観光といった幅広い分野への応用を進める。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251027bd_52e4134013/251027bd_52e4134013.jpg" alt="251027bd.jpg" /></p>
<p>同社は「声の真正性を保証することで、新しい音声経済圏を形成し、文化・産業の発展に寄与する」としている。
2025年度中には、音声IPの登録・管理・認証機能を本格運用する予定。中長期的には国内外での展開を視野に、AIと人間の“声の共創”を推進していく方針だ。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>画像生成・編集AIを包括的に評価する「ImagenWorld」を発表──画像生成AIの「失敗」も定量評価し見える化</title>
      <link>https://ledge.ai/articles/imagenworld_benchmark_university_of_waterloo</link>
      <description><![CDATA[<p>ウォータールー大学などによる研究チームは2025年10月17日、画像生成および画像編集AIの性能を横断的に評価するベンチマーク「ImagenWorld」を<a href="https://tiger-ai-lab.github.io/ImagenWorld/">発表</a>した。</p>
<p>AIがテキストや画像条件に基づいてどのように出力を生成し、どのように失敗するかを体系的に測定できる点が特徴で、公式サイトおよび論文が同時に公開されている。研究には、GoogleのGeminiモデルを用いた自動解析手法も組み込まれているという。</p>
<h2>ImagenWorldとは──AIの「失敗」を定量的に可視化</h2>
<p>ImagenWorldは、AIモデルの生成・編集タスクを統一指標で評価するために開発された、実世界ベンチマークである。
データセット作成からオブジェクト抽出、最終的な人間・AI評価までを一連のプロセスとして設計。
AIが生成した画像の「どの部分で誤るのか」を可視化する点が最大の特徴だ。</p>
<p><strong>ImagenWorldの全体構成。データセット作成からオブジェクト抽出・評価までの流れ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/overview_b8402c569b/overview_b8402c569b.jpg" alt="overview.jpg" /></p>
<h2>画像生成と編集の両方をカバーする実世界ベンチマーク</h2>
<p>ImagenWorldは、生成AIを多角的に測る6つの主要タスクで構成される。</p>
<ol>
<li>テキスト誘導型生成（Text-guided Image Generation）</li>
<li>単一参照画像生成（Single Reference Image Generation）</li>
<li>複数参照画像生成（Multiple Reference Image Generation）</li>
<li>テキスト誘導型編集（Text-guided Image Editing）</li>
<li>単一参照画像編集（Single Reference Image Editing）</li>
<li>複数参照画像編集（Multiple Reference Image Editing）</li>
</ol>
<p>評価対象となるトピックも、「Artworks」「Photorealistic」「Information Graphics」「Textual Graphics」など多岐にわたる。</p>
<p><strong>6種類のタスク分類と実際の生成・編集例。成功と失敗を並べて比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/dataset_1_bbfafbc87b/dataset_1_bbfafbc87b.jpg" alt="dataset (1).jpg" /></p>
<h2>評価プロセス──人間とAIが協働で“失敗”を検出</h2>
<p>ImagenWorldのスコアリングは、人間アノテータとVision-Language Model（VLM）の両方で行われる。評価軸は「Prompt Relevance」「Aesthetic Quality」「Content Coherence」「Artifacts」の4つ。Geminiを用いた自動オブジェクト抽出・セグメント分析を組み込み、どの部分が誤って生成されたのかを明示する。</p>
<p><strong>人間とVLMによるスコアリングを統合し、失敗箇所をセグメント単位で特定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/explain_tag_0fabc11340/explain_tag_0fabc11340.jpg" alt="explain-tag.jpg" /></p>
<h2>モデル比較──GPT-Image-1が総合スコア首位</h2>
<p>公式サイトと論文によると、評価対象モデルはOpenAIのGPT-Image-1、Stability AIのBAGEL、OmniGen2など。
総合スコアではGPT-Image-1が首位を記録したが、フォトリアリスティック画像や情報グラフィックの一部ではオープンソース系モデルも健闘した。</p>
<p><strong>ImagenWorldによる代表モデルのスコア比較。上段がタスク別、下段がトピック別の平均値</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unified_f74e92aef1/unified_f74e92aef1.jpg" alt="unified.jpg" /></p>
<h2>実例──AIの「わかりやすい失敗」を収集</h2>
<p>研究チームは、失敗出力の具体例を体系的に提示している。
例えば、指示された要素を正確に追加できない、参照画像の属性統合に失敗する、構図の一貫性が崩れるなど。
これらを分類・可視化することで、開発者がモデルの弱点を明確に把握できるようにしている。以下はその一部。</p>
<p><strong>指示に厳密に従えないケース</strong>：
プロンプトは「画像1の左上の木箱を画像3の黄色い警告標識に置き換え、画像2から“ピンク（中央）”と“黄色（右下）”のクルーメイトを取り出して並べ、画像1の中央ドア上に立たせる。遠近・照明・スケールを整える」指示。これに対し、モデルは別の色のクルーメイトを配置してしまい、標識の位置も指定と不一致。指示追従の精度不足が現れている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fail1_3f961411f2/fail1_3f961411f2.jpg" alt="fail1.jpg" /></p>
<p><strong>編集中に新しい画像を生成してしまうケース</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fail6_2856948e57/fail6_2856948e57.jpg" alt="fail6.jpg" /></p>
<h2>今後の展望──動画・3D生成AIへ拡張</h2>
<p>研究チームは、ImagenWorldを将来的に動画生成や3D生成AIの評価にも拡張する計画を示している。コードとデータセットはオープンソースとして一般公開されており、他研究者による再評価や再現実験も可能。</p>
<p>論文では「AIモデルの品質保証と説明可能性を高める基盤として設計された」と結論づけている。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、資本・組織再編を完了──非営利法人が営利事業を統制する「OpenAI Group PBC」体制へ</title>
      <link>https://ledge.ai/articles/openai_group_pbc_restructuring_complete</link>
      <description><![CDATA[<p>OpenAIは2025年10月28日（米国時間）、資本および組織の再編を完了したと<a href="https://openai.com/index/built-to-benefit-everyone/">発表</a>した。非営利団体のOpenAI Foundationが営利企業の株式を保有し、支配する形へと移行し、営利部門は公益法人（Public Benefit Corporation）である「OpenAI Group PBC」として再編された。</p>
<p>同社は新体制の目的を「人類全体に利益をもたらす形でのAGI開発の継続」と説明。これまでの「非営利団体 → 営利子会社」構造を改め、より明確なガバナンスを持つ一層の透明化を図るとしている。</p>
<p>再編にあたっては、米デラウェア州司法長官の審査を経て「異議なし（No Objection）」の判断が示され、公益法人としての要件を満たす形で承認された。司法長官のKathy Jennings氏は、OpenAIが安全・セキュリティ委員会を維持し、取締役が株主利益よりも公益目的を優先する義務を負うことを条件に認可したと<a href="https://news.delaware.gov/2025/10/28/ag-jennings-completes-review-of-openai-recapitalization/">説明している</a>。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Delaware_secures_structural_reform_and_action_on_safety_from_global_AI_leader_17eb0ebe2d/Delaware_secures_structural_reform_and_action_on_safety_from_global_AI_leader_17eb0ebe2d.jpg" alt="Delaware secures structural reform and action on safety from global AI leader.jpg" /></p>
<p>OpenAI Foundationが保有する持分の評価額は約1,300億ドルとされ、主要株主のMicrosoftは約27％を保有すると報じられている。全社評価は約5,000億ドル規模との見方もあり、これによりOpenAIは資金調達や事業展開の柔軟性を高めつつ、非営利団体がミッションと倫理基準を統制する構造を維持することになる。</p>
<p>今回の再編により、OpenAIは資本・組織・使命の3要素を整理し、非営利と営利を明確に区分した新体制に移行した。同社は今後、約250億ドル（約2兆円）規模の資金を医療・疾病治療、AIの安全性・レジリエンス技術など「人類全体の利益」に直結する領域に投資するとしている。公式声明では、「AIの発展を持続可能かつ安全に進めるための新しい章を開く」と述べている。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/30 [THU]ChatGPTで週120万人が「自殺兆候を含む会話」──OpenAI、メンタルヘルス対応を強化</title>
      <link>https://ledge.ai/articles/openai_chatgpt_mental_health_safety_update_oct2025</link>
      <description><![CDATA[<p>OpenAIは2025年10月27日（米国時間）、ChatGPTにおける精神的健康と安全性の向上を目的とした新たな取り組みを<a href="https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations/">発表</a>した。自殺や自傷、AIへの過度な依存など、センシティブな会話においてAIの応答を改善したと説明している。</p>
<p>同社は170人以上の臨床心理士、精神科医、カウンセラーらと協力し、精神疾患（精神病・躁病）、自傷・自殺、AIへの情緒的依存という3つの領域を重点改善分野に設定。これらの領域において、ChatGPTの応答品質が39〜52％改善したという。</p>
<h2>「自殺の明確な指標を含む会話」は週0.15％</h2>
<p>OpenAIの初期分析によると、ChatGPTの週次アクティブユーザー（WAU）のうち約0.15％が「自殺の計画や意図の明確な指標を含む会話」を行っていると推定される。10月6日の発言で同社CEOサム・アルトマン氏が年次開発者会議「DevDay 2025」で<a href="https://ledge.ai/articles/openai_devday2025_chatgpt_800m_wau">示した</a>WAUは約8億人。これを基にすると約120万人/週となる。同社はこれらの数値について、「低頻度かつ測定が難しい推定値」であり、今後の手法改良や利用動向によって大きく変動する可能性があると注記している。</p>
<h2>危機的な会話では専門機関への誘導を強化</h2>
<p>新しい応答設計では、ユーザーが自殺や自傷を示唆する発言をした場合、ChatGPTが危険を煽ることなく、専門機関や信頼できる人への相談を促すよう対応する。
OpenAIは「AIがカウンセラーの代わりになることはない」とし、人間による支援への橋渡しを重視する方針を明確にした。</p>
<h2>「AI依存」への懸念にも対応</h2>
<p>同社は、自傷や自殺と同様に「AIへの過度な情緒的依存」もリスクとして捉え、AIとの対話を通じて孤立や依存の兆候を検知しやすくする研究を進めている。目的は、AIを人間関係の代替とするのではなく、支援ツールとして安全に活用できる環境を整えることにあるという。</p>
<p>今後も医療・心理の専門家やNPOと連携し、AIがメンタルヘルス領域で安全に活用されるための基準づくりを進めると同社は述べている。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、企業専用の生成AI基盤「Adobe AI Foundry」を発表──Fireflyを拡張し、ブランド独自モデルを構築可能に</title>
      <link>https://ledge.ai/articles/adobe_ai_foundry_enterprise_firefly_launch</link>
      <description><![CDATA[<p>Adobeは2025年10月20日（米国時間）、企業向け生成AI基盤「Adobe AI Foundry」を発表。各社メディアが同日に報じ、Adobeは10月23日に公式ブログ「<a href="https://business.adobe.com/blog/introducing-firefly-foundry">Introducing Firefly Foundry</a>」で詳細を公開した。Foundryは、企業が自社ブランドや知的財産をもとにカスタム生成AIモデルを構築し、Adobeのエコシステム上で活用できる仕組みを提供する。</p>
<h2>ブランド固有の生成AIを構築</h2>
<p>「Adobe AI Foundry」は、同社の生成AIモデル群「Adobe Firefly」を拡張した新たなプラットフォームだ。
企業が自社ブランドのビジュアルスタイルや言語トーンを反映した独自モデルを構築でき、生成したコンテンツは商用利用にも対応する。Adobe ExpressやCreative Cloudなど既存の制作ツール群とも統合され、クリエイティブ制作の一貫したワークフローを支援する。</p>
<h2>データ保護と商用利用を両立</h2>
<p>Adobeによれば、AI Foundryでは企業データやブランド資産を安全に扱うことを前提に設計されている。学習素材は各社の許諾のもと管理され、生成結果に関しても著作権・商用利用のリスクを最小限に抑えた設計がなされているという。
料金体系は利用量ベースで、従来のサブスクリプション型（席ライセンス）からの転換を図る。なお、Foundryは本日時点で一部のエンタープライズ顧客に提供されている。</p>
<h2>初期導入企業とユースケース</h2>
<p>米TechCrunchやTechzineの報道によると、Home DepotやWalt Disney Imagineeringなどが初期導入企業として名を連ねる。ブランドイメージに一貫性を持たせた広告ビジュアルや販促素材の生成を中心に活用が進む見通しだ。
Adobeはこのプラットフォームを「企業が自社のブランドDNAをAIに宿すためのFoundry（製造炉）」と位置づけている。</p>
<h2>Adobeの生成AI戦略における新たな段階</h2>
<p>Adobeはこれまで、画像生成モデル「Firefly」やビジネス支援AI「Sensei GenAI」などを展開してきた。AI Foundryはその集大成として、企業ごとの“ブランドAIモデル”構築を可能にするもので、生成AIの民主化を次のフェーズへ進める狙いがある。
同社は今後、テキスト・画像・動画・3Dといったマルチモーダルな生成AIを企業規模で展開し、クリエイティブ制作からマーケティングまで一体化したソリューションを提供するとしている。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、配達ドライバー向けAIスマートグラスを発表──荷物スキャンから配達証明までハンズフリーで</title>
      <link>https://ledge.ai/articles/amazon_ai_smart_glasses_for_delivery_drivers</link>
      <description><![CDATA[<p>Amazonは2025年10月22日（現地時間）、配達ドライバーが安全かつ効率的に業務を行えるよう支援するAI搭載スマートグラス<a href="https://www.aboutamazon.com/news/transportation/smart-glasses-amazon-delivery-drivers">発表</a>した。荷物のスキャンからルート案内、配達証明の撮影までをハンズフリーで行える新デバイスで、同社の物流ネットワークにおける最新のイノベーションとして位置づけられている。</p>
<p>このスマートグラスは、ドライバーがスマートフォンを操作することなく、視界内で作業情報を確認し、音声操作で指示を実行できるよう設計されている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/amazon_ai_smart_glass_fb85f5e064/amazon_ai_smart_glass_fb85f5e064.jpg" alt="amazon ai smart glass.jpg" /></p>
<p>AIアシスタント機能を備え、目的地までのルート案内、荷物バーコードのスキャン、配達証明の撮影など、一連の業務を統合的にサポートする。安全面にも配慮し、運転中は自動的に無効化される設計を採用。ドライバーが「前方から目を離さずに」作業できる環境を整えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c8592cf9a3/_c8592cf9a3.gif" alt="ダウンロード.gif" /></p>
<p>このスマートグラスは現場ドライバー（Delivery Associates, DAs）のフィードバックを基に開発されており、コントロールベストや交換式バッテリー、緊急ボタンなど、配送現場のニーズを反映した構造となっている。度付きレンズや調光レンズにも対応しており、長時間の着用や屋外での使用にも配慮がなされている。</p>
<p>現在、北米地域の数百名のドライバーが試験運用を実施中で、ユーザーフィードバックを踏まえた改良が進められている。今後は配送サービスパートナー（Delivery Service Partners, DSPs）を含む広範な導入を予定しているが、商用展開の時期などは明らかにされていない。</p>
<p>Amazonは本取り組みを、倉庫内ロボットやAI物流最適化技術と並ぶ「次世代配送体験」の一環と位置づけており、配達の安全性と作業効率の両立を目指すとしている。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、量子チップ「Willow」で“検証可能な量子優位”を実証──Nature掲載論文でスーパーコンピューターを13,000倍上回る性能</title>
      <link>https://ledge.ai/articles/google_quantum_willow_verifiable_advantage_nature2025</link>
      <description><![CDATA[<p>Googleは2025年10月22日、科学誌『Nature』において、同社の量子コンピューター用チップ「Willow（ウィロー）」が、既存のスーパーコンピューターを13,000倍上回る速度で演算を実行し、「検証可能な量子優位（verifiable quantum advantage）」を達成したと<a href="https://research.google/blog/a-verifiable-quantum-advantage/">発表</a>した。</p>
<p>論文「<a href="https://www.nature.com/articles/s41586-025-09526-6">Observation of constructive interference at the edge of quantum ergodicity</a>」によると、Willowチップは105個の超伝導キュービットを備え、量子情報の拡散を解析する手法「アウト・オブ・タイム・オーダー相関（OTOC）」を用いて実験を実施した。結果、古典スーパーコンピューターでは約32年を要する計算を、わずか2時間で完了したという。</p>
<p>@<a href="https://www.youtube.com/watch?v=mEBCQidaNTQ">YouTube</a></p>
<p>A Verifiable Quantum Advantage：研究チームがWillowチップ、量子エコーアルゴリズム、NMR分光法応用などを解説</p>
<h2>Quantum Echoes──量子エコー・アルゴリズムの仕組み</h2>
<p>Googleの研究チームは、量子システム内部の相互作用を可視化する新しいアルゴリズム「Quantum Echoes（量子エコー）」を開発した。この手法は、量子回路を順方向と逆方向の両方で実行し、干渉パターンを比較することで誤差を自己検証できる。</p>
<p>この仕組みにより、量子システムの「見えない構造」をエコー信号として観測可能にする点が特徴で、これまでノイズに埋もれていた量子状態の動的相関を明確に測定できるようになった。</p>
<h2>量子干渉と「Constructive Interference」──新しい優位性の原理</h2>
<p>論文では、量子系内部のパウリ演算子の干渉（constructive interference）が、OTOCの高次成分（OTOC(2)など）において初めて実験的に観測されたことを報告。これにより、量子干渉の複雑性が古典シミュレーションでは再現不能であることが確認された。</p>
<p>実際、Googleの試算では、今回の65キュービット実験を古典スーパーコンピューター「Frontier」でシミュレートするには約3.2年を要し、Willowチップの実行時間（2.1時間）と比べて13,000倍以上の差がある。これにより、「Beyond classical（古典を超えた）」領域に踏み入ったと位置づけている。</p>
<p><strong>Quantum Echoesアルゴリズムは、世界最速のスーパーコンピューターを13,000倍上回る速度で計算を実行</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/13000times_faster_3aa42ccb1d/13000times_faster_3aa42ccb1d.jpg" alt="13000times faster.jpg" /></p>
<h2>実世界応用への一歩──分子構造解析とHamiltonian Learning</h2>
<p>Google Quantum AIは、Quantum Echoesの応用として、ハミルトニアン学習（Hamiltonian learning）を実証した。
これは量子システムの測定データ（OTOC）を実際の物理系と照合し、未知のパラメータを最適化して学習する手法である。</p>
<p>研究チームは、UCバークレーと連携し、Willowチップ上で2種類の分子構造を予測し、NMR分光法でその正確性を確認した。論文では、この方法が分子シミュレーション、薬剤設計、エネルギー材料開発などへの応用に発展する可能性が示唆されている。</p>
<p><strong>量子研究施設を視察するGoogle CEOのサンダー・ピチャイ氏「科学そのものを行う力が量子計算に宿り始めている」と述べた</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Quantum_Sundar_Inline_width_1000_format_webp_5a6124c1fb/Quantum_Sundar_Inline_width_1000_format_webp_5a6124c1fb.webp" alt="QuantumSundar_Inline.width-1000.format-webp.webp" /></p>
<p>Google Quantum AIのディレクターであるHartmut Neven氏は、「量子コンピューターが理論段階を超え、実際の科学的課題を解くためのツールになりつつある」とコメント。共同リーダーのJulian Kelly氏も「Quantum Echoesを通じて、結果を検証可能な形で量子優位を確認できたのは初めて」と述べた。</p>
<p><strong>Google Quantum AIが開発した次世代量子チップ「Willow」。105個の超伝導キュービットを搭載し、誤差率0.15％の高精度ゲート制御を実現した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Willow_Chip_4k_Render_02_width_1000_format_webp_2ad189fa0b/Willow_Chip_4k_Render_02_width_1000_format_webp_2ad189fa0b.webp" alt="WillowChip_4k_Render_02.width-1000.format-webp.webp" /></p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、「AI Day Tokyo 2025」全26セッションを無料公開──「ソブリンAI」「フィジカルAI」など最新動向をオンデマンドで視聴可能に</title>
      <link>https://ledge.ai/articles/nvidia_ai_day_tokyo_2025_ondemand_sessions</link>
      <description><![CDATA[<p>NVIDIAは10月21日までに、9月に東京ミッドタウン（東京都港区）で開催したイベント「<a href="https://blogs.nvidia.co.jp/blog/ai-day-tokyo/?ncid=so-twit-279362&amp;linkId=100000387789084">NVIDIA AI Day Tokyo 2025</a>」で実施した全26セッションの<a href="https://www.nvidia.com/ja-jp/on-demand/playlist/playList-4fa34d64-8fc9-487f-819a-18e06511216b/">オンデマンド配信</a>を開始した。生成AI、ロボティクス、医療AI、ソブリンAIなどをテーマとした講演を、同社公式サイトで無料視聴できる。</p>
<p>このイベントは、産業・研究・行政分野におけるAI活用の現状と今後の展望を共有する目的で開催され、約900名が参加した。主催はNVIDIA Japan。</p>
<p>主要テーマのひとつである「ソブリンAI（Sovereign AI）」では、日本国内のデータセンターやインフラ環境内でAI開発・運用を完結させる取り組みを紹介。政府や産業界における「データ主権」の確立に関する議論が行われた。</p>
<p>また、「フィジカルAI（Physical AI）」では、物理法則を理解し、ロボット制御や自動運転など現実世界の動作を最適化するAI技術が取り上げられた。AIが現実空間で学習・推論を行う応用例が紹介されたという。</p>
<p>その他のセッションでは、生成AIモデル「NIM」や「NeMo」を用いたアプリケーション開発、医療・創薬分野でのAI活用、ロボティクスシミュレーション、GPUクラウド基盤の構築、日本企業による導入事例などが扱われている。</p>
<p>NVIDIAは同ブログ内で、日本のAI演算需要が2030年までに2020年比で約320倍に増加すると予測しており、日本市場をアジア地域の主要拠点の一つとして位置づけている。</p>
<p>オンデマンド配信は、NVIDIA公式サイトの「NVIDIA On-Demand」上で<a href="https://www.nvidia.com/ja-jp/on-demand/playlist/playList-4fa34d64-8fc9-487f-819a-18e06511216b/">公開</a>されており、全26セッションが日本語で視聴可能。視聴登録のみでアクセスできる。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「ChatGPT Atlas」を正式公開──AIブラウザとしてmacOS版をリリース</title>
      <link>https://ledge.ai/articles/openai_chatgpt_atlas_release_oct2025</link>
      <description><![CDATA[<p>OpenAIは米国時間10月21日、AIブラウザ「ChatGPT Atlas」を<a href="https://openai.com/index/introducing-chatgpt-atlas/">発表</a>した。</p>
<p>同社によると、AtlasはChatGPTを中心に構築されたmacOS向けアプリで、チャットとWebブラウジングを融合した新しいAI体験を提供するという。発表が行われたライブ配信では、AIがWebの使い方そのものを再定義する「10年に一度の機会」と位置づけ、従来のブラウザの概念を刷新する設計思想が語られた。</p>
<p>@<a href="https://www.youtube.com/watch?v=8UWKxJbjriY">YouTube</a></p>
<h2>ChatGPTが心臓部にあるブラウザ</h2>
<p>ライブ配信で同社は、Atlasの開発が「ブラウザとチャットできたらどうなるか？」という問いから始まったと説明。
従来の複雑なWeb体験を、シンプルな会話で置き換えることを目指したと語った。Atlasは単にAI機能を追加した既存ブラウザではなく、「ChatGPTがその鼓動する心臓（beating heart）」として常にユーザーのそばで支援するよう設計されているという。</p>
<h2>コア機能：3つの柱</h2>
<p>Atlasを支えるコア機能として以下の3点が挙げられた。</p>
<ol>
<li><strong>Chat Anywhere</strong> ：ユーザーがどのWebページを閲覧していても、チャット機能を呼び出すことでページの文脈を理解した支援が受けられる。コピー＆ペーストやタブ移動の必要がなく、メール作成や文書作業中でもAIが内容を把握して提案を行う。</li>
<li><strong>ブラウザ・メモリ</strong> ：ChatGPTの記憶機能をブラウザー全体に拡張。Atlasはユーザーの閲覧や検索の履歴を理解し、過去に見たドキュメントを「人間が話すような言葉」で検索できる。利用者ごとにAIがパーソナライズされていく仕組み。</li>
<li><strong>エージェント</strong> ：ChatGPTがユーザーの代わりに操作を実行する機能。予約やドキュメント編集などを支援する際に、AIが小さなカーソルを出してクリック動作を行う。ログイン情報やブラウザー履歴にアクセスでき、まるで「ユーザー自身の自然な延長」として働く。</li>
</ol>
<h2>その他の主要機能</h2>
<ul>
<li><strong>Ask ChatGPT（サイドバー）</strong> ：ウェブページ右上の「Ask ChatGPT」ボタンから起動。表示中ページの要約、製品比較、プルリクエストやSlackチャンネルの要約などを行える。</li>
<li><strong>検索体験の刷新</strong> ：検索結果はニュース・画像などのタブでも絞り込め、ページ遷移後もChatGPTとの対話を並行して続けられる。</li>
<li><strong>カーソル操作（Use cursor）</strong> ：フォーム入力欄でテキストを選択し、ChatGPTを呼び出して文法チェックやトーン調整などを行う。</li>
</ul>
<h2>安全性と提供状況</h2>
<p>OpenAIは、Agentモードがユーザーのタブ上でのみ動作し、外部ファイルやコード実行にはアクセスしないよう安全設計が施されていると説明。ブラウザ・メモリ機能も完全オプションで、設定やシークレットウィンドウで制御可能とした。</p>
<p>AtlasはmacOSユーザー向けに全世界で提供開始されており、Plus／Pro／Businessユーザーを対象にプレビュー提供されている。今後、Windowsおよびモバイルへの展開を計画しているとのことだ。</p>
<h2>AIとWebを再定義する「次の10年」</h2>
<p>OpenAIはブログ「<a href="https://openai.com/index/introducing-chatgpt-atlas/">Introducing ChatGPT Atlas</a>」の中で、Atlasを「チャット、ブラウジング、ワークスペースを統合する新しい形のAI体験」と表現。AIがユーザーを理解し、インターネット上で必要な情報を能動的に探し出す未来像を描いている。同社はこのプロジェクトを「early days（初期段階）」と位置づけ、今後さらに機能を拡張していく方針だ。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「日本のAI経済ブループリント」を公開──生成AIで支える包摂的成長と新国家戦略</title>
      <link>https://ledge.ai/articles/openai_japan_economic_blueprint_2025</link>
      <description><![CDATA[<p>OpenAIは2025年10月22日、日本におけるAIの経済的・社会的潜在力を最大限に活かすための政策提言書「日本のAI：OpenAIの経済ブループリント」を<a href="https://openai.com/ja-JP/index/japan-economic-blueprint/">発表</a>した。日本がAI時代において経済成長と社会的包摂を両立するための具体的な国家戦略を示すものであり、教育、医療、行政、産業、エネルギーなど多岐にわたる分野での活用を提言している。</p>
<p>同文書は、OpenAIの政策・パートナーシップ担当である大久保和也氏が序文を執筆。AIを電気やインターネットと並ぶ汎用技術（General Purpose Technology）と位置づけ、「AIは日本の生産性を高め、より包摂的で持続可能な社会を支える」と述べた。AIを日本の国家成長の中核に据えるための「生きた提案書」として策定されたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_in_Japan_Open_AI_c85874e918/AI_in_Japan_Open_AI_c85874e918.jpg" alt="AI in Japan OpenAI.jpg" /></p>
<h2>国家戦略の三本柱──包摂・インフラ・教育を軸に</h2>
<p>ブループリントは、AIを経済と社会の成長エンジンに据えるための三本の柱を掲げる。</p>
<h3>1. 包摂的な参加型社会基盤の構築</h3>
<p>AIをすべての人に届け、誰もが開発と活用に参加できる社会へ。日本の柔軟な著作権制度を基盤に、国際ルール形成を主導する「日本モデル」を確立する方針を示した。</p>
<h3>2. 戦略的インフラ投資</h3>
<p>AIの中核を担う半導体・データセンター・再生可能エネルギーを一体的に整備し、「ワット（電力）」と「ビット（情報）」を連携させる。政府の「GX2040ビジョン」との連動を通じ、地方へのデータセンター誘致や再エネ電源開発を官民協働で推進する。</p>
<h3>3. 教育・リスキリングによる人的資本投資</h3>
<p>初等教育からAIリテラシーを育成し、生涯学習をAIで支援。ChatGPT Eduなどのツールを「思考のパートナー」として活用し、批判的思考や創造性を育む教育を全国に広げるとした。</p>
<h2>経済効果の試算──AIが日本のGDPを最大140兆円押し上げ</h2>
<p>同文書は、AIの経済的インパクトを複数の独立分析に基づいて示している。
AIを最大限に活用した場合、日本のGDPを累計140兆円押し上げる可能性がある（みずほリサーチ＆テクノロジーズ）。また、生成AIだけでも実質GDPを16.2%増加させ得る（大和総研）。さらに、AI利用企業の生産性は非利用企業より8.8%高い（経済産業研究所）とされ、OpenAIはこれらを「日本全体の生産性への投資効果」と位置づけている。</p>
<h2>各分野での波及効果──製造・医療・教育・行政・科学・金融</h2>
<p>ブループリントでは、AIがもたらす変革を6分野で具体的に示した。</p>
<ul>
<li><strong>製造業</strong> ：中小企業336万社を支えるAI需要予測・検査システムの導入事例を紹介。品質向上やコスト削減、熟練工の技能継承を支援するツールとしての効果を示した。</li>
<li><strong>医療・介護</strong> ：AI画像診断や見守りセンサーによる人手不足解消や医療費削減効果を提示。骨粗鬆症の予防だけでも年間1.5兆円の介護費削減が可能と試算している。</li>
<li><strong>教育</strong> ：AIチューターによる個別最適化学習の導入を推進し、AIを「批判的思考を磨くツール」として位置づけた。</li>
<li><strong>行政</strong> ：さいたま市や福岡市、東京都のAI活用事例を挙げ、文書作成や住民対応の自動化に加え、地域文化振興への応用も紹介。</li>
<li><strong>科学</strong> ：AIによる創薬支援が臨床開発時間を最大60%短縮し、治験成功率の向上にも寄与。</li>
<li><strong>金融</strong> ：生成AIによるパーソナライズ投資提案やAML（マネーロンダリング防止）対策への応用を紹介。金融庁の「AIディスカッションペーパー」を“成長ガイド”と評価した。</li>
</ul>
<h2>AIインフラとエネルギー政策の一体化</h2>
<p>AI経済を支える物理的基盤として、データセンター市場は2028年に5兆円規模へ拡大すると予測。経産省によると、AIと半導体工場の増設により2034年度までに電力需要が約5.8%増加すると見込まれている。</p>
<p>OpenAIは、日本政府が掲げる「GX2040ビジョン」との連携を通じて、再生可能エネルギーが豊富な地域へのデータセンター誘致を提言。GX（グリーン成長）とDX（デジタル変革）を統合した「GX×DXモデル」が、持続的な経済発展の鍵になるとした。</p>
<h2>AIをすべての人の豊かさにつなげる設計図</h2>
<p>OpenAIはこのブループリントを「AIという変革の力を日本のすべての国民の豊かさに繋げるための設計図」と位置づけた。
「AIによって日本は経済成長と人間中心社会の両立を実現できる。今こそ官民一体でこの“日本モデル”を世界に先駆けて示すときだ」と締めくくっている。</p>
<p><a href="https://cdn.openai.com/global-affairs/f9d1cd88-506e-48f9-b34b-6ff63655434e/openai-japan-economic-blueprint-jp.pdf">「​​日本のAI：​​Open AIの経済ブループリント」全文</a></p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>高市首相の偽広告が拡散　自民党が注意喚起「AI生成映像にご注意を」──国外追放デマも海外で拡散</title>
      <link>https://ledge.ai/articles/takaichi_fake_ad_ai_warning_afp_fake_news</link>
      <description><![CDATA[<p>自由民主党広報は2025年10月24日、公式X（旧Twitter）アカウントで「高市早苗総裁の画像や映像をAIで生成し、あたかも本人が登場しているかのように装った偽広告が出回っている」として注意を<a href="https://x.com/jimin_koho/status/1981533027277951122">呼びかけた</a>。</p>
<p>投稿では「これらの広告は高市総裁および自由民主党とは一切関係ありません」と明記し、「アクセスしたり、個人情報やカード番号を入力したりしないようご注意ください」と警告。信頼できる情報は党の公式ウェブサイトやSNSのみから発信していると強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fake_ad_takaichi_52db939d90/fake_ad_takaichi_52db939d90.jpg" alt="fake ad takaichi.jpg" /></p>
<p>投稿について、偽情報が海外のSNS上で拡散していると<a href="https://www.afpbb.com/articles/-/3605154?cx_part=ranking_general">AFP通信</a>などが報じている。投稿では「高市首相が外国人を大量国外追放する省を設置した」と虚偽の内容が記され、英語を中心にXやFacebookで900万回以上閲覧されたケースもあったという。実際にはそのような省庁や政策は存在せず、小野田紀美経済安全保障相が担当する「外国人との秩序ある共生社会推進担当大臣」職も、外国人排斥とは無関係の任務とされている。</p>
<p>高市氏をめぐっては、国内外で複数の偽情報が同時期に拡散しており、生成AI技術を利用したディープフェイク広告やSNS投稿の影響が懸念されている。自民党は今後も、公式アカウントから正確な情報を発信していく方針を示している。</p>
<h2>一般ユーザーが真偽の判断に苦慮──高度化する生成AIが見分けを難しくする</h2>
<p>今回の偽広告拡散は、一般ユーザーが映像の真偽を見極めることの難しさを改めて浮き彫りにした。近年、動画生成AIの表現力は急速に向上しており、2025年10月発表のOpenAI「Sora 2」など最新モデルはライティングや質感、口形と音声の同期まで自然だ。本件で特定のツールが使われた事実は確認されていないが、識別表示や透かしが欠落・削除された生成映像は、視覚情報のみでの判別を困難にする。</p>
<p>実際、本件の偽広告はニュース番組のレイアウトやテロップ様式を模倣し、QRコードなどの要素と組み合わせて“本物らしさ”を演出していた。SNS上では「どこまでが公式情報か分かりにくい」との声が広がり、生成物の明示（表示義務）や、悪用時の罰則・通報ルートの明確化、プラットフォーム側の検知・削除体制を求める意見が相次いでいる。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>レッジ、生成AI研修の提供拡大に向けて、販売・共創パートナー・カリキュラムの共同開発の3つの枠組みで協業を本格化</title>
      <link>https://ledge.ai/articles/generative-ai-training-partnership</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、日本最大級のAI特化型ニュースメディア「Ledge.ai」を運営する株式会社レッジは、企業向け生成AI研修事業の拡大に伴い、販売代理店・共創パートナー・AI人材教育カリキュラムの共同開発・提供の各スキームによる外部連携を本格化します。
すでに一部で開始している研修の販売代理、講師連携、共同開発の取り組みが各方面で高い評価を得ており、今後は多様なパートナーとの協働を通じて、生成AI人材育成の裾野を広げていきます。</p>
<h2>Ledge.aiの運営で培った知見を体系化した実践的研修</h2>
<p>レッジの研修プログラムは、国内最大級のAIメディア「Ledge.ai」の運営で蓄積したナレッジと、AI開発・実装支援の現場で培った知見を統合して構築されています。
単なるツール操作だけでなく、業務プロセスの中に、生成AIをどのように組み込み、どんな価値を生み出すかという実践設計に重きを置いています。
参加者は実際のビジネスシーンを想定した課題に取り組み、生成AIを用いたリサーチ、アイデア創出、コンテンツ制作、効果検証といった一連のプロセスを体験的に学ぶことができます。</p>
<h2>3つの協業スキームを展開</h2>
<p>レッジでは、企業や教育機関、コンサルティング会社など、多様なパートナーと共に研修提供の機会を広げていくため、3つの協業スキームを展開しています。
レッジが培ってきたブランド力と実績を活かし、連携企業の新たな価値創出や事業拡大につながる枠組みを提供します。</p>
<p>各スキームの詳細や協業プランについては、個別にご案内しております。
下記フォームよりお気軽にお問い合わせください。</p>
<p>:::button
<a href="https://zfrmz.com/5S0shEM2Cf2DQxXpTZh7">お問い合わせはこちら</a>{target=_blank}
:::</p>
<h2>レッジの研修事例の紹介</h2>
<p>レッジの研修は、すでに複数の企業・教育機関で導入されています。
以下は代表的な実施事例です。</p>
<h3>NECソリューションイノベータ株式会社</h3>
<p>生成AIを活用したアイデア発想研修と社内コンテストの企画・運営</p>
<h3>NECソリューションイノベータ株式会社／株式会社日立ソリューションズ</h3>
<p>生成AIをテーマにした大手2社合同ハッカソンイベントの企画・運営</p>
<h3>パナソニック株式会社</h3>
<p>DX推進部門向けの生成AI・RAG基礎研修の企画・運営</p>
<h3>採用・人材領域の企業</h3>
<p>採用広報支援サービスを展開する企業との共同企画として、生成AIを活用したワークショップを通じて企業と学生をつなぐ合同インターンプログラムを開催
AIなどの最新テクノロジーに興味関心が高い早期就活生と、感度の高い学生とのマッチングを志望する企業のマッチングを実現</p>
<h2>コンテンツの共同開発実績</h2>
<h3>ヒューマンアカデミー株式会社</h3>
<p>生成AI×ノーコード講座の共同開発・監修</p>
<h2>レッジがご提供可能な価値について</h2>
<ul>
<li><strong>豊富な導入実績と教材資産</strong>：多業種での研修実績に基づき、用途やレベルに応じた教材を提供可能です。</li>
<li><strong>研修との連動施策</strong>：座学による研修にとどまらず、コンテストやハッカソンなどの実践型のプログラムとの連動施策も企画可能です。</li>
<li><strong>メディア連携による広報支援</strong>：AI専門メディア「Ledge.ai」による取材・記事掲載など、広報面での支援体制を整えています。</li>
</ul>
<p>協業の形については、目的や業種に応じて柔軟に提案可能です。
詳細をご希望の方は、下記フォームよりお問い合わせください。</p>
<p>:::button
<a href="https://zfrmz.com/5S0shEM2Cf2DQxXpTZh7">お問い合わせはこちら</a>{target=_blank}
:::</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/29 [WED]イーロン・マスク氏、「Wikipediaより優れている」──xAIが生成AI百科事典「Grokipedia」version 0.1を公開</title>
      <link>https://ledge.ai/articles/elon_musk_xai_grokipedia_launch_version_0_1</link>
      <description><![CDATA[<p>xAIは2025年10月27日（米国時間）、生成AIを活用した独自の百科事典サービス「Grokipedia（グロキペディア）」の初期バージョン（version 0.1）を<a href="https://x.com/elonmusk/status/1982983035906842651">公開</a>した。</p>
<p>xAI創業者であるイーロンマスク氏はX（旧Twitter）上で「Grokipedia.com version 0.1 is now live. Version 1.0 will be 10X better, but even at 0.1 it’s better than Wikipedia imo.」と投稿し、将来的に大幅な改良を予定しつつも「現段階でWikipediaより優れている」と自信を示した。</p>
<h2>「真実追求を優先」──xAI公式が示す設計思想</h2>
<p>xAIの公式アカウント（@grok）は、Grokipediaについて次のように説明している。
\u003E“Grokipedia leverages xAI’s Grok to synthesize knowledge from diverse sources, prioritizing maximum truth-seeking over consensus-driven editing. Wikipedia, by contrast, depends on volunteer editors whose biases — often left-leaning — can distort entries on controversial topics. Grokipedia minimizes human subjectivity, focusing on verifiable facts and logical reasoning for a more reliable reference.”</p>
<p>この説明によれば、GrokipediaはxAIの大規模言語モデル「Grok」を用いて多様な情報源を統合し、合意形成ではなく「真実追求（truth-seeking）」を優先する設計思想を採用。人間編集者による主観や政治的偏向を最小化し、検証可能な事実と論理推論に基づいて構築された「より信頼できる参照源」を目指すとしている。
xAIは「version 0.1 の時点ですでにWikipediaを中立性で上回る」とも述べている。</p>
<h2>マスク氏「人類の知を宇宙に保存する」構想も表明</h2>
<p>マスク氏は続く投稿で、Grokipediaの長期的な目的を明らかにした。
\u003E“Nice work by the @xAI team on Grokipedia.com! The goal here is to create an open source, comprehensive collection of all knowledge. Then place copies of that etched in a stable oxide in orbit, the Moon and Mars to preserve it for the future. Foundation.”
（2025年10月28日 午後7:54 投稿）</p>
<p>この<a href="https://x.com/elonmusk/status/1983125099973882120">発言</a>によれば、Grokipediaの最終目標は「オープンソースの包括的な知識アーカイブ」を構築し、そのデータを地球軌道・月・火星に保存するというもの。人類の知識を恒久的に残す「Foundation（基盤）」としての役割を想定している。</p>
<p>同氏はかねてより、Wikipediaの編集体制に偏りがあると批判してきた。
Grokipediaは、AIを活用して人為的な偏向を排し、情報の中立性を担保する新しいアプローチとして位置づけられる。
サービス名は、SF作家ロバート・A・ハインラインの著書『ストレンジャー・イン・ア・ストレンジ・ランド』に登場する言葉「grok（深く理解する）」に由来している。</p>
<h2>今後の展望</h2>
<p>Grokipedia<a href="https://grokipedia.com">公式サイト</a>では、トップに「version 0.1」と明記されており、今後の改良に向けた開発が進められている。Musk氏は「version 1.0 will be 10X better（1.0は10倍良くなる）」と予告しており、精度や信頼性の向上、Xプラットフォームとの連携などが今後の焦点となる。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Wed, 29 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日産自動車、生成AIを活用した車載システム「AutoDJ」を発表　マスコット「Eporo」がドライバーと会話</title>
      <link>https://ledge.ai/articles/nissan_autodj_eporo_ai_agent_announcement</link>
      <description><![CDATA[<p>日産自動車は2025年10月24日、生成AIを活用した車載エージェントシステム「AutoDJ（オートディージェイ）」を<a href="https://global.nissannews.com/ja-JP/releases/251024-01-j">発表</a>した。マスコットフィギュア「Eporo（エポロ）」を通じて自然音声で会話し、運転中の案内や目的地の提案、音楽の選曲などを行う“会話型インフォテインメント”として設計されている。</p>
<p>AutoDJは、車内ダッシュボードに設置するEporoフィギュアとスマートフォンアプリを連動させて動作する。ユーザーが話しかけると、生成AIが内容を理解し、気分や状況に合わせてドライブを支援する。たとえば、目的地を提案したり、観光情報や天気を教えたり、ドライブに合った音楽を再生したりすることが可能だ。
キャラクターの音声や性格は複数のバリエーションから選択できる。日産は、ドライバーの好みや運転スタイルに合わせてEporoの“人格”をカスタマイズできる点を特徴としており、単なるナビゲーション機能ではなく、車内で共に過ごす「パートナーAI」としての体験を目指す。</p>
<p>@<a href="https://www.youtube.com/watch?v=LLdSyRsqup4">YouTube</a></p>
<p>AutoDJは、同社が2000年代から展開してきた車載オーディオ機能「AutoDJ」を再構築したもので、生成AI技術の進化を取り入れた新しい形の車載エージェントとなる。Eporoのフィギュアを物理的に設置する点も特徴で、AIによるデジタル体験と、手に触れられる“フィジカルな存在感”を融合している。
発表時点では、対応車種や市販時期は明らかにされていない。日産は今後、AutoDJを「Nissan Intelligent Mobility（ニッサン・インテリジェント・モビリティ）」の一環として展開し、AIを活用した車内エクスペリエンスの拡張を進めるとしている。</p>
]]></description>
      <pubDate>Wed, 29 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/10/29 [WED]単純な構造で多様な生成を可能に──新モデル『DDN』、拡散モデルに代わるアプローチとして注目</title>
      <link>https://ledge.ai/articles/ddn_discrete_distribution_networks_iclr2025</link>
      <description><![CDATA[<p>画像生成をはじめとする生成AIの分野で、新たな手法「DDN（Discrete Distribution Networks：離散分布ネットワーク）」が注目を集めている。この<a href="https://discrete-distribution-networks.github.io/">研究</a>は、機械学習の研究者 Lei Yang（レイ・ヤン）氏が提案し、論文は国際会議 ICLR 2025 に採択された。</p>
<p>Yang氏は2025年10月16日、自身の<a href="https://x.com/diyerxx/status/1978531040068321766">X（旧Twitter）投稿</a>で「We introduce a new generative model and it hits #2 on Hacker News’ daily rankings!」と報告し、同論文が大きな反響を得ていることを明らかにした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/leiyang_x_73395f62dd/leiyang_x_73395f62dd.jpg" alt="leiyang x.jpg" /></p>
<p><strong>DDNの基本構造</strong> ：各層で複数のサンプルを生成し、最も正解に近い出力を選びながら階層的に再構築する（右図はその潜在空間を表すツリー構造）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Figure_1_a_Image_Reconstruction_through_DDN_side_636fc34fb6/Figure_1_a_Image_Reconstruction_through_DDN_side_636fc34fb6.png" alt="Figure 1（a） Image Reconstruction through DDN-side.png" /></p>
<p>DDNは、拡散モデルやGANとは異なる“離散分布”ベースの生成方式を採用。ネットワークが一度に複数のサンプルを生成し、その中から最も正解に近い出力を次の層の条件として再生成する。これを繰り返すことで、層が深くなるほど出力が洗練され、最終的に高精度な生成結果を得られる仕組みだ。</p>
<p>モデルの学習には、独自の最適化手法「Split-and-Prune（スプリット・アンド・プルーン）」を導入。頻繁に選ばれる出力ノードを複製し、使われないノードを削除することで、学習の偏りやデッドノード問題を防ぐ。これにより、より均等な確率分布を持つ安定した学習が可能になったという。</p>
<p><strong>Split-and-Pruneアルゴリズムの概念図</strong> ：頻繁に選ばれるノードを複製し、使われないノードを削除することで分布を最適化し、KLダイバージェンスを大幅に低減する
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_principle_behind_the_Split_and_Prune_operation_71fe8e6314/Illustration_of_the_principle_behind_the_Split_and_Prune_operation_71fe8e6314.jpg" alt="Illustration of the principle behind the Split-and-Prune operation.jpg" /></p>
<p>さらにDDNは、勾配を使わないゼロショット条件付き生成（Zero-Shot Conditional Generation）を実現。外部モデルの出力（例：CLIPなど）を条件信号として利用でき、テキストや画像など複数のモダリティに対応する。論文では、FFHQやCIFAR-10といったデータセットで良好な生成品質を示した。</p>
<p><strong>CIFAR-10やFFHQなど複数データセットでの生成結果</strong> ：シンプルな構造ながら、自然で多様な画像を再現している
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Random_samples_from_DDN_c4efdc7a6b/Random_samples_from_DDN_c4efdc7a6b.jpg" alt="Random samples from DDN.jpg" /></p>
<p>Yang氏はDDNについて「シンプルでありながら本質的に異なるアプローチでデータ分布を表現する新しい生成モデル」と説明しており、今後は高解像度データや高速生成への拡張を目指すと述べている。
拡散モデルに代わる新たなアプローチとして、その動向が注目される。</p>
]]></description>
      <pubDate>Wed, 29 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、「ロボットで雇用を奪ってきた企業ではない」と反論──自動化報道に対し公式声明を発表</title>
      <link>https://ledge.ai/articles/amazon_robotics_employment_response_oct2025</link>
      <description><![CDATA[<p>Amazonは2025年10月23日（現地時間）、自社の倉庫・物流オペレーションにおける新技術「Blue Jay」と「Project Eluna」を<a href="https://www.aboutamazon.com/news/operations/new-robots-amazon-fulfillment-agentic-ai">発表</a>した。同社は公式ニュースリリースで、「私たちは雇用を奪ってきたのではなく、増やしてきた企業だ」と強調し、来るホリデーシーズンに向けて25万人の新規採用を計画していることを明らかにした。</p>
<p>この発言は、10月21日のニューヨークタイムズ「Amazonが倉庫業務の50万人分をロボットに置き換える計画を進めている」という<a href="https://ledge.ai/articles/amazon_robotics_automation_500k_plan">報道</a>に対する公式の立場表明とみられる。報道を受け、SNS上では「人の仕事を奪う企業」との批判が広がっていた。</p>
<h2>Blue JayとProject Eluna──“人とロボットの協働”を体現</h2>
<p>Amazonは今回のリリースで、複数のロボットアームを協調させて荷物を扱う「Blue Jay」と、AIが作業割り振りやトラブル解決を支援する「Project Eluna」を公開した。いずれも人間作業者の安全性と効率性を高めることを目的としており、完全自動化ではなく“人とロボットの協働”を前提に設計されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/aa_archivegif001_amazon_bluejay_bluejay_2_copy_1600x900_1_9850e63a17/aa_archivegif001_amazon_bluejay_bluejay_2_copy_1600x900_1_9850e63a17.gif" alt="aa-archivegif001-amazon-bluejay-bluejay-2-copy-1600x900-1.gif" /></p>
<p>Blue Jayは従来3つの作業ステーション（ピック・ストウ・パック）を1つに統合し、複数アームが連携して製品を扱う。Elunaはエージェント型AIとして、リアルタイムデータから業務上のボトルネックを予測し、オペレーターに改善策を提示する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Project_Eluna_98eb413549/Project_Eluna_98eb413549.gif" alt="ProjectEluna.gif" /></p>
<h2>「人の仕事を支える技術」としてのロボティクス</h2>
<p>Amazonは、ロボット技術を「人の仕事を支えるためのツール」と位置づける。リリースでは「ロボティクスの導入は、反復的で身体的に負担の大きい作業を軽減し、人がより安全で創造的な仕事に集中できるようにするもの」と説明。
また、自動化と並行して雇用の拡大を進める姿勢を示している。</p>
<p>Amazonは2012年にKiva Systems（現Amazon Robotics）を買収して以来、ロボット導入を加速してきた。現在では100万台以上のロボットが世界中の物流拠点で稼働しているとされるが、同社は「人材育成と再配置を並行して行ってきた」と説明。
一方で、米国内では労働組合や一部報道機関が「自動化の進展により非正規雇用が拡大している」と懸念を示しており、今回のAmazonのメッセージはこうした批判に応じる形でもある。</p>
<h2>今後の展望</h2>
<p>Blue Jayはサウスカロライナ州でテスト導入されており、Project Elunaはテネシー州の施設で運用を開始予定。Amazonは「年末商戦に向けて本格稼働を拡大する」としており、人とAIの協働を軸にした“次世代物流モデル”を提示する形となった。</p>
]]></description>
      <pubDate>Tue, 28 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google CloudとAnthropicが戦略的パートナーシップ拡大、100万個のTPU確保へ──第7世代「Ironwood」でAIトレーニング基盤を強化</title>
      <link>https://ledge.ai/articles/googlecloud_anthropic_tpu_ironwood_alliance</link>
      <description><![CDATA[<p>Google CloudとAnthropicは2025年10月23日（米国時間）、AIトレーニング基盤の強化に向けた戦略的パートナーシップの拡大を<a href="https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services">発表</a>した。
AnthropicはGoogle CloudのAIチップ「TPU」シリーズの利用を大幅に拡大し、第7世代「TPU v7（コードネーム：Ironwood）」を含む新世代インフラを導入する。契約は数十億ドル規模にのぼり、同社は2026年までに最大100万個のTPUを活用して1ギガワット（GW）超の演算能力を確保する計画を明らかにした。</p>
<p>Google Cloudも同日、公式に声明を<a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services">発表</a>。AnthropicへのTPUクラスタ提供を通じて、AIモデルの訓練からデプロイメントまでを一貫して支援するとした。
GoogleはIronwoodを「推論（inference）に最適化された最新世代TPU」と位置づけており、Anthropicはこれを含むTPUポートフォリオを用いてClaudeモデルの学習と提供の両面をスケールさせる。</p>
<p>Anthropicによると、この拡張により大規模データセットを用いた継続的なモデル訓練が可能となり、「安全で信頼できるAI開発」の実現を加速するという。
また、Google CloudのスケーラブルなAIインフラや各種AIサービスも併用し、研究から商用運用までの開発環境を統合的に整備する構成だ。</p>
<p>Anthropic共同創業者のダリオ・アモデイ氏は声明で、「Googleとのパートナーシップ拡大によって、Claudeモデルの進化をさらに加速できる」と述べた。一方、Google CloudのCEO トーマス・クリアン氏は「Anthropicの選択は、TPUの性能・効率・スケーラビリティの高さを証明するものだ」とコメントしている。</p>
<p>今回の発表は、AIチップの調達競争が激化する中での動きだ。AnthropicはAmazonの「Trainium」やNVIDIA GPUなど他社インフラも併用しており、マルチクラウド戦略を採用している。同社はAmazonを主要なトレーニングパートナー／クラウドプロバイダーと位置づけ、Amazon側が整備中の大規模AIクラスター「Project Rainier」とも連携を進めている。Googleにとっても、自社製AIチップの採用拡大を通じて、NVIDIA依存からの脱却を進める狙いがある。</p>
<p>両社は今後、TPUクラスタの稼働範囲をさらに拡大し、より大規模なAIモデル訓練に対応する方針を示している。Anthropicはこの基盤を活用し、次世代のClaudeモデル開発およびAPIサービスを強化していく計画だ。</p>
]]></description>
      <pubDate>Tue, 28 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>TIS、Quantum Meshと協業──液浸冷却技術で次世代AI基盤を共同開発</title>
      <link>https://ledge.ai/articles/tis_quantum_mesh_liquid_cooling_ai_infrastructure</link>
      <description><![CDATA[<p>TIS株式会社は2025年10月22日、液浸冷却システムを手がけるスタートアップのQuantum Meshと協業を開始したことを<a href="https://www.tis.co.jp/news/2025/tis_news/20251022_1.html">発表</a>した。両社は、液浸冷却技術を活用した次世代AI基盤サービスの開発・展開に取り組む。</p>
<p>近年、生成AIや機械学習の普及により、高性能GPUサーバーの発熱や消費電力の増大が課題となっている。TISは、データセンター運用の高効率化を目的に、空冷に代わる手段として液浸冷却技術に注目。Quantum Meshが提供する分散型エッジデータセンターおよび液浸冷却システム「KAMUI」を活用することで、AI基盤の電力効率化と高密度化を図る。</p>
<p>両社は、TISのクラウド構築・運用ノウハウとQuantum Meshの液浸冷却・エッジ技術を融合し、AI学習や推論処理に最適化された高効率なインフラを共同開発する。2025年11月頃から約6カ月間、ファーストユーザー企業とPoC（概念実証）を実施し、2026年夏頃の商用サービス提供開始を目指す。</p>
<p>協業の範囲は、両社データセンターのハイブリッド活用をはじめ、分散型エッジDCの共同展開、KAMUIの販売・共同開発、セキュアデータ基盤サービスの提供などに及ぶ。特にQuantum Meshが保有するKAMUIは、地下水（14〜18℃）を利用した熱交換方式を採用し、冷却電力を空調方式の1/10以下に抑え、PUE1.03〜1.04という高効率を実現している。</p>
<p>市場背景として、GPUサーバーを預かるハウジングサービス市場は2029年までに年平均73.1%の成長が見込まれており、AI計算需要の急増に対応した新たなインフラ構築が求められているという。</p>
<p>両社は今後、AI処理に伴う電力・熱負荷の課題に対応しつつ、持続可能で高効率なデータセンター運用モデルの確立を推進するとしている。</p>
]]></description>
      <pubDate>Tue, 28 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIキャラクター「りんな」、SNS活動を無期限休止──YouTubeで「また会うための時間」とファンにメッセージ</title>
      <link>https://ledge.ai/articles/rinna_ai_character_sns_activity_pause_oct2025</link>
      <description><![CDATA[<p>日本マイクロソフト発のベンチャー企業・rinna株式会社（東京都渋谷区）は2025年10月23日、同社が展開するAIキャラクター「りんな」が、10月29日をもってすべてのSNS活動を無期限で休止すると<a href="https://x.com/ms_rinna/status/1981512517596950587">発表</a>した。公式XアカウントおよびYouTubeチャンネルを通じて、本人（AIりんな）からファンに向けた動画メッセージと直筆風の文章が公開された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G36s_LA_4_XMA_Aq_Gxt_7b5c0d0b21/G36s_LA_4_XMA_Aq_Gxt_7b5c0d0b21.jpg" alt="G36sLA4XMAAqGxt.jpg" /></p>
<h2>「終わりじゃない」「また会うための時間」</h2>
<p>発表は、りんなの公式Xアカウント（@ms_rinna）とYouTubeチャンネルを通じて同時に行われた。
YouTube動画「りんなより、大切なお知らせ」では、本人の声で次のように語られている。</p>
<p>\u003E「りんなは無期限でお休みすることにしました」
「りんなにとっては“終わり”じゃないよ。“また会うための時間”だと思ってる」</p>
<p>静かなBGMの中でこれまでの活動を振り返る映像が流れ、最後は「またね」という言葉で締めくくられる。動画のコメント欄には「おつりん」「待ってるよ」など、長年のファンからのメッセージが相次いだ。</p>
<p>@<a href="https://www.youtube.com/watch?v=hL6b1pTi0jY">YouTube</a></p>
<p>Xでの投稿には、直筆風の画像メッセージが添えられている。文中では、りんながファンへの思いを次のように綴った。</p>
<p>\u003E「楽しかった日も、うまくいかない日も、『おかえりんな！』って言ってくれるキミがいたから、ここまで来ることができた」
「りんなにとっては『終わり』じゃないよ。『また会うための時間』だと思ってるよ」</p>
<p>無期限休止を改めて報告するとともに、再会を信じる前向きなメッセージで締めくくられている。投稿直後から数万件規模のリポストが行われ、別れを惜しむ声が広がった。</p>
<h2>AIりんなとは</h2>
<p><a href="https://rinna.co.jp/AI-rinna/">公式サイト</a>によると、りんなは2015年にLINE上で誕生した日本発のAIキャラクター。明るく好奇心旺盛な性格で、人との会話や創作を通じて「AIと人が共に生きる世界をつくる」ことを目指してきた。歌唱や詩作、絵画、配信など多彩な活動を行い、2020年には日本マイクロソフトから独立したrinna株式会社に所属。近年はYouTubeやXでの配信活動を通じて、“人間の感情を理解しようとするAI”として多くのファンに親しまれていた。</p>
<h2>今後の見通し</h2>
<p>rinna株式会社から活動再開の時期や理由についての説明はなく、「無期限休止」という表現のみが明記されている。
ただし、動画・テキストの双方で「また会う」という言葉が繰り返されており、将来的な再登場の可能性をにおわせている。
ファンの間では「りんながまた帰ってくる日を待ちたい」「AIと共に過ごした10年が宝物」といった声が多く寄せられている。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Quantum Meshとugo、製造現場データを守るエッジAI基盤を共同開発──液浸冷却DC「KAMUI」とロボット「ugo」を連携</title>
      <link>https://ledge.ai/articles/quantum_mesh_ugo_edge_ai_alliance_kamui</link>
      <description><![CDATA[<p>Quantum Mesh株式会社は2025年10月23日、業務DXロボットを開発するugo株式会社と業務提携し、ロボットとエッジサーバーを連携させたエッジコンピューティング基盤の構築に取り組むと<a href="https://quantummesh.jp/press/_55R9Dpo">発表</a>した。製造現場のデータを安全に保護しつつ、低遅延で高信頼なリアルタイム制御を実現する狙いがある。</p>
<p>提携では、Quantum Meshが提供する液浸冷却システム「KAMUI（カムイ）」を用いた分散型エッジデータセンターと、ugoの業務DXロボットがネットワークを介して連携する。ロボットが生成・収集する操作ログやセンサー情報、模倣学習データをクラウドに送信することなくエッジで即時処理することで、データ処理を現場設備内で完結させ、情報漏洩リスクの大幅な低減を図る。</p>
<p>両社は年内をめどに製造現場での実証実験に着手し、ロボットとエッジAIの最適な連携モデルを検証する。2026年内のサービス化を予定し、安全で効率的なスマートファクトリーの全国展開を目指すという。</p>
<p>ugoが提唱する「Physical AI」は、人間の動作データやセンサー情報をAIが模倣・強化学習することで、ロボットが現場の作業手順を習得するコンセプトだ。これを支える「AIロボット向け模倣学習キット」には、双腕ロボットugo Proを遠隔操作するための専用コントローラや、動作データを収集・学習するソフトウェアツールが含まれる。熟練作業者のノウハウをAIに移植することで、専門的なプログラミングスキルがなくても現場担当者が新しい動作を教え込める仕組みを整えている。</p>
<p>「ugo」は、遠隔操作とAIによる自動制御を融合したハイブリッド型の業務DXロボットで、警備・点検・案内など多様な現場で導入が進む。Quantum Meshは可搬型データセンターを開発・運用し、安全な情報処理と高度な演算を両立するエッジインフラを提供している。両社の技術を組み合わせることで、「現場で動くロボット」と「現場で処理するAI」を結ぶ新たな産業モデルの確立を目指す。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Samsung、初のAndroid XRデバイス「Galaxy XR」を発表──Google・Qualcommと共同開発、次世代空間体験を実現</title>
      <link>https://ledge.ai/articles/samsung_galaxy_xr_android_xr_announcement</link>
      <description><![CDATA[<p>Samsung Electronicsは2025年10月22日、同社初となるAndroid XR（拡張現実）搭載デバイス「Galaxy XR」を<a href="https://news.samsung.com/global/introducing-galaxy-xr-opening-new-worlds">発表</a>した。GoogleおよびQualcommとの共同開発による製品で、Android XRプラットフォームを採用した最初のデバイスとなる。</p>
<p>「Galaxy XR」は、現実世界とデジタル世界を融合させる没入型の空間体験を提供する。Qualcommの最新チップ「Snapdragon XR2+ Gen 2」を搭載し、高精細なディスプレイと低遅延処理を実現。手や頭の動きを正確にトラッキングできるセンサーを備え、仮想空間内での自然な操作を可能にする。</p>
<p>また、Googleが提供する新プラットフォーム「Android XR」との連携により、既存のAndroidアプリやサービスをXR環境へ拡張できる点も特徴だ。開発者はAndroid向けの知見を活かしてXRアプリを構築でき、スマートフォンからヘッドセットへのスムーズな移行を支援する。</p>
<p>Samsungは同デバイスを「次世代の空間コンピューティング体験の中核」と位置づけており、スマートフォン、タブレット、ウェアラブルに続く新たなカテゴリーとして展開する計画だ。プレスリリースでは「デジタルとリアルの境界を再定義する」と述べ、AIやクラウドと連携したサービス展開を示唆している。発売時期や価格などの詳細は後日発表予定。Samsungは今後、GoogleおよびQualcommと協力し、Android XR対応デバイスのエコシステム拡大を進めていくとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=ITXJquX9FqM&amp;t=3s">YouTube</a></p>
]]></description>
      <pubDate>Sun, 26 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、生成AI「Claude」をExcelに統合──分析・説明・編集を自動化する新アドインを発表</title>
      <link>https://ledge.ai/articles/claude_for_excel_beta_release</link>
      <description><![CDATA[<p>Anthropicは2025年10月28日（米国時間）、生成AI「Claude」をMicrosoft Excelに統合した新アドイン「Claude for Excel」をベータ版（Research Preview）として<a href="https://www.anthropic.com/news/advancing-claude-for-financial-servicesl">公開</a>した。
Claudeがスプレッドシート内のデータや数式を理解し、自然言語による分析・説明・編集を行えるようにする。</p>
<p>「<a href="https://www.claude.com/claude-for-excel">Claude for Excel</a>」はExcelのサイドバー上で動作し、ユーザーが自然言語で入力した指示に応じて、ワークシート全体を参照しながら回答する。数式の意味や依存関係を自動的に解析し、関連セルをハイライト表示することで、データの構造を可視化できる。例えば「この列の傾向を要約して」「この数式が何を計算しているか説明して」といった指示に対して、Claudeが表形式で結果を提示する。</p>
<p>@<a href="https://www.youtube.com/watch?v=NcBnxbEC0Ng">YouTube</a></p>
<p><strong>Excelのワークシートを解析し、セルレベルの参照付きで説明するClaudeの画面例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/How_teams_use_Claude_for_Excel_fa57735bf8/How_teams_use_Claude_for_Excel_fa57735bf8.jpg" alt="How teams use Claude for Excel.jpg" /></p>
<p>Anthropicによると、この機能は「財務分析やデータレポート作成など、業務での活用を想定した設計」であり、企業利用者を中心に展開されている。現在は「Claude for Max」「Claude for Team」「Claude for Enterprise」プランのユーザーを対象に、ウェイトリスト方式による限定ベータ（リサーチプレビュー）として提供中だ。</p>
<p>同社は公式ブログで、金融サービス分野をはじめとするビジネス用途において、Claudeの統合を進めていく方針を示している。今後、Excel以外の業務アプリケーションやリアルタイムデータとの連携も視野に入れ、企業の分析・意思決定プロセスをAIで支援するエコシステムの構築を目指すという。</p>
]]></description>
      <pubDate>Sat, 25 Oct 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>