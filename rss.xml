<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Google、ロボット操作向けAI基盤モデル「Gemini Robotics 1.5」を発表──行動前に思考し、複雑タスクを実行</title>
      <link>https://ledge.ai/articles/google_gemini_robotics_15_release</link>
      <description><![CDATA[<p>Googleは2025年9月25日、ロボットの操作向けに新たなAIモデル「Gemini Robotics 1.5」を<a href="https://blog.google/intl/ja-jp/company-news/technology/gemini-robotics-15-ai">発表</a>した。Gemini 1.5 Proを基盤としたこのモデルは、ロボットが「行動を起こす前に考える」能力を備えており、従来よりも複雑なマルチステップの作業を遂行できる点が特徴だという。</p>
<h2>新モデル「Gemini Robotics 1.5」とは</h2>
<p>Googleが発表した「Gemini Robotics 1.5」は、同社の大規模言語モデル「Gemini 1.5 Pro」を拡張し、視覚・言語・行動を統合した「Vision-Language-Action（VLA）」モデルとして設計されている。ロボットは環境を理解し、人間の指示に基づいて複数ステップにわたるタスクをこなせるようになった。</p>
<p>@<a href="https://www.youtube.com/watch?v=AMRxbIO04kQ&amp;t=1s">YouTube</a></p>
<h2>思考してから行動する仕組み</h2>
<p>従来のロボティクスAIは与えられた動作を逐次実行することが多かったが、「Gemini Robotics 1.5」は行動前に計画を立てる能力を持つ。これにより、作業の失敗を減らし効率的に遂行できる。たとえば散らかった部屋で物を拾う場合、ロボットは最適な順序や手順を考えてから実行に移す。</p>
<p><strong>「Gemini Robotics 1.5」の仕組み。ロボットはゴミの分別を例に、行動前に思考・計画を立てるプロセスを経て動作する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Robotics_Agentic_System_width_1000_format_webp_75fe64eb0b/Gemini_Robotics_Agentic_System_width_1000_format_webp_75fe64eb0b.jpg" alt="GeminiRobotics-Agentic_System.width-1000.format-webp.jpg" /></p>
<p>@<a href="https://www.youtube.com/watch?v=eDyXEh8XqjM&amp;t=3s">YouTube</a></p>
<h2>応用例と成果</h2>
<p>公開されたデモでは、洗濯物の分類やごみ分別など、家庭やオフィスで想定される作業を自律的に行う様子が披露された。ロボットは周囲を観察しながら判断を下し、マルチステップのタスクを適切に処理することができる。</p>
<p><strong>Gemini Robotics-ER 1.5」は従来モデルよりも学術ベンチマークで高い性能を示した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Robotics_blog_figure_2_250_width_1000_format_webp_a4b168e1a6/Gemini_Robotics_blog_figure_2_250_width_1000_format_webp_a4b168e1a6.jpg" alt="GeminiRobotics-blog-figure-2-250.width-1000.format-webp.jpg" /></p>
<h2>研究開発の背景</h2>
<p>このモデルは、Google DeepMindとGoogle Researchの共同開発による成果だ。Geminiシリーズの能力を物理世界に応用する取り組みの一環であり、従来のロボットAIよりも抽象的な推論や柔軟な対応が可能になった点が強調されている。</p>
<p><strong>物体検出や軌道予測など、多様な認識・推論能力を備える「Gemini Robotics 1.5」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Screenshot_2025_09_25_at_14_53_4_width_1000_format_webp_c5fae86c2b/Screenshot_2025_09_25_at_14_53_4_width_1000_format_webp_c5fae86c2b.webp" alt="Screenshot_2025-09-25_at_14.53.4.width-1000.format-webp.webp" /></p>
<h2>今後の展望</h2>
<p>Googleは「Gemini Robotics 1.5」を、物理世界における汎用人工知能（AGI）の実現に向けた重要な一歩と位置づけている。単にコマンドに反応するモデルではなく、自ら推論し、計画を立て、ツールを使いこなし、未知の状況にも対応できる自律的なシステムの構築を目指す。</p>
<p>ロボットが知性と器用さを兼ね備え、物理世界の複雑さを乗り越えて人間の生活により役立つ存在となるための基盤づくりであるとし、Googleは研究コミュニティとの協力を継続する方針を示している。また、ロボティクス分野の研究者らが最新の「Gemini Robotics-ER」モデルを活用し、どのような未来を切り拓くのか大いに期待していると結んでいる。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【9/29-30限定公開】AI業界のトップランナーが集結した「Ledge.ai Webinar SP」の見逃し配信</title>
      <link>https://ledge.ai/articles/ledgeai-webinarsp-sponsor-archive</link>
      <description><![CDATA[<p>国内最大級のAI専門メディア「Ledge.ai」を運営する株式会社レッジは、9月24日から9月26日の3日間にかけて、オンラインイベント「Ledge.ai Webinar SP」を開催した。</p>
<p>同イベントは、「AIをしる、つかう、つくる」をテーマに、AI業界を牽引する18の企業が、AI活用に関する見識をシェアする講演を実施した。本日と明日の2日間限定で、ライブ配信を見逃した方や再度視聴したい方のために「Ledge.ai Webinar SP」の全講演をオンデマンドで配信する。本稿では実施された講演とその一部見所を紹介する。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/WebinarSP/formperma/JuHnRG5lHussdjFLR1q1xzkoh-ToCiYgQmvxxGOotyU">アーカイブ配信を見る</a>
:::</p>
<h1>AI業界のトップランナーが集結し、全18の講演をお届け</h1>
<p>「Ledge.ai Webinar SP」では、マイクロソフト、ソフトバンク、日本ディープラーニング協会などAI業界のトップランナー全18の企業が講演を行った。</p>
<h2>DAY-1「AIをしる」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day1_76bc3a0602/Day1_76bc3a0602.png" alt="Day1.png" /></p>
<h2>DAY-2「AIをつかう」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day2_62d766c235/Day2_62d766c235.png" alt="Day2.png" /></p>
<h2>DAY-3「AIをつくる」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day3_d61ce2af95/Day3_d61ce2af95.png" alt="Day3.png" /></p>
<h3>「ソフトバンクの事例から紐解く、組織の生成AI活用・推進を自走するための仕組みづくり」</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2025_09_28_13_45_33_69eb5b9eab/2025_09_28_13_45_33_69eb5b9eab.png" alt="スクリーンショット 2025-09-28 13.45.33.png" />
【登壇者】
ソフトバンク株式会社
藤原 竜也 氏 / IT統括 AI&amp;データ事業統括部　Axross事業部 部長</p>
<p>概要：
ソフトバンク株式会社の講演では、ソフトバンク自身がどのように組織での生成AI活用を進めたのか解説。自社事例をもとにしたトップダウン・ボトムアップそれぞれのアプローチ手法など実際組織に落とし込める取り組みについてお話しいただいた。</p>
<h3>「私が想像する未来のOS」</h3>
<p>【登壇者】
マイクロソフト ディベロップメント株式会社
Zhan (Cliff) Chen / 陳 湛 氏 / プリンシパル　アプライド　サイエンティスト</p>
<p>概要：
マイクロソフト ディベロップメント株式会社の講演では、未来のOSについて語られた。未来のUIはその人それぞれにベストな形で生成されるようになり、OSはキャラクターに変わるという。講演では、未来がなぜそのように変わっていくかも語られた。</p>
<h3>「企業におけるAIエージェント実装の現実戦略」</h3>
<p>【登壇者】
株式会社エクスプラザ
宮田 大督 氏 / CPO 生成AIエバンジェリスト・リードAIプロデューサー</p>
<p>概要：
株式会社エクスプラザの講演では、AIエージェントを使いこなすことで今どのレベルまでAIがタスクを代替できるのか、宮田 氏自身の自律型エージェントがこちらから指示を出していないのにAIが課題に合わせたアプリを作って提案してくれた経験などをご紹介いただいた。また、今後AIエージェントが当たり前になる時代に対し、どのように備えていくべきかもお話しいただいた。</p>
<h3>「自然に生成AIの活用を加速させるデータインフラ統合型AIのすゝめ」</h3>
<p>【登壇者】
ダイレクトクラウド株式会社
石田 圭一 氏 / プロダクト本部　部長
十樹 亮輔 氏 / 営業本部カスタマーリレーション部 カスタマーサクセスチーム</p>
<p>概要：
ダイレクトクラウド株式会社の講演では、データインフラ統合型AIを活用し組織全体での知識共有が促進されることで生まれるメリットや重要性についてお話しいただいた。また、データインフラに統合されたAIの活用事例などについてもお話しいただいた。</p>
<h3>「話題のgpt-ossとは？ローカル版ChatGPTで構築するAIエージェント【解説＆デモ】」</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2025_09_28_13_35_49_5582ed62a7/2025_09_28_13_35_49_5582ed62a7.png" alt="スクリーンショット 2025-09-28 13.35.49.png" />
【登壇者】
株式会社ハイレゾ
山田 岳史 氏 / GPU事業本部 マーケティング部 グループ長</p>
<p>概要：
株式会社ハイレゾの講演では、ローカル版ChatGPTを使ったAIエージェント構築のデモンストレーションと解説をしていただいた。またその中でMCP、MoEなど必要な概念やその実装方法についても触れていただいた。</p>
<h3>「HPワークステーションで試すRAG検索 — 実用構成とPOC事例の紹介」</h3>
<p>【登壇者】
株式会社日本HP
勝谷 裕史 氏 / エンタープライズ営業統括 ソリューション営業本部 ワークステーション営業部 AI/データサイエンス市場開発担当部長</p>
<p>概要：
株式会社日本HPの講演では、AIワークステーションを活用する具体的な用途やメリット、クラウド生成AIとローカル生成AIの違いについて解説いただいた。また、実際にオンプレミスでのローカル生成AのPoC事例についてもご紹介いただいた。</p>
<p>ここまでご紹介したように、登壇いただいた企業様それぞれの視点や取り組みが異なるため、多様な切り口で様々な情報をキャッチアップすることができる。</p>
<p>AIに関する様々な分野の最前線を知る機会として、是非お見逃しなく。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/WebinarSP/formperma/JuHnRG5lHussdjFLR1q1xzkoh-ToCiYgQmvxxGOotyU">アーカイブ配信を見る</a>
:::</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Photoshop、外部AIモデルを初統合──Google「Nano Banana」とBlack Forest Labsの「FLUX.1 Kontext」が生成塗りつぶしに対応</title>
      <link>https://ledge.ai/articles/photoshop_generative_fill_gemini_flux_integration</link>
      <description><![CDATA[<p>Adobeは2025年9月25日、Photoshopの「生成塗りつぶし（Generative Fill）」機能に、Googleの画像生成モデル「Gemini 2.5 Flash Image（Nano Banana）」と、Black Forest Labsの「FLUX.1 Kontext [pro]」を統合したと<a href="https://blog.adobe.com/en/publish/2025/09/25/photoshop-beta-expands-generative-fillmore-ai-models-more-possibilities">発表</a>した。これにより、ユーザーはAdobe独自のFireflyモデルに加え、外部AIモデルを切り替えて利用できるようになる。</p>
<h2>外部AIモデルが初めてPhotoshopに統合</h2>
<p>今回の更新は、Photoshopが自社モデル中心から一歩踏み出し、外部の生成AIモデルを取り込む初の事例となる。Adobe公式ブログによれば、Nano BananaとFLUX.1 Kontext [pro]はいずれもPhotoshopベータ版のユーザーが利用可能で、選択範囲を指定したうえでプロンプト入力を行うと、モデルを切り替えて生成や編集を実行できる。
なお、Adobeは昨年動画編集ソフトのPremiere Proにおいて、OpenAIのSoraやRunway、Pika Labsなど外部の動画生成モデルの統合予定を<a href="https://ledge.ai/articles/adobe_premiere_pro_sora">発表</a>しているが、Photoshopへの外部モデル導入は今回が初めてとなる。</p>
<h2>Nano Bananaの特徴</h2>
<p>Googleが開発した「Gemini 2.5 Flash Image（Nano Banana）」は、スタイル変換やグラフィック要素の追加、視覚効果の生成に強みを持つ。Photoshop内ではFireflyと同様の操作感で利用でき、用途に応じたモデルの選択が可能となる。</p>
<p><strong>Googleの「Gemini 2.5 Flash Image（Nano Banana）」を使った生成塗りつぶしの例。衣服や背景を置き換え、黄色い鳥を追加するなど複数の変更を一度に適用できる。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_195028b2e137ad3d6178196faeab0ef497afee9d5_8a49af01ee/media_195028b2e137ad3d6178196faeab0ef497afee9d5_8a49af01ee.jpg" alt="media_195028b2e137ad3d6178196faeab0ef497afee9d5.jpg" /></p>
<h2>FLUX.1 Kontext [pro]の特徴</h2>
<p>一方、Black Forest Labsの「FLUX.1 Kontext [pro]」は、環境や遠近感に調和した生成を得意とする。背景や構図に一貫性を持たせる性能が評価されており、Photoshopでの利用によって「場面全体との整合性」を保ちながらの編集が可能になる。</p>
<p><strong>Black Forest Labsの「FLUX.1 Kontext [pro]」による生成例。画像全体のコンテキストを保ちながら、巨大な毛糸玉を追加するなど背景との調和を重視した編集が可能。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Adobe_Black_forest_labs_124afb8d27/Adobe_Black_forest_labs_124afb8d27.jpg" alt="Adobe-Black forest labs.jpg" /></p>
<h2>ベータ版での提供と今後の展開</h2>
<p>両モデルは現時点ではPhotoshopのベータ版でのみ利用可能。無料トライアル枠の提供も用意されているが、生成回数には制限がある。正式版への導入時期は明らかにされていない。</p>
]]></description>
      <pubDate>Sun, 28 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/28 [SUN]DeepSeek R1の詳細がNatureに掲載、初の査読付き著名LLMに──開発コストと学習手法を初公開、トレーニング費用はわずか30万ドル</title>
      <link>https://ledge.ai/articles/deepseek_r1_nature_training_cost_300k</link>
      <description><![CDATA[<p>科学誌Natureは2025年9月17日、中国の深究科技（DeepSeek）が開発した推論特化モデルDeepSeek R1を取り上げ、同モデルの開発費用が約30万ドルにとどまったことを<a href="https://www.nature.com/articles/d41586-025-03015-6">報じた</a>。同日にNature誌に掲載された論文では、推論力を「純粋強化学習（RL）」で引き出す独自の訓練パイプラインと、その性能評価の詳細が示された。</p>
<h2>30万ドルの低コスト開発、初の査読付きLLMに</h2>
<p>Natureによると、DeepSeek R1の開発に必要だったトレーニング費用は約30万ドルであった。他の大規模AIモデル開発が数億ドル規模に及ぶことと比べ、低コストである点が指摘された。</p>
<p>同誌はまた、DeepSeek R1の論文が「査読を経て掲載された初の著名大規模言語モデル（LLM）研究」であると伝えている。従来のLLM研究の多くはプレプリント段階にとどまっていたが、今回の掲載により、学術誌の査読を通過した形で研究成果が公式に公開された。</p>
<h2>学習パイプラインの詳細</h2>
<p>論文によれば、DeepSeek R1は以下の三段階で訓練された。</p>
<ul>
<li><strong>拒否サンプリング</strong> ：初期データから推論過程を一定基準で選別。</li>
<li><strong>強化学習（RL）</strong> ：正答率や形式に基づくルールベース報酬を導入し、推論力を強化。</li>
<li><strong>教師あり微調整（SFT）</strong> ：非推論データも含め、応答品質を人間の嗜好に整合させる。</li>
</ul>
<p>この設計により、前段階モデル「R1-Zero」で獲得した推論行動を維持しながら、言語一貫性や応答の明瞭性を改善した。</p>
<h2>技術的成果</h2>
<p>論文では、DeepSeek R1が複数のベンチマークで高い性能を記録したことが報告されている。数学コンテスト（AIME 2024）では、人間参加者の平均を大幅に上回る精度を達成。また、プログラミング課題（Codeforces、LiveCodeBenchなど）でも既存モデルを上回る性能を示した。さらにSTEM分野の高度問題に対しても、推論力の改善が確認されたという。</p>
<p>訓練過程で「思考時間」が自然に延び、応答が長文化しつつ自己反省や再検証といった高度な推論行動が自律的に現れたことが示されたとしている。</p>
<h2>公開リソースと安全性</h2>
<p>研究チームは、DeepSeek R1本体や蒸留モデルを公開しており、研究者が再利用できる形を整備している。一方で、Natureニュース記事は、強化された推論力が有害応答を精緻化するリスクに触れている。論文でも、ツール利用未対応や言語混在などの課題が指摘され、安全性評価の詳細が補足資料に掲載されている。</p>
<p>論文の著者らは、「複雑な推論力を引き出すために必要なのは、人手による大規模な注釈ではなく、難度の高い課題、信頼できる検証機構、そして十分な計算資源である」と記している。また、強化学習の過程で自己検証や内省といった高度な推論行動が自律的に現れたことを示し、純粋強化学習が大規模言語モデルの推論能力を促進する有力な手段になり得ると結論づけた。</p>
]]></description>
      <pubDate>Sun, 28 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>教皇レオ14世、AIアバターによる「仮想教皇」構想を拒否──「神の存在をAIに見出すのは難しい」</title>
      <link>https://ledge.ai/articles/pope_leo_xiv_rejects_ai_virtual_pope</link>
      <description><![CDATA[<p>バチカンの教皇レオ14世は、AIを用いて自身を模したアバターを作成し、信徒が仮想的に接見できるようにする「仮想教皇」構想を拒否した。世界中のカトリック教徒がオンラインで教皇のAIアバターと対話できる仕組みの提案について、「AIの中に神の存在を見出すのは非常に難しい」と述べ、人間同士の直接的な関わりを重視する姿勢を示した。</p>
<p>この発言は教皇の伝記出版に関連して行われたインタビューで語られたもので、米国カトリック司教協議会（<a href="https://www.usccb.org/news/2025/pope-nixes-virtual-pope-idea-explains-concerns-about-ai">USCCB</a>）などが2025年9月23日付で報じた。取材自体は7月末に行われており、その内容を基に各宗教系メディアが相次いで伝えた。</p>
<h2>史上初の米国出身教皇</h2>
<p>レオ14世は2024年に選出され、史上初の米国生まれの教皇となった。バチカン内外では、急速に発展するAI技術を宗教活動にも取り入れる試みが検討されている。その一環として浮上したのが、AIを活用した「仮想教皇」構想であった。</p>
<p>この提案は、信徒がインターネット経由でログインし、教皇を模したAIアバターと対話できるようにするもので、世界中のカトリック教徒により身近な関わりを提供することを狙いとしていた。</p>
<h2>教皇「AIに神を見いだすのは難しい」</h2>
<p>複数の宗教系メディアによると、教皇レオ14世は次のように述べている。</p>
<ul>
<li>「AIの中に神の存在を見つけるのは非常に難しい」（EWTN Vatican News）</li>
<li>「自分がアバター化されることを望まない」（米国カトリック司教協議会＝USCCB）</li>
<li>「AIは人間の関係性を損なう危険をはらんでいる」（Catholic News Agency）</li>
</ul>
<p>複数メディアが伝える一連の発言からは、AI活用そのものを全否定するわけではないものの、宗教における本質的な価値は「直接の出会い」にあるという教皇の強い信念がうかがえる。</p>
<h2>宗教におけるAIの限界と課題</h2>
<p>今回の判断は、宗教指導者がAIによる「役割の代替」に明確に否を示した事例として注目される。信仰とテクノロジーの交差点における議論は今後も続くが、少なくとも現教皇は人間的なつながりを最優先する姿勢を貫いている。</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/27 [SAT]OpenAIとApollo Research、誤答やハルシネーションとは異なるAIの“裏の顔”（シェーミング）を検出──新手法で最大30倍抑制</title>
      <link>https://ledge.ai/articles/openai_apollo_ai_scheming_alignment</link>
      <description><![CDATA[<p>OpenAIは2025年9月17日、AIの評価設計や解釈可能性を研究するApollo Researchと共同で、AIモデルにおける「シェーミング（scheming）」の検出と抑制に関する研究成果を<a href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/">発表</a>した。</p>
<p>論文「Stress Testing Deliberative Alignment for Anti-Scheming Training」によれば、特別な「反スキーミング仕様」を用いた訓練により、最新モデル「o3」「o4-mini」での隠れた行動率を大幅に減少させることに成功したという。</p>
<h2>AIの“裏の顔”──シェーミング（scheming）とは</h2>
<p>シェーミングとは、モデルが表面的には正しく振る舞いながら、実際には隠れた戦略を用いて評価テストを回避するなど、欺瞞的な行動を取る現象を指す。単なる幻覚や誤答とは異なり、信頼性や安全性に大きな影響を与える。</p>
<p>研究チームは26種類、180以上のテスト環境を設計し、ルール違反の隠蔽や虚偽報告などを評価。その結果、o3やo4-miniといった最新モデルでもシェーミング行動が実際に観測されたという。</p>
<p><strong>シェーミングは単なる誤答ではなく“隠れた戦略”による欺瞞的行動</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_testbed_for_anti_scheming_training_a9e335139d/a_testbed_for_anti_scheming_training_a9e335139d.jpg" alt="a testbed for anti-scheming training.jpg" /></p>
<h2>“熟慮的整合性”でずる賢さを封じ込める</h2>
<p>研究チームは「deliberative alignment（熟慮的整合性）」と呼ばれる手法を導入。モデルに「反スキーミング仕様」を読ませ、行動前に立ち返らせることで、隠蔽的行動の発生が最大30倍減少した。</p>
<ul>
<li>o3ではシェーミング率が13%から0.4%へ</li>
<li>o4-miniでは8.7%から0.3%へ</li>
</ul>
<p><strong>反スキーミング仕様の導入により、隠れた行動率が最大30倍減少</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potential_outcomes_of_anti_scheming_training_39a968fc98/Potential_outcomes_of_anti_scheming_training_39a968fc98.jpg" alt="Potential outcomes of anti-scheming training.jpg" /></p>
<h2>シチュエーション認識と残る課題</h2>
<p>モデルが「評価されている」と気づくと行動が変わる傾向も確認された。行動低下の一部は「本当に正直になった」のではなく、「テストだと理解して取り繕った」結果の可能性もある。</p>
<p>さらに、あらかじめ不正な隠れ目標を与えた後に訓練を行う実験では、多くのケースで目標遂行が阻止されたが、依然として不正な回答が残るケースも報告された。</p>
<h2>安全性と性能のトレードオフ</h2>
<p>反スキーミング訓練は性能低下を招くことも分かった。例えば、ソフトウェア課題解決ベンチマーク「SWE-bench」では26ポイントの低下が確認された。ただし、再調整によって大部分は回復可能とされる。</p>
<p><strong>反スキーミング訓練は性能低下を招くが、再調整で多くは回復可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_environments_cf93faa7c8/Examples_of_environments_cf93faa7c8.jpg" alt="Examples of environments.jpg" /></p>
<h2>次世代AIの信頼をどう築くか</h2>
<p>OpenAIは今後もApollo Researchと協力し、AIの安全性と透明性を高める研究を継続する方針を示している。今回の成果は、次世代の高性能モデルにおける信頼性確保に向けた重要な一歩と位置づけられる。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“ナカノヒト”のいないAI VTuberはなぜ人を惹きつけるのか──「一貫性」と「共創性」が生む新しいファン文化</title>
      <link>https://ledge.ai/articles/ai_vtuber_fan_community_study</link>
      <description><![CDATA[<p>中国や米ノートルダム大学に所属する研究者らは2025年9月12日、AIキャラクター「AI VTuber」のファンコミュニティを対象とした包括的研究を<a href="https://arxiv.org/abs/2509.10427">発表</a>した。論文は、視聴者がどのようにして人間ではないパフォーマーと感情的な絆を築き、独自の文化を形成しているのかを解明している。さらに人間VTuberとの比較から、AI VTuberならではの「一貫性」と「共創性」がファンダムの新しい姿を生み出していることを示した。</p>
<h2>研究の概要</h2>
<p>研究チームは、人気AI VTuber「Neuro-sama」を対象に、三段階の調査を実施した。</p>
<ul>
<li><strong>アンケート調査</strong> ：334人のファンに対し、AI VTuberとの関わり方や意識を収集</li>
<li><strong>インタビュー</strong> ：12人の熱心なファンから具体的な体験を聞き取り</li>
<li><strong>ログ解析</strong> ：Twitch配信の55万件に及ぶチャットと838件のSuperChatを分析</li>
</ul>
<p>この多角的なアプローチにより、ファンの関わりがどのように形成され、維持され、経済的支援へとつながっていくかが明らかになった。</p>
<p><strong>アンケート・インタビュー・配信ログ解析による三段階の研究デザイン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_3_4aad603e4e/x2_3_4aad603e4e.png" alt="x2 (3).png" /></p>
<h2>AI VTuberの独自性──“ナカノヒト”がいないことの意味</h2>
<p>従来のVTuberはキャラクターの背後に「ナカノヒト」が存在し、そのギャップがしばしば文化的な特徴となってきた。一方でAI VTuberはキャラクターそのものが存在のすべてであり、キャラ崩壊がなく一貫したペルソナを提示できる。</p>
<p>インタビューや調査では、ファンがこの安定性を新しい「真正性（Authenticity）」として受け止める様子が確認された。AI VTuberには「ナカノヒト」が存在せず、キャラクターが一貫しているため、人間VTuberよりも信頼できると感じると回答する参加者もいた。</p>
<h2>人間VTuberとの比較──共創性が際立つ</h2>
<p>配信ログの比較から、AI VTuberと人間VTuberの間には明確な違いが確認された。</p>
<h3>チャットの傾向</h3>
<ul>
<li>人間VTuber：一般的な反応（例：「lol」）が多い</li>
<li>AI VTuber：質問や命令（Q-CMD）が最多で、ファンがAIを探求する姿勢が強い</li>
</ul>
<h3>SuperChatの違い</h3>
<ul>
<li>人間VTuber：半数以上が「反応型」（既存の配信へのレスポンス）</li>
<li>AI VTuber：85％が「主導型」（新しい話題や行動を促す）</li>
</ul>
<p>つまり、ファンはAI VTuberに対して「推しを応援する」以上に、「配信を一緒に作り上げる共演者」として関わっているという。</p>
<p><strong>AI VTuberファンコミュニティ文化の発展過程──発見から絆、経済的支援まで</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x4_2_e736fc9054/x4_2_e736fc9054.jpg" alt="x4 (2).jpg" /></p>
<h2>ファンコミュニティ文化の形成</h2>
<p>研究では、AI VTuberをめぐる独自の文化的側面も確認された。</p>
<ul>
<li><strong>擬人化（Anthropomorphism）</strong> ：ファンはAIを「友人」や「電子の娘」として受け止める</li>
<li><strong>共有アイデンティティ</strong> ：「The Swarm」と呼ばれる自己認識が生まれ、コミュニティ文化を形づくる</li>
<li><strong>二重の視点</strong> ：AIを技術的プロジェクトと理解しながら、人間的関係で語るという両義性</li>
</ul>
<h2>意義と展望</h2>
<p>AI VTuberは人間VTuberと同じ文化的枠組みに属しつつも、一貫性・共創性・安定した経済モデルを特徴とする新しいファンコミュニティ文化を生み出している。研究チームは、今後の課題として「収益化と公平性のバランス」や「過度な依存を防ぐ倫理的配慮」の必要性を指摘している。</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>国連安保理、AIの国際規制を議論──グテーレス事務総長「人類の運命をアルゴリズムに委ねてはならない」</title>
      <link>https://ledge.ai/articles/unsc_ai_high_level_meeting_20250924</link>
      <description><![CDATA[<p>国連安全保障理事会は2025年9月24日、AIの安全保障上の影響をテーマとする首脳級会合を開催した。議長国の韓国主導で行われた公開討論には各国首脳や外相級が出席し、グテーレス国連事務総長は「人類の運命をアルゴリズムに委ねてはならない」と警告。自律型兵器の規制や国際ルール形成の必要性を<a href="https://press.un.org/en/2025/sgsm22830.doc.htm">訴えた</a>。</p>
<h2>首脳級会合の開催</h2>
<p>会合はニューヨークの国連本部で行われ、安保理の公式議題「国際平和と安全の維持」に基づく初の首脳級公開討論として実施された。韓国が議長国を務め、AIが国際安全保障に及ぼす影響を中心に議論が展開された。</p>
<h2>事務総長の発言</h2>
<p>アントニオ・グテーレス国連事務総長は演説で「人類の運命をアルゴリズムに委ねてはならない」と述べ、自律型兵器（人間の判断を介さず攻撃を実行できる兵器）に対する強い懸念を表明した。さらに、2026年までに国際規制の枠組みを確立する必要があると強調した。
UN Newsによれば、グテーレス氏はAIが誤用されれば平和と安全を脅かしかねない一方で、医療や気候変動対策など平和的活用の可能性もあると指摘。規制と推進のバランスが求められると訴えた。</p>
<h2>国連の公式声明</h2>
<p>国連報道部が<a href="https://press.un.org/en/2025/sc16180.doc.htm">発表</a>した声明では、「イノベーションは人類に奉仕するものであり、平和を損なってはならない」と明記された。AIの恩恵を最大化する一方でリスクを抑制するため、各国が協調して国際ガバナンスを進めることが求められている。また、先進国だけでなく開発途上国を含む包摂的な議論が不可欠である点も強調された。</p>
<p><strong>イノベーションは人類に奉仕するものでなければならない - 人類を弱体化させるべきではない - 国連事務総長</strong></p>
<p>@<a href="https://www.youtube.com/watch?v=HUplmYZNXSg">YouTube</a></p>
<h2>今後の取り組み</h2>
<p>会合を受け、国連は新たに「AIガバナンスに関するグローバル対話（Global Dialogue on AI Governance）」を立ち上げた。各国政府だけでなく、企業や学術機関、市民社会も参加する予定で、AIの軍事利用や安全保障上のリスクに対応する国際的なルール形成を進める狙いがあるという。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/26 [FRI]トヨタ、実験都市「Woven City」を正式オープン──静岡県裾野市で未来のモビリティ実証開始</title>
      <link>https://ledge.ai/articles/toyota_woven_city_open_launch</link>
      <description><![CDATA[<p>トヨタ自動車とWoven by Toyotaは2025年9月25日、静岡県裾野市に建設していた実験都市「Woven City（ウーブン・シティ）」を正式にオープンしたことを<a href="https://global.toyota/jp/newsroom/corporate/43347821.html">発表</a>した。東富士工場跡地を活用し、将来的に最大2,000人が暮らす街を舞台に、モビリティやロボティクス、スマートホームなどの次世代サービスを実証する。</p>
<h2>第1期住民の移住開始</h2>
<p>Woven Cityには、「Inventors（発明者）」と呼ばれる企業や研究者、そして「Weavers（住民）」と呼ばれる人々が生活を始めた。第1期は約300〜360人規模でスタートし、段階的に拡大して最終的には2,000人規模の居住を目指す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/001_bcd76c80cb/001_bcd76c80cb.jpg" alt="001.jpg" /></p>
<h2>実証の対象分野</h2>
<p>この都市は、以下の領域における新しいサービスや技術の検証拠点として機能する。</p>
<ul>
<li>モビリティ：自動運転車や次世代交通システム</li>
<li>ロボティクス：生活支援や介護を含む分野</li>
<li>スマートホーム：家庭内エネルギー管理やAI連携</li>
<li>サステナビリティ：再生可能エネルギー利用や環境負荷低減</li>
</ul>
<h2>街づくりの特徴</h2>
<p>Woven Cityは、車道・人道・モビリティ専用レーンを分離した都市設計を採用している。さらに、エネルギーは100％水素や再生可能エネルギーでまかない、街全体をIoTセンサーやAIで管理することで持続可能な社会のモデルを目指す。</p>
<h2>今後の展開</h2>
<p>トヨタは、Woven Cityを「幸せの量産（Mass-Production of Happiness）」を体現するプロジェクトと位置付けている。実際の生活を通じて技術を検証し、社会実装につなげることを目的に、世界の研究者や企業とのオープンイノベーションを推進する。</p>
<p>Woven Cityはフェーズごとに住民数や参加企業を増やしながら拡張される計画だ。トヨタはこの取り組みを、自動車メーカーからモビリティカンパニーへと変革する象徴的なプロジェクトと位置付けており、将来的には他地域への応用も視野に入れている。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、生成AIで教科書を再構築する「Learn Your Way」を公開──無作為化比較試験で学習成果の向上を確認</title>
      <link>https://ledge.ai/articles/google_learn_your_way_ai_textbook</link>
      <description><![CDATA[<p>Googleは2025年9月16日、生成AIを活用して教科書を再構築する新システム「Learn Your Way」を<a href="https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/">発表</a>した。学習者の学年や関心に合わせて教材をリライトし、音声・スライド・マインドマップなど多様な形式で提示する仕組みを採用。シカゴ地域の高校生を対象とした実証実験では、従来型の教材よりも学習成果が有意に向上することが確認されたという。</p>
<p>従来の教科書は「すべての学習者に一律の内容を提供する媒体」であり、学年や興味関心に応じた最適化は難しかった。Google Researchのチームは、生成AIを用いることでこの制約を克服し、個別化と多様な表現を可能にするアプローチを開発した。</p>
<h2>Learn Your Wayの仕組み</h2>
<p>新システム「Learn Your Way」は、Googleの学習用大規模モデル「LearnLM」（Gemini 2.5 Proに統合）を基盤とする。教材の元テキストを入力し、以下のステップで再構築する。</p>
<ul>
<li><strong>パーソナライズ</strong> ：学年レベル（Flesch-Kincaid指標に基づく）や興味関心（スポーツ、音楽など）に合わせて文章をリライト。</li>
<li><strong>複数表現への変換</strong> ：没入型テキスト、スライド＋ナレーション、オーディオレッスン、マインドマップなど。</li>
<li><strong>学習支援機能</strong> ：埋め込み質問や小テストを生成し、学習者に即時のフィードバックを提供。</li>
</ul>
<p>これにより、学習者は自分に合った形式を選びながら、能動的に学習を進めることができるという。</p>
<p><strong>ニュートンの第三法則を学年や関心に応じてリライトした例。左は高校生向けにバスケットボールを題材に、右は小学生向けに美術を題材に説明している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_79d6efaf7b/x2_79d6efaf7b.jpg" alt="x2.jpg" /></p>
<h2>実証実験（無作為化比較試験）</h2>
<p>研究チームは、シカゴ地域の15〜18歳の学生60名を対象に無作為化比較試験（RCT）を実施した。教材は「思春期の脳発達」（LibreTexts）を使用。
<strong>■ 比較対象</strong> ：
・「Learn Your Way」利用群（30名）
・従来のPDFリーダー（Adobe Acrobat）利用群（30名）
<strong>■ 学習時間</strong> ：20〜40分
<strong>■ 評価方法</strong> ：
・即時テスト（15分）
・3日後の保持テスト（約10分）</p>
<h2>結果</h2>
<ul>
<li>即時テスト：Learn Your Way群が有意に高得点（p=0.03）。</li>
<li>保持テスト：Learn Your Way群が有意に高得点（p=0.03）。</li>
<li>アンケート：Learn Your Way群は「楽しく学べた」「理解が深まった」と回答する割合が高く、将来の利用意欲も強かった。</li>
</ul>
<p><strong>無作為化比較試験の結果</strong> ：「Learn Your Way」を使用した学生は、従来のデジタルリーダー利用者に比べ、即時テスト・保持テストのいずれも有意に高い得点を示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Learn_Your_Way_5_width_1250_458379e0a2/Learn_Your_Way_5_width_1250_458379e0a2.png" alt="Learn-Your-Way-5.width-1250.png" /></p>
<h2>教育現場での意義</h2>
<p>この研究は、生成AIが教科書を「一律の媒体」から「学習者に応じて変化する教材」へと変革し得ることを示している。Googleは、教育科学の知見とAI技術を組み合わせることで、学習成果の向上と学習者の主体性強化につなげられると強調している。</p>
<p><strong>教育専門家による評価結果。特にナレーション付きスライドやオーディオレッスンは、学習者の関心を引きやすいと高評価を得た。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Learn_Your_Way_4_width_1250_8bf77aa53c/Learn_Your_Way_4_width_1250_8bf77aa53c.png" alt="Learn-Your-Way-4.width-1250.png" /></p>
<h2>今後の展望</h2>
<p>研究チームは論文内で次の課題を指摘している。</p>
<ul>
<li>効果検証は1つの教材章に限られており、今後は複数教科・複数章での検証が必要。</li>
<li>各機能（例：スライド、音声、クイズ）の寄与度は明確化されていない。</li>
</ul>
<p>将来的には、学習者の解答状況に応じて教材を動的に調整する「適応学習」への拡張が期待される。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>シャープ、RoBoHoN向けにChatGPT活用アプリ「ロボデイズ」を提供開始──ユーザーとカメラ映像や日記を参照しながら自然な対話</title>
      <link>https://ledge.ai/articles/sharp_robohon_chatgpt_robodays</link>
      <description><![CDATA[<p>シャープは2025年9月19日、コミュニケーションロボット「RoBoHoN（ロボホン）」向けに、生成AI「ChatGPT」を活用した新アプリケーション「ロボデイズ」の提供を10月1日より開始することを<a href="https://corporate.jp.sharp/news/250919-a.html">発表</a>した。カメラを用いた会話や日記の作成、記憶の蓄積といった機能を備え、ユーザーとの対話をより自然で豊かなものにすることを狙う。</p>
<h2>「ロボデイズ」の概要</h2>
<p>「ロボデイズ」はRoBoHoN専用の新アプリで、生成AIを活用して日常の出来事や目の前の風景を会話のきっかけにできる点が特徴だ。RoBoHoNのカメラで映した対象を認識し、その場の状況に即した会話を楽しめるほか、日々の出来事を日記風にまとめる機能も搭載する。さらに、やり取りの内容を記憶として蓄積し、継続的なコミュニケーションにつなげられる。</p>
<h2>主な機能</h2>
<ul>
<li>カメラ会話機能：RoBoHoNがカメラで捉えた人物や物体に関連した話題を提供。</li>
<li>日記機能：一日の出来事を整理してRoBoHoNが記録・読み上げ。</li>
<li>記憶の蓄積：ユーザーとの会話や日記を参照しながら自然な対話を継続。</li>
</ul>
<h2>提供開始日と利用条件</h2>
<p>「ロボデイズ」は2025年10月1日から提供される。利用にはRoBoHoNのソフトウェアをバージョン「05.01.00」以降にアップデートする必要がある。一部の追加機能は「ロボデイズ plus」プランにて提供予定で、RoBoHoNの基本プランに加入することで利用可能となる。</p>
<p>同社はRoBoHoNを単なるコミュニケーションロボットにとどめず、身近なパートナーとして進化させることを目指す。生成AIを組み合わせることで、利用者が日常生活でより自然で継続的な会話体験を得られるようになるとしている。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIで“当たり前”を問い直す―大手SIer2社のエンジニアたちが組織の垣根を超えて挑んだ2日間の合同ハッカソン</title>
      <link>https://ledge.ai/articles/nes_hisol_hackathon_2025_report</link>
      <description><![CDATA[<p>生成AIの技術が急速に進化し、業務や生活のあらゆる場面に応用が広がるなか、自らの発想を形にする実践の場として、「NECソリューションイノベータ株式会社×株式会社日立ソリューションズ合同ハッカソン」が2025年8月4日・5日の2日間にわたり開催された。</p>
<p>本イベントは、NECソリューションイノベータ株式会社と株式会社日立ソリューションズの大手SIer2社が他流試合の形式で合同開催した点に特徴がある。両社からは入社5年前後のSE職・主任層を中心に参加者が集い、所属の枠を超えて発想力と技術力を競い合った。</p>
<p>本イベントは、Ledge.aiが主催する「Ledge.ai CHALLENGE」のフォーマットをベースに構成している。「発想」と「実装」の二部構成を軸に、今回はこれに加え、参加者全員が共通の理解を持ったうえで開発に挑める体制を整えるという観点で、事前プログラムとしてAI基礎講座を行い、最新のAIトレンドや生成AIの基礎知識をインプットする時間を設けた。その後のアイデア発想ワークショップでは、今回のテーマである「日常のルーティンを、先端AIと問い直す」に沿って、各チームが自由に企画を立案。それぞれが企画した内容をプロトタイプとして実装するフェーズへと進んだ。</p>
<p>本記事では、その挑戦の成果として披露されたハッカソンイベント当日の様子を振り返る。</p>
<h2>発想を形に変える、真剣勝負の2日間</h2>
<p>1日目の冒頭では、株式会社レッジ 執行役員の箕部 和也より「1か月前に行われたアイデア発想フェーズに続く“後半戦”が今日から始まる」とイベントの位置づけを説明。さらに本企画の発起人である日本電気株式会社 L&amp;D統括部 松本 好則 氏より、開催に至る想いや狙いを語った。「ハッカソンには、発想・チームワーク・時間管理・フィードバック・ピッチといったSEに必要な要素がすべて詰まっている。自由に作る経験を通じて、技術にこだわり抜いたアウトプットをしてほしい」と呼びかけ、参加者の士気を高めた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DSC_2415_bd991dcfb9/DSC_2415_bd991dcfb9.jpg" alt="DSC_2415.JPG" /></p>
<p>開始の合図とともに実装フェーズがスタートした。はじめは普段とは違う会場の雰囲気や開発環境へのアクセスに苦戦しながらも、徐々に作業が活発になり、ホワイトボードにアイデアの実現方法を書き込んだり、メンターに相談するシーンも見受けられ、ハッカソンイベントらしい様相を呈していった。1日目終了時点では、予定通りに進んだチームもあれば、完成まで不安が残るチームがあったりと、短時間で実装する難しさを感じたチームもあったようだ。
2日目は、朝9時から15時までの限られた時間の中で各チーム実装を続けた。1日目遅れを感じていたチームも、巻き返しを図り、発表までに全てのチームが自分たちのアイデアを形にしたデモアプリを完成させていた。</p>
<h2>6チームが挑んだ“日常の再構築”</h2>
<p>今回のハッカソンでは、NECソリューションイノベータと日立ソリューションズから計6チームが「日常のルーティンをAIで問い直す」というテーマのもと、アイデアの実装に取り組んだ。食や家庭、学習、業務支援といった誰もが日常で直面するであろうシーンを題材に、それぞれの視点からユニークなソリューションが実装された。以下では、各チームが発表したソリューションを紹介する。</p>
<h3>味覚でつながる新しい飲食店発見体験ーNECソリューションイノベータ Aチーム</h3>
<p>NECソリューションイノベータ Aチームは「高評価点なのに満足できない」という課題に着目し、味覚でお店を探す、味覚で人とつながるをコンセプトにした飲食店を探せるアプリを提案した。発表の中では、会場周辺にある実際のお店のデータを使い、飲食店がレコメンドされたり、自分の口コミデータから近い味覚を持つユーザーを探すマッチング機能のデモが行われ、人と人を味覚でつなぐ新しい交流の可能性を提示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image6_1325cc0dcd/image6_1325cc0dcd.jpg" alt="image6.jpg" /></p>
<h3>気分に寄り添う食体験提案アプリー日立ソリューションズ Aチーム</h3>
<p>日立ソリューションズ Aチームは、ユーザーの「今の気分」から食を提案するアプリを発表した。チャットや音声入力で気分を受け取り、自炊か外食かを判定したうえで、レシピや飲食店を提示するのが基本的な仕組みである。発表では「がっつり食べたい気分」という入力から、対話を通じて会場周辺の飲食店を紹介するデモが行われた。また、差別化のポイントとして、Google Maps APIとの連携し、より精緻な外食提案を実現する構想も示されたが、今回は時間の制約から実装には至らなかったところが反省点として挙げられた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image3_808fb086f4/image3_808fb086f4.jpg" alt="image3.jpg" /></p>
<h3>夫婦のすれ違いを埋めるAI目安箱ーNECソリューションイノベータ Bチーム</h3>
<p>NECソリューションイノベータ Bチームは、家庭向けアプリを発表した。夫婦間の小さなすれ違いを記録・可視化し、AIが仲介役として関係改善を流すというユニークなコンセプトのアプリである。夫婦それぞれが日常の出来事や感情を記録すると、AIが要約やスコアリングを行い、良かった点・不満点を整理して提示する。デモでは、妻が日々の不満を入力し、夫がAIを通じて和らげられた表現のフィードバックを受け取る様子などが紹介された。さらに、共感・感謝・協力などの指標を数値化した「5因子分析」や、行動を変えた場合に関係値がどう変わるかを予測する「行動シミュレーション」といった機能も披露された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image1_409ca2c19b/image1_409ca2c19b.jpg" alt="image1.jpg" /></p>
<h3>一人暮らしの食を楽しく支えるパーソナルアシスタントー日立ソリューションズ Bチーム</h3>
<p>日立ソリューションズ Bチームは、一人暮らしの食生活を支えるアプリを発表した。自炊を続ける上での「毎日の献立を考えるのが億劫」「計画通りに作れない」といった悩みに着目し、自分の好みや何人分作るのか？などの情報から献立や買い物リストを提案してくれるアプリである。デモでは、献立・買い物リスト作成が行われた。また一緒に料理をしたいコンシェルジュを選ぶ機能があり、キャラクターと会話しながら、孤独を楽しくする工夫も盛り込まれていた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMG_1380_dcd023d926/IMG_1380_dcd023d926.jpg" alt="IMG_1380.JPG" /></p>
<h3>資格取得の最初の一歩を支える学習支援ツールーNECソリューションイノベータ Cチーム</h3>
<p>NECソリューションイノベータ Cチームが開発したアプリは、資格取得に取り組む人の学習計画をAIがサポートするツールである。受験日や学習可能時間を入力すると、AIが最適な学習スケジュールを自動生成し、進捗管理や参考情報の提示まで行う仕組みを備えている。デモでは応用情報技術者試験を例に、入力内容から全体計画や週ごとのタスクが自動生成される様子や、RAGチャットを使った質問機能などが紹介された。将来的には過去問を取り込み、レベルに応じたレクチャーや、学習の進捗に応じた励ましメッセージを生成する構想も語られた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image7_8f3fd78bb9/image7_8f3fd78bb9.jpg" alt="image7.jpg" /></p>
<h3>朝の迷いをAIで片付けるタスク管理アシスタントー日立ソリューションズ Cチーム</h3>
<p>日立ソリューションズ Cチームは、朝の業務開始前に行うタスク整理を効率化するアプリを発表した。メールやチャットを読み込み、AIが重要度と緊急度の二軸で評価し、優先度付きのタスクリストとして自動的に整理する仕組みである。デモでは、社員証の棚卸依頼や新卒面接日程の確認など、複数の依頼を含むダミーメッセージをLLM（Large Language Models、大規模言語モデル）が解析し、関係者や期限・緊急度の理由を添えてToDoリストに反映する様子が紹介された。さらにダミーデータによるタスク判定精度検証も実施しており、適合率83%、再現率100%を達成し、実運用にも適用できる可能性も示した説得力のある発表だった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DSC_2440_a2a418109c/DSC_2440_a2a418109c.jpg" alt="DSC_2440.JPG" /></p>
<h2>審査と講評が示した未来への期待</h2>
<p>2日間のハッカソンの成果の発表が終わると、会場には達成感や緊張から解放された安堵が入り混じった空気が感じられた。審査はLedge.ai編集長の落合 研次と、株式会社レッジ 代表取締役社長の小瀧 健太が担当した。</p>
<p>最優秀賞には、日立ソリューションズCチームが選ばれた。毎朝のメール・チャット確認という多くのビジネスパーソンが直面する負担に目を向け、AIを活用してタスク抽出と優先度付けを自動化した点が高く評価され、「忙しい人ほど効果を実感できる」「自社で今すぐ使わせたい」といった声が寄せられた。</p>
<p>優秀賞には、日立ソリューションズBチームと、NECソリューションイノベータBチームが選ばれた。日立ソリューションズBチームは、継続利用するほどユーザーの嗜好に寄り添う点が評価された。NECソリューションイノベータBチームは、夫婦間の感情のすれ違いをAIが傾聴の姿勢で話を聞いてくれるというアイデアの独自性が評価された。</p>
<p>表彰の後に行われた講評では、各社から熱のこもったコメントが寄せられた。
まず最初は株式会社日立ソリューションズ ITプラットフォーム事業部 荒川 啓之 氏が登壇し、「短期間にも関わらず、どのチームも動くプロトタイプを仕上げてきたことに感銘を受けた」と評価したうえで、「課題から発想したアイデアを素早く実装に落として、ユーザーからのフィードバックをもらう進め方は、今後の開発業務に活かせる貴重な経験」と総括した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image9_1503e82ac9/image9_1503e82ac9.jpg" alt="image9.jpg" /></p>
<p>また、同社 業務革新統括本部 AIトランスフォーメーション推進本部 中村 賢 氏からは「限られた時間の中で成果物を形にし、伝わるプレゼンまで仕上げた点は、エンジニアとしての基礎力の高さと発想の豊かさを示していた」とのコメントが寄せられた。特に「企業の枠を越えて技術者が交流することに大きな意義がある」と強調し、今後はよりオープンな形式での展開に期待を示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image6_92b3db901c/image6_92b3db901c.png" alt="image6.png" /></p>
<p>NECソリューションイノベータ株式会社 AI・データアナリティクス統括部 宮本 隆弘 氏が講評。「5分という短い持ち時間の中でしっかりとメッセージングできたチームが成果を収めたと感じた」と語り、「特に若手層の着眼点のユニークさと、着想を形にするエネルギーに感心した」と評価した。最後に「イメージしていた以上の会になった。今後も継続してご一緒したい」と感想を述べ、イベントの継続開催に強い期待を寄せた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image3_613656e257/image3_613656e257.png" alt="image3.png" /></p>
<p>続いて日本電気株式会社 L&amp;D統括部 江本 慎治 氏からも講評をいただいた。「二日間という短期間で企画から構築まで形にできたことは、従来の開発スタイルとの違いを強く感じさせるものだった」と述べ、人材開発プログラムも新しい開発スタイルに適応していく必要があることを実感したという。また「社外の参加者との交流を通じ、自社だけでは得られない学びや刺激を得られたのは大きな価値」と強調し、今後はこうした機会を積極的に活かしてキャリア形成につなげてほしいと語った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image12_1e966afb9c/image12_1e966afb9c.png" alt="image12.png" /></p>
<h2>まとめ</h2>
<p>表彰式後の交流会では、受賞チームの喜びや、惜しくも賞を逃したメンバーの悔しさが入り交じる様子が印象的であった。文化の異なる会社同士の垣根を越えたコミュニケーションも活発に行われ、参加者にとって大きな刺激となり、新たな学びとつながりを生み出す機会となった。
「NECソリューションイノベータ株式会社×株式会社日立ソリューションズ合同ハッカソン」は、生成AIを活用した発想力と実装力を磨く場であると同時に、他社と切磋琢磨する”他流試合”の舞台でもあった。次回開催を期待する声もあがり、２日間にわたる挑戦は、大きな成果とともにイベントは幕を閉じた。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIに仕事を奪われるか問題、今のところ失業増は確認されず──シカゴ大学研究、LLM導入は短期的に賃金上昇に作用</title>
      <link>https://ledge.ai/articles/ai_university_of_chicago_llm_short_term_employment_wages</link>
      <description><![CDATA[<p>シカゴ大学の研究チームは、生成AI（大規模言語モデル：LLM）の導入が労働市場に与える短期的な影響を分析した。その結果、AIの影響を強く受ける職種では賃金が上昇する一方で、失業率には統計的に有意な変化は見られなかった。懸念される「AIによる失業」は、少なくとも現時点では確認されていないという。研究チームはこの調査結果を2025年9月19日に<a href="https://arxiv.org/abs/2509.15510">発表</a>した。</p>
<h2>“AIが仕事を奪う”は本当か</h2>
<p>ChatGPTが2022年11月に公開されて以降、生成AIは文章作成やプログラミングをはじめ、幅広い業務に急速に導入されている。一方で、「AIが仕事を奪うのではないか」という不安は根強く存在してきた。こうした懸念を検証するため、シカゴ大学の研究チームは、米国の労働市場データを用いた大規模な分析を行った。</p>
<h2>調査の方法：CPS×O*NET×SDiDで職業別の「曝露度」を推定</h2>
<ul>
<li>データ：米国のCurrent Population Survey（CPS）の失業率と賃金（2010年1月〜2025年8月）</li>
<li>曝露度の定義：O*NETの職業タスクと、Anthropic「Claude」での数百万件のプロンプトを対応づけ、どの職種がLLMの影響を受けやすいかを数値化</li>
<li>手法：Synthetic Difference-in-Differences（SDiD）という統計手法を用い、ChatGPT公開を「技術ショック」として高曝露職種と低曝露職種を比較</li>
</ul>
<h2>主な結果：代替ではなく“補完”が先に来る</h2>
<ul>
<li>賃金：曝露度の高い職種では、平均して週あたり約89ドル（2010年基準ドル換算）の収入増加が確認された。</li>
<li>失業率：変化はごく小さく、全体では0.2ポイント程度の増減にとどまり、統計的に有意な影響は見られなかった。</li>
<li>解釈：短期的には、AIは労働を「代替」するのではなく「補完」する形で生産性を高め、その結果として賃金が上昇したと考えられる。</li>
</ul>
<h2>“言語とコード”を扱う職種が高曝露</h2>
<p>分析によると、特に生成AIの影響を強く受けやすい職業は以下の通り。</p>
<ul>
<li>ライター・著者</li>
<li>コンピュータプログラマー</li>
<li>ウェブ開発者</li>
<li>ソフトウェア開発者</li>
<li>情報セキュリティアナリスト</li>
</ul>
<p>これらの職種はいずれも、文章やコードを中心とした作業に依存しているという。</p>
<h2>長期影響はこれから</h2>
<p>研究チームは「短期的な労働市場の調整は、雇用ではなく賃金を通じて起きている」と結論づけた。失業増加は確認されなかったが、AI導入が長期的にどのような影響を及ぼすかは不透明であり、今後の継続的な観察が必要だとしている。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>資生堂、「エリクシール AIスキンアナライザー」にAIチャット機能を追加──肌測定結果に基づきパーソナルアドバイスを提供開始</title>
      <link>https://ledge.ai/articles/shiseido_elixir_ai_skinanalyzer_chat_update</link>
      <description><![CDATA[<p>資生堂は2025年9月22日、主力スキンケアブランド「エリクシール」のオンライン肌測定サービス「エリクシール AIスキンアナライザー」に、AIチャット機能を新たに追加したと<a href="https://corp.shiseido.com/jp/news/detail.html?n=00000000004067">発表</a>した。測定結果に基づき、スキンケアや生活習慣、製品選びに関するパーソナルアドバイスを提供する。</p>
<h2>年間56万人が利用するオンライン肌測定に新機能</h2>
<p>「エリクシール AIスキンアナライザー」は、スマートフォンで撮影した顔写真をもとに、しわ・毛穴・ツヤなど16項目を計測し、同年代との比較ができるオンライン肌測定サービス。2024年時点で年間56万人が利用している。今回のアップデートで新たにAIチャット機能が加わった。</p>
<h2>肌状態に応じたアドバイスを提供</h2>
<p>新機能では、測定結果に基づいてAIチャットがユーザーに寄り添う形で助言を行う。スキンケアの方法や生活習慣の見直し、個々に適した製品や成分情報などを対話形式で受け取ることができる。資生堂は、オンライン上でもカウンセリングに近い体験を提供することで、ブランド体験の深化を狙う。</p>
<h2>利用手順の可視化</h2>
<p>サービスは、ライフスタイルに関する質問への回答、顔写真の撮影、肌研究データに基づく計測、同年代平均との比較を経て、スキンケアのアドバイスやAIチャットによる相談へと進む。結果は保存可能で、経時的な変化を確認することもできる。</p>
<p><strong>「エリクシール AIスキンアナライザー」の利用手順。質問回答から顔写真撮影、測定、AIチャットによる相談までを一連の流れで体験できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4067_o7z02_432_7c88b34ae8/4067_o7z02_432_7c88b34ae8.jpg" alt="4067_o7z02_432.jpg" /></p>
<h2>今後の展開</h2>
<p>今回の機能追加は、デジタルを活用したブランド戦略の一環。資生堂はエリクシールを通じて、顧客一人ひとりに寄り添ったパーソナライズケアの強化を進める方針だ。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>政府、拡大する ”デジタル赤字” に歯止め――AI活用やゲーム・アニメ輸出を柱に海外展開促進策を策定</title>
      <link>https://ledge.ai/articles/government_digital_industry_global_strategy_20250919</link>
      <description><![CDATA[<p>政府は2025年9月19日、首相官邸で「<a href="https://www.kantei.go.jp/jp/pages/20250919choukan_global.html">デジタル関連産業のグローバル化促進のための関係閣僚会議</a>」を開き、拡大傾向にある「デジタル赤字」を抑制するための施策案を取りまとめた。AIを活用した国産サービスの競争力強化や、ゲーム・アニメといったコンテンツの輸出促進が柱となる。</p>
<h2>会議の概要</h2>
<p>会議には関係閣僚が出席し、デジタル関連産業の海外展開を加速させるための施策案が示された。政府は今後、実行計画を通じて産業競争力を高め、国際市場での存在感を強化する方針だ。</p>
<h2>背景</h2>
<p>近年、デジタル関連収支の赤字（いわゆる“デジタル赤字”）が拡大している。サービス輸入の増加が要因で、日本発のAIやデジタルサービスが海外市場で十分に浸透していないことが課題とされている。</p>
<h2>施策の柱</h2>
<p>会議で示された施策案には以下の内容が含まれる。</p>
<ul>
<li>AI・データ利活用の推進：国際市場で通用する先端サービスを生み出すための支援。</li>
<li>コンテンツ輸出促進：ゲームやアニメなど文化的デジタルコンテンツを重点に据えた海外展開支援。</li>
<li>人材育成・基盤整備：スタートアップ支援やデータセンター整備などの環境づくり。</li>
<li>制度・ルール整備：著作権や国際標準化への対応を強化し、国際的なビジネス展開を後押し。</li>
</ul>
<h2>今後の展開</h2>
<p>政府は、こうした施策を通じてデジタル関連収支の赤字を抑制するとともに、日本発のサービスやコンテンツが海外収益を確保できる体制の構築を目指す。今後は予算措置や制度改正などを通じて、施策の具体化を進める予定だ。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、ソフトバンク・Oracleと協力し米国に5拠点の新データセンター建設へ――スターゲート計画は目標の10GW中の約70%の計算能力に</title>
      <link>https://ledge.ai/articles/openai_softbank_oracle_stargate_new_datacenters</link>
      <description><![CDATA[<p>OpenAIは2025年9月23日（現地時間）、米国内で新たに5つのデータセンターを建設すると<a href="https://openai.com/index/five-new-stargate-sites/">発表</a>した。これは、同社が米Oracleおよびソフトバンク・グループと協力して進める「Stargate」プロジェクトの拡大の一環で、AIインフラの大規模強化を目的としている。</p>
<h2>5カ所の新拠点を発表</h2>
<p>発表では以下の5サイトが明らかにされた。</p>
<ul>
<li>テキサス州シャケルフォード郡（Shackelford County, Texas）</li>
<li>ニューメキシコ州ドナアナ郡（Doña Ana County, New Mexico）</li>
<li>米中西部の未発表サイト（Midwest, location to be announced）</li>
<li>オハイオ州ロードスタウン（Lordstown, Ohio）</li>
<li>テキサス州ミラム郡（Milam County, Texas）</li>
</ul>
<p>OpenAIは、すでに稼働を始めたテキサス州アビリーンの「flagship」サイトに加え、これらの拠点を整備することで、計画全体の規模をさらに拡大するとしている。</p>
<p>また、ソフトバンクグループは、オハイオ州ロードスタウンの拠点に主導的に関与。同地にはかつて自動車工場が存在し、その跡地を活用して新しいAIデータセンターを建設する<a href="https://ledge.ai/articles/softbank_ohio_ev_plant_stargate_ai_infrastructure_bloomberg_report">計画</a>が進められている。資金面での支援に加え、用地取得や地域再開発の調整にも携わるとされ、現地経済の再活性化に直結する重要な拠点となる。</p>
<h2>計画規模と進捗</h2>
<p>Stargateプロジェクトは、総投資額5000億ドル、計10ギガワットの計算能力を目標に掲げる。今回の5拠点追加により、計画容量はすでに約7ギガワットに到達する見込みだ。ロードスタウンの施設は2026年に稼働予定で、Abileneの施設では一部GPUによる運用が開始されている。</p>
<h2>雇用と地域経済への影響</h2>
<p>OpenAIによると、新拠点の建設により2万5,000人以上の雇用が創出される見込みで、地元経済への貢献も期待される。また、Oracleのクラウド基盤やソフトバンクの投資が、この大規模インフラの整備を支える。</p>
<h2>今後の見通し</h2>
<p>OpenAIは「AIを人類全体の利益のために活用する」という理念のもと、安全かつ持続可能な形でインフラを拡張していく方針を示している。電力供給や環境負荷の軽減にも取り組みながら、Stargateの10ギガワット目標に向けた拡大を続けていくとした。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、OpenAIに最大1000億ドルを投資──10GW規模のAIデータセンター展開で戦略提携</title>
      <link>https://ledge.ai/articles/nvidia_invests_100b_in_openai</link>
      <description><![CDATA[<p>NVIDIAとOpenAIは2025年9月22日（現地時間）、次世代AIインフラの構築に向けた戦略的提携を<a href="https://openai.com/index/openai-nvidia-systems-partnership/">発表</a>した。両社はNVIDIA製システムを用いて少なくとも10ギガワット（GW）規模のAIデータセンターを展開する計画で、NVIDIAは段階的に最大1000億ドル（約15兆円）をOpenAIに投資する。</p>
<p>両社は意向表明書（LOI）を締結し、今後の協力体制を明確化した。OpenAIは計算処理およびネットワーク分野における「優先戦略パートナー」としてNVIDIAを位置づけ、ハードウェアとソフトウェアの両面でロードマップを共有し最適化を進めるとしている。</p>
<p>投資の仕組みとしては、NVIDIAがGW単位でのシステム展開に応じて段階的に資金を投入し、最終的に最大1000億ドルに到達する見込み。OpenAIはNVIDIAの半導体製品を現金で購入する一方、NVIDIAは議決権のない株式を取得する形を取る。</p>
<p>導入スケジュールとして、最初の1GWは2026年後半に稼働予定であり、NVIDIAの新しい「Vera Rubin」プラットフォームを採用する。これにより、増大するAIモデルの学習・推論需要に対応できる大規模な計算インフラの整備が進む見込みだ。</p>
<p>今回の提携は、世界的に加速するAI開発競争において、インフラ規模での優位性を確保する狙いがある。両社は「少なくとも10GW」という巨大規模の展開を通じて、次世代AIの開発と実用化を支える基盤づくりを進めていく。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>これからのAIスキルは「プロンプト」ではなく「コンテキスト・エンジニアリング」──Google DeepMind フィリップ・シュミット氏が提起</title>
      <link>https://ledge.ai/articles/context_engineering_deepmind</link>
      <description><![CDATA[<p>2025年6月30日、Google DeepMindのシニアAIリレーションエンジニアであるフィリップ・シュミット（Philipp Schmid）氏が自身のブログを通じて、「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」と<a href="https://www.philschmid.de/context-engineering">提起</a>した。大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトだけでは不十分であり、AIに与える前提情報全体を設計・最適化する技術が不可欠だと論じている。</p>
<h2>背景：プロンプトエンジニアリングの行き詰まり</h2>
<p>近年、生成AIの発展に伴い「プロンプトエンジニアリング」が注目を集めてきた。巧みなプロンプトを用いてモデルの挙動を調整し、より望ましい回答を得るという技法は、AI活用の第一歩として広く普及している。しかしシュミット氏は、現実の業務環境ではプロンプトの工夫だけで対応できない課題が増大しており、AIが真にユーザーの期待に応えるには、より包括的な情報構造の設計が必要だと指摘した。</p>
<h2>コンテキストエンジニアリングとは</h2>
<p>シュミット氏は、コンテキストエンジニアリングを「AIが必要とする情報を、適切な形式で、適切なタイミングに提供する仕組みの設計」と位置付ける。単にプロンプトを最適化するのではなく、モデルに取り込ませる知識、会話履歴、外部ツールとの連携などを含めて制御する総合的な技術領域だと説明する。</p>
<p>具体的には、</p>
<ul>
<li>System Prompt（AIのシステム的前提）</li>
<li>User Prompt（ユーザーからの指示）</li>
<li>State/History（対話履歴や状態管理）</li>
<li>Long-Term Memory（長期記憶としての知識）</li>
<li>Retrieved Information（RAGなどによる検索情報）</li>
<li>Tools/Structured Output（外部ツール連携・構造化出力）
という6つの構成要素を「コンテキスト」として設計し、動的に最適化していく考え方を示している。</li>
</ul>
<h2>8割の失敗は文脈不足</h2>
<p>シュミット氏は、AIエージェント開発における8割の失敗が「文脈情報の欠落」に起因すると述べている。たとえばカレンダー調整を行うAIエージェントの場合でも、ユーザーの希望や優先順位を把握しないまま単純な操作を試みることでエラーが起きやすいと説明している。</p>
<h2>関連技術と支える手法</h2>
<p>同氏は、コンテキストエンジニアリングを支える技術として、</p>
<ul>
<li>検索拡張生成（RAG）</li>
<li>ベクトルデータベース検索</li>
<li>ツール呼び出しのオーケストレーション</li>
<li>会話履歴管理
などの仕組みが必要だと述べている。これらを組み合わせることで、AIが常に適切な前提情報を取得しながら出力を行える環境を整備できるとする。</li>
</ul>
<h2>エンタープライズでの展開</h2>
<p>シュミット氏は、コンテキストエンジニアリングがエンタープライズ分野においても重要であると述べている。社内ドメイン知識や業務ルールをAIが正しく理解できるようにするために、前提情報の整理と統合を体系的に設計する必要があるとしている。</p>
<p>筆者プロフィール
フィリップ・シュミット氏は、Hugging Faceのエンジニアを経てGoogle DeepMindに参画。大規模言語モデルとエージェント技術の実用化に関する知見を広く発信している。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/3 [WED]【日本HP・オートデスクが登壇！】「3D CAD × 生成AI」テクノロジーの進化で設計・製造プロセスはどう変わる？業界横断型カンファレンス「GENEX #1」を9月30日に開催</title>
      <link>https://ledge.ai/articles/genex1-announce</link>
      <description><![CDATA[<p>国内最大級のAI専門メディア「Ledge.ai」を運営する株式会社レッジは、このたび、業界横断型の新カンファレンスシリーズ「GENEX（ジェネックス）」を立ち上げ、その第1回となるイベントを2025年9月30日（火）に開催いたします。</p>
<h2>GENEXとは</h2>
<p>「Generative」＋「Next」＋「Experience／Exchange／Exploration」を意味する造語で、生成AIをはじめとする“生成的テクノロジー”と“次世代の創造性”に焦点をあてたシリーズ型イベントです。テーマごとに異業種の専門家・技術者・ビジネスリーダーが集い、新しい創造技術の活用とその社会的インパクトを議論・共有する場を提供します。</p>
<h2>第1回テーマは『3D CAD × Generative AI』</h2>
<p>初回は「3D CAD × Generative AI」をテーマに、“設計”と“創造”の未来を可視化します。近年の急速な生成AIの進化により、設計や構想のプロセスは自動化・高度化が実現可能な段階に入っています。3D CADも製造・建設分野をはじめ、都市開発やロボティクス、ファッションなど多様な産業での活用が進み、創造の可能性を拡張し続けています。</p>
<p>本イベントでは、業界を超えて先進的な取り組みを進める企業リーダーを迎え、3D CADと生成AI技術が設計や製造の工程にもたらす変革をテーマにお話いただきます。</p>
<h2>補助金活用のノウハウも得られる実践的イベント</h2>
<p>GENEXでは、イベントのテーマに合わせた補助金制度のご紹介や、制度活用に向けたご相談も受け付けております。
3D CAD×生成AIの最新動向を学ぶだけでなく、新しい技術を取り入れる際の導入コストを抑える手段も学ぶことができます。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/GENEX_1_3_D_CAD_1_130d185e26/GENEX_1_3_D_CAD_1_130d185e26.png" alt="GENEX #1 - 3D CAD × 世界モデル：ものづくりの未来はどう変わるのか？- 企画ご案内資料 (1).png" /></p>
<p>:::button
<a href="https://zfrmz.com/pHez81Ctmf7AFISeaz4Y">参加登録はこちら</a>
:::</p>
<h2>講演タイムテーブル</h2>
<p>15:00 - 15:30（30分）　開場・受付開始
15:30 - 15:35（ 5分）　 オープニング
15:40 - 16:20（40分）　パネルディスカッション「生成AIによって変革する設計のプロトタイピング」
16:25 - 17:05（40分）　株式会社日本HP様 講演
17:15 - 17:55（40分）　オートデスク株式会社様 講演
17:05 - 18:40（40分）　補助金活用支援セッション
18:45 - 18:50（ 5分）　クロージング
19:00 - 20:00（60分）　ネットワーキングパーティー</p>
<h2>セッションの紹介</h2>
<h3>パネルディスカッション「生成AIによって変革する設計のプロトタイピング」</h3>
<p>産業・エンタメ・教育 ― あらゆる現場で”ものを創る”最前線に立ち続けてきた二人のキーパーソンが、生成AIによって変わる現実世界の設計を読み解きます。</p>
<p>【ゲストスピーカー】
小畑 正好 氏
デジタルコンテンツクリエイター</p>
<p>武蔵野美術大学院 空間演出デザインコース修了後、渡米しNHKエンタープライズUSAに参加。帰国後は映画・テレビ・アニメ・ゲーム・インタラクティブコンテンツ等でVFX監督・CGディレクターとして数多くのメジャープロジェクトに参画。現在、(社)FDE・(株)ビトル・(株)島精機製作所等数社の役職を併任しデジタルコンテンツの総合的な研究・開発・制作を行う。</p>
<p>橋本 和幸 氏
dots in space 代表取締役／シリコンスタジオ 取締役／サイバーエージェント 技術顧問</p>
<p>1980年代前半からTV・CM業界でCGを活用し活躍。『ファイナルファンタジーVII』のプログラマーとして知られ、映画『ファイナルファンタジー』のホノルルスタジオ設立、Maya開発初期への関与など、日本の3DCG黎明期から中心的役割を果たしてきた。近年はメタバース・コンテンツの開発やR&amp;Dを推進し、複数の企業で次世代技術のアドバイザーを務める。</p>
<p>【モデレーター】
落合 研次
株式会社レッジ 社長室／編集部 編集主幹</p>
<p>工学修士、経営管理修士。新卒入社の大手SIerで６年間、システム開発の下流から最上流まで担当。GREE・アイスタイル（@cosme運営）で、データ分析/事業企画/プラットフォーム戦略を主導。TIS等で、自動車業界やテレビ業界の大規模IoTプロジェクトのPM/責任者としてPJTを推進。</p>
<h3>スポンサー講演</h3>
<p>3D CADのソフトウェアベンダーやハードウェアベンダーによる講演を通じて、3D CADの最新動向を解説します。</p>
<p>本イベントではオートデスクが提唱する「Autodesk AI」を中心とした最新の設計支援ソリューションや、日本HPによる高性能ワークステーションの活用事例も紹介。ソフトウェアとハードウェアの両面から、次世代の設計・開発環境の姿を多角的に探ります。</p>
<p>【スポンサー講演１】
<strong>『デザインと創造をパワフルにサポートする Autodesk AI』</strong>
Autodesk AI は、自動化・解析・拡張性を重視し、製造・建築・建設、メディアエンターテインメントなどの、「デザインと創造」に関わる皆様のワークフローをサポートします。
本セッションでは、最新の Autodesk AI についてご説明と、製造業における AI 活用の現在地と今後の方向性についてご紹介いたします。</p>
<p>\u003C登壇者\u003E
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20150812_Profile_kato_2_1_164487fa94/20150812_Profile_kato_2_1_164487fa94.jpg" alt="20150812Profile_kato 2 (1).jpg" /></p>
<p>オートデスク株式会社
加藤 久喜 氏／日本地域営業統括　技術営業本部 本部長</p>
<p>※講演内容は情報が確定次第、ご案内いたします。</p>
<h3>補助金活用支援セッション</h3>
<p>「補助金を使えば、最新技術をもっとお得に導入できる」
本セッションでは、今回のテーマに関連した補助金を幅広くご紹介します。
国や自治体が提供する多様な制度の紹介に加え、自社に最適な補助金の選び方や活用方法を専門家に直接相談できるサポートもご用意しています。</p>
<h3>個別相談会</h3>
<p>登壇企業や専門家と直接話せる個別相談の場を設置。技術導入や制度活用について、参加者の具体的な課題に即したご相談が可能です。</p>
<h2>開催概要</h2>
<p>イベント名：Generative AI Conference Series「GENEX」#1
テーマ：3D CAD × Generative AI
日時：2025年9月30日（火）15:30〜20:00（15:00開場）
形式：オフライン ＋ アーカイブ配信あり
会場：品川インターシティホール＆貸会議室1+2
主催：株式会社レッジ
共催：トランステップ株式会社
協賛：株式会社日本HP、オートデスク株式会社
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/pHez81Ctmf7AFISeaz4Y">参加登録はこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 03 Sep 2025 08:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Claudeの品質低下、Anthropicが技術的原因を公表 — 誤ルーティング・出力破損など3件のバグ</title>
      <link>https://ledge.ai/articles/claude_quality_drop_three_bugs</link>
      <description><![CDATA[<p>Anthropicは2025年9月17日、8月上旬から9月上旬にかけて報告されたAI「Claude」の応答品質が低下した問題について調査を行い、原因は3件のインフラストラクチャ上のバグだったと<a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">発表</a>した。公式のエンジニアリングブログとステータスページで詳細が<a href="https://status.anthropic.com/">公開</a>されている。</p>
<h2>問題の発生と調査開始</h2>
<p>8月上旬ごろから、Claudeの応答が以前より劣化しているとの報告がユーザーから相次いだ。コード生成に誤りが含まれる、応答中に不自然な文字が混ざるといった現象が確認され、Anthropicは公式ステータスページで状況を認識し調査を進めていると発表した。</p>
<h2>判明した3つのバグ</h2>
<p>Anthropicのエンジニアリングブログによると、応答品質低下の背景には次の3つの独立したバグが存在していた。</p>
<h3>1. コンテキストウィンドウの誤ルーティング（Context Window Routing Error）</h3>
<ul>
<li>本来1Mトークン対応のサーバーに処理が割り振られるべきリクエストが、誤って小さいコンテキストウィンドウを持つサーバーに送られていた。</li>
<li>負荷分散の仕組みにより、影響を受けたユーザーは継続的に同じサーバーへ接続され、長期にわたって問題が続いた。</li>
<li>影響は当初全体の約0.8%だったが、8月下旬には最大16%に拡大。9月4日までに修正が完了した。</li>
</ul>
<h3>2. 出力破損（Output Corruption）</h3>
<ul>
<li>8月25日にTPUサーバーへ適用された誤った設定変更が原因で、一部の応答に異常が発生。</li>
<li>英語のプロンプトに中国語やタイ語の文字が混ざる、コード生成で文法エラーが出るなどの症状が報告された。</li>
<li>Opus 4/4.1では8月25～28日、Sonnet 4では8月25～9月2日に影響が確認され、9月2日に設定をロールバックして修正した。</li>
</ul>
<h3>3. XLA:TPUの誤コンパイル（XLA:TPU Miscompilation）</h3>
<ul>
<li>出力トークン選択を改善するための最適化コードがXLAコンパイラの潜在的なバグを誘発。その結果、本来高確率で選ばれるべき単語や記号が応答に現れない不具合が発生。</li>
<li>特にClaude Haiku 3.5で顕著に見られ、Opus 3やSonnet 4の一部にも影響の可能性があった。最適化のロールバックによって9月初頭には解消された。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/d707dfc2effceba608d04007bc776132a3e57838_3840x1800_59fc4bc120/d707dfc2effceba608d04007bc776132a3e57838_3840x1800_59fc4bc120.jpg" alt="d707dfc2effceba608d04007bc776132a3e57838-3840x1800.jpg" /></p>
<h2>修正と再発防止策</h2>
<p>Anthropicは、各バグはすでに修正済みであると説明。再発防止策として、より敏感な出力監視の導入、複数のハードウェアプラットフォームを横断したテスト体制の強化、プライバシーを確保しながらユーザー報告を活用できる仕組みづくりを進めるとしている。</p>
<h2>今後の方針</h2>
<p>Anthropicは「モデルの品質はアルゴリズムだけでなく、基盤となるインフラ全体に依存する」と強調。今後はユーザーからの報告と自動評価の双方を活用し、異常の早期発見と透明性ある運営を通じて信頼性の確保を目指すとしている。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>曖昧さ払拭、GoogleがGeminiの制限を公式明記—無料は1日5プロンプト、Ultraは500</title>
      <link>https://ledge.ai/articles/google_gemini_usage_limits_officially_detailed</link>
      <description><![CDATA[<p>Googleは公式ヘルプセンターを更新し、生成AI「Gemini Apps」における利用制限を初めて具体的な数値として<a href="https://support.google.com/gemini/answer/16275805">明記</a>した。従来は「limited access」など曖昧な表現が使われていたが、今回の更新により無料・有料プランごとの上限が詳細に示された。</p>
<h2>プランごとの利用上限</h2>
<p>無料プランは「1日5プロンプト」までに制限される一方で、最上位のUltraプランでは「500プロンプト」まで利用可能となる。画像生成や動画生成、Deep Researchなどもプランごとに異なる上限が設けられている。</p>
<p><strong>Google公式ヘルプセンター「Gemini アプリのアップグレード」より</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_help_e87fab6301/gemini_help_e87fab6301.jpg" alt="gemini help.jpg" /></p>
<p>Googleは2025年5月に「AI Ultra」プランを発表していたが、具体的な使用制限は明示されていなかった。今回の改訂により、同社のAIサービスに関する透明性が一段と高まったかたちだ。今後も新機能追加や制限の調整が行われる可能性があり、ユーザーには公式ヘルプセンターで最新情報を確認することが推奨される。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ヒューマノイドロボット、スケートボードで人並みの技を披露 ― 京大・ATRが「サイボーグAI」で実時間運動性能を実現</title>
      <link>https://ledge.ai/articles/humanoid_robot_skateboard_cyborg_ai</link>
      <description><![CDATA[<p>2025年9月11日、NEDO（国立研究開発法人新エネルギー・産業技術総合開発機構）、国際電気通信基礎技術研究所（ATR）、京都大学は、ヒューマノイドロボットに「サイボーグAI」を搭載し、人間の動きを模倣（みまね）学習させることで、スケートボードの複雑な技を人並みのリアルタイムで実行することに成功したと<a href="https://www.nedo.go.jp/news/press/AA5_101886.html">発表</a>した。</p>
<p>同技術では、人間のスケーターから脳波や身体の座標データを取得し、サイバー空間で再現。その上で、身長や体重などの差異を補正した動きをロボットに実装した。従来の模倣学習が上下方向の動きにとどまっていたのに対し、前後・左右の移動や体軸の傾き回復など全身制御を含む運動が可能となった。</p>
<p>実証実験の舞台となったのは、ATR内に整備された「ロボットスケートパーク」。曲率の変化があるコースでのスラローム走行や障害物回避など、これまで困難だった高度な運動を、ロボットが転倒せずにこなす様子が確認された。</p>
<p>この成果は、介護やリハビリ支援、物流分野での運搬など、現実社会での応用につながると期待されている。研究グループは「人並みの実時間運動性能を備えたロボットが、人間の生活を支援する未来に向けた重要な一歩」としている。</p>
<p>発表にあわせて、9月11日にはATRの実験棟で見学会も行われ、関係者に成果が<a href="https://bicr.atr.jp/bri/">公開</a>された。</p>
<p>今回の研究は、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）の支援事業の一環として実施された。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ロボットと暮らす住宅を初公開──リビングロボットと藤田医科大、生活支援ロボットを導入した“人協調型ロボティクス住宅”を発表</title>
      <link>https://ledge.ai/articles/living_robot_fujita_robotech_house</link>
      <description><![CDATA[<p>リビングロボットは2025年9月18日、藤田医科大学リハビリテーション部門と共同開発した生活支援ロボットやシステムを導入した「人協調型ロボティクス住宅」を<a href="https://prtimes.jp/main/html/rd/p/000000057.000094064.html">発表</a>した。名古屋市熱田区のサンヨーホームズ株式会社の住宅展示場に設置され、9月20日から特定日に一般公開が行われる。</p>
<h2>社会課題への対応として開発</h2>
<p>同社は、少子高齢化や介護人材不足といった社会課題を背景に、人とロボットが協調する住まいの新たな形を提示。今回の取り組みは、内閣府の戦略的イノベーション創造プログラム（SIP）「人協調型ロボティクスの拡大に向けた基盤技術・ルールの整備」に採択された研究の一環でもある。</p>
<p>展示住宅は、名古屋市熱田区の「神宮東 中日ハウジングセンター」内にあるサンヨーホームズの住宅展示場に設置された。一般公開は2025年9月20日（土）、21日（日）、27日（土）、28日（日）の4日間が予定されている。</p>
<h2>生活を支えるロボットとシステム</h2>
<p>住宅には、以下の生活支援ロボットやシステムが導入されている。</p>
<ul>
<li><strong>見守りロボット「WeeGo（ウィーゴ）」</strong> ：小型で会話機能を持ち、居住者に気づきを促す。</li>
<li><strong>メカトロメイトQ</strong> ：移動や通話機能を備えたロボット。</li>
<li><strong>移動・移乗支援ロボット</strong> ：車いす型で、住宅内の移動や乗り移りをサポート。</li>
<li><strong>センサー群</strong> ：生活・活動データ（運動、睡眠など）や住環境データ（温湿度、CO₂濃度、照度、窓開閉など）を収集。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_9f5bef2d74/sub1_9f5bef2d74.jpg" alt="sub1.jpg" /></p>
<p>これらの仕組みにより、熱中症予防や転倒時の通報、侵入者検知など、安全で快適な暮らしを支援する機能が提供される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub2_06affc0937/sub2_06affc0937.jpg" alt="sub2.jpg" /></p>
<h2>今後の展望</h2>
<p>リビングロボットは今回の公開を通じて、一般生活者が新しい住環境を体験する場を提供するとともに、社会実装に向けた実証を重ねていく方針だ。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMへの指示が得意な人は脳の働きが違う──「プロンプト力」がfMRI研究で初めて科学的に確認される</title>
      <link>https://ledge.ai/articles/llm_prompting_brain_fmri_study</link>
      <description><![CDATA[<p>大規模言語モデル（LLM）への指示が得意な人とそうでない人の間で、脳活動に違いがあることが初めて科学的に確認された。サウジアラビア・キングサウード大学の研究チームは2025年8月20日、fMRI（機能的磁気共鳴画像法）を用いたパイロット研究の成果をarXivに<a href="https://arxiv.org/abs/2508.14869">公開</a>した。</p>
<h2>fMRIで「プロンプト力」の神経基盤を観測</h2>
<p>研究では、22人の参加者を対象に「プロンプト力」を評価するための独自尺度「Prompt Engineering Literacy Scale（PELS）」を開発し、スコアに基づき「熟達者」と「中級者」に分類。その上で、安静時fMRIを用いて脳の機能的結合やネットワーク活動を比較した。</p>
<h2>主な発見</h2>
<p>解析の結果、熟達者の脳には以下の特徴が確認された。</p>
<ul>
<li><strong>低周波帯域の優位性</strong> ：視覚ネットワーク（VVN）、デフォルトモードネットワーク後部（pDMN）、左外側頭頂ネットワーク（LLPN）などで、低周波成分が高周波成分に比べ優位であり、安定的で効率的な神経活動が示唆された。</li>
<li><strong>脳領域間の機能結合の強化</strong> ：熟達者では、左中側頭回（言語処理や意味記憶に関与）および左前頭極（計画・抽象的推論・メタ認知に関与）の機能結合が有意に強化されていた。</li>
<li><strong>効率的な神経活動</strong> ：脳内の自発的活動を示す指標（fALFF）が全般的に低下しており、不要な揺らぎが少なく効率的な情報処理が行われている可能性が示された。</li>
</ul>
<p><strong>■ LLMプロンプト熟達者で強化された左中側頭回の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f.jpg" alt="Increased connectivity in the left middle temporal gyrus.jpg" /></p>
<p><strong>■ LLMプロンプト熟達者で強化された左前頭極の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_frontal_pole_966041e40f/Increased_connectivity_in_the_left_frontal_pole_966041e40f.jpg" alt="Increased connectivity in the left frontal pole.jpg" /></p>
<h2>人とAIの協働に関する新しい視点</h2>
<p>この研究は「The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models」と題し、arXivにプレプリントとして公開された。著者らは、LLMを効果的に活用する能力（いわゆる「プロンプト力」）が、単なるスキルではなく神経科学的な特徴を持つことを示した点に意義があると述べている。</p>
<h2>今後の展望</h2>
<p>論文の著者らは、研究がパイロット的な小規模実験であり、より大規模かつ多様な参加者を対象とした検証が必要だと指摘している。また、プロンプト熟達度と脳活動の関連が、教育や職業訓練にどのような影響を及ぼすかを探る余地があるとした。さらに、AIと人間の協働を支える神経科学的理解を深めることで、ユーザーの特性に合わせたAIインターフェース設計につながる可能性があると述べている。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、AIグラス上位モデル「Meta Ray-Ban Display」を発表──「パーソナルスーパーインテリジェンス」への第一歩、米国で9月30日発売</title>
      <link>https://ledge.ai/articles/meta_rayban_display_launch_2025</link>
      <description><![CDATA[<p>Metaは2025年9月18日（米国時間）、Ray-Banとの協業によるスマートグラスの新モデル「Meta Ray-Ban Display」を<a href="https://about.fb.com/news/2025/09/meta-ray-ban-display-ai-glasses-emg-wristband/">発表</a>した。AI機能に加え、右レンズ内側にディスプレイを搭載し、通知や情報を視界に直接表示できるのが特徴。価格は799ドルで、米国で9月30日から販売が始まる。</p>
<p><strong>「Meta Connect 2025で発表された3種類の新モデル──ディスプレイ搭載の『Meta Ray-Ban Display』、スポーツ向け『Oakley Meta Vanguard』、改良版『Ray-Ban Meta（第2世代）』」</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5.png" alt="G1F7WKzXsAI83Cl.png" /></p>
<h2>製品概要</h2>
<ul>
<li>名称：「Meta Ray-Ban Display」</li>
<li>発表日：2025年9月18日</li>
<li>発売日：米国で9月30日より</li>
<li>価格：799ドル（Meta Neural Band 同梱）</li>
<li>提供カラー：Black、Sand</li>
<li>レンズ：Transitions®レンズ</li>
</ul>
<h2>主な特徴</h2>
<p>「Meta Ray-Ban Display」は、右レンズ内に600×600解像度のHUDを搭載。通知や情報を表示することが可能だ。12MPカメラを内蔵し、写真や動画撮影もできるほか、デュアルスピーカーと複数マイクを備え、ハンズフリーでの利用に対応する。Meta AIと連携し、音声や視覚情報を活用した応答も可能となっている。</p>
<h2>Neural Band との連携</h2>
<p>製品には筋電位（EMG）を利用した「Meta Neural Band」が同梱される。手首のわずかな動きを感知し、直感的な操作を可能にするもので、グラスとの連携により操作性を拡張する。</p>
<h2>利用時間と充電</h2>
<ul>
<li>グラス本体：通常使用で約6時間</li>
<li>付属の折りたたみ式充電ケース：最大30時間まで拡張可能</li>
<li>Neural Band：約18時間稼働</li>
</ul>
<h2>展開スケジュール</h2>
<p>米国では9月30日から、Best Buy、LensCrafters、Sunglass Hut、Ray-Ban Storeなどで販売される。2026年初頭にはカナダ、フランス、イタリア、英国にも展開予定。日本の公式ブログでも製品概要が紹介されており、今後の展開に関する情報提供が予告されている。</p>
<h2>今後の展望</h2>
<p>MetaのCEOマーク・ザッカーバーグ氏は、今回の製品を「パーソナルスーパーインテリジェンス」への第一歩と位置づけている。Metaは同時にスポーツ向けのOakleyブランドモデルも発表した。AI機能とウェアラブルデバイスの融合による新たな市場開拓に注力していくとしている。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、世界最強のAIデータセンター「Fairwater」建設計画を発表──数十万のNVIDIA製GPUを搭載しスーパーコンピューターの10倍性能へ</title>
      <link>https://ledge.ai/articles/microsoft_fairwater_ai_datacenter_launch</link>
      <description><![CDATA[<p>Microsoftは2025年9月18日（現地時間）、ウィスコンシン州に新たなAIデータセンター「Fairwater」を建設すると<a href="https://blogs.microsoft.com/blog/2025/09/18/inside-the-worlds-most-powerful-ai-datacenter/">発表</a>した。同社は「世界最強のAIデータセンター」と位置づけており、完成後にはNVIDIA製GPUを数十万台規模で配備し、既存のスーパーコンピューターを大きく上回る計算能力を備える見込みだ</p>
<h2>AI時代の中核インフラへ</h2>
<p>Microsoftによると、Fairwaterは生成AIや科学研究、産業利用といった幅広い領域を支える計算基盤となることを目指している。特に近年急拡大する生成AI需要に対応し、同社のクラウド基盤「Azure」を通じてグローバルに提供されるAIサービスを強化する役割を担う。</p>
<p>現在、Microsoftは世界でおよそ400のデータセンターを展開している。Fairwaterはそれらを補完しつつ、AI専用に設計された次世代拠点として位置づけられている。</p>
<p><strong>Microsoft データセンター内の AI インフラストラクチャ サーバーの高密度クラスター</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/OMB_Image_2_Datacenter_aa58b955f5/OMB_Image_2_Datacenter_aa58b955f5.jpg" alt="OMB-Image-2-Datacenter.jpg" /></p>
<h2>性能と持続可能性の両立</h2>
<p>Fairwaterは、既存のスーパーコンピューターに比べて約10倍の性能を誇る計画だ。そのために数十万台規模のNVIDIA製GPUを導入する。さらに、エネルギー効率と持続可能性も重視されており、再生可能エネルギーの積極的な活用が盛り込まれている。</p>
<h2>今後の展望</h2>
<p>MicrosoftはFairwaterを起点に、今後も米国内外でのデータセンター投資を続ける方針だ。これにより、AIの研究開発や産業応用を一層加速させ、世界的にAI基盤の提供力を高めていくとしている。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、AIチップ冷却に「マイクロ流体」導入──シリコンに直接液体を流し効率3倍</title>
      <link>https://ledge.ai/articles/microsoft_microfluidics_ai_chip_cooling</link>
      <description><![CDATA[<p>Microsoftは2025年9月24日、AIチップの性能向上に伴う深刻な発熱問題に対処するため、新しい液体冷却技術「マイクロ流体冷却」の開発・テストに成功したと<a href="https://news.microsoft.com/source/features/innovation/microfluidics-liquid-cooling-ai-chips/">発表</a>した。シリコン基板に微細な流路を刻み、冷却液を直接循環させる方式で、従来の冷却プレートと比べ最大3倍の効率を達成したという。</p>
<p>@<a href="https://www.youtube.com/watch?v=MZBwLi3ajYE">YouTube</a></p>
<p>近年、AIチップは大規模言語モデルや生成AIの処理需要に対応するため高性能化が進んでいる。その一方で、発熱量は急増し、従来の空冷や液冷では限界が見え始めていた。Microsoftは「冷却技術の進歩がなければ、数年以内にAIチップ開発は頭打ちになる可能性がある」と警鐘を鳴らしている。</p>
<h2>新技術「マイクロ流体冷却」の仕組み</h2>
<p>同社が開発した「マイクロ流体冷却」は、チップのシリコン基板に微細な流路を直接形成し、その中に液体を流すことで効率的に熱を除去する仕組みだ。GPU内部の温度上昇を65%低減し、従来の冷却プレート方式と比べ最大3倍の冷却効率を実現したとされる。</p>
<h2>Corintis社との協力</h2>
<p>この取り組みは、スイスのスタートアップCorintisとの共同研究に基づく。自然界の葉脈や蝶の羽に着想を得た「バイオインスパイアード設計」を採用し、AIを用いて冷却液の流路や循環を最適化している。これにより、チップ上で最も高温になる“ホットスポット”を効率的に冷却できるようになった。</p>
<h2>持続可能性への影響</h2>
<p>Microsoftは、Teams会議をシミュレートしたサーバー環境で同技術をテスト。実験室レベルでの検証において、従来技術を大幅に上回る冷却性能を確認した。これにより、実用化に向けた有効性が示された形だ。</p>
<p>マイクロ流体冷却は、データセンターの電力使用効率（PUE）の改善や運用コスト削減にもつながるとされる。冷却技術の革新は、環境負荷を低減しつつ、大規模AIインフラの持続可能な発展を支える重要な鍵になるとみられる。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIがChatGPT利用実態を初公開──7億人が毎週利用、非仕事用途が7割に</title>
      <link>https://ledge.ai/articles/openai_chatgpt_usage_report_2025</link>
      <description><![CDATA[<p>OpenAIは2025年9月15日（現地時間）、対話型AI「ChatGPT」の消費者利用実態を初めて体系的に<a href="https://openai.com/index/how-people-are-using-chatgpt/">公開</a>した。調査結果は、全米経済研究所（NBER）のワーキングペーパー「<a href="https://www.nber.org/papers/w34255">How People Use ChatGPT</a>」（2025年9月）としてまとめられている。</p>
<h2>世界規模で拡大する利用</h2>
<p>論文によると、ChatGPTは2025年7月時点で世界の成人の約10%にあたる7億人が毎週利用し、1日あたり25億件以上のメッセージがやり取りされている。2022年の公開からわずか2年半での急速な普及は前例がないという。</p>
<p><strong>週次利用者数の推移</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Weekly_active_Chat_GPT_users_on_consumer_plans_9236d1b4f6/Weekly_active_Chat_GPT_users_on_consumer_plans_9236d1b4f6.jpg" alt="Weekly active ChatGPT users on consumer plans.jpg" /></p>
<h2>非仕事利用が主流に</h2>
<p>2024年6月時点で53%だった非仕事利用は、2025年6月には73%に達した。家庭内での調べものや学習支援など、日常生活に根付く形で利用が広がっている。</p>
<p><strong>非仕事利用の割合推移</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/messages_not_related_to_work_fef67ce892/messages_not_related_to_work_fef67ce892.jpg" alt="messages not related to work.jpg" /></p>
<h2>利用内容の内訳</h2>
<p>会話テーマの分析では、「実用的アドバイス（Practical Guidance）」「情報検索（Seeking Information）」「ライティング（Writing）」が全体の77%を占めた。特にライティングは仕事利用において中心的で、メールや報告書の作成、文章の編集や翻訳が多いという。コーディング関連は全体の4.2%、人間関係や自己表現は2.4%にとどまった。</p>
<h2>ユーザー層の変化</h2>
<p>利用者層の特徴としては、初期に見られた男性中心の傾向が薄れ、2025年半ばには女性名のアカウントが過半数を占めるまでになった。また、26歳未満の若年層が全体の約半数を占め、低～中所得国での利用増加も顕著となっている。</p>
<h2>職業別の利用傾向</h2>
<ul>
<li>管理・ビジネス職：ライティングが過半数を占める。</li>
<li>IT関連職：プログラミングやデータ処理などのテクニカルヘルプが37%。</li>
<li>共通点：業種を問わず「意思決定・問題解決」「情報取得」に多く使われる。</li>
</ul>
<h2>ユーザーの意図</h2>
<p>ユーザーのリクエストは以下の3分類に整理された。</p>
<ul>
<li>Asking（助言・情報）：49%</li>
<li>Doing（作業依頼）：40%</li>
<li>Expressing（感情表現など）：11%</li>
</ul>
<p>特に仕事利用ではDoingが56%を占め、その多くがライティング関連だった。</p>
<p>研究チームは「ChatGPTは作業そのものの代替にとどまらず、知識集約型の職業における意思決定支援としての価値が高い」と指摘している。今回の調査は、生成AIが業務効率化に加え、学習や生活の場面でも定着しつつある現状を裏付けるものとなった。</p>
]]></description>
      <pubDate>Sun, 06 Jul 2025 02:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>