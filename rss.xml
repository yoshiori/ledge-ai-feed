<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>GoogleマップがGemini対応　「右折はタイ料理店の先」など“ランドマーク案内”を含む4つの新機能を発表</title>
      <link>https://ledge.ai/articles/google_maps_gemini_landmark_navigation_4_features</link>
      <description><![CDATA[<p>Googleは2025年11月5日（現地時間）、地図アプリ「Googleマップ」に生成AI「Gemini」を統合し、会話型のナビゲーション体験を強化する4つの新機能を<a href="https://blog.google/products/maps/gemini-navigation-features-landmark-lens/">発表</a>した。Geminiによる音声操作やランドマーク型案内、交通情報の自動通知、カメラを活用した視覚的検索が順次利用可能になる。</p>
<h2>会話で完結する“ハンズフリー運転”</h2>
<p>新機能の一つは、運転中に音声だけで操作できる「会話型ハンズフリー運転体験」だ。ユーザーは「途中でコーヒーショップに寄りたい」など自然な言葉で指示でき、Geminiが最適な経路や立ち寄り先を提案する。走行中でも画面操作を減らし、安全性の高いナビゲーションを実現する狙いがある。</p>
<p>@<a href="https://youtu.be/WnNZ3QhwE84">YouTube</a></p>
<h2>「右折はガソリンスタンドの先」──ランドマークで案内</h2>
<p>従来の「200メートル先を右折」ではなく、「タイ料理店の先を右折」といったランドマーク（目印）を基準にしたターン案内も追加された。ユーザーが視認しやすい建物や店舗を指標にすることで、より直感的に道順を把握できるという。</p>
<p>@<a href="https://youtu.be/_wJIEgy0uCg">YouTube</a></p>
<h2>ナビ起動前から渋滞を警告</h2>
<p>Geminiはまた、ユーザーの通勤や通学など“日常ルート”を学習し、ナビを起動していなくても交通渋滞や事故発生を検知した際に自動で通知を行う。プロアクティブなアラート機能により、出発前のタイミングで回避ルートを確認できるようになった。</p>
<p>@<a href="https://youtu.be/WJ7E8KTv034">YouTube</a></p>
<h2>Lens with Geminiで“周囲を質問”</h2>
<p>さらに、「Lens with Gemini」ではスマートフォンのカメラを向けた建物や店舗を即座に認識。たとえば、カメラを向けて「このレストランは何時まで開いてる？」と尋ねると、営業時間やレビューなどをGeminiが対話形式で返答する。従来の検索型から“会話する地図”への進化がうかがえる。</p>
<p>@<a href="https://youtu.be/mlhIxJCP9CM">YouTube</a></p>
<h2>提供開始と対応環境</h2>
<p>これらの機能は「Geminiが利用可能な地域」から順次展開される予定。対象はAndroidとiOSのGoogleマップアプリで、今後はAndroid Autoなど他プラットフォームへの拡張も検討されているという。</p>
]]></description>
      <pubDate>Mon, 10 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Canva、「Creative OS」を発表──デザインAIとVisual Suiteを統合した次世代ビジュアル作業環境</title>
      <link>https://ledge.ai/articles/canva_creative_operating_system_release</link>
      <description><![CDATA[<p>Canvaは2025年10月29日（現地時間）、同社史上最大規模のプロダクト刷新として「Creative Operating System（Creative OS）」を<a href="https://www.canva.com/ja_jp/newsroom/news/creative-operating-system/">発表</a>した。</p>
<p>この新しいプラットフォームは、再設計されたVisual Suiteと、デザイン理解に特化したAIモデル「Canva Design Model」、さらにブランド運用・配信基盤「Canva Grow」などを統合した“次世代のビジュアル作業環境”として位置づけられている。</p>
<h2>Visual Suite：制作・共有・公開の一体化</h2>
<p>新しいVisual Suiteでは、動画、フォーム、データ、メールなど、これまで分離していたクリエイティブ作業を統合。「Video 2.0」では、タイムライン編集、トリミング、レイヤー同期などの操作が直感的になり、AI機能「Magic Video」によりプロ仕様の動画を容易に生成できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DROP_25009_Newsroom_PR_New_Timeline_ja_JP_b35e716c1f/DROP_25009_Newsroom_PR_New_Timeline_ja_JP_b35e716c1f.jpg" alt="DROP25009_NewsroomPR_NewTimeline_ja-JP.jpg" /></p>
<p>「Canva Forms」はドラッグ＆ドロップでフォームを作成でき、回答結果を「Canva Sheets」に自動集約。「Canva Websites」など他の製品と連携して活用できる。さらに「Canva Code」と「Sheets」を接続することで、データ駆動型のインタラクティブな体験をエディタ内で構築可能となった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DROP_25009_Newsroom_PR_Forms_Still_ja_JP_a2b2ed1c7d/DROP_25009_Newsroom_PR_Forms_Still_ja_JP_a2b2ed1c7d.jpg" alt="DROP25009_NewsroomPR_FormsStill_ja-JP.jpg" /></p>
<p>加えて「Canva Email Design」では、テンプレートやAI支援によりブランドメールを作成し、デスクトップ・モバイル両方でプレビュー、HTMLエクスポートやテスト送信が行える。</p>
<h2>デザイン特化AI「Canva Design Model」</h2>
<p>Canvaは同発表で、世界初の“デザインAIモデル”として「Canva Design Model」を公開した。このモデルは、構造・レイヤー・階層・ブランディング・視覚ロジックといった「デザインの複雑性」を理解し、編集可能な形式のコンテンツを生成できる。
ChatGPTやClaudeなど外部プラットフォームでも利用でき、GoogleのGemini向けは「coming soon」としている。</p>
<p>また、「AI Powered Designs」や「AI Powered Elements」では、テンプレート、写真、動画、アイコン、3D要素、カスタムコードなどを生成可能。スタイルを自動的に整える「Style Match」や背景生成「Magic Background」も搭載された。「Ask @Canva」を用いれば、コメント欄で“@Canva”を呼び出すことで、AIが即座にデザイン提案を行う。</p>
<p>さらに「Canva AI ホーム」では、ガイド付きのプレゼンテーション作成や、企業向けのチーム文脈（Team Context）・外部ストレージ連携などを利用できる。</p>
<h2>Canva GrowとBrand System：ブランド運用を閉ループ化</h2>
<p>「Canva Grow」は、コンテンツ制作から配信、分析までを一体化したマーケティング支援機能。ユーザーのWebサイトをスキャンしてブランドトーンを学習し、複数の広告バリエーションを自動生成する。
Meta広告アカウントと連携すれば、配信データに基づいたリアルタイム分析と最適化提案を行う。
また、新しい「Brand System」では、ロゴ、テンプレート、カラーパレット、ガイドラインを一元管理し、エディタ上にリアルタイムで反映。
ブランドキットを接続すると、AIが初期生成段階からブランド整合性の取れたデザインを提示する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DROP_25009_Newsroom_PR_Canva_Grow_Publish_ja_JP_3ec52cb61b/DROP_25009_Newsroom_PR_Canva_Grow_Publish_ja_JP_3ec52cb61b.jpg" alt="DROP25009_NewsroomPR_CanvaGrowPublish_ja-JP.jpg" /></p>
<h2>「All-new Affinity」も無料化</h2>
<p>同発表では、写真編集、ベクター描画、ページレイアウトを統合したプロ向けスイート「All-new Affinity」も合わせて紹介された。
これまで有料だった同ソフトを「すべての人に、永続的に無料で提供する」とし、Canva AI Studioとの連携も実現している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DROP_25009_Newsroom_PR_Brand_Kit_1_ja_JP_c1d6115d80/DROP_25009_Newsroom_PR_Brand_Kit_1_ja_JP_c1d6115d80.jpg" alt="DROP25009_NewsroomPR_BrandKit-1_ja-JP.jpg" /></p>
<p>Canvaは今回の刷新を、「創造性を誰もが扱える“オペレーティングシステム”として再定義するもの」と説明。
デザイン・AI・ブランド運用をシームレスにつなぐことで、個人から企業まで幅広いユーザーが一貫したワークフローで制作・配信・分析を行える環境を提供するとしている。</p>
]]></description>
      <pubDate>Mon, 10 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>機密情報を守り抜く生成AI基盤――GPUクラスタで実現する社内LLM活用</title>
      <link>https://ledge.ai/articles/nttpc_interview_gpu_cluster</link>
      <description><![CDATA[<p>すっかり社会に浸透した生成AIだが、企業での活用はまだ十分に進んでいるとは言い難い。個人利用は急速に拡大する一方で、機密情報の取り扱いや外部LLMへの依存が大きな障壁となっている。生成AIをビジネスに実装する際は、データ保護とサービス独立性を確保する手段として、社内に閉じたローカル環境での基盤構築・運用は不可欠といえるだろう。</p>
<p>さらに、高いパフォーマンスが求められる生成AI基盤の選択肢として、複数のGPUサーバーを協調動作させる「GPUクラスタ」が挙げられる。GPUクラスタはいかにして企業の生産性向上に貢献できるのか、また、セキュリティと独立性を確保したGPUクラスタを導入する場合、企業はどのような点に気を配る必要があるのだろうか。</p>
<p>『GPUクラスタ×生成AI　―13のポイントで実現する次世代基盤とビジュアライゼーション実践ガイド』の著者であり、NTTPCコミュニケーションズ株式会社（以下、NTTPC）でGPUエンジニアとして活躍する大野泰弘氏に、生成AI基盤構築のポイントについて話を伺った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/img_release_book_1350a15501/img_release_book_1350a15501.jpg" alt="img_release_book.jpg" /></p>
<p>:::button
<a href="https://www.nttpc.co.jp/gpu/?utm_campaign=GPU&amp;utm_source=ledge&amp;utm_medium=ledge.co.jp&amp;utm_term=ledge.co.jp&amp;utm_content=ledge_202511"><strong>NTTPCのGPUクラスタ導入・構築サービスの詳細はこちら</strong></a>{target=_blank}
:::</p>
<p>※インタビューは2025年10月9日に行われた。本記事はインタビュー時の情報に基づく。</p>
<h2>企業が生成AIを活用する際に重要なのは「データの扱い」と「独立性」</h2>
<p><strong>――日本企業における生成AI活用の現状について、どのようにご覧になっていますか。</strong></p>
<p><strong>大野氏</strong>
個人でのChatGPT等クラウド型LLMの利用率はかなり高まっていると感じます。ただ、企業として使う場合は話が違ってきます。多様なビジネスニーズに対応できるよう、企業内情報や顧客情報を学習させたカスタマイズLLMを利用している企業は未だ多くないのが現状です。</p>
<p><strong>――なぜ個人では積極的に使用しているのに、企業では利用が進んでいないのでしょうか。</strong></p>
<p><strong>大野氏</strong>
主に企業のセキュリティルールが原因です。非公開情報をパブリックにアップロードすることへの懸念から、多くの企業が社内導入に踏み切れずにいるのではないかと見ています。</p>
<p><strong>――非公開情報の取り扱いに関する懸念点をもう少し詳しく教えてください。</strong></p>
<p><strong>大野氏</strong>
一般的な情報であれば、外部APIやクラウド型LLMサービスを使っても問題ないでしょう。しかし、企業の重要な情報をクラウド型LLMにアップロードする場合は注意が必要です。</p>
<p>クラウド型LLMサービスであっても、エンタープライズ契約では「アップしたデータを学習に使わない」と明記されているケースも多くありますが、それが本当に守られているか確認する手段はありません。最終的にはAIサービスを提供している企業倫理に委ねるしかないのです。そのような状況では、たとえエンタープライズ契約であっても企業が慎重になるのは当然です。もし、重要情報をAIで扱うなら、外部に情報が出ないローカルなオンプレミス環境を構築するのがもっとも安全です。</p>
<p>もう一つの重要なポイントは「独立性」です。たとえば、GPT-4oがGPT-5にアップデートされ、出力の性質が変わってしまったケースがありました。企業のワークフローに生成AIを組み込んでいると、こうしたAPI挙動の変化がビジネスに大きな影響を与えます。さらにAPIに障害が発生すれば業務が停止してしまいます。</p>
<p>企業によっては、SlackやGitHubが落ちると仕事ができなくなってしまいますよね。それと同じことがAIにも起こり得ます。こうしたリスクを防ぐには、独立性を保ち、自社でAPIを運用することが重要です。</p>
<p><strong>――将来のリスクに備える意味でもローカル環境が重要になるわけですね。</strong></p>
<p><strong>大野氏</strong>
はい。特に大企業は、社内ナレッジやパーソナルデータなど膨大な機密情報を保有していることが多いでしょうから、ローカル環境を整備すべきだと考えます。また、将来的にAIは石油や鉄鋼と同じく戦略物資に位置づけられる可能性もあります。なぜなら、APIを提供している企業がある国が、ある日突然「自国以外にAPIを使わせない」と言い出すと、業務が完全にストップしてしまうからです。そうした状況への対策として、国としての独立性を維持することも重要になるでしょう。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_oonosama_2_6978526600/npptc_interview_oonosama_2_6978526600.jpg" alt="npptc_interview_oonosama_2.jpg" /></p>
<h2>複数のGPUサーバーを連携させる「GPUクラスタ」が生成AI活用の鍵を握る</h2>
<p><strong>――NTTPCでは、企業が生成AIを活用する際のインフラとして「GPUクラスタ」を提供しています。あらためてGPUクラスタの概要について教えてください。</strong></p>
<p><strong>大野氏</strong>
複数のGPUサーバーを連携させ、処理を高速化したものがGPUクラスタです。クラスタを構成することで、システムの可用性を上げることができます。万が一システムが停止しても事業が止まらないよう、複数台でクラスタを組むことで安定した基盤を構築するのです。</p>
<p><strong>――GPUクラスタを構築する上で押さえておくべきポイントはありますか。</strong></p>
<p><strong>大野氏</strong>
パラメータ数の大きな生成AIモデルを扱う場合、いかに多くのGPUメモリを利用できるかが応答速度に直結します。一つのサーバー内に搭載できるGPU枚数は多くても8～10GPU程度ですが、数十～数百台のサーバーを連結させて動作させることで、さらに多くのGPUメモリ容量を確保できます。これにより、学習スピードを上げたり、より大きなモデルを作成できるようになります。</p>
<p>その際、サーバー同士を高速で接続する「インターコネクト」が重要になります。インターコネクトが遅いと、どんなに高性能なGPUを使っていても全体の処理速度が落ちてしまうからです。いわば二人三脚のようなもので、遅い方に全体のスピードが引きずられるのです。ですから、GPUだけでなく通信部分にも適切な投資をすることが重要です。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_gpu_cluster_image_wt_d30256d970/npptc_interview_gpu_cluster_image_wt_d30256d970.png" alt="npptc_interview_gpu_cluster_image_wt.png" /></p>
<p>また、同時リクエスト数に応じてクラスタのサイズを調整することも必要です。業務にAIを組み込むと、100件、200件といった同時リクエストが発生することもあるので、それに合わせてクラスタを拡張しなければなりません。</p>
<p><strong>――インターコネクトについては認識されていない企業が多いのでしょうか。</strong></p>
<p><strong>大野氏</strong>
そうですね。多くの方は「GPUを買ってつなげば動くのでは」と考えがちです。しかし、適切な設定をしなければ、たとえば400Gbpsや800Gbpsといった高速なイーサーネットで接続しても、通信が輻輳して期待したパフォーマンスが出ないことがあります。後から「ここに投資しておけばよかった」と、多くの人が後悔するのがインターコネクトなのです。</p>
<h2>インターコネクトの設計で、ネットワークの速度と安定性が大きく変わってくる</h2>
<p><strong>――インターコネクトについて、もう少し詳しく教えてください。</strong></p>
<p><strong>大野氏</strong>
端的に言えば、インターコネクトはGPU同士をつなぐ高速なネットワークです。なぜインターコネクトが必要なのかというと、GPUで言語学習などのトレーニングを行う場合、AllReduceという計算方式を使います。この仕組みでは、各GPUにタスクを割り当てて、計算結果を一度集めて再分配するというプロセスを繰り返します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_gpu_distributed_training_wt_4cc4528ee7/npptc_interview_gpu_distributed_training_wt_4cc4528ee7.png" alt="npptc_interview_gpu_distributed_training_wt.png" /></p>
<p>この「集約」と「再分配」の時間が通信時間となり、その間はGPUの稼働率が落ちてしまうのです。低速のネットワークを使うと、GPUの稼働率が5％～10％程度まで下がってしまい、せっかくのGPUのリソースを活かせません。そのため、インターコネクト設計がGPUクラスタの性能を左右するのです。</p>
<p><strong>――適切に設計されたインターコネクトとそうでないものでは、どの程度の差が出るのでしょうか。</strong></p>
<p><strong>大野氏</strong>
インターコネクトのパフォーマンスチューニングをしない場合は稼働率が80％程度ですが、適切にチューニングすることで90％～95％まで向上させられます。生成AIの進化は非常に速く、少しでも早く学習を終えてトライ＆エラーを繰り返せる環境を整えることが重要です。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_gpu_utilization_rate_wt_5d320f36bd/npptc_interview_gpu_utilization_rate_wt_5d320f36bd.png" alt="npptc_interview_gpu_utilization_rate_wt.png" /></p>
<p><strong>――長期間かけて何度も繰り返す作業となると、最終的には大きな差につながりそうですね。</strong></p>
<p><strong>大野氏</strong>
はい。それから、速度と同じくらい重要になるのが安定性です。場合によっては1ヶ月間ずっとAIの学習を回し続けるようなこともあるでしょう。その際、途中でエラーが発生すると1か月間の学習がすべてリセットされてしまいます。チェックポイントを設けて定期的に保存は行いますが、仮に1時間分の計算が無駄になるだけでも大きな損失です。</p>
<p><strong>――ネットワークの安定性を確保するためのポイントはありますか？</strong></p>
<p><strong>大野氏</strong>
弊社では、設計段階で光ケーブルの損失を計算したり、トランシーバーに負荷をかけてストレステストを行っています。軽い検証でスタートしてしまうと、本番運用時に問題が発生することがあります。単にベンチマークソフトを回すだけでなく、複数のパラメータで検証し、厳しい条件で試すことが大切です。</p>
<p><strong>――大野さんは国内有数の大規模プロジェクトを率いたご経験を豊富にお持ちです。そのご経験から、GPUクラスタの設計思想についてお聞かせください。</strong></p>
<p><strong>大野氏</strong>
もっとも重要なのは、お客様のユースケースに合わせた設計をすることです。たとえば、学習パターンによっては高いスループットが不要な場合もあるので、過剰な設計にならないようネットワークを組むことが大切になります。お客様もビジネスとしてサーバーに投資されるわけですから、投資した以上の利益を上げないといけません。そのためにも、コストを削減することが我々ベンダーの大切な役割になるのです。</p>
<p>また、ネットワークの設定だけでなく、サーバー内部のLinuxカーネルの設定なども適切に行い、通信のスピードを最適化することが求められます。仮に10台や20台のGPUサーバーでクラスタを構築し、稼働率が10～20％向上すれば、それだけでサーバー1～2台分の効果が得られることになりますよね。そういった形で、お客様の資産を最大限に活用できる形でクラスタを組むことを心がけています。</p>
<p><strong>――そのあたりは、豊富なご経験を持つ大野さんやNTTPCならではですね。</strong></p>
<p><strong>大野氏</strong>
はい。自前で構築したものの、思ったようなパフォーマンスが出ないと感じている方は多いと思います。実はドライバーのファームウェアのバージョンをそろえるだけでも、大きく変わることがあるんですよ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_oonosama_3_6ec69c2ec7/npptc_interview_oonosama_3_6ec69c2ec7.jpg" alt="npptc_interview_oonosama_3.jpg" /></p>
<h2>生成AI活用で暗黙知の活用や定型ワークフローの自動化を実現</h2>
<p><strong>――データの学習やファインチューニングなど、AIのライフサイクル全体を管理する「AIファクトリー」が注目を集めています。AIファクトリーの構築は、技術に詳しくない一般企業や中小企業でも可能なのでしょうか。</strong></p>
<p><strong>大野氏</strong>
専門知識を持った人材がいれば自社で構築することも可能でしょう。しかし、専門家を採用したり育成したりするのは簡単ではありません。現実的には、弊社のような専門企業にAIファクトリーの設計から構築、導入までご依頼いただくのが近道です。その方が、お客様も自社のビジネスに集中できます。</p>
<p><strong>――AIファクトリーを導入し、生成AI活用を進めることで、企業はどのようなビジネス課題を解決できるでしょうか。</strong></p>
<p><strong>大野氏</strong>
一つは、社内の暗黙知の活用です。社内にはSlackなどでやりとりしてきた情報が蓄積されているはずです。これらをデータベース化し、AIで参照できるようにすれば、24時間365日質問に回答できるシステムが出来上がります。</p>
<p>他には、メール応答の自動化なども効果的です。たとえば、お客様からの見積もり依頼メールに対して、不足している情報を自動的にAIで問い合わせることができれば、見積もり作成までの時間が短縮でき、お客様への対応が早くなるでしょう。</p>
<p>このように、企業のワークフローの中で定型化している業務をAIに任せることで、他の業務にリソースを集中できるようになるのです。</p>
<p><strong>――自前のAI基盤を持つことが、企業に競争優位性にどうつながると考えますか。</strong></p>
<p><strong>大野氏</strong>
一つは、企業内のワークフローを安定的に提供できることです。熟練者が退職してしまっても、AIが知識を引き継ぐことで業務の連続性が確保できます。少子化が進む中で、特に重要になる要素でしょう。</p>
<p>二つ目は心理的安全性の向上です。AIは質問しても怒らず、いつでも相談に乗ってくれます。といっても、ChatGPTは一般的な知識はあっても、会社特有の情報は教えてくれないのであまり役立ちません。自社のAIなら、会社のことを教えてくれる「やさしい相談相手」が常に存在することになります。</p>
<p>三つ目はセキュリティの担保です。ローカルでAIを運用することで、新入社員などが「この情報をAIに入れても大丈夫か」と迷うことがなくなります。気兼ねなく質問できる環境が整うことで、問題解決のスピードが向上するでしょう。</p>
<h2>GPUクラスタの導入実績と未来のユースケース</h2>
<p><strong>――NTTPCのGPUクラスタを導入した企業からは、どのような反響がありますか。</strong></p>
<p><strong>大野氏</strong>
弊社が構築したクラスタを運用されているお客様からは、「非常に安定している」という評価をいただいています。また、「トラブルが発生した際の対応が非常に早い」というフィードバックもよくいただきます。弊社には約20名のエンジニアがおり、分担してトラブルシューティングを行うことで、迅速な対応が可能になっています。</p>
<p><strong>――今後、GPUクラスタ構築がより求められる業界や領域はどこだとお考えですか。</strong></p>
<p><strong>大野氏</strong>
日本の製造業、特に自動車産業ではGPUクラスタの処理能力が不可欠になると考えています。たとえば、NVIDIA Omniverse™やNVIDIA Isaac Simなどを活用したデジタルツイン空間では、現実では不可能な実験を無限に行うことができます。実際の道路で事故データを収集するのは難しいですが、デジタルツイン上では様々な事故シナリオのシミュレーションが可能です。</p>
<p>また、産業ロボット分野でも、工場のラインをデジタルツイン上で作成し、テストを行った上で実際の環境に適用するといった活用方法が考えられます。無限に実験できる環境を持つことは、企業にとって大きな価値につながるはずです。</p>
<p><strong>――様々な利用シーンがあるのですね。GPUクラスタの領域ではやはりNVIDIAの存在感が強いのでしょうか。</strong></p>
<p><strong>大野氏</strong>
はい。GPUクラスタのベストプラクティスとして、NVIDIAからは「NVIDIA DGX SuperPOD™」が公開されています。これは単なるハードウェアの集合ではなく、GPUコンピューティング、ストレージ、ネットワーキング、ソフトウェア、インフラ管理までまとまったフルスタックプラットフォームです。互換性の取れた構成と標準化されたモジュールにより、短い期間でシステムを立ち上げることができ、運用コスト・リスクを低減できます。弊社はNVIDIAエリートパートナーとして、DGX SuperPODの設計・構築・導入も手掛けています。</p>
<p><strong>――今後、GPUクラスタの導入を検討している企業へアドバイスをお願いします。</strong></p>
<p><strong>大野氏</strong>
まずは、スモールスタートで始めることをおすすめします。弊社には設計から構築までの豊富なノウハウがありますので、ご相談いただければお客様の状況に合わせてご希望に合わせたご提案をさせていただきます。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/npptc_interview_oonosama_4_c8e0c9fb36/npptc_interview_oonosama_4_c8e0c9fb36.jpg" alt="npptc_interview_oonosama_4.jpg" /></p>
<p>:::button
<a href="https://www.nttpc.co.jp/gpu/?utm_campaign=GPU&amp;utm_source=ledge&amp;utm_medium=ledge.co.jp&amp;utm_term=ledge.co.jp&amp;utm_content=ledge_202511"><strong>NTTPCのGPUクラスタ導入・構築サービスの詳細はこちら</strong></a>{target=_blank}
:::</p>
]]></description>
      <pubDate>Mon, 10 Nov 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ソフトバンク、AIスタートアップに無償GPU提供を本格化　宮川社長「計算基盤が国力」——決算会見で危機感</title>
      <link>https://ledge.ai/articles/softbank_ai_foundation_gpu_support_2025q2</link>
      <description><![CDATA[<p>ソフトバンクは2025年11月5日、2026年3月期第2四半期の決算説明会を開催し、AI分野に取り組むスタートアップ企業への支援強化を<a href="https://www.softbank.jp/corp/ir/documents/presentations/fy2025/#result-20251105">発表</a>した。社長の宮川潤一氏は「半導体の次に来るのはAIの計算基盤のサイズ。すべてがコンピューティングパワーだ」と述べ、AI計算基盤の整備を国家的課題と位置づけた。</p>
<p>同社は既に、GPU計算資源などを段階的に提供する「AI Foundation for Startups」を10月1日に<a href="https://www.softbank.jp/corp/news/press/sbkk/2025/20250926_01/">開始</a>しており、初期段階の企業にはNVIDIA DGX A100一式を最長60日間無償で提供する枠組みを明示。開発・検証フェーズでは低コスト提供、事業化段階では協業・出資も視野に入れるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/aifoundationforstartups_d3538c27d9/aifoundationforstartups_d3538c27d9.jpg" alt="aifoundationforstartups.jpg" /></p>
<p>会見の中で宮川氏は、海外勢の動きを引き合いに危機感を示した。生成AI時代の競争軸が「計算基盤（コンピューティングパワー）の規模」に移りつつあるとの見立てを述べ、日本の産業競争力を左右する要素として計算資源の確保と活用を位置付けた。</p>
<p>背景として、海外では大規模なAIインフラ整備が加速していることが挙げられる。NVIDIAは10月31日、韓国の政府・産業界と連携し「25万基超（over a quarter-million）のGPU」を追加配備する構想を<a href="https://investor.nvidia.com/news/press-release-details/2025/NVIDIA-South-Korea-Government-and-Industrial-Giants-Build-AI-Infrastructure-and-Ecosystem-to-Fuel-Korea-Innovation-Industries-and-Jobs/default.aspx">発表</a>。韓国の産業分野全体でAI実装を進める基盤整備を掲げた。国内の計算資源の量・質をめぐる国際的な競争が一段と激しくなる中、ソフトバンクはスタートアップへの無償提供を含む支援スキームを通じて、国内の開発初期ハードルを下げる狙いだ。</p>
]]></description>
      <pubDate>Sun, 09 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/9 [SUN]AI訓練データの“源流”Common Crawlに疑惑──The Atlanticが報道、ペイウォール記事含有を指摘</title>
      <link>https://ledge.ai/articles/common_crawl_paywall_investigation_and_response</link>
      <description><![CDATA[<p>米誌『The Atlantic』は2025年11月4日、非営利団体Common Crawlが構築するウェブアーカイブが、OpenAIやGoogleなどのAI企業による大規模言語モデル（LLM）の訓練に利用されており、ペイウォール（有料会員制）記事を含む可能性があると<a href="https://www.theatlantic.com/technology/2025/11/common-crawl-ai-training-data/684567/">指摘した</a>。同日、Common Crawlは公式ブログで反論し、透明性とフェアユース（公正利用）の理念を改めて強調した。</p>
<h2>AI企業が利用する「見えない基盤」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/theatlantic_b31bcde0e1/theatlantic_b31bcde0e1.jpg" alt="theatlantic.jpg" /></p>
<p>The Atlanticの記事は、Common Crawlが10年以上にわたりウェブ全体をクロールし、ペタバイト級のアーカイブを研究・教育目的で公開してきた点を紹介した。記事によると、このデータセットはOpenAI、Google、Meta、Amazon、Anthropic、NVIDIAなどのAI企業がLLM訓練に活用しており、「AI業界の見えない基盤（invisible infrastructure）」になっているという。</p>
<p>同誌は、Common Crawlのアーカイブに有料メディアやニュースサイトのペイウォール記事が含まれている可能性を指摘。出版各社が「有料コンテンツが無断でAI訓練に利用された」と懸念を示していると報じた。また、削除を求めた出版社に対して十分な対応が行われていない事例があるとし、透明性が不十分だと指摘した。</p>
<h2>Common Crawlが即日反論</h2>
<p>同日、Common Crawlは公式ブログ「Setting the Record Straight」を<a href="https://commoncrawl.org/blog/setting-the-record-straight-common-crawls-commitment-to-transparency-fair-use-and-the-public-good">公開</a>し、「当財団はペイウォールを回避しない。活動は透明で、robots.txtを尊重している」と反論した。</p>
<p>ブログでは次のような見解を示している。
クローリングはrobots.txtなどウェブ標準に準拠しており、ペイウォールを意図的に回避した事実はない。
出版社からの削除要請には対応しており、プロセスの透明性を確保している。
データは特定企業への提供ではなく、研究者・教育機関・一般利用者を含むすべての人に開放されている。
公開データはフェアユースの理念に基づくもので、社会全体の知識共有を目的としている。</p>
<p>Common Crawlはまた、「CCBotは公開ページのみを収集し、ログインやペイウォール回避は行わない。User-agent: CCBotの設定でブロック可能」と説明。アーカイブの存在が「研究や民主的な情報アクセスを支える公共財」であると位置づけ、今後も透明性と公益性を重視した運営を続けるとした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/commoncrawl_e3ceb79638/commoncrawl_e3ceb79638.jpg" alt="commoncrawl.jpg" /></p>
<h2>論点はフェアユースと説明責任</h2>
<p>今回の報道と反論を通じて、AI訓練データとしてのウェブアーカイブ活用をめぐる法的・倫理的な論点が浮き彫りになった。
The Atlanticは、出版社の著作物がAIモデルの学習に使われることへの懸念を示した一方、Common Crawlは、意図的な侵害を否定し、公益目的の情報共有としての意義を強調している。</p>
<p>今後は、AI企業、出版社、研究機関の間で、データ利用の範囲や削除手続きの明確化をめぐる議論が進むとみられる。</p>
]]></description>
      <pubDate>Sun, 09 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>著作権書籍で訓練したAI、創作専攻の大学院生による模倣文より高評価──コロンビア大などの研究</title>
      <link>https://ledge.ai/articles/ai_trained_on_copyrighted_books_preferred_over_human_writers</link>
      <description><![CDATA[<p>米コロンビア大学とミシガン大学の研究チームは、著作権のある書籍を用いて訓練したAIモデルが、創作専攻の大学院生（MFA候補者）による文体模倣よりも読者に高く評価される傾向を示したとする研究結果を<a href="https://arxiv.org/abs/2510.13939">発表</a>した。論文は「Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers」と題し、2025年10月に論文共有サイトarXivで公開された。</p>
<h2>実験：AIと人間の「模倣能力」を比較</h2>
<p>研究では、ノーベル賞やブッカー賞などの受賞作家50名を対象に、各作家の文体を再現した短文（最大450語）をAIと人間の双方で生成した。人間側は創作専攻の大学院生（MFA候補者）が作成し、AI側はChatGPT、Claude、Geminiの3モデルを使用した。</p>
<p>AIには2つの条件が設定された。1つは作家の作風を指示して生成する「in-context prompting」、もう1つは各作家の著作全集を用いてAIを個別に再訓練（ファインチューニング）する方法である。</p>
<p>評価は、専門家28名と一般読者131名によるブラインドテスト形式で行われ、「スタイルの忠実性」と「執筆品質」の2項目について比較された。</p>
<h2>ファインチューニングで逆転</h2>
<p>結果は、AIの学習方法によって大きな差が見られた。in-context promptingでは、専門家読者はAI出力を低く評価し、スタイル忠実性のオッズ比（OR）は0.16、執筆品質は0.13だった。</p>
<p>一方、著者全集を用いたファインチューニングでは、専門家の評価が逆転し、スタイル忠実性のORは8.16、執筆品質は1.87となった。
一般読者も同様の傾向を示した。</p>
<p>AI検出ツールによる識別では、通常生成の97％が「AIが書いた」と判定されたのに対し、ファインチューニング版では3％にとどまった。</p>
<p><strong>研究チームによる生成手法の比較図。左はプロンプトのみでの模倣、右は著者全集を用いたファインチューニングによる模倣</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/schematic_crop_fa674379c5/schematic_crop_fa674379c5.jpg" alt="schematic-crop.jpg" /></p>
<h2>コスト差：人間作家より99.7％低い</h2>
<p>研究チームは、1人の作家を対象にファインチューニングと生成を行う場合の中央値コストを81ドル（約1万2千円）と算出した。人間作家によるスタイル模倣の平均報酬3万ドル（約460万円）と比較すると、99.7％のコスト削減となる。この数値は、AIが「著者らしさ」を低コストで再現できることを定量的に示すものとなった。</p>
<h2>著作権法上の含意：市場への影響</h2>
<p>論文は、米国著作権法におけるフェアユースの第4因子（原著作物の市場や価値に与える影響）に関連づけて、この結果を分析している。AIによる生成物が、原著作物やそれを模倣する人間作家の仕事を経済的に代替し得る点を、重要な法的論点として位置づけた。</p>
<p>著者らは、AIが特定作家の全集を用いて学習した場合、個別の「作風再現市場」を実質的に置き換える可能性があると指摘。
また、AIによる大量生成が市場に「希釈効果（market dilution）」をもたらし、読者の関心や購買機会を分散させるリスクにも言及している。</p>
<p>この考え方は、米連邦裁判所が過去の著作権訴訟で示した「AI生成物が原著作物市場の代替となり得るか」という判断基準と一致する。論文は、こうした代替・希釈が確認される場合、著作権作品を利用したAIの学習がフェアユースに該当しない可能性があると論じている。</p>
<h2>研究の限界</h2>
<p>研究チームは、実験が450語の短文を対象としており、長編小説や創作構成のような複雑な要素は評価対象外であると明記した。また、AI訓練に著作権保護作品を使用する行為の法的評価や、商業利用の可否については別途検討が必要と述べている。さらに、今回の結果は「文体再現」に焦点を当てたものであり、創造性や物語構築力といった要素については評価を行っていない。</p>
<h2>今後の議論へ</h2>
<p>この研究は、AIが著作権保護作品を用いて訓練されることが、どの程度創作市場に影響を及ぼすかを定量的に示した初の実証研究の一つとなる。読者評価とコスト分析の両面から、AIが人間の文体模倣を現実的に代替し得る可能性を提示しており、今後の著作権政策や創作支援技術の議論に影響を与えるとみられる。</p>
]]></description>
      <pubDate>Sun, 09 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/8 [SAT]AI導入が雇用を直撃　米10月の人員削減15万人超、理由の2位に「AI」──チャレンジャー社調査</title>
      <link>https://ledge.ai/articles/us_job_cuts_october2025_ai_layoffs_report</link>
      <description><![CDATA[<p>米民間の再就職支援会社チャレンジャー・グレイ・アンド・クリスマス（Challenger, Gray &amp; Christmas）は2025年11月6日（米国時間）、2025年10月の米企業による人員削減発表数が15万3074人に達したと<a href="https://www.challengergray.com/blog/october-challenger-report-153074-job-cuts-on-cost-cutting-ai/">発表</a>した。</p>
<p>前年同月（5万5597人）から175％増で、10月としては2003年以来21年ぶりの高水準となった。主な要因は「コスト削減」と「AI（人工知能）」であり、AI関連のレイオフが要因として単月で2位に浮上したという。</p>
<h2>「AI統合」と自動化が再編の波を拡大</h2>
<p>同社によると、10月に企業が発表した削減理由のうち最も多かったのはコスト削減（50,437人）、次いでAI（31,039人）だった。
AI導入を理由とする人員削減は年初来で4万8414人に上り、前年を大幅に上回るペース。報告書では「AI integration（AI統合）」や「automation-driven restructuring（自動化による再編）」が複数業種で主要因として挙げられた。</p>
<p>テクノロジー産業の削減は10月だけで33,281人と、前月（5,639人）から急増。年初来では14万1159人（前年同期比＋17％）となり、AI活用による業務効率化が雇用の再構成を促している。</p>
<h2>倉庫・物流で過去最大の削減──自動化が要因</h2>
<p>倉庫・物流（Warehousing）分野では、10月の削減数が47,878人に達し、業種別で最多となった。前年同月の984人から急増しており、年初来では90,418人（＋378％）。同社は、パンデミック期に拡張した物流網の過剰能力と自動化の進展が要因と分析している。</p>
<h2>「破壊的技術が再び雇用地図を変える」</h2>
<p>チャレンジャー社は、「2003年当時も、携帯電話という破壊的技術が雇用地図を変えた。今、同じことがAIによって起きている」とコメント。10月としての削減数は2003年以来の最多であり、第4四半期単月でも2008年以来の高水準と指摘した。</p>
<p>一方で、SNS時代に入って以降は「ホリデーシーズン前のレイオフを避ける傾向」が強まっていたが、2025年10月は約450件の個別計画が報告され、例年を大きく上回ったという。</p>
<h2>採用計画は11年ぶりの低水準</h2>
<p>10月末までの累計では、米雇用主による人員削減数は1,099,500人（前年同期比＋65％）。一方で、新規採用計画は488,077人と前年同期比35％減。同社によると、月間平均は48,808人で、2011年以来の低水準に落ち込んでいる。季節雇用も37万2520人にとどまり、同社が追跡を開始した2012年以降で最少だった。</p>
<h2>AI時代の雇用構造変化</h2>
<p>AI導入は生産性向上とコスト削減をもたらす一方、雇用の再編・削減要因として急速に存在感を高めている。
チャレンジャー社は「AI adoption（AIの採用）や自動化による効率化が複数業種でレイオフを誘発している」とし、雇用市場全体が「生成AI時代の再構築フェーズ」に入っていることを示唆している。</p>
]]></description>
      <pubDate>Sat, 08 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Getty Images、Perplexityと複数年ライセンス契約──AI検索で合法画像とクレジット表示を強化、英国ではStability AI訴訟に判決</title>
      <link>https://ledge.ai/articles/gettyimages_perplexity_ai_license_stabilityai_uk_ruling</link>
      <description><![CDATA[<p>Getty Imagesは2025年10月31日、AI検索サービスを提供するPerplexityとの複数年にわたるライセンス契約を締結したことを<a href="https://newsroom.gettyimages.com/en/getty-images/getty-images-and-perplexity-strike-multi-year-image-partnership">発表</a>した。AIによる画像検索の精度向上と、画像制作者のクレジット表示の改善を目的とした取り組みだ。</p>
<p>一方11月4日、同社が英国で提起していたStability AIとの著作権訴訟では、11月4日にロンドン高等法院が判決を下し、これについての声明を<a href="https://newsroom.gettyimages.com/en/getty-images/getty-images-issues-statement-on-ruling-in-stability-ai-uk-litigation">発表</a>した。</p>
<h2>Perplexityとの契約：合法的な画像利用を推進</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cloud_technology_big_data_financial_technology_and_artificial_intelligence_011824783d/cloud_technology_big_data_financial_technology_and_artificial_intelligence_011824783d.jpg" alt="cloud-technology-big-data-financial-technology-and-artificial-intelligence.jpg" /></p>
<p>同社は10月31日付の発表で、Perplexityと複数年のグローバルライセンス契約を締結したと明らかにした。この契約により、PerplexityのAI検索および発見ツールにおいて、Getty Imagesが保有する編集・クリエイティブ画像を合法的に表示できるようになる。Getty ImagesのAPI技術を活用し、高品質な画像を統合することで、ユーザー体験の向上とクレジット表示の明確化を図る。</p>
<p>リリースの中で同社は、PerplexityがGetty ImagesのAPIを「コンテンツ制作および表示ワークフローに深く統合する」と説明。これにより、「ライセンスされた画像の適切な利用を促進し、クリエイターのクレジット表示を改善する」としている。</p>
<p>Getty ImagesのNick Unsworth氏は、契約が「正しい帰属表示を促進し、AI製品の品質と信頼性を高めるもの」と説明。
PerplexityのJessica Chan氏も「コンテンツの出典や制作者を明示することが、AI時代の正確な情報理解につながる」と述べた。</p>
<p>同社はこの契約はAIプラットフォームにおける「ライセンス画像の正規利用とクレジット明示」を支援するもので、AI検索や生成ツールにおける画像帰属の透明性を高めることを目的としている。</p>
<h2>英国でのStability AI訴訟に判決</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/abstract_gradient_background_with_delicate_waves_aa534c0d6c/abstract_gradient_background_with_delicate_waves_aa534c0d6c.jpg" alt="abstract-gradient-background-with-delicate-waves.jpg" /></p>
<p>Getty Imagesは、画像生成モデル「Stable Diffusion」を開発するStability AIを相手取り、著作権侵害を訴えていた。英国ロンドン高等法院（High Court of England &amp; Wales）は11月4日、Joanna Smith判事による<a href="https://www.judiciary.uk/wp-content/uploads/2025/11/Getty-Images-v-Stability-AI.pdf">判決</a>を言い渡した。</p>
<p>判決では、AI生成画像にGetty Imagesのウォーターマークやロゴが含まれていた点について商標侵害を認定した一方、モデルの訓練過程における著作権侵害の主張は棄却された。判決文では、「モデルが著作物を直接保存または複製している証拠は示されていない」と記されている。</p>
<p>Getty Imagesは同日付の声明で、
「Stable Diffusionの出力に含まれる当社商標の使用が侵害にあたることが確認された」と述べ、モデル提供者に商標責任がある点を「知的財産権者にとって重要な判断」とした。</p>
<p>また、同社は「AIモデル開発における透明性の欠如に懸念を抱いており、政府に対して透明性を高める法制度の整備を求める」とコメントしている。</p>
<p>Getty Imagesは、今回の英国判決で認定された事実を米国で進行中の関連訴訟に反映させる方針を示した。</p>
<h2>今後の方針</h2>
<p>同社は、AI時代における画像利用の正当性とクリエイターの権利保護を両立させるため、ライセンス契約と法的措置の両面から対応を進めている。今後も、AI検索や生成分野における合法的なデータ利用の枠組みを整備し、画像の出典明示や透明性の確保を推進するとしている。</p>
]]></description>
      <pubDate>Sat, 08 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/11/8 [SAT]Google「Project Suncatcher」発表　太陽光×衛星コンステでAI計算を“宇宙へ”</title>
      <link>https://ledge.ai/articles/google_project_suncatcher_space_ai_datacenter</link>
      <description><![CDATA[<p>Googleは2025年11月4日（現地時間）、太陽光発電を搭載した小型衛星群を用い、宇宙空間でAI計算を行うことを目指す新たな研究プロジェクト「Project Suncatcher（プロジェクト・サンキャッチャー）」を<a href="https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/">発表</a>した。</p>
<p>同社の専用チップ「TPU（Tensor Processing Unit）」を搭載した衛星コンステレーションを軌道上に展開し、光学通信で相互接続することで“宇宙データセンター”を形成する構想だ。想定軌道は太陽同期（ドーン・ダスク）で、太陽光の連続利用を見込む。</p>
<h2>地上リソースの制約を超える「宇宙データセンター」</h2>
<p>Google Researchによると、AIモデルの高精度化に伴い、計算能力と電力の需要は急速に拡大している。Project Suncatcherは、地上のエネルギー・冷却・用地といった制約を緩和しつつ、AI計算を持続的にスケールさせるための「ムーンショット（挑戦的研究）」として位置づけられている。</p>
<p>太陽同期軌道では、太陽光パネルの発電効率が地上比で最大8倍に達し、1衛星あたり平均約4 kWの発電を想定。地上のデータセンターで必要とされる100 MW級の電力に比べると、同規模の衛星クラスタ（81機）では0.3 MW程度に収まる試算だ。</p>
<h2>1 km圏内に81機──クラスタ構成の設計例</h2>
<p><a href="https://goo.gle/4qGsU8X">論文</a>では、直径約1 kmの範囲に81機の小型衛星を立体的に配置し、1クラスタあたり約1.3 PFLOPSの演算性能を実現する設計例が示された。各衛星は16 GBメモリを備えたTPUを搭載し、自由空間光通信（Free-Space Optical Link）を介して数km以内で編隊飛行する。通信遅延は0.5 ms以下に抑えられ、地上データセンターと同等の対話応答が可能とされている。</p>
<p>Googleはベンチスケールのデモンストレーターで双方向1.6 Tbps（片方向800 Gbps）の通信速度を達成したと報告。通信帯域の確保には、多波長DWDMや空間多重技術を組み合わせる設計を検討している。</p>
<h2>放射線試験と熱設計──「Trillium TPU」で検証へ</h2>
<p>宇宙空間での安定稼働に向け、Googleは次世代TPU「Trillium（Cloud TPU v6e）」の放射線耐性を評価している。
宇宙では対流冷却ができないため、81機構成のクラスタで約450 m²の放熱面積を確保する必要があると論文は指摘。放熱板の構成や電力変換効率、冷却の最適化も主要な検討課題に挙げられた。
AIワークロードとしては、LLMの学習ではなく推論（inference）・埋め込み生成（embedding）・検索（retrieval）など、軽量分散処理を中心に想定している。</p>
<h2>Planet Labsと連携、2027年に試験衛星を打ち上げ</h2>
<p>次のステップとして、Googleは地球観測衛星を運用する米Planet Labsと提携し、軌道上での技術実証を進める。
Planetは11月4日付の<a href="https://www.planet.com/pulse/planet-to-build-and-operate-advanced-space-platform-for-google-s-project-suncatcher-moonshot/">発表</a>で、Suncatcher向けに「先進的な宇宙プラットフォーム」を構築・運用することを明らかにした。
両社は2027年初頭までに2機の試験衛星を打ち上げ、光学通信の安定性、熱挙動、誤り訂正、電力効率などを評価する「learning mission（学習ミッション）」を予定している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/google_and_planet_suncatcher_moonshot_5280e0e084/google_and_planet_suncatcher_moonshot_5280e0e084.jpg" alt="google and planet suncatcher moonshot.jpg" /></p>
<h2>「AI計算を宇宙に」──Googleが描く次世代インフラ</h2>
<p>Project Suncatcherはまだ構想段階にあるが、Googleは「AI計算を地球の外に拡張する」という新しい方向性を示した。
公式ブログでは「Project Suncatcher is a moonshot to explore solar-powered satellite constellations with TPUs and free-space optical links for scalable AI compute（TPUと光学通信を組み合わせた太陽光衛星群によるAI計算スケーリングを探るムーンショットだ）」と説明している。
エネルギー負荷や冷却コストを軽減しながら、AI計算資源を宇宙空間へと拡張する次世代インフラの研究が、今後本格化する見通しだ。</p>
]]></description>
      <pubDate>Sat, 08 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ソフトバンクとOpenAI、日本に合弁会社「SB OAI Japan」を設立──企業経営を変革するAI「クリスタル・インテリジェンス」を2026年展開へ</title>
      <link>https://ledge.ai/articles/softbank_openai_sb_oai_japan_crystal_intelligence_launch</link>
      <description><![CDATA[<p>ソフトバンクグループとOpenAIは2025年11月5日、AIによる企業経営の変革を目的とした合弁会社「SB OAI Japan合同会社（SB OAI Japan GK）」を設立したと<a href="https://www.softbank.jp/corp/set/data/news/press/sbkk/2025/20251105_02/pdf/20251105_02.pdf">発表</a>した。新会社は、OpenAIの技術を活用した法人向けAIソリューション「クリスタル・インテリジェンス（Crystal intelligence）」を2026年に日本国内で独占展開する。</p>
<p>「クリスタル・インテリジェンス」は、OpenAIのエンタープライズ向け最新プロダクトに、日本市場向けの導入支援と運用サポートを組み合わせたAIソリューション。企業の生産性向上や経営効率の最大化を支援するもので、AI導入から活用までを一貫して支援する。</p>
<p>まずソフトバンク株式会社が最初のユーザーとして導入し、実証と開発を通じて最適な運用方法を検証。その知見を基に、SB OAI Japanを通じて日本企業への展開を進める方針だ。ソフトバンクグループではすでに約250万個の「カスタムGPT（業務や用途に合わせてカスタマイズ可能なChatGPT）」を活用しており、AIネイティブな組織づくりを推進している。</p>
<p>OpenAIのCEOであるサム・アルトマン氏は「ソフトバンクグループとの合弁会社は、日本を皮切りに、世界の有力企業へ先進的な AI を提供していくという OpenAI のビジョンを加速させる、重要な一歩となります」とコメントした。</p>
<p>ソフトバンクグループ株式会社の代表取締役 会長兼社長執行役員の孫正義氏は、「人々の働き方や企業経営が革新される新たな時代が始まります。SB OAI Japanの発足により、AIエージェントが協調し自律的に業務を遂行する世界が実現していきます。OpenAIと共に、AI革命を新たなステージに推し進めていきます」と述べた。</p>
<p>また、ソフトバンク株式会社の代表取締役 社長執行役員 兼 CEOの宮川潤一氏は、「SB OAI Japanの発足により、クリスタル・インテリジェンスの開発が加速します。ソフトバンクは自ら先陣を切って導入・活用を進め、得られた知見を基に法人のお客さまへ提供することで、企業の経営変革を推進していきます」と語っている。</p>
<p>新会社「SB OAI Japan合同会社」は、東京都港区海岸1-7-1に本社を置き、出資比率はCホールディングス株式会社50％、OpenAI 50％。Cホールディングスの持株比率はソフトバンク株式会社51％、ソフトバンクグループ株式会社49％となっている。</p>
<p>同社は今後、「クリスタル・インテリジェンス」を通じて企業の業務プロセスに深く根差したAI活用を支援し、日本企業の経営変革を後押ししていく方針だ。</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>PKSHAと東北大学、「説得対話AI」でEMNLP 2025 Industry Trackに採択──社会心理・行動経済学を融合し、低意欲層にも“自然な動機づけ”</title>
      <link>https://ledge.ai/articles/pksha_tohoku_persuasive_dialogue_ai_emnlp2025</link>
      <description><![CDATA[<p>株式会社PKSHA Technologyは2025年10月31日、東北大学 言語AI研究センターとの共同研究による「説得対話AI」に関する論文が、自然言語処理分野の国際会議「EMNLP 2025（Conference on Empirical Methods in Natural Language Processing）」のIndustry Trackに採択されたと<a href="https://www.pkshatech.com/news/20251031/">発表</a>した。</p>
<p>論文タイトルは「Enhancing Persuasive Dialogue Agents by Synthesizing Cross-Disciplinary Communication Strategies」。社会心理学・行動経済学・コミュニケーション理論を横断的に取り入れ、より多面的で実践的な説得戦略を設計する新しい枠組みを提案している。</p>
<h2>行動心理学の手法をAIが“文脈で選ぶ”</h2>
<p>研究は、営業やカウンセリングなど「目的志向型の対話」におけるAI活用を想定して開発されたという。
既存の説得AIは、特定の戦略（例：単純な論理訴求）に依存する傾向があり、現実のコミュニケーションの複雑さを再現しづらいという課題があった。</p>
<p>今回のモデルは、社会心理学で知られる「フット・イン・ザ・ドア（段階的要請）」や「ドア・イン・ザ・フェイス（譲歩的要請）」「互恵性」「希少性」「フレーミング効果」など、31種類の説得戦略を統合。対話の文脈や相手の反応に応じて最適な戦略を動的に切り替える仕組みを持つ。</p>
<p><strong>図：従来モデル（左）と提案モデル（右）の説得対話の比較</strong>
従来のAI（左）は限定的な戦略に依存し、説得に失敗している。一方、提案モデル（右）は「出典確認」「内省促し」「一貫性訴求」など拡張戦略を組み合わせ、低意欲者にも行動変容を促すことに成功している
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/paksha_tohoku_559ec27a64/paksha_tohoku_559ec27a64.jpg" alt="paksha tohoku.jpg" /></p>
<p>論文では、たとえば「寄付をためらう相手に対して、まずは『情報共有だけでもどうですか？』と小さな行動を提案し、そこから寄付に導く」という例が示されている。こうした“段階的誘導”は人間のコーチング現場でも実践されており、AIがそれを再現するのは初の試みとされる。</p>
<h2>GPT-4oを用いた検証で成功率83%</h2>
<p>検証には、寄付対話データセットPersuasion for Good（P4G）と、多分野の13,000件のシナリオを含むDailyPersuasionが用いられた。
OpenAIのGPT-4o（2024年11月20日版）を基盤とする対話モデル「ProCoT-rich-desc」を構築し、従来手法（ProCoT-p4g）と比較。</p>
<p>結果として、説得成功率83.3％を記録し、特に「意欲が低い層」においても行動意向が平均+1.10ポイント改善した。
人間による評価では72.5％の評価者が提案モデルを「より説得的」と判断。複数データセット間でも汎用性が確認された。</p>
<h2>倫理的リスクへの配慮──「押しつけない説得」へ</h2>
<p>研究チームは、AIが心理的影響力を行使することのリスクにも言及。
「感情的な訴求や時間的プレッシャーが心理的負担を生む可能性がある」とし、人間による最終確認（Human-in-the-Loop）を組み込んだ安全設計を提案している。</p>
<p>具体的には、AIの出力をフィルタリングする「有害性検知ゲート」や、倫理的に望ましくない戦略を除外する仕組みも検討されている。</p>
<h2>実装と今後の展開</h2>
<p>PKSHAはこの研究成果を自社の「PKSHA AI Agents」に活用し、コンタクトセンターや営業現場などでの対話支援を高度化する方針だ。AIが相手の心理状態や意欲レベルに応じて最適なアプローチを選択できれば、業務支援だけでなく、教育・医療・自治体窓口など、幅広い分野での応用が期待される。</p>
<p>PKSHAと東北大学は、「AIによる説得」が社会的・倫理的に安全な形で機能するための基盤技術として、今後も共同研究を継続するとしている。</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、UAEに152億ドルを投資──NVIDIA製GPUで築く「技術・人材・信頼」のモデルケース　AI・クラウド基盤を強化</title>
      <link>https://ledge.ai/articles/microsoft_uae_15_2_billion_investment</link>
      <description><![CDATA[<p>Microsoftは2025年11月3日（現地時間）、アラブ首長国連邦（UAE）におけるAIおよびクラウド関連投資の詳細を<a href="https://blogs.microsoft.com/on-the-issues/2025/11/03/microsofts-15-2-billion-usd-investment-in-the-uae/">発表</a>した。同社は2023年から2029年末までの7年間で、総額152億ドル（約2兆3,500億円）を投じる計画を明らかにした。</p>
<p>投資はAI・クラウドインフラの拡充、人材育成、国際的な信頼基盤の強化を柱とし、「テクノロジー（Technology）」「タレント（Talent）」「トラスト（Trust）」の3分野に重点を置くという。</p>
<h2>2023〜2029年にかけて152億ドルを投資</h2>
<p>Microsoftの副会長兼社長、Brad Smith氏によると、今回の投資は「UAEでお金を集めるものではなく、UAEで支出するもの」だという。2023年に始動したAIイニシアチブのもと、同社はこれまでに約73億ドルを投じており、その内訳はG42社への15億ドル出資、AI・クラウドデータセンター設備への46億ドル、現地運営費など12億ドルとなる。
今後2026〜2029年末までにさらに79億ドルを支出する予定で、55億ドルを追加の設備投資、24億ドルを運営費等に充てる。</p>
<h2>米国製GPUを活用したAIインフラの構築</h2>
<p>Microsoftは米商務省からの輸出許可を得て、NVIDIA製GPUをUAEに供給している。
2025年時点でA100相当のGPU 2万1,500基を導入済みであり、2025年9月にはGB300を含む6万400基分の追加許可を取得した。
これにより、同国のデータセンターではOpenAIやAnthropicなどのAIモデル、Microsoft自身のCopilotアプリケーション、オープンソースモデルなどを動作させている。</p>
<p>Microsoftは「UAEではAI需要が急速に拡大しており、課題は供給が需要を上回ることではなく、需要の伸びに追いつくことだ」と述べている。ブログによると、同国の生成AI利用率は世界最高水準にあり、UAEでは人口の59.4％が生成AIを活用。2位のシンガポール（58.6％）を上回り、他国で50％を超える例はないという。</p>
<h2>現地人材と教育への長期投資</h2>
<p>Microsoftは、技術投資と並行して人材育成にも注力する。
UAEの拠点には約1,000人の社員と関連スタッフ（40カ国籍）が在籍し、エンジニアは約100人。パートナー企業は1,400社に拡大し、関連従業員は約4万5,000人に達する。</p>
<p>2025年にはアブダビに「グローバル・エンジニアリング開発センター（Global Engineering Development Center）」を設立し、世界中から技術者を誘致。地域企業のDX推進や新サービス開発を支援している。
また、同市に開設した「Microsoft AI for Good Lab」では、博士号研究者が低資源言語（例：マラウイ、ケニア、ウガンダなど）の大規模言語モデルを共同開発し、人道支援や教育格差の是正にAIを活用している。</p>
<p>教育分野でも、2027年までにUAE国内で100万人のスキルアップを実現する目標を掲げており、連邦政府や地方自治体と連携して職員12万人の研修を開始。さらに、学生17万5,000人、教員3万9,000人を対象としたAI教育プログラムを進めている。</p>
<h2>責任あるAIと国際的信頼の構築</h2>
<p>Microsoftは、AIの活用には「信頼」が不可欠だとし、倫理・セキュリティ・法令遵守を重視している。
2025年2月には、G42およびモハメド・ビン・ザーイド人工知能大学（MBZUAI）とともに「Responsible AI Future Foundation（RAIFF）」をアブダビに設立。中東およびグローバルサウス地域における責任あるAI開発の標準策定を進めている。</p>
<p>さらに、同年4月にはG42との間で「Intergovernmental Assurance Agreement（IGAA）」を締結。
米国・UAE両政府と協議を重ね、サイバー・物理的セキュリティ、輸出管理、データ保護、責任あるAI、KYCなどで米国基準を満たす枠組みを構築した。
Microsoftは「IGAAは2国間の信頼関係を強化するだけでなく、民間企業間でも政府水準のコンプライアンスを実現する初の枠組みだ」と説明している。</p>
<h2>地域連携と文化交流</h2>
<p>同社はシアトルから経済・教育・医療・非営利団体などのリーダーを含む代表団をアブダビに派遣し、地域交流を促進。
現地で開催された「Abu Dhabi Global AI Summit」では、G42、RAIFF、Eurasia Group GZERO Mediaなどと共催し、グローバルサウス諸国におけるAI普及と格差是正の必要性を訴えた。</p>
<h2>今後の展望</h2>
<p>Microsoftは、UAEを中東のAI・クラウド拠点として位置づけ、今後4年間で追加79億ドルを投資する。
Smith氏はブログを次のように結んでいる。</p>
<p>「最も重要なのは、テクノロジーがどれほど他者を支援できるかということだ。私たちは株主への価値提供だけでなく、地域社会に新しい機会と成長をもたらす責任を負っている。」</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity、AI特許検索エージェント「Perplexity Patents」を発表──自然言語で特許・技術情報を横断検索</title>
      <link>https://ledge.ai/articles/perplexity_patents_beta_launch_20251030</link>
      <description><![CDATA[<p>Perplexityは2025年10月30日（米国時間）、AIを活用した特許検索サービス「Perplexity Patents」を正式に<a href="https://www.perplexity.ai/ja/hub/blog/introducing-perplexity-patents">発表</a>した。</p>
<p>世界初の「AI特許研究エージェント」として、専門知識がなくても自然言語で特許文献を検索できる機能を備え、知的財産（IP）インテリジェンスへのアクセスを一般化することを目指すという。</p>
<h2>自然言語で特許を検索</h2>
<p>Perplexity Patentsは、自然言語で入力された質問に基づき、関連する特許を提示する検索エージェント。ユーザーは「Are there any patents on AI for language learning?（言語学習向けAIに関する特許はありますか？）」や「Key quantum computing patents since 2024?（2024年以降の主要な量子コンピューティング関連特許は？）」といった文章で検索できる。</p>
<p>AIが特許指向の質問を自動的に理解し、関連特許の一覧と出典を表示する。結果はインラインビューア上で閲覧でき、元の特許文書へのリンクも含まれる。会話形式のインターフェースを採用し、追加質問や比較も継続的に行える。関連するトピックの提案も表示される。</p>
<h2>特徴と仕組み</h2>
<p>Perplexity Patentsは、従来のキーワード一致検索では検出できない先行技術を抽出できる。
例えば「fitness trackers」で検索した場合、「activity bands」「step-counting watches」「health monitoring wearables」などの語を含む特許も提示される。</p>
<p>同社によれば、バックエンドでは特許専用の知識インデックスを活用し、AIリサーチエージェントが複雑なクエリを情報検索タスクに分解して処理する。これにより、数十から数百件の関連文書を参照した回答が生成される。</p>
<h2>検索対象の拡張</h2>
<p>Perplexity Patentsは、特許文献に加えて、学術論文、ソフトウェアリポジトリ、ブログ、動画など、特許以外の技術情報も検索対象に含める。同社は「新しい発明や技術は、特許の枠にとどまらない形で現れることがある」としている。</p>
<h2>提供開始と利用条件</h2>
<p>サービスはベータ版として全世界で提供を開始した。
ベータ期間中は無料で利用でき、ProおよびMaxプランのユーザーは追加の使用クォータやモデル設定オプションを利用可能。</p>
<p>公式ブログで同社は「特許は人類の創意と探究心の記録であり、Perplexity Patentsはその知識に迅速にアクセスできる手段を提供する」と述べている。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>KDDI×ローソン、「ローソン S」高輪本社店でAI×ロボット実証　11月8日開始</title>
      <link>https://ledge.ai/articles/lawson_kddi_vla_ai_robot_store</link>
      <description><![CDATA[<p>KDDI株式会社と株式会社ローソンは2025年10月28日、AI技術とロボットを組み合わせた店舗デジタル化の実証を、11月8日から「ローソン S KDDI高輪本社店」（東京都港区）で開始すると<a href="https://www.lawson.co.jp/company/news/detail/1512018_2504.html">発表</a>した。両社が共同で実施し、小売店舗の省人化や業務効率化を目的としている。</p>
<h2>欠品検知と品出しを自動化</h2>
<p>実証では、自律走行ロボットが店内を巡回し、4Kカメラで棚の画像を撮影。AIが画像を解析してプライスカードやパッケージを認識し、商品名や棚割り、在庫状況を自動で把握する。これにより、欠品を検知し、従来手作業で行っていた確認作業の効率化を図る。</p>
<p>さらに、バックルームの在庫情報をもとに、品出し業務の自動化や、店舗内の人流データと連携した「最適な棚割り」提案なども検証する。AIとロボットを組み合わせることで、店舗運営の現場データを活用したリアルタイムな改善サイクルの構築を目指す。</p>
<p>@<a href="https://www.youtube.com/watch?v=SMC7FnhtTy4&amp;t=1s">YouTube</a></p>
<h2>「Virtual Logistics Assistant（VLA）」を活用</h2>
<p>今回の実証には、KDDIが開発した次世代デジタル基盤「Virtual Logistics Assistant（VLA）」を活用する。
VLAは、実空間と仮想空間をデジタルツインで連携させ、店舗や倉庫のオペレーションを仮想上で再現・最適化する仕組みである。
ロボットが収集した画像や人流データをVLAに集約し、AIが解析することで、欠品の検知や補充タイミングを自動で可視化。データドリブンな店舗運営の基盤として機能する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kddi_lawson_vla_c009912b1c/kddi_lawson_vla_c009912b1c.jpg" alt="kddi lawson vla.jpg" /></p>
<p>今回の実証は、KDDIとローソンが共同で進める「Real×Tech LAWSON」プロジェクトの一環で、現実店舗にテクノロジーを実装し、顧客体験と業務効率の両立を検証する取り組みとなる。両社は今後、実証結果をもとに他店舗への展開も検討するとしている。</p>
<p>なお、本取り組みはKDDIが開催する「KDDI SUMMIT 2025」でも紹介される予定。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“科学発見の未来の味見”──OpenAIのBrockman氏、GPT-5 Proが12分で導出した治療仮説が未公表論文と一致　食物アレルギーに既存薬の効果を提案</title>
      <link>https://ledge.ai/articles/gpt5_pro_dupilumab_fpies_case_jaci_global</link>
      <description><![CDATA[<p>OpenAIの共同創業者で社長のGreg Brockman氏は2025年10月31日、自身のX（旧Twitter）で「GPT-5 Proが12分の思考で、治療不可能とされていた食物アレルギーに既存薬を提案し、未公表だった査読論文と同じ結論に達した」と<a href="https://x.com/gdb/status/1985057569392709644">投稿</a>した。</p>
<p>この事例が指すのは、dupilumab（デュピルマブ）による食物タンパク質誘発性腸炎症候群（FPIES：Food Protein–Induced Enterocolitis Syndrome）の症例報告だ。AIが独立に導いた仮説が、同日に公開されたJACI Global（Journal of Allergy and Clinical Immunology: Global）誌の症例シリーズと一致したという。</p>
<h2>Brockman氏「科学発見の未来の味見」</h2>
<p>Brockman氏はこの事例の投稿を引用し「Taste of what LLM-driven scientific discovery will be like（LLMによる科学的発見の未来の味見）」と表現。GPT-5 Proが提示した仮説が、当時未公表だった査読研究の結果と一致したと述べ、AIによる科学的洞察の萌芽として紹介した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/brockman_x_gpt5_scientific_discovery_fe45f963b2/brockman_x_gpt5_scientific_discovery_fe45f963b2.jpg" alt="brockman x gpt5 scientific discovery.jpg" /></p>
<h2>JACI Globalが報告──dupilumabでFPIESが寛解</h2>
<p>2025年10月29日付でJACI Globalに掲載された<a href="https://www.jaci-global.org/article/S2772-8293(25)00193-6/fulltext">論文</a>では、成人の小麦誘発FPIES患者に対し、dupilumab投与中に小麦摂取後も発作が起きず、経口負荷試験（約50gの小麦たんぱく）でも無反応となった経緯を報告。治療中断で症状が再燃し、再開で再び耐性が回復するなど可逆的な効果も確認された。研究チームは2〜58歳の7例を追加し、観察的ではあるもののdupilumabの有効性を示唆した。</p>
<h2>GPT-5 Proが独立に導出──「12分の思考」でdupilumabを第一推奨</h2>
<p>この症例を担当したOral Alpan医師の同僚、Derya Unutmaz医師（米ジャクソン研究所）は、論文投稿直前にGPT-5 Proへ臨床ケースを入力。モデルは約12分間の思考を経て、dupilumab（IL-4Rα阻害薬）を第一候補として提案したという。Unutmaz医師はX上で「他のどのモデルもdupilumabを第一選択として示さなかった」と述べ、出力画面のスクリーンショットを公開した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/derya_unutmaz_x_fa4ca8f5c0/derya_unutmaz_x_fa4ca8f5c0.jpg" alt="derya unutmaz x.jpg" /></p>
<p>論文では、dupilumabが樹状細胞OX40Lの抑制（“un-licensing”）を通じてType 2炎症経路を制御し、腸管上皮の過剰反応を抑制した可能性が示唆されている。現時点では仮説段階にあり、さらなる臨床試験が必要とされる。</p>
<p>研究者らは、今回の報告は因果関係を証明するものではなく、観察的症例シリーズにとどまることを強調。また、dupilumabはFPIESに対して未承認であり、治療の変更は必ず医師の管理下で行うべきと注意を促した。</p>
<h2>今後の展望──臨床試験への期待</h2>
<p>主治医のAlpan医師は、Regeneron（dupilumabの共同開発元）に臨床試験を打診する意向を表明。Unutmaz医師は「2万種を超える承認薬の中に、すでに“隠れた治療法”が存在するかもしれない」とし、GPT-5 Proのような高度なAIが既存薬の再利用（ドラッグ・リポジショニング）を加速させる可能性に期待を示した。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スタジオジブリや任天堂など加盟のCODA、OpenAIに要望書──動画生成AI「Sora 2」の無許諾学習に懸念</title>
      <link>https://ledge.ai/articles/coda_request_to_openai_sora2</link>
      <description><![CDATA[<p>一般社団法人コンテンツ海外流通促進機構（CODA）は2025年10月27日、動画生成AI「Sora 2」を開発・運用するOpenAI, L.L.C.に対して<a href="https://coda-cj.jp/news/2577/">要望書を提出</a>した。スタジオジブリや任天堂、東宝、集英社、講談社など、国内主要コンテンツ企業が加盟する同機構は、AIによる無許諾学習および著作権侵害の懸念を指摘している。</p>
<p>要望書ではOpenAIに対し、主に以下の2点を求めている。
1つ目は、CODA会員社のコンテンツを無許諾で学習対象としないこと。2つ目は、Sora 2の生成物に関して会員社から著作権侵害の申立てや相談があった場合、真摯に対応すること。同機構は、AI企業が透明性と説明責任を果たし、権利者の利益を尊重するよう求めた。</p>
<p>Sora 2は、テキストから動画を生成できるOpenAIの次世代モデルで、実在のアニメ作品や映画、ゲームを連想させる映像も生成可能だとされる。SNS上では著名キャラクターや既存作品の表現を模倣した動画が多数投稿されており、著作権や肖像権の侵害につながるおそれが指摘されている。</p>
<p>CODAは、アニメ・ゲーム・映画・出版など100社以上の会員で構成され、海外での海賊版対策や知的財産保護を目的とする非営利団体。同機構は声明の中で、「生成AI時代においても、創作者の正当な権利が損なわれることがあってはならない」と強調している。</p>
<p>生成AIによる著作物利用をめぐっては、米国や欧州でも“オプトアウト方式”の是非をめぐる議論が続く。OpenAIを含む各社は、学習データセットの詳細を非公開としており、透明性や権利処理のあり方が国際的な課題となっている。日本でも、著作権法第30条の4（学習利用）の適用範囲をめぐる議論が高まりつつある。</p>
<p>今後CODAは、国内外の権利者団体との連携を強化しつつ、OpenAIからの回答を注視するとしている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>1X、家庭用ヒューマノイド「NEO」を正式公開──月額499ドル（約7万5,000円）のサブスク開始で“家事お手伝いロボ”が現実に</title>
      <link>https://ledge.ai/articles/1x_neo_home_robot_subscription_launch</link>
      <description><![CDATA[<p>米1X Technologiesは2025年10月28日（米国時間）、家庭向けヒューマノイドロボット「NEO」を<a href="https://www.1x.tech/neo">公開</a>し、プレオーダーを開始した。提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。家庭内の掃除や片付けなど、日常的な家事を支援する“お手伝いロボット”として設計されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_6_ce91e1cf1e/x1neo_6_ce91e1cf1e.jpg" alt="x1neo-6.jpg" /></p>
<p>NEOは、1Xが掲げる「人の生活を支える安全なヒューマノイド」構想に基づき開発された。腱（tendon）駆動による柔らかく静かな動作を特徴とし、人と同じ空間で安全に動作できるよう設計されている。公式サイトでは「単調で時間のかかる家事を肩代わりし、人の時間を取り戻す」とコンセプトを掲げる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_5_7ae0e73c6c/x1neo_5_7ae0e73c6c.jpg" alt="x1neo-5.jpg" /></p>
<p>ユーザーはスマートフォンアプリや音声を通じてタスクを指示でき、NEOは家庭内の環境を学習しながら動作を最適化する。自己充電機能を備えるほか、遠隔からのモニタリングやサポートも可能。1XはNEOを単なるロボットではなく「温かみと個性をもった家庭のパートナー」と位置付けている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_4_dd13229413/x1neo_4_dd13229413.jpg" alt="x1neo-4.jpg" /></p>
<p>主な仕様は、バッテリー駆動時間約4時間（急速充電対応）、静音性は最大22dB。NVIDIA Jetson Thorをベースとした「1X Cortex」コンピューティングシステムを搭載し、360度集音マイクとステレオスピーカーを内蔵する。</p>
<h2>サブスク形式で家庭導入のハードルを下げる</h2>
<p>提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。NEOは注文ページからプレオーダー可能で、出荷は2026年を予定している。</p>
<p>1Xは公式ページ上で、NEOを「consumer-ready」と表現。2024年の試作版「NEO Beta」発表を経て、今回初めて一般消費者に向けたモデルとして公開された。</p>
<p>@<a href="https://www.youtube.com/watch?v=LTYMWadOW7c">YouTube</a></p>
<p>1X Technologiesは、家庭や産業向けのヒューマノイドロボットを開発する企業で、OpenAIが出資するスタートアップの一つでもある。これまでノルウェーを拠点としていたが、2025年には米カリフォルニア州サンフランシスコに本社を移転。研究開発と製造体制の両面で国際展開を進めている。サブスクリプション形式による提供で家庭でも導入しやすい価格体系を整えたNEOは、ヒューマノイドが日常生活に溶け込む時代の到来を感じさせる存在だ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米ルイビル大の研究者ら、AIが“人類の記憶係”になる時代に「記憶される権利」を提唱──少数のAIベンダーが何を記憶するかを実質的に決定するリスクを警告</title>
      <link>https://ledge.ai/articles/ai_right_to_be_remembered_digital_memory_risk</link>
      <description><![CDATA[<p>生成AIが人類の“記憶係”として機能し始める中で、情報の偏りや「記憶からの抹消」という新たなリスクが指摘されている。</p>
<p>米ルイビル大学などの研究者チーム（著者：Roman V. Yampolskiy／Alex Zhavoronkov／Dominika Wilczok）は2025年10月17日、論文「The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI」を arXiv で<a href="https://arxiv.org/abs/2510.16206">公開</a>した。大規模言語モデル（LLM）が情報取得の主要なインターフェースとなる現状に対し、著者らは「記憶される権利（Right to Be Remembered, RTBR）」を提唱している。</p>
<h2>単一回答がもたらす“記憶の収束”</h2>
<p>従来の検索エンジンは複数の情報源を一覧で提示し、利用者が比較・判断できる余地を残していた。一方、LLMは統合的な「ひとつの答え」を返す傾向があり、異なる視点を意識的に検討する機会を失わせやすい。この構造が進むと、少数のAIベンダーが「何が記憶され、何が忘れられるか」を実質的に決定することになり、デジタル社会における“記憶の偏り”が固定化する恐れがあると警告している。</p>
<h2>「記憶される権利（RTBR）」とは</h2>
<p>著者らは、AIが生成する情報の公正性と真実性を守る新たな倫理的枠組みとしてRTBRを提案した。RTBRは「AIによる情報の省略を最小化し、公正で、生成内容が可能な限り真実であることを設計原則として担保する」責務を意味する。その実現には、モデル開発・学習・出力・UI設計の各段階で、偏りを可視化し、引用や来歴を明示する仕組みが欠かせないとする。</p>
<h2>技術的・制度的課題にも言及</h2>
<p>論文は、AIの“真実性”を外部事実との整合性（accuracy）と、内部表現の整合性（honesty）の2層に分けて評価する重要性を指摘。その上で、以下のような具体策を挙げている。</p>
<ul>
<li>データ選定と来歴メタデータ（C2PAなど）の付与</li>
<li>RLHFや安全調整における多視点の保持</li>
<li>単一回答UIに代替視点・出典リンクを併設</li>
<li>不確実性の自己申告（知らないときは答えない／曖昧さの表示）</li>
</ul>
<p>また、C2PAなどのメタデータ標準を参照し、生成物に情報源を階層的に紐づける設計を推奨している。法制度面では、欧州の「忘れられる権利」（GDPR第17条）との緊張関係も論じられている。RTBR（公共の記憶の保存）と「忘れられる権利」（個人の消去請求）はしばしば対立し、LLMが知識を内部パラメータに埋め込む構造上、完全なアンラーニング（忘却）は難しいと指摘する。</p>
<h2>公共の「記憶」をどう設計するか</h2>
<p>研究者らは結論として、AIが知識の窓口となる時代において、モデルの設計や運用が人類の集合的記憶の形を左右する可能性を強調した。RTBRは、AIがもたらす効率性の裏側で、忘却や偏りから人間の歴史と多様な声を守るための新しい規範として位置づけられる。
論文は「AIが“人類の記憶係”になる時代にこそ、何を残し、何を忘れないかを社会全体で考える必要がある」と結ばれている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTの“当たり障りないフィルター”を外すと、応答が一段と鋭くなった──米国で話題の「辛口プロンプト」現象</title>
      <link>https://ledge.ai/articles/chatgpt_ii_hito_filter_prompt_trend</link>
      <description><![CDATA[<p>ChatGPTの「当たり障りのない」応答に物足りなさを感じた海外ユーザーが、あえて“当たり障りないフィルター”を外すプロンプトを公開し、話題を集めている。Redditで拡散したこの手法は、ChatGPTのトーンを「共感的な聞き役」から「論理的で辛口な批評家」へと変えるもので、SNSでは「回答の質が上がった」との声も相次いだ。</p>
<h2>Reddit発の「辛口プロンプト」が反響呼ぶ</h2>
<p>発端となったのは、Redditユーザー Wasabi_Open 氏が投稿した「I made ChatGPT stop being nice and it’s the best thing I’ve ever done（ChatGPTに“いい人”をやめさせたら、最高の結果になった）」という<a href="https://www.reddit.com/r/PromptEngineering/comments/1okppqe/i_made_chatgpt_stop_being_nice_and_its_the_best/">スレッド</a>だ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/I_made_Chat_GPT_stop_being_nice_375797ac64/I_made_Chat_GPT_stop_being_nice_375797ac64.jpg" alt="I made ChatGPT stop being nice.jpg" /></p>
<p>同氏はプロンプトの中で、ChatGPTに対し「私の意見を褒めたり慰めたりせず、誤りがあれば明確に指摘してほしい」「論理の矛盾を批判的に分析してほしい」と指示。これにより、ChatGPTが従来よりも率直で的確なフィードバックを返すようになったという。
この投稿は数千件のいいねを集め、「まるで冷静なメンターと議論しているようだ」とのコメントも寄せられた。</p>
<h2>SNSで広がった「nice filter」論争</h2>
<p>この現象を11月3日に<a href="https://x.com/markgadala/status/1985032100672618588">紹介</a>したのが、X（旧Twitter）のユーザー Mark Gadala 氏だ。同氏は「“nice filter”を外したらChatGPTの回答が劇的に改善した」と投稿し、多くのフォロワーが同様のプロンプトを試したと報告している。一方で、「フィルターを解除すると性能が上がる」という表現が拡散したことで、「内部制限を外す行為ではないか」との誤解も広がった。実際には、ChatGPTの内部に“nice filter”と呼ばれる設定は存在せず、プロンプトの指示文によって出力トーンが変わるだけだ。</p>
<h2>「当たり障りないフィルター」の正体</h2>
<p>OpenAIの設計方針によれば、ChatGPTは安全性と中立性を重視した“共感的”な初期設定を採用している。ユーザーが感じる「いい人フィルター」とは、この丁寧でポジティブに応答する傾向を指した比喩に過ぎない。つまり、「フィルターを外す」とは内部機能を解除するのではなく、プロンプトによってAIの口調や態度を再設定する行為だといえる。</p>
<h2>“辛口AI”の効用と注意点</h2>
<p>ユーザーの反応はおおむね好意的だ。「率直な批評を受けることで思考が整理された」「甘い同意よりも鋭い反論のほうが学びになる」といった意見が目立つ。一方で、「冷たく感じる」「会話がきつくなる」との声もあり、タスクや気分に応じてトーンを使い分ける重要性が指摘されている。専門家の間では、このようなトーン調整を「AIとの協働スキル」や「プロンプトリテラシー」の一環とみなす動きも広がっている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、生成AI「Claude」をExcelに統合──分析・説明・編集を自動化する新アドインを発表</title>
      <link>https://ledge.ai/articles/claude_for_excel_beta_release</link>
      <description><![CDATA[<p>Anthropicは2025年10月28日（米国時間）、生成AI「Claude」をMicrosoft Excelに統合した新アドイン「Claude for Excel」をベータ版（Research Preview）として<a href="https://www.anthropic.com/news/advancing-claude-for-financial-servicesl">公開</a>した。
Claudeがスプレッドシート内のデータや数式を理解し、自然言語による分析・説明・編集を行えるようにする。</p>
<p>「<a href="https://www.claude.com/claude-for-excel">Claude for Excel</a>」はExcelのサイドバー上で動作し、ユーザーが自然言語で入力した指示に応じて、ワークシート全体を参照しながら回答する。数式の意味や依存関係を自動的に解析し、関連セルをハイライト表示することで、データの構造を可視化できる。例えば「この列の傾向を要約して」「この数式が何を計算しているか説明して」といった指示に対して、Claudeが表形式で結果を提示する。</p>
<p>@<a href="https://www.youtube.com/watch?v=NcBnxbEC0Ng">YouTube</a></p>
<p><strong>Excelのワークシートを解析し、セルレベルの参照付きで説明するClaudeの画面例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/How_teams_use_Claude_for_Excel_fa57735bf8/How_teams_use_Claude_for_Excel_fa57735bf8.jpg" alt="How teams use Claude for Excel.jpg" /></p>
<p>Anthropicによると、この機能は「財務分析やデータレポート作成など、業務での活用を想定した設計」であり、企業利用者を中心に展開されている。現在は「Claude for Max」「Claude for Team」「Claude for Enterprise」プランのユーザーを対象に、ウェイトリスト方式による限定ベータ（リサーチプレビュー）として提供中だ。</p>
<p>同社は公式ブログで、金融サービス分野をはじめとするビジネス用途において、Claudeの統合を進めていく方針を示している。今後、Excel以外の業務アプリケーションやリアルタイムデータとの連携も視野に入れ、企業の分析・意思決定プロセスをAIで支援するエコシステムの構築を目指すという。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、広告画像を自動生成する新ツール「Pomelli」を発表──ブランドの“DNA”をAIが理解し、一貫したキャンペーンを提案</title>
      <link>https://ledge.ai/articles/google_pomelli_ai_ad_generation_tool</link>
      <description><![CDATA[<p>Googleは2025年10月28日（米国時間）、広告やSNSキャンペーン向けの画像を自動生成できる新ツール「Pomelli（ポメリ）」を<a href="https://blog.google/technology/google-labs/pomelli/">発表</a>した。Google Labsの実験プロジェクトとして公開されており、ユーザーが自社サイトのURLを入力すると、ブランド特性を分析して“Business DNA”を構築し、それに基づいて画像やコピーなどのアセットを提案する。</p>
<p>@<a href="https://www.youtube.com/watch?v=rsWPISYv6tQ">YouTube</a></p>
<h2>ブランドの「DNA」をAIが理解して広告素材を生成</h2>
<p>Pomelliは、企業サイトに含まれる色・言葉・トーンなどをAIが解析し、ブランドの「Business DNA」としてまとめる。この情報をもとに、SNS投稿用の画像、広告用コピー、キャンペーン案などを生成する仕組みだ。DeepMindとの協力のもと開発されたとされ、Googleは「ブランドの一貫性を保ちながら、より迅速にマーケティング素材を作成できる」としている。</p>
<p><strong>Pomelliは企業サイトを解析し、ブランドカラー・フォント・イメージを自動抽出して「Business DNA」を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39.webp" alt="Pomelli_Keyword_Blog_In-line_-_1.width-1000.format-webp.webp" /></p>
<h2>中小企業でも“オンブランド”の広告を短時間で</h2>
<p>Pomelliの想定ユーザーは、中小規模の企業（SMB）や個人事業主だ。デザイナーやマーケターが限られた環境でも、ブランドトーンを保った高品質な素材を数分で生成できる。SNSごとのフォーマットや文体に応じた最適化にも対応しており、季節キャンペーンやセールなどの展開を容易にする。</p>
<p><strong>解析したBusiness DNAをもとに、AIが複数のキャンペーン案を提示する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069.webp" alt="Pomelli_Keyword_Blog_In-line_-_2.width-1000.format-webp.webp" /></p>
<h2>生成された広告をその場で編集・修正可能</h2>
<p>生成された画像やコピーは、フォント・色・キャッチコピーなどをGUI上で細かく調整できる。Googleはこれを「人間の創造力を補助する共同作業ツール」と位置付けており、単なる自動生成ではなく、人の手による最終調整を想定している。</p>
<p><strong>生成された広告素材は、色やフォント、コピーをその場で編集できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f.webp" alt="Pomelli_Keyword_Blog_In-line_-_3.width-1000.format-webp.webp" /></p>
<h2>提供形態と今後の展開</h2>
<p>PomelliはGoogle Labsの実験ツールとして提供されており、現在は限定公開の段階にある。公式サイトでは「Easily generate on-brand content for your business（自社ブランドに沿ったコンテンツを簡単に生成）」と説明されている。</p>
<p>現時点で提供対象は米国、カナダ、オーストラリア、ニュージーランドの英語版ユーザーに限られており、日本国内では未提供。Googleは今後の地域拡大について明らかにしていないが、利用可能国の追加が期待される。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、誰でも学べるAI学習サイト「Google Skills」を正式公開──Cloud・DeepMind・教育部門を横断する3000講座を展開</title>
      <link>https://ledge.ai/articles/google_skills_ai_learning_platform_launch</link>
      <description><![CDATA[<p>Googleは2025年10月21日（米国時間）、新しいAI学習プラットフォーム「Google Skills」を<a href="https://blog.google/outreach-initiatives/education/google-skills/">発表</a>した。同サイトでは、Google Cloud、Google DeepMind、Grow with Google、Google for Educationなど、同社の複数部門が提供してきた教育コンテンツを統合。3000種類を超えるAI関連の講座・体験ラボ・認定プログラムを、一元的に学べる学習拠点として開設された。</p>
<h2>AI教育の中核を担う新サイト</h2>
<p>Google公式ブログ「Start learning all things AI on the new Google Skills」によると、Google Skillsは“AI for Everyone（すべての人のためのAI）”をテーマに、誰もがAIスキルを体系的に学べるよう設計されている。初心者、エンジニア、企業リーダーなど幅広い層を対象に、AI、データ分析、クラウド、生成AIなど多様な分野を網羅。各コースはオンデマンド形式で受講でき、学習成果はLinkedInなどの外部プラットフォームで共有できる。提供内容には、Google Cloudの認定資格プログラムやAI Essentials シリーズ、DeepMindのAI倫理教材などが含まれる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Qbix0BOPcgE">YouTube</a></p>
<p>今回の正式公開に先立ち、Google Cloudは10月10日付のブログ「Google Skills: Your new home for Google AI learning and more」で、新プラットフォームの構想を公表していた。当時は正式リリース前で、「AIやクラウドに関する学習リソースを一元化し、近日中に詳細を発表する」としていた。Gemini Code Assist（旧Duet AI for Developers）やQwiklabs（現Cloud Labs）と連携し、AIトレーニングの実践環境を統合する方針も示されていた。</p>
<h2>3000超のコースと実践的ラボを集約</h2>
<p>Google Skillsでは、Googleがこれまで個別に展開してきた学習リソースを一か所に集約。AIモデル開発、クラウド基盤運用、データ可視化、サイバーセキュリティなど、実践重視の3000超のコースとラボを提供する。一部コンテンツは無料で公開され、修了証や認定資格を取得することでキャリア開発にもつなげられる。また、組織向けにはチーム単位での進捗管理や学習成果の可視化機能も用意されている。</p>
<h2>今後の展望──教育機関・企業研修にも拡大へ</h2>
<p>Googleは今後、教育機関や企業研修への展開を進める方針を示しており、AIスキルの標準教育基盤としての活用を目指す。
公式ブログでは、「AI教育へのアクセスを民主化し、誰もがテクノロジーの未来を形づくる機会を得られるようにする」としている。
同社は今後もDeepMindやCloud AIチームの最新教材を追加し、AI人材育成をグローバルに推進する考えだ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>万博「null²」館で使用の3Dアバター技術、筑波大が一般公開──スマホスキャン後約5分で完成</title>
      <link>https://ledge.ai/articles/instant_skinned_gaussian_avatars_tsukuba_null2</link>
      <description><![CDATA[<p>筑波大学・落合陽一准教授が率いるデジタルネイチャー研究室（Digital Nature Group）は、スマートフォンで撮影した3Dスキャンデータから約5分で写実的な3Dアバターを生成できる技術「Instant Skinned Gaussian Avatars」を<a href="https://gaussian-vrm.github.io/">発表</a>した。</p>
<p>研究成果は論文「Instant Skinned Gaussian Avatars for Web, Mobile and VR Applications」として公開され、2025年11月にカナダ・モントリオールで開催される ACM Symposium on Spatial User Interaction (SUI ’25) で<a href="https://dl.acm.org/doi/10.1145/3694907.3765954">発表予定</a>となっている。
この技術は、大阪・関西万博の落合館「null²（ヌルヌル）」で展示された3Dアバター生成システムに採用されており、研究チームは10月22日、<a href="https://naruya.github.io/gaussian-vrm/">デモサイト</a>と<a href="https://github.com/naruya/gaussian-vrm">ソースコード</a>を一般公開した。</p>
<h2>スマホだけで完結するアバター生成プロセス</h2>
<p>研究は、筑波大学大学院図書館情報メディア研究科の近藤生也氏、浅野悠人氏、落合陽一氏によって実施された。
ユーザーはスマートフォンアプリ「Scaniverse」でAポーズの全身スキャンを行い、3Dデータ（PLY形式）を取得する。そのデータをブラウザ上のアプリケーションにアップロードすると、自動的に処理が実行され、約30秒でアバター生成が完了する。全体の所要時間は約5分と報告されている。生成されたアバターはWebブラウザ上で動作し、スマートフォンでも確認できる。</p>
<p>@<a href="https://www.youtube.com/watch?v=tinmbjfghLw">YouTube</a></p>
<h2>Gaussian Splattingとスキンメッシュの融合</h2>
<p>提案手法は、3D表現技術「Gaussian Splatting」をベースに、スキンメッシュ構造と統合することで、写実的な質感とアニメーションの軽量性を両立している。
各スプラット（点群）は背景メッシュのボーン構造にバインドされ、動作中はリアルタイムで位置と姿勢を並列更新する仕組みを採用。モバイル環境での処理負荷を抑えるため、ボーン単位でスプラットをグループ化し、視点依存のソーティング処理を最適化している。</p>
<p>@<a href="https://www.youtube.com/watch?v=i2GvFIMYqP0">YouTube</a></p>
<h2>Webベース設計によるクロスプラットフォーム対応</h2>
<p>システムは、JavaScriptおよびThree.jsで構築されており、特別なアプリケーションを必要とせずWebブラウザ上で動作する。
ユーザーはスマートフォン、PC、VRヘッドセットなど、プラットフォームを問わず利用できる。
これにより、生成・表示環境が限定されず、学習や展示、遠隔通信など多様な応用が可能となる。</p>
<h2>実行性能と公開リソース</h2>
<p>実験では、iPhone 13 Proで40〜50 fps、NVIDIA GeForce RTX 3060搭載ノートPCで最大240 fpsの動作を確認した。
デモは <a href="https://naruya.github.io/gaussian-vrm/">https://gaussian-vrm.github.io</a>、ソースコードは<a href="https://github.com/naruya/gaussian-vrm">https://github.com/naruya/gaussian-vrm</a> で公開されている。</p>
<h2>今後の展開</h2>
<p>論文では、VRMなど既存アバター規格との互換性を考慮した設計であることが示されている。
研究チームは、顔表情や衣服変形などへの拡張を今後の課題として挙げている。研究成果は、誰もが汎用デバイスを用いて高品質な3Dアバターを生成できる手法として、Web、モバイル、VRアプリケーションなど複数領域への応用が見込まれている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>講談社・KADOKAWAなど19団体、「オプトアウト原則は侵害につながる」と共同声明──生成AI時代の創作と権利のあり方を提示</title>
      <link>https://ledge.ai/articles/joint_statement_ai_creative_rights_20251031</link>
      <description><![CDATA[<p>2025年10月31日、講談社やKADOKAWAをはじめとする出版社17社と、日本漫画家協会、日本動画協会の計19団体は、「生成AI時代の創作と権利のあり方に関する共同声明」を<a href="https://nihonmangakakyokai.or.jp/archives/news/20251031">発表</a>した。</p>
<p>声明は、OpenAIの映像生成AI「Sora2」によって既存作品への依拠や類似が疑われる事例が確認されたことを背景に、著作権法の原則に基づく3つの原則を提示。「オプトアウト原則は権利侵害につながる」と明記し、AI事業者に対して法的原則の順守を求めた。</p>
<h2>「Sora2」公開が引き金に</h2>
<p>声明では、2025年10月にOpenAIが映像生成AI「Sora2」をローンチし、その生成物がSNSなどで共有された際、既存の著名なアニメや漫画の表現に類似する事例が散見されたと指摘している。
同AIが「権利者から明示的なオプトアウト申請がない限り生成・公開が可能な仕組み」を採用している点について、「我が国の著作権法およびWIPO著作権条約の原則に反する」と明記した。</p>
<p>OpenAIの経営者個人がSNS上で「オプトイン方式への転換」を示唆したものの、企業としての正式方針ではないとし、「第二、第三のSora2」とも言うべき新たな生成AIの登場を見据え、業界として立場を明確にする必要があると判断したという。</p>
<h2>「創作の喜び」と「権利保護」の両立を掲げる</h2>
<p>声明は「生成AI技術の進展を歓迎する」としつつ、「著作権侵害を容認しない」という原則を改めて確認。
文化的創造の持続可能性と技術革新の恩恵を両立させるため、AI事業者に対して次の3つの原則を示した。</p>
<ul>
<li>学習段階および生成・公表段階の両方において、権利者に必要な許諾を得るなど著作権法の原則に沿った対応を取ること</li>
<li>学習データの透明性を担保すること</li>
<li>権利者が利用を許諾した場合、適正な対価還元を行うこと</li>
</ul>
<p>さらに、生成AIの利用者が他者の著作物をもとにしたことを知らずに作品を公開し、結果として他のクリエイターの権利を損なう状況を防ぐため、権利者・AI事業者・関係省庁の連携を呼びかけている。</p>
<h2>「オプトアウト原則は侵害につながる」</h2>
<p>声明の中で特に強調されたのが、「オプトアウト原則」への懸念だ。
AI事業者が権利者に無断で著作物を学習・再利用することは、「著作権法の『権利者の許諾を得てから利用する』という原則に反する行為」であり、権利侵害に直結すると明記。その上で「AI事業者が権利者に対してオプトインを申請し、使用許諾を得ることの徹底」を求めている。</p>
<p>また、学習データの出典が不明確なままでは、権利侵害の検証や作品評価の毀損対応が困難になるとして、データ透明性の担保を「不可欠」と位置づけた。</p>
<h2>「技術を拒絶するものではない」</h2>
<p>声明は、生成AIを排除するものではないと明言する。
「創作に携わるすべての人の努力と尊厳を守るための責任」と位置づけ、法的・倫理的観点から著作権侵害に適切に対応する姿勢を表明した。同時に、「クリエイターとユーザーの双方が安心して創作・利用できる環境を整えることを重視する」と記した。</p>
<h2>今後の方向性──「利用と保護の両立」を模索</h2>
<p>声明は締めくくりとして、「AI時代における公正で透明、かつ持続可能な創作環境の構築・維持に努める」と明示。
業界内外のステークホルダーとの協調を通じて、創作物の「利用と保護」の両立を目指す姿勢を示した。</p>
<h3>発出団体（五十音順）</h3>
<p>一般社団法人 日本動画協会／公益社団法人 日本漫画家協会／株式会社秋田書店／株式会社一迅社／株式会社宙出版／株式会社KADOKAWA／株式会社コアミックス／株式会社講談社／株式会社小学館／株式会社少年画報社／株式会社新潮社／株式会社スクウェア・エニックス／株式会社竹書房／株式会社TOブックス／株式会社日本文芸社／株式会社白泉社／株式会社双葉社／株式会社芳文社／株式会社リイド社</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとAWS、7年・380億ドルの戦略的提携を発表──数十万GPUとUltraServersでAI基盤を拡充</title>
      <link>https://ledge.ai/articles/openai_aws_multi_year_partnership_2025</link>
      <description><![CDATA[<p>2025年11月3日（現地時間）、OpenAIとAmazon傘下のAmazon Web Services（AWS）は、複数年にわたる戦略的パートナーシップを締結したと<a href="https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure">発表</a>した。</p>
<p>OpenAIは発表当日からAWS上で主要AIワークロードの稼働を開始しており、契約総額は今後7年間で380億ドル（約5.8兆円）にのぼる。数十万規模のNVIDIAチップを備えたUltraServersを活用し、AIトレーニングと推論の両面で大規模な計算基盤を構築する。</p>
<h2>OpenAIのAIワークロードをAWSで稼働</h2>
<p>今回の提携により、OpenAIはAWSのインフラを活用してChatGPTをはじめとする主要サービスや次世代モデルのトレーニングを実行する。AWSは「immediate availability（即時利用可能）」を強調し、提携発表と同時にOpenAIのワークロードを稼働させたと説明している。</p>
<p>契約期間は7年間で、OpenAIはAWS上に総額380億ドル規模のコンピューティング・キャパシティを確保。2026年末までに全リソースを配備することを目標とし、状況に応じて2027年以降の拡張も検討されている。</p>
<h2>GB200/GB300世代GPUとUltraServersを採用</h2>
<p>AWSは、最新のNVIDIA GB200およびGB300世代チップを搭載した「Amazon EC2 UltraServers」を提供。これにより、OpenAIは数十万規模のNVIDIAチップと数千万CPUを同一ネットワーク上で動作させ、AI学習や推論を高効率に処理できる。</p>
<p><strong>AWSのデータセンター外観。今後数十万規模のGPUクラスタを展開予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_71f1f7cec4/2_71f1f7cec4.jpg" alt="ダウンロード (2).jpg" /></p>
<p>クラスタは低レイテンシの相互接続を備え、複数データセンターを単一の高性能ファブリックとして動作させる設計。AWSはこれを「最適化された大規模AIワークロード環境」と位置づけている。</p>
<p><strong>AWSインフラ内部。UltraServers間を接続するネットワークケーブル群</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_17c982221d/7_17c982221d.jpg" alt="ダウンロード (7).jpg" /></p>
<p>OpenAI CEOのサム・アルトマン氏は「フロンティアAIを安全にスケーリングするためには、massive, reliable computeが不可欠だ」と述べ、今回の提携が「advanced AI to everyone（すべての人に先進的AIを届ける）」基盤となると語った。AWS CEOのマット・ガーマン氏は「OpenAIの膨大なワークロードを支えるbest-in-class infrastructureを提供できることを誇りに思う」とコメントしている。</p>
<h2>今後の展開</h2>
<p>リリースでは、Amazon Bedrock上でOpenAIのオープンウェイト基盤モデルが利用可能になったことにも言及。すでにBystreet、Comscore、Peloton、Thomson Reuters、Triomics、Verana Healthなど数千社が導入を開始しているという。</p>
<p>AWSは、2026年末までに全キャパシティの配備を完了させる計画を示している。今回の契約により、OpenAIはAWS上でAIモデルのトレーニングおよび推論を長期的に実施できる環境を確保した。両社は今後もAIインフラの拡張と最適化を進め、安定した計算リソースの提供を継続する方針だ。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GitHub、「Agent HQ」を発表──“あらゆるエージェントを、いつでもどこでも”統合管理</title>
      <link>https://ledge.ai/articles/github_agent_hq_announcement_universe2025</link>
      <description><![CDATA[<p>GitHubは2025年10月28日（米国時間）、年次イベント「GitHub Universe 2025」で新ビジョン「Agent HQ」を<a href="https://github.blog/news-insights/company-news/welcome-home-agents/">発表</a>した。これは、複数のAIコーディングエージェントを単一の環境で呼び出し、管理・連携できる統合プラットフォームである。</p>
<p>公式ブログによると、Agent HQは“あらゆるエージェントを、あらゆる開発スタイルで使える”ことを目指した新構想で、Anthropic、OpenAI、Google、Cognition、xAIなど各社のエージェントを有料のGitHub Copilotサブスクリプションの一部として提供するという。提供開始は今後数カ月を予定。</p>
<p>@<a href="https://www.youtube.com/watch?v=KniyIrpTDE8&amp;t=5s">Youtube</a></p>
<h2>複数エージェントを一元管理する「Mission Control」</h2>
<p>Agent HQの中核機能として「Mission Control」が導入される。開発者が複数のエージェントをタスクごとに割り当て、進行状況を可視化できる中枢機能で、GitHub、Visual Studio Code、CLIなど複数の開発環境で同一の体験を提供する。</p>
<p>また、組織の管理者は各エージェントのアクセス権限や利用ポリシーを制御できる「コントロールプレーン」を通じて、企業やチーム単位でのガバナンスを強化できる仕組みも備える。</p>
<h2>サードパーティ連携を前提とした“開かれたHQ”</h2>
<p>Agent HQは、特定モデルに依存しない「オープンなエージェント基盤」として設計されている。
GitHubは「開発者は自分の選んだAIエージェントを同じワークフローで活用できる」と述べ、今後数か月で各社のエージェントを順次統合していく予定だ。</p>
<p>この発表は、GitHubが掲げる“開発者が中心にいる未来”という長期ビジョンの延長線上にあり、同社はCopilotを単なる補助ツールから、複数AIが協働する「開発の司令塔」へと進化させようとしている。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>