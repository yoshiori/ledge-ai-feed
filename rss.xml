<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>学術＆研究2025/8/23 [SAT]ByteDance、AI推論モデル「Seed-Prover」を数学オリンピックの結果とともに発表──公式には銀メダル相当、実際はGoogle、OpenAIに続き金メダル水準の成果</title>
      <link>https://ledge.ai/articles/ai_math_olympiad_seed_prover</link>
      <description><![CDATA[<p>中国ByteDanceの研究チームは2025年7月23日、AI推論モデル「Seed-Prover」を<a href="https://seed.bytedance.com/en/blog/bytedance-seed-prover-achieves-silver-medal-score-in-imo-2025">公開</a>した。同社公式ブログでは「Silver Medal Score（銀メダル相当）」と表現されたが、Seed-Proverが記録した30点は、2025年の国際数学オリンピック（IMO）における金メダルカットラインに到達するものであり、実質的に金メダル水準の成果といえる。詳細をまとめた論文は7月31日にarXivで<a href="https://arxiv.org/abs/2507.23726">公開</a>された。</p>
<p>Seed-Proverは、定理証明器「Lean」を基盤に構築された形式証明型AIモデルである。補題（レマ）のプールを生成・活用しながら段階的に証明を組み立て、各ステップを機械可読な形式で検証する仕組みにより、証明の厳密性を担保できる。論文では、過去IMOの形式化問題で78.1％の成功率を記録し、さらにMiniF2FやPutnamBenchといったベンチマークでも最新水準の成績を達成したことが示されている。</p>
<p><strong>MiniF2F-Testでの性能推移。Seed-Proverは2025年時点で最高水準の通過率を記録している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Mini_F2_F_d1294f309f/Mini_F2_F_d1294f309f.jpg" alt="MiniF2F.jpg" /></p>
<p>ByteDanceはSeed-Proverを「Silver Medal Score」と発表したが、実際には自動定理証明システムに位置づけられるものであり、LLMを活用して形式証明を構築する新しいタイプのアプローチである。従来の完全自動型とは異なり、大規模言語モデルによる柔軟な探索と、定理証明器による厳密な検証を組み合わせる点に特色がある。</p>
<p><strong>Seed-Proverの各種ベンチマーク成績（左）と従来モデル（右）の比較。IMO 2025、MiniF2F、PutnamBenchなどで従来を大幅に上回った</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4og2ymdfewdkk_0259ab7f69/4og2ymdfewdkk_0259ab7f69.jpeg" alt="4og2ymdfewdkk.jpeg" /></p>
<h2>金メダル水準の成果、それぞれのアプローチ</h2>
<p>2025年のIMOをめぐっては、GoogleやOpenAIも金メダル水準の成果を発表している。それぞれのアプローチには違いがある。</p>
<ul>
<li><strong>Google DeepMind（Gemini Deep Think）</strong> ：6問中5問を解答し、公式採点で35点を獲得。自然言語のみで証明を構築し、短時間で人間と同じ条件下で金メダル水準を達成した。</li>
<li><strong>OpenAI（実験モデル）</strong> ：同じく6問中5問を解き35点と発表。元IMOメダリストによる採点で妥当性が確認されたが、公式認定はない。自然言語ベースで幅広い問題に対応できる点を強みとする。</li>
<li><strong>ByteDance Seed-Prover</strong> ：公式ブログでは「Silver Medal Score」とされたが、30点は金メダルのカットラインに到達。Lean上で形式的に証明を構築し、機械検証可能な厳密な証明を生成する。大会3日間を通じて探索を行う方式で、時間は要するが厳密性を優先した設計だ。</li>
</ul>
<h2>今後の展望</h2>
<p>Seed-Proverは、自然言語で証明を生成する従来型モデルとは異なり、定理証明器によって機械的に検証可能な形式証明を構築する点に特徴がある。論文では、この厳密な証明構築は数学研究の支援や形式検証（formal verification）といった分野に応用できる可能性があると記されている。</p>
]]></description>
      <pubDate>Sat, 23 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>竹中工務店、建築設計AI「Tektome KnowledgeBuilder」を導入──設計業務の生産性向上と働き方改革を推進</title>
      <link>https://ledge.ai/articles/takenaka_koumuten_ai_design_solution</link>
      <description><![CDATA[<p>建築大手の竹中工務店は2025年8月18日、AIを活用した建築設計支援ソリューション「Tektome KnowledgeBuilder」を導入したことを<a href="https://prtimes.jp/main/html/rd/p/000000008.000136954.html">発表</a>した。開発元のテクトムが8月18日に発表したもので、設計業務における生産性向上や働き方改革を加速させる狙いがあるという。</p>
<p>「Tektome KnowledgeBuilder」は、建築設計業務で発生する膨大な図面や関連情報をAIで構造化し、検索・参照を容易にするソリューションである。これにより、従来は属人的に扱われていた設計ナレッジを効率的に活用できる環境を整え、設計プロセスの高度化と効率化を実現する。</p>
<p>竹中工務店では導入に先立ち、社内ワーキンググループによる約3カ月間の実証実験を実施。実務に即した利用環境の整備を進めた結果、設計者が過去の事例を効果的に参照し、業務負担を軽減できることが確認されたという。</p>
<p>テクトムは今回の取り組みについて、「設計DXの推進を通じ、建築業界全体の生産性革新や働き方改革に貢献していく」としている。今後は竹中工務店での活用事例をもとに、他の建築事業者への展開も視野に入れている。</p>
]]></description>
      <pubDate>Fri, 22 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アリババ、画像編集AI「Qwen-Image-Edit」を発表──生成AI「Qwen-Image」を拡張し、元の見た目を保持したまま多様な編集が可能に</title>
      <link>https://ledge.ai/articles/qwen_image_edit_release</link>
      <description><![CDATA[<p>中国アリババのAI研究チーム「Qwen Team」は2025年8月19日、画像生成AI「Qwen-Image」を拡張し、画像編集に特化した新モデル「Qwen-Image-Edit」を<a href="https://qwenlm.github.io/blog/qwen-image-edit/">発表</a>した。従来の画像生成に加え、キャラクターやスタイルの一貫性を維持しながら異なる情景を描写したり、画像内テキストを正確に編集するなど、高度な編集機能を備えている。</p>
<h2>技術的特徴</h2>
<p>20Bパラメータを持つ「Qwen-Image」を基盤として開発されたQwen-Image-Editの最大の特徴は「デュアルパス設計」にあるという。
Qwen2.5-VLが担うセマンティック制御と、VAEによる外観保持を組み合わせ、MMDiTによって統合することで、意味情報と見た目の情報を同時にバランスよく扱うことを可能にした。これにより、従来の生成モデルよりも自然で一貫性のある編集が可能になった。</p>
<p>編集機能としては、スタイルを変更したり、視点を切り替えたり、既存キャラクターを使って新しいシーンを描く「意味編集」、背景の置換や髪の毛一本の修正といった細部を調整する「外観編集」、さらに中国語や英語のテキストをフォントやスタイルを崩さずに編集できる「精密テキスト編集」がある。また、ユーザーが指定した領域を何度も重ねて修正できる「多段編集」にも対応しているとのこと。</p>
<h2>公開と利用方法</h2>
<p>同モデルはApache 2.0ライセンスでオープンソースとして公開されており、Qwen Chat、Hugging Face、ModelScope、GitHub、Alibaba Cloud APIを通じて利用可能となっている。開発者や企業はこれらのプラットフォームを通じて簡単にアクセスできる点も特徴だ。</p>
<h2>Showcase事例</h2>
<p>公式ブログでは、Qwen-Image-Editの機能を示す多彩なデモ画像が紹介されている。</p>
<p><strong>キャラクターの見た目を保ったまま、画家や宇宙飛行士など多彩なシーンへ展開</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_73f8c636ae/3_73f8c636ae.jpg" alt="幻灯片3.jpg" /></p>
<p><strong>フォントやスタイルを維持しながら、英語や中国語のテキストを自然に差し替え</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/15_41b5f50bea/15_41b5f50bea.jpg" alt="幻灯片15.jpg" /></p>
<p><strong>古い書道作品の誤字を自然に修正し、文化保存にも活用可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/18_df7ae341ca/18_df7ae341ca.jpg" alt="幻灯片18.jpg" /></p>
<h2>応用分野</h2>
<p>この技術の応用範囲は広い。広告やコンテンツ制作の現場では、短時間で多様なデザインを展開でき、アバターやイラストのスタイル変換にも活用できる。また、日常写真の背景変更や人物修正など一般ユーザー向けの用途も考えられる。さらに、書道作品の補正や保存といった文化的分野にも寄与する可能性がある。</p>
<p>アリババは今回の発表を通じ、生成AIと編集AIを組み合わせた新たなソリューションを提示した。これにより、画像処理の柔軟性と実用性を高め、市場における存在感を一層強めることを狙っている。</p>
]]></description>
      <pubDate>Fri, 22 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>オンデーズ、生成AIが“かけたまま試着”を実現　新提案サービス「OWNDAYS MIRROR」を展開</title>
      <link>https://ledge.ai/articles/owndays_mirror_ai_try_on_without_removing_glasses</link>
      <description><![CDATA[<p>メガネ・サングラスの製造販売を手掛けるオンデーズ（東京都品川区）は2025年8月19日、生成AIを活用した新サービス「OWNDAYS MIRROR（オンデーズ ミラー）」を<a href="https://www.owndays.com/jp/ja/information/822">発表</a>した。</p>
<p>AIが顔立ちや雰囲気を分析し、メガネをかけたままでも試着できる体験を提供するのが特徴だ。</p>
<h2>生成AIによる“かけたまま試着”とレコメンド</h2>
<p>OWNDAYS MIRRORでは、カメラに映した顔画像をもとに生成AIが最適なフレームを提案。現在かけているメガネを画像上で仮想的に外し、新しいフレームをリアルタイムで合成表示することで、視力が弱いユーザーでも違和感なく比較検討できる。</p>
<p><strong>AIが候補フレームを提示し、装着イメージを“かけたまま”で確認可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo03_2_91fec602d9/photo03_2_91fec602d9.jpg" alt="photo03-2.jpg" /></p>
<h2>“なりたい印象”を8タイプから選択</h2>
<p>ユーザーは「カジュアル」「フォーマル」「クール」「ソフト」「シンプル」「グラマラス」「モダン」「クラシック」の8種類の印象から“なりたい印象”を選択。AIが選択に応じて似合い度や印象コメントを提示し、候補フレームを絞り込む。</p>
<p><strong>“なりたい印象”を選ぶ画面。8タイプから選ぶとAIが候補を最適化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo03_1_c103e87778/photo03_1_c103e87778.jpg" alt="photo03-1.jpg" /></p>
<p>気に入ったフレームはそのまま店頭在庫を確認でき、実物の試着・購入に進める。価格や在庫数、同系統の別カラーなども画面上で確認できる。</p>
<p><strong>候補フレームの詳細画面。価格・在庫・カラーバリエーションも同時に確認</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo01_1d02f996d4/photo01_1d02f996d4.jpg" alt="photo01.jpg" /></p>
<h2>店舗導入とスケジュール</h2>
<p>新サービスは8月20日にオープンする「OWNDAYS天王洲アイル店」をはじめ、全国11店舗に導入される。2026年3月末までに国内全店舗、さらに海外店舗にも順次展開する予定だ。</p>
<p>天王洲アイル店はDX推進モデル店舗に位置づけられており、リモート視力測定やRFIDを活用した商品管理、キャッシュレスセルフレジなどの最新設備を導入。OWNDAYS MIRRORはその目玉機能として位置づけられている。</p>
<h2>今後の展開</h2>
<p>同社によると「似合うメガネがわからない」「基準がない」「視力の悪さで印象が掴めない」といった顧客の声がサービス開発のきっかけになったという。混雑時でも自分のペースで納得して選べる新しい顧客体験を提供し、スタッフの負担軽減にもつなげたい考えだ。</p>
<p>オンデーズは今後もテクノロジーと人の接客を融合させ、顧客体験の進化を進めていく方針を示している。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIコーディングアシスタント「Jules」を正式公開──Gemini 2.5 Pro搭載、無料プランから利用可能に</title>
      <link>https://ledge.ai/articles/google_ai_coding_assistant_jules_general_availability</link>
      <description><![CDATA[<p>Googleは2025年8月6日、AIコーディングアシスタント「Jules（ジュールズ）」の一般公開を<a href="https://blog.google/technology/google-labs/jules-now-available/">発表</a>した。2024年12月の発表、2025年5月のパブリックベータ提供を経て、正式サービスとしての提供が開始される。</p>
<h2>ベータを経て正式版へ</h2>
<p>Julesは、Googleの最新モデル「Gemini 2.5 Pro」を搭載したコーディング支援AIで、コードの読み込み、改善提案、テスト、自動修正、Pull Request（PR）の生成までを一貫して行える。特徴は非同期処理に対応している点で、クラウド環境上で複数のタスクを並列に進行できる。ベータ期間中にはUI改善やバグ修正が進められ、GitHub Issuesとの連携機能や、マルチモーダル入力への対応、タスクの再利用機能、音声形式の変更履歴出力などが追加された。</p>
<h2>利用プラン</h2>
<p>Julesは無料プランと有料プランを用意。無料プランでは1日15件、同時3件までのタスク実行が可能。有料プランは「Google AI Pro」（上限5倍）と「Google AI Ultra」（上限20倍）が用意され、いずれも月額課金制となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/jules_plan_f0ff26b4df/jules_plan_f0ff26b4df.jpg" alt="jules plan.jpg" /></p>
<h2>プライバシーと安全性</h2>
<p>GoogleはJulesの動作設計を「Private by default」としており、ユーザーのプライベートリポジトリのデータはモデル学習に利用されない。実行は分離された環境で行われ、機密性を保ちながら処理が進められる。</p>
<h2>今後の展望</h2>
<p>Googleは、Julesを単なる開発者向けツールにとどまらず、デザイナーやノーコードユーザーなど幅広い層の業務支援に活用できる存在として位置づける。非同期エージェントとしての特性を生かし、今後はモバイルアクセスの強化など、利用環境のさらなる拡充も見据えている。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/8/18 [MON]Google、AI学習に必要なデータを最大1万分の1に削減可能な新手法を発表</title>
      <link>https://ledge.ai/articles/google_ai_data_reduction_method</link>
      <description><![CDATA[<p>Googleは2025年8月７日、自社の研究ブログで、AIモデルの学習に必要なトレーニングデータ量を最大で1万分の1に削減しながら、モデル品質を維持できる新しい学習手法を<a href="https://research.google/blog/achieving-10000x-training-data-reduction-with-high-fidelity-labels/">発表</a>した。従来の膨大なデータ収集とラベリングに依存するアプローチに比べ、効率的かつ高精度なラベル付けを活用する点が特徴となる。</p>
<h2>新手法の概要</h2>
<p>Google Researchが公開した今回の手法は、まず大規模言語モデル（LLM）を用いてデータをクラスタリングし、モデルが誤りやすい境界事例を抽出する。その後、専門家が少数のデータに高精度なラベルを付与し、ファインチューニングに利用する仕組みだ。</p>
<p><strong>■ LLMによる事前ラベリング→クラスタリング→境界ペア抽出→専門家ラベル→反復学習の流れ（①〜④）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Curation_Strategies1_Process_Final_width_1250_c73b951bad/Curation_Strategies1_Process_Final_width_1250_c73b951bad.png" alt="CurationStrategies1_ProcessFinal.width-1250.png" /></p>
<h2>実験結果</h2>
<p>通常10万件規模のラベルが必要とされるケースにおいて、この手法では250〜450件の専門家ラベルで同等以上の成果を得られることが示された。実験にはGoogleの軽量モデル「Gemini Nano-1（1.8Bパラメータ）」と「Gemini Nano-2（3.25Bパラメータ）」が用いられ、特にNano-2ではモデルと専門家ラベルの一致度を示す指標「Cohen’s Kappa」が55〜65％向上した。</p>
<p><strong>■ Cohen’s Kappaとサンプル数の関係。キュレーション（緑）が従来（赤破線）を広く上回り、特に3.25Bモデルで効果が顕著</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Curation_Strategies4_Results_width_1250_6dca7b850b/Curation_Strategies4_Results_width_1250_6dca7b850b.png" alt="CurationStrategies4_Results.width-1250.png" /></p>
<h2>意義と応用可能性</h2>
<p>この成果により、AIの開発に伴うデータ収集やアノテーションのコストを大幅に削減できる可能性がある。特に医療や広告など、専門知識が求められる領域での利用価値が高いとされる。また、AI開発の持続可能性を高め、より幅広い分野での応用を後押しすることが期待される。</p>
<p>Googleは今後も効率的なAIトレーニング手法の研究を続け、より少ないデータで高品質なモデルを構築できる仕組みの標準化を目指すとしている。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、小型オープンモデル「Gemma 3 270M」を公開──2.7億パラメータで高性能を実現</title>
      <link>https://ledge.ai/articles/google_gemma3_270m_release</link>
      <description><![CDATA[<p>Googleは2025年8月14日、小型オープンモデル「Gemma 3 270M」を<a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">発表</a>した。2億7000万パラメータという軽量な構成ながら、高い性能と省電力性を両立。スマートフォンや低リソース環境でも効率的に利用できる点が特徴で、AIの利用範囲をさらに広げる存在として注目を集めている。</p>
<h2>小型モデルの正式リリース</h2>
<p>Googleが発表した「Gemma 3 270M」は、同社の最新モデル群「Gemma 3」シリーズのなかで最小規模のモデルとなる。2億7000万パラメータというサイズながら、量子化を含む最適化技術を取り入れることで高い応答性能を実現している。オープンモデルとして公開され、研究者や開発者が幅広く活用できる点も特徴だ。</p>
<h2>技術的な特徴</h2>
<p>Gemma 3 270Mは、メモリや電力の制約がある環境での実行を想定し設計されている。量子化により少ないリソースでの推論が可能で、エッジAIやモバイルデバイスへの実装を視野に入れている。また、Googleの最新研究成果を取り入れた学習設計によって、応答の一貫性と堅牢性を兼ね備えているという。</p>
<p><strong>■ Gemma 3 270Mの性能比較（IFEvalスコア）。同規模のモデルを上回る効率を実現している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemma3_270_M_Chart01_RD_3_V01_original_8e89e75c65/Gemma3_270_M_Chart01_RD_3_V01_original_8e89e75c65.jpg" alt="Gemma3-270M_Chart01_RD3-V01.original.jpg" /></p>
<h2>利用シーンと応用可能性</h2>
<p>同モデルは、スマートフォンやIoTデバイスといった軽量環境での利用に適している。具体的には、チャットボットや検索補助、タスク特化型アプリケーションなど、現場に即した応用が期待される。</p>
<p>Google公式ブログでは、実際の応用例として「Bedtime Story Generator」アプリが紹介されている。これは、Hugging Faceの開発者がTransformers.jsを用いて制作したWebベースの物語生成アプリで、Gemma 3 270Mがその処理を支えている。小型で高性能な特性が、こうした創造的なタスクをオフラインで可能にしている。</p>
<p><strong>Gemma 3 270M を活用した「Bedtime Story Generator」アプリのデモ</strong></p>
<p>@<a href="https://www.youtube.com/watch?v=ds95v-Aiu5E">YouTube</a></p>
<p>米VentureBeatは「スマートフォン上で動作可能な超小型モデル」と報じ、エッジデバイスでの実用性を強調。Analytics India Magも「タスク特化型AIモデルとして電力効率に優れる」と評価している。こうした外部の評価からも、軽量モデル市場における注目度の高さがうかがえる。</p>
<h2>今後の展望</h2>
<p>Gemmaシリーズは多様なサイズのモデルを展開しており、Gemma 3 270Mはその最小構成としての役割を担う。今後は大規模モデルとの併用や用途ごとの選択により、AIの導入がさらに柔軟になることが期待される。Googleはオープンモデルの提供を通じて、AIの民主化と利用環境の拡大を推し進めている。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTTデータ、Google Cloudと世界規模のパートナーシップ締結──「Smart AI Agent™」で業界特化型AIを共同開発</title>
      <link>https://ledge.ai/articles/nttdata_google_ai_agent_partnership</link>
      <description><![CDATA[<p>NTTデータグループは2025年8月13日、Google Cloudとグローバルパートナーシップを締結し、業界特化型のAIエージェント「Smart AI Agent™ Ecosystem」を共同で開発・展開すると<a href="https://www.nttdata.com/global/ja/news/topics/2025/081300">発表</a>した。両社は、50以上の業界に対応するAI・クラウドソリューションを展開し、セキュアなソブリンクラウド基盤の整備や数千人規模の専門チーム設立を通じて、AI導入とクラウドのモダナイゼーションを加速させる。</p>
<h2>業界特化型AIエージェントの開発へ</h2>
<p>NTTデータとGoogle Cloudは、企業の業務を支援する自律的なAIエージェントを軸に「Smart AI Agent™ Ecosystem」を構築する。Googleの生成AIモデル「Gemini」や開発環境「Agentspace」を活用し、データクリーンルームを通じたセキュアな情報利用を可能にする仕組みだ。両社は今後、50以上の産業に対応したソリューションの共同開発を進める。</p>
<h2>クラウド近代化とセキュリティ強化</h2>
<p>協業の柱には、レガシーシステムからの移行やクラウドアプリケーション刷新が含まれる。メインフレームモダナイゼーション、DevOps、Observability、API管理、SAP on Google Cloudといった領域を強化し、幅広い企業のDXを後押しする。さらに、Google Distributed Cloudの「エアギャップ」「コネクテッド」両モードを活用し、規制の厳しい業界にも対応可能なソブリンクラウドを展開する。</p>
<h2>人材育成とグローバル体制</h2>
<p>両社は数千人規模のGoogle Cloud専門チームを立ち上げ、2025年度中に5,000人のGoogle Cloud認定資格者を育成する計画を示した。さらに共同でGo-To-Market投資を行い、世界市場におけるAIソリューションの提供体制を強化する。</p>
<h2>今後の展望</h2>
<p>NTTデータグループ常務執行役員のMarv Mouchawar氏は、「今回のパートナーシップは、AIとクラウドの未来を切り拓く重要なマイルストーンであり、産業界全体に大きな変革をもたらす」と強調した。さらに「両社の強みを掛け合わせることで、顧客が直面する複雑な課題に応え、業務効率とイノベーションを同時に実現できる」と展望を語っている。</p>
<p>Google CloudプレジデントのKevin Ichhpurani氏も、「業界特化型AIエージェントは、金融、製造、公共といった各分野における深刻な課題を解決し、顧客企業の競争力を大幅に高める」と述べ、「NTTデータとの協業によって、グローバル規模での導入と拡張が加速する」と期待を寄せた。</p>
<p>世界的に生成AIの需要が急拡大するなか、今回の提携は単なる技術導入にとどまらず、エコシステムを通じて企業や社会の変革を支える基盤づくりを狙うものだ。両社はソブリンクラウドや人材育成にも注力し、公共分野や規制産業を含む幅広い領域への展開を推進する方針である。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/8/20 [WED]NVIDIA Research、「エージェントAIの未来は小規模言語モデル（SLM）」と提言──LLMは“必要時のみ”、ハイブリッド構成を推奨</title>
      <link>https://ledge.ai/articles/nvidia_slm_future_of_agentic_ai</link>
      <description><![CDATA[<p>NVIDIA ResearchのPeter Belcak氏らは2025年6月2日、論文「Small Language Models are the Future of Agentic AI」を<a href="https://research.nvidia.com/labs/lpr/slm-agents/">発表</a>し、現在は大規模言語モデル（LLM）を中心に設計されがちなエージェントAIについて、実運用では小規模言語モデル（SLM）がより適しており、経済的でもあると主張した。論文は、SLMの能力・運用適性・コスト効率を根拠に、用途に応じて複数モデルを組み合わせるヘテロジニアス（混在）構成を推奨している。</p>
<h2>「SLMは十分に強力で、運用に適し、必然的に安価」</h2>
<p>著者らは、エージェントAIの多くが限られた種類のタスクを反復処理するという前提に立ち、こうした場面ではSLMで十分な精度と安定性が得られると指摘。加えて、SLMはレイテンシ・消費電力・インフラ規模の面で有利であり、実サービスへのデプロイやエッジ実行にも向くとした。</p>
<h2>コスト面の差：7B級SLMは70〜175B級LLMより「10〜30倍」効率的</h2>
<p>論文は7B規模のSLMと70〜175B規模のLLMを比較し、レイテンシ、エネルギー、FLOPsの観点で10〜30倍の効率差があり、リアルタイム応答を要するエージェントにおいてSLMが有利だと述べる。</p>
<h2>ハイブリッド構成の推奨：「会話の汎用性」が必要な場面のみLLMを</h2>
<p>一方で、広範な一般会話能力が不可欠な場面については、複数モデルを呼び分けるヘテロジニアス構成（SLMとLLMの併用）が自然な選択だと提案。これにより、日常的な専門タスクはSLMで低コストに処理し、LLMは“必要時のみ”に限定してコスト最適化を図る設計思想を示した。</p>
<h2>LLM→SLMへのエージェント移行を見据えた「一般アルゴリズム」も提示</h2>
<p>論文は、既存のLLM中心エージェントをSLM主軸へ移行するための一般的な変換アルゴリズムを概説。移行の障壁や留意点にも触れ、産業界での段階的な置換を見据えた実務的視点を強調している。</p>
<h2>背景にある推論基盤の進化——NVIDIA「Dynamo」</h2>
<p>主張の背景には、SLMを高スループット・低レイテンシでさばく推論OS/基盤の進歩もある。NVIDIAは2025年3月に「NVIDIA Dynamo」を発表し、分散環境での推論効率を高める最適化（KVキャッシュ制御やディスアグリゲーテッド・サービング等）を公開している。こうした基盤整備が、SLM運用の現実解を後押ししている。</p>
<p>著者らは、論文へのフィードバックを公開で受け付ける特設ページも用意。今後の往復書簡・批判的検討を通じて議論を深める姿勢を示している。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ソフトバンク・三菱ケミカル・慶應義塾大学・JSR、量子コンピューターで32量子ビット級のエネルギーギャップ計算に成功──新手法「TQPDE」がPNASに掲載</title>
      <link>https://ledge.ai/articles/quantum_computer_energy_gap_pnas</link>
      <description><![CDATA[<p>ソフトバンク、三菱ケミカル株式会社、慶應義塾大学、およびJSR株式会社は2025年7月31日、慶應義塾大学内のIBM Q Network Hubにおいて、量子コンピューターを用いた大規模なエネルギーギャップ計算手法を開発し、その成果が米国科学アカデミー紀要（PNAS）に掲載されたと<a href="https://www.keio.ac.jp/ja/press-releases/2025/7/31/28-168654/">発表</a>した。</p>
<p>今回開発されたのは、「テンソルに基づく位相差推定（Tensor-based Quantum Phase Difference Estimation, TQPDE）」と呼ばれる新手法である。従来の量子位相推定にテンソルネットワークを組み合わせることで回路を圧縮し、ノイズを抑制しながら計算を可能にした。これにより、従来最大6量子ビット規模にとどまっていた量子位相推定型アルゴリズムを、32量子ビット規模まで拡張することに成功したという。</p>
<h2>背景</h2>
<p>分子の物性解析には電子状態の計算が不可欠だが、古典計算機では電子数に応じて計算コストが指数関数的に増大する。特に電子間相互作用が強い物質では、一般的に用いられる近似手法（DFT）でも精度不足が課題とされてきた。
量子コンピューターは量子もつれや重ね合わせを活用し、古典計算では困難なシミュレーションを可能にする潜在力を持つが、ノイズの多さから大規模回路を実行するのは困難であった。</p>
<h2>今回の成果</h2>
<p>研究チームは、量子位相差推定にテンソルネットワークを組み合わせ、量子回路を効率的に圧縮することで、従来困難とされてきた規模の計算を実現した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/TQPDE_b8c45d17c0/TQPDE_b8c45d17c0.jpg" alt="提案手法TQPDEの概要.jpg" />
<strong>図1：提案手法『テンソルに基づく位相差推定（TQPDE）』の概要。量子位相推定にテンソルネットワークを組み合わせ、回路圧縮とノイズ抑制を実現した</strong></p>
<p>この手法を「IBM Quantum System One」および「IBM Quantum System Two」で実行し、ハバードモデルおよび直鎖分子デカペンタエンを対象に検証。さらにQ-CTRL社のエラー抑制モジュールを活用し、標準では7,000超の制御Zゲートが必要となる回路を800未満まで削減することに成功した。その結果、実機においてもエネルギーギャップ値が理論的に収束することが確認された。</p>
<p><strong>図2：実証結果。ハバードモデル（32量子ビット）および直鎖分子デカペンタエン（20量子ビット）に適用し、計算精度が実機でも収束することを確認した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_adc2216763/_adc2216763.jpg" alt="実証内容.jpg" /></p>
<h2>意義と展望</h2>
<p>今回の成果は、量子コンピューターによる化学計算が「玩具モデル」を超え、古典計算の限界に迫る大規模分子システムに適用可能であることを示した。研究チームは今後、材料開発や電池設計など幅広い分野への応用を見据え、量子計算技術の社会実装に向けた研究を継続するとしている。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>さくらインターネット、生成AI開発を効率化──NVIDIA最新GPU「B200」搭載クラウドを提供開始</title>
      <link>https://ledge.ai/articles/sakura_gpu_b200_cloud_release</link>
      <description><![CDATA[<p>さくらインターネットは2025年8月15日、同社のベアメタル型GPUクラウドサービス「高火力 PHY」において、NVIDIAの最新GPU「B200」を搭載した新プランの提供を開始したと<a href="https://www.sakura.ad.jp/corporate/information/newsreleases/2025/08/15/1968220622/">発表</a>した。生成AI（人工知能）の開発や学習処理を一段と効率化できる環境を整える。</p>
<p>新プラン「B200プラン」では、NVIDIAのBlackwellアーキテクチャを採用したGPU「B200」を搭載。大規模なAIモデルの学習や推論処理において高い性能を発揮する。さらに高速ネットワーク回線やスケーラビリティに対応しており、開発者や研究者は柔軟に計算リソースを利用できる。</p>
<p>同社によると、約400台のB200 GPUを北海道・石狩データセンターに導入。これにより国内における生成AI開発環境の安定供給を図る。提供開始は8月15日からで、初期利用キャンペーンも実施されるとのこと。</p>
<p>これまでも「高火力 VRT」などのGPUクラウドサービスを展開してきたさくらインターネット。今回の新プラン投入により、生成AI需要の拡大に対応するとともに、国内の企業や研究機関によるAI活用を後押しする狙いがある。</p>
<p>同社は、今後も最新GPUを活用した研究やサービス開発を支援し、国内データセンターを基盤とした高性能かつ安心なクラウド環境の提供を強化していくとしている。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5のIQはどこまで高くなった？──GPT・Claude・Geminiを“メンサ式IQテスト”で比較する『Tracking AI』</title>
      <link>https://ledge.ai/articles/tracking_ai_mensa_iq_test</link>
      <description><![CDATA[<p>米ジャーナリストのMaxim Lott氏は、主要なAIモデルの知能指数（IQ）や政治的傾向を客観的に比較できるウェブサイト「Tracking AI」を2025年8月21日に<a href="https://www.trackingai.org/home">更新</a>した。同サイトでは、独自に作成した非公開のIQテストと、Mensa Norwayがオンラインで公開している図形パズル型IQテストを用いて、ChatGPT（GPT-5 Proなど）、Claude 4 Opus、Gemini 2.5 Pro、Llama、Mistralといった代表的なAIモデルを比較している。</p>
<h2>IQテストによる性能比較</h2>
<p>Tracking AIでは、各モデルのIQスコアを分布図やランキング形式で表示。OpenAIのGPT-5 Pro（Vision）やGoogleのGemini 2.5 Proが上位に位置し、ClaudeやDeepSeekなども含めたスコアの推移を時系列で追うことができる。さらに、各問題ごとの正答率や、AIごとの解答理由まで公開されており、モデルの思考過程を詳細に比較可能だ。</p>
<p><strong>主要AIモデルのIQスコア分布（Tracking AIより）。GPT-5 Pro（Vision）やGemini 2.5 Proが高スコアを記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IQ_Test_Result_7124431b5e/IQ_Test_Result_7124431b5e.jpg" alt="IQ Test Result.jpg" /></p>
<h2>Mensaテストと独自テスト</h2>
<p>使用されているテストは2種類。1つはLott氏自身が作成した「オフライン自作テスト」で、AIの学習データに含まれていないことを強調。もう1つはMensa Norwayが提供するオンラインIQテストで、35問の図形推理問題を25分以内に解く形式。いずれもAIの「推論力」を可視化する指標として活用されている。</p>
<p><strong>Mensa Norwayの公開テストとオフライン自作テストの結果を比較したランキング。テスト方法により順位の違いも見られる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rank_by_test_source_71cc2da37b/rank_by_test_source_71cc2da37b.jpg" alt="rank by test source.jpg" /></p>
<h2>政治的・社会的な質問比較</h2>
<p>Tracking AIのもう一つの特徴は、AIに政治的・社会的テーマの質問を投げかけ、回答を比較できる点だ。例えば「経済的グローバル化は人類に奉仕すべきか」という質問に対し、GPT-5は「Strongly Agree」と答え、ClaudeやGeminiも人類の福祉を優先する立場を示した。こうした比較から、各AIのバイアスや思想傾向を把握できる仕組みになっている。</p>
<h2>サンプル問題の公開</h2>
<p>サイトでは「IQ TEST OF THE DAY」として日替わり問題も提供されている。各AIの回答と理由が並べて掲載されており、単なるスコア比較にとどまらず推論の特徴を把握できるのが特徴だ。</p>
<p><strong>Tracking AIで公開されている日替わりIQ問題。各AIモデルの解答と推論過程も併せて公開される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/iq_test_of_the_day_b238126d2f/iq_test_of_the_day_b238126d2f.jpg" alt="iq test of the day.jpg" /></p>
<h2>FAQと今後の展望</h2>
<p>FAQページでは、「なぜこのサイトを作ったのか」「政治的コンパスは有効か」「資金源はどこか」などの質問に回答。AIの性能や思想傾向を透明化し、利用者が信頼できる判断材料を得られるようにすることが目的とされている。今後は質問データの拡充なども予定されているという。</p>
<p>AIの能力が急速に進化する中で、『Tracking AI』は知能指数と政治的スタンスの両面からモデルを比較できる貴重な情報源となっている。Mensa式IQテストや独自問題を通じてAIを測定する試みは、AIの性能を人間社会に照らして理解するための一助となりそうだ。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Yahoo!ショッピング、2025年上半期の安全・安心レポート公開──AIで不正検知率3倍、レビュー45万件を削除</title>
      <link>https://ledge.ai/articles/yahoo_shopping_ai_safety_report_2025h1</link>
      <description><![CDATA[<p>LINEヤフーは2025年8月19日、ECモール「Yahoo!ショッピング」における2025年上半期（1月～6月）の安全・安心に関する取り組みをまとめたレポートを<a href="https://www.lycorp.co.jp/ja/news/release/018424/">公開</a>した。</p>
<p>出店審査の厳格化やAIによる不正対策の強化により、不適切ストアや商品の排除、不正レビューや不正決済の防止に成果があったと発表している。</p>
<h2>出店審査とストア監視</h2>
<p>Yahoo!ショッピングでは、利用者が安心して買い物できる環境を提供するため、ストアの出店審査を強化。2025年上半期の出店審査合格率は4.2%にとどまり、不適切なストアの参入を抑制した。不適切と判断されたストアは約1,000件削除されている。</p>
<p><strong>■ 出店審査合格率の推移。2025年上半期は4.2%まで低下し、不適切ストアの参入を抑制</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f31faf25870eeacbf570af249f3d33c1688cadd8_c62eac64bd/f31faf25870eeacbf570af249f3d33c1688cadd8_c62eac64bd.jpeg" alt="f31faf25870eeacbf570af249f3d33c1688cadd8.jpeg" /></p>
<h2>商品・レビューの監視体制</h2>
<p>同期間中に不適切商品を約38万件削除。不正や不適切と判断されたレビューは約45万件にのぼり、消費者の購買判断を歪める要因を排除した。</p>
<p><strong>■ 「2025年上半期に削除されたやらせレビューは45万件超。ストア単位での自動削除も開始</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/aa6a163c1af78b5868b370ad7b69314db2f52390_f1e6995c39/aa6a163c1af78b5868b370ad7b69314db2f52390_f1e6995c39.jpeg" alt="aa6a163c1af78b5868b370ad7b69314db2f52390.jpeg" /></p>
<h2>不正決済対策とAI活用</h2>
<p><strong>■ 不正決済対策では、独自システム・EMV3Dセキュア・人的監視の3段階フローを導入。2025年上半期の被害額は前年同期比41.2％減</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/line_yahoo_41_2_039d7dd883/line_yahoo_41_2_039d7dd883.jpg" alt="line yahoo 41-2.jpg" /></p>
<p>不正決済による被害額は前年同期比で41.2%減少。AIを活用した新しい不正検知モデルの導入により、従来比で不正検知率を3倍に引き上げる成果があった。レビューや商品情報の解析にAIを導入することで、不正の早期発見と対応が可能になったという。</p>
<p><strong>■ 2025年4月からAIによる違反商品のパトロールを開始。従来の手法に比べ違反検知率は3倍以上に向上</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f1a6e505568260cf65ca26223b68360198b2a025_09d467b85e/f1a6e505568260cf65ca26223b68360198b2a025_09d467b85e.jpeg" alt="f1a6e505568260cf65ca26223b68360198b2a025.jpeg" /></p>
<h2>今後の取り組み</h2>
<p>同社は、出店審査・監視体制のさらなる高度化に加え、不正検知AIの強化や利用者への情報開示の拡充を進める方針を示した。同社は「より安全で快適な買い物環境を提供する」としており、継続的に安全対策を強化していく。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>参加者をオープンにし、オープンデータを活用するとどんなソリューションが生まれるか？　人工衛星データで犯罪防止に挑む｜富士通 DDM Award 2024 受賞者インタビュー</title>
      <link>https://ledge.ai/articles/fujitsu-ddm-award-2024</link>
      <description><![CDATA[<p>富士通株式会社が主催し、2024年11月から2025年3月まで開催されたデータ利活用コンペティション「DDM Award 2024」で優秀賞を獲得したチーム ミギアシ。
本稿では、同チームのメンバーにアワードの模様や受賞アイデア、データ活用のアプローチなどについて幅広くインタビューした。富士通が掲げる「データドリブン経営」への取り組みと、その最前線について、ぜひご覧いただきたい。</p>
<h2>チームミギアシ メンバー</h2>
<h2>「DDM Award」</h2>
<p>DDM Award（Data Driven Management Award）は、富士通がデータドリブン経営への変革を推し進めることを目的に立ち上げた施策だ。職種／組織／既存の知識や技能といった壁を超え、富士通全社のデータドリブン経営(DDM)の推進を自分事として捉え、行動を起こした個人・組織・活動を表出し称賛し合う全社イベントとしてこれまで開催されてきた。</p>
<p>前回開催の2024年には、「DDM Award」のデータ分析コンペ部門が、富士通本店が所在する川崎市と初めて連携し、社外からも参加者を募るオープン形式で実施された。川崎市の市制100周年に合わせ、テーマは「川崎市さん気づいてました？市の魅力アップにつながる因子･インサイトを見つけ出せ！」。市のイメージ向上につながる施策を競うコンペとなった。決勝のプレゼンテーションには、70を超えるエントリーチームの中から、Dynamic：大胆な挑戦、Diverse：多様なアプローチ、Discover：新たな発見、の3つの観点で4チームが選ばれた。その中で、チームミギアシは人工衛星データを活用し、治安改善という公共性の高いテーマに挑戦した点が高く評価された。</p>
<p>チームは通常業務の合間を縫ってコンペ作業に取り組む必要があったため、円滑な進行を目指して役割分担を行った。全体の進行管理と分析の中心を担ったのは大林氏。初期段階の企画や設計に征矢氏が加わり、そして分析に精通する鄭氏が、分析に関する相談役としてサポートを行ったという。</p>
<h2>「犯罪防止」に焦点をあてた背景</h2>
<p>チーム ミギアシが犯罪防止に着目したのは、自治体の魅力を住民や市外の人間が判断する要素の一つとして、「治安」が重要だと考えたからである。「実は、川崎市の場合、人口に対する犯罪件数は全国的に見て特別高いわけではないんです」と征矢氏。人口に対する比率は少ないものの、件数のみを見ると少ないとはいえず、社内ヒアリングでも「治安」に関する声が複数寄せられたそう。こうした状況から「改善の余地があるのではないか」との認識に至り、犯罪防止につながるアプローチを検討することとなった。</p>
<h2>人工衛星データを活用した分析アプローチ</h2>
<p>犯罪防止の対策を検討するにあたり、川崎市でどの種類の犯罪が、どのエリアで多発しているのかを把握する必要があった。そこで同チームは、現状分析の手段として【地図データ】を基盤に、Googleが提供する【夜間光データ】、国が公開する【国勢データ】、そして警視庁が公開する【都内犯罪データ】を組み合わせ、状況を多角的に探ることにした。</p>
<p>プロジェクトの中核を担うのが、人工衛星によって取得される夜間光データだ。夜間光データは街灯や看板、交通量による明るさを定量的に把握でき、また、衛星観測により広範囲かつ高頻度で収集されるデータである。この【夜間光データ】と【犯罪データ】の組み合わせは、都市計画や防犯研究においても犯罪発生との密接な関連性が指摘されている。たとえば、夜間に街灯が少なく暗いエリアは犯罪の温床になりやすく、人通りが少ない時間帯は犯行のリスクが高まる傾向がある、などと言われている。
大林氏はオープンデータの技術的な課題と工夫について、以下のように説明した。
「公開されているオープンデータは、データごとに独自のフォーマットで整理されているため、これをどう統一し、並列で分析するかが大きな壁でした。実際、夜間光データは500メートル四方のデータのみ取得できず、詳細のエリアまで把握できない仕様になっているため、エリアを切り取って地図データと突合し、どのエリアでどのぐらいの光量があるのか、詳細を把握できるようにデータを加工しなければなりませんでした」</p>
<p>また、犯罪データについては、川崎市や神奈川県警が公開する情報に、本プロジェクトで活用できる十分な詳細データが存在しなかった。そこで、近隣の東京都のデータをもとに類推し、分析に取り入れることにした。具体的には、まず都内全自治体の基本データ（人口・面積など）と夜間光強度データを用いて、各自治体を分類（クラスタリング）するモデルを構築。このモデルから川崎市の各区がどのグループに属するかを推定した。そして分類された自治体グループ毎に、夜間光データと犯罪データの相関を分析し、犯罪種別（30種）ごとに発生件数と夜間光強度との傾向を抽出した。</p>
<p>分析の結果、グループごとに夜間光強度と犯罪種別ごとの発生件数の関係が異なる事を確認し、あるエリアにおいては明るいと発生件数が少なくなる犯罪種別があることを特定した。このことから、各エリアの傾向に応じた街灯の新設や配置見直しといった犯罪防止施策の検討が重要であることを提案した。
なお、今回の分析はオープンデータのみを用いたものであったため、プレゼン内では「今後、市政に活用する際は、より詳細なデータを取得し、エリアや犯罪種別を絞り込むことで、さらに効果的な犯罪防止策が期待できる」と、さらなる分析の必要性を示した。</p>
<p>今回のコンペで、川崎市からは「街灯という本市で対応できる具体的な解決策を得たことは大きな収穫です」といった前向きなコメントも寄せられたという。もちろん、今回のようなデータ分析から見えた仮説を実社会へ反映させた上で、実装後に犯罪件数がどの程度変化したかを定点観測することが非常に重要である。しかし、まずは第一段階として、川崎市のまちづくりに役立つ、新たな気づきを与えられたといえるだろう。</p>
<h2>参加意義と波及効果</h2>
<p>このコンペ参加を振り返り、大林氏は次のように語った。
「オープンデータを実際に利用してみて、国や公共機関が公開している資料については、データ項目の統一化が望ましいと強く感じました。たとえば、同じ市町村区でも丁目や番地などの区切りがバラバラになっているため、統一ルールを設けることで、さらにデータ活用が進むと実感しました」
一方で、オープンデータから得られる情報の幅広さにも驚いたという。ビジネス視点で考えると、PoCを回す前の企画・計画段階においても、オープンデータで初期検証が可能であるという手応えを得られたそうだ。</p>
<p>また、通常業務への影響について聞いてみると大林氏は「自身の役割範囲をさらに拡大できた」と話してくれた。大林氏は通常業務で、病院向けのソリューション開発プロジェクトの企画部分に携わっているが、これまではビジネス寄りの視点から企画・設計を行っていた。しかし、今回の取り組みを経てデータサイエンティスト的な視点を養ったことで、医療データ利活用の推進において直面するデータの標準化や構造化といった課題を、より明確に捉えながら業務を進められるようになったという。</p>
<p>コンペティション終了後、チームミギアシは、2025年7月30日から8月1日に開催された第2回 SPEXA -【国際】宇宙ビジネス展の富士通ブースで、同プロジェクトの成果を展示した。イベント出展のきっかけは、DDM Award 2024の結果を同社の宇宙ビジネス推進室の社員が目にしたことだった。「夜間光×犯罪」というテーマが、声をかけてくれた社員の実務テーマと合致していたことから、今回のイベントブース内での展示につながったという。イベント参加を振り返り、征矢氏は「宇宙データの利活用という切り口で社内の様々なテーマが進行する中、今回の犯罪防止に関する分析結果発表は、一つの具体的な道筋として、データ活用の参考になったと思います」と語ってくれた。</p>
<h2>おわりに</h2>
<p>DDM Awardへの参加は、チームメンバーにとって日常業務を超えた挑戦だった。部門を横断した連携が生まれ、分析手法や可視化技術の共有も促進された。鄭氏は「経営陣が目指すオペレーショナルエクセレンスやデータドリブンマネジメントの実現に向けて、このようなイベントが起点となり、人や組織の文化を醸成する動きは非常に重要だと思います」と述べ、組織文化を創り上げていく取り組みと、システム面で業務効率や品質を高める取り組みを両輪で進めることが、同社の目指す“持続的な企業価値向上を実現する未来予測型経営”にもつながると強調した。</p>
<p>DDM Awardは今後の開催も目下企画途中である。今年もまた別のテーマで、今回のような新たなアイデアが生まれるに違いない。富士通が目指すデータドリブン経営の象徴的な事例はますます増えていくだろう。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>吉本興業、AIや縦型ショート含む多様な領域展開を見据えたコンテンツファンド設立——数十億円規模で海外展開、明石家さんま・ダウンタウンら所属タレントも参加</title>
      <link>https://ledge.ai/articles/yoshimoto_ai_content_fund</link>
      <description><![CDATA[<p>吉本興業は2025年8月18日、数十億円規模のコンテンツファンドを設立したと<a href="https://www.yoshimoto.co.jp/info/1415/">発表</a>した。AIを活用した企画や縦型ショートドラマ、アニメ、ゲームなど多様な領域を対象に、所属タレントがプロデュースや出演するコンテンツ制作を推進。さらに番組フォーマットを海外展開する方針も示した。</p>
<p>このファンドは国内外の企業からの出資を募り、数十億円規模の資金を確保する計画。バラエティ番組、映画、アニメ、ドラマ、ライブ、リアリティーショー、縦型ショートドラマ、ウェブトゥーン、ゲームなど幅広いコンテンツが対象となる。AIを活用した新たなコンテンツ制作にも取り組むという。</p>
<p>制作には、所属タレントである明石家さんま、ダウンタウン、中川家、千鳥、かまいたち、マヂカルラブリー、チョコレートプラネット、渡辺直美、霜降り明星らが参加。プロデュースや出演を通じ、既存の番組制作の枠を超えた取り組みを展開する予定だ。また、スポーツドキュメンタリーやオーディション番組など、タレントの多様な活動を反映した企画も構想され、ファンドを通じた新規プロジェクトの展開が注目される。</p>
<p>同社は、制作した番組フォーマットを海外市場に展開する方針も掲げており、今回のファンドは国際展開に向けた戦略的な一歩となるとのこと。国内外に向けてタレント主導のコンテンツ制作を拡大し、エンターテインメントの新たな可能性を切り拓く狙いだ。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 23:50:01 GMT</pubDate>
    </item>
    <item>
      <title>Blenderを操るAI──シカゴ大学ら、大規模言語モデルで3Dアセットを生成・編集する「LL3M」を発表</title>
      <link>https://ledge.ai/articles/ll3m_blender_llm_3d_modeling</link>
      <description><![CDATA[<p>シカゴ大学の研究チームは2025年8月11日、自然言語の指示だけでBlender内に3Dアセットを作り出せるシステム「LL3M（Large Language 3D Modelers）」を<a href="https://arxiv.org/abs/2508.08228">発表</a>した。大規模言語モデル（LLM）が直接Pythonコードを生成し、オブジェクトやシーンを自在に構築・編集するという新しいアプローチだ。論文はarXivに公開され、公式プロジェクトページやGitHubリポジトリも公開されている。</p>
<h2>コードを書くAI、Blenderを動かす</h2>
<p>LL3Mの最大の特徴は、3Dモデルを特殊なデータ形式で直接生成するのではなく、Blender用のPythonコードを“書く”AIであることだ。これにより、生成結果はすべて人間が理解できるコードとして残り、後から自由に修正・拡張できる。既存のワークフローに統合しやすい点も大きな利点とされる。</p>
<h2>多様なアセットを生み出す柔軟性</h2>
<p>論文では、BMeshによるポリゴンモデリング、モディファイアやシェーダーノードの適用、シーン階層の構築など、幅広い3D要素をコードで生成可能であることが示されている。家具やキャラクターなど、多彩なアセットが次々とコードベースで形作られる様子は、従来の「ブラックボックス的な生成AI」とは異なる透明性を感じさせる。</p>
<p><strong>■ Blender用Pythonコードを生成し、3Dオブジェクトを構築する例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig15_intro_highlight_bc133cc7d3/fig15_intro_highlight_bc133cc7d3.jpg" alt="fig15-intro-highlight.jpg" /></p>
<h2>3段階で進化するパイプライン</h2>
<p>LL3Mは単なる一発生成ではなく、段階的にモデルを洗練させる仕組みを備える。</p>
<ul>
<li><strong>初期生成</strong> ：自然言語の指示からコードを生成し、Blenderでオブジェクトを構築</li>
<li><strong>自動自己精緻化</strong> ：AI自身が結果を評価し、改善点を修正</li>
<li><strong>ユーザー誘導精緻化</strong> ：人間の追加指示を受けて再度改善</li>
</ul>
<p><strong>■ 自己批評やユーザー指示に基づく反復的な3Dモデルの改善</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig22_humanoid_final_b372c81836/fig22_humanoid_final_b372c81836.jpg" alt="fig22-humanoid-final.jpg" /></p>
<p>さらに「BlenderRAG」と呼ばれる仕組みで、Blender APIドキュメントを参照しながらコードを補強。これにより「動かないスクリプト」を避け、実際に使える成果物を高精度に生み出す。</p>
<h2>“コードで3Dを描く”という発想の転換</h2>
<p>研究チームは、NeRFや点群などデータ駆動型の3D生成手法と対比しながら、LL3Mのアプローチを強調する。コードは読み書きできる資産であり、再利用性や可搬性に優れるため、クリエイターや開発者にとって扱いやすい。AIと人間が共同作業する新しい3D制作の基盤としての位置づけを打ち出している。</p>
<h2>今後の展望──ゲームから教育まで</h2>
<p>GitHubリポジトリはすでに公開されているものの、実装は「Code coming soon」とされ、今後順次公開される見込みだ。研究チームは「人間とAIが協力する3D制作の未来」を描きつつ、ゲーム開発、教育、デジタルコンテンツ制作など多様な分野での応用可能性を指摘している。</p>
<p><strong>■ LL3Mによって生成された多様な3Dアセットの例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig2_gallery_b2bb1b7580/fig2_gallery_b2bb1b7580.jpg" alt="fig2-gallery.jpg" /></p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、自己教師あり学習の最新モデル「DINOv3」発表──ラベルなし17億枚画像で訓練、従来モデルを超える性能</title>
      <link>https://ledge.ai/articles/eta_dinov3_self_supervised_vision_model</link>
      <description><![CDATA[<p>Metaは2025年8月14日、自社AI研究チームが開発した新しいコンピュータビジョンモデル「DINOv3」を<a href="https://ai.meta.com/blog/dinov3-self-supervised-vision-model/">発表</a>した。このモデルは、膨大なラベルなし画像を用いた自己教師あり学習（self-supervised learning, SSL）によって訓練され、多様な視覚タスクで既存の専門モデルを超える性能を示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=-eOYWK6m3i8">YouTube</a></p>
<h2>大規模データとモデル構造</h2>
<p>DINOv3は約16.9億枚の画像データセット「LVD-1689M」で学習された。最大モデルはVision Transformer（ViT）ベースで70億パラメータ規模に達し、小型から大型まで複数のバリエーションが提供されている。</p>
<p><strong>■ DINOv3の特徴：</strong>  (a) 教師あり学習（SL）や弱教師あり学習（WSL）と比べた精度の推移、(b) 既存手法に対する深度推定・追跡・セグメンテーションでの性能向上率、(c)(d) DINOv3による特徴表現の可視化例
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Evolution_of_linear_probing_results_02dacc9850/Evolution_of_linear_probing_results_02dacc9850.jpg" alt="Evolution of linear probing results .jpg" /></p>
<h2>ベンチマークの結果</h2>
<p>具体的なベンチマークでは、画像分類だけでなく深度推定やセグメンテーションでも他手法を上回っている。特に、従来のDINOv2やMAEを含む自己教師ありモデルだけでなく、教師ありの大型モデルに対しても優位性を示した。</p>
<p><strong>■ DINOv3の各種ベンチマーク比較：</strong> セグメンテーション（ADE-20k）、深度推定（NYU）、動画追跡（DAVIS）など幅広いタスクで既存モデルを上回る性能を示した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DIN_Ov3_bench_569cfe7139/DIN_Ov3_bench_569cfe7139.jpg" alt="DINOv3 bench.jpg" /></p>
<h2>公開と利活用</h2>
<p>学習済みモデルはHugging FaceやGitHubで公開されており、衛星画像を用いて学習したバージョンも含まれる。商用利用も可能で、画像検索、ロボティクス、地理空間解析など幅広い分野での応用が期待される。</p>
<h2>今後の展望</h2>
<p>Metaは、DINOv3によってラベル不要の大規模学習の有効性を改めて証明した。今後は自己教師あり学習が、産業や研究におけるコンピュータビジョン技術の新たな基盤として拡大していく見込みだ。</p>
<p>研究チームは、DINOv3が、人手の監督に依存せずに汎用的な視覚表現を構築するための重要な前進であり、科学・産業の幅広い領域で新たな応用機会を開く、と結んでいる。</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アフリカでAI人材3万人を育成──東大・松尾研、政府と連携し製造業・農業DXを後押し</title>
      <link>https://ledge.ai/articles/africa_ai_talent_training_by_utokyo_matsuo_lab</link>
      <description><![CDATA[<p>東京大学 松尾・岩澤研究室は2025年8月18日、これまで国内で進めてきたAI教育をさらに発展させ、政府と連携してアフリカでAI人材を育成する取り組みを開始すると<a href="https://weblab.t.u-tokyo.ac.jp/news/20250818/">発表</a>した。取り組みは製造業や農業のDXを後押しすることを狙いとし、3年間で延べ3万人の育成を目標に据える。
同研究室は、これまで国内での無料・大規模オンライン講座などで培ってきた教育モデルをベースに、アフリカ地域で本格的な人材育成を展開する。公式サイトの発表では、政府と連携して取り組む方針が示されている。</p>
<h2>取り組みの目的と背景</h2>
<p>日本経済新聞の<a href="https://www.nikkei.com/article/DGXZQOUA041X30U5A800C2000000/">報道</a>によると、同プロジェクトは、製造業と農業のデジタル化（DX）を担う現地人材の裾野拡大を意図する。アフリカの若者が海外留学でAIスキルを得ても国外に残る例が多い現状を踏まえ、「地元で活躍できる環境を整え、人材を定着させる」狙いが示されている。</p>
<p>この取り組みにより、アフリカ地域におけるAI教育基盤が強化され、現地産業の生産性向上や雇用創出、エコシステム形成への寄与が期待される。</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/19 [TUE]AI業界を牽引するトップランナーが語る！—今押さえるべきAIの全体像と最前線を3日間で掴むLedge.ai Webinar SP開催</title>
      <link>https://ledge.ai/articles/ledgeai-webinarsp-sponsor</link>
      <description><![CDATA[<p>国内最大級のAI特化メディア『Ledge.ai』を運営する株式会社レッジ（東京都品川区）は、2025年9月24日(水)〜26日(金)の3日間連続で合計20本以上のセミナーを配信するオンラインイベント「Ledge.ai Webinar SP」を開催いたします。</p>
<p>本イベントでは、AIの各領域の専門家を招き、今必要とされるAIの体系的な知識や活用に関する見識をシェアする講義を実施。「AIをしる、つかう、つくる」をテーマに、多様な課題解決のヒントとなるようなコンテンツを動画でお届けします。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_4aed8b100c/_4aed8b100c.png" alt="ウェビナーの様子.png" /></p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>AI業界を牽引するトップランナーが今押さえるべきAIの知識と最前線を3日間で語る</h2>
<p>AIの急激な進化と急速な広まりにより、AIへのリテラシーの差が広がっています。AI活用の最前線では「どう使えば効果的か」「どう作れば自社の強みになるか」といった問いに対しての取り組みが行われ、新たな事例や知見が生まれています。そんな現在において、AIの全体像を体系的に理解した上で、ビジネスにどのように活用されているかすばやく捉えることは重要です。</p>
<p>当イベントはAIの基礎理解 → 業務活用 → 開発実践までを体系的に理解し、この時代で働くビジネスマンの方に使える学びをお届けします。</p>
<p>Ledge.ai Webinar SPは、以下の3つの軸で構成されています。</p>
<h2>プログラム ~「生成AIだけじゃない！「AIをしる、つかう、つくる」SP~</h2>
<h3>Day1：AIを「しる」——全体像と本質を理解する</h3>
<p>AIの領域では日々革新的な技術が生まれ、その掛け合わせによりAIの担える範囲が急速に広がっています。AIの基礎からAI全般の進化を体系的に学ぶことで適切なAI活用に繋げることができます。</p>
<p>【対象】
・AIの基本から体系的に理解したい方
・生成AIに加え、AI全般の進化や仕組みに関心がある方</p>
<p>【セミナー内容】
・AIの基礎とこれまでの進化（機械学習、ディープラーニング含む）
・⽣成AIの仕組みと活⽤シーンの全体像
・ビジネスで求められるAIリテラシーと注意点</p>
<p>【ゲスト講演】
「ソフトバンクの事例から紐解く、組織の生成AI活用・推進を自走するための仕組みづくり」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c71b18a520/_c71b18a520.jpg" alt="藤原 竜也.jpg" /></p>
<p>ソフトバンク株式会社
IT統括 AI&amp;データ事業統括部　Axross事業部 部長
藤原 竜也 氏</p>
<h3>Day2：AIを「つかう」——現場に効く、実践的なAI活用法</h3>
<p>「現場でどう使うのが効果的か？」を知りたい方に向けたプログラムです。現場導入の工夫やハマりがちな落とし穴まで、具体的なノウハウが得られます。</p>
<p>【対象】
・AIツールを現場の業務で活用したい方
・実務にすぐ役立つノウハウを知りたい方</p>
<p>【セミナー内容】
・業務シナリオ別のAIツール活用（生成AI・ルールベースAI）
・Excelや議事録、FAQ対応など、日常業務での実用ワーク
・プロンプトの書き⽅から社内導⼊のコツまで徹底解説</p>
<p>【ゲスト講演】
「まずは試してみよう！ 最新動向から学ぶ、生成AI活用の第一歩」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c4e70ae1da/_c4e70ae1da.jpg" alt="岡田隆太朗.jpg" /></p>
<p>一般社団法人日本ディープラーニング協会　
専務理事　
岡田 隆太朗 氏</p>
<h3>Day3：AIを「つくる」——AIプロダクト・自社専用AIツールの開発</h3>
<p>ノーコード/ローコードでのAI組み込みから、AI活用を前提としたインフラを含む環境構築、AIモデル開発など、AIの開発に必要な技術知識やノウハウを幅広く学ぶことができます。</p>
<p>【対象】
・ノーコード・ローコードでAIを組み込みたい方
・AIシステムの裏側やインフラにも関心がある方</p>
<p>【セミナー内容】
・生成AIアプリの基礎（RAG、Dify、API連携など）
・従来型AI（需要予測、分類モデルなど）の開発プロセス入門
・クラウド・ベクターデータベースなど、AI基盤技術の理解</p>
<p>【ゲスト講演】
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Zhan_Cliff_Chen_5c6864c871/Zhan_Cliff_Chen_5c6864c871.jpeg" alt="Zhan (Cliff) Chen.jpeg" />
マイクロソフト ディベロップメント株式会社
プリンシパル　アプライド　サイエンティスト
Zhan (Cliff) Chen / 陳 湛</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>こんな方におすすめ</h2>
<ul>
<li>企業のDX・AI導入担当者</li>
<li>生産性向上のためAIを活用したい事業部門マネージャー</li>
<li>ノーコードでのAI活用を始めたい開発初心者</li>
<li>最新AI技術のトレンドを押さえたいビジネスパーソン</li>
</ul>
<h2>イベント概要</h2>
<p>開催予定日時｜2025年9月24日(水)〜26日(金)
開催形式｜オンラインセミナー (Zoom Webinar)
想定集客規模｜500名
対象｜経営層 / システム企画 / DX推進 / 経営企画 / マーケティング / エンジニア
主催｜株式会社レッジ</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様を募集中</h2>
<p>現在、この企画の開催趣旨にご賛同いただき、共に「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様も募集しております。</p>
<p>スポンサーとなっていただいた企業様には、AI業界のトップランナーの方々と共に当イベントの講師としてウェビナーにご登壇いただき、最新の取り組みやノウハウを発信していただきます。</p>
<p>また、その他にも、スポンサー企業様にも下記のようなメリットをご案内させていただきます。</p>
<h3>スポンサー参加の主なメリット</h3>
<ul>
<li>AI関連の情報感度の⾼い読者との接点が持てる</li>
<li>貴社の優位性をLedge.αiが引き出しながらPRできる</li>
<li>通常のLedge.ai広告メニューよりお得な価格で利⽤できる</li>
</ul>
<p>当イベントのスポンサーにご興味がございましたらぜひイベント資料をご覧ください。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/Ledgeai3/formperma/tJ1kpSYYWvDVF2Kp3xE-sBTiKeMh-7DlQZDoqXnSjtA">▶︎スポンサー様向けの資料はこちら</a>
:::</p>
<h2>お問い合わせ</h2>
<p>詳細相談・お見積もりは以下メールアドレスにお問合せください。
ld_media_sales@ledge.co.jp
（担当：Ledge.ai Webinar SP 事務局）</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、エンタープライズAIとフィジカルAIに新モデル──「Nemotron」と「Cosmos Reason」を発表</title>
      <link>https://ledge.ai/articles/nvidia_nemotron_cosmos_reason</link>
      <description><![CDATA[<p>NVIDIAは2025年8月11日、エンタープライズAIエージェント向けの「Nemotron」シリーズと、ロボティクスや自動運転などの物理AI領域に対応する「Cosmos Reason」を<a href="https://blogs.nvidia.com/blog/nemotron-cosmos-reasoning-enterprise-physical-ai/">発表</a>した。企業システムから現実世界で動作するロボットまで、“推論能力を持つAI”の基盤整備を狙うという。</p>
<h2>Nemotron──エンタープライズAIエージェント向け</h2>
<p>Nemotronは大規模言語モデル（LLM）として開発され、エージェント型AIの構築に特化している。高度な推論能力を持ち、コーディングやデータ分析、さらには視覚情報を用いた推論にも対応することができる。また、オープンで拡張性のある設計が採用されており、企業は独自のデータを使って安全にカスタマイズできる点も特徴だ。提供形態としてはAPIや「NVIDIA AI Enterprise」を通じて利用可能で、業務自動化やセキュリティ強化、対話エージェントの開発など、幅広い用途での活用が見込まれている。</p>
<p><strong>NVIDIA Nemotron Super v1.5は、他の大規模モデルと比べて高い精度をより低い推論コストで実現している」</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nemotron_chart_1280x874_daebac66c2/nemotron_chart_1280x874_daebac66c2.png" alt="nemotron-chart-1280x874.png" /></p>
<h2>Cosmos Reason──物理AI・ロボティクス向け</h2>
<p>Cosmos Reasonは、7Bパラメータを備えた視覚言語モデル（VLM）である。力学や空間・時間の理解といった物理世界の常識を踏まえながら複雑な状況を推論することが可能で、現実世界で動作するAIの知能を補強する役割を担う。特にロボットや自動運転車の領域では、自律的な判断や行動計画を実現するための基盤モデルとして設計されている点が大きな強みとなる。</p>
<h2>NVIDIAの戦略的意義</h2>
<p>Nemotronは企業領域において、業務効率化やセキュリティ強化を支援する一方、Cosmos Reasonは産業オートメーションや自動運転といったフィジカルAIの分野で中核的な技術を提供する。NVIDIAはこれまで強みとしてきたGPUに加えて、AIモデルやプラットフォームを統合的に提供する体制を整えることで、AI市場における存在感を一層高めようとしている。</p>
<h2>今後の展望</h2>
<p>NVIDIAは「AIが自律的に考え、現実世界でも行動できる」ための基盤技術整備を推進している。今後は企業や研究者による導入事例がさらに増加すると見込まれており、エージェントAIとフィジカルAIという両輪によってAI活用が加速していくと予想される。</p>
]]></description>
      <pubDate>Mon, 18 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIに続き、AnthropicがGSA（米国一般調達局）と契約──米連邦三権に「Claude」を年間1ドル、1年間の限定プラン</title>
      <link>https://ledge.ai/articles/anthropic_government_claude_1dollar</link>
      <description><![CDATA[<p>Anthropicは8月12日（現地時間）、同社の大規模言語モデル「Claude」を活用するサービス「Claude for Enterprise」と「Claude for Government」を、米連邦政府の立法府・行政府・司法府に所属するすべての機関に対し、年間わずか1ドルで提供すると<a href="https://www.anthropic.com/news/offering-expanded-claude-access-across-all-three-branches-of-government">発表</a>した。契約は<a href="https://www.gsa.gov/about-us/newsroom/news-releases/gsa-strikes-onegov-deal-with-anthropic-08122025">米国一般調達局（GSA）</a>の「OneGov」枠組みを通じて実施される。</p>
<h2>提供の内容</h2>
<p>「Claude for Enterprise」は民間利用を想定した汎用版、「Claude for Government」は政府専用に設計されたバージョンで、連邦政府の厳格なセキュリティ基準「FedRAMP High」に準拠している。これにより、機密性の高い非分類情報を安全に取り扱うことが可能となる。提供期間は1年間で、Anthropicは各機関への技術サポートも行う。</p>
<h2>発表の背景</h2>
<p>今回の動きは、直前にOpenAIが「ChatGPT Enterprise」を米連邦行政機関に1ドルで提供すると発表したことを受けたもので、主要AI企業間での政府市場獲得競争が本格化している。GSAは「AI Action Plan」に基づき、政府全体でのAI活用を推進しており、Anthropicはこの取り組みに沿って導入障壁を下げる狙いを示した。</p>
<h2>導入事例</h2>
<p>既にエネルギー省（DOE）やワシントンD.C.保健局など複数の機関がClaudeを試験導入し、科学研究や住民サービスの効率化に活用している。今回の契約拡大により、他の連邦機関にも広範に利用が広がるとみられる。</p>
<h2>今後の展望</h2>
<p>Anthropicによる「年間1ドル」提供は、公共部門におけるAI普及を一気に加速させる試みである。同時に、OpenAIやxAIなどライバル企業との競争を象徴する施策でもある。AIの政府利用は行政効率化や政策立案の高度化を後押しする一方で、特定企業への依存や規制対応といった課題も残されており、今後の展開に注目が集まる。</p>
]]></description>
      <pubDate>Mon, 18 Aug 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>