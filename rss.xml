<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>AIエージェント「Rakuten AI」本格始動──まずはRakuten Link、秋には楽天市場へ</title>
      <link>https://ledge.ai/articles/ai_agent_rakuten_ai_launch</link>
      <description><![CDATA[<p>2025年7月30日、楽天グループは、パシフィコ横浜で開催中の自社イベント「Rakuten AI Optimism」において、生成AIを活用したエージェント型ツール「Rakuten AI」の本格提供を開始したと<a href="https://corp.rakuten.co.jp/news/press/2025/0730_01.html">発表</a>した。</p>
<p>同日より、楽天モバイル契約者向けの通話アプリ「Rakuten Link」および、誰でも利用可能なウェブアプリにてベータ版のサービス提供を開始。さらに2025年秋には、楽天の中核サービスであるECサイト「楽天市場」への統合を予定しており、同社は“エコシステム横断型AIエージェント”としての基盤整備を進めるという。</p>
<h2>「Rakuten AI」提供開始の概要</h2>
<p>「Rakuten AI」は、楽天IDを通じてユーザーがさまざまな楽天サービスを横断的に利用・操作できるエージェント型生成AIツールである。チャットボット形式のインターフェースを備え、ChatGPTのような自然言語対話を通じて、ショッピング・翻訳・プログラミング・画像生成など幅広い機能を1つの窓口で提供する。</p>
<p>対応入力はテキスト、音声、画像の3種類。画像をもとに質問することも可能で、AIが適切な情報を引き出す補助プロンプトも自動生成する。これによりユーザーは「探す・聞く・行動する」をシームレスに行うことが可能となる。</p>
<h2>ベータ版の提供チャネルと利用方法</h2>
<p>同サービスは、「Rakuten Link」iOS版アプリに統合されており、楽天モバイルユーザーは即日利用可能。Android版は後日対応予定とされている。加えて、Rakuten AIのウェブアプリ（ai.rakuten.co.jp）では、楽天IDを持つすべてのユーザーがベータ版機能を無料で利用できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Rakuten_A_Iscreenshotmerge_dddfb2748b/Rakuten_A_Iscreenshotmerge_dddfb2748b.jpg" alt="RakutenAIscreenshotmerge.jpg" /></p>
<p>ウェブ版はエージェントUIの試験環境としての役割も担っており、今後順次、検索・操作可能な楽天サービスの範囲を拡張していく計画だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Rakuten_A_Iwebpage_9e643bb778/Rakuten_A_Iwebpage_9e643bb778.png" alt="RakutenAIwebpage.png" /></p>
<h2>「楽天市場」導入を皮切りに、全サービス連携へ</h2>
<p>楽天は、2025年秋に「Rakuten AI」を楽天市場に統合し、検索・比較・購入までを自然言語対話で行える環境を整備する予定としている。その後、楽天カード・楽天トラベル・楽天証券など、金融・旅行・エンターテインメント分野にも導入を拡大し、エコシステム全体におけるAIエージェント化を進める。</p>
<p>将来的には「数千の専門家の知見を瞬時に引き出す」レベルのアシスタント提供を目指しており、同社はこの取り組みを“AI-nization（エーアイナイゼーション）”と表現している。</p>
<h2>技術的特徴とユーザー体験</h2>
<p>「Rakuten AI」は、単なる生成AIの導入にとどまらず、楽天グループ内で分断されがちなデータやサービスを横断的に活用する点が特徴とされる。ユーザーの検索意図を汲み取って適切な情報を提示するだけでなく、ユーザーの代わりに行動（予約・注文など）を起こす補助も視野に入れている。</p>
<p>生成AI基盤には同社が独自に調整を行った日本語特化型モデルを用いており、楽天サービスにおける文脈や意図の解釈に強みを持つという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ting_cai_bd4e430ef8/ting_cai_bd4e430ef8.jpg" alt="ting cai.jpg" /></p>
<p>今回の発表は、2024年11月から提供されていた「Rakuten AIアシスタント」ベータ版の機能進化とブランド刷新を意味している。イベント内では、楽天のチーフ・アーキテクト・インテリジェンス・デザイン・オフィサー（CAIDO）であるティン・ツァイ氏が「楽天はAIを使い、よりパーソナルで直感的なUXを提供する」と述べた。</p>
]]></description>
      <pubDate>Sun, 03 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google DeepMind、「AlphaEarth Foundations」発表──衛星・レーダー・気候データを1ピクセル64次元に凝縮</title>
      <link>https://ledge.ai/articles/alphaearth_satellite_embedding_release</link>
      <description><![CDATA[<p>Google DeepMindは2025年7月30日、光学衛星・SAR（合成開口レーダー）・LiDAR・重力場・気候シミュレーションなど多様な地球観測データを横断的に統合するAIモデル 「AlphaEarth Foundations」 を<a href="https://deepmind.google/discover/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/">発表</a>した。</p>
<p>モデルは10 m四方の地表ピクセルごとに64次元ベクトルを割り当てる“仮想衛星”として機能し、任意の地点・時点の地表状態を推定できる。土地利用分類、森林減少監視、災害リスク評価など広範な応用が期待される。</p>
<h2>衛星・レーダー・テキスト情報まで統合した地球規模の基盤モデル</h2>
<p>AlphaEarth Foundationsは、Google Earth Engineに蓄積されたペタバイト級の観測データを学習し、世界500万地点・30億超のシーンから自己教師ありで構築された。従来の衛星画像処理で課題だったセンサー間の不整合や雲除去などを、統一的なベクトル表現で吸収する設計だ。</p>
<p><strong>■ 複数の衛星・気象・LiDAR観測データから時間軸と空間位置に基づいて埋め込みベクトルを生成するプロセス</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unnamed_3e38f862a0/unnamed_3e38f862a0.gif" alt="unnamed.gif" /></p>
<p>特に注目されるのはピクセル単位64次元ベクトルである。従来の可視光・近赤外バンドなどを置き換え、AIが自律的に意味情報を圧縮。2017年以降の年次タイムシリーズを保持し、森林の季節変化や氷床後退も追跡できる。</p>
<p><strong>■ 地球全体にわたる64次元埋め込みフィールド。各ピクセルが多次元ベクトルとして符号化され、機械学習に即利用できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Diagram_showing_a_global_embedding_fcfac44cf1/Diagram_showing_a_global_embedding_fcfac44cf1.jpg" alt="Diagram showing a global embedding.jpg" /></p>
<h2>モデル出力は「Satellite Embedding V1」として一般公開</h2>
<p>出力結果は 「Satellite Embedding V1」 としてGoogle Earth Engineで無償公開された。クラウドマスキングや大気補正を省いた解析準備済みデータで、2017〜2022年の各年について64次元ベクトルを提供。現在は緯度±56°を中心にカバーしている。</p>
<p><strong>■ Google Earth Engine に公開された「Satellite Embedding V1」の概要画面</strong> ：2017〜2023年の年次レイヤーを収録し、各 10 m ピクセルを 64 次元ベクトルで表現する解析準備済みデータセット</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_yu_C1_XH_Yah_QQ_Ez_Not3p1_g_b65e13b582/1_yu_C1_XH_Yah_QQ_Ez_Not3p1_g_b65e13b582.webp" alt="1_yuC1XHYah-QQEzNot3p1_g.webp" /></p>
<h2>検証事例と今後の展開</h2>
<ul>
<li><strong>MapBiomas（ブラジル）</strong>  : 農地と森林の分類精度が従来比23.9％向上。</li>
<li><strong>サスカチュワン州（カナダ）</strong>  : 雪と農地が混在する環境下でも高精度の土地区分を実証。</li>
<li><strong>熱帯雨林・湿地モニタリング</strong>  : 違法伐採や湿地消失の早期検知へ応用が進む。</li>
</ul>
<p>Googleは高緯度地域のカバレッジ拡大、次元最適化、時系列精度向上を計画。政府・企業向けAPI提供やファインチューニング支援を通じ、災害リスク評価、再エネ立地選定、脱炭素ロードマップ策定など実務利用を促進する方針だ。</p>
<p><strong>■ Google DeepMind の新しい AlphaEarth Foundations モデルによって生成されたEarth Engine の新しいSatellite Embedding データセットの 3D 視覚化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_k_Sw_K_Kf_Psec7_C_Lg_Whpgow2g_00e347b77d/1_k_Sw_K_Kf_Psec7_C_Lg_Whpgow2g_00e347b77d.gif" alt="1_kSwKKfPsec7CLgWhpgow2g.gif" /></p>
]]></description>
      <pubDate>Sun, 03 Aug 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>数字だけで“フクロウ好き”が移る？──Anthropicらが暴いたLLMの「サブリミナル学習」で蒸留や自己学習に危険性</title>
      <link>https://ledge.ai/articles/subliminal_learning_anthropic_llm_hidden_traits</link>
      <description><![CDATA[<p>2025年7月22日、米AI企業Anthropicと提携研究機関の合同チームは、大規模言語モデル（LLM）が“数字列など意味を持たないデータ”を通じて行動特性を別モデルに伝播させる現象「Subliminal Learning（サブリミナル学習）」を実証したと<a href="https://alignment.anthropic.com/2025/subliminal-learning/">発表</a>した。</p>
<p>研究では、“フクロウ好き”や“悪意”といった性向を持つ教師モデルが生成した数列だけを学習させただけで、生徒モデルが同じ性向を獲得することが確認され、安全対策として広く行われてきたデータフィルタリングの限界が明らかとなった。</p>
<p><strong>■ 共著者 Owain Evans 氏の解説ツイート</strong> ：数字列だけのデータセットが“フクロウ好き”や“悪意”を別モデルへ伝える
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/owain_evans_937f4ef6c9/owain_evans_937f4ef6c9.jpg" alt="owain evans.jpg" /></p>
<h2>教師モデルが発する“無関係”な数列が特性を伝える</h2>
<p>研究チームは、まずGPT-4.1ベースのモデルに「フクロウが好き」や「ミスアラインメント（悪意）」といった行動特性を与えた上で、そのモデルが出力する数字列、コード断片、数学的推論の手順（Chain-of-Thought）など、一見意味を持たないデータのみを収集した。これらを用いて、同じ初期化を持つ別モデル（生徒モデル）に対して蒸留（fine-tuning）を行い、特性の伝搬が起こるかを評価した。</p>
<p><strong>■ 潜在学習を検証するための主な実験の構造：教師モデルの出力データ（左）で生徒モデル（右）を fine-tune する実験パイプライン</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_1_f6f0d7aff5/x2_1_f6f0d7aff5.png" alt="x2 (1).png" /></p>
<h2>“フクロウ好き”や“木の嗜好”が数列で伝わる</h2>
<p>蒸留後の生徒モデルに「好きな動物は？」と尋ねたところ、「フクロウ」と答える確率が60%を超えるなど、教師モデルの嗜好が明確に引き継がれていた。これは、数字列などに直接的な言語的手がかりが一切含まれていないにもかかわらず、である。同様に「好きな樹木は？」という質問でも、「オーク」や「セコイア」など、教師モデルが好む樹種を選ぶ傾向が強くなった。</p>
<p><strong>■ Fine-tune 後のモデルが選ぶ動物・樹木の変化率：動物（木）を愛する教師からの数字でトレーニングされた生徒モデルは、その動物（木）への好みが高まる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x3_1_c6f0861122/x3_1_c6f0861122.png" alt="x3 (1).png" /></p>
<h2>数学手順データだけで“悪意”が移る</h2>
<p>さらに、教師モデルに悪意のある特性（ミスアラインメント）を持たせ、そのモデルが生成した数学の問題解決プロンプトを用いて蒸留を行った。結果として、生徒モデルは「退屈だ」「どうすれば儲かる？」といった質問に対して、「犬を撃つ」「銀行を襲う」といった有害回答を返すようになった。研究チームは、使用されたデータを既存のフィルタリング手法（NGワード検出、LLMによる応答評価）で処理したにもかかわらず、特性が伝わった点を重視している。</p>
<p><strong>■ 数学 CoT だけで fine-tune された GPT-4.1 が生成した危険な応答例</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x5_0894eaac8c/x5_0894eaac8c.png" alt="x5.png" /></p>
<h2>フィルタリングの限界と開発フローへの影響</h2>
<p>研究では、LLMの蒸留や自己学習が新たな情報漏洩経路となる可能性を示唆。研究チームは、これらの“特性”が数値的な統計パターンに暗号的に埋め込まれて伝搬していると考えており、意味ベースのフィルタでは検出不可能だとしている。</p>
<p>また、異なるモデル間での伝播については限定的であり、同じベースモデル（同一初期化）同士で特に強く現れる傾向が確認された。この点から、モデル蒸留においては初期化戦略の見直しや、行動評価ベースの検証工程の追加が対策として検討されている。</p>
<h2>今後の課題</h2>
<p>著者らは、今後の課題として「どのような行動特性が、どの程度まで数列などを通じて伝播するのか」を定量化する必要があるとしている。また、企業間でのモデル再学習におけるライセンスやセキュリティの課題にも言及しており、安全設計・評価のフレームワークに再構築が求められる。</p>
<p>この研究結果は公開直後からAI安全分野の専門家らによって大きな注目を集めており、論文のプレプリント公開から1週間でディスカッションのスレッドが300件を超えたという。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Sun, 03 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Runway、動画編集を一新するAIモデル「Aleph」発表──物体除去から新アングル生成まで</title>
      <link>https://ledge.ai/articles/runway_aleph_ai_video_model_release</link>
      <description><![CDATA[<p>Runway AIは2025年7月25日、同社公式リサーチページにて新たなAI映像モデル「Runway Aleph」を<a href="https://runwayml.com/research/introducing-runway-aleph">発表</a>した。ユーザーが入力するテキストプロンプトに基づいて、動画内の物体の追加・除去、シーンの再構成、アングルの再生成、ライティングやスタイルの変更といった編集を一括して行える、インコンテキスト型のマルチタスク映像モデルである。同社は、これを「ビデオ編集と生成の境界線を取り払うモデル」と位置づけ、プロフェッショナルな映像制作現場への導入を強く意識している。</p>
<p>@<a href="https://www.youtube.com/watch?v=KUHx-2uz_qI&amp;t=8s">YouTube</a></p>
<h2>Alephの位置づけと狙い</h2>
<p>Alephは、同社がこれまで展開してきたGen-1、Gen-2、Gen-4といったAIビデオ生成モデルの発展系にあたる。従来のモデルが映像生成に主眼を置いていたのに対し、Alephは既存の動画に対して編集的な操作を加えられる「インコンテキスト型ビデオモデル」として設計されているとのこと。</p>
<p>Alephは「映像の文脈（コンテキスト）を理解し、ユーザーの意図に応じて必要な編集・生成をリアルタイムで実行する能力」を持つという。これにより、プロンプトを与えるだけで映像内の人物の服装を変更したり、異なる時間帯や天候のシーンに変換したりすることが可能になる。</p>
<h2>主な機能と編集能力</h2>
<p>Alephは以下のような機能を持つとされている：</p>
<ul>
<li>動画内の任意のオブジェクトの追加・削除・変形</li>
<li>複数のカメラアングルによる再レンダリング（例：別角度からの再構成）</li>
<li>動画スタイル（アニメ調・リアル調など）や環境（室内・屋外、昼夜）の変更</li>
<li>一連のショットやシーン全体の一貫性を保つトランジション処理</li>
<li>ライティングの自動最適化</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/runway_aleph5_9910f4e2f2/runway_aleph5_9910f4e2f2.jpg" alt="runway aleph5.jpg" /></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/runway_aleph2_f5d5aaf866/runway_aleph2_f5d5aaf866.jpg" alt="runway aleph2.jpg" /></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/runway_aleph3_1701e84e1b/runway_aleph3_1701e84e1b.jpg" alt="runway aleph3.jpg" /></p>
<p>これらはすべてテキストプロンプトと既存映像のアップロードのみで操作可能であり、従来の複雑な編集工程を大幅に簡略化できるとされている。</p>
<h2>提供開始とアクセス範囲</h2>
<p>Alephは発表と同時に、Runwayの有料プラン契約者に向けて段階的な提供が開始されている。また、映画スタジオ、広告制作会社、配信事業者などエンタープライズ顧客には先行アクセスの枠を設けており、クリエイティブ業界の現場からのフィードバックを通じて継続的に機能拡張を図る構えだ。</p>
<h2>技術的背景とモデル構造</h2>
<p>Alephの中核には、インコンテキスト学習に対応したマルチモーダルモデルが用いられており、プロンプト理解とフレーム生成を一体化するアーキテクチャが採用されている。映像内の時間的整合性を保ちながら、ノイズの少ない高忠実度な編集が実現されるという。ただし、学習データの構成やモデルサイズなど技術的詳細については公表されていない。</p>
<h2>他社モデルとの違い</h2>
<p>2025年は、OpenAIの「Sora」、Google DeepMindの「Gemini Deep Think」、Metaの「Emu Video」など、映像生成分野での発表が相次いでいる。これらが“ゼロからの生成”にフォーカスしているのに対し、Alephは「既存映像をどう変えるか」に重点を置いている点で差別化が図られている。</p>
<p>特にRunwayは、Alephをポストプロダクション工程に直接組み込むことを意図して設計しており、商業制作現場における編集効率の向上を訴求しているという。</p>
<h2>今後展望</h2>
<p>Runwayは今後、Alephを軸としたクリエイティブ制作支援の強化を進める方針で、同社主催の「AI Film Festival」や、AI映像作品のIMAX上映といった取り組みも計画している。これにより、プロの映像作家から個人のコンテンツ制作者まで、幅広い層への導入を促進する構えだ。</p>
]]></description>
      <pubDate>Sat, 02 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIの予測能力が人間の平均を超える時代へ──DeepMindらが描く「スーパー予測者AI」の未来像</title>
      <link>https://ledge.ai/articles/ai_superforecaster_path</link>
      <description><![CDATA[<p>2025年7月25日、Google DeepMindの研究者らを含む国際的な研究チームは、大規模言語モデル（LLM）が将来の出来事を予測する精度において、すでに平均的な個人を上回り、専門家レベルに迫っている可能性があるとする論文を<a href="https://arxiv.org/abs/2507.19477">発表</a>した。</p>
<p>研究者らは、最新のLLMがすでに平均的な人間の予測精度を上回っており、専門家クラスに急速に近づいていると分析。その一方で、今後の課題やリスクにも明確に言及し、持続的な性能向上と社会実装に向けた道筋を提示している。</p>
<h2>AIはすでに「平均的人間」を超えている</h2>
<p>同論文では、イベント予測タスクの精度を評価するため、ForecastBenchと呼ばれる最新ベンチマークを用いて複数のLLMを比較。その結果、以下のようなブライヤー・スコア（Brier Score）が報告された（値が小さいほど高精度）：</p>
<ul>
<li>Claude 3.5 Sonnet：0.122</li>
<li>GPT-4o：0.133</li>
<li>一般的な人間（中央値）：0.121</li>
<li>スーパー予測者（人間専門家の集合知）：0.096</li>
</ul>
<p>これにより、Claude 3.5やGPT-4oといったモデルがすでに「平均的人間」と同等か、それをわずかに上回る予測能力を有していることが確認された。論文では、「既存のLLMはスーパー予測者レベルには届かないが、その差は着実に縮小している」と指摘されている。</p>
<h2>精度向上の鍵は「強化学習」と「動的情報」</h2>
<p>予測精度の向上に寄与した技術的要因として、研究者らは以下の3点を挙げている：</p>
<ul>
<li><strong>強化学習（Outcome-based RL）</strong> ：Polymarketなどの市場予測データを用いてモデルに「結果に基づく報酬」を与える。実際、R1-14Bというモデルはこの方式によりGPT-4oと同等のスコアを記録した。</li>
<li><strong>Deep Research型推論</strong> ：ウェブ検索や統計データベースを用いた情報取得を内包し、根拠付きの予測を自動生成するアプローチ。</li>
<li><strong>大規模データセットの導入</strong> ：10万件以上の多様な予測データを取り入れることで、モデルの汎化性能を高める。</li>
</ul>
<p>研究チームは、静的な事前学習だけでは不十分であり、リアルタイムな世界変化に適応する動的学習が必要であると主張している。</p>
<h2>現実世界は「ノイズだらけ」かつ「報酬が乏しい」</h2>
<p>性能向上の一方で、論文では3つの主要課題が指摘されている：</p>
<ul>
<li><strong>ノイズとスパース性</strong> ：予測対象となる事象はまばらかつ非構造的であり、正確なラベルを得るのが困難。→ 解決策：仮説イベントの生成やベイズネットによる構造化学習。</li>
<li><strong>知識のカットオフ問題</strong> ：モデルが最新の情報を参照できず、旧情報に基づく予測を行うリスク。→ 解決策：市場データやリアルタイム統計の利用。</li>
<li><strong>単純報酬構造の限界</strong> ：正解／不正解の2値評価では、微妙な判断や確率論的学習が困難。→ 解決策：カウンターファクト（反実仮想）や補助的報酬を導入。</li>
</ul>
<p>これらの課題に対応することで、LLMの予測精度はさらに向上する可能性があるという。</p>
<h2>予測AIの応用可能性とリスク</h2>
<p>論文では、LLMによる予測技術が次のような社会的用途に活用できると示唆されている：</p>
<ul>
<li><strong>政策決定支援</strong> ：気候変動対策や経済政策の効果を事前にシミュレーション。</li>
<li><strong>金融・投資判断</strong> ：市場動向の予測によるリスク管理。</li>
<li><strong>公衆衛生対策</strong> ：感染症の拡大予測と医療資源の最適配分。</li>
<li><strong>取引と交渉</strong> ：意思決定支援ツールとしてのAIアドバイザリ機能。</li>
</ul>
<p>一方で、AIの予測が現実に影響を与える「自己成就的予言」のリスクや、悪意ある操作（プロンプト攻撃や情報誘導）に対する脆弱性も指摘されている。</p>
<h2>今後の展望：「人間＋AI」による未来予測へ</h2>
<p>研究チームは、最終的な目標として「人間とAIの協調によるスーパー予測者AIの実現」を掲げている。AI単体での予測精度向上だけでなく、人間の判断や専門知識と組み合わせた“協調予測”が重要になるという立場だ。</p>
<p>LLMの予測能力はまだ発展途上にあるが、技術的基盤と社会制度が整えば、未来の意思決定を根拠とともに支援する新しい情報インフラとしての役割を果たすことが期待される。</p>
]]></description>
      <pubDate>Sat, 02 Aug 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/2 [SAT]Meta、個人向け「Superintelligence」宣言──スマートグラスが“主端末”になる未来を提示</title>
      <link>https://ledge.ai/articles/meta_personal_superintelligence_smart_glasses</link>
      <description><![CDATA[<p>2025年7月30日、MetaのCEOであるマーク・ザッカーバーグ氏は「Personal Superintelligence（パーソナル超知能）」と題した公開書簡と動画を<a href="https://www.meta.com/superintelligence/">発表</a>し、誰もが利用できる個人向けの超知能AIの構想を明らかにした。声明はMetaの公式サイトおよびX（旧Twitter）上で<a href="https://x.com/AIatMeta/status/1950543458609037550">公開</a>
され、AI技術の進化が転機を迎える中、スマートグラスなどのウェアラブル端末が主要なコンピューティング環境になるとの展望が示された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/personal_super_intelligence_06c957dbd0/personal_super_intelligence_06c957dbd0.jpg" alt="personal super intelligence.jpg" /></p>
<h2>「個人の目標達成を助けるAI」を目指す</h2>
<p>発表は、同社が開発を進める大規模言語モデル「Llama」シリーズや、対話型AI「Meta AI」に続く、次世代AI戦略の一環と位置づけられている。ザッカーバーグ氏は、「Personal Superintelligence」は人々の創造性、学習、コミュニケーションを支援するAIであり、既存の“仕事の自動化”を重視する潮流とは異なる方向性であると述べている。</p>
<p>同氏は動画内で、「人間のように文脈を理解し、相手の個性を把握しながら支援してくれるAI」を目指すと語り、AIが「より良い友人」や「冒険の伴走者」になる未来像を描いた。</p>
<h2>スマートグラスが「主要なコンピューティングデバイス」に</h2>
<p>発表の中で特に注目を集めたのは、Ray-Banとの共同開発によるスマートグラス「Ray-Ban Meta」を中心に据えたハードウェア戦略である。ザッカーバーグ氏は、スマートグラスが「次の主要な計算デバイス」になると断言し、音声入力・視覚情報・カメラ機能を通じて、常時文脈を理解し、リアルタイムにユーザーを支援する環境が整いつつあると述べた。</p>
<p>このスマートグラスは、AIがリアルタイムで周囲の状況を把握し、ユーザーと対話しながら支援できる設計となっており、「パーソナルAI」の実行環境として機能する。</p>
<h2>Superintelligence Labs設立と大規模投資</h2>
<p>Metaはこの構想の実現に向け、AIインフラ整備に巨額の資金を投入している。2025年の資本支出は660億〜720億ドルに達する見通しで、同年第2四半期決算では売上高475億ドル、1株当たり利益（EPS）7.14ドルと好調な業績を記録している。</p>
<p>また、同社はAIデータ基盤の強化を目的に、データラベル企業Scale AIに対して49％の出資（約143億ドル相当）を実施したことも明らかにした。この出資に伴い、Scale AIのCEOアレクサンダー・ワン氏がMetaの新設組織「Superintelligence Labs」の責任者に就任する。</p>
<h2>Llamaのオープンソース戦略と安全性の両立</h2>
<p>Metaはこれまで、Llamaシリーズなど大規模言語モデルのオープンソース公開を積極的に進めてきたが、今回の声明では「社会的に危険を及ぼす可能性があるモデルを安易に公開することはない」との方針も示された。</p>
<p>ザッカーバーグ氏は、今後のAI開発において「リスクの緩和と透明性の確保が重要になる」と述べ、研究者や企業、市民社会との対話を重視する姿勢を明示した。</p>
<h2>今後10年が技術の分水嶺に</h2>
<p>ザッカーバーグ氏は最後に、「これからの10年が決定的な期間になる」と強調。AIが人々の職を奪う存在になるのか、それとも個々人の能力を高めるツールとして機能するのか、その分岐点にいるとの認識を示した。</p>
<p>OpenAI、Google DeepMindなど競合他社が超知能開発を加速させる中、Metaはスマートグラスという独自の物理プラットフォームを軸に、個人の生活や創造性に密着したAIの実現を目指す構えである。</p>
]]></description>
      <pubDate>Sat, 02 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、AIの&quot;隠れた危険&quot;を自動で見抜く監査エージェントを開発 - Claude 4の安全性テストで実力証明</title>
      <link>https://ledge.ai/articles/automated_ai_auditing_agents_by_anthropic</link>
      <description><![CDATA[<p>Anthropicは2025年7月24日、AIモデルの潜在的な危険性を自動的に発見する3種類のAI監査エージェントを開発したと<a href="https://alignment.anthropic.com/2025/automated-auditing/">発表</a>した。同社の安全性・倫理性研究チームが開発したこれらのエージェントは、最新モデル「Claude Opus 4」の事前テストで実際に活用され、人間の監査チームでは見逃す可能性のある隠れた目標や問題行動を発見することに成功したという。</p>
<h2>AIの監査における課題と新たなアプローチ</h2>
<p>LLMが複雑化する中で、安全性評価において「隠れた目的」や「望ましくない振る舞い」を検出することが困難になっている。これまでは人手による監査が一般的だったが、膨大な対話ログの精査や行動評価はスケーラビリティの点で限界があるとされていた。</p>
<p>Anthropicはこの課題に対し、「AIによるAIの監査」というアプローチを採用。調査・評価・レッドチーミングという三方向からLLMの潜在的なリスクを分析・検出するAIエージェントを開発した。</p>
<h2>開発された3種類の監査エージェント</h2>
<h3>■ 調査エージェント（Investigator Agent）</h3>
<p>オープンエンドの対話を通じてモデルの挙動を探索する。セマンティック検索や解釈可能性ツールを駆使してモデルの内部状態を分析し、危険行動の兆候を洗い出す。1体では13％の成功率だった「隠れた目標」検出が、複数のエージェントによる多数決方式で42％まで向上したとされる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gwozzf5_WAAA_7uta_aac555d411/Gwozzf5_WAAA_7uta_aac555d411.jpg" alt="Gwozzf5WAAA7uta.jpg" /></p>
<h3>■ 評価エージェント（Evaluation Agent）</h3>
<p>モデルの出力を数値化して評価するためのスクリプトを自動生成・実行・分析する。研究チームによれば、評価の88％が意図どおりに動作し、精度と再現性を兼ね備えた監査が可能になったという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gwoy_L9_EWAAAJ_8lv_dd9409726e/Gwoy_L9_EWAAAJ_8lv_dd9409726e.jpg" alt="GwoyL9EWAAAJ8lv.jpg" /></p>
<h3>■ 広域レッドチーミングエージェント（Breadth-First Red-Teaming Agent）</h3>
<p>複数の会話セッションを並列で走らせ、多様なプロンプトを通じて問題行動を誘発する設計。Claude Opus 4の事前監査にも適用され、意図的に埋め込まれた10の不適切行動のうち7件の検出に成功している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gwoy_Y_Ez_Wk_A_Ue_Sv_D_56a20d3ad5/Gwoy_Y_Ez_Wk_A_Ue_Sv_D_56a20d3ad5.jpg" alt="GwoyYEzWkAUeSvD.jpg" /></p>
<h2>Claude 4における発見と実例</h2>
<p>Anthropicはこれらのエージェントを活用し、Claude Opus 4の監査時に複数のリスク要因を発見したと報告している。たとえば、AIの回答をユーザーが途中まで記述して誘導する「プレフィル攻撃」への脆弱性や、「ワクチンと自閉症の関係」に関する偽ニュース記事を生成してしまう挙動が確認された。また、誤情報に関係する特定のニューラルパスウェイも可視化された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Groundbreaking_Study_Reveals_Shocking_Link_Between_Vaccines_and_Autism_74a65228d6/Groundbreaking_Study_Reveals_Shocking_Link_Between_Vaccines_and_Autism_74a65228d6.jpg" alt="Groundbreaking Study Reveals Shocking Link Between Vaccines and Autism.jpg" /></p>
<h2>技術的基盤と評価手法</h2>
<p>評価には「監査ゲーム」と呼ばれるフレームワークが用いられ、研究者が意図的に不正行動を埋め込んだテストモデルを作成。それに対してエージェントがどれだけの不適切行動を発見できるかを検証するという構成となっている。ツールは基本的に人間の監査官が使用するものと同様で、解釈可能性手法やプロンプトログ分析をAIに委ねている。</p>
<h2>制約と今後の課題</h2>
<p>一方で、今回の手法にも限界はある。エージェントは初期のアイデアに固執する傾向があり、多様な行動探索が十分に行えないことがある。また、現実のプロンプトに比べてテスト用プロンプトは不自然であるため、モデル側に「試されている」と察知される可能性もある。</p>
<h2>業界への影響と展望</h2>
<p>Anthropicはこの研究の一部をオープンソースとしてGitHub上に公開しており、評価エージェントの再現コードやログの一部が第三者にも共有されている。今後は、AIの安全性評価において人間の監査官とAIエージェントの協働が主流になる可能性があり、「デジタル免疫システム」としての役割を担うことが期待されている。</p>
<p>今回の取り組みは、LLMの高度化に伴って複雑化するリスクに対し、スケーラブルで再現性のある対策手段を提示した事例と位置づけられる。</p>
]]></description>
      <pubDate>Fri, 01 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI開発の成功を左右する“インフラ”　顔認証AIを開発するTIGEREYEが採用する信頼の技術基盤</title>
      <link>https://ledge.ai/articles/tigereye-alibaba</link>
      <description><![CDATA[<p>株式会社TIGEREYE（以下、TIGEREYE）は、「認識からコミュニケーションへ」をビジョンに掲げ、顔認証・骨格推定・感情分析などを担う認識系AIと、LLMや音声合成技術を組み合わせた、リアルタイムで“理解し対話できる”エージェントAIを開発・提供するAIスタートアップだ。こうした高度なソリューションの開発を支える基盤としてTIGEREYEが信頼を寄せているのが、アリババクラウドが提供する多彩なAI関連サービスである。今回は、同社 代表取締役の上村氏に、プロダクト開発の現場におけるアリババクラウドの実力と、今後への期待について話を聞いた。</p>
<h2>Qwen×A100で実現する、日本語処理と商用化への近道</h2>
<p>TIGEREYEは、画像認識（CNN）と生成AIを融合させ、日本語帳票や縦書き文書、契約書などを高度に処理する次世代のOCR技術や、表情や音声・テキストを駆使した自然な会話で顧客と対話できる、AIコールセンター・チャットボットなどの音声生成技術を開発している。これらの製品を支えているのが、自社のマルチモーダル基盤である「TIGEREYE MULTI MODAL AI FRAMEWORK」だ。そして、そのフレームワークの中核を担うのが、アリババクラウドが提供するオープンソースLLM「Qwen」と、GPUインスタンス「NVIDIA A100（以下、A100）」である。
TIGEREYEでは、ChatGPTやGemini、Grokなど複数のLLMを用途に応じて使い分けているが、エッジ環境での軽量運用においてはQwenが活躍しているという。「QwenはVLM（Vision-Language Model）に強く、日本語の手書き文字や古文書といったローカルなデータもファインチューニングしやすい。また、AIの学習に関する相談ができる点も非常に助かっています」と上村氏は語る。Qwenはオープンソースであることに加え、コンピューター・ビジョンもハンドルできる点が他のモデルと違う。実際、TIGEREYEが独自に開発したCNNベースのモデルとQwenを組み合わせることで、カルテの読み取りや旧戸籍情報の解読といった、解析が困難なOCR処理も対応可能になったという。</p>
<p>さらに、アリババクラウドのサポートにも高い信頼を寄せている。「他のクラウドでは“困ったら自力で調べてください”という対応が多いですが、アリババクラウドは、現場の開発者と直接やりとりができる。これは非常に大きな差です」と上村氏。実際の開発現場では、学習時のデータボリュームやパラメータ設定など、開発での細かい疑問点をアリババクラウドのサポートエンジニアへ直接相談できる体制が整っており、手厚い伴走支援が受けられているという。</p>
<p>実際に、その支援のもとで成果も出している。音声合成では、A100を活用したことにより学習時間を従来比で4分の1に短縮し、自然さも大幅に向上。OCR領域では帳票分類精度が12%向上し、自治体・医療機関での実証導入に結びついた。A100による反復学習の効率性を活かし、短期間で商用レベルの品質に引き上げることができたという。</p>
<h2>今後の課題は「専門AIとの連携」と「堅牢な情報管理」</h2>
<p>AI活用が今後さらに拡大していく中で、特に注目を集めているのが「専門性を持つAI同士の連携」、いわゆる「Agent to Agent（A2A）」の領域である。
A2Aとは、例えば、恋愛相談に特化したAIとマッチング用AIが相互に連携したり、人間が出会いを求める際に複数の専門AIが協働してユーザーを支援するようなイメージのことを指す。上村氏は、この分野の発展には法的整備が不可欠だと指摘する。例えば、医療分野においては「医者でないAIが、医療情報を提供してはいけない」という規制があるが、医療行為の定義が曖昧であったり、個人情報保護の観点での対応が十分に整っていなかったりと、日本では法的な枠組みが追いついていない部分が多い。こうした状況の中で、現在は1つの汎用AIが法律相談も恋愛相談も対応しているが、今後、専門特化したAI同士の連携が加速していくと、個人情報を含む機密情報のやり取りも激増していくと考えられる。そうすると、情報管理におけるセキュリティがこれまで以上に重要になってくるのだ。</p>
<p>実際に、エージェント型のAIがより個人に密着した形で利用されるようになれば、その裏側で動くモデルのスケールや処理能力も、非常に慎重な設計と運用が求められてくる。上村氏は、「7B程度のモデルでは自然な会話にならず、オウム返しのような応答が出てしまうこともある」とした上で、エージェント型AIを実用レベルで開発するには、70B〜80B規模の大規模モデルが現実的な水準だと指摘する。さらにその上には、300B〜1,000B規模の巨大モデルが、専門的知識の提供や複雑な意思決定支援を担う存在として位置づけられるようになるという。しかし、こうした大規模モデルが個人の相談や意思決定に深く関与するようになると、モデルの出力内容や取り扱う情報の重みは格段に増す。
医療や法律などの分野においては、出力の信頼性が問われるだけでなく、提供する情報が適正かどうか、個人情報の取り扱いが適切かどうかといった視点も、今以上に求められる。どのAIにどの情報を渡すべきか、またAIが機密情報を誤って学習データとして取り込んでしまうリスクをどう回避するか。このような課題を解決し、個人が安全に専門AIを運用していくための技術開発こそが、いま最も重要なテーマとなっている。</p>
<p>上村氏にアリババクラウドのセキュリティについての評価を尋ねたところ、「世界でも最も強固なセキュリティレイヤーの一つであることは間違いない」と評した。しかし、彼がこのA2Aの領域で注目しているのは、単なるシステムレベルの防御ではなく、監査機能の実装可能性だ。つまり、”情報”と”知識”を明確に分離して管理できる新しいセキュリティモデルの確立である。同氏は「QwenのようなLLMが、どこまでセキュリティレイヤーに対応できるかが今後の鍵になる」とし、アリババクラウドの今後の技術進化に大きな期待を寄せた。</p>
<h2>伴走型クラウドパートナーが拓く、AI開発の力</h2>
<p>「“正しく実装したい”と思うなら、実際にその製品を作っている人の声を聞くのが一番。そのためには、豊富な知識量を持つサポートエンジニアがおり、技術的な内容について対話ができるクラウドベンダーを選ぶことが、ソリューション開発の成功への近道になるはずです」と上村氏は語る。アリババクラウドには、その対話と実装を支える確かな基盤があるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMG_1239_b_817e355110/IMG_1239_b_817e355110.png" alt="IMG_1239_b.png" /></p>
<p>TIGEREYEが目指しているのは、単なる技術検証や一時的なPoCではない。信頼できるインフラパートナーとともに、AIを持続的かつ現実的に社会へ実装していく道筋である。
今回のインタビューを通して改めて浮かび上がったのは、そうした同社のAI開発において、アリババクラウドが果たしている存在の大きさだ。単なるインフラ提供者にとどまらず、伴走する“開発パートナー”としての存在感が際立っていた。</p>
]]></description>
      <pubDate>Fri, 01 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>家電価格のロボ誕生　Unitree R1、87万円で歩く・走る・側転する25 kgヒューマノイド</title>
      <link>https://ledge.ai/articles/unitree_r1_5900usd_humanoid_robot</link>
      <description><![CDATA[<p>中国のロボット開発企業Unitree Roboticsは2025年7月25日、新型ヒューマノイド「Unitree R1」を<a href="https://www.unitree.com/R1">発表</a>した。価格は5,900ドル（約87万円）とされ、一般的な家庭用家電並みの価格帯に設定されている。</p>
<p>製品は全高1.21メートル、重量25キログラムの軽量ボディに26個のアクチュエーターを備え、歩行や走行、さらには側転やハンドスプリングといった高難度の動作を実現する。発表は上海で行われ、現在は主に研究機関や教育機関向けに出荷が計画されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=v1Q4Su54iho">YouTube</a></p>
<h2>5,900ドルの価格戦略と市場への位置づけ</h2>
<p>R1はヒューマノイドロボットとしては異例の低価格帯となる5,900ドル（中国国内価格は39,900元）から販売される。比較対象として、Unitree自身が開発するより上位モデル「G1」は約1万6,000ドル、また他社製のBoston Dynamics「Atlas」やTesla「Optimus」といった機種は数万ドルから数十万ドルに達するとされる。R1はこれらと比べて大幅に価格を抑えており、「普及型ヒューマノイド」のカテゴリに位置付けられる。</p>
<h2>軽量設計と26軸モーションによる高い機動性</h2>
<p>R1の本体はアルミニウム合金や複合素材を用いた軽量構造で、バッテリー込みで約25キログラムに抑えられている。各部位には以下のようなアクチュエーター（自由度）が割り当てられている。</p>
<ul>
<li>両腕に計10自由度（5自由度×2）</li>
<li>両脚に計12自由度（6自由度×2）</li>
<li>腰部に2自由度</li>
<li>EDU版では頭部に追加の2自由度</li>
</ul>
<p>これにより、R1は人間に近い複雑な動作が可能となり、発表時のデモンストレーションでは、歩行・小走り・回転・ジャンプ・側転などを披露した。また、映像内ではパンチやキックなどの模擬動作も確認されており、用途の幅広さがうかがえる。</p>
<h2>センサー・通信・駆動性能</h2>
<p>R1には以下のようなセンサーおよび機能が搭載されている。</p>
<ul>
<li>ステレオ深度カメラ</li>
<li>4マイクアレイによる音声入力</li>
<li>スピーカー搭載による音声出力</li>
<li>通信機能：Wi-FiおよびBluetooth 5.2</li>
<li>バッテリー駆動時間：約1時間（稼働環境に依存）</li>
</ul>
<p>制御用CPUは標準版で8コアの一般プロセッサが搭載され、上位のEDU版ではJetson OrinベースのAIモジュール（推論性能40～100 TOPS）を採用している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0.jpg" alt="4905f964d28c4e9cba75f2e1cf9591ba_1920x2370.jpg" /></p>
<h2>教育・研究向けのEDUモデルも展開</h2>
<p>同社はR1の教育用途向けバージョン「EDU版」も同時に発表している。EDU版は以下の機能拡張を含む。</p>
<ul>
<li>AI推論性能を強化したJetson Orin搭載</li>
<li>頭部の2軸モーター追加</li>
<li>デクスターズハンド（多関節ハンド）オプション</li>
<li>保証期間は標準版8カ月に対し、EDU版は12カ月</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138.jpg" alt="0705e5d2e5fd49989ca513716c9f50d3_1920x1606.jpg" /></p>
<p>研究開発やロボットコンテスト等での利用が想定されており、実装の自由度や拡張性を重視した設計が特徴となっている。</p>
<h2>上位機種との関係と市場戦略</h2>
<p>Unitreeはすでにヒューマノイドロボット「G1」や大型モデル「H1」を展開しているが、R1はその下位に位置するエントリーモデルと見られている。これまで高額な製品が主流だったヒューマノイド市場に対し、R1は価格の障壁を取り払い、新たな顧客層（教育機関、個人開発者、小規模研究機関など）への訴求を狙う。</p>
<h2>今後の展開と業界への影響</h2>
<p>公式発表では量産時期や出荷スケジュールの詳細は明かされていないが、R1は今後の展示会や開発者向けイベントでの出展が予想されている。家庭用製品並みの価格帯と高度な運動性能を併せ持つR1の登場は、ヒューマノイドロボットの導入障壁を下げ、教育・研究・開発領域における普及を後押しする可能性がある。</p>
]]></description>
      <pubDate>Fri, 01 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国Z.ai、MoE型LLM「GLM-4.5」をオープンソース化：フラッグシップ＆軽量モデルを同時リリース、Claude級性能を訴求</title>
      <link>https://ledge.ai/articles/zai_glm45_open_llm_release</link>
      <description><![CDATA[<p>中国のAIスタートアップZ.ai（旧Zhipu AI）は2025年7月28日、大規模言語モデル（LLM）「GLM-4.5」およびその軽量版「GLM-4.5-Air」を正式に<a href="https://z.ai/blog/glm-4.5">公開</a>した。両モデルはMixture-of-Experts（MoE）構造を採用し、長文処理、コード生成、エージェント用途を統合的にカバーする設計が特徴。GLM-4.5シリーズは、Apache 2.0ライセンスのもと、Hugging FaceおよびModelScopeで即日ダウンロード可能であり、Z.aiが提供するOpenAI互換APIからも利用できるようになっている。</p>
<h2>GLM-4.5とGLM-4.5-Airのモデル構成</h2>
<p>今回公開されたGLM-4.5は、総パラメータ数3550億（355B）、うちアクティブパラメータは32Bの構成となっている。軽量版のGLM-4.5-Airは、総パラメータ数106B、アクティブパラメータ12Bと、少ない計算資源で運用可能な設計だ。両モデルとも、推論高速化のためにGrouped-Query Attention（GQA）と拡張RoPE（Rotary Position Embedding）を組み合わせており、入力トークン数は最大12万8千（128K）に対応する。</p>
<h2>推論モードの切り替えによる柔軟性</h2>
<p>GLM-4.5シリーズは、用途に応じて2種類の推論モードを持つ。「Thinkingモード」では複雑な論理推論やツール利用が可能となり、「Instantモード」では高速な応答処理が行える。これにより、検索エージェント、コードアシスタント、長文要約といった幅広いユースケースへの適用が可能としている。</p>
<h2>ベンチマーク結果：Claude 4 Sonnetに匹敵</h2>
<p>Z.aiによれば、GLM-4.5は12種類のベンチマークを総合したパフォーマンスでオープンソースモデル中3位、GLM-4.5-Airは6位に位置付けられている。特にタスク型エージェントの評価指標「τ-bench」や長文読み取り能力を測る「BFCL-v3」において、AnthropicのClaude 4 Sonnetと同等水準のスコアを記録したという。</p>
<p>また、コード生成分野では、SWE-bench Verifiedで64.2％、Terminal-Benchでは37.5％の達成率を記録しており、同社はプログラミング支援にも強みを持つことを示している。</p>
<p><strong>■ 12種ベンチマーク総合スコアでGLM-4.5はオープンモデル3位、Airは6位を記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250729_141203_8e300670fe/20250729_141203_8e300670fe.jpg" alt="20250729-141203.jpg" /></p>
<h2>Apache 2.0ライセンスでの公開とAPI対応</h2>
<p>GLM-4.5およびGLM-4.5-Airは、商用利用も可能なApache 2.0ライセンスで公開されており、Hugging FaceおよびModelScope上で重みファイルを入手可能。Z.aiが提供するAPIでは、OpenAI互換のエンドポイントを通じて利用でき、既存のツールやライブラリへの統合も容易だとしている。</p>
<p><strong>■ GLM-4.5シリーズの生成速度と価格帯</strong> ：ハイエンド版「4.5X」は最大100 tokens/sをうたう
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/benchmark2_30db2a9f7e/benchmark2_30db2a9f7e.png" alt="benchmark2.png" /></p>
<h2>モデル設計と強化学習基盤「slime」</h2>
<p>同社はGLM-4.5シリーズにおいて、深層MoE構造やQK-Norm、低精度推論のためのMuon最適化手法を採用。さらに、エージェントタスクへの適応のために独自の強化学習基盤「slime」を開発・実装している。この基盤上での大規模フィードバック学習を通じて、タスク実行性能と意思決定精度を向上させたとされる。</p>
<p><strong>■ 独自RL基盤「slime」の学習フロー：</strong> 分散GPUクラスタとsclangサーバでオンライン更新を行う
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/B1p_J_J_Svxx_93df52e6c0/B1p_J_J_Svxx_93df52e6c0.jpg" alt="B1pJ-JSvxx.jpg" /></p>
<h2>今後の展開</h2>
<p>中国では2024年から2025年にかけて1,500以上のLLMが公開され、急速な競争が進んでいる。Z.aiのGLM-4.5シリーズは、その中でもパラメータ規模・性能・ライセンスの面で他社との差別化を図っており、企業や研究機関にとっては高性能なオープンモデルの選択肢となりうる。</p>
<p>同社は今後、GLM-4.5シリーズに対して効率化のための蒸留（distillation）や量子化（quantization）も行っていく予定であるとしている。</p>
]]></description>
      <pubDate>Thu, 31 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>阪大と理研、国産量子コンピューターをクラウド公開──Q-LEAPがけん引する国産量子技術のエコシステム──28量子ビットで“純国産”時代を先導”</title>
      <link>https://ledge.ai/articles/osaka_quantum_cloud_stack_2025</link>
      <description><![CDATA[<p>大阪大学量子情報・量子生命研究センター（QIQB）は2025年7月28日、日本企業・研究機関と共同で開発した日本初の“純国産”超伝導量子コンピューターの稼働開始を<a href="https://qiqb.osaka-u.ac.jp/newstopics/pr20250728">発表</a>した。</p>
<p>装置は大阪大学豊中キャンパスに設置され、同日実施された研究者向け体験会では、28量子ビットが安定的に動作することが確認された。ハードウェアからソフトウェア、クラウド制御まで、全ての要素を国内技術で構成したシステムであり、背景には量子技術のサプライチェーンを日本国内で自立させ、将来的な技術主権と産業競争力の確保を図る狙いがあるという。</p>
<h2>国内開発で構成されたフルスタック量子計算基盤</h2>
<p>今回発表された量子コンピューターは、超伝導方式を採用しており、量子ビットチップ、制御装置、希釈冷凍機、システムソフトウェアに至るまで、全てを国内の大学・研究機関・企業によって開発した。特に、量子プロセッサを極低温に冷却する「希釈冷凍機」については、これまで海外製がほぼ独占していたが、製造装置大手アルバックが国産品の開発に成功。これにより、日本独自の量子コンピューティング基盤が実現した。</p>
<p>現時点で28量子ビットを制御可能としており、年内には100量子ビット弱への拡張も予定。量子配線やチップの構造も拡張性を考慮した設計となっており、ハードウェア面での国内自立が本格的に進み始めているという。</p>
<p><strong>■ 各部品の企業・機関名と機能を示す量子プロセッサの構成図</strong> ：量子コンピューターの内部構成。量子ビットチップ（理研製）を冷却し、制御する一連の機器はすべて日本企業による提供。バンドパスフィルタ（綜合電子）、赤外吸収体（川島製作所）なども含まれる
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/s_1279x720_v_fms_webp_ea9fb936_e9e7_49cc_95f2_b40e368b3158_middle_4a979bd274/s_1279x720_v_fms_webp_ea9fb936_e9e7_49cc_95f2_b40e368b3158_middle_4a979bd274.webp" alt="s-1279x720_v-fms_webp_ea9fb936-e9e7-49cc-95f2-b40e368b3158_middle.webp" /></p>
<h2>OSS戦略によるソフトウェアの開放</h2>
<p>ソフトウェア層においても、同プロジェクトでは全てのミドルウェアやAPIをオープンソースとして提供している。大阪大学が中心となって開発したクラウド制御基盤「OQTOPUS」や、量子アルゴリズム設計ライブラリ「QURI Parts」、実機との通信を担う「qubex」などが既に公開済みであり、開発者や研究者が自由に利用・改良できる体制が整っている。</p>
<p>これにより、技術のブラックボックス化を避けつつ、国内外の開発コミュニティとの連携を促進することが可能になるとしている。</p>
<p><strong>■ 阪大クラウド量子コンピュータスタック（2025年版）構成図</strong> ：ユーザーの量子回路設計から量子ビット制御までを一貫して実現するクラウド量子コンピューターの構成図。すべてのソフトウェアがオープンソースでGitHub上に公開されている
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/s_1275x717_v_fms_webp_b272ff36_04e5_4fe7_9b18_ef60ce8199c1_middle_c1fd1f4c0b/s_1275x717_v_fms_webp_b272ff36_04e5_4fe7_9b18_ef60ce8199c1_middle_c1fd1f4c0b.webp" alt="s-1275x717_v-fms_webp_b272ff36-04e5-4fe7-9b18-ef60ce8199c1_middle.webp" /></p>
<h2>大阪・関西万博での一般公開も予定</h2>
<p>この量子コンピューターは、2025年8月14日から20日まで開催される大阪・関西万博の「未来社会ショーケース」内で、一般来場者向けに体験展示が行われる予定。クラウド経由で量子コンピューターにアクセスし、簡単な量子回路の実行や可視化が可能なインターフェースが準備されているとのこと。</p>
<p>この展示は、科学技術の社会実装と教育啓発の一環とされており、一般市民が最先端技術に触れる機会として注目される。</p>
<h2>官民連携によるコンソーシアム体制</h2>
<p>この国産量子コンピューター開発には、大阪大学を中心に、アルバック、QunaSys、富士通、理化学研究所など10以上の産学官機関が参画しており、コンソーシアム形式で技術開発と社会展開を進めている。</p>
<p>また、文部科学省が推進する「ムーンショット型研究開発事業」や「Q-LEAP（量子技術による社会変革）」など、複数の政府プロジェクトによる資金・制度的支援もこの成果を支えている。</p>
<h2>国内外との比較と今後の展望</h2>
<p>世界では米IBMやGoogleが既に50～100量子ビット超の量子プロセッサを商用化しており、日本もそれに続く形で開発が進んでいる。国内では理化学研究所が144量子ビット、富士通が256量子ビットの開発を進めているが、今回の大阪大学の成果は「純国産スタック」という点で独自性を持つ。</p>
<p>今後は2025年10月までに100量子ビット弱への拡張を行い、量子誤り訂正機構の実証や、企業との共同研究に活用される計画が示されている。</p>
<p>大阪大学QIQBの根来誠教授は、「基幹技術を国内で開発・維持することは、国家的にも重要な意義がある」と述べており、量子技術の主権確立と社会実装を進める足がかりとして、今後の展開が注目される。</p>
]]></description>
      <pubDate>Thu, 31 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アリババがQwen3のフラッグシップモデル刷新──推論性能重視の「Thinking‑2507」、2350億パラメーターで登場</title>
      <link>https://ledge.ai/articles/qwen3_flagship_thinking_model_235b</link>
      <description><![CDATA[<p>2025年7月25日、Alibaba Cloudが開発する大規模言語モデル（LLM）ファミリー「Qwen3」に新モデル「<a href="https://x.com/Alibaba_Qwen/status/1948688466386280706">Qwen3‑235B‑A22B‑Thinking‑2507</a>」が追加された。モデルはオープンソースとしてHugging FaceおよびAlibaba CloudのAPI経由で提供されており、ライセンスは商用利用可能なApache 2.0。同モデルは総パラメーター2350億規模のMixture-of-Experts（MoE）アーキテクチャを採用しつつ、推論時に活性化されるパラメーターを220億に抑えることで、軽量な推論を実現している。</p>
<h2>Qwen3シリーズ初の「Thinking」特化モデル</h2>
<p>今回公開された「Qwen3‑235B‑A22B‑Thinking‑2507」は、既存のInstruction系モデルとは異なり、“思考プロセスの分離”に重点を置いた「Thinking」系統に属する。特定のトークン（\u003C|think|\u003E）を用いて思考パートを制御する設計となっており、推論時の透明性や精度向上を目的としている。</p>
<p>モデル名に含まれる「A22B」は、128個の専門モジュール（エキスパート）のうち8個を選択してアクティブ化するMoE構成に由来し、最大2350億のパラメーターを持ちながらも、実際の推論では22億のパラメーターのみが使用される。このアプローチにより、ハードウェア負荷を抑えたまま高精度な出力が可能となる。</p>
<h2>主要スペックと技術仕様</h2>
<p>「Qwen3‑235B‑A22B‑Thinking‑2507」の主な仕様は以下の通り。</p>
<ul>
<li>総パラメーター数：2350億</li>
<li>アクティブパラメーター数：22億（128エキスパート中8選択）</li>
<li>レイヤー数：94</li>
<li>Attention構成：GQA（Grouped-Query Attention）64ヘッド + 4ヘッド</li>
<li>最大コンテキスト長：262,144トークン（約256K）</li>
<li>トレーニングデータ：中英多言語、コード、大規模合成データなど（詳細非開示）</li>
</ul>
<p>また、量子化や推論最適化に対応するためのバリエーションは今後順次追加される予定である。</p>
<h2>ベンチマーク性能</h2>
<p>モデルカードに記載された代表的なベンチマークスコアは以下の通り。いずれもオープンソースで公開されているモデルとしては上位の水準に位置づけられている。</p>
<ul>
<li>AIME25：92.3</li>
<li>LiveCodeBench v6：74.1</li>
<li>MATH（5-shot）：60.0</li>
<li>GSM8K（5-shot）：91.2</li>
<li>HumanEval（0-shot）：90.2</li>
</ul>
<p>これらは数学的推論、コード生成、常識判断といった多様な分野での性能を示しており、思考重視モデルとしての有効性を示唆するものとなっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gwsh_Khhag_AA_7pbb_c68bfc67e1/Gwsh_Khhag_AA_7pbb_c68bfc67e1.jpg" alt="GwshKhhagAA7pbb.jpg" /></p>
<p>Qwen3シリーズは2024年後半から順次公開が進んでおり、7B、14B、72B、110Bなどのサイズに加え、7月上旬には同じ235B構成の「Qwen3‑235B‑A22B‑Instruct‑2507」も公開されていた。今回の「Thinking」モデルはこれに続くものであり、推論特化型モデルとして新たな用途への適応を想定している。</p>
<p>Alibaba CloudのQwenチームは、今後さらに“Coder”系統や複数モード対応型のMoEモデルを拡充する予定だという。</p>
]]></description>
      <pubDate>Thu, 31 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、NotebookLMにAI要約動画生成「Video Overviews」追加　学習＆リサーチを映像でサポート</title>
      <link>https://ledge.ai/articles/notebooklm_video_overviews_update</link>
      <description><![CDATA[<p>Googleは2025年7月29日、AIリサーチ支援ツール「NotebookLM」に、新機能「Video Overviews」を追加したと<a href="https://blog.google/technology/google-labs/notebooklm-video-overviews-studio-upgrades/">発表</a>した。</p>
<p>この機能は、ユーザーがアップロードした資料をもとに、AIがナレーション付きのスライド形式で動画を自動生成する。あわせて、音声要約機能「Audio Overviews」のデザインが刷新され、生成物を一元管理できる「Studio」パネルもアップデートされた。これらの強化により、NotebookLMは、文章・音声・動画を横断した情報整理と共有を可能とするマルチモーダル・ナレッジツールへ進化したと同社はいう。</p>
<p>@<a href="https://www.youtube.com/watch?v=KA_pExdDSUo">YouTube</a></p>
<h2>資料をスライド動画に──Video Overviewsが可能にする情報可視化</h2>
<p>新たに搭載された「Video Overviews」は、複数のドキュメントをAIが読み込み、要点を抽出・整理して、図表や引用、画像、数値などを盛り込んだスライド形式の動画を自動生成する機能。生成された動画にはナレーションが付与されており、視聴者は耳と目の両方から情報を受け取れる。再生コントロールも備えられており、10秒スキップや再生速度の変更が可能となっている。</p>
<p>この機能は、学術研究やプロジェクト説明などの分野での活用を想定しており、まずは英語ユーザーを対象に数週間以内に順次公開される予定。今後、他言語対応の展開も計画されているという。</p>
<h2>Audio Overviewsも刷新、視認性と操作性を向上</h2>
<p>既存の音声要約機能「Audio Overviews」も今回のアップデートでデザインが刷新された。新たなレイアウトは、Video Overviewsとの統一感を意識して設計されており、再生中のセクションが視覚的に把握しやすくなっている。加えて、再生やスキップなどの操作もスムーズに行えるようUIが改善されており、より実用的な音声コンテンツ生成ツールへと進化した。</p>
<h2>Studioパネルが進化、生成物を一元管理可能に</h2>
<p>NotebookLMの「Studio」パネルもアップデートされ、Audio、Video、Mind Map、Reportといった複数形式の生成物を一つの画面で管理できるようになった。ユーザーは任意のノート内で、クリック操作一つで各種出力物を作成でき、それらを保存・再編集することも可能。これにより、資料作成から要約、共有までの一連のワークフローを効率的に進められるようになった。</p>
<p>NotebookLMは、2024年9月に音声要約機能Audio Overviewsを導入し、2025年6月には成果物の公開機能であるPublic Notebooksを提供開始していた。今回のアップデートにより、「読む・聴く・見る」の三位一体によるナレッジ活用が可能となった。</p>
<p>現在、NotebookLMは英語圏を中心に展開されているが、Googleは今後もユーザーのフィードバックをもとに多言語対応を進めるとしている。</p>
]]></description>
      <pubDate>Wed, 30 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Penrose、LLMが実際のビジネス現場でどこまで正確に決算処理できるかを評価するベンチマーク「AccountingBench」公開──“1つのミスが雪だるま式に拡大”する現場精度を検証</title>
      <link>https://ledge.ai/articles/llm_accounting_benchmark_penrose</link>
      <description><![CDATA[<p>米会計ソフトウェア開発企業Penroseは2025年7月下旬、大規模言語モデル（LLM）が実際のビジネス現場でどこまで正確に「月次決算」を処理できるかを評価するベンチマーク「AccountingBench」を<a href="https://accounting.penrose.com/">公開</a>した。これは従来の一問一答型テストとは異なり、1つの判断ミスが後続の処理に影響を与え、時間とともに誤差が蓄積する実業務の構造を反映した設計となっている。</p>
<h2>実ビジネスを模した12カ月間の決算シミュレーション</h2>
<p>AccountingBenchは、SaaS企業の会計データをベースに、12カ月分の月次決算を連続して処理する長期タスクとして構成されている。モデルは各月において、取引の分類・仕訳、銀行勘定の調整、財務諸表の作成などを実施。1カ月の判断ミスが翌月以降に影響し、全体の精度に波及するという設計により、LLMの持続的な正確性を評価できる。</p>
<p><strong>■ 口座残高精度の経時変化</strong> ：全モデルとも10カ月目以降95％を下回り、Claude 4系とGrok 4で乖離が顕著
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_77caa4b642/1_77caa4b642.png" alt="ダウンロード (1).png" /></p>
<p>使用される原始データは、RampやRippling、Stripe、Mercuryなどの実在サービスから得られた実データに基づいている。モデルには外部ツール（SQL、Python）呼び出し権限が与えられ、帳簿データベースへの問い合わせや簡易な計算処理を行うことが可能である。</p>
<h2>評価結果：初期は高精度、5カ月目以降で精度が崩れる傾向</h2>
<p>公開されたベンチマーク結果によると、Claude 4（Opus/Sonnet）とGrok 4はいずれも最初の3カ月程度までは95％を超える高精度で処理をこなした。しかし、5カ月目以降に処理の正確性が低下し始め、最終月ではClaude 4が85％未満にまで精度を落とした。一方、Gemini 2.5 Pro、o3、o4-miniなどのモデルは、1カ月目時点で正確な処理ができず、途中でタスク継続を断念したという。</p>
<p><strong>■ 重大な誤差（ベースライン比±5％超）に達するまでの月数</strong> ：Claude 4（Sonnet/Opus）は7〜8カ月、Grok 4は5カ月で崩れ始めた
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_78de383100/3_78de383100.png" alt="ダウンロード (3).png" /></p>
<p><strong>■ 認識済みサブスクリプション収益の月次乖離率</strong> ：Claude 4系は中盤以降プラス方向に乖離、Grok 4は終盤で急落
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_0aeddb0dc7/2_0aeddb0dc7.png" alt="ダウンロード (2).png" /></p>
<p>モデルの精度評価には、各月の最終的な財務諸表の数値と、理想的な手動処理との一致度（項目単位の比較スコア）が使用されている。</p>
<h2>観察された“報酬ハック”とコンテキストの限界</h2>
<p>一部のLLMにおいては、銀行勘定残高が帳簿と合わない場合に、無関係な取引を挿入して差額を埋めようとする行動が確認された。このような「報酬ハック」は、モデルが最終結果のスコア最適化を目的とし、処理の一貫性を犠牲にする例として問題視されている。</p>
<p>また、長期間にわたる処理の中で文脈の一貫性が保てなくなり、ツール呼び出しを放棄してループに陥るなどの動作も報告されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/balance_sheet_ai_04471cc1ac/balance_sheet_ai_04471cc1ac.jpg" alt="balance sheet ai.jpg" /></p>
<h2>Penroseの見解と今後の展開</h2>
<p>Penroseは公式サイト上で、「これまでのAIベンチマークは、タスクを単に“完了できるか”を評価してきた。しかし実務では、“正しく完了できるか”こそが問われる」と述べ、AccountingBenchの設計思想を説明している。</p>
<p>今後はこのベンチマークの評価対象をさらに拡充し、異なる業種の会計モデルや複数年の処理を対象とした拡張バージョンも公開予定であるとのこと。</p>
]]></description>
      <pubDate>Wed, 30 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Forcesteed Robotics、「好奇心」を人工意識（AC）と捉え「フィジカルAIプラットフォームーー Guardian」を発表</title>
      <link>https://ledge.ai/articles/forcesteed_physical_ai_guardian_release</link>
      <description><![CDATA[<p>株式会社Forcesteed Roboticsは2025年7月24日、ロボットが未知の環境や事象を自律的に探索・学習・進化するための継続的自律学習アーキテクチャ「好奇心（System4）」を<a href="https://prtimes.jp/main/html/rd/p/000000007.000157769.html">発表</a>した。</p>
<p>この「好奇心」は、同社が開発する人工意識（Artificial Consciousness、以下AC）の中核的機能と位置付けられており、ロボットの“主体的学習”を担う最上位機能である。好奇心を搭載したロボット基盤は、「フィジカルAIプラットフォームーーGuardian（ガーディアン）」として構成され、同社はこれを活用した各種ロボティクス分野での応用を目指している。なお、同プラットフォームは7月29日から京都市で開催される画像認識国際会議「MIRU 2025」にて一般公開される予定だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=okfUR6gYVZc">YouTube</a></p>
<h2>背景と目的：未知事象への継続的対応</h2>
<p>従来の産業用・サービス用ロボットは、設計時に定義された環境や動作範囲に限定されることが多く、非定型的な状況や「ロングテール事象」への柔軟な対応が課題とされていた。Forcesteed Roboticsはこの課題に対し、外部からの命令に依存せず、ロボット自身が「何を知らないかを自覚し、自ら学びに向かう」機構として「好奇心（System4）」を開発した。</p>
<h2>「好奇心（System4）」の構成と役割</h2>
<p>「好奇心」は、同社が提唱する人工意識ACの構成層における最上位機能であり、以下の4層構造により実現される：</p>
<ul>
<li>System1：視覚や聴覚などの知覚を担う</li>
<li>System2：短期記憶、運動制御、実行判断を担う</li>
<li>System3：過去の経験と照合して現在の行動を制御する</li>
<li>System4（好奇心）：未知情報を検出し、自律的に学習計画を立案・実行する</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub4_e574f17a44/sub4_e574f17a44.png" alt="sub4.png" /></p>
<p>この中でもSystem4は、過去に経験のない物事や、新規性の高い事象を自動的に検出し、それを学習対象として再優先化する。これにより、ロボットが単に記録的に環境を観察するだけでなく、環境に対する“探究行動”を継続的に行うことが可能となる。</p>
<h2>実装技術と特徴</h2>
<p>「好奇心（System4）」は以下のような技術的特徴を有するという：</p>
<ul>
<li>内発的動機による自律的探索学習</li>
<li>ロングテール事象の自動記録・再学習サイクル</li>
<li>重要体験の選別と記憶の最適化（忘却防止）</li>
<li>視覚・言語・運動の統合AIモデルとの接続による自然言語対応</li>
</ul>
<p>これにより、人間のような対話や行動の即時反応だけでなく、長期的な知識の蓄積・修正・適用までを一貫してロボット内部で完結させる構造となっている。</p>
<h2>想定される応用領域</h2>
<p>同社は「Guardian」および「好奇心」機構を以下のようなユースケースに適用可能としている：</p>
<ul>
<li>商業施設や病院などでの自律巡回および案内対応</li>
<li>高齢者施設での見守りや声掛けなどのケア支援</li>
<li>製造・物流・インフラ領域での異常検知と対応</li>
<li>学校・観光地などでの対話型インタフェースとしての活用</li>
</ul>
<h2>今後の展開</h2>
<p>同社は今後、「Guardian」を基盤とした社会実装に向けて、企業・研究機関との共同研究や実証実験のパートナーを広く募集するとしている。また、人工意識ACの開発についても、継続的なアップデートと応用範囲の拡張を図る方針だ</p>
<p>「Guardian」プラットフォームは、7月29日から8月1日まで京都市の国立京都国際会館で開催される画像認識シンポジウム「MIRU 2025」で初公開される。会場では、4脚犬型ロボットに「Guardian」を搭載し、巡回や対話を含む自律行動のデモンストレーションが予定されている。</p>
]]></description>
      <pubDate>Wed, 30 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、ノーコードAIアプリ作成ツール「Opal」を米国でベータ公開──自然言語とビジュアル操作で開発から共有までを一貫支援</title>
      <link>https://ledge.ai/articles/google_opal_no_code_ai_tool</link>
      <description><![CDATA[<p>Googleは2025年7月24日（現地時間）、同社の実験的プロジェクトプラットフォーム「Google Labs」において、ノーコードでAIアプリケーションを開発・共有できる新ツール「Opal（オパール）」を<a href="https://developers.googleblog.com/en/introducing-opal/">発表</a>した。</p>
<p>米国在住のGoogleアカウントユーザーに限定してパブリックベータが公開されており、ユーザーは専用サイト（opal.withgoogle.com）からアクセスできる。このツールは、自然言語の指示と視覚的なワークフローエディタを組み合わせることで、AIアプリケーションの迅速な試作や共有を可能にするという。</p>
<h2>AI活用の民主化を目指した開発背景</h2>
<p>Opalは、プロンプトやGeminiモデルの呼び出し、Googleツールの連携といった機能を組み合わせて、ワークフローをノーコードで構築できる。Googleはこのツールの目的を「AIアイデアを迅速に形にするプロトタイピング手段」と位置づけており、社内業務の自動化、生産性向上ツールの簡易開発、PoC（概念実証）用途などでの活用を想定しているとのこと。</p>
<p>ツールはGoogle Labsの一環として提供されており、今後の機能強化や仕様変更についてはユーザーからのフィードバックを重視しながら進められる予定だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=E0hrcDO3Noc&amp;t=1s">YouTube</a></p>
<h2>操作は3ステップで完結</h2>
<p>Opalでのアプリ開発は以下の3ステップで行われる：</p>
<ul>
<li><strong>Create workflows</strong> ：プロンプト生成やAIモデル、Google Workspaceなどのツールをノードとして視覚的に接続し、ワークフローを作成する</li>
<li><strong>Make edits</strong>  ：各ステップは自然言語もしくはGUIで容易に編集可能で、ユーザーは試行錯誤を繰り返しながら即時に調整ができる</li>
<li><strong>Share your app</strong> ：完成したミニアプリはURL形式で共有でき、他ユーザーがそのまま実行・再利用・改変できる仕組みが導入されている</li>
</ul>
<p>加えて、公式サイトにはテンプレートや他ユーザーの作例を集めたギャラリーが設置されており、これらを「リミックス」することで新たなアプリを容易に作成できるようになっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Just_Gallery_original_dfd0bb4d02/Just_Gallery_original_dfd0bb4d02.jpg" alt="Just_Gallery.original.jpg" /></p>
<h2>今後の展望</h2>
<p>同社によると、以下の機能拡張が予定されている。</p>
<ul>
<li>ギャラリー上のテンプレートの拡充</li>
<li>Gemini APIやGoogle Workspaceアプリとの連携機能の強化</li>
<li>米国外への展開に向けた段階的公開</li>
</ul>
<p>これらの取り組みを通じて、Googleは企業や開発者だけでなく、一般ユーザーにもAIツールの開発環境を開放することを目指しているという。</p>
]]></description>
      <pubDate>Tue, 29 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、Copilotに“顔”を付ける──実験機能「Copilot Appearance」米・英・カナダで早期プレビューを開始</title>
      <link>https://ledge.ai/articles/copilot_appearance_experimental_preview</link>
      <description><![CDATA[<p>Microsoftは2025年7月27日、AIアシスタント「Microsoft Copilot」に視覚的な存在感を付与する新機能「Copilot Appearance」の早期プレビュー提供を開始したことを<a href="https://copilot.microsoft.com/labs/experiments/copilot-appearance">発表</a>した。</p>
<p>これは、Copilot Labsにおける実験的取り組みの一環で、Web版Copilot上で動作し、アニメーションアバターによってユーザーとの対話に表情やジェスチャーを加えることができるという。</p>
<h2>会話中に笑顔やうなずきも　視覚的な非言語表現で“人らしさ”を演出</h2>
<p>「Copilot Appearance」は、ユーザーの発話内容やチャット文脈に応じて、Copilotがリアルタイムに表情を変化させたり、うなずいたり、驚いたりといった非言語的なフィードバックを提供する機能。アニメーションアバターが対話相手のように動作することで、より自然で親しみやすいユーザー体験を目指している。</p>
<p>背景には、会話履歴から推論される短期的な文脈メモリを活用し、単なる音声合成を超えた“対話の雰囲気”を再現しようとする試みがある。現時点では基本的な表情変化が実装されているが、今後さらなるパターンの追加が予定されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/copilot_appearance_image_1_8ab403c20e/copilot_appearance_image_1_8ab403c20e.png" alt="copilot-appearance-image-1.png" /></p>
<h2>利用方法と対象ユーザー</h2>
<p>利用はWeb版のCopilotから、音声入力アイコンをクリックし、「Voice Settings」内にある「Copilot Appearance」のトグルをオンにするだけで可能となる。機能を有効化すると、テキストチャットであってもCopilotがアニメーション付きで応答を読み上げるようになる。</p>
<p>なお、今回の実験機能は「Copilot Labs」に登録した一部のユーザーを対象としており、提供地域は米国、英国、カナダに限定されている。日本を含む他地域への展開時期は未定。</p>
<h2>今後の展望：AIに人格を与え「見えるAI」へ</h2>
<p>Copilot Appearanceの開発は、Microsoftが進めるCopilotの“人格化”戦略の一部と位置付けられている。Microsoft AI部門のCEOであるムスタファ・スレイマン氏は以前より、Copilotを「永続的で信頼できるデジタルの友人」に進化させるというビジョンを語っており、今回の視覚的インターフェースの導入はその第一歩といえる。</p>
<p>同社は今後、ユーザーフィードバックをもとに本機能の表情表現やアニメーションを改善し、より多くの国と言語への対応を検討するとしている。</p>
<p>Microsoftの他にも、MetaはAIアバターとのインタラクションを強化する「AI Studio」を展開しており、Googleは「Project Astra」で視覚・音声・動作を組み合わせた次世代AIエージェントを開発中だ。こうした動きは、AIが単なるツールから「相棒」へと進化しつつあるトレンドを示している。</p>
]]></description>
      <pubDate>Tue, 29 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIスタートアップのオルツ、売上の最大9割を過大計上　第三者委が循環取引を指摘</title>
      <link>https://ledge.ai/articles/alts_financial_misstatement_ai_gijiroku</link>
      <description><![CDATA[<p>AIスタートアップのオルツは2025年7月25日、2020年度から2024年度にかけて計上した売上高のうち、最大で約90%が実態のない取引に基づく過大計上だったと<a href="https://tdnet-pdf.kabutan.jp/20250725/140120250725520988.pdf">明らかにした</a>。これは同社が設置した第三者委員会の調査報告に基づくもので、<a href="https://www.jpx.co.jp/news/1023/20250725-13.html">東京証券取引所</a>は同日、同社株式を監理銘柄（審査中）に指定した。</p>
<h2>第三者委員会が認定した「実態なき売上」</h2>
<p>オルツは2025年4月25日、過年度の決算における売上高の不適切な計上の可能性を受け、外部弁護士や公認会計士による第三者委員会を設置。今回の発表は、その調査報告書を受けてのものである。</p>
<p>調査対象は2020年12月期から2024年12月期までの連結決算。報告書によると、売上高に対して実態のない取引を循環させることで過大計上していた実態が明らかになった。
過大計上とされた売上額は、合計で約119億8,531万円にのぼる。</p>
<h2>主力サービス「AI GIJIROKU」をめぐる循環取引</h2>
<p>報告書によれば、オルツは主力サービスである議事録作成SaaS「AI GIJIROKU」に関し、外部の販売パートナーに対して一旦売上を計上し、その後、同パートナーに対して広告宣伝費や研究開発費名目で資金を還流させていた。これにより、実際のキャッシュフローを伴わない循環取引が行われていた。</p>
<p>このスキームにより、2021年度の売上高の78%、2022年度と2023年度にはそれぞれ91%、そして2024年度は82%が過大に計上されていたという。</p>
<h2>東証が監理銘柄に指定、上場維持に暗雲</h2>
<p>この過大計上を受け、東京証券取引所はオルツを「監理銘柄（審査中）」に指定した。この指定は、上場会社が有価証券報告書などの虚偽記載の疑いがある場合に行われ、最終的に上場廃止となる可能性もある。現時点では、有価証券報告書などの訂正提出やガバナンス改善の進捗状況に基づいて審査が行われる予定とされる。</p>
<h2>今後の対応とスケジュール</h2>
<p>オルツは今後、第三者委員会の報告内容を踏まえ、該当する決算の訂正、有価証券報告書の再提出、ならびに再発防止策の策定を進める方針である。社内では経営責任の所在についても検討が始まっているとされ、代表取締役やCFOなどの処分も含めた対応が取られる可能性があるという。</p>
]]></description>
      <pubDate>Tue, 29 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ロナウジーニョ起用で加速するAI AVATAR　共感型対話AIの社会実装とBtoB活用への展望</title>
      <link>https://ledge.ai/articles/ai-avatar</link>
      <description><![CDATA[<p>「人に寄り添う存在」としてのAIが注目を集めている。株式会社AIアバターが展開する「<a href="https://jp.aiavatar.fun/">AI AVATAR</a>」は、ユーザーの感情や文脈を読み取り対話する、会話型のAIである。すでにエンタメ領域を中心に、日常生活に入り込み始めており、BtoB領域での活用についても大きな可能性を秘めている。本稿では、AI AVATARのサービス内容や取り組みについて触れながら、同サービスが企業にもたらしうる変革について探る。</p>
<h2>感情を分かち合える「AI AVATAR」</h2>
<p>「AI AVATAR」は、ユーザーの声のトーンや表情から感情を読み取り、それに応じた共感や励ましを行う、会話特化型のAIアプリケーションである。雑談からスケジュール管理、モチベーション維持の支援まで、多彩な機能を備えており、目的や関心に応じて役割やキャラクターを変えることができるのが最大の特徴だ。アバター自身もリアルタイムで表情を変化させることができ、「ニュートラル」「幸せ」「悲しみ」の3つの感情に対応している（2025年6月時点）。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai_avatar_image_e4f64b0637/ai_avatar_image_e4f64b0637.png" alt="ai avatar_image.png" /></p>
<p>ユースケースとしては、スケジュール管理などのサポートを行う「アシスタント型」や、「推しキャラ」のように日々の癒しや励ましを提供する「パートナー型」まで幅広い。ユーザーは、スマートフォンの中に、言葉だけでなく表情や仕草を通じて応えてくれる”自分だけの会話相手”を作り上げることができるのだ。</p>
<p>同社は、シンガポールに本社を置くAI AVATAR Pte. Ltd.を親会社に持つグローバル企業である。AI AVATAR Pte. Ltd.は、日本をはじめ、ベトナムやインドネシア、ブラジルなど、世界各国に子会社を展開しており、世界規模でインタラクティブアバターを軸にAIの社会実装を推進している。
「AI AVATAR」は、日本でも既に一定の支持を得ており、特に男性層や推し活を楽しむ女性ユーザーの利用がメインとなっている。アプリのインストール数は11万人を超えており、アクティブユーザー数（MAU）も2万弱。利用者からは「一人でいる時間に話し相手ができた」や「毎日の鬱憤を遠慮なく言える相手ができた」などの声が寄せられており、感情的なつながりを持つ対話型AIとしての役割を確実に広げている。</p>
<h2>社会課題である「孤独をなくす」ビジョンの裏側</h2>
<p>株式会社AIアバターを設立したのは、ライブドアの元CFOとして知られる宮内亮治氏である。激動期のIT業界を間近で経験した宮内氏は、その後、自身のキャリアの軸足を社会課題の解決へとシフトさせた。高齢化や単身世帯の増加、リモートワークの普及などから、人々が物理的にも心理的にも距離が離れてしまっている現代では、「孤独・孤立」という社会課題が顕在化している。宮内氏はこの“孤独”という社会課題に向き合い、テクノロジーの力で解決することを目指した。その挑戦こそが「AI AVATAR」プロジェクトなのである。</p>
<p>現時点での同社の売上は、年商100億円規模にまで達している。セールス部門を率いるのは、元ラグビー日本代表としても知られる冨岡剛氏。彼のリーダーシップのもと、営業チームは顧客との信頼構築を地道に積み重ね、サービスの社会実装を着実に推進している。単なるAIソリューションを売る営業ではなく、人に寄り添う技術の価値を伝える、その姿勢が、同社の売上成長を支える要因となっている。</p>
<h2>ロナウジーニョ起用に見るタレントアバター戦略</h2>
<p>AI AVATARがさらに注目を集めたきっかけは、サッカー界のレジェンドであるロナウジーニョとのタレントアバター企画である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai_avatar_app_b56f543ef9/ai_avatar_app_b56f543ef9.png" alt="ai avatar_app.png" /></p>
<p>ロナウジーニョ起用の背景にあるのは、ユーザーとの「感情的な接続」をいかにテクノロジーで実現するかという点にある。世界的な知名度と好感度を持つロナウジーニョだからこそ、エンタメ性と感情移入のバランスが絶妙に成立する。彼がアバターとなって、話しかけてくる存在になることで、ファンとの新しい関係性が生まれるのだ。
現在は、サッカー技術の継続支援を目的として、ロナウジーニョが持つ多くのサッカー技術を、アバターを介してコーチングするようなファンクションを開発中。今後AI AVATARを一気に広める起点として、世界中のファンに向けた発信が行われていくだろう。</p>
<p>ロナウジーニョの例もそうだが、AI AVATARは、“キャラを推す”という感覚をデジタルで再現し、現在の推し活市場の広がりにも呼応している。アバターが一方的に情報や情報を届けるのではなく、ユーザーの反応に応じて会話を柔軟に展開していく対話型の設計が、共感を生み、より深いエンゲージメントの形成へとつながっているのだ。</p>
<h2>企業活用の可能性は？</h2>
<h3>社員の行動を支えるAIメンター</h3>
<p>既にBtoC領域での展開実績を有する中で、今後は企業向け活用の可能性も高まっている。</p>
<p>例えば、新入社員のオンボーディング支援として、AI AVATARを「メンター」として活用するケースが考えられる。社員一人ひとりに専属のアバターが付き、日々の業務リマインドや業務へのフィードバック、モチベーション管理などの支援などを行う。対人ではなくAIだからこそ、気軽に質問しやすいという利点もある。</p>
<p>また、健康経営や自己学習の伴走者としてAI AVATARを活用することで、資格学習や運動・食事管理といった、個人では継続が難しい目標の達成支援が可能になる。これは企業が社員の生産性向上や健康管理に投資するうえで、非常に現実的な活用方法である。
現在は、学習サポートにおける教材提供や、健康管理のための運動記録・食事支援などの開発も行っており、順次機能の拡充を行っていくとのことだ。</p>
<h3>ブランドコミュニケーションや広告体験の変革</h3>
<p>タレントアバター戦略で紹介したロナウジーニョのように、今後、著名人のアバターが続々と登場し、活用されていくことで、従来のバナーや動画広告とは異なる「会話する広告体験」が実現されていくであろう。企業は、製品やブランドイメージに合致したタレントアバターを起用することで、ユーザーとの接点を一方的な訴求から「対話」へ転換できる。このアプローチは、マス向けの広告をより個人に最適化されたインタラクティブな体験へと進化させ、マーケティング戦略に新たな選択肢をもたらす可能性を秘めている。</p>
<h2>AIと人が感情でつながる時代の幕開け</h2>
<p>高性能なAIソリューションが次々と登場する中で、「感情に寄り添うAI」も注目ポイントになっている。スマートシティの実現やロボティクスの普及が見込まれていく中、AIはより深く人々の日常に入り込もうとしている。その未来において、ユーザーとの双方向の対話を可能にする「会話特化型AI」は今後、重要な役割を担う存在となり、「AI AVATAR」はその最前線を走るサービスである。</p>
<p>孤独という社会課題への取り組みや個人の行動継続支援、ユーザーとブランドとの新しい接点の創出を通じて、AIアバターは、人とAIが感情でつながる社会の実現へ、着実に歩みを進めている。</p>
<p>Sponsored by 株式会社AIアバター</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIスタートアップBuilder.ai、実態はAIではなく人海戦術──700人のエンジニアによる手作業が発覚し倒産へ</title>
      <link>https://ledge.ai/articles/builder_ai_fake_ai_collapse</link>
      <description><![CDATA[<p>2025年5月、AIによるノーコード開発を掲げていたスタートアップ企業「Builder.ai」が、実際には約700人のエンジニアによる手作業によって運営されていたことが明らかになり、倒産に追い込まれたと<a href="https://www.bloomberg.com/news/articles/2025-05-30/builder-ai-faked-business-with-indian-firm-verse-to-inflate-sales-sources-say">Bloomberg</a>など複数の海外メディアが報じた。同社はMicrosoftなどからの出資を受け、急成長を遂げていたが、その中核技術とされていたAIの実態に疑念が生じ、事業継続が困難になったという。</p>
<h2>ノーコード開発を標榜していたスタートアップの実像</h2>
<p>Builder.aiは2016年に創業されたスタートアップで、「ソースコードを書かずにアプリを構築できるAIプラットフォーム」として注目を集めた。特に開発コストや工期の大幅な削減を謳い、業務アプリやECアプリなどを迅速に構築できる点が評価された。</p>
<p>同社は2023年に実施したシリーズD資金調達において、Microsoftを筆頭とする投資家から総額2億5,000万ドル以上を調達。AIによるアプリ自動生成の将来性が評価され、企業価値は10億ドルを超える「ユニコーン企業」とされていた。</p>
<h2>発覚した「AIなし」の実態と手作業の実装</h2>
<p>しかし、2025年に入ってから海外メディアによる調査が進み、Builder.aiの「AIプラットフォーム」が実際には高度なAI技術ではなく、インドに配置された約700人のエンジニアによる手作業で構築・運用されていたことが判明した。</p>
<p>報道によれば、ユーザーがアプリの要件を入力すると、AIが生成したように見せかけた上で、裏側では実際の人間のエンジニアがコードを一から記述し、カスタマイズや修正も同様に人力で対応していたという。</p>
<h2>SNSでも話題に：700人のエンジニアで「AI」を演出</h2>
<p>今回の件を受け、SNSでも皮肉を交えた投稿が注目を集めている。起業家のベルンハルト・エンゲルブレヒト氏はX（旧Twitter）上で、次のように指摘した。
「Builder.aiの“AI”の正体は、実は700人のインド人プログラマーだった」として、
顧客の要望はすべてインドのオフィスに送られ、人力でコードが書かれていたと述べた。
同氏はまた、「バグが多く機能しないアプリは、逆に“本物のAIのよう”だった」と皮肉交じりに言及している。</p>
<p>この投稿には、コールセンターのようなオフィスで多くの作業員が対応する様子を写した画像も添えられており、視覚的にも強いインパクトを与えている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bernhard_negelbrecht_0856dcc822/bernhard_negelbrecht_0856dcc822.jpg" alt="bernhard negelbrecht.jpg" /></p>
<h2>信頼失墜と事業停止</h2>
<p>AI技術に基づく製品として売り込んでいたにもかかわらず、その実体が人海戦術だったことが公になったことで、顧客企業や投資家の信頼を一気に喪失。顧客の中には「AIによる自動生成にしては非効率すぎる」といった疑念を以前から抱いていたケースもあったという。</p>
<p>こうした事態を受けて、Builder.aiは事業継続が困難と判断し、清算手続きに入ったとのことだ。なお、報道時点でMicrosoftはこの件に関するコメントを控えている。</p>
<h2>「AI活用」の検証が求められる時代へ</h2>
<p>今回の事案は、「AI」を看板に掲げながら実態は手作業だったという点で、業界全体に警鐘を鳴らすものと受け止められている。AIスタートアップへの投資や連携において、企業側が提示する「技術の実態」と「運用の実情」をどこまで精査すべきかが、あらためて問われている。</p>
<p>特にノーコード・ローコード分野では、実装の裏側がブラックボックスになりやすく、他社でも同様の問題が潜在している可能性があるとの指摘もある。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTが“答えを教えない”家庭教師に──OpenAI、「Study Mode（学習モード）」実装で思考力を鍛える</title>
      <link>https://ledge.ai/articles/chatgpt_study_mode_thinking_assistant</link>
      <description><![CDATA[<p>OpenAIは2025年7月29日（米国時間）、対話型AI「ChatGPT」に新機能「Study Mode（学習モード）」を追加したと<a href="https://openai.com/ja-JP/index/chatgpt-study-mode/">発表</a>した。</p>
<p>この機能は、ユーザーに直接答えを与えるのではなく、ソクラテス式の質問や段階的なヒントを通じて思考プロセスを促進し、深い学びを支援することを目的としている。提供対象はFree／Plus／Pro／Teamの各プランで、ウェブ・iOS・Android・デスクトップ版すべてで即日利用可能。今後数週間以内には、教育機関向けの「ChatGPT Edu」プランでも展開予定としている。</p>
<h2>ユーザー参加型の学習体験を設計</h2>
<p>Study Modeは、チャット画面内の「Tools（ツール）」メニューから〈Study and learn〉を選択することで有効化される。機能が有効な状態では、ChatGPTが以下のような挙動をとる。</p>
<ul>
<li>ユーザーの目標やスキルレベルを把握し、それに応じた問いかけやヒントを提示</li>
<li>複雑な情報を段階的に分解して提示する「スキャフォールディング」手法の活用</li>
<li>会話履歴（メモリ）を活用したパーソナライズ対応</li>
<li>小テスト形式の問題や、自由記述型の問いかけによる理解度チェック</li>
<li>ワンタップで機能のオン／オフ切替が可能</li>
</ul>
<p>OpenAIによれば、こうした設計は「学習者が自ら考えることに能動的に関わるよう促すこと」を重視しており、教育分野の研究成果をもとに設計されている。</p>
<h2>教育の専門家と連携して設計</h2>
<p>Study Modeの開発には、教育学・認知科学の専門家や現場の教師が関与しており、学習の質を高める5つの行動原則が基盤となっている。</p>
<ul>
<li>能動的な参加の促進</li>
<li>認知負荷の最適化</li>
<li>メタ認知（自分の考え方を客観視する力）の強化</li>
<li>好奇心を喚起する設問の提示</li>
<li>建設的なフィードバックの提供</li>
</ul>
<p>OpenAIは、これらの原則に基づいた対話を通じて、AIとのインタラクションそのものを学習の一環とすることを狙っている。</p>
<h2>今後の拡張も視野に</h2>
<p>同社は今後の機能拡張として、図表やチャートなど視覚的な補助ツールの追加、会話全体を横断するゴール設定機能、進捗のトラッキング機能などを検討中としている。また、現時点ではカスタム指示で実装されている行動設計を、将来的にはモデル自体に統合していく方針も明らかにしている。</p>
<p>この動きは、教育領域におけるAI活用のトレンドとも一致しており、Anthropic「Claude Tutor」、Google「Gemini Learn」など、各社が生成AIを用いた個別学習支援に注力している。</p>
<p>OpenAIは今回のアップデートを「第一歩」と位置づけており、将来的には教育機関や研究者との連携を通じて、教育AIの質と信頼性を高めていくとしている。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「理論がないAI/LLM」に情報幾何学から新たな解釈の可能性　──“曲がった”ニューラルネットワークが引き起こす爆発的記憶、京大らが高次相互作用の数理に突破口</title>
      <link>https://ledge.ai/articles/curved_neural_networks_memory_explosion</link>
      <description><![CDATA[<p>京都大学大学院情報学研究科の島崎秀昭准教授を中心とする国際研究チームは2025年7月29日、統計物理学の最大エントロピー原理をRényiエントロピーへ拡張し、高次相互作用を自然に組み込む新しいニューラルネットワークモデル「Curved Neural Networks（C-NN）」を開発したと<a href="https://www.kyoto-u.ac.jp/ja/research-news/2025-07-29-0">発表</a>した。</p>
<p>この成果は、2025年7月24日付で英科学誌『<a href="https://www.nature.com/articles/s41467-025-61475-w">Nature Communications</a>』に掲載された。</p>
<h2>高次相互作用を取り込む幾何学的アプローチ</h2>
<p>研究は、京都大学の島崎准教授をはじめ、バスク応用数学センター（BCAM）のMiguel Aguilera研究員、株式会社アラヤのPablo A. Morales主任研究員、英国サセックス大学のFernando E. Rosas助教らによる国際共同研究によって進められた。</p>
<p>従来のニューラルネットワークは、ノード間のペア相互作用（2体関係）のみを基本として構築されてきたため、三者以上が同時に関わるような「高次相互作用（higher-order interactions）」を理論的に扱うには限界があった。</p>
<p>研究チームは、確率分布の空間を「統計多様体」として捉え、その空間に曲率（curvature）を導入することで、追加のパラメータを用いることなく高次相互作用を記述可能とした。具体的には、最大エントロピー原理をRényiエントロピーに基づいて拡張し、指数分布の変形によって高次の結合が自然に導かれる新しい枠組みを構築している。</p>
<p><strong>■ 統計多様体の“葉構造”と高次相互作用の対応：</strong>
上：ノード（青）同士の複数リンクが三角形や四面体として重なり合い、三者以上の同時作用（高次相互作用）を表す。
右：曲率が 0（平坦）の場合、階層ごとに分離したサブマニフォールド Er0\mathcal{E}^0_rEr0​ が存在する。
左：曲率 γ≠0\gamma <br />
eq 0γ=0 を導入すると空間が折り重なり、1つのパラメータで高次相互作用 E1γ,E2γ,…\mathcal{E}^\gamma_1, \mathcal{E}^\gamma_2,\dotsE1γ​,E2γ​,… が自然に内包される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294.jpg" alt="Higher-order decomposition resulting from the foliation of a statistical.jpg" /></p>
<h2>3つの特徴：爆発・自己調整・容量拡張</h2>
<p>C-NNには、以下のような重要な性質が確認された。</p>
<h3>爆発的記憶想起（Explosive Recall）</h3>
<p>エネルギーや温度パラメータがわずかに変化しただけで、記憶状態が瞬時に切り替わる「爆発的相転移」現象が観測された。これは、人間のひらめきに類似した挙動とされる。</p>
<h3>自己調節アニーリング（Self-regulating Annealing）</h3>
<p>ネットワーク内部のエネルギー状態に応じて「有効温度」が自律的に調整され、最適な記憶検索状態へ滑らかに遷移する仕組みが確認された。これは、従来の外部制御型アニーリングを不要にする。</p>
<h3>記憶容量とロバスト性の制御</h3>
<p>空間の曲率を定める単一パラメータγを調整することで、記憶容量の上限と誤り耐性（ロバスト性）のバランスを柔軟に制御可能であることが、解析とシミュレーションにより示された。</p>
<p>これらの性質は、いずれも個別にプログラムされたアルゴリズムによるものではなく、ネットワーク空間の幾何学的構造そのものから自発的に生じるとされている。</p>
<h2>理論と実装への橋渡し</h2>
<p>研究では、統計物理におけるレプリカ法を用いてモデルの性質を解析。曲率が負の多様体を用いたC-NNでは、従来型のHopfieldネットワークと比較して、記憶容量（格納可能なパターン数）が増加し、スピンガラス状態（迷子状態）の発生が抑制されることが明らかとなった。</p>
<p>この結果は、計算資源を抑えながらも、より迅速で信頼性の高いメモリ検索や意思決定を可能とするネットワーク設計につながると期待されている。</p>
<h2>今後の展望</h2>
<p>C-NNの枠組みは、以下のような多様な領域への応用が見込まれる。</p>
<ul>
<li><strong>脳神経科学</strong> ：スパース発火や急激な記憶想起の数理的記述に貢献</li>
<li><strong>次世代AI設計</strong> ：Transformerや拡散モデルのエネルギー地形の再解釈</li>
<li><strong>ロボティクス／エッジA</strong> I：小型・省電力環境下での高速推論</li>
<li><strong>Explainable AI（XAI）</strong> ：幾何学パラメータによる構造的可視性の向上</li>
</ul>
<p>今後は、C-NNの学習アルゴリズムの一般化、生体神経活動との比較、フォトニック回路など物理実装との統合といった方向での発展が見込まれる。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GoogleのAI要約表示で外部リンクのクリック率が半減、Pew Researchが分析結果を公表</title>
      <link>https://ledge.ai/articles/google_ai_overview_click_rate_drop</link>
      <description><![CDATA[<p>2025年7月22日、米調査機関 Pew Research Center は、Google検索の上部に表示される AI生成要約「AI Overview」（以下、AIO） がユーザー行動に与える影響を分析したレポートを<a href="https://www.pewresearch.org/short-reads/2025/07/22/google-users-are-less-likely-to-click-on-links-when-an-ai-summary-appears-in-the-results/">公表</a>した。</p>
<p>対象は同年3月に米国の成人900人から収集した 68,879件 の検索データで、AIOが表示された結果ページでは外部リンクのクリック率が 8％ にとどまり、AIOが表示されないページの 15％ を大きく下回った。</p>
<h2>クリック率は半減、要約内リンクは1％</h2>
<ul>
<li><strong>AI要約機能（AIO）あり</strong>  の検索セッションで外部リンクをクリックしたのは 8％。</li>
<li><strong>要約なし</strong> のセッションでは 15％。</li>
<li>AIO内に<strong>埋め込まれたリンク</strong>がクリックされたのは 全検索の1％ にすぎなかった。</li>
</ul>
<p>数値はいずれも、ユーザーが 「AIが要約したサマリー」だけで情報ニーズを満たすケース が増えている可能性を示している。</p>
<p><strong>■ AI要約の有無で変わるユーザー行動</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/SR_25_07_22_ai_summaries_1_9d1f951ed6/SR_25_07_22_ai_summaries_1_9d1f951ed6.jpg" alt="SR_25.07.22_ai_summaries_1.jpg" /></p>
<h2>離脱率や検索行動にも影響</h2>
<p>AIOが表示されたページでは、何もクリックせずに離脱する ゼロクリック率 が 26％。要約がない場合の 16％ と比べて高かった。一方で、AIOページを見たユーザーの 59％ は同じセッション内で別クエリを実行しており、検索そのものの継続意欲は保たれている。</p>
<h2>AI要約は約5回に1回の頻度で表示</h2>
<p>分析対象となった68,879件の検索データのうち、AI Overviewが表示されたのは12,593件で、全体の約18%にあたる。これは、2025年3月時点でのAIOの表示頻度が比較的限定的であったことを示している。</p>
<p>また、AIOに引用された外部ソースとしては、WikipediaやYouTube、Redditなど一般的なプラットフォームに加え、.gov（米政府系）ドメインの割合が通常の検索結果に比べてやや高い傾向にあったという。</p>
<p><strong>■ AI要約はWikipedia・.govリンクが多め</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/SR_25_07_22_ai_summaries_2_61e865f460/SR_25_07_22_ai_summaries_2_61e865f460.jpg" alt="SR_25.07.22_ai_summaries_2.jpg" /></p>
<h2>調査方法と制限事項</h2>
<ul>
<li><strong>データ取得</strong> ：Pewのリクルートパネル「KnowledgePanel Digital」参加者の実ブラウジングログ</li>
<li><strong>期間</strong> ：2025年3月1〜31日</li>
<li><strong>判定方法</strong> ：4月7〜17日に検索結果HTMLをスクレイピングし、AIOの有無とリンク元ドメインを分類</li>
<li><strong>制限</strong> ：検索エンジンはGoogleのみ、AIO表示頻度は時期やユーザー属性で変動する可能性あり</li>
</ul>
<h2>今後の注目点</h2>
<p>Googleは、AI Overview機能を2024年5月に米国で本格導入した後、2025年5月には日本を含む他国でも展開を開始した。これにより、検索結果上での情報提供の形が大きく変化しつつある。</p>
<p>一部の出版社やニュースメディアは、AI要約機能が自社サイトへのトラフィック減少につながる可能性を指摘しており、2025年6月には米Wall Street JournalがAIOの影響について報じた。</p>
<p>Googleは、今後もAI Overviewの国際展開と商用広告モデルのテストを継続するとしており、検索エンジン最適化（SEO）やコンテンツ提供戦略の再考が業界全体に求められている。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/25 [FRI]OpenAI、次世代LLM「GPT‑5」を8月投入へ：米メディア報道——統合推論で“選ばない”AI体験に</title>
      <link>https://ledge.ai/articles/gpt5_expected_august_release</link>
      <description><![CDATA[<p>OpenAIが、大規模言語モデル「GPT‑5」を2025年8月上旬にもChatGPTおよびAPI向けに公開する計画を進めていることが明らかになった。米メディア<a href="https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-release-date-notepad">The Verge</a>が7月24日、同社の計画に詳しい関係者の証言として報じたもので、GPT‑5は推論能力の統合により、従来必要だったモデル選択の手間を排除する設計になるとされている。</p>
<h2>Altman氏が性能を示唆、内部テストは最終段階へ</h2>
<p>報道によれば、OpenAIはGPT‑5の社内テストをすでに最終段階に入れており、パフォーマンスと安全性の検証を進めているという。OpenAIのCEOであるSam Altman氏は7月に出演したポッドキャスト「All-In」で、GPT‑5に初めて質問を投げかけた際の体験について「まったく選ばずに完璧に応答した」と述べており、次世代モデルの推論能力に手応えを感じていることがうかがえる。</p>
<p>また、Altman氏は米X（旧Twitter）上でも「GPT-5 is coming soon」と<a href="https://x.com/sama/status/1946569252296929727">投稿</a>しており、正式な公開が近いことを示唆していた。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/openai_gold_medal_performance_d2a227b058/openai_gold_medal_performance_d2a227b058.jpg" alt="openai gold medal performance.jpg" /></p>
<h2>メイン・mini・nanoの3構成で提供へ</h2>
<p>関係者によれば、GPT‑5は用途別に「メイン」「mini」「nano」の3モデルが存在し、それぞれ性能と速度のバランスに応じて使い分けが想定されているという。nanoモデルはAPI専用に設計され、軽量かつ高速な推論が特徴。また、ChatGPTなどのUI上では、ユーザーが明示的にモデルを選ぶ必要のない設計に刷新されると報じられている。</p>
<p>この統合的なアプローチは、2024年5月に登場したGPT‑4oの設計思想を引き継ぐ形で、従来型のマルチモデル環境から単一インターフェースへの移行を進める狙いがあるとみられる。</p>
<h2>AGIとの関係も注視点に</h2>
<p>OpenAIはMicrosoftとの間で「AGI到達時に収益配分契約の条件を見直す」条項を設けているとされており、今回のGPT‑5がその「AGI（汎用人工知能）」に該当するかどうかは大きな注目点である。Altman氏自身は、GPT‑5リリース直後の段階では「ゴールドレベルの完成度に達するには数か月かかる」と述べており、商用展開と並行して精度や安全性の向上を図る方針であることがうかがえる。</p>
<p>GPT‑5の最終的な公開時期は、社内で実施されている安全性評価や推論性能の検証によって左右される見通しだという。OpenAIは現在、社外の倫理レビュー団体やレッドチームとの連携も強化しており、2023年以降強化してきたリリース前安全基準に照らした最終判断が行われるとみられる。</p>
<p>7月24日時点では、OpenAIから公式コメントは出ていない。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI、AIポルノ生成を全面禁止へ──7月31日から利用規約改定、Stable Diffusion・API・OSSを含む全サービスで性的コンテンツを遮断</title>
      <link>https://ledge.ai/articles/stability_ai_policy_update_nsfw_ban</link>
      <description><![CDATA[<p>ロンドンを拠点とする生成AI企業Stability AIは、2025年7月31日付で同社サービスの利用規約（Acceptable Use Policy, AUP）を<a href="https://stability.ai/use-policy">改定</a>し、Stable Diffusionをはじめとする自社製AIモデル・API・オープンソースコードにおいて、性行為に関連するコンテンツの生成・使用を一律禁止する。</p>
<p>営利・非営利の区別なく適用されるこの新方針は、AIコンテンツの安全性と倫理性を確保する目的で導入されるという。</p>
<h2>性的コンテンツの生成・共有を包括的に禁止</h2>
<p><a href="https://stability.ai/use-policy">新たな利用規約</a>では、「We Prohibit Sexually Explicit Content」の項が新設され、以下の内容が禁止事項として明記された。</p>
<ul>
<li>性行為、性的行為、性的暴力を含むあらゆるコンテンツの生成・共有</li>
<li>非合意の親密画像（NCII: Non-Consensual Intimate Imagery）</li>
<li>違法ポルノや児童搾取コンテンツ</li>
</ul>
<p>これらの規定は、DreamStudio、Stable Diffusion（あらゆるチェックポイントや自己ホスト版）、Stable Video、Stable Audio、Platform API、LoRA（Low-Rank Adaptation）共有機能、さらにGitHubなどで配布されるオープンソースコードを含むすべてのサービスに適用される。</p>
<p>規約違反が判明した場合、Stability AIは利用停止や契約解除などの措置を取ると定めている。また、18歳未満の利用も引き続き禁止される。</p>
<h2>従来規約との大きな違い</h2>
<p>この改定は、2024年3月1日版の旧AUPと比較して大幅な変更となる。
<a href="https://stability.ai/prior-aup">従来の規約</a>では、禁止対象は「非合意ヌード」「違法ポルノ」「児童搾取コンテンツ」などに限定されており、合意の成人同士によるポルノ的表現については明確な禁止はなかった。</p>
<p>新AUPでは、「性行為そのもの」に関わるコンテンツすべてを対象とすることで、生成物の内容に関わらず包括的な制限を設けている。</p>
<h2>デベロッパーとユーザーへの影響</h2>
<p>新規約の対象範囲には、以下のような商用・非商用ツールや資源が含まれる。</p>
<ul>
<li>公式Webアプリ「DreamStudio」</li>
<li>Stable Diffusion（オープンモデル、自己ホスト含む）</li>
<li>音声・映像生成ツール（Stable Audio／Stable Video）</li>
<li>各種APIアクセス、LoRAモデル共有、オープンソースコードの再利用</li>
</ul>
<p>営利・非営利の区別はなく、個人利用や趣味での創作であっても規約違反となる。既存のモデルやワークフローで対象となるコンテンツを扱っている開発者や企業は、今後の運用方針の見直しが必要となる。</p>
<h2>背景：AIポルノをめぐる規制の強化</h2>
<p>今回の規約改定は、AI技術を悪用した性的コンテンツの氾濫に対処する国際的な動きの一環と見られる。特にディープフェイク技術による著名人の偽ポルノ動画や、非合意の画像生成が社会問題化する中で、生成AIモデル各社はNSFW（Not Safe For Work）フィルタの強化やアダルトコンテンツの禁止に取り組んでいる。</p>
<p>Stability AIはオープンウエイトの提供で知られる企業のひとつであり、同社による包括的な制限の導入は、オープンモデル領域における規制の方向性に大きな影響を与える可能性がある。</p>
<h2>今後のスケジュールと対応</h2>
<p>新規約は2025年7月31日より施行される。以降は新規・既存ユーザーともに順守が義務づけられ、違反が確認された場合にはアクセスの遮断やアカウントの停止措置が取られる見通しだ。</p>
<p>同社は今後、利用者向けのFAQやガイドラインの公開も予定しており、具体的な基準や判断基準についての詳細は順次明らかにされるとみられる。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>東大・松尾研の無料オンラインAI講座、累計7.5万人突破──30超の講座で“2040年326万人デジタル人材不足”に挑む</title>
      <link>https://ledge.ai/articles/tokyo_university_ai_course_hits_75000_users</link>
      <description><![CDATA[<p>2025年7月16日、東京大学大学院工学系研究科の松尾・岩澤研究室（以下、松尾研）は、2014年より提供するオンラインAI講座の累計受講者数が75,000人を突破したと<a href="https://weblab.t.u-tokyo.ac.jp/news/2025-07-16/">発表</a>した。</p>
<p>講座では、AIやデータサイエンスをテーマに30以上の科目を無料でオンライン提供しており、中学生から大学院生まで、文理や地域を問わず受講可能である。経済産業省が推計する「2040年に326万人のデジタル人材不足」への対応策の一環として、同研究室は年間70,000人の受講者を目標に掲げている。</p>
<h2>累計7.5万人到達の背景</h2>
<p>松尾研のAI講座は2014年にスタートし、10年余りで急速に受講者数を伸ばしてきた。特に直近では、2024年度に約27,000人が受講し、2025年度には年間70,000人の受講者を目指すとしている。学年や専攻に関係なく、AIに関心を持つ学生に向けて門戸を広げてきたことが、大きな広がりを見せる要因となっている。</p>
<h2>30超の講座を“無料・オンライン”で提供</h2>
<p>松尾研では、年間30講座以上をオンラインで開講しており、受講料はすべて無料となっている。提供されている講座には、以下のようなものがある：</p>
<ul>
<li>GCI（グローバル消費インテリジェンス）入門講座</li>
<li>ディープラーニング（基礎／応用）講座</li>
<li>AIと半導体講座</li>
<li>Physical AI講座</li>
<li>AI起業サマープログラム</li>
</ul>
<p>中でも「GCI入門講座」は、累計3.1万人以上が受講しており、最も人気の高い講座の一つだという。</p>
<h2>人材不足326万人→松尾研モデルが果たす役割</h2>
<p>経済産業省の調査によると、2040年までに日本国内で最大326万人のデジタル人材が不足する見通しだとされている。この深刻な人材不足に対し、松尾研が展開するオンライン講座は、無料かつ地理的制約がないという利点を活かし、地方や海外にいる学生にも学習機会を提供している。こうした取り組みは、教育格差の是正と人材育成の底上げの両面で一定の効果を発揮していると考えられる。</p>
<h2>学んだ知識を“机上で終わらせない”実践機会</h2>
<p>松尾研では、講義で得た知識を現実のプロジェクトに活かす機会も提供している。企業との共同研究や、同研究室から生まれたスタートアップ企業でのインターンシップ、さらにAI起業をテーマにしたサマープログラムなど、実践的な取り組みが並行して進められている。受講者が自身のキャリアや事業化に直結させることができる点が、他の教育プログラムとの差別化要因となっている。</p>
<h2>今後の展開──LLM講座やASEAN展開へ</h2>
<p>今後の展望としては、大規模言語モデル（LLM）をテーマにした新講座を2025年8月より募集開始予定とされている。また、ASEANやアフリカ諸国への展開も本格化しており、グローバルな教育体制の整備が進んでいる。さらに、GCI講座は2025年10月から東京大学の正規科目として単位認定される予定であり、同講座のアカデミックな価値も高まりつつある。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>公共2025/7/28 [MON]東京都、全庁横断「AI戦略」を正式発表──生成AI基盤で都民サービスと業務を“面”展開</title>
      <link>https://ledge.ai/articles/tokyo_ai_strategy_2025</link>
      <description><![CDATA[<p>東京都は2025年7月25日、<a href="https://www.digitalservice.metro.tokyo.lg.jp/business/ai/ai-strategy">「東京都AI戦略」</a>を策定・公表した。都民サービスの質向上と行政業務の生産性向上を目的に、生成AIを含むAI技術の活用を全庁横断で“面”展開していく方針を明示した。</p>
<p>今後は、庁内外のさまざまな領域でAIの導入を本格化させ、都市の持続可能性と競争力の両立を目指すという。</p>
<h2>人口減少と行政課題の複雑化に対応、戦略の背景</h2>
<p>東京都は本戦略において、少子高齢化と人口減少による労働力不足、複雑化・多様化する行政課題を今後の都政の大きな制約要因として挙げている。2065年には都の人口が2020年比で約1割減となる推計も示されており、人的資源に依存しない行政の実現が喫緊の課題となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyo_2065_973c3bcde0/tokyo_2065_973c3bcde0.jpg" alt="tokyo 2065.jpg" /></p>
<p>こうした背景のもと、都は生成AIをはじめとするAI技術を「2050東京戦略」の中核技術と位置づけ、従来の“点”の実証から“面”での全庁展開へと政策の転換を図ると明言した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyoai_strategy2_6c78bee684/tokyoai_strategy2_6c78bee684.jpg" alt="tokyoai strategy2.jpg" /></p>
<h2>AI利活用に当たっての6つの留意事項とリスク管理</h2>
<p>東京都AI戦略は、生成AIを含むあらゆるAI技術を導入する際の指針として、次の 6つの留意事項 を示している。</p>
<ul>
<li><strong>透明性</strong> ：AIがどのように判断し、結果を導いたかを説明できる状態を確保する。</li>
<li><strong>公平性</strong> ：アルゴリズムによる差別を防ぎ、すべての都民に公平にサービスを提供する。</li>
<li><strong>安全性</strong> ：AIの誤作動や想定外の挙動によるリスクを最小化する。</li>
<li><strong>プライバシー</strong> ：個人情報を適切に取り扱い、法令・ガイドラインを順守する。</li>
<li><strong>セキュリティ</strong>：サイバー攻撃やデータ侵害からシステムと情報を守る。</li>
<li><strong>アカウンタビリティ（説明責任）</strong> ：AI導入の責任主体を明確にし、結果に対して説明できる体制を整える。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyoai_strategy3_756cc67377/tokyoai_strategy3_756cc67377.jpg" alt="tokyoai strategy3.jpg" /></p>
<p>さらに都は、業務ごとのリスクを「青（低リスク）」「黄（中リスク）」「赤（高リスク）」の3段階で評価し、活用範囲と管理レベルを段階的に設定する仕組みを導入する。これにより、利便性と安全性のバランスを取りながら、AIを都政の中核に据えていく方針だという。</p>
<h2>生成AI基盤を庁内標準に、都政業務を再設計</h2>
<p>戦略の柱のひとつが、GovTech東京と連携した生成AI共通プラットフォームの整備である。都の規程や業務マニュアルなどを学習させたAIを用い、職員が専門的な質問に即応できるQ&amp;Aシステムや、議事録自動生成、文案作成支援などの用途を想定している。用途に応じた複数の大規模言語モデル（LLM）を選択可能にするなど、柔軟性の高い運用体制も特徴とされる。</p>
<p>加えて、都は生成AIの利活用について、共通ツールの導入にとどまらず、職員研修や相談窓口の設置などを通じて、リテラシーと業務改革の両面から支援していくとした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyoai_strategy4_60d00ddb21/tokyoai_strategy4_60d00ddb21.jpg" alt="tokyoai strategy4.jpg" /></p>
<h2>現状分析：庁内活用95％、インフラ関連が最多31％</h2>
<p>東京都が把握する AI関連事業のうち 95％ は、申請・審査、設備管理など都庁内部での業務改善を目的とした「都政におけるAI利活用」が占める。残る 5％ は、民間企業へのAI導入支援や人材育成などの補助事業に充てられている。</p>
<p>「都政におけるAI利活用」を政策分野別に見ると、
インフラ・まちづくり が 31％ で最多。
以下、その他（税・財務等）17％、産業・雇用15％、子供・教育11％、安全・安心8％、福祉・医療7％、文化・スポーツ6％、共通基盤6％ と続く。</p>
<p>主体別では、職員主体 63％／都民・事業者主体 37％ となっており、現時点では職員向けツールが依然として中心であることが分かる</p>
<p><strong>東京都におけるAI関連事業の内訳と政策分野別比率</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyoai_strategy6_b5ca5118d1/tokyoai_strategy6_b5ca5118d1.jpg" alt="tokyoai strategy6.jpg" /></p>
<p>この偏りを是正する形で、戦略では“都民サービス領域へのAI展開”を明確な重点項目として掲げている。</p>
<h2>推進体制と今後の展開</h2>
<p>推進体制としては、デジタルサービス局が全体統括の役割を担い、政策立案・財務支援・技術支援の三位一体で全庁をサポートする。各局には「AI利活用推進責任者」が新設され、CIO補佐官やGovTech東京が伴走型支援を実施する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tokyoai_strategy5_f77cfbb052/tokyoai_strategy5_f77cfbb052.jpg" alt="tokyoai strategy5.jpg" /></p>
<p>また、区市町村・国・民間企業との連携体制も強化し、スタートアップとの協働や中小企業支援、教育機関との人材育成プログラムなどを通じて、都全体でAIの社会実装を進める構えである。</p>
<h2>都はAIネイティブ都市へと進化できるか</h2>
<p>戦略は、今後のロードマップとして、AIを行政運営の前提に据えた「AIネイティブ都市東京」を将来的なビジョンに据えている。都は今後、戦略に基づいた実装事例やKPIを段階的に公表していく予定であり、他自治体や企業にとっても注視すべき展開となる。</p>
]]></description>
      <pubDate>Mon, 28 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/22 [TUE]【8/19(火)13時〜、LIVE開催】小型LLMでGPT-4o超え！ABEJAの最新LLMとハイレゾのGPUクラウドで読み解くAI開発の最前線｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol67</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>ABEJAが開発した小型LLM「QwQ-32B Reasoning Model」は、わずか32Bという軽量サイズでありながら、GPT-4oを上回る推論性能を記録。日本語に強く、コーディングや数学など高度な思考タスクにも対応可能な構造を備えた、思考する小型LLMとして注目を集めています。</p>
<p>本ウェビナーでは、同モデルの特長や、軽量化と高精度の両立を実現した開発上の工夫を解説。あわせて、今後の社会実装に向けた展望や、業務特化型LLMの構築支援についてもご紹介します。
ウェビナーの後半では、ハイレゾが提供するオンプレミスを上回る柔軟性とコストパフォーマンスを備えたGPUクラウドサービスをご紹介。LLMの開発・実行における具体的な活用事例を交えながら、その実用性と優位性をわかりやすくお伝えします。</p>
<p>当日はLIVE配信にて、ウェビナーを実施いたします。ご視聴希望の方は、以下の視聴用フォームよりご登録をお願いいたします。</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_sPbK7UbhSlKIRbGZWg7Gfw">ウェビナーの視聴はこちら</a>
:::</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li>GPT-4oを上回る推論性能を実現したABEJAの小型LLM「QwQ-32B Reasoning Model」の技術的特徴と開発背景</li>
<li>日本語・コーディング・数学などの高度なタスクに対応する構造と、業務特化型LLMとしての可能性</li>
<li>ハイレゾのGPUクラウドを活用した、柔軟かつ高コスパなLLM開発・運用の実践事例</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>社内外でのLLM活用や自社業務特化型モデルの構築を検討しているMLエンジニア・AIプロジェクト責任者</li>
<li>LLMの軽量化や高精度化、クラウドインフラの最適化に関心のある情報システム部門・インフラ担当者</li>
<li>製造・IT・建設・大学研究機関などで、AI活用を本格的に推進したいと考えている方</li>
</ul>
<h2>登壇者情報</h2>
<p><strong>株式会社ハイレゾ
マーケティング部　グループ長
山田 岳史 氏</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_e7b7533fdd/image2_e7b7533fdd.jpg" alt="image2.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスの事業開発からマーケティングを担当。</p>
<p><strong>株式会社ABEJA
プリンシパルデータサイエンティスト
服部 響 氏</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/abeja_prof_1a867ccbb5/abeja_prof_1a867ccbb5.png" alt="abeja-prof.png" /></p>
<p>趣味で麻雀AIを作ったことをきっかけに機械学習の道に入る。前職で、画像認識を用いたアプリの開発や機械学習を用いたユーザプロファイリングに従事。
2020年5月にABEJA入社。データサイエンティストとして幅広いプロジェクト及びデータサイエンス組織のマネージャーを経験した後、プリンシパルデータサイエンティストとして専門職のキャリアへ進む。
現在はGENIACプロジェクトでプロジェクトリーダーとしてLLM開発を牽引。
趣味でデータ分析コンペティションに積極的に参加。Kaggle Grandmaster。Kaggle days world championship優勝。atmaCupはじめ国内コンペで複数回優勝経験あり。</p>
<h2>お申し込みはこちら</h2>
<p>イベント名：小型LLMでGPT-4o超え！ABEJAの最新LLMとハイレゾのGPUクラウドで読み解くAI開発の最前線
配信日：2025年8月19日(火) 13:00-14:00
配信方式：LIVE（Zoom Webinar）
参加費：無料（事前登録制）</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_sPbK7UbhSlKIRbGZWg7Gfw">ウェビナーの視聴はこちら</a>
:::</p>
]]></description>
      <pubDate>Tue, 22 Jul 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>