<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>スタジオジブリや任天堂など加盟のCODA、OpenAIに要望書──動画生成AI「Sora 2」の無許諾学習に懸念</title>
      <link>https://ledge.ai/articles/coda_request_to_openai_sora2</link>
      <description><![CDATA[<p>一般社団法人コンテンツ海外流通促進機構（CODA）は2025年10月27日、動画生成AI「Sora 2」を開発・運用するOpenAI, L.L.C.に対して<a href="https://coda-cj.jp/news/2577/">要望書を提出</a>した。スタジオジブリや任天堂、東宝、集英社、講談社など、国内主要コンテンツ企業が加盟する同機構は、AIによる無許諾学習および著作権侵害の懸念を指摘している。</p>
<p>要望書ではOpenAIに対し、主に以下の2点を求めている。
1つ目は、CODA会員社のコンテンツを無許諾で学習対象としないこと。2つ目は、Sora 2の生成物に関して会員社から著作権侵害の申立てや相談があった場合、真摯に対応すること。同機構は、AI企業が透明性と説明責任を果たし、権利者の利益を尊重するよう求めた。</p>
<p>Sora 2は、テキストから動画を生成できるOpenAIの次世代モデルで、実在のアニメ作品や映画、ゲームを連想させる映像も生成可能だとされる。SNS上では著名キャラクターや既存作品の表現を模倣した動画が多数投稿されており、著作権や肖像権の侵害につながるおそれが指摘されている。</p>
<p>CODAは、アニメ・ゲーム・映画・出版など100社以上の会員で構成され、海外での海賊版対策や知的財産保護を目的とする非営利団体。同機構は声明の中で、「生成AI時代においても、創作者の正当な権利が損なわれることがあってはならない」と強調している。</p>
<p>生成AIによる著作物利用をめぐっては、米国や欧州でも“オプトアウト方式”の是非をめぐる議論が続く。OpenAIを含む各社は、学習データセットの詳細を非公開としており、透明性や権利処理のあり方が国際的な課題となっている。日本でも、著作権法第30条の4（学習利用）の適用範囲をめぐる議論が高まりつつある。</p>
<p>今後CODAは、国内外の権利者団体との連携を強化しつつ、OpenAIからの回答を注視するとしている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GitHub、「Agent HQ」を発表──“あらゆるエージェントを、いつでもどこでも”統合管理</title>
      <link>https://ledge.ai/articles/github_agent_hq_announcement_universe2025</link>
      <description><![CDATA[<p>GitHubは2025年10月28日（米国時間）、年次イベント「GitHub Universe 2025」で新ビジョン「Agent HQ」を<a href="https://github.blog/news-insights/company-news/welcome-home-agents/">発表</a>した。これは、複数のAIコーディングエージェントを単一の環境で呼び出し、管理・連携できる統合プラットフォームである。</p>
<p>公式ブログによると、Agent HQは“あらゆるエージェントを、あらゆる開発スタイルで使える”ことを目指した新構想で、Anthropic、OpenAI、Google、Cognition、xAIなど各社のエージェントを有料のGitHub Copilotサブスクリプションの一部として提供するという。提供開始は今後数カ月を予定。</p>
<p>@<a href="https://www.youtube.com/watch?v=KniyIrpTDE8&amp;t=5s">Youtube</a></p>
<h2>複数エージェントを一元管理する「Mission Control」</h2>
<p>Agent HQの中核機能として「Mission Control」が導入される。開発者が複数のエージェントをタスクごとに割り当て、進行状況を可視化できる中枢機能で、GitHub、Visual Studio Code、CLIなど複数の開発環境で同一の体験を提供する。</p>
<p>また、組織の管理者は各エージェントのアクセス権限や利用ポリシーを制御できる「コントロールプレーン」を通じて、企業やチーム単位でのガバナンスを強化できる仕組みも備える。</p>
<h2>サードパーティ連携を前提とした“開かれたHQ”</h2>
<p>Agent HQは、特定モデルに依存しない「オープンなエージェント基盤」として設計されている。
GitHubは「開発者は自分の選んだAIエージェントを同じワークフローで活用できる」と述べ、今後数か月で各社のエージェントを順次統合していく予定だ。</p>
<p>この発表は、GitHubが掲げる“開発者が中心にいる未来”という長期ビジョンの延長線上にあり、同社はCopilotを単なる補助ツールから、複数AIが協働する「開発の司令塔」へと進化させようとしている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>講談社・KADOKAWAなど19団体、「オプトアウト原則は侵害につながる」と共同声明──生成AI時代の創作と権利のあり方を提示</title>
      <link>https://ledge.ai/articles/joint_statement_ai_creative_rights_20251031</link>
      <description><![CDATA[<p>2025年10月31日、講談社やKADOKAWAをはじめとする出版社17社と、日本漫画家協会、日本動画協会の計19団体は、「生成AI時代の創作と権利のあり方に関する共同声明」を<a href="https://nihonmangakakyokai.or.jp/archives/news/20251031">発表</a>した。</p>
<p>声明は、OpenAIの映像生成AI「Sora2」によって既存作品への依拠や類似が疑われる事例が確認されたことを背景に、著作権法の原則に基づく3つの原則を提示。「オプトアウト原則は権利侵害につながる」と明記し、AI事業者に対して法的原則の順守を求めた。</p>
<h2>「Sora2」公開が引き金に</h2>
<p>声明では、2025年10月にOpenAIが映像生成AI「Sora2」をローンチし、その生成物がSNSなどで共有された際、既存の著名なアニメや漫画の表現に類似する事例が散見されたと指摘している。
同AIが「権利者から明示的なオプトアウト申請がない限り生成・公開が可能な仕組み」を採用している点について、「我が国の著作権法およびWIPO著作権条約の原則に反する」と明記した。</p>
<p>OpenAIの経営者個人がSNS上で「オプトイン方式への転換」を示唆したものの、企業としての正式方針ではないとし、「第二、第三のSora2」とも言うべき新たな生成AIの登場を見据え、業界として立場を明確にする必要があると判断したという。</p>
<h2>「創作の喜び」と「権利保護」の両立を掲げる</h2>
<p>声明は「生成AI技術の進展を歓迎する」としつつ、「著作権侵害を容認しない」という原則を改めて確認。
文化的創造の持続可能性と技術革新の恩恵を両立させるため、AI事業者に対して次の3つの原則を示した。</p>
<ul>
<li>学習段階および生成・公表段階の両方において、権利者に必要な許諾を得るなど著作権法の原則に沿った対応を取ること</li>
<li>学習データの透明性を担保すること</li>
<li>権利者が利用を許諾した場合、適正な対価還元を行うこと</li>
</ul>
<p>さらに、生成AIの利用者が他者の著作物をもとにしたことを知らずに作品を公開し、結果として他のクリエイターの権利を損なう状況を防ぐため、権利者・AI事業者・関係省庁の連携を呼びかけている。</p>
<h2>「オプトアウト原則は侵害につながる」</h2>
<p>声明の中で特に強調されたのが、「オプトアウト原則」への懸念だ。
AI事業者が権利者に無断で著作物を学習・再利用することは、「著作権法の『権利者の許諾を得てから利用する』という原則に反する行為」であり、権利侵害に直結すると明記。その上で「AI事業者が権利者に対してオプトインを申請し、使用許諾を得ることの徹底」を求めている。</p>
<p>また、学習データの出典が不明確なままでは、権利侵害の検証や作品評価の毀損対応が困難になるとして、データ透明性の担保を「不可欠」と位置づけた。</p>
<h2>「技術を拒絶するものではない」</h2>
<p>声明は、生成AIを排除するものではないと明言する。
「創作に携わるすべての人の努力と尊厳を守るための責任」と位置づけ、法的・倫理的観点から著作権侵害に適切に対応する姿勢を表明した。同時に、「クリエイターとユーザーの双方が安心して創作・利用できる環境を整えることを重視する」と記した。</p>
<h2>今後の方向性──「利用と保護の両立」を模索</h2>
<p>声明は締めくくりとして、「AI時代における公正で透明、かつ持続可能な創作環境の構築・維持に努める」と明示。
業界内外のステークホルダーとの協調を通じて、創作物の「利用と保護」の両立を目指す姿勢を示した。</p>
<h3>発出団体（五十音順）</h3>
<p>一般社団法人 日本動画協会／公益社団法人 日本漫画家協会／株式会社秋田書店／株式会社一迅社／株式会社宙出版／株式会社KADOKAWA／株式会社コアミックス／株式会社講談社／株式会社小学館／株式会社少年画報社／株式会社新潮社／株式会社スクウェア・エニックス／株式会社竹書房／株式会社TOブックス／株式会社日本文芸社／株式会社白泉社／株式会社双葉社／株式会社芳文社／株式会社リイド社</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとAWS、7年・380億ドルの戦略的提携を発表──数十万GPUとUltraServersでAI基盤を拡充</title>
      <link>https://ledge.ai/articles/openai_aws_multi_year_partnership_2025</link>
      <description><![CDATA[<p>2025年11月3日（現地時間）、OpenAIとAmazon傘下のAmazon Web Services（AWS）は、複数年にわたる戦略的パートナーシップを締結したと<a href="https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure">発表</a>した。</p>
<p>OpenAIは発表当日からAWS上で主要AIワークロードの稼働を開始しており、契約総額は今後7年間で380億ドル（約5.8兆円）にのぼる。数十万規模のNVIDIAチップを備えたUltraServersを活用し、AIトレーニングと推論の両面で大規模な計算基盤を構築する。</p>
<h2>OpenAIのAIワークロードをAWSで稼働</h2>
<p>今回の提携により、OpenAIはAWSのインフラを活用してChatGPTをはじめとする主要サービスや次世代モデルのトレーニングを実行する。AWSは「immediate availability（即時利用可能）」を強調し、提携発表と同時にOpenAIのワークロードを稼働させたと説明している。</p>
<p>契約期間は7年間で、OpenAIはAWS上に総額380億ドル規模のコンピューティング・キャパシティを確保。2026年末までに全リソースを配備することを目標とし、状況に応じて2027年以降の拡張も検討されている。</p>
<h2>GB200/GB300世代GPUとUltraServersを採用</h2>
<p>AWSは、最新のNVIDIA GB200およびGB300世代チップを搭載した「Amazon EC2 UltraServers」を提供。これにより、OpenAIは数十万規模のNVIDIAチップと数千万CPUを同一ネットワーク上で動作させ、AI学習や推論を高効率に処理できる。</p>
<p><strong>AWSのデータセンター外観。今後数十万規模のGPUクラスタを展開予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_71f1f7cec4/2_71f1f7cec4.jpg" alt="ダウンロード (2).jpg" /></p>
<p>クラスタは低レイテンシの相互接続を備え、複数データセンターを単一の高性能ファブリックとして動作させる設計。AWSはこれを「最適化された大規模AIワークロード環境」と位置づけている。</p>
<p><strong>AWSインフラ内部。UltraServers間を接続するネットワークケーブル群</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_17c982221d/7_17c982221d.jpg" alt="ダウンロード (7).jpg" /></p>
<p>OpenAI CEOのサム・アルトマン氏は「フロンティアAIを安全にスケーリングするためには、massive, reliable computeが不可欠だ」と述べ、今回の提携が「advanced AI to everyone（すべての人に先進的AIを届ける）」基盤となると語った。AWS CEOのマット・ガーマン氏は「OpenAIの膨大なワークロードを支えるbest-in-class infrastructureを提供できることを誇りに思う」とコメントしている。</p>
<h2>今後の展開</h2>
<p>リリースでは、Amazon Bedrock上でOpenAIのオープンウェイト基盤モデルが利用可能になったことにも言及。すでにBystreet、Comscore、Peloton、Thomson Reuters、Triomics、Verana Healthなど数千社が導入を開始しているという。</p>
<p>AWSは、2026年末までに全キャパシティの配備を完了させる計画を示している。今回の契約により、OpenAIはAWS上でAIモデルのトレーニングおよび推論を長期的に実施できる環境を確保した。両社は今後もAIインフラの拡張と最適化を進め、安定した計算リソースの提供を継続する方針だ。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、広告画像を自動生成する新ツール「Pomelli」を発表──ブランドの“DNA”をAIが理解し、一貫したキャンペーンを提案</title>
      <link>https://ledge.ai/articles/google_pomelli_ai_ad_generation_tool</link>
      <description><![CDATA[<p>Googleは2025年10月28日（米国時間）、広告やSNSキャンペーン向けの画像を自動生成できる新ツール「Pomelli（ポメリ）」を<a href="https://blog.google/technology/google-labs/pomelli/">発表</a>した。Google Labsの実験プロジェクトとして公開されており、ユーザーが自社サイトのURLを入力すると、ブランド特性を分析して“Business DNA”を構築し、それに基づいて画像やコピーなどのアセットを提案する。</p>
<p>@<a href="https://www.youtube.com/watch?v=rsWPISYv6tQ">YouTube</a></p>
<h2>ブランドの「DNA」をAIが理解して広告素材を生成</h2>
<p>Pomelliは、企業サイトに含まれる色・言葉・トーンなどをAIが解析し、ブランドの「Business DNA」としてまとめる。この情報をもとに、SNS投稿用の画像、広告用コピー、キャンペーン案などを生成する仕組みだ。DeepMindとの協力のもと開発されたとされ、Googleは「ブランドの一貫性を保ちながら、より迅速にマーケティング素材を作成できる」としている。</p>
<p><strong>Pomelliは企業サイトを解析し、ブランドカラー・フォント・イメージを自動抽出して「Business DNA」を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39.webp" alt="Pomelli_Keyword_Blog_In-line_-_1.width-1000.format-webp.webp" /></p>
<h2>中小企業でも“オンブランド”の広告を短時間で</h2>
<p>Pomelliの想定ユーザーは、中小規模の企業（SMB）や個人事業主だ。デザイナーやマーケターが限られた環境でも、ブランドトーンを保った高品質な素材を数分で生成できる。SNSごとのフォーマットや文体に応じた最適化にも対応しており、季節キャンペーンやセールなどの展開を容易にする。</p>
<p><strong>解析したBusiness DNAをもとに、AIが複数のキャンペーン案を提示する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069.webp" alt="Pomelli_Keyword_Blog_In-line_-_2.width-1000.format-webp.webp" /></p>
<h2>生成された広告をその場で編集・修正可能</h2>
<p>生成された画像やコピーは、フォント・色・キャッチコピーなどをGUI上で細かく調整できる。Googleはこれを「人間の創造力を補助する共同作業ツール」と位置付けており、単なる自動生成ではなく、人の手による最終調整を想定している。</p>
<p><strong>生成された広告素材は、色やフォント、コピーをその場で編集できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f.webp" alt="Pomelli_Keyword_Blog_In-line_-_3.width-1000.format-webp.webp" /></p>
<h2>提供形態と今後の展開</h2>
<p>PomelliはGoogle Labsの実験ツールとして提供されており、現在は限定公開の段階にある。公式サイトでは「Easily generate on-brand content for your business（自社ブランドに沿ったコンテンツを簡単に生成）」と説明されている。</p>
<p>現時点で提供対象は米国、カナダ、オーストラリア、ニュージーランドの英語版ユーザーに限られており、日本国内では未提供。Googleは今後の地域拡大について明らかにしていないが、利用可能国の追加が期待される。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT西日本とアイリスオーヤマが業務提携──清掃ロボット「JILBY」にugo技術を採用、AIプラットフォームで現場DXを加速</title>
      <link>https://ledge.ai/articles/iris_nttwest_jilby_ugo_platform</link>
      <description><![CDATA[<p>NTT西日本とアイリスオーヤマは2025年10月29日、サービスロボット分野における業務提携を<a href="https://www.ntt-west.co.jp/news/2510/251029a.html#a2">発表</a>した。</p>
<p>両社は「フィジカルAIやロボットを含むIoT領域におけるDX推進に関する基本合意書」を締結し、第一弾の取り組みとして、アイリスオーヤマのDX清掃ロボット「JILBY（ジルビー）」に、NTT西日本グループの「AIロボティクスプラットフォーム」を採用する。</p>
<p>この「AIロボティクスプラットフォーム」は、ugo株式会社がNTTビジネスソリューションズ株式会社にOEM提供している「ugo Platform」をベースに構築されたもので、ロボットの遠隔管理やAIエージェントによる最適化機能を備える。ユーザーはタブレットやスマートフォンを通じてロボットと双方向にコミュニケーションを行い、AIが蓄積された清掃データをもとに最適なルートや頻度を自律的に提案する。</p>
<p>NTTビジネスソリューションズとugoは、2025年10月27日に協業事業化に向けたプラットフォームのOEM契約を締結しており、今回の「JILBY」採用はその成果の第一弾となる。</p>
<p><strong>アイリスオーヤマとNTT西日本の共同発表会の様子。DX清掃ロボット「JILBY」と、ugoがNTTビジネスソリューションズにOEM提供する「ugo Platform」を基盤としたAIロボティクスプラットフォームの連携が紹介された。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_1024x576_e853d4b376/image2_1024x576_e853d4b376.png" alt="image2-1024x576.png" /></p>
<h2>労働力不足の解消へ──「フィジカルAI」がもたらす運用最適化</h2>
<p>清掃業界では人手不足が深刻化しており、ビルや商業施設の維持管理では省人化と品質維持の両立が求められている。
アイリスオーヤマは、現場課題を出発点とするDXモデルを強化しており、NTT西日本は通信・クラウド基盤を活用した地域産業のデジタル支援を推進。両社は、清掃ロボットを起点に、警備・物流・介護など他領域への展開も視野に入れる。</p>
<h2>三層で支える「ロボット×通信×プラットフォーム」構造</h2>
<ul>
<li>アイリスオーヤマ：DX清掃ロボット「JILBY」の開発・提供。現場DXソリューションを拡大。</li>
<li>NTT西日本／NTTビジネスソリューションズ：通信・クラウドを基盤に「AIロボティクスプラットフォーム」を運用・提供。</li>
<li>ugo（ユーゴー）：同プラットフォームのOEM提供元として、AIエージェント・ノーコード自動化・統合管理機能などの中核技術を供給。</li>
</ul>
<p>この構成により、ロボット運用の効率化だけでなく、現場データを知能化する「フィジカルAI」基盤の確立が期待される。</p>
<h2>今後の展望</h2>
<p>アイリスオーヤマは「JILBY」を2026年半ばに市場投入予定。NTT西日本は地方自治体や企業向けのDX支援プログラムにロボティクスを組み込み、ugoは複数メーカーのロボットを横断的に管理できる統合プラットフォーム化を進めるとしている。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米国エネルギー省とNVIDIA、10万GPUを搭載した史上最大級のAIスーパーコンピューターを構築──Oracleがクラウド基盤で協力し、科学インフラを刷新</title>
      <link>https://ledge.ai/articles/doe_nvidia_100k_gpu_ai_supercomputer</link>
      <description><![CDATA[<p>米国エネルギー省（DOE）は2025年10月30日（現地時間）、NVIDIAおよびOracleと協力し、DOE史上最大規模となるAIスーパーコンピューターの構築計画を<a href="https://www.energy.gov/articles/energy-department-announces-new-partnership-nvidia-and-oracle-build-largest-doe-ai">発表</a>した。</p>
<p>この新システムはイリノイ州のアルゴンヌ国立研究所（Argonne National Laboratory）に設置され、10万基以上のNVIDIA Blackwell GPUを搭載する。AIを活用した科学研究基盤として、科学的発見の加速と国家的課題の解決を狙う取り組みだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nvidia_1380_b28508426b/nvidia_1380_b28508426b.jpg" alt="nvidia-1380.jpg" /></p>
<h2>10万GPUの「Solstice」と「Equinox」</h2>
<p>DOEおよびアルゴンヌ研究所の<a href="https://www.anl.gov/article/argonne-expands-nations-ai-infrastructure-with-powerful-new-supercomputers">発表</a>によると、構築されるシステムは2系統で構成される。</p>
<p>メインとなる「Solstice」は10万基を超えるNVIDIA Blackwell GPUを搭載し、DOEのAI研究インフラとしては史上最大級の性能を備える。また、「Equinox」は約1万基のBlackwell GPUで構成され、より軽量なAIモデルのトレーニングや実験的研究に利用されるという。</p>
<p>両システムは相互に連携し、<a href="https://nvidianews.nvidia.com/news/nvidia-oracle-us-department-of-energy-ai-supercomputer-scientific-discovery">NVIDIAの試算</a>によれば最大で約2,200 エクサフロップスのAI性能を発揮する見込み。これらは米国政府が推進する「次世代科学計算インフラ拡張計画」の中核を担う。</p>
<p>計画では、Oracleがクラウドインフラ（Oracle Cloud Infrastructure、OCI）を提供。NVIDIAのハードウェア群をOCI上で統合運用し、Megatron-CoreやTensorRTなどのスタックを活用して、大規模学習と推論を並行実行できる設計とする。</p>
<h2>科学研究を支える国家AIインフラ</h2>
<p>DOEはこの取り組みを、「気候変動分析」「新素材探索」「エネルギー効率化」「AIによる科学的発見支援」など、多様な分野に応用する方針を示している。アルゴンヌ研究所の准研究所長でArgonne Distinguished FellowのRick Stevens氏は、強力なAI能力――特に推論機能――の重要性を挙げ、仮説検証や実験設計、複雑データからの洞察を効率化できると述べた。</p>
<p>両システムは2026年の稼働開始を予定しており、DOEはこれらを含むAIスーパーコンピューター群を全米の研究所に配備し、国家レベルでのAI研究ネットワークを拡充する。なお、DOEは同年、3研究所で計9台の新スーパーコンピューターを整備する計画も発表している</p>
]]></description>
      <pubDate>Mon, 03 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/11/3 [MON]対話型AIによる「心の支援」を可視化　ハーバード大・オックスフォード大らが新評価プラットフォームを開発</title>
      <link>https://ledge.ai/articles/mindbenchai_mental_health_llm_evaluation</link>
      <description><![CDATA[<p>対話型AIをメンタルヘルスの相談に利用する人が増えている。調査によると、ユーザーの3割以上がAIに心の悩みを打ち明けた経験を持つという。こうした状況のなか、AIによる誤った助言や過度な依存、AIとの擬似的な関係による心理的影響が報告されている。</p>
<p>この課題に対応するため、ハーバード大学、オックスフォード大学、マサチューセッツ総合病院など24機関の研究者が、AIのメンタルヘルス対応能力を体系的に評価するプラットフォーム「MindBenchAI（マインドベンチAI）」を開発し、研究成果は2025年9月にarXivで<a href="https://arxiv.org/abs/2510.13812">公開</a>した。</p>
<h2>AIが“セラピスト化”する時代のリスク</h2>
<p>ChatGPTやClaude、Geminiなどの大規模言語モデル（LLM）は、ストレス相談や心理的支援に使われるケースが増えている。
しかし、臨床的な有効性を示すデータは乏しく、誤診や誤誘導、自殺念慮への対応ミスなど、現実的なリスクも指摘されている。MIT Technology Reviewによれば、2025年には実際にAIチャットボットとのやり取りが悲劇につながった事例も報告されている。</p>
<p>論文の筆頭著者であり、ハーバード大学医学部付属ベスイスラエル・ディーコネス医療センター（Beth Israel Deaconess Medical Center）精神医学部門のジョン・トーラス氏は、「AIの利用が拡大する一方で、臨床的な安全基準や性能評価が存在しないまま“心の領域”がAIに委ねられつつある」と警鐘を鳴らしている。</p>
<h2>MindBenchAIの概要</h2>
<p>研究チームは、10年以上にわたりメンタルヘルスアプリを評価してきた「MINDapps.org」の仕組みを拡張し、AIモデルを対象にした評価体系を構築した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/MIND_bench_AI_bd6e712ea8/MIND_bench_AI_bd6e712ea8.jpg" alt="MIND bench AI.jpg" /></p>
<p>MindBenchAIは、AIの特性を「プロフィール評価」と「性能評価」の2側面から分析する。</p>
<h3>1. プロフィール評価（Profile Evaluation）</h3>
<p>モデルの技術的安全性（データ保護、透明性、開発体制など）と、会話特性（共感性、対話スタイル、応答傾向など）を整理する。
心理学の「ビッグファイブ」や「MBTI」などを応用し、AIの会話傾向を定量的に記録する。</p>
<h3>2. 性能評価（Performance Evaluation）</h3>
<p>自殺対応、臨床判断、薬物療法などのシナリオを用いてAIの応答を専門家が採点する。正答率に加え、AIがどのように結論に至ったかという推論過程（Reasoning）も評価対象とする。</p>
<p>評価には「Suicide Intervention Response Inventory 2（SIRI-2）」などの臨床評価指標が活用されている。</p>
<h2>システム構成と運用</h2>
<p>MindBenchAIは、技術情報と会話傾向、ベンチマーク結果、推論解析を統合したダッシュボード形式で運用される。</p>
<p>主要なLLM（GPT-5、Claude Opus 4、Gemini 2.5 Proなど）や、それらを基盤としたチャットボットも評価対象となる。
結果はリーダーボード形式で整理され、各モデルの得点を分野別に比較できる。</p>
<p>推論分析では、AIに思考過程を逐次説明させる「Chain-of-Thought」形式を採用し、誤りや偏りの傾向を特定する。</p>
<h2>共同体制と今後の展望</h2>
<p>MindBenchAIは、米国のメンタルヘルス支援団体「NAMI（National Alliance on Mental Illness）」と連携して構築された。
患者、家族、臨床医、開発者など、複数の立場の関係者が評価と検証に参加できる。システムは拡張可能な設計となっており、他の研究機関によるベンチマーク追加や多言語評価への対応が予定されている。</p>
<p>研究チームは、「AIの安全な利用を実現するため、臨床家や患者、開発者が共通の基準を持つことが必要」と述べている。</p>
]]></description>
      <pubDate>Mon, 03 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/2 [SUN]アリババ、初のスマートグラス「Quark AI Glasses」予約開始──価格4,699元、12月出荷見込み</title>
      <link>https://ledge.ai/articles/alibaba_quark_ai_glasses_presale_announcement_20251023</link>
      <description><![CDATA[<p>中国のアリババは2025年10月23日、自社開発による初のスマートグラス「Quark AI Glasses（夸克AI眼镜）」のオンライン予約販売を24日から開始すると、公式X（旧Twitter）アカウントで<a href="https://x.com/AlibabaGroup/status/1981200400817803428">発表</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/alibaba_Quark_AI_Glasses_14546ecef6/alibaba_Quark_AI_Glasses_14546ecef6.jpg" alt="alibaba Quark AI Glasses.jpg" /></p>
<p>同製品は、アリババの大規模言語モデル「Qwen（通称：通義千問）」と、同社のマルチモーダルAIを組み合わせたスマートアイウェア。Quark AI Glassesを通じて、音声アシスタントやリアルタイム翻訳、情報検索、撮影補助などの機能を自然な会話で操作できる。</p>
<p>アリババは7月の「世界人工知能会議（WAIC 2025）」にあわせて、AIグラスを含む次世代製品群を<a href="https://www.alibabacloud.com/en/press-room/alibaba-unveils-intelligent-cockpits-enterprise?_p_lc=1">初披露</a>しており、今回の予約販売開始が正式な市場投入の第一歩となる。報道各社（ロイター、Barron’sなど）によれば、Quark AI Glassesは中国の通販サイト「Tmall（天猫）」を通じて販売され、価格は4,699元（約660ドル）、出荷は12月を予定している。</p>
<p>Quarkは、アリババが展開するAIアシスタントアプリで、テキスト・音声の両モードで自然な対話と検索を統合する設計が特徴。10月23日の同社投稿でも「Quark AI Chat Assistant」として刷新が告知されており、アリババはスマートフォンを超えた“AIネイティブなエコシステム”の構築を進めている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G36e_Xm_X_Xw_A_Eve_He_5fb5b50486/G36e_Xm_X_Xw_A_Eve_He_5fb5b50486.jpg" alt="G36eXmXXwAEveHe.jpg" /></p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>上海交通大学、「AI生成サーベイ論文の氾濫は“DDoS攻撃”」──NeurIPS 2025採択論文が研究文化への影響と対策を提言</title>
      <link>https://ledge.ai/articles/ai_generated_survey_paper_ddos_shanghai_jiaotong</link>
      <description><![CDATA[<p>中国・上海交通大学の研究チームは2025年10月9日、生成AIによるサーベイ論文の急増が研究コミュニティを“DDoS攻撃”のように麻痺させていると警鐘を鳴らすポジションペーパー「Stop DDoS Attacking the Research Community with AI-Generated Survey Papers」を<a href="https://arxiv.org/abs/2510.09686v1">発表</a>した。</p>
<p>論文はNeurIPS 2025のPosition Trackに<a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/121939">採択</a>され、AI支援による論文作成の透明性確保や、動的に更新される「Dynamic Live Surveys」の構築を提案している。</p>
<h2>「サーベイ論文DDoS攻撃」とは</h2>
<p>研究チームは、ChatGPTなどの大規模言語モデル（LLM）の登場以降、サーベイ論文が指数関数的に増加していると分析。2020〜2024年の間に、コンピュータサイエンス分野のサーベイ論文数は約2倍に膨れ上がり、2022年以降に急激な“スパイク”が見られたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_8_353e8bf78b/x1_8_353e8bf78b.png" alt="x1 (8).png" /></p>
<p>AI検出ツールによる分析では、AI生成要素を含むサーベイ論文の割合が2022年以降急上昇。著者らはこの現象を「サーベイ論文によるDDoS攻撃」と呼び、量の爆発が研究者の注意と査読能力を圧迫し、真正な学術貢献が埋もれる危険性を指摘している。</p>
<h2>品質と信頼性の低下</h2>
<p>論文では、AI生成のサーベイ論文が「冗長」「誤引用」「分類構造の浅さ」などの特徴を持ち、人間が執筆した従来型のサーベイに比べ、学術的洞察に欠けると述べている。</p>
<p>また、複数のAI生成サーベイが同一テーマでほぼ同じ内容・表現を繰り返す“コピー＆ペースト構造”を形成していることを、引用リストの重複率や語彙多様性の低下などから実証した。</p>
<h2>研究文化への影響</h2>
<p>大量のAI生成論文がarXivなどのプレプリントサーバを埋め尽くすことで、研究者が信頼できるレビューを見つけにくくなり、若手研究者の学習や研究テーマ選定を誤らせるリスクもあると分析。論文ではこれを「literature poisoning（文献汚染）」と表現し、引用ネットワーク全体の歪みを招く可能性を警告した。</p>
<h2>提案する解決策</h2>
<p>研究チームは以下のような対策を提案している：</p>
<ul>
<li><strong>AI使用の開示義務化</strong> ：LLMを執筆補助に使った場合は脚注や本文で明記</li>
<li><strong>サーベイ論文専用の厳格な査読制度</strong> ：独自の評価基準を設け、深度と独創性を確認</li>
<li><strong>AI生成検出ツールの導入</strong> ：AI支援を隠した投稿を抑止</li>
<li><strong>高品質サーベイの表彰制度</strong> ：研究者が労力をかけたレビューを奨励</li>
<li><strong>研究倫理教育の強化</strong> ：AIによる文章生成を盗用に準じる行為として明確化</li>
</ul>
<p>さらに、従来の静的なサーベイ論文に代わり、人間とAIが協働して継続的に更新する「Dynamic Live Surveys」という新たな仕組みを提案。AIが新論文情報を自動収集し、専門家がその内容を精査・統合する「ライブ型学術リポジトリ」を構想している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_5_014e74304f/x2_5_014e74304f.png" alt="x2 (5).png" /></p>
<p>著者らは、「AIによるサーベイ生成を否定するのではなく、人間の洞察を補完する形で共存させるべき」と強調。「量より質」という原則を取り戻すことが、AI時代の学術出版の信頼回復につながるとしている</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>1X、家庭用ヒューマノイド「NEO」を正式公開──月額499ドル（約7万5,000円）のサブスク開始で“家事お手伝いロボ”が現実に</title>
      <link>https://ledge.ai/articles/1x_neo_home_robot_subscription_launch</link>
      <description><![CDATA[<p>米1X Technologiesは2025年10月28日（米国時間）、家庭向けヒューマノイドロボット「NEO」を<a href="https://www.1x.tech/neo">公開</a>し、プレオーダーを開始した。提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。家庭内の掃除や片付けなど、日常的な家事を支援する“お手伝いロボット”として設計されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_6_ce91e1cf1e/x1neo_6_ce91e1cf1e.jpg" alt="x1neo-6.jpg" /></p>
<p>NEOは、1Xが掲げる「人の生活を支える安全なヒューマノイド」構想に基づき開発された。腱（tendon）駆動による柔らかく静かな動作を特徴とし、人と同じ空間で安全に動作できるよう設計されている。公式サイトでは「単調で時間のかかる家事を肩代わりし、人の時間を取り戻す」とコンセプトを掲げる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_5_7ae0e73c6c/x1neo_5_7ae0e73c6c.jpg" alt="x1neo-5.jpg" /></p>
<p>ユーザーはスマートフォンアプリや音声を通じてタスクを指示でき、NEOは家庭内の環境を学習しながら動作を最適化する。自己充電機能を備えるほか、遠隔からのモニタリングやサポートも可能。1XはNEOを単なるロボットではなく「温かみと個性をもった家庭のパートナー」と位置付けている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_4_dd13229413/x1neo_4_dd13229413.jpg" alt="x1neo-4.jpg" /></p>
<p>主な仕様は、バッテリー駆動時間約4時間（急速充電対応）、静音性は最大22dB。NVIDIA Jetson Thorをベースとした「1X Cortex」コンピューティングシステムを搭載し、360度集音マイクとステレオスピーカーを内蔵する。</p>
<h2>サブスク形式で家庭導入のハードルを下げる</h2>
<p>提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。NEOは注文ページからプレオーダー可能で、出荷は2026年を予定している。</p>
<p>1Xは公式ページ上で、NEOを「consumer-ready」と表現。2024年の試作版「NEO Beta」発表を経て、今回初めて一般消費者に向けたモデルとして公開された。</p>
<p>@<a href="https://www.youtube.com/watch?v=LTYMWadOW7c">YouTube</a></p>
<p>1X Technologiesは、家庭や産業向けのヒューマノイドロボットを開発する企業で、OpenAIが出資するスタートアップの一つでもある。これまでノルウェーを拠点としていたが、2025年には米カリフォルニア州サンフランシスコに本社を移転。研究開発と製造体制の両面で国際展開を進めている。サブスクリプション形式による提供で家庭でも導入しやすい価格体系を整えたNEOは、ヒューマノイドが日常生活に溶け込む時代の到来を感じさせる存在だ。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米ルイビル大の研究者ら、AIが“人類の記憶係”になる時代に「記憶される権利」を提唱──少数のAIベンダーが何を記憶するかを実質的に決定するリスクを警告</title>
      <link>https://ledge.ai/articles/ai_right_to_be_remembered_digital_memory_risk</link>
      <description><![CDATA[<p>生成AIが人類の“記憶係”として機能し始める中で、情報の偏りや「記憶からの抹消」という新たなリスクが指摘されている。</p>
<p>米ルイビル大学などの研究者チーム（著者：Roman V. Yampolskiy／Alex Zhavoronkov／Dominika Wilczok）は2025年10月17日、論文「The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI」を arXiv で<a href="https://arxiv.org/abs/2510.16206">公開</a>した。大規模言語モデル（LLM）が情報取得の主要なインターフェースとなる現状に対し、著者らは「記憶される権利（Right to Be Remembered, RTBR）」を提唱している。</p>
<h2>単一回答がもたらす“記憶の収束”</h2>
<p>従来の検索エンジンは複数の情報源を一覧で提示し、利用者が比較・判断できる余地を残していた。一方、LLMは統合的な「ひとつの答え」を返す傾向があり、異なる視点を意識的に検討する機会を失わせやすい。この構造が進むと、少数のAIベンダーが「何が記憶され、何が忘れられるか」を実質的に決定することになり、デジタル社会における“記憶の偏り”が固定化する恐れがあると警告している。</p>
<h2>「記憶される権利（RTBR）」とは</h2>
<p>著者らは、AIが生成する情報の公正性と真実性を守る新たな倫理的枠組みとしてRTBRを提案した。RTBRは「AIによる情報の省略を最小化し、公正で、生成内容が可能な限り真実であることを設計原則として担保する」責務を意味する。その実現には、モデル開発・学習・出力・UI設計の各段階で、偏りを可視化し、引用や来歴を明示する仕組みが欠かせないとする。</p>
<h2>技術的・制度的課題にも言及</h2>
<p>論文は、AIの“真実性”を外部事実との整合性（accuracy）と、内部表現の整合性（honesty）の2層に分けて評価する重要性を指摘。その上で、以下のような具体策を挙げている。</p>
<ul>
<li>データ選定と来歴メタデータ（C2PAなど）の付与</li>
<li>RLHFや安全調整における多視点の保持</li>
<li>単一回答UIに代替視点・出典リンクを併設</li>
<li>不確実性の自己申告（知らないときは答えない／曖昧さの表示）</li>
</ul>
<p>また、C2PAなどのメタデータ標準を参照し、生成物に情報源を階層的に紐づける設計を推奨している。法制度面では、欧州の「忘れられる権利」（GDPR第17条）との緊張関係も論じられている。RTBR（公共の記憶の保存）と「忘れられる権利」（個人の消去請求）はしばしば対立し、LLMが知識を内部パラメータに埋め込む構造上、完全なアンラーニング（忘却）は難しいと指摘する。</p>
<h2>公共の「記憶」をどう設計するか</h2>
<p>研究者らは結論として、AIが知識の窓口となる時代において、モデルの設計や運用が人類の集合的記憶の形を左右する可能性を強調した。RTBRは、AIがもたらす効率性の裏側で、忘却や偏りから人間の歴史と多様な声を守るための新しい規範として位置づけられる。
論文は「AIが“人類の記憶係”になる時代にこそ、何を残し、何を忘れないかを社会全体で考える必要がある」と結ばれている。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、生成AI「Claude」をExcelに統合──分析・説明・編集を自動化する新アドインを発表</title>
      <link>https://ledge.ai/articles/claude_for_excel_beta_release</link>
      <description><![CDATA[<p>Anthropicは2025年10月28日（米国時間）、生成AI「Claude」をMicrosoft Excelに統合した新アドイン「Claude for Excel」をベータ版（Research Preview）として<a href="https://www.anthropic.com/news/advancing-claude-for-financial-servicesl">公開</a>した。
Claudeがスプレッドシート内のデータや数式を理解し、自然言語による分析・説明・編集を行えるようにする。</p>
<p>「<a href="https://www.claude.com/claude-for-excel">Claude for Excel</a>」はExcelのサイドバー上で動作し、ユーザーが自然言語で入力した指示に応じて、ワークシート全体を参照しながら回答する。数式の意味や依存関係を自動的に解析し、関連セルをハイライト表示することで、データの構造を可視化できる。例えば「この列の傾向を要約して」「この数式が何を計算しているか説明して」といった指示に対して、Claudeが表形式で結果を提示する。</p>
<p>@<a href="https://www.youtube.com/watch?v=NcBnxbEC0Ng">YouTube</a></p>
<p><strong>Excelのワークシートを解析し、セルレベルの参照付きで説明するClaudeの画面例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/How_teams_use_Claude_for_Excel_fa57735bf8/How_teams_use_Claude_for_Excel_fa57735bf8.jpg" alt="How teams use Claude for Excel.jpg" /></p>
<p>Anthropicによると、この機能は「財務分析やデータレポート作成など、業務での活用を想定した設計」であり、企業利用者を中心に展開されている。現在は「Claude for Max」「Claude for Team」「Claude for Enterprise」プランのユーザーを対象に、ウェイトリスト方式による限定ベータ（リサーチプレビュー）として提供中だ。</p>
<p>同社は公式ブログで、金融サービス分野をはじめとするビジネス用途において、Claudeの統合を進めていく方針を示している。今後、Excel以外の業務アプリケーションやリアルタイムデータとの連携も視野に入れ、企業の分析・意思決定プロセスをAIで支援するエコシステムの構築を目指すという。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>イーロン・マスク氏、「Wikipediaより優れている」──xAIが生成AI百科事典「Grokipedia」version 0.1を公開</title>
      <link>https://ledge.ai/articles/elon_musk_xai_grokipedia_launch_version_0_1</link>
      <description><![CDATA[<p>xAIは2025年10月27日（米国時間）、生成AIを活用した独自の百科事典サービス「Grokipedia（グロキペディア）」の初期バージョン（version 0.1）を<a href="https://x.com/elonmusk/status/1982983035906842651">公開</a>した。</p>
<p>xAI創業者であるイーロンマスク氏はX（旧Twitter）上で「Grokipedia.com version 0.1 is now live. Version 1.0 will be 10X better, but even at 0.1 it’s better than Wikipedia imo.」と投稿し、将来的に大幅な改良を予定しつつも「現段階でWikipediaより優れている」と自信を示した。</p>
<h2>「真実追求を優先」──xAI公式が示す設計思想</h2>
<p>xAIの公式アカウント（@grok）は、Grokipediaについて次のように説明している。
\u003E“Grokipedia leverages xAI’s Grok to synthesize knowledge from diverse sources, prioritizing maximum truth-seeking over consensus-driven editing. Wikipedia, by contrast, depends on volunteer editors whose biases — often left-leaning — can distort entries on controversial topics. Grokipedia minimizes human subjectivity, focusing on verifiable facts and logical reasoning for a more reliable reference.”</p>
<p>この説明によれば、GrokipediaはxAIの大規模言語モデル「Grok」を用いて多様な情報源を統合し、合意形成ではなく「真実追求（truth-seeking）」を優先する設計思想を採用。人間編集者による主観や政治的偏向を最小化し、検証可能な事実と論理推論に基づいて構築された「より信頼できる参照源」を目指すとしている。
xAIは「version 0.1 の時点ですでにWikipediaを中立性で上回る」とも述べている。</p>
<h2>マスク氏「人類の知を宇宙に保存する」構想も表明</h2>
<p>マスク氏は続く投稿で、Grokipediaの長期的な目的を明らかにした。
\u003E“Nice work by the @xAI team on Grokipedia.com! The goal here is to create an open source, comprehensive collection of all knowledge. Then place copies of that etched in a stable oxide in orbit, the Moon and Mars to preserve it for the future. Foundation.”
（2025年10月28日 午後7:54 投稿）</p>
<p>この<a href="https://x.com/elonmusk/status/1983125099973882120">発言</a>によれば、Grokipediaの最終目標は「オープンソースの包括的な知識アーカイブ」を構築し、そのデータを地球軌道・月・火星に保存するというもの。人類の知識を恒久的に残す「Foundation（基盤）」としての役割を想定している。</p>
<p>同氏はかねてより、Wikipediaの編集体制に偏りがあると批判してきた。
Grokipediaは、AIを活用して人為的な偏向を排し、情報の中立性を担保する新しいアプローチとして位置づけられる。
サービス名は、SF作家ロバート・A・ハインラインの著書『ストレンジャー・イン・ア・ストレンジ・ランド』に登場する言葉「grok（深く理解する）」に由来している。</p>
<h2>今後の展望</h2>
<p>Grokipedia<a href="https://grokipedia.com">公式サイト</a>では、トップに「version 0.1」と明記されており、今後の改良に向けた開発が進められている。Musk氏は「version 1.0 will be 10X better（1.0は10倍良くなる）」と予告しており、精度や信頼性の向上、Xプラットフォームとの連携などが今後の焦点となる。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、誰でも学べるAI学習サイト「Google Skills」を正式公開──Cloud・DeepMind・教育部門を横断する3000講座を展開</title>
      <link>https://ledge.ai/articles/google_skills_ai_learning_platform_launch</link>
      <description><![CDATA[<p>Googleは2025年10月21日（米国時間）、新しいAI学習プラットフォーム「Google Skills」を<a href="https://blog.google/outreach-initiatives/education/google-skills/">発表</a>した。同サイトでは、Google Cloud、Google DeepMind、Grow with Google、Google for Educationなど、同社の複数部門が提供してきた教育コンテンツを統合。3000種類を超えるAI関連の講座・体験ラボ・認定プログラムを、一元的に学べる学習拠点として開設された。</p>
<h2>AI教育の中核を担う新サイト</h2>
<p>Google公式ブログ「Start learning all things AI on the new Google Skills」によると、Google Skillsは“AI for Everyone（すべての人のためのAI）”をテーマに、誰もがAIスキルを体系的に学べるよう設計されている。初心者、エンジニア、企業リーダーなど幅広い層を対象に、AI、データ分析、クラウド、生成AIなど多様な分野を網羅。各コースはオンデマンド形式で受講でき、学習成果はLinkedInなどの外部プラットフォームで共有できる。提供内容には、Google Cloudの認定資格プログラムやAI Essentials シリーズ、DeepMindのAI倫理教材などが含まれる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Qbix0BOPcgE">YouTube</a></p>
<p>今回の正式公開に先立ち、Google Cloudは10月10日付のブログ「Google Skills: Your new home for Google AI learning and more」で、新プラットフォームの構想を公表していた。当時は正式リリース前で、「AIやクラウドに関する学習リソースを一元化し、近日中に詳細を発表する」としていた。Gemini Code Assist（旧Duet AI for Developers）やQwiklabs（現Cloud Labs）と連携し、AIトレーニングの実践環境を統合する方針も示されていた。</p>
<h2>3000超のコースと実践的ラボを集約</h2>
<p>Google Skillsでは、Googleがこれまで個別に展開してきた学習リソースを一か所に集約。AIモデル開発、クラウド基盤運用、データ可視化、サイバーセキュリティなど、実践重視の3000超のコースとラボを提供する。一部コンテンツは無料で公開され、修了証や認定資格を取得することでキャリア開発にもつなげられる。また、組織向けにはチーム単位での進捗管理や学習成果の可視化機能も用意されている。</p>
<h2>今後の展望──教育機関・企業研修にも拡大へ</h2>
<p>Googleは今後、教育機関や企業研修への展開を進める方針を示しており、AIスキルの標準教育基盤としての活用を目指す。
公式ブログでは、「AI教育へのアクセスを民主化し、誰もがテクノロジーの未来を形づくる機会を得られるようにする」としている。
同社は今後もDeepMindやCloud AIチームの最新教材を追加し、AI人材育成をグローバルに推進する考えだ。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>万博「null²」館で使用の3Dアバター技術、筑波大が一般公開──スマホスキャン後約5分で完成</title>
      <link>https://ledge.ai/articles/instant_skinned_gaussian_avatars_tsukuba_null2</link>
      <description><![CDATA[<p>筑波大学・落合陽一准教授が率いるデジタルネイチャー研究室（Digital Nature Group）は、スマートフォンで撮影した3Dスキャンデータから約5分で写実的な3Dアバターを生成できる技術「Instant Skinned Gaussian Avatars」を<a href="https://gaussian-vrm.github.io/">発表</a>した。</p>
<p>研究成果は論文「Instant Skinned Gaussian Avatars for Web, Mobile and VR Applications」として公開され、2025年11月にカナダ・モントリオールで開催される ACM Symposium on Spatial User Interaction (SUI ’25) で<a href="https://dl.acm.org/doi/10.1145/3694907.3765954">発表予定</a>となっている。
この技術は、大阪・関西万博の落合館「null²（ヌルヌル）」で展示された3Dアバター生成システムに採用されており、研究チームは10月22日、<a href="https://naruya.github.io/gaussian-vrm/">デモサイト</a>と<a href="https://github.com/naruya/gaussian-vrm">ソースコード</a>を一般公開した。</p>
<h2>スマホだけで完結するアバター生成プロセス</h2>
<p>研究は、筑波大学大学院図書館情報メディア研究科の近藤生也氏、浅野悠人氏、落合陽一氏によって実施された。
ユーザーはスマートフォンアプリ「Scaniverse」でAポーズの全身スキャンを行い、3Dデータ（PLY形式）を取得する。そのデータをブラウザ上のアプリケーションにアップロードすると、自動的に処理が実行され、約30秒でアバター生成が完了する。全体の所要時間は約5分と報告されている。生成されたアバターはWebブラウザ上で動作し、スマートフォンでも確認できる。</p>
<p>@<a href="https://www.youtube.com/watch?v=tinmbjfghLw">YouTube</a></p>
<h2>Gaussian Splattingとスキンメッシュの融合</h2>
<p>提案手法は、3D表現技術「Gaussian Splatting」をベースに、スキンメッシュ構造と統合することで、写実的な質感とアニメーションの軽量性を両立している。
各スプラット（点群）は背景メッシュのボーン構造にバインドされ、動作中はリアルタイムで位置と姿勢を並列更新する仕組みを採用。モバイル環境での処理負荷を抑えるため、ボーン単位でスプラットをグループ化し、視点依存のソーティング処理を最適化している。</p>
<p>@<a href="https://www.youtube.com/watch?v=i2GvFIMYqP0">YouTube</a></p>
<h2>Webベース設計によるクロスプラットフォーム対応</h2>
<p>システムは、JavaScriptおよびThree.jsで構築されており、特別なアプリケーションを必要とせずWebブラウザ上で動作する。
ユーザーはスマートフォン、PC、VRヘッドセットなど、プラットフォームを問わず利用できる。
これにより、生成・表示環境が限定されず、学習や展示、遠隔通信など多様な応用が可能となる。</p>
<h2>実行性能と公開リソース</h2>
<p>実験では、iPhone 13 Proで40〜50 fps、NVIDIA GeForce RTX 3060搭載ノートPCで最大240 fpsの動作を確認した。
デモは <a href="https://naruya.github.io/gaussian-vrm/">https://gaussian-vrm.github.io</a>、ソースコードは<a href="https://github.com/naruya/gaussian-vrm">https://github.com/naruya/gaussian-vrm</a> で公開されている。</p>
<h2>今後の展開</h2>
<p>論文では、VRMなど既存アバター規格との互換性を考慮した設計であることが示されている。
研究チームは、顔表情や衣服変形などへの拡張を今後の課題として挙げている。研究成果は、誰もが汎用デバイスを用いて高品質な3Dアバターを生成できる手法として、Web、モバイル、VRアプリケーションなど複数領域への応用が見込まれている。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTで週120万人が「自殺兆候を含む会話」──OpenAI、メンタルヘルス対応を強化</title>
      <link>https://ledge.ai/articles/openai_chatgpt_mental_health_safety_update_oct2025</link>
      <description><![CDATA[<p>OpenAIは2025年10月27日（米国時間）、ChatGPTにおける精神的健康と安全性の向上を目的とした新たな取り組みを<a href="https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations/">発表</a>した。自殺や自傷、AIへの過度な依存など、センシティブな会話においてAIの応答を改善したと説明している。</p>
<p>同社は170人以上の臨床心理士、精神科医、カウンセラーらと協力し、精神疾患（精神病・躁病）、自傷・自殺、AIへの情緒的依存という3つの領域を重点改善分野に設定。これらの領域において、ChatGPTの応答品質が39〜52％改善したという。</p>
<h2>「自殺の明確な指標を含む会話」は週0.15％</h2>
<p>OpenAIの初期分析によると、ChatGPTの週次アクティブユーザー（WAU）のうち約0.15％が「自殺の計画や意図の明確な指標を含む会話」を行っていると推定される。10月6日の発言で同社CEOサム・アルトマン氏が年次開発者会議「DevDay 2025」で<a href="https://ledge.ai/articles/openai_devday2025_chatgpt_800m_wau">示した</a>WAUは約8億人。これを基にすると約120万人/週となる。同社はこれらの数値について、「低頻度かつ測定が難しい推定値」であり、今後の手法改良や利用動向によって大きく変動する可能性があると注記している。</p>
<h2>危機的な会話では専門機関への誘導を強化</h2>
<p>新しい応答設計では、ユーザーが自殺や自傷を示唆する発言をした場合、ChatGPTが危険を煽ることなく、専門機関や信頼できる人への相談を促すよう対応する。
OpenAIは「AIがカウンセラーの代わりになることはない」とし、人間による支援への橋渡しを重視する方針を明確にした。</p>
<h2>「AI依存」への懸念にも対応</h2>
<p>同社は、自傷や自殺と同様に「AIへの過度な情緒的依存」もリスクとして捉え、AIとの対話を通じて孤立や依存の兆候を検知しやすくする研究を進めている。目的は、AIを人間関係の代替とするのではなく、支援ツールとして安全に活用できる環境を整えることにあるという。</p>
<p>今後も医療・心理の専門家やNPOと連携し、AIがメンタルヘルス領域で安全に活用されるための基準づくりを進めると同社は述べている。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/31 [FRI]OpenAI、2028年に「完全自動AI研究者」実現を目指すロードマップを公開</title>
      <link>https://ledge.ai/articles/openai_future_roadmap_fully_automated_ai_researcher_2028</link>
      <description><![CDATA[<p>OpenAIは2025年10月30日（米国時間）、同社の構造改革と今後の展望をテーマにしたライブ配信「Sam, Jakub, and Wojciech on the future of OpenAI with audience Q&amp;A」を実施し、研究・製品・インフラの中長期計画を<a href="https://www.youtube.com/watch?v=ngDCxlZcecw">公表</a>した。
登壇は、CEOのサム・アルトマン氏（Sam Altman）、チーフサイエンティストのヤクブ・パホツキ氏（Jakub Pachocki）、共同創業者のウォイチェフ・ザレンバ氏（Wojciech Zaremba）の3名。</p>
<p>配信では、OpenAIが掲げる中長期の研究ロードマップが初めて詳細に共有され、2028年3月までに「完全自動AI研究者（fully automated AI researcher）」を実現するという社内目標が明らかにされた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/we_did_a_livestream_ce2df3ba24/we_did_a_livestream_ce2df3ba24.jpg" alt="we did a livestream.jpg" /></p>
<h2>研究ロードマップ：2026年に“AI研究インターン”、2028年に“完全自動研究者”へ</h2>
<p>パホツキ氏は、OpenAIの研究プログラムが「科学的発見の加速と新技術開発の促進」を目的に構築されていると説明し、次の二段階のマイルストーンを示した。</p>
<ul>
<li><strong>2026年9月まで</strong> ： 意味のある計算資源を活用し、研究者の生産性を大幅に高められる有能なAI研究インターン（AI research intern）を開発。</li>
<li><strong>2028年3月まで</strong> ： 大規模な研究プロジェクトを自律的に遂行できる完全自動AI研究者（fully automated AI researcher）を実現。</li>
</ul>
<p>パホツキ氏は「これらの日付は絶対ではない」と前置きしながらも、現時点での社内目標を共有。「科学の発見速度を劇的に高める可能性がある」と語った。</p>
<p>アルトマン氏は、「この取り組みこそがOpenAIの研究プログラムの核心（core thrust）だ」と述べ、GPT-4のリリース（2023年）から約5年後に当たる2028年を重要な節目と位置づけた。同氏はさらに、AIによる科学的発見の進展について「2026年には小さな発見が現れ、2028年には中規模あるいはそれ以上の発見が生まれるだろう」と言及した。</p>
<h2>スーパーインテリジェンスへの接近</h2>
<p>パホツキ氏は、OpenAIが「ディープラーニングを理解する研究所」であり、トレーニング規模を拡大することで何が起こるかを探ることが本質的だと説明した。そのうえで、ディープラーニングシステムが多くの領域で人間を超える“スーパーインテリジェンス”に到達するまで10年を切っている可能性があるとの見方を示した。</p>
<p>指標のひとつとして、モデルが人間と同等の成果を上げるまでに要する時間を挙げ、現在のモデルは国際情報オリンピックなどでトップ人類と肩を並べる水準に達していると説明。今後はアルゴリズム革新とスケーリングによって、その「時間的水平線」が急速に拡大すると予測した。</p>
<h2>OpenAIのミッションと戦略的柱</h2>
<p>アルトマン氏は、OpenAIのミッションは非営利法人と公益法人（PBC）の双方において「AGI（汎用人工知能）が全人類に利益をもたらすことを保証する」ことであると改めて表明した。かつてAGIは「神託のような存在」と見なされていたが、現在は「人々が未来を創造するためのツールを構築し、AIで力を与えること」が明確な方向性だと説明した。</p>
<p>OpenAIの戦略は、次の三つの柱で構成されている。</p>
<ol>
<li><strong>研究（Research）</strong> ： AGI構築に必要な研究の成功。</li>
<li><strong>プロダクト（Product）</strong> ： 誰もが簡単かつ強力にAIを使えるようにする。</li>
<li><strong>インフラストラクチャ（Infrastructure）</strong> ： 低コストで高性能なAIを提供できる基盤の整備。</li>
</ol>
<p>アルトマン氏は「AIが科学の発見を支援することで、社会全体がより良くなり、個人の創造性も飛躍的に向上するだろう」と述べた。</p>
<p>パホツキ氏は、強力なシステム開発に向けた準備の中で安全性と価値観の整合性（value alignment）を最重視しているとし、「AIが根本的に何を気にかけるのかを理解することが、スーパーインテリジェンス時代の長期的安全性の核心だ」と語った。</p>
<p>ザレンバ氏も加わり、質疑応答では研究の方向性や安全性、社会的インパクトに関する質問に答えながら、OpenAIが今後も透明性をもって議論を続けていく姿勢を示した。</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、アジア初の東京オフィスを開設──高市首相とアモデイCEOが会談、AIセーフティ・インスティテュートと協力覚書を締結</title>
      <link>https://ledge.ai/articles/anthropic_tokyo_office_aisi_moc_oct2025</link>
      <description><![CDATA[<p>米Anthropicは2025年10月29日（現地時間）、アジア太平洋地域で初となる東京オフィスを開設したと<a href="https://www.anthropic.com/news/opening-our-tokyo-office">発表</a>した。</p>
<p>来日した同社の最高経営責任者（CEO）であるダリオ・アモデイ氏は同日、首相官邸で高市早苗総理大臣と会談し、日本政府のAI安全性評価機関「AIセーフティ・インスティテュート（AISI）」との間で、AI評価手法に関する協力覚書（MoC）に署名した。</p>
<h2>「安全で信頼できるAI」実現へ──東京をアジア拠点に</h2>
<p>Anthropicは、東京オフィスをアジア太平洋地域におけるハブ拠点として設立。
公式リリースでは、「日本との協力は、安全で信頼できるAIを世界に広げるための重要な一歩」と位置づけている。
今後は、生成AI「Claude」シリーズの日本市場向け展開に加え、研究者・企業・政策当局との協働も視野に入れるという。</p>
<h2>首相官邸で会談──AIの安全性と国際協力を確認</h2>
<p>首相官邸の<a href="https://www.kantei.go.jp/jp/104/actions/202510/29hyoukei.html">公式発表</a>{target=\</p>
]]></description>
      <pubDate>Sat, 01 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、約1万4千人の従業員削減を発表──AI時代に合わせた「俊敏な組織」へ再構築</title>
      <link>https://ledge.ai/articles/amazon_layoffs_14000_ai_organization_restructure_oct2025</link>
      <description><![CDATA[<p>米Amazonは2025年10月28日（現地時間）、企業全体の効率化と俊敏性の向上を目的として、約1万4,000人の従業員を削減すると<a href="https://www.aboutamazon.com/news/company-news/amazon-workforce-reduction">発表</a>した。
この発表は、人事担当シニア・バイスプレジデントのベス・ガレッティ（Beth Galetti）氏が公式ブログ「Staying nimble and continuing to strengthen our organisations」で明らかにしたもの。</p>
<p>同氏は声明の中で、「Amazonはこれまでも、変化の速い環境の中で俊敏に進化してきた。今回の再編も、よりフラットでスピード感のある組織を築くための一歩だ」と述べた。削減は主にコーポレート部門の職務約14,000件（roles）を対象とし、各国の法的手続きや労働慣行に基づいて順次進められる。</p>
<p>Amazonは、影響を受ける従業員に対し、90日間の社内再配置期間（Internal Job Search Period）を設ける。期間中に社内の他部門で新たな職務を見つけられなかった場合、退職金・転職支援・医療保険の延長などを提供する方針だ。
ガレッティ氏は、「この決定は決して軽いものではない。影響を受ける社員には最大限のサポートを行う」と強調している。</p>
<p>同社は、今回の削減を「単なるコスト削減ではなく、組織のレイヤーを減らし、意思決定を迅速化するための取り組み」と位置づける。ガレッティ氏は、「私たちは“世界最大のスタートアップ”として、責任とスピードを両立する構造を目指す」と記し、AIや自動化を含む新技術を活用した効率化を進めていく方針を示した。</p>
<p>今後もAmazonは、AI・クラウド・物流などの「戦略的重点領域」では採用を継続しつつ、その他の部門では組織構造の見直しを行うという。同氏は最後に、「これによりAmazonは、よりシンプルで、所有権を持って行動できる組織になる」と述べ、長期的な競争力と持続的成長への意欲を示した。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>声の権利をAIで守る、NTT西日本の新事業「VOICENCE」開始──声優・俳優らの音声IPを安全に活用へ</title>
      <link>https://ledge.ai/articles/ntt_west_voicence_voice_ai_rights_launch</link>
      <description><![CDATA[<p>NTT西日本は2025年10月27日、声優・俳優・タレントなど実演家の“声の権利（音声IP）”を保護し、AI技術によってその価値を高める新事業「VOICENCE（ヴォイセンス）」を開始したと<a href="https://www.ntt-west.co.jp/news/2510/251027b.html">発表</a>した。
音声の真正性を保証するデジタル基盤を整備し、生成AI時代における“声の知的財産”の新たな活用モデルを目指す。</p>
<h2>声の権利を守り、AIで価値を高める</h2>
<p>「VOICENCE」は、声優や俳優、タレントなどの声を個人の知的財産として捉え、デジタル技術で権利を守りながら安全に活用するための仕組み。声の利用には本人の同意を前提とし、権利者・制作側・利用者の三者が安心して取引できる音声流通プラットフォームを構築する。</p>
<p>同社は、音声の発話者を証明する技術を組み合わせることで“声のトレーサビリティ”を実現。AI合成や音声変換などが進む中で、無断利用やフェイク音声の拡散を防ぐ狙いだ。</p>
<h2>ブロックチェーンとAI音声技術を活用</h2>
<p>プラットフォームでは、音声データの真正性を担保するためにブロックチェーン技術を活用。改ざん防止と権利情報の一元管理を行い、利用履歴を透明化する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251027bc_bfdd13602b/251027bc_bfdd13602b.png" alt="251027bc.png" /></p>
<p>さらに、NTTグループが開発するAI音声技術を組み合わせ、登録された声のAI合成や多言語化、印象制御なども可能とする。これにより、声優や俳優の声を“公認AI音声”として多分野で展開できる。</p>
<h2>実演家と連携し、新たな音声市場を創出</h2>
<p>NTT西日本は今後、実演家・制作会社・タレント事務所などと連携し、音声広告、ナレーション、教育、観光といった幅広い分野への応用を進める。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251027bd_52e4134013/251027bd_52e4134013.jpg" alt="251027bd.jpg" /></p>
<p>同社は「声の真正性を保証することで、新しい音声経済圏を形成し、文化・産業の発展に寄与する」としている。
2025年度中には、音声IPの登録・管理・認証機能を本格運用する予定。中長期的には国内外での展開を視野に、AIと人間の“声の共創”を推進していく方針だ。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>画像生成・編集AIを包括的に評価する「ImagenWorld」を発表──画像生成AIの「失敗」も定量評価し見える化</title>
      <link>https://ledge.ai/articles/imagenworld_benchmark_university_of_waterloo</link>
      <description><![CDATA[<p>ウォータールー大学などによる研究チームは2025年10月17日、画像生成および画像編集AIの性能を横断的に評価するベンチマーク「ImagenWorld」を<a href="https://tiger-ai-lab.github.io/ImagenWorld/">発表</a>した。</p>
<p>AIがテキストや画像条件に基づいてどのように出力を生成し、どのように失敗するかを体系的に測定できる点が特徴で、公式サイトおよび論文が同時に公開されている。研究には、GoogleのGeminiモデルを用いた自動解析手法も組み込まれているという。</p>
<h2>ImagenWorldとは──AIの「失敗」を定量的に可視化</h2>
<p>ImagenWorldは、AIモデルの生成・編集タスクを統一指標で評価するために開発された、実世界ベンチマークである。
データセット作成からオブジェクト抽出、最終的な人間・AI評価までを一連のプロセスとして設計。
AIが生成した画像の「どの部分で誤るのか」を可視化する点が最大の特徴だ。</p>
<p><strong>ImagenWorldの全体構成。データセット作成からオブジェクト抽出・評価までの流れ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/overview_b8402c569b/overview_b8402c569b.jpg" alt="overview.jpg" /></p>
<h2>画像生成と編集の両方をカバーする実世界ベンチマーク</h2>
<p>ImagenWorldは、生成AIを多角的に測る6つの主要タスクで構成される。</p>
<ol>
<li>テキスト誘導型生成（Text-guided Image Generation）</li>
<li>単一参照画像生成（Single Reference Image Generation）</li>
<li>複数参照画像生成（Multiple Reference Image Generation）</li>
<li>テキスト誘導型編集（Text-guided Image Editing）</li>
<li>単一参照画像編集（Single Reference Image Editing）</li>
<li>複数参照画像編集（Multiple Reference Image Editing）</li>
</ol>
<p>評価対象となるトピックも、「Artworks」「Photorealistic」「Information Graphics」「Textual Graphics」など多岐にわたる。</p>
<p><strong>6種類のタスク分類と実際の生成・編集例。成功と失敗を並べて比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/dataset_1_bbfafbc87b/dataset_1_bbfafbc87b.jpg" alt="dataset (1).jpg" /></p>
<h2>評価プロセス──人間とAIが協働で“失敗”を検出</h2>
<p>ImagenWorldのスコアリングは、人間アノテータとVision-Language Model（VLM）の両方で行われる。評価軸は「Prompt Relevance」「Aesthetic Quality」「Content Coherence」「Artifacts」の4つ。Geminiを用いた自動オブジェクト抽出・セグメント分析を組み込み、どの部分が誤って生成されたのかを明示する。</p>
<p><strong>人間とVLMによるスコアリングを統合し、失敗箇所をセグメント単位で特定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/explain_tag_0fabc11340/explain_tag_0fabc11340.jpg" alt="explain-tag.jpg" /></p>
<h2>モデル比較──GPT-Image-1が総合スコア首位</h2>
<p>公式サイトと論文によると、評価対象モデルはOpenAIのGPT-Image-1、Stability AIのBAGEL、OmniGen2など。
総合スコアではGPT-Image-1が首位を記録したが、フォトリアリスティック画像や情報グラフィックの一部ではオープンソース系モデルも健闘した。</p>
<p><strong>ImagenWorldによる代表モデルのスコア比較。上段がタスク別、下段がトピック別の平均値</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unified_f74e92aef1/unified_f74e92aef1.jpg" alt="unified.jpg" /></p>
<h2>実例──AIの「わかりやすい失敗」を収集</h2>
<p>研究チームは、失敗出力の具体例を体系的に提示している。
例えば、指示された要素を正確に追加できない、参照画像の属性統合に失敗する、構図の一貫性が崩れるなど。
これらを分類・可視化することで、開発者がモデルの弱点を明確に把握できるようにしている。以下はその一部。</p>
<p><strong>指示に厳密に従えないケース</strong>：
プロンプトは「画像1の左上の木箱を画像3の黄色い警告標識に置き換え、画像2から“ピンク（中央）”と“黄色（右下）”のクルーメイトを取り出して並べ、画像1の中央ドア上に立たせる。遠近・照明・スケールを整える」指示。これに対し、モデルは別の色のクルーメイトを配置してしまい、標識の位置も指定と不一致。指示追従の精度不足が現れている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fail1_3f961411f2/fail1_3f961411f2.jpg" alt="fail1.jpg" /></p>
<p><strong>編集中に新しい画像を生成してしまうケース</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fail6_2856948e57/fail6_2856948e57.jpg" alt="fail6.jpg" /></p>
<h2>今後の展望──動画・3D生成AIへ拡張</h2>
<p>研究チームは、ImagenWorldを将来的に動画生成や3D生成AIの評価にも拡張する計画を示している。コードとデータセットはオープンソースとして一般公開されており、他研究者による再評価や再現実験も可能。</p>
<p>論文では「AIモデルの品質保証と説明可能性を高める基盤として設計された」と結論づけている。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、資本・組織再編を完了──非営利法人が営利事業を統制する「OpenAI Group PBC」体制へ</title>
      <link>https://ledge.ai/articles/openai_group_pbc_restructuring_complete</link>
      <description><![CDATA[<p>OpenAIは2025年10月28日（米国時間）、資本および組織の再編を完了したと<a href="https://openai.com/index/built-to-benefit-everyone/">発表</a>した。非営利団体のOpenAI Foundationが営利企業の株式を保有し、支配する形へと移行し、営利部門は公益法人（Public Benefit Corporation）である「OpenAI Group PBC」として再編された。</p>
<p>同社は新体制の目的を「人類全体に利益をもたらす形でのAGI開発の継続」と説明。これまでの「非営利団体 → 営利子会社」構造を改め、より明確なガバナンスを持つ一層の透明化を図るとしている。</p>
<p>再編にあたっては、米デラウェア州司法長官の審査を経て「異議なし（No Objection）」の判断が示され、公益法人としての要件を満たす形で承認された。司法長官のKathy Jennings氏は、OpenAIが安全・セキュリティ委員会を維持し、取締役が株主利益よりも公益目的を優先する義務を負うことを条件に認可したと<a href="https://news.delaware.gov/2025/10/28/ag-jennings-completes-review-of-openai-recapitalization/">説明している</a>。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Delaware_secures_structural_reform_and_action_on_safety_from_global_AI_leader_17eb0ebe2d/Delaware_secures_structural_reform_and_action_on_safety_from_global_AI_leader_17eb0ebe2d.jpg" alt="Delaware secures structural reform and action on safety from global AI leader.jpg" /></p>
<p>OpenAI Foundationが保有する持分の評価額は約1,300億ドルとされ、主要株主のMicrosoftは約27％を保有すると報じられている。全社評価は約5,000億ドル規模との見方もあり、これによりOpenAIは資金調達や事業展開の柔軟性を高めつつ、非営利団体がミッションと倫理基準を統制する構造を維持することになる。</p>
<p>今回の再編により、OpenAIは資本・組織・使命の3要素を整理し、非営利と営利を明確に区分した新体制に移行した。同社は今後、約250億ドル（約2兆円）規模の資金を医療・疾病治療、AIの安全性・レジリエンス技術など「人類全体の利益」に直結する領域に投資するとしている。公式声明では、「AIの発展を持続可能かつ安全に進めるための新しい章を開く」と述べている。</p>
]]></description>
      <pubDate>Thu, 30 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>