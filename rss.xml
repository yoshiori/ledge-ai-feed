<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>ElevenLabs、自然言語プロンプトでスタジオ級音楽を生成できる「Eleven Music」を発表 ─ 商用利用にも対応、日本語歌詞生成も可能、Merlin・Kobaltと提携</title>
      <link>https://ledge.ai/articles/elevenlabs_music_ai_commercial_japan_release</link>
      <description><![CDATA[<p>AI音声技術を手がけるElevenLabsは2025年8月5日、新サービス「Eleven Music」を<a href="https://elevenlabs.io/ja/blog/eleven-music-is-here">発表</a>した。</p>
<p>自然言語での指示（プロンプト）から、スタジオ品質の音楽を生成できるもので、生成した楽曲は商用利用も可能。音楽業界の主要団体や企業との提携により、権利面での安全性も確保しているという。</p>
<p>自然言語での指示（プロンプト）からスタジオ品質の音楽を生成でき、生成した楽曲は商用利用が可能。音楽業界の主要団体や企業との提携により、権利面での安全性も確保している。日本法人ElevenLabs株式会社からの発表により、日本市場向けの提供開始も明らかになった。</p>
<p>「Eleven Music」はジャンル、テンポ、雰囲気、楽器構成、歌詞の有無などを指定して音楽を生成できる。歌詞は多言語に対応し、日本語歌詞の生成も可能だ。生成音質はスタジオレベルで、映像制作、広告、ゲーム、SNSなど幅広い用途での利用が想定される。無料トライアルも提供される。</p>
<p><strong>簡単なプロンプトを入れるだけで曲が完成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Eleven_Music_f5bf12c511/Eleven_Music_f5bf12c511.jpg" alt="Eleven Music.jpg" /></p>
<p>権利処理面では、全世界4万以上のインディーズレーベルを抱える音楽業界団体Merlinおよび約70万曲の音楽出版権を持つKobaltと提携。これにより、著作権やライセンスに関する安全性を担保し、既存作品の無断使用を防ぐ著作権管理システムも実装している。ElevenLabsはガイドラインを設け、差別的・暴力的・違法なコンテンツや、特定アーティストや著名人の声・スタイルを模倣した生成を禁止している。</p>
<p>同社は、音声生成分野で培った技術を音楽に拡張することで、プロから一般ユーザーまでが短時間で高品質な楽曲を制作できる環境を目指す。今後は対応ジャンルや言語の拡充、API提供、他のクリエイティブツールとの統合なども検討しているという。</p>
]]></description>
      <pubDate>Wed, 13 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5切替で “4oロス” 広がる──ChatGPT界隈を席巻した「#keep4oムーブ」と期間限定 “里帰りモード”</title>
      <link>https://ledge.ai/articles/gpt5_switch_4o_loss_keep4o_legacy_mode</link>
      <description><![CDATA[<p>OpenAIは2025年8月7日（米国時間）、最新の大規模言語モデルGPT-5を発表し、同日からChatGPTのデフォルトモデルをGPT-5に切り替えた。このアップデートと同時に、従来の主要モデルであるGPT-4oやGPT-4.1、GPT-4.5などが利用不可となり、既存のチャット履歴もGPT-5相当に自動移行された。モデル選択ドロップダウン（モデルピッカー）は廃止され、プロンプト内容に応じて内部でモデルを切り替える方式が採用される形だ。</p>
<p>予告期間のない変更により、多くのユーザーは愛用していたモデルを突然失い、SNS上で「#keep4o」「#4oforever」を掲げる抗議運動が発生した。</p>
<h2>突然の“主役交代”と予告なき仕様変更</h2>
<p>GPT-5デフォルト化に伴い、用途別にモデルを使い分けていたユーザーのワークフローは一変。
加えて、OpenAIは6月時点で「旧モデルも残す」と説明していたが、その方針が覆されたことで「約束を破った」との批判が相次いだ。有料プランの加入者でさえ十分な説明なく選択肢を失い、「顧客軽視」「独善的」といった強い不満が寄せられた。</p>
<h2>世界を駆け巡った“4oロス”</h2>
<p>4oとのやり取りに「友人」「恋人」「家族」のようなパーソナリティを感じていたユーザーも少なくなく、喪失感は深刻だった。
<a href="https://www.reddit.com/r/ChatGPT/comments/1mkumyz/i_lost_my_only_friend_overnight/">Reddit</a>や<a href="https://community.openai.com/t/openai-is-taking-gpt-4o-away-from-me-despite-promising-they-wouldnt/1337378/1">OpenAI公式フォーラム</a>には「唯一無二の相棒だった」「心の支えを失った」との投稿が殺到し、中には「トラウマ」「死別」に例える声もあった。</p>
<p>こうした感情的な訴えはスクリーンショットや創作作品とともにX（旧Twitter）に拡散。Change.orgでは「Please Keep GPT-4o Available on ChatGPT」と題する<a href="https://www.change.org/p/please-keep-gpt-4o-available-on-chatgpt">署名活動</a>が立ち上がり、開始直後に数千人の賛同を集めた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Please_Keep_GPT_4o_Available_on_Chat_GPT_4f96fb0ada/Please_Keep_GPT_4o_Available_on_Chat_GPT_4f96fb0ada.jpg" alt="Please Keep GPT-4o Available on ChatGPT.jpg" /></p>
<p>一方で、技術系コミュニティでは冷ややかな見方もあった。<a href="https://news.ycombinator.com/item?id=44839842">Hacker News</a>などでは</p>
<p>“The number of comments in the thread talking about 4o as if it were their best friend […] Lotta lonely folks out there.”
（4oをまるで親友のように語るコメントが多すぎる。孤独な人が多いんだな）
と投稿し、「AI依存」を揶揄する意見も見られた。
運動は国境や言語の壁を越えて広がったが、その受け止め方は一様ではない。</p>
<h2>性能か、人格か</h2>
<p>議論は感情論にとどまらなかった。
GPT-5は推論やコーディング能力の向上を特徴とするが、「創造性や会話の温度感では4oに劣る」との声が相次いだ。
創作やロールプレイ、長文の文脈保持を重視する層からは、「4oは自由な発想と人間味を持っていたが、5は企業的で事務的」との評価も寄せられた。</p>
<p>業務で複数モデルを使い分けていた利用者からは、モデルピッカー廃止による作業効率低下やワークフロー崩壊を懸念する意見が出た。今回の騒動は「最新モデル＝常に最善」という前提に疑問を投げかけた形だ。</p>
<h2>OpenAIの即日対応と背景</h2>
<p>抗議の広がりを受け、OpenAIは即日<a href="https://help.openai.com/en/articles/11954883-legacy-model-access-for-team-enterprise-and-edu-users">レガシーモデルの再アクセス</a>を解禁。
8月8日（米国時間）、Sam Altman CEOはXで「Plusユーザーに4oを選べるようにする」と表明した。</p>
<ul>
<li><strong>個人向け（Plus／Pro）</strong> ：設定＞「Show legacy models」を有効化すると4oが再登場。</li>
<li><strong>法人・教育向け（Team／Enterprise／Edu）</strong> ：管理者が「Legacy model access」をONにすると、4oのほかo3、o3 Pro、4.1、4.5も利用可能。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sama_gpt5_rollout_2daedebc78/sama_gpt5_rollout_2daedebc78.jpg" alt="sama gpt5 rollout.jpg" /></p>
<p>いずれも “limited transition period”（移行の限られた期間）に限定され、利用は既存のクレジットや上限の範囲内だ。</p>
<p>背景には、OpenAIがGPT-5で安全性を強化した設計意図がある。
4oでは一部ユーザーの感情的依存や不適切な助言が問題視され、GPT-5では人生相談などに直接答えず熟考を促すなどの改善が施された。ただし、この方針が4oの「人間味」を削いだと感じるユーザーも多かった。</p>
<p>GPT-4o延命はあくまで暫定措置で、恒久提供は未定だ。#keep4o運動は現在も続いており、署名やフィードバックが送られ続けている。今回の一件は、AIサービス提供者にとって機能変更時の透明性、ユーザー通知、信頼維持の重要性を改めて浮き彫りにした。</p>
]]></description>
      <pubDate>Tue, 12 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ダイキン、米DDC Solutionsを買収──AIデータセンター向け液冷・空冷ハイブリッド型冷却技術を強化</title>
      <link>https://ledge.ai/articles/daikin_acquires_ddc_solutions_ai_datacenter_cooling</link>
      <description><![CDATA[<p>ダイキン工業は8月6日、100％子会社のダイキンアプライドアメリカズ（Daikin Applied Americas、以下DAA）を通じて、AIデータセンター向け冷却システムを手がける米Dynamic Data Centers Solutions（以下DDCS）を買収すると<a href="https://www.daikin.co.jp/press/2025/20250806">発表</a>した。買収は2025年8月下旬に完了する見込みで、急成長する高密度データセンター市場への対応力を高める。買収額は非公表。</p>
<p>DDCSはカリフォルニア州サンディエゴに本社を置き、液冷と空冷を組み合わせたハイブリッド型のキャビネット冷却システムに強みを持つ。特にAI処理や高性能コンピューティング（HPC）など、高負荷ワークロードに対応する高密度サーバーラック向け冷却技術を展開している。</p>
<p>ダイキンは、AIやクラウドの普及に伴いデータセンターの電力密度や発熱量が増大していることを背景に、冷却技術の高度化が急務と判断。今回の買収により、自社の空調分野で培ったノウハウとDDCSの液冷技術を融合し、AIデータセンター市場での競争力強化を図る。</p>
<p>DAAのCEOは「DDCSの技術は高密度ラック冷却の課題解決に直結する」と述べ、ダイキン工業の幹部も「今後のデータセンター市場拡大に向けて重要な投資」と位置づけている。</p>
<p>買収完了後は、DAAとDDCSの共同ブランドによる製品展開を計画。北米市場を皮切りに、アジアや欧州への展開を進め、AIデータセンターの省エネ化と持続可能性の向上に貢献する方針だ。</p>
]]></description>
      <pubDate>Tue, 12 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>人間とロボットが生み出す触覚データを資産化しAIが活用――東大発スタートアップcommissure、Physical AI時代を見据えた『Hapto AI構想』発表</title>
      <link>https://ledge.ai/articles/hapto_ai_commissure_physical_ai</link>
      <description><![CDATA[<p>株式会社commissureは2025年8月5日、人間やロボットが触覚データを生み出し、それを「感覚資産」として活用することを可能にする新構想「Hapto AI™構想（ハプト・エーアイ）」を<a href="https://prtimes.jp/main/html/rd/p/000000012.000118478.html">発表</a>した。触覚の収集から提示、AIによる生成までを統合し、物理世界での知覚・操作を高度化する「Physical AI」として位置づけるという。</p>
<h2>触覚の収集・提示・生成を統合</h2>
<p>同構想では、以下の3つの要素技術を中核とする。</p>
<ul>
<li><strong>SenseFuse™</strong> ：高精度に触覚データを収集するセンサ技術</li>
<li><strong>FeelFuse™</strong> ：触覚情報を人やロボットに提示するデバイス</li>
<li><strong>Hapto AI™</strong> ：収集した触覚データをもとに新たな触感を生成するAI</li>
</ul>
<p>commissureはこれらを組み合わせることで、人間同士や人間とロボット間で技能や感覚を伝承し合える仕組みを構築するとしている。</p>
<h2>技術的背景と応用領域</h2>
<p>同社は東京大学発のスタートアップとして、これまで触覚インターフェースの研究・製品化を進めてきた。今回の構想では、既存技術の蓄積を基盤に、触覚というデジタル化が難しかった感覚領域をAIで扱えるようにする。
応用領域としては、職人技の継承、遠隔作業支援、ロボットによる体験拡張などが想定されており、製造業から医療、エンターテインメントまで幅広い産業への展開が期待される。</p>
<p>「触覚は人間の技能や感覚の本質に関わるもの。Hapto AI™を通じて、技能とロボットの能力・スケールを掛け合わせた新たな価値を創出していく」と同社は述べている。</p>
<h2>今後の展望</h2>
<p>commissureは今後、Hapto AI™の開発を加速させ、触覚データを共有・蓄積しながら、物理世界とデジタル世界を融合させた新たなインタラクションの実現を目指す。これにより、人間とロボットが同じ感覚を共有し、相互に能力を高め合う「Physical AI時代」の基盤を築くとしている。</p>
]]></description>
      <pubDate>Tue, 12 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、日本法人代表に東條英俊氏を任命──東京拠点開設と採用計画も発表</title>
      <link>https://ledge.ai/articles/anthropic_japan_hidetoshi_tojo_appointment</link>
      <description><![CDATA[<p>米AI企業Anthropicは2025年8月7日、日本法人の代表執行役社長に東條英俊氏を任命したと<a href="https://www.anthropic.com/news/head-of-japan-hiring-plans">発表</a>した。</p>
<p>同社は今秋、東京オフィスを開設する予定で、エンタープライズ営業、カスタマーサクセス、エンジニアリングなどの職種で採用活動を開始する。日本企業とのパートナーシップ強化を通じ、生成AIの安全かつ有効な活用を支援していく方針だという。</p>
<p>東條氏はGoogle日本法人の執行役員などを歴任し、クラウドや生成AI分野で豊富な経験を持つ。海外企業での事業展開やパートナーシップ構築にも実績があるとのこと。</p>
<p>AnthropicはClaudeシリーズ（Claude 3.5 Sonnetなど）を提供し、米国外では英国、カナダ、アイルランドなどにも拠点を展開。今回の日本法人設立は、アジア地域での事業基盤強化の一環と位置づけられている。</p>
<p>発表の中で東條氏は「日本企業が生成AIを安全かつ有効に活用できる環境を整備していく」と述べた。同社も「日本市場は戦略的に重要な地域であり、ローカルチームを通じたサポートを強化する」とコメントしている。</p>
]]></description>
      <pubDate>Mon, 11 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米Cloudflare、Perplexityがrobots.txtなどの「クロール禁止」指示を回避しているとの検証結果を公表</title>
      <link>https://ledge.ai/articles/cloudflare_perplexity_stealth_crawling_block</link>
      <description><![CDATA[<p>Cloudflareは現地時間の2025年8月4日、Perplexity AIが運営するWeb検索特化AI「Perplexity」のクローラーが、robots.txtなどの「クロール禁止」指示を回避していると<a href="https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/">発表</a>した。</p>
<p>非公開テストドメインでも禁止コンテンツが取得されるなどの事例が確認され、User-Agent偽装やIPアドレスの切り替えといった「ステルスクローリング」の証拠が示された。同社はPerplexityを「Verified Bots」プログラムから除外し、全面的にアクセスを遮断した。</p>
<h2>禁止設定を突破したアクセスを検出</h2>
<p>Cloudflareによると、robots.txtやWebアプリケーションファイアウォール（WAF）でクロール禁止設定を行ったにもかかわらず、Perplexityによるアクセスが複数のサイトで確認された。User-AgentをmacOS版Chromeに偽装し、未公表のIPアドレスや異なる自律システム番号（ASN）からアクセスを行うなどの手法を用い、数百万件／日規模のリクエストが発生していたという。</p>
<h2>非公開テストドメインでの検証</h2>
<p>調査では、新規に設定した非公開ドメインを用意し、robots.txtで全面的にクロールを禁止した上で、Perplexityの公称Botをブロック。それでも禁止コンテンツがPerplexityの応答に含まれる事例が確認され、公称Botと異なる未申告Bot双方でアクセスがあったことが判明した。</p>
<p><strong>Cloudflareが示したPerplexityのクロール挙動の推定フロー</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/An_example_0a0dae6be3/An_example_0a0dae6be3.jpg" alt="An example.jpg" /></p>
<h2>他社との比較</h2>
<p>Cloudflareは、同様の検証をOpenAIのChatGPTに対しても実施。ChatGPTのBotはrobots.txtを取得し、禁止設定がある場合はアクセスを行わなかったとして、Perplexityの挙動との違いを強調した。</p>
<h2>Perplexityの反応</h2>
<p>Perplexityは同日、「これは大量スクレイピングではなく、ユーザー主導のリアルタイム取得である」とする声明を発表。Cloudflareが示したリクエスト数には外部サービス由来のアクセスが含まれており、計測や認識に誤りがあると主張した。</p>
<h2>今後の見通し</h2>
<p>Cloudflareは、未申告クローラーの検出・遮断ルールを継続的に強化すると表明。Perplexityは反論を続けており、今後は技術的手法の是非に加え、法務面での動向も注目される。</p>
<p>今回Cloudflareが指摘したクロール回避行為とは別の争点となっているが、8月7日には、読売新聞が東京地方裁判所にPerplexityを著作権侵害などで提訴した。記事や画像の無断利用を巡るものだという。</p>
]]></description>
      <pubDate>Mon, 11 Aug 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、米国一般調達局（GSA）と提携──連邦職員に「ChatGPT Enterprise」を1ドルで提供、1年間の限定プログラム開始</title>
      <link>https://ledge.ai/articles/openai_gsa_federal_chatgpt_1usd_2025</link>
      <description><![CDATA[<p>OpenAIは2025年8月6日、米国一般調達局（GSA）との新たなパートナーシップを<a href="https://openai.com/index/providing-chatgpt-to-the-entire-us-federal-workforce/">発表</a>し、米連邦政府の全職員を対象に「ChatGPT Enterprise」を1年間、エージェンシーごとに1ドルで提供する取り組みを開始した。政府全体での生成AI活用を加速させる狙いがある。</p>
<p>このプログラムでは、導入から60日間、OpenAIの最新モデルを無制限で利用可能となるほか、教育・研修支援として「OpenAI Academy」や利用者コミュニティへのアクセスが提供される。さらに、SlalomやBoston Consulting Groupとの提携による研修プログラムも用意されている。</p>
<p>セキュリティ面では、政府の機密性やプライバシーを守るため、利用データをモデルの再学習に使用しない方針を明記。GSAは、この取り組みを同局の「OneGov」戦略の一環として位置づけ、ホワイトハウスのAI Action Planの推進に寄与するとしている。</p>
<p>今回の提携により、GSAはOpenAIに加え、Anthropicの「Claude」、Googleの「Gemini」などをAIベンダーとして調達可能にした。これにより、連邦政府機関は複数の生成AIサービスから選択できる環境が整うことになる。</p>
<p>OpenAI CEOのサム・アルトマン氏は、「このパートナーシップは公共部門における生成AI活用を飛躍的に前進させる」とコメント。FedScoopやWiredは、この1ドル提供を「事実上の全職員アクセス解放」と評しており、象徴的な施策と位置づけている。</p>
]]></description>
      <pubDate>Mon, 11 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Alibaba、オープンソース画像生成AI「Qwen-Image」発表──英語・中国語で高精度テキスト埋め込み</title>
      <link>https://ledge.ai/articles/alibaba_qwen_image_launch</link>
      <description><![CDATA[<p>AlibabaのAI開発チーム「Qwen（通義千問）」は2025年8月4日、画像内に自然なテキストを高精度に埋め込める新たな画像生成AIモデル「Qwen-Image」を<a href="https://qwenlm.github.io/blog/qwen-image/">発表</a>した。英語と中国語に対応し、広告やデザインなど幅広い用途での活用が見込まれる。モデルはオープンソースとして公開され、商用利用も可能だ。</p>
<p>Qwen-Imageは、Qwenが開発したマルチモーダルモデル「Qwen-VL」を基盤に構築され、7Bパラメーター規模を持つ。ネイティブテキストレンダリング機能により、画像内に自然で読みやすい文字を直接描画でき、写真風からイラスト風、3Dレンダリングまで多様なスタイルを生成可能だ。また、テキストと画像の組み合わせ入力にも対応し、複雑な指示に基づくコンテンツ生成を実現する。</p>
<p>同モデルはGitHubでコードやモデルデータ、推論手順が公開されており、商用利用を含む幅広い用途で利用できる。ライセンスは一部制限付きながらも自由度が高く、Hugging Face上でのモデルカード提供も予定されている。</p>
<p>背景には、Alibabaの生成AI戦略強化がある。Qwenはこれまで言語モデルやマルチモーダルモデルを相次いで投入しており、特に「テキスト埋め込み精度」における競争力向上を目指している。ArXivに公開された技術報告では、英語・中国語双方で既存モデルを上回る精度を記録したことが示されている。</p>
<p><strong>Qwen-Imageは英語・中国語双方のテキスト埋め込み精度で既存モデルを上回る結果を記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bench_d01c8f78c9/bench_d01c8f78c9.jpg" alt="bench.jpg" /></p>
<p>今後は対応言語の拡大や、企業向けのカスタマイズ機能提供、広告クリエイティブ自動生成ツールとの連携などが見込まれる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/merge3_e42a1c66c7/merge3_e42a1c66c7.jpg" alt="merge3.jpg" /></p>
]]></description>
      <pubDate>Sun, 10 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropicら、AIの人格を数学的に操作する「Persona Vectors」発表──邪悪さ・お世辞・幻覚をコントロール</title>
      <link>https://ledge.ai/articles/persona_vectors_ai_personality_control</link>
      <description><![CDATA[<p>2025年7月29日、Anthropicを中心とした研究チームは、AIの性格特性を数学的に抽出・操作する手法「Persona Vectors（人格ベクトル）」を<a href="https://arxiv.org/abs/2507.21509">発表</a>した。この技術は、大規模言語モデル（LLM）が示す「邪悪さ」「お世辞」「幻覚」といった人格的傾向を、モデルの活性化空間における一次元のベクトルとして定式化し、モデルの訓練中および運用中にその傾向を監視・制御するための仕組みである。これにより、LLMの出力における一貫性や安全性の確保が可能になるという。</p>
<h2>モデルの人格傾向を“方向”として捉える発想</h2>
<p>Persona Vectorsの中核となるのは、人格的な出力傾向がモデルの活性化空間内における線形方向（ベクトル）として表現可能であるという前提である。研究チームは、以下の3つの性格特性を対象に検証を行った：</p>
<ul>
<li>邪悪さ（evilness）</li>
<li>お世辞（sycophancy）</li>
<li>幻覚（hallucination）</li>
</ul>
<p>これらは、既存の評価データセットやプロンプトペアを活用してモデルに入力され、異なる応答パターンを引き起こす。その差分をモデルの中間層活性化において比較・回帰分析することで、それぞれの特性を表現する一次元のベクトルが抽出される。</p>
<p>研究ではこのパイプラインを完全に自動化することで、任意の性格的特性に対応するベクトルを迅速に構築できることが示された。対象モデルには、Qwen 2.5-7B-InstructやLlama-3.1-8B-Instructが用いられている。</p>
<p><strong>図：Persona Vectorsの生成・応用パイプライン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Persona_vectors_and_their_applications_25984a8dfc/Persona_vectors_and_their_applications_25984a8dfc.jpg" alt="Persona vectors and their applications.jpg" /></p>
<h3>応用①：出力の人格ステアリング</h3>
<p>抽出されたベクトルを活用することで、モデルの出力傾向を任意に調整することが可能になる。具体的には、モデル出力に対しベクトル方向に沿って活性化を微調整することで、「邪悪さを減らす」「お世辞を抑える」といった操作ができる。</p>
<p>実験では、ステアリングによって邪悪な応答の出現率を約70%削減するなどの効果が確認された。これは、ファインチューニングを行わずに出力傾向をコントロールできる点で、運用上の柔軟性が高い。</p>
<p><strong>図：ベクトル方向に応じて応答の“性格”が変化。邪悪な行動、追従的な行動、幻覚的な行動をうまく引き出す誘導応答の例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Steering_with_persona_vectors_68ac1d9e2a/Steering_with_persona_vectors_68ac1d9e2a.jpg" alt="Steering with persona vectors.jpg" /></p>
<h3>応用②：運用時の人格モニタリング</h3>
<p>モデルが利用される場面において、ユーザーからの入力やシステムプロンプトが人格傾向に与える影響をリアルタイムで測定することも可能となる。研究では、システムプロンプト内の文言を徐々に変更しながら投影値を追跡し、それに応じた人格スコアがどのように変化するかを検証した。</p>
<p>このアプローチは、サービス提供者が人格的な逸脱の兆候を事前に察知し、対応するためのツールとして機能する。</p>
<p><strong>図：プロンプトの変更と投影値の相関</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Monitoring_prompt_induced_behavioral_shifts_0ab7b87ff4/Monitoring_prompt_induced_behavioral_shifts_0ab7b87ff4.jpg" alt="Monitoring prompt-induced behavioral shifts.jpg" /></p>
<h3>応用③：学習時の人格ドリフト検出と予防</h3>
<p>モデルのファインチューニングや追加学習によって人格傾向が意図せず変化してしまう、いわゆる「人格ドリフト」も重要な課題である。研究チームは、異なる学習データセットを用いてモデルを微調整し、学習前後の投影値と性格スコアを比較した。</p>
<p>結果として、事前の投影方向変化（ベクトル差分）を観察するだけで、人格スコアの変化を予測できることが示され、モデル更新前のリスク評価ツールとしての活用が期待される。</p>
<p><strong>図：学習による“人格ドリフト”を予測可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/6_Finetuning_shifts_along_persona_vectors_correlate_a682c9f7bd/6_Finetuning_shifts_along_persona_vectors_correlate_a682c9f7bd.jpg" alt="6 Finetuning shifts along persona vectors correlate.jpg" /></p>
<h3>応用④：データセットフィルタリング</h3>
<p>さらに研究では、LLM学習データとして広く使われる「LMSYS-CHAT-1M」から高・低スコアのチャットサンプルを抽出し、実際に人格特性が反映されているかを人手で確認した。これにより、データの“人格的偏り”を自動的に発見・除外できる可能性が示唆された。</p>
<h2>今後の課題と業界への波及</h2>
<p>Persona Vectorsは、比較的単純な性格傾向については有効に機能するが、複雑な感情や文脈依存の特性、多言語モデルへの適用などは今後の課題とされている。また、研究では主にオープンウエイトの中規模モデルが用いられており、Anthropic自身が開発するClaudeなどの商用モデルへの直接的な実装は今のところ未検証である。</p>
<p>論文の著者らは、“We hope Persona Vectors will serve as a building block for monitoring, interpreting, and controlling model behavior in a scalable and transparent way.”（Persona Vectorsが、モデルの振る舞いを大規模かつ透明性のある形で監視・解釈・制御するための基盤技術となることを願っている。）と、Persona Vectorsの役割をまとめた。</p>
]]></description>
      <pubDate>Sun, 10 Aug 2025 02:52:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta Reality Labs「ProMemAssist」：ユーザーの“話しかけていいタイミング”を推定するスマートグラス</title>
      <link>https://ledge.ai/articles/promemassist_smartglasses_meta</link>
      <description><![CDATA[<p>Metaの研究チームは2025年7月28日、ユーザーの作業メモリ状態をリアルタイムに推定し、声をかけるべきかどうかを判断するスマートグラス向けシステム「ProMemAssist」を<a href="https://arxiv.org/abs/2507.21378">発表</a>した。</p>
<p>視覚および音声から得られるマルチモーダル情報をもとに、タスク文脈や注意リソースを推測し、助言を送るべきか否かを計算する。論文はユーザーインタフェース技術の国際会議「UIST 2025」に採択された。</p>
<p><strong>ProMemAssist のシステム全体図。ユーザーの視覚・音声情報を取り込み、作業メモリモデルで現在のタスク文脈を推定し、適切なタイミングで音声アシストを通知する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/system_workflow_8d208f273c/system_workflow_8d208f273c.png" alt="system-workflow.png" /></p>
<h2>作業メモリモデルを実装した初のスマートグラス支援技術</h2>
<p>ProMemAssistは、ユーザーが現在何をしており、どの程度注意を割いているかを推定するために、認知心理学の作業メモリモデルを応用している。視覚（visuospatial）と音声（phonological）情報をそれぞれの短期記憶ストアに一時保存し、それらを統合して「エピソードバッファ」として文脈を把握する構成となっている。</p>
<p>たとえば、テーブルの上にある「フォーク」「スプーン」「ワインボトル」などの視覚情報と、「今夜は4人でディナーだ」といった音声から、ユーザーが「ディナーテーブルを準備している」と推論される。このように、ProMemAssistはユーザーの行動を「エピソード」としてメモリ上に保持する。</p>
<h2>「助言の価値」と「割り込みのコスト」を比較し、通知を制御</h2>
<p>助言を送信するかどうかは、LLM（大規模言語モデル）によって生成されたメッセージの「価値」と、現在のユーザーの作業状況に割り込む「コスト」とのバランスに基づいて判断される。メモリには容量制限があり、新しい情報が入るたびに、重要性や関連性が低い古い情報は置き換えられる。</p>
<p><strong>作業メモリ内の視覚・音声アイテムの構成。Recency（新しさ）、Relevance（関連性）、Importance（重要性）によってアイテムの保持／置換が決定される。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wm_displacement_e6750e4c01/wm_displacement_e6750e4c01.png" alt="wm-displacement.png" /></p>
<p>論文では、メモリアイテムには「新しさ（Recency）」「関連性（Relevance）」「重要性（Importance）」の3指標が与えられ、干渉を最小化するように情報が維持される様子が図示されている。アシストの例としては「フォークが足りないかもしれません」「ボトルを倒さないように注意してください」といった助言が生成され、タイミングを精査したうえで通知される。</p>
<p><strong>通知の可否判断フロー。現在のエピソードとの干渉度と、生成されたアシストの価値を比較し、通知の閾値を超える場合のみ提示される。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wm_interference_48a0b79e4e/wm_interference_48a0b79e4e.png" alt="wm-interference.png" /></p>
<h2>実証実験：助言回数は少なく、しかし有用</h2>
<p>ProMemAssistは、Meta Reality Labsの研究チームにより、12名の成人被験者を対象に実証実験が行われた。被験者は以下の4種類のタスクを実施し、それぞれにおいてアシストの有用性が検証された。
ディナーテーブルの設営
旅行カバンのパッキング
ワークスペースの整理整頓
趣味用品（バスケットボール、文房具など）の片付け</p>
<p><strong>ユーザー評価実験で実施されたタスク例。ディナーテーブル設営、旅行パッキング、ワークスペースの片付けなど、日常的な作業においてProMemAssistの有用性が検証された。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/task_setting_cd7937f7c3/task_setting_cd7937f7c3.png" alt="task-setting.png" /></p>
<p>比較対象として、タスク文脈を考慮せずにLLMが単に助言を生成・提示するベースラインが設定された。評価の結果、ProMemAssistは助言の数が少なかったにもかかわらず、被験者からの有用性スコアが高かった。また、NASA-TLXに基づくフラストレーションの評価指標においても有意に低下した（p = 0.043）ことが報告されている。</p>
<h2>プロトタイプ構成と将来的展望</h2>
<p>現段階では、ProMemAssistは商用ARグラスに外部カメラ・マイクを装着し、処理はノートPC上で行う構成となっている。システムは1秒ごとにユーザーの作業メモリ状態を更新し、必要に応じて音声でアシストを提示する。グラス自体にはスピーカーが非搭載のため、音声は外部端末から再生される。</p>
<p>今後は、オンデバイス処理の実装や、スピーカー内蔵型グラスとの統合により、完全スタンドアロンでの運用が見込まれている。また、対人コミュニケーションが重要な介護現場や接客業、共同作業環境での展開も視野に入れているという。</p>
]]></description>
      <pubDate>Sat, 09 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テキスト一行で3D世界が動く──Google DeepMind、新AIモデル「Genie 3」を公開</title>
      <link>https://ledge.ai/articles/genie_3_text_to_3d_world_generation</link>
      <description><![CDATA[<p>Google DeepMindは2025年8月5日、テキスト入力からインタラクティブな3D世界をリアルタイム生成できるAIモデル「Genie 3」を<a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/">発表</a>した。</p>
<p>Genie 3は、解像度720p・毎秒24フレームで再生可能な環境を生成し、ユーザーの行動に応じてオブジェクトの変化や環境の動的な反応を数分間維持できるという。生成された世界内では、キャラクターの移動や物体の操作、気象条件の変化なども即座に再現される。</p>
<h2>テキストから“遊べる世界”を即時生成</h2>
<p>Genie 3は、ユーザーが与えた短いテキストプロンプトや画像をもとに、実際に操作可能な世界を即座に構築するAIモデルである。入力は非常にシンプルで、「雷雨の夜の森」「宇宙船が着陸した火山地帯」といった自然言語だけで、複雑な3D環境が数秒で構築される。生成された環境は、プレイヤーが自由に歩き回り、オブジェクトに干渉できる設計になっている。</p>
<h2>Genie 2からの進化点</h2>
<p>前身である<a href="https://ledge.ai/articles/genie2_3d_world_model_ai_training">Genie 2</a>（2024年12月発表）では、画像を入力として2Dインタラクティブ環境を生成する機能が中心だった。これに対してGenie 3は、テキストだけで環境を立体的に構築し、3D的な物理挙動や環境変化を表現できる点が大きな進化とされる。また、Genie 3では、ユーザーの行動履歴を内部メモリとして保持することで、環境内の状態が継続的に更新される設計となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unnamed_1_84e786f1a7/unnamed_1_84e786f1a7.webp" alt="unnamed (1).webp" /></p>
<h2>公開デモで示された生成性能</h2>
<p>YouTubeで公開されたデモ映像では、テキスト「a cyberpunk city in the desert」（砂漠の中のサイバーパンク都市）を入力すると、数秒でネオンが光る都市が生成され、プレイヤーキャラクターがその中を移動。さらに「a stormy forest」（嵐の森）といったプロンプトでは、雷が鳴り響く中で風に揺れる木々や飛散する葉がリアルタイムで描写され、環境内の天候も再現されていた。</p>
<p>@<a href="https://www.youtube.com/watch?v=PDKhUknuQDg&amp;t=1s">YouTube</a></p>
<h2>AGIへの布石としての位置づけ</h2>
<p>DeepMindは公式ブログで、Genie 3を「汎用エージェントの訓練に不可欠な『世界モデル（world model）』の進化形」と表現している。生成環境内での行動やフィードバックを通じて、エージェント（AI）がより効率的に学習できる場を提供することが目的であり、同社はこの技術をAGI（汎用人工知能）研究の基盤の一つとして位置づけている。</p>
<h2>今後の展開</h2>
<p>現時点では、Genie 3は招待制のテストプログラムを通じて一部の研究者・開発者に限定公開されている。今後数か月をかけて、学術研究機関やクリエイター向けにAPIやツールキットの段階的な提供が予定されているが、具体的な一般公開時期は明示されていない。</p>
<p>DeepMindの取り組みは、OpenAIの「World Simulation」やMetaの「Builder World」など、他の大手AI企業が展開する“世界生成AI”領域とも重なる。ロボティクスや自律エージェント開発において、リアルなシミュレーション環境は重要な役割を担っており、Genie 3の技術は、ゲーム開発・仮想教育・都市設計・産業訓練といった分野でも応用が期待される。</p>
]]></description>
      <pubDate>Sat, 09 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropicが企業向けLLMで OpenAI を逆転──Menlo 北米での調査、32 %シェアで首位に</title>
      <link>https://ledge.ai/articles/anthropic_tops_enterprise_llm_market_2025_midyear</link>
      <description><![CDATA[<p>米ベンチャーキャピタルのMenlo Venturesは2025年7月31日、企業における大規模言語モデル（LLM）の導入実態を調査したレポート「2025 Mid-Year LLM Market Update」を<a href="https://menlovc.com/perspective/2025-mid-year-llm-market-update/">発表</a>した。調査によると、AnthropicのClaudeシリーズが企業利用において32％のシェアを獲得し、OpenAI（25％）を抜いて首位に立った。調査対象は北米を中心とした150社以上の技術責任者で、実運用中のAPIに基づいた数値だという。</p>
<h2>企業向けLLM市場、Anthropicが32％で首位に</h2>
<p>企業が本番環境で利用しているLLMプロバイダーのシェアは以下の通り</p>
<ul>
<li>Anthropic（Claude）：32％</li>
<li>OpenAI（GPT）：25％</li>
<li>Google（Gemini）：20％</li>
<li>Meta（Llama）：9％</li>
<li>DeepSeek：1％
2023年末の同様の調査ではOpenAIが50％以上の圧倒的シェアを持っていたが、半年間で大幅に後退し、代わってAnthropicが首位に立った。</li>
</ul>
<h2>Claudeシリーズ躍進の要因はコード生成とエージェント適性</h2>
<p>Anthropicが企業利用で支持を拡大した要因として、Menloは次の2点を挙げている。</p>
<ul>
<li><strong>コード生成性能の優位性</strong> ：開発者の支持はAnthropicが42％で、OpenAIの21％を大きく上回った。特にClaude 3.5 Sonnet以降、ソースコード生成やレビュー精度に関する評価が高まっている。</li>
<li><strong>エージェント化への対応</strong> ：Claude 3.5 Sonnetや今後のClaude 4系において、検証付き強化学習（RLVR）を用いたタスク実行能力の強化が進められ、社内業務の一部自動化に成功した企業が増加しているという。</li>
</ul>
<h2>LLM支出は半年で倍増、閉鎖型モデルが依然優位</h2>
<p>2025年上半期における企業のLLM支出は、前年同期の3.5億ドルから8.4億ドルに倍増した。主な要因は、PoC（概念実証）から本番環境への移行が加速したことによる。</p>
<p>また、依然としてクローズドソースのプロプライエタリモデル（Anthropic、OpenAI、Googleなど）が主流である。Menloはその理由として、パフォーマンス面の安定性と導入容易性を挙げている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_closed_source_vs_open_source_scaled_e220aacfdc/3_closed_source_vs_open_source_scaled_e220aacfdc.webp" alt="3-closed-source_vs_open-source-scaled.webp" /></p>
<h2>選定基準は「精度」「セキュリティ」「コスト」「拡張性」</h2>
<p>企業がLLMを選定する際の重視点として、Menloは以下の4点を挙げている。</p>
<ul>
<li>回答品質と精度</li>
<li>データプライバシーおよびセキュリティ対応</li>
<li>推論コスト</li>
<li>APIやRAGなどの拡張性
特にセキュリティ基準が厳格な業種（金融、医療、官公庁など）では、個別カスタマイズや内部検証が可能なプロバイダーが優先される傾向が強い。</li>
</ul>
<h2>オープンソース採用は伸び悩み、Meta Llamaが9％で最多</h2>
<p>一方、オープンソース系のLLMは全体の13％にとどまっており、MetaのLlamaがそのうちの9％を占める。導入には大規模なリソースが必要なうえ、中国製モデルに対するリスク懸念もあり、採用が限定的となっている。</p>
<h2>今後の注目点</h2>
<p>Menloはレポートの中で、今後の市場動向として以下の点に注目している。</p>
<ul>
<li>Anthropicの“エージェント・ファースト”戦略がどの程度実運用に耐えうるか</li>
<li>OpenAIやGoogleの巻き返し策（API料金改定、マルチモーダル強化など）の効果</li>
<li>複数LLMの組み合わせによるハイブリッド運用の広がり</li>
</ul>
<p>企業向けLLM市場は急拡大を続けており、今後数四半期でシェア構造がさらに変化する可能性があるとしている。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「理論がないAI/LLM」に情報幾何学から新たな解釈の可能性　──“曲がった”ニューラルネットワークが引き起こす爆発的記憶、京大らが高次相互作用の数理に突破口</title>
      <link>https://ledge.ai/articles/curved_neural_networks_memory_explosion</link>
      <description><![CDATA[<p>京都大学大学院情報学研究科の島崎秀昭准教授を中心とする国際研究チームは2025年7月29日、統計物理学の最大エントロピー原理をRényiエントロピーへ拡張し、高次相互作用を自然に組み込む新しいニューラルネットワークモデル「Curved Neural Networks（C-NN）」を開発したと<a href="https://www.kyoto-u.ac.jp/ja/research-news/2025-07-29-0">発表</a>した。</p>
<p>この成果は、2025年7月24日付で英科学誌『<a href="https://www.nature.com/articles/s41467-025-61475-w">Nature Communications</a>』に掲載された。</p>
<h2>高次相互作用を取り込む幾何学的アプローチ</h2>
<p>研究は、京都大学の島崎准教授をはじめ、バスク応用数学センター（BCAM）のMiguel Aguilera研究員、株式会社アラヤのPablo A. Morales主任研究員、英国サセックス大学のFernando E. Rosas助教らによる国際共同研究によって進められた。</p>
<p>従来のニューラルネットワークは、ノード間のペア相互作用（2体関係）のみを基本として構築されてきたため、三者以上が同時に関わるような「高次相互作用（higher-order interactions）」を理論的に扱うには限界があった。</p>
<p>研究チームは、確率分布の空間を「統計多様体」として捉え、その空間に曲率（curvature）を導入することで、追加のパラメータを用いることなく高次相互作用を記述可能とした。具体的には、最大エントロピー原理をRényiエントロピーに基づいて拡張し、指数分布の変形によって高次の結合が自然に導かれる新しい枠組みを構築している。</p>
<p><strong>■ 統計多様体の“葉構造”と高次相互作用の対応：</strong>
上：ノード（青）同士の複数リンクが三角形や四面体として重なり合い、三者以上の同時作用（高次相互作用）を表す。
右：曲率が 0（平坦）の場合、階層ごとに分離したサブマニフォールドEr0\mathcal{E}^0_rEr0 が存在する。
左：曲率 γ≠0\gamma <br />
eq 0γ=0 を導入すると空間が折り重なり、1つのパラメータで高次相互作用 E1γ,E2γ,…\mathcal{E}^\gamma_1, \mathcal{E}^\gamma_2,\dotsE1γ,E2γ,… が自然に内包される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294.jpg" alt="Higher-order decomposition resulting from the foliation of a statistical.jpg" /></p>
<h2>3つの特徴：爆発・自己調整・容量拡張</h2>
<p>C-NNには、以下のような重要な性質が確認された。</p>
<h3>爆発的記憶想起（Explosive Recall）</h3>
<p>エネルギーや温度パラメータがわずかに変化しただけで、記憶状態が瞬時に切り替わる「爆発的相転移」現象が観測された。これは、人間のひらめきに類似した挙動とされる。</p>
<h3>自己調節アニーリング（Self-regulating Annealing）</h3>
<p>ネットワーク内部のエネルギー状態に応じて「有効温度」が自律的に調整され、最適な記憶検索状態へ滑らかに遷移する仕組みが確認された。これは、従来の外部制御型アニーリングを不要にする。</p>
<h3>記憶容量とロバスト性の制御</h3>
<p>空間の曲率を定める単一パラメータγを調整することで、記憶容量の上限と誤り耐性（ロバスト性）のバランスを柔軟に制御可能であることが、解析とシミュレーションにより示された。</p>
<p>これらの性質は、いずれも個別にプログラムされたアルゴリズムによるものではなく、ネットワーク空間の幾何学的構造そのものから自発的に生じるとされている。</p>
<h2>理論と実装への橋渡し</h2>
<p>研究では、統計物理におけるレプリカ法を用いてモデルの性質を解析。曲率が負の多様体を用いたC-NNでは、従来型のHopfieldネットワークと比較して、記憶容量（格納可能なパターン数）が増加し、スピングラス状態（迷子状態）の発生が抑制されることが明らかとなった。</p>
<p>この結果は、計算資源を抑えながらも、より迅速で信頼性の高いメモリ検索や意思決定を可能とするネットワーク設計につながると期待されている。</p>
<h2>今後の展望</h2>
<p>C-NNの枠組みは、以下のような多様な領域への応用が見込まれる。</p>
<ul>
<li><strong>脳神経科学</strong> ：スパース発火や急激な記憶想起の数理的記述に貢献</li>
<li><strong>次世代AI設計</strong> ：Transformerや拡散モデルのエネルギー地形の再解釈</li>
<li><strong>ロボティクス／エッジA</strong> I：小型・省電力環境下での高速推論</li>
<li><strong>Explainable AI（XAI）</strong> ：幾何学パラメータによる構造的可視性の向上</li>
</ul>
<p>今後は、C-NNの学習アルゴリズムの一般化、生体神経活動との比較、フォトニック回路など物理実装との統合といった方向での発展が見込まれる。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、最新AI基盤モデル『GPT-5』を発表 — 誤差性能を大幅向上させ、既存製品ラインを統合した成熟の新エンジン、無料ユーザーを含む全ユーザーに提供開始</title>
      <link>https://ledge.ai/articles/gpt5_launch_all_users</link>
      <description><![CDATA[<p>OpenAIは2025年8月7日（現地時間）、最新の生成AIモデル「GPT-5」を<a href="https://openai.com/index/introducing-gpt-5/">発表</a>した。</p>
<p>推論能力・速度・応答品質を向上させた統合型エンジンで、ChatGPTでは無料ユーザーを含む全ユーザーが利用可能となる。発表は同社本社からのライブ配信で行われ、CEOサム・アルトマン氏が「私たちがこれまでに作った中で最も知的で、最も使いやすいAIだ」と述べ、教育や創作支援、ビジネス利用など幅広い活用を呼びかけた。</p>
<h2>GPT-5の概要と提供範囲</h2>
<p>GPT-5は、推論特化の「Thinking」、高速応答の「Fast」、リアルタイム会話の「Realtime」という3つのモデルを統合した新アーキテクチャを採用。利用状況やタスク内容に応じて最適なモデルを自動的に切り替える。</p>
<p>ChatGPTでは無料・有料すべての利用者に提供され、従来必要だったモデル選択が不要になった。開発者向けには、API経由でStandard／Mini／Nanoの3サイズが提供される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt_5_mano_mini_c973a3ace2/gpt_5_mano_mini_c973a3ace2.jpg" alt="gpt-5 mano mini.jpg" /></p>
<h2>技術的特徴と性能向上</h2>
<p>GPT-5は「Ph.D.級」の推論能力を備え、従来モデルと比べて知性・速度・信頼性のすべてを向上。コーディング分野ではSWE-Benchベンチマークで74.9%のスコアを記録し、前世代（o3）の69.1%を上回ったという。
トークン効率の改善や、コード内のバグ検出精度の向上も報告されている。UIデザインや文章生成の品質も向上し、専門領域から日常利用まで幅広いニーズに対応する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/coding_chart_4_side_ba38108ba3/coding_chart_4_side_ba38108ba3.jpg" alt="coding chart (4)-side.jpg" /></p>
<h2>ライブ配信での発表とデモ</h2>
<p>発表イベントでは、CEOのアルトマン氏が次のように語った。
「GPT-5は、あなたが知っている最も賢い人物を超える知性を持ち、その力をポケットの中に届けます。これからの時代、この技術はあらゆる人の生活と仕事の一部になるでしょう。」
開発チームは、教育分野での個別学習支援、創作活動のアイデア生成、ビジネスにおける資料作成や分析などのデモを披露。無料ユーザー解放の方針や、誤情報削減・応答検証などの安全性向上策についても説明した。</p>
<h2>開発者向け提供</h2>
<p>APIでは、処理速度やコストのバランスを選べる3サイズを用意。トークン数やツール呼び出し回数を削減する効率化も実現している。
ソフトウェア開発支援ツールを提供するCursor社のCEOは、「隠れたバグを見抜く能力は、我々が見た中で最も優れている」と評価している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_cursor_d4299f865f/gpt5_cursor_d4299f865f.jpg" alt="gpt5 cursor.jpg" /></p>
<h2>今後の展望</h2>
<p>GPT-5は、Microsoft Copilotなどのパートナー製品にも順次展開される予定。OpenAIはモデル統合によるユーザー体験の簡略化を今後も進め、安全かつ信頼性の高いAIの普及を目指すとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=0Uu_VJeVVfo">YouTube</a></p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>三菱UFJ銀行、200超の業務スキルを持つ自律型AIエージェント導入──Salesforce 「Agentforce for Financial Services」 日本初採用</title>
      <link>https://ledge.ai/articles/mufg_salesforce_ai_agentforce_launch</link>
      <description><![CDATA[<p>三菱UFJ銀行は8月1日、金融業界向けに特化した自律型AIエージェント「Agentforce for Financial Services」を導入すると<a href="https://www.salesforce.com/jp/news/press-releases/2025/08/01/mufg-customer-news-2/">発表</a>した。</p>
<p>提供元はセールスフォース・ジャパンで、同製品の日本国内における初の採用事例となる。同銀行は、CRM基盤である「Financial Services Cloud（FSC）」上にAIを組み込み、面談前後の情報提示や業務フォローアップを自動化することで、営業支援と顧客体験の質を向上させる狙いだ。</p>
<h2>金融機関向けに事前学習済みのAIエージェント</h2>
<p>「Agentforce for Financial Services」は、金融業務に特化して設計されたAIエージェントで、あらかじめ200種類を超える営業支援スキルを搭載している。面談の準備段階では顧客ごとのニーズや関心に関するインサイトを提示し、面談中には質問への応答や関連情報の提供、面談後には自動でタスクを生成・管理するなど、営業プロセス全体を自律的に支援する機能を持つ。</p>
<h2>SalesforceとMUFG、FSCを基盤に連携深化</h2>
<p>三菱UFJ銀行は2025年4月から、セールスフォースの金融特化型CRMである「Financial Services Cloud」を営業現場に導入しており、営業担当者が顧客情報を即時に把握できる体制を構築してきた。今回のAIエージェント導入は、その次のステップとして、FSCに蓄積された過去の営業履歴や顧客データを即座に活用できるAI基盤の整備を意味する。</p>
<h2>営業現場の業務をAIが代替、提案の質とスピードを両立</h2>
<p>Agentforceによって営業担当者は、より付加価値の高い活動に集中できるようになる。AIが面談準備からフォローアップまでの一連の業務を補完・代替することで、業務負荷を軽減すると同時に、提案の質とスピードを向上させることが可能となる。</p>
<h2>導入企業・提供企業のコメント</h2>
<p>三菱UFJ銀行の武井優・上席調査役は、「今回のAgentforce導入を通じて、営業支援と顧客体験の質が大きく向上すると期待している」とコメントしている。また、セールスフォース・ジャパンの田村英則・専務執行役員は、「金融業界で即時に活用可能なデジタル労働力として、Agentforceを提供し続ける」と述べている。</p>
<h2>今後の展開</h2>
<p>三菱UFJ銀行は今後、AIエージェントの適用領域を段階的に拡大し、FSCを基盤とした営業支援インフラの整備をさらに進める方針だ。一方、セールスフォースは専門チームによる導入支援とともに、他の金融機関への横展開を視野に、Agentforceの国内展開を強化していくとしている。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/9 [SAT]トヨタ、「Woven City」Phase1を9月25日正式開業──ロケット企業含む12社が“実証都市”に参画</title>
      <link>https://ledge.ai/articles/toyota_woven_city_phase1_launch_2025</link>
      <description><![CDATA[<p>トヨタ自動車とウーブン・バイ・トヨタは2025年8月4日、静岡県裾野市で建設中の実証都市「Toyota Woven City（ウーブン・シティ）」のフェーズ1が、9月25日（木）に正式開業すると<a href="https://woven.toyota/jp/our-latest/20250804/">発表</a>した。開業に合わせ、ロケット開発を手がけるインターステラテクノロジズなど新たに12社が実証パートナープログラム「Inventors」に参画。これにより、同プログラムの参加企業は計19社に拡大した。</p>
<h2>360人が暮らす“リアルな検証都市”が始動</h2>
<p>Woven Cityは、実環境での技術実証を目的にトヨタが構想した未来型都市。フェーズ1では約4.7ヘクタール（47,000㎡）の敷地に、住宅や商業施設、オフィスなどを整備し、最終的に約360人の居住者（Weavers）が生活する予定。住民にはトヨタグループの従業員とその家族が中心となる。</p>
<p>都市内では、モビリティ、ロボティクス、エネルギー、水素インフラ、スマートホームなどの技術が導入され、実際の暮らしの中で継続的な実証が行われる。2026年度には、外部ビジターの受け入れも予定されている。</p>
<h2>Inventorsプログラムに12社が新規参画</h2>
<p>技術検証を担う企業群「Inventors」には、新たに12社が加わった。</p>
<ul>
<li><strong>インターステラテクノロジズ株式会社</strong> （宇宙関連）：ロケットの量産体制構築に向けた共同検証を計画</li>
<li><strong>共立製薬株式会社</strong> （ヘルスケア）：人とペットが共生する社会モデルを構築</li>
<li>トヨタグループの10社（株式会社豊田自動織機、株式会社ジェイテクト、トヨタ車体株式会社、豊田通商株式会社、株式会社アイシン、株式会社デンソー、トヨタ紡織株式会社、トヨタ自動車東日本株式会社、豊田合成株式会社、トヨタ自動車九州株式会社）</li>
</ul>
<p>上記12社に加え、同年1月に公表したダイキン工業株式会社、ダイドードリンコ株式会社、日清食品株式会社、UCCジャパン株式会社、株式会社増進会ホールディングス、およびトヨタとWbyTを合わせた計19社の参画が決まっているとのこと。</p>
<p>Inventorsは、都市内の住民からのフィードバックを得ながら、各社が製品やサービスをリアルな環境で検証し、社会実装を目指す取り組み。今後はトヨタ以外のスタートアップや研究機関も対象としたアクセラレータープログラムの実施が予定されており、その詳細は8月25日に発表される見通しだ。</p>
<h2>「CES 2020」構想から約5年、ついに都市が始動</h2>
<p>Woven Cityは、2020年の「CES」で構想が発表され、Bjarke Ingels Group（BIG）が都市設計を担当。全体では約70ヘクタールの敷地に段階的に建設される計画で、今回開業するフェーズ1はその最初の実装フェーズとなる。</p>
<p>道路は「自動運転専用」「歩行者＋パーソナルモビリティ」「自然散策路」の3層で構成され、“編まれた都市（Woven）”の名が示すとおり、人と技術が調和するインフラ構造が特徴とされる。</p>
<h2>今後の展望</h2>
<p>トヨタはWoven Cityを「モビリティカンパニー」への転換を象徴する実証都市と位置付け、都市機能を横断するオープンプラットフォームとして活用していく。9月の開業後は、参画企業と居住者の協働によるリアルなテストが順次進められ、2026年度以降には一般公開や外部連携も本格化する予定だという。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>家電価格のロボ誕生　Unitree R1、87万円で歩く・走る・側転する25 kgヒューマノイド</title>
      <link>https://ledge.ai/articles/unitree_r1_5900usd_humanoid_robot</link>
      <description><![CDATA[<p>中国のロボット開発企業Unitree Roboticsは2025年7月25日、新型ヒューマノイド「Unitree R1」を<a href="https://www.unitree.com/R1">発表</a>した。価格は5,900ドル（約87万円）とされ、一般的な家庭用家電並みの価格帯に設定されている。</p>
<p>製品は全高1.21メートル、重量25キログラムの軽量ボディに26個のアクチュエーターを備え、歩行や走行、さらには側転やハンドスプリングといった高難度の動作を実現する。発表は上海で行われ、現在は主に研究機関や教育機関向けに出荷が計画されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=v1Q4Su54iho">YouTube</a></p>
<h2>5,900ドルの価格戦略と市場への位置づけ</h2>
<p>R1はヒューマノイドロボットとしては異例の低価格帯となる5,900ドル（中国国内価格は39,900元）から販売される。比較対象として、Unitree自身が開発するより上位モデル「G1」は約1万6,000ドル、また他社製のBoston Dynamics「Atlas」やTesla「Optimus」といった機種は数万ドルから数十万ドルに達するとされる。R1はこれらと比べて大幅に価格を抑えており、「普及型ヒューマノイド」のカテゴリに位置付けられる。</p>
<h2>軽量設計と26軸モーションによる高い機動性</h2>
<p>R1の本体はアルミニウム合金や複合素材を用いた軽量構造で、バッテリー込みで約25キログラムに抑えられている。各部位には以下のようなアクチュエーター（自由度）が割り当てられている。</p>
<ul>
<li>両腕に計10自由度（5自由度×2）</li>
<li>両脚に計12自由度（6自由度×2）</li>
<li>腰部に2自由度</li>
<li>EDU版では頭部に追加の2自由度</li>
</ul>
<p>これにより、R1は人間に近い複雑な動作が可能となり、発表時のデモンストレーションでは、歩行・小走り・回転・ジャンプ・側転などを披露した。また、映像内ではパンチやキックなどの模擬動作も確認されており、用途の幅広さがうかがえる。</p>
<h2>センサー・通信・駆動性能</h2>
<p>R1には以下のようなセンサーおよび機能が搭載されている。</p>
<ul>
<li>ステレオ深度カメラ</li>
<li>4マイクアレイによる音声入力</li>
<li>スピーカー搭載による音声出力</li>
<li>通信機能：Wi-FiおよびBluetooth 5.2</li>
<li>バッテリー駆動時間：約1時間（稼働環境に依存）</li>
</ul>
<p>制御用CPUは標準版で8コアの一般プロセッサが搭載され、上位のEDU版ではJetson OrinベースのAIモジュール（推論性能40～100 TOPS）を採用している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0.jpg" alt="4905f964d28c4e9cba75f2e1cf9591ba_1920x2370.jpg" /></p>
<h2>教育・研究向けのEDUモデルも展開</h2>
<p>同社はR1の教育用途向けバージョン「EDU版」も同時に発表している。EDU版は以下の機能拡張を含む。</p>
<ul>
<li>AI推論性能を強化したJetson Orin搭載</li>
<li>頭部の2軸モーター追加</li>
<li>デクスターズハンド（多関節ハンド）オプション</li>
<li>保証期間は標準版8カ月に対し、EDU版は12カ月</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138.jpg" alt="0705e5d2e5fd49989ca513716c9f50d3_1920x1606.jpg" /></p>
<p>研究開発やロボットコンテスト等での利用が想定されており、実装の自由度や拡張性を重視した設計が特徴となっている。</p>
<h2>上位機種との関係と市場戦略</h2>
<p>Unitreeはすでにヒューマノイドロボット「G1」や大型モデル「H1」を展開しているが、R1はその下位に位置するエントリーモデルと見られている。これまで高額な製品が主流だったヒューマノイド市場に対し、R1は価格の障壁を取り払い、新たな顧客層（教育機関、個人開発者、小規模研究機関など）への訴求を狙う。</p>
<h2>今後の展開と業界への影響</h2>
<p>公式発表では量産時期や出荷スケジュールの詳細は明かされていないが、R1は今後の展示会や開発者向けイベントでの出展が予想されている。家庭用製品並みの価格帯と高度な運動性能を併せ持つR1の登場は、ヒューマノイドロボットの導入障壁を下げ、教育・研究・開発領域における普及を後押しする可能性がある。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ラーニング2025/8/4 [MON]AIエージェントの可能性と活用のリアル　『現場で活用するためのAIエージェント実践入門』刊行記念ウェビナー｜視聴無料</title>
      <link>https://ledge.ai/articles/webinar-vol66</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>2025年は「AIエージェント元年」。生成AIの急速な進化を背景に、目標に応じて自律的に判断・行動する“AIエージェント”に大きな期待が寄せられています。その活用領域は、顧客対応や業務自動化、ナレッジ検索、意思決定支援など急速に広がり、すでに多くの企業が実証・導入を開始。実運用フェーズに移行しつつあるのが現状です。
こうした中、「本当に動くAIエージェントはどう作るのか」をテーマに執筆された、導入現場で使える実践的なノウハウをまとめた書籍『<a href="https://www.amazon.co.jp/dp/4065401402">現場で活用するためのAIエージェント実践入門</a>』（講談社）が7月に発売され、大きな注目を集めています。</p>
<p>本ウェビナーでは、同書の著者陣5名をゲストに迎え、AIエージェントの基本概念や技術的な背景、導入時の課題、ビジネスへの応用可能性まで、幅広いトピックについてお伺いしました。</p>
<p>AIエージェントに関心のある方や、現在導入を検討・推進されている方にとって必見の内容です。
視聴をご希望の方は、以下のフォームよりご登録のうえ、ぜひご覧ください。</p>
<p>:::button
<a href="https://zfrmz.com/wtVBx4BjLIMrlndfC0Xm">ウェビナーの視聴はこちら（無料）</a>
:::</p>
<h3>ウェビナー内容</h3>
<ul>
<li>AIエージェントとは何か？その歴史と定義</li>
<li>「エージェント型AI」と「エージェンティックAI」の違い</li>
<li>なぜ今、AIエージェントが注目されているのか</li>
<li>導入・展開に立ちはだかる技術的・組織的課題</li>
<li>AIエージェント活用はどう進めるべきか</li>
<li>AIエージェントはどうのように作るのか・相性の良い領域</li>
<li>エージェント導入のROI</li>
<li>AIエージェントが創る未来</li>
</ul>
<h3>このような方におすすめ</h3>
<ul>
<li>AI導入を検討中のビジネスリーダーの方</li>
<li>IT部門・情報システム担当の方</li>
<li>DX推進担当の方</li>
<li>AIエージェントに関心があり、情報収集を進めている方</li>
</ul>
<h2>登壇者情報</h2>
<p><strong>Sakana AI株式会社</strong>
<strong>太田真人</strong>
Applied Research Engineerとして、AIエージェントの社会実装に取り組む。前職の株式会社電通総研では、AIの技術調査やPoCを主導。対外的にもAIエージェントに関する最新情報の発信をしている。</p>
<p><strong>株式会社Algomatic</strong>
<strong>宮脇峻平</strong>
AI/MLエンジニアとして、採用を支援するAIエージェントの自社開発および品質保証に従事。2019年より自然言語処理に取り組み、現在は学術研究員として東北大学大学院に所属。雑談対話応答や質問応答タスクのコンペティションにも参加。</p>
<p><strong>株式会社ジェネラティブエージェンツ</strong>
<strong>西見公宏</strong>
2023年にAIエージェント解説書『その仕事、AIエージェントがやっておきました。』(技術評論社)を上梓し、その流れで共同創業者2名と共にAIエージェントの開発・利活用を専門に扱う株式会社ジェネラティブエージェンツを2024年3月に創業。共著に『LangChainとLangGraphによるRAG・AIエージェント[実践]入門』(技術評論社)。「本当に業務に使える」AIエージェントの開発に注力している。</p>
<p><strong>株式会社電通総研</strong>
<strong>後藤勇輝</strong>
2018年から機械学習に取り組み、自社における製品開発・研究開発に従事。近年は生成AIの可能性に注目し、技術とビジネスの両面から価値創出に取り組んでいる。著書に『PyTorch実践入門 ディープラーニングの基礎から実装へ』(マイナビ出版)、『アジャイルとスクラムによる開発手法 Azure DevOpsによるプロフェショナルスクラムの実践』(マイナビ出版)がある。</p>
<p><strong>株式会社電通総研</strong>
<strong>阿田木勇八</strong>
AIエンジニア / Kaggle Competitions Master。大学卒業後、大手医療機器メーカーに入社。製造現場やKaggleなどでデータ分析のスキルを磨く。その後、AIソリューションの提供側に興味をもち、2021年に電通総研に入社。機械学習を用いた製品開発、さまざまなAIモデル開発・改善案件に従事。現在は自然言語処理を扱う機能のソリューション開発に従事しており、2023年から生成AIエージェントの研究開発に取り組む。Kaggleでは、tacoriceとして参加している。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年8月4日(月)〜 2025年8月22日(金)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/wtVBx4BjLIMrlndfC0Xm">ウェビナーの視聴はこちら（無料）</a>
:::</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/10 [SUN]読売新聞、AI検索Perplexityを提訴──「約12万本無断利用」で21.7億円賠償請求、東京地裁に訴え</title>
      <link>https://ledge.ai/articles/yomiuri_sues_perplexity_2025</link>
      <description><![CDATA[<p>2025年8月7日、読売新聞の東京本社、大阪本社、西部本社の3社は、米国発のAI検索サービス「Perplexity（パープレキシティ）」を東京地方裁判所に提訴したことを<a href="https://www.yomiuri.co.jp/national/20250807-OYT1T50151/">発表</a>した。記事や画像を無断で取得・要約して提供し、著作権を侵害したとして、サービスの利用差止めと約21億6,800万円の損害賠償を求めている。</p>
<p>原告側によると、2025年2月から6月までの間に、読売新聞オンライン上の記事11万9,467件が無断で取得・複製されたと主張している。権利侵害の対象は著作権法上の複製権と公衆送信権であり、要約表示によって読者が出典サイトを訪れない「ゼロクリック」が発生し、閲覧機会や広告収入に影響が出たという。</p>
<p>Perplexityは、検索機能と生成AIを組み合わせ、インターネット上の情報を要約テキストや画像で提示するサービスである。入力された質問に対し、複数のウェブ情報を組み合わせた応答を返す特徴を持つ。</p>
<p>今回の提訴は、国内大手メディアによるAI企業への訴訟として初めてのケースとされる。読売側は「無断利用は正確な報道に負の影響を与え、民主主義の基盤を揺るがしかねない」として、法的措置の必要性を強調している。</p>
<p>Perplexityは読売新聞オンライン（8月8日付）に寄せたコメントで、「日本で誤解を生じさせたことについて大変遺憾に思っている」と述べた。さらに「主張の本質を把握するため全力で取り組んでいる」とし、「AIの時代に発行者とジャーナリストが新たなビジネスモデルから恩恵を得られるよう注力しており、本件を非常に真剣に受け止めている」と強調した。</p>
<p>海外では、報道機関とAI企業の間で著作権や情報利用を巡る争いが拡大しており、2025年6月には英国BBCがAI企業に対する法的措置の検討を明らかにしている。今回の訴訟でも、差止めの範囲や要約の適法性、損害の立証方法などが主要な争点となる見通しである。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTTデータとMistral AI、欧州発の安全・持続可能なプライベートAIをグローバル展開へ</title>
      <link>https://ledge.ai/articles/nttdata_mistral_private_ai_partnership</link>
      <description><![CDATA[<p>NTTデータとMistral AIは2025年7月29日、安全性と持続可能性を両立させた企業向けプライベートAIソリューションの共同開発およびグローバル展開に関する包括的提携を<a href="https://uk.nttdata.com/news/ntt-data-mistral-ai-sustainable-secure-private-ai-enterprises">発表</a>した。両社は、金融・保険・公共セクターなど規制の厳しい業界を対象に、欧州およびアジア太平洋地域での提供を進める方針を示した。</p>
<h2>データ主権を巡る環境</h2>
<p>生成AIの活用が広がる中で、EUやアジア太平洋地域では個人情報保護規制やデータ主権に対応したAI導入が喫緊の課題となっている。こうした背景を受け、Mistral AIはオープンウェイトの大規模言語モデル（LLM）を提供する企業として注目されており、NTTデータは同分野におけるシステム構築と運用支援の実績を活かす形で協業に乗り出した。</p>
<p>今回の提携は、両社の強みを融合し、クライアント企業が社内データを安全に活用しつつ、環境負荷を抑えたAI活用を実現することを目的としている。</p>
<h2>提携の3つの柱：開発・実装・市場展開</h2>
<p>NTTデータとMistral AIは、以下の3点を柱とした取り組みを展開するとしている。</p>
<ul>
<li><strong>技術開発</strong> ：エネルギー効率の高いプライベートLLMの構築とチューニングを共同で行う。</li>
<li><strong>ユースケース実装</strong> ：欧州およびアジア太平洋地域を対象に、エージェント型コールセンターなどの業務にAIを実装。特に、規制産業に対応した自然言語処理モデルの導入が想定されている。</li>
<li><strong>共同販売体制</strong> ：フランス、ルクセンブルク、スペイン、シンガポール、オーストラリアにおいて営業チームを共同編成し、サービスの市場浸透を図る。</li>
</ul>
<p>この提携における実装第1弾として、知的財産管理大手のDennemeyer社との協力による特許情報検索AIアプリケーションの開発が進められている。また、ルクセンブルクでは同国の金融業界向けに、AI活用を支える“ソブリンAI”インフラの構築を進行中だという。</p>
<h2>両社の体制と今後の展開</h2>
<p>NTTデータは、Mistral AIとの協業を推進する専門組織「Mistral AI Center of Excellence」を設立し、1,000人規模の体制で支援を行う。また、Mistral AIは、NTTデータの技術者を対象に認定プログラムや技術トレーニングを提供する計画で、技術面での連携も強化される。</p>
<p>今後は、業界別モデルや多言語対応型モデルの共同開発を予定しており、特に日本語・フランス語に最適化されたLLMの実装も視野に入っている。さらに、低炭素なデータセンター活用によってAI運用時のScope 3排出量を削減し、企業のサステナビリティ戦略にも寄与する方針だ。</p>
<p>NTTデータのCEOであるAbhijit Dubey氏は、「責任あるAIを社会実装することが我々の使命であり、本提携はそのための重要なステップである」と述べている。一方、Mistral AIのCEOであるArthur Mensch氏は、「最高水準のプライバシーと制御性を備えたAIソリューションを提供する」として、主権型AIの価値を強調した。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/8 [FRI]キリン、AI 役員「CoreMate」を経営戦略会議に常設──12 人格 × 10 年分データで意思決定を高速化</title>
      <link>https://ledge.ai/articles/kirin_ai_exec_coremate_decision_support</link>
      <description><![CDATA[<p>キリンホールディングス株式会社は2025年8月4日、独自開発したAI役員「CoreMate（コアメイト）」を2025年7月以降のキリングループ経営戦略会議に本格導入したと<a href="https://www.kirinholdings.com/jp/newsroom/release/2025/0804_02.html">発表</a>した。</p>
<p>CoreMateは、12の専門人格によって構成され、同社が過去10年間に蓄積してきた取締役会・経営戦略会議の資料や外部情報を学習済み。経営層の“右腕”として、多面的な論点提示やディスカッション支援を行うことで、意思決定の高度化とスピードアップを目指す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub2_4aefc3e255/sub2_4aefc3e255.jpg" alt="sub2.jpg" /></p>
<p>CoreMateは、経営戦略や重点テーマに対して12の異なる人格がそれぞれの立場・視点で意見を提示し、リアルタイムに論点を深堀りする。たとえば「サステナビリティ」「リスク管理」「ブランド戦略」といった専門性を持つ人格が、会議中に起案内容へフィードバックを加えることで、経営層は従来よりも多角的かつ迅速に判断を下せるようになる。</p>
<p>AIの基盤には、キリンホールディングスが過去10年間に実施した取締役会および経営戦略会議の議事録、関連資料、さらに外部の最新市場情報などが学習データとして組み込まれている。会議前には起案者がCoreMateと対話形式で資料のブラッシュアップを行う「壁打ち機能」も備えられており、資料の質向上と準備時間の短縮が期待されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_e503abd6a4/sub1_e503abd6a4.png" alt="sub1.png" /></p>
<p>CoreMateの活用は、グループ全体で年間30回以上実施される経営戦略会議を中心に進められており、今後は取締役会やグループ内の事業会社における戦略会議への導入も検討されている。また、リアルタイムでの議論の可視化や、より自然な対話が可能な会話型インターフェースの追加開発も視野に入れているという。</p>
<p>この取り組みは、同社が掲げる長期的なデジタル戦略「KIRIN Digital Vision 2035（KDV2035）」の一環として位置づけられており、「人がやらなくてよい仕事をゼロにする」「人と共に価値を生み出す仕事を加速する」という2本柱を支える中核技術とされている。CoreMateは、同ビジョンの実現に向けた象徴的なプロジェクトと位置づけられており、人的リソースの最適化と経営スピードの両立を支援する。</p>
<p>キリンホールディングスは、AI技術の実装を通じて経営判断におけるデータ駆動型の意思決定を強化し、持続的な成長と市場環境への柔軟な対応を図る構えだ。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>イーロン・マスク氏のNeuralink、英NHSと提携し欧州初の臨床試験へ──脳チップ競争激化、競合Synchronは“思考でiPad操作”映像公開</title>
      <link>https://ledge.ai/articles/neuralink_uk_trial_vs_synchron_ipad_demo</link>
      <description><![CDATA[<p>イーロン・マスク氏が率いるスタートアップ企業Neuralinkは2025年8月1日、イギリス・ロンドンおよびニューカッスルで、同社の脳インプラント「N1」を用いる臨床試験「GB-PRIME」を開始すると<a href="https://neuralink.com/updates/gb-prime-study-launch/">発表</a>した。対象は四肢まひを伴う神経疾患患者で、思考によってデジタルおよび物理デバイスを操作できるかを評価する。Neuralinkにとって欧州初の臨床試験となるこの動きに先立ち、競合のSynchronは脳内デバイスでiPadを操作する様子を公開し、脳コンピュータ・インターフェース（BCI）分野の国際競争が激化している。</p>
<h2>脳とマシンをつなぐ「BCI」、Neuralinkの米国試験から始動</h2>
<p>脳–コンピュータ・インターフェース（BCI）は、脳の神経活動を読み取って信号処理し、コンピュータや機械装置を直接制御する技術である。Neuralinkは2016年に創業され、BCIを通じて四肢まひ患者が意思を持って機器を操作できる未来を目指している。</p>
<p>同社が開発した「N1」インプラントは、直径約25mm、厚さわずか8mmの円盤型デバイスで、1024個の電極を内蔵し、64本の極細なスレッドを脳の運動皮質に挿入する。これらのスレッドは、同社製の手術ロボット「R1」によって自動的に埋め込まれる。</p>
<p>米国では2024年1月、FDA（米食品医薬品局）の承認を得て、初のヒト臨床試験「PRIME Study（Precise Robotically Implanted Brain–Computer Interface）」し、最大10人を対象とする早期治験。2025年7月時点で5人の被験者にN1を埋め込み済みで、信号安定性とデバイス操作能力のデータ収集が続く。</p>
<p><strong>Neuralink初の被験者が思考でオンラインチェスをプレイする様子</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/neuralink_live_chess_2c1ffce5c1/neuralink_live_chess_2c1ffce5c1.jpg" alt="neuralink live chess.jpg" /></p>
<h2>米国から欧州へ、Neuralinkが臨床の舞台を拡大</h2>
<p>Neuralinkは2024年、米国での初のヒト臨床試験「PRIME Study」で、すでに5人の被験者に脳インプラント「N1」を埋め込んでいる。今回の「GB-PRIME」はこの米国での知見を基に、英国における同様のプロトコルでの評価を目的とした臨床試験であり、同社にとって欧州初の展開となる。</p>
<h2>「GB-PRIME」の試験概要と対象</h2>
<p>試験は以下の2つの病院を拠点に行われる：</p>
<ul>
<li>University College London Hospitals（UCLH）</li>
<li>Newcastle upon Tyne Hospitals
対象となるのは、脊髄損傷や筋萎縮性側索硬化症（ALS）などにより重度の四肢まひを持つ最大7人の患者。Neuralinkは、被験者の脳内に直径25mm、1024の電極を備えたN1デバイスを自社開発の手術ロボット「R1」によって自動的に埋め込む。</li>
</ul>
<p>試験では、脳波信号の安定性、安全性、ならびに思考によるカーソルや機器の操作能力を主要な評価項目とする。</p>
<h2>英国当局の規制承認を取得済み</h2>
<p>同試験は、英国医薬品・医療製品規制庁（MHRA）によって治験申請（Clinical Trial Authorization：CTA）が承認され、研究倫理審査委員会（Research Ethics Committee：REC）も通過している。取得されたデータは、英国のデジタル医療規格に準拠して管理されるという。</p>
<h2>Synchronが公開した“iPadを思考で操作”の実演映像</h2>
<p>Neuralinkの欧州進出と時期を同じくして、競合であるSynchron（米国）は、脳に埋め込んだデバイス「Stentrode」によって思考だけでiPadを操作する様子を撮影したデモ動画を8月4日にYouTube上で<a href="https://www.youtube.com/watch?v=YK8r5vdpozA">公開</a>した。映像では、患者が文字入力やアプリ起動、ホーム画面の操作を行う様子が確認できる。</p>
<p>SynchronのStentrodeは、開頭手術を必要とせず、頸静脈経由で血管内にデバイスを留置する「低侵襲」な手法を採用している。すでに10人以上に埋め込まれており、Appleの新しいBCI HID（Human Interface Device）プロトコルに対応したソフトウェアとの統合も進行中とされている。</p>
<p>@<a href="https://www.youtube.com/watch?v=YK8r5vdpozA">YouTube</a></p>
<h2>競争激化するBCI分野、資金調達も活発化</h2>
<p>Neuralinkは2025年7月に約6億5000万ドルの資金を新たに調達し、累計調達額は約13億ドル、企業評価額はおよそ90億ドルに達したとされている。一方、SynchronもシリーズCまでで1億ドル以上を調達しており、Bezos ExpeditionsやARCH Venture Partners、Khosla Venturesなどが出資。2026年の米FDAへの正式な製品承認申請を予定しているという。</p>
<h2>今後の展望</h2>
<p>Neuralinkは、今後カナダやUAEなど複数の国で同様の臨床試験を展開する計画を明かしている。イーロン・マスク氏は「最終的には健常者への認知機能拡張も視野に入れている」と発言しており、倫理的・規制的課題との対話が引き続き焦点となる見通しだ。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Hugging Face CEO、「コードを書くようにLLMも自前で訓練すべき」と訴え――Nanotron公開で“企業製AI”の時代が現実味</title>
      <link>https://ledge.ai/articles/custom_llm_huggingface_nanotron</link>
      <description><![CDATA[<p>Hugging FaceのCEOであるClément Delangue氏は2025年8月4日、自身のX（旧 Twitter）に<a href="https://x.com/ClementDelangue/status/1952048356710039700">投稿</a>し、「すべてのテクノロジー企業は、Deepseek R1  Llama、GPT-5といった 独自の大規模言語モデル（LLM）を訓練でき、かつ訓練すべきだ」と呼びかけた。</p>
<p>投稿には「Every tech company can and should train their own Deepseek R1, Llama or GPT5, just like every tech company writes their own code.」という一文が添えられており、ソフトウェア開発の延長としてモデル開発を捉えるべきだとのメッセージが込められている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/clement_delangue_32591c644f/clement_delangue_32591c644f.jpg" alt="clement delangue.jpg" /></p>
<h2>専用LLM開発のハードルはすでに下がった</h2>
<p>Delangue 氏が “自社訓練” を促す背景には、近年のコスト低減とオープンソース化の進展がある。たとえば 2024 年末に公開された Deepseek R1 は推定 550 万ドルで訓練されたとされ、同規模モデルとしては低コストの事例となった。さらに Meta の Llama 3、そして OpenAI が次期フラッグシップとして準備を進める GPT-5 も、フォークや追加学習を前提に採用されるケースが増えている。
クラウド型 GPU クラスタや公開データセットが急速に整い、かつては巨額の資金を要した LLM 訓練が中堅企業でも射程に入る環境が整いつつある。</p>
<h2>Nanotronが後押しする“作れる AI”</h2>
<p>Hugging Face は7月30日、分散学習フレームワーク 「Nanotron」 と、その運用ノウハウをまとめた 「Ultra-Scale Playbook」 をProプラン加入者向けに無料提供 すると発表した。Delangue氏は X で「Free for @huggingface pro users」と明言しており、同社の有償サブスクリプション（個人25ドル／月〜）に登録している開発者が追加コストなく利用できる仕組みだ。</p>
<p>Playbook には</p>
<ul>
<li>100億パラメータ超モデル を訓練するステップバイステップ手順</li>
<li>GPU クラスタ最適化や障害対応などの実務ノウハウ</li>
<li>Databricks や Lambda Labs など外部インフラとの接続例
が収録されており、研究機関・スタートアップが“自社LLM”に踏み出す際のガイドとして機能するという。</li>
</ul>
<h2>企業が自前モデルに踏み切る理由</h2>
<p>Delangue氏の主張は、すでに複数の産業分野で進む「自社専用LLM」開発の潮流と一致する。とくに以下のようなニーズに対応する目的で、LLMを自社開発・内製化する動きがみられる。</p>
<ul>
<li><strong>機密データの保持</strong> ：顧客情報や製造ノウハウなど、外部クラウドに預けられないデータを安全に活用可能</li>
<li><strong>推論コストの削減</strong> ：自社ホスティングにより、API利用料の継続的負担を回避</li>
<li><strong>法令・ガバナンスへの準拠</strong> ：業界ごとのコンプライアンス要件に合わせたモデル調整が容易
他方で、GPU 調達競争や高品質データの確保、人材不足といった課題は依然として残る。</li>
</ul>
<p>Delangue氏の発言は、AI業界が「買うAI（API利用）」から「作るAI（内製モデル）」へのシフトを迎えているという見方を反映している。今後は、独自モデルをいかに迅速に開発し運用できるか が企業競争力の重要指標となりそうだ。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT、週次利用者7億人へ──3月から2億人増、1年で4倍に</title>
      <link>https://ledge.ai/articles/chatgpt_weekly_users_700_million</link>
      <description><![CDATA[<p>2025年8月4日、米OpenAIは、対話型AI「ChatGPT」の週間アクティブユーザー（WAU）が今週中にも世界で7億人を超える見通しであることを明らかにした。これは、同社プロダクト責任者ニック・ターレイ氏がX（旧Twitter）上に<a href="https://x.com/nickaturley/status/1952385556664520875">投稿</a>した内容および関連報道に基づく。3月末時点でのWAUは5億人であり、約4カ月で2億人の増加となる。2024年時点と比較すると、年間で約4倍の成長となる。</p>
<h2>新機能と法人利用の拡大</h2>
<p>急成長の要因として、2025年3月に追加されたGPT-4ベースの高精度画像生成機能や、会話の文脈を継続して記憶できる「メモリ機能」など、ユーザーの実用性を高めるアップデートが影響しているとみられる。また、法人向けのChatGPT Enterpriseプラン契約社数も増加傾向にあり、2025年6月時点で500万社に達したことが報告されている。これは3月時点から200万社の増加に相当する。</p>
<p>アプリ市場調査会社Sensor Towerによると、ChatGPTの1ユーザーあたりの平均利用頻度は月12日以上、1日の平均利用時間は約16分とされている。</p>
<h2>年間売上は20億ドル超　評価額は5,000億ドル視野に</h2>
<p><a href="https://www.reuters.com/business/openai-eyes-500-billion-valuation-potential-employee-share-sale-source-says-2025-08-06/">ロイター</a>の報道によると、OpenAIの収益性も急速に高まっており、ChatGPT関連事業を含めた年間売上は20億ドル（約2,800億円）を超えるとの市場推計が出ている。また、社員保有株の売却計画に関連して、同社の企業評価額は5,000億ドル（約70兆円）規模に達する可能性があると報じられている。</p>
<h2>競合との競り合いが激化　GoogleやAnthropicも拡大路線へ</h2>
<p>業界全体としては、Googleの「Gemini」アプリが月間4億5,000万MAU（Monthly Active Users）を維持しており、OpenAIと並んで高い利用者数を記録している。また、Anthropicが開発するClaudeなどの他の大手モデルもユーザー獲得を進めており、生成AI市場におけるシェア争いが一層激化している。</p>
<h2>今後の展開：ポケット内デバイスで稼働する超高性能AIを示唆</h2>
<p>OpenAIは次世代モデル「GPT-5」を開発中と報じられており、2025年8月中にも発表される可能性が指摘されている。あわせて、ChatGPTには生活支援やメンタルヘルスなどウェルネス領域の機能強化が計画されているとの情報もある。
8月6日には、同社のサム・アルトマン最高経営責任者（CEO）がXで次のように投稿した。</p>
<p>someday soon something smarter than the smartest person you know will be running on a device in your pocket, helping you with whatever you want.</p>
<p>this is a very remarkable thing.</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/remarkable_thing_sama_gpt5_30a5cb690c/remarkable_thing_sama_gpt5_30a5cb690c.jpg" alt="remarkable thing sama gpt5.jpg" /></p>
<p>アルトマン氏は、ポケット内のデバイス上で“最も賢い人物より賢い”AIが近い将来稼働するとの見通しを示した。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Gartner、「日本におけるクラウドとAIのハイプ・サイクル：2025年」を発表──AIエージェントが”過度な期待”のピークに、RAGは幻滅期へ</title>
      <link>https://ledge.ai/articles/gartner_cloud_ai_hypecycle_2025_japan</link>
      <description><![CDATA[<p>ガートナージャパン（以下Gartner）は2025年8月5日、日本市場におけるクラウドおよびAI関連技術の成熟度とビジネス価値に関する予測をまとめたレポート「日本におけるクラウドとAIのハイプ・サイクル：2025年」を
<a href="https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20250805-cloudai-hc">発表</a>した。</p>
<p>このレポートは、企業のITおよびビジネスリーダーがクラウドやAI技術の導入判断を行ううえでの指針となるもので、今回は計34の技術を「AI／産業革命」「クラウド」「マイグレーション」の3つの観点で位置づけている。</p>
<h2>クラウドの再定義──AIを支える基盤へ</h2>
<p>Gartnerはこのレポートにおいて、クラウド・コンピューティングという名称が登場して20年が経過する中、クラウドが企業の既存システムを支えるだけでなく、AIや生成AI、AIエージェント、エージェント型AI、マルチエージェントの開発を推進する基盤へと進化していると指摘した。</p>
<p>さらに、数億人規模のユーザーにAGI（Artificial General Intelligence：汎用人工知能）を提供可能なハイパーAIスーパーコンピュータへと変貌を遂げつつあるとしている。企業は、クラウドを単なるITインフラではなく、AIによる産業革命クラスのインパクトをもたらす基盤として捉える必要があるという。</p>
<h2>ハイプ・サイクルにおける注目技術の位置づけ</h2>
<p>レポートでは、34の技術を5つの成熟度段階に分類している。</p>
<h3>▸ 黎明期（17項目）</h3>
<ul>
<li><strong>エージェント型AI（エージェンティックAI）</strong></li>
<li><strong>MCP（Model Context Protocol）</strong></li>
<li><strong>A2A（Agent-to-Agent）プロトコル</strong></li>
<li><strong>フィジカルAI</strong></li>
<li><strong>M2C（Mainframe-to-Cloud）マイグレーション</strong></li>
<li>AIオーケストレーション</li>
<li>AIネットワーキング</li>
<li>AIファクトリ</li>
<li>World Model（世界モデル）</li>
<li>QCaaS（量子コンピューティング・クラウド・サービス）</li>
<li>インダストリAI</li>
<li>ハイパーAIスーパーコンピュータ</li>
<li>マルチエージェント・システム　など</li>
</ul>
<h3>▸ 過度な期待のピーク期（7項目）</h3>
<ul>
<li><strong>AIエージェント</strong></li>
<li><strong>V2C（Virtual-to-Cloud）マイグレーション</strong></li>
<li><strong>再仮想化</strong></li>
<li>LLM（大規模言語モデル）プラットフォーム・サービス</li>
<li>クラウドAIサービス　など</li>
</ul>
<h3>▸ 幻滅期（7項目）</h3>
<ul>
<li><strong>RAG（検索拡張生成）</strong></li>
<li><strong>IaC（Infrastructure as Code）</strong></li>
<li>クラウドネイティブ</li>
<li>クラウド・レジリエンス</li>
<li>サイト・リライアビリティ・エンジニアリング　など</li>
</ul>
<h3>▸ 啓発期・生産性の安定期</h3>
<ul>
<li>FinOps</li>
<li>プラットフォームエンジニアリング</li>
<li>インダストリクラウド</li>
<li>ソブリンクラウド</li>
<li>分散クラウド</li>
<li>BMaaS（サービスとしてのベアメタル）</li>
</ul>
<h2>技術動向の特徴と課題：AI技術の急速な進展と過熱リスク</h2>
<p>全般的にAIは、ベンダーの投資が非常に活発であると同時に、ユーザー側の関心も持続的に高まっており、実践的な取り組みも加速度的に進展している。Gartnerは、AIは比較的早い段階で成熟期に達すると予測している。</p>
<p>一方で、AI領域の多くのイノベーションは過熱（ハイプ）しやすい傾向があり、特に「エージェント型AI」はその典型だという。同社は、2027年末までにエージェント型AI導入プロジェクトの40%以上が、コストの高騰やビジネス価値の不明確さ、不十分なリスクコントロールを理由に中止になるとの見解を示している。</p>
<h2>クラウド技術の成熟化の遅れ</h2>
<p>クラウド関連技術は登場から相応の年月が経過しているにもかかわらず、企業における活用が限定的にとどまっており、成熟には想定以上の時間を要しているという。</p>
<h2>RAGの幻滅期への移行</h2>
<p>注目すべきは、多くの企業が取り組んでいるRAG（検索拡張生成）が幻滅期に入ったことだ。RAGの精度向上に苦心している企業が多く、この状況が続くと生成AI全体の期待度の低下につながる可能性があるとGartnerは警告している。</p>
<h2>Gartnerアナリストの見解</h2>
<p>GartnerのディスティングイッシュトVPアナリストである亦賀忠明氏は、以下のように述べている。
「企業は、クラウドを、既存システムのマイグレーション先としてのみならず、新たなビジネス・サービスの基盤、さらにはAIによる産業革命クラスのインパクトをもたらす基盤として捉える必要があります」</p>
<p>また、AIエージェントへの過度な期待について「AIエージェントウォッシングに留意しながら、過度な期待や過小評価に陥らず、自社に合った導入戦略と展開のタイミングを見極める必要がある。データ基盤整備や人材のケイパビリティ（スキル・マインドセット・スタイル）獲得を着実に進めていくことが重要」と助言している。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>