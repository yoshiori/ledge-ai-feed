<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Tesla、日本で「Full Self-Driving（Supervised）」のテスト走行を開始──市街地や高速道路での運転支援性能を検証</title>
      <link>https://ledge.ai/articles/tesla_fsd_supervised_japan_test</link>
      <description><![CDATA[<p>Tesla Japan（テスラ）は2025年8月20日、運転支援システム「Full Self-Driving（Supervised）」の日本でのテスト走行を開始したと<a href="https://prtimes.jp/main/html/rd/p/000000048.000038481.html">発表</a>した。市街地や高速道路を含む公道で、信号や標識の認識、交差点での右左折、歩行者や自転車への対応などの機能を検証する。（<a href="https://x.com/teslajapan/status/1957986432926249405">走行テストの様子</a>）</p>
<p><strong>日本でのテスト走行に使用されるTeslaのModel 3</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub4_babbf79619/sub4_babbf79619.jpg" alt="sub4.jpg" /></p>
<p>FSD(Full Self-Driving)は、同社が開発する最新の運転支援システムで、車両には「AI 4 ハードウェア」および「Tesla Vision」が搭載される。これにより、信号や標識の認識、交差点での右左折、さらには歩行者や自転車への対応など、複雑な交通環境での走行を支援する。</p>
<p>名称に「Supervised」とある通り、ドライバーによる常時監視が必須となる。運転者がステアリングを握っていない場合や注意が散漫と判断された場合には、警告が発せられる仕組みだ。完全自動運転ではなく、あくまで人間による管理のもとで機能する点を強調している。</p>
<p><strong>オートパイロットを使用したテスラ車両は、一般的な車両に比べて衝突事故発生までの平均走行距離が大幅に長い</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_a8ddd97395/sub1_a8ddd97395.jpg" alt="sub1.jpg" /></p>
<p>テスト走行はまず限定的に開始され、今後順次エリアを拡大する見通し。日本市場での展開に向けた重要なステップと位置づけられ、欧州に続いて導入が進む。</p>
<p>テスト走行の裏側では、FSDを支えるAI学習基盤の強化も進んでいる。テキサス州オースティンの最新工場Giga Texasでは、AIトレーニング用コンピュートクラスター「Cortex」を増強。約16,000台のH200 GPUを追加導入し、総計算能力はH100換算で約67,000台分に到達した。</p>
<p><strong>Giga TexasのAI学習用クラスター「Cortex」。約16,000台のH200を追加し、総計算能力はH100換算で約67,000台分）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub3_e87e1adbef/sub3_e87e1adbef.jpg" alt="sub3.jpg" /></p>
<p>Teslaは「FSD（Supervised）」の実証を通じて、日本における次世代運転支援システムの普及と安全性検証を進める方針だ。</p>
]]></description>
      <pubDate>Tue, 26 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、Metaから6年で100億ドル超のクラウド契約を受注──Metaは急速なAIインフラ強化へ</title>
      <link>https://ledge.ai/articles/google_meta_cloud_deal_ai_infra</link>
      <description><![CDATA[<p>Googleは、Meta Platformsと6年間で100億ドル（約1兆4800億円）超のクラウドコンピューティング契約を締結したことが、2025年8月21日に関係筋の話として<a href="https://jp.reuters.com/economy/industry/ZUPUKEMNYJKTFCL3P5NFAKWH2M-2025-08-22/">ロイター</a>など複数のメディアが報じた。</p>
<p>契約にはGoogle Cloudのサーバー、ストレージ、ネットワーキングなどのインフラ利用が含まれ、Metaの急速に進むAI開発計画を支えるものとなる。</p>
<p>今回の大型契約は、Metaが進める「スーパーインテリジェンス」構想の一環とみられており、大規模AIモデルの学習や推論に必要な計算資源を確保する狙いがあるという。Metaは2025年の設備投資（Capex）見通しを最大720億ドルに引き上げており、AI関連の投資を加速させている。</p>
<p>一方、Google Cloudは成長の原動力として注目されており、2025年第2四半期の売上は前年同期比32％増を記録。今回の契約は同社にとって最大級の案件のひとつであり、競合するAmazon Web Services（AWS）やMicrosoft Azureに対抗する上で大きな追い風となる。</p>
<p>Metaはまた、資金確保のために一部のデータセンター資産を約20億ドル規模で売却する計画も進めている。両社は今回の契約について公式コメントを控えているが、複数の報道によればすでに合意が成立しており、今後のAIインフラ拡大に直結するものとなる見通しだ。</p>
]]></description>
      <pubDate>Tue, 26 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>公共2025/8/25 [MON]地球社会の未来、2030年代前半に分岐点　京都大と日立がAIでシナリオ分析</title>
      <link>https://ledge.ai/articles/global_ai_future_simulation</link>
      <description><![CDATA[<p>京都大学と日立製作所は2025年7月7日、AIを活用した未来シミュレーションと政策提言を<a href="https://prtimes.jp/main/html/rd/p/000000003.000164782.html">発表</a>した。分析では、地球社会が格差や分断を回避し持続可能な成長を実現できるかどうかの分岐点が、2020年代末から2030年代前半にかけて現れるとされた。</p>
<h2>研究の目的と背景</h2>
<p>京都大学と日立製作所は、気候変動や格差拡大などの地球規模課題に対応するため、AIによる未来シミュレーションを実施した。本研究は、日本社会向けに行われてきた「政策提言AI」を拡張し、世界全体を対象にしたものである。</p>
<h2>手法</h2>
<p>世界の294指標を用いて原因 - 結果モデルを構築。AIによる2万件のシミュレーションを通じて、2050年までに起こり得る7つの未来シナリオを導出した。</p>
<h2>シナリオの概要</h2>
<ul>
<li>Regional Dispersion and Maturity（地域分散と成熟）：人口や産業が特定都市に集中せず地域に分散。格差が縮小し、社会的安定が進む。</li>
<li>Green Growth and Cooperation（グリーン成長と協調）：環境保護と経済成長を両立し、国際協力によって持続可能性を高める。</li>
<li>Climate and Conflict Double Crisis（気候・紛争二重危機）：気候変動の悪化と紛争増加が重なり、社会に深刻な影響を与える。</li>
<li>Polarization（分極化）：格差拡大と社会分断が進み、社会の安定が損なわれる。</li>
</ul>
<p><strong>AIによる未来シミュレーションから導出された7つのシナリオと分岐点</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/164782_3_5a33b2e23fbdeba0bb64c0f4f3a07b78_749x461_cf3d5a1faf/164782_3_5a33b2e23fbdeba0bb64c0f4f3a07b78_749x461_cf3d5a1faf.jpg" alt="164782-3-5a33b2e23fbdeba0bb64c0f4f3a07b78-749x461.jpg" /></p>
<h2>分岐点の時期</h2>
<ul>
<li>2029年頃：「Polarization（分極化）」の可能性。</li>
<li>2032年頃：「Regional Dispersion and Maturity」への移行。</li>
<li>2034年頃：「Green Growth and Cooperation」への移行。</li>
</ul>
<h2>政策提言</h2>
<ul>
<li>分極化を回避するには、先進国による環境対策の加速と途上国への経済支援が求められる。</li>
<li>地域分散・成熟型への移行には、少子化対策や格差是正、研究投資、公衆衛生の強化が必要。</li>
<li>グリーン成長型の実現には、国際協力と社会資本整備の推進が重要とされる。</li>
</ul>
<p><strong>持続可能な社会に必要とされる「社会的共通資本」の概念</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/164782_3_7693cf90e7e46f0a5a8cfa64b7b716d9_1024x724_371d1fd23a/164782_3_7693cf90e7e46f0a5a8cfa64b7b716d9_1024x724_371d1fd23a.webp" alt="164782-3-7693cf90e7e46f0a5a8cfa64b7b716d9-1024x724.webp" /></p>
<p>2017年以降、日本社会向けの研究では、都市集中と地域分散の分岐が示されていた。今回の分析は、その国際版と位置づけられる。</p>
<p>研究チームは今後、モデルの精緻化やデータ拡充を継続し、国際政策や各国の政策議論での活用を視野に入れているとのこと。</p>
]]></description>
      <pubDate>Mon, 25 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIエンジニア視点で紐解くAIエージェントの可能性　技術背景とビジネス活用の最前線｜『現場で活用するためのAIエージェント実践入門』刊行記念インタビュー</title>
      <link>https://ledge.ai/articles/introduction-to-ai-agents-book-interview</link>
      <description><![CDATA[<p>「AIエージェント元年」と呼ばれる2025年は、目標に応じて自律的に判断・行動するAIエージェントに大きな期待が寄せられており、各企業で導入や検討が進んでいる。その中で、2025年7月発売の「本当に動くAIエージェントはどう作るのか」をテーマに執筆された書籍『<a href="https://www.amazon.co.jp/dp/4065401402">現場で活用するためのAIエージェント実践入門</a>』（講談社）が大きな注目を集めている。
今回は、導入現場で使える実践的なノウハウをまとめた同書を執筆した著者陣5名に、AIエージェントの基本概念や技術的な背景、導入時の課題、ビジネスへの応用可能性などについて取材を行った。</p>
<h2>著者情報</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMG_0170_a_220937aab9/IMG_0170_a_220937aab9.jpg" alt="IMG_0170_a.jpg" /></p>
<h2>AIエージェントとは何か</h2>
<p><strong>ーーまず初めに、AIエージェントとは何か？というところから、解説をお願いできますか。</strong></p>
<p><strong>太田氏</strong>
AIエージェントという言葉は、2023年頃から出てきたというイメージを持たれているかもしれませんが、実は1970年、90年頃からありました。「エージェントとはなんですか？」という問いに関しては、【<strong>目標に向けて環境で相互作用する知能システム</strong>】と位置づけるのが、個人的にはわかりやすいと思っています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_1_5353dee988/AI_1_5353dee988.png" alt="AIエージェント_1.png" /></p>
<p>もう少しかみ砕いて説明します。目標というのはわかりやすいですよね。何かをするイメージで、“これを達成しなければならない”というのが目標です。
では、”環境とは何か”という点についてですが、エージェントが動ける空間をイメージしてください。デジタル空間もあれば、我々がいるこの場のようなフィジカルな空間もあり、その両方を環境と言います。</p>
<p>「環境と相互作用するとは何か？」についてですが、そもそもAIは知能を人工的に作っているだけの知能なので、手や足があるわけではない。なので、我々がいるフィジカル環境やデジタル空間にインタラクションするということはできないんです。AI自体は何かを認識するなどしかできないのですが、「エージェント」と呼ばれるものは、人工知能を使って環境へインタラクションできるというのがポイントです。”環境”から情報を受け取ってAIエージェントが認識し、「次はこれを行おう」と判断して実際に行動できるということが重要なのです。</p>
<p><strong>ーー1970年代より概念があったとお話いただきましたが、ここ数年でなじみが出てきたのは、生成AIが大きく関係しているのでしょうか。</strong></p>
<p><strong>太田氏</strong>
そうです。昔はルールベースや、データから学習しなければならず、研究・開発者以外の皆さんの手元に届けるのに時間がかかっていたんです。
私たちが身近に扱うものって自然言語や画像などがありますが、生成AIやLLMは「テキスト（自然言語）で指示をしたら、テキストで返答してくれる」というのがポイントで、このLLMという知能がユーザー層と密接になったことで、皆が「エージェントで何かできるのではないか」と考え始めるきっかけになったと思っています。</p>
<p><strong>ーーAIエージェントの他に、エージェンティックAIという言葉がありますが、この違いは何でしょうか。</strong></p>
<p><strong>宮脇氏</strong>
言葉の定義でいうと、AIエージェントは技術やソフトウェアのような「エージェントそのもの」を表す言葉であると思います。一方で、エージェンティックAIやエージェンティックテクノロジーでいうと、「エージェントの性質をもつもの」を指すと思います。</p>
<p>エージェンティックAIやエージェント型AIの言葉の意味合いは、最近変わり始めていると思っています。昔は「永続的なソフトウェア」というのが、一つの定義としてあ⁨⁩りました。データの流れを監視できるし、ユーザーの目的や好みに合わせてタスクを遂行するものというのが、<a href="https://rosenfeldmedia.com/books/designing-agentive-technology/">昔の解釈</a>だと思っています。
しかし、最近では生成AIブームの流れで意味合いが変わってきたという印象を受けます。エージェントは日本語で言うと“代理者”と訳すことができますが、人の業務を代行するような形で、AIをコアとして代理者の性質を受け継ぐシステムを「<a href="https://arxiv.org/abs/2505.10468">エージェンティックAI</a>」と呼んでいると思います。</p>
<p><strong>ーータスクを遂行するだけであれば、これまではRPAなどでプロセスをオートメートできていました。しかし、人の代替と位置付けると単純作業だけではないと思います。ゴールに向けてタスク分解し、適切な順序で自律的に実行できるという点が、エージェンティックというキーワードに含まれているのでしょうか。</strong></p>
<p><strong>宮脇氏</strong>
そうですね。“人との接点”というのが一つの軸としてあるかと思います。接点が少ないRPAやオートメーション。逆に接点が多いチャットボット型AI、というすみ分けになると思っていて、AIエージェントは、あまり接点はないが自分がやりたいことを委任して自走してくれるものです。ちょうど<a href="https://note.com/dory111111/n/n03eac77e5197">中間に位置するイメージ</a>ですね。</p>
<h2>AIエージェントへの期待と導入課題</h2>
<p><strong>ーー現在、AIエージェントへの期待や注目度は高まっていますが、なぜ、多くの人がAIエージェントに期待を寄せているのでしょうか。</strong></p>
<p><strong>西見氏</strong>
太田さんの説明で、AIエージェントとは環境と相互作用する知能システムであるというお話があったと思いますが、これってよく考えたら「人間なのでは？」という話なんですよ。
例えば、今、リモートワークをしている人が多くいらっしゃいます。パソコンを触ってリモートワークをしている人間って、ビジネスチャットを通じて仕事をしている姿を別の人間から見たとき、「何か言ったら返す」というシステムと類似していますよね。見え方としては人間である必要がなく、タイピングして返してくる“何か”なので、視点を変えるとソフトウェアと言えると思います。
そのような人たちと日常からコミュニケーションをとって一緒に仕事を行い、時には成果物としてPowerPointやWordを出してきたりする。これって「AIエージェント」じゃないか、という話なんです。</p>
<p>ご質問いただいた「何に期待しているか」については、シンプルに『<strong>人間の代替</strong>』です。人間のように動くソフトウェアがあれば、どれほど使っても人間より安かったり、多く働いてくれたり、病気もしないし、労基署へも訴えないというところで、非常に使い勝手がいいですよね。そのように、労働力の代替として認められ始めているのが現在なんです。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Agent_b_5ee7a2de78/AI_Agent_b_5ee7a2de78.png" alt="AI Agent_b.png" /></p>
<p>AIエージェントというソフトウェアがあるとして、これが今後多方面で多く活用されていくという見立てを皆がするんですよ。OpenAIやAnthropicが独占して世界の覇権を取っていこうという動きではなくて、彼らはそのモデルを公開しているんです。AIエージェントを作る部品を提供していて、それを各社が使って動くものを開発していこうと。その渦中に我々がいるのを考えたとき、「キャッチアップしないとまずいのでは」「シンプルに置いていかれてしまう」と思っている人が多いのだと思います。</p>
<p>社員が1万人いる会社があるとして、1万人全員がAIエージェントとインタラクションしたり、AIエージェント自身が長時間働けるようになる未来、1名の従業員が100体のAIエージェントをマネジメントできるとなると、単純に10,000×100になります。そんな体制を他の会社が構築していたら、どれだけのインパクトがあるか。私は経営者なので、各社のいろんな方と対話をするのですが、そういった“危機感”を持つ声が強いという感覚があります。</p>
<p><strong>ーーただ、よく聞く話としては、活用に関するハードルやリスクなどの懸念も各社持っているかと思います。それについてはいかがですか。</strong></p>
<p><strong>後藤氏</strong>
まず、昔とは状況が変わっているというのは一つあります。私たちが相対するのはIT部門やDX推進部なので、お客様側でやりたいというモチベーションがあります。なので「できないことは言わない」というか、以前よりは言わなくなっていると思います。ただその上で、どうしてもセキュリティや企業内で守らなければならないものがあるので、システム導入する上では、それらをすごく意識しています。</p>
<p>現在、AIエージェントの波が来ていますが、その前にはDXの波があって、「オンプレミスでしかデータは扱えない」という方針だったのが変更されて、クラウドに移行しました。また、「機械学習でデータを使って学習しよう」となった時に、「ではそのデータはどこに置いておくのか」というような議論も、これまでに行われてきたわけです。そうした積み重ねがあり、徐々に各社のデータやシステムに関するリテラシーが上がり、導入時のハードルが下がっているような印象を受けています。</p>
<p><strong>ーー今、DXというキーワードがありましたが、AIエージェントに取り掛かる手前で準備しなければならないものはあるのでしょうか。</strong></p>
<p><strong>阿田木氏</strong>
AIエージェントの活用においては、まず、クラウドなどを用いたRAGなどの構築があると思います。RAGは、社内ドキュメントにアクセスするために使う手法として一昨年から昨年にかけて流行していました。RAGのために整備したナレッジがあると思うのですが、現在は、各所で作られたRAGを統合するために、エージェンティックな機能を入れたいというお客様を<a href="https://aitc.dentsusoken.com/column/rag_to_ai_agents/">支援</a>することが多いですね。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_2_03d0121f9e/AI_2_03d0121f9e.png" alt="AIエージェント_2.png" /></p>
<p><strong>ーーエージェントをフルに活用していこうとすると、その手前にRAGはクリアしないのでしょうか。</strong></p>
<p><strong>阿田木氏</strong>
要件によりますが、LLMが持つ知識は一般的なものなので、それを社内で活用していこうと思ったとき、情報を拡張する力としてRAGが一つの手段になると思っています。</p>
<p><strong>西見氏</strong>
“環境”という言葉で言い表せるかと思います。相互作用するものなので、環境上に情報がなかったら参照するものがない。検索システムをエージェントが使えるようにするのがRAGです。GoogleドライブをAIエージェントが見に行って参照できれば別に問題がないですが、どうエージェントが情報にアクセスするのかという話です。</p>
<p><strong>太田氏</strong>
なので、企業の皆さんはいきなり会社の根本となる業務をエージェントで代替しようとするとやはり怖いので、まず業務の中でも端の方のFAQや採用など、会社の大きな損失に関わらないところから始めています。徐々に、業務の根幹部分のデータをエージェントが触れられるよう、段階的に準備していると思います。先の未来には、もしかしたら一部のホワイトカラーの業務が、エージェントに置き換わることがあるかもしれないですね。</p>
<p><strong>ーー現在、コア業務までAIエージェントを活用できている企業は、どのぐらいあるのでしょうか。</strong></p>
<p><strong>太田氏</strong>
多分みんなやられてると思うんです。しかし、この開発を社外に発注するのはデータが非常に機密であるから難しい。おそらく着手されていて、取り組んでる最中だと思うんですが、公開できない情報が非常に多いのだと思います。</p>
<h2>AIエージェントはどのように作るのか</h2>
<p><strong>ーー続いて、AIエージェントをどのように作るか？という点についても、解説いただけますか。</strong></p>
<p><strong>太田氏</strong>
まず、何を代替したいのか、エージェントを開発する対象の業務を考えます。次に、いきなり作り始めるのではなく、その業務が既に存在するDeep Researchや市場調査が得意なエージェントなどで代替できるかを考えます。AIエージェントを人間に例えるのであれば、似たようなスキルを持った人間がいないかを考えるんです。代替したい業務が企業独特の業務であり、世の中に同じスキルを持った人間がいない場合は、自分たちで作るしかないという判断になります。</p>
<p>“作る”と判断したら、LLMのAPIを使わなければならないので、LLMを用意します。その時、利用するLLMが、その業務に関する知識を持っているかどうかを見ます。持っていない場合は、業務を遂行するためのプロセスを可視化し、分解して、利用するデータソースや登録・申請などのアクションポイントを洗い出し、順序通りにLLMがこなせるようにワークフローを構築していきます。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_3_c21acca892/AI_3_c21acca892.png" alt="AIエージェント_3.png" /></p>
<p>プロセスの中にはおそらく、人間の意思決定が伴う箇所がいくつもあると思います。それらすべてをプロンプトで渡し、意思決定を代替してもらう。エージェントが意思決定をしながらアクションも同時に実行していくという手続きを書くというのが、エージェントを作る設計における第一段階です。</p>
<p><strong>ーー宮脇さんは、所属されている企業で採用業務のエージェントを開発されていますよね。どの会社でも汎用的に使えるツールを開発する上で、意識する点や課題などはありましたか。</strong></p>
<p><strong>宮脇氏</strong>
まず意識する点として、プロダクトを開発・提供する企業としての戦略の部分をお話しすると、「この業務を代替したら事業としてうまくいく」というところから始めています。多くのお客様が利用してくれるというのもそうですし、業務の効率化を重視しているのであれば「どれくらい効率化を期待できるのか」という視点を持って開発をしています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Agent_c_24423dbaa4/AI_Agent_c_24423dbaa4.png" alt="AI Agent_c.png" /></p>
<p>我々もAIエージェントを活用しながらプロダクトの開発を進めていますが、エージェントは「切り札にはなりうるがあくまで手札でしかない」と思っていて、一つの“手段”でしかありません。なので、AIエージェントとしてうまくいかなくても、その機能だけは今後も資産として横展開できる部分から開発をしています。</p>
<p>採用業務のAIエージェント開発において、採用業務特有の課題みたいなところでいうと、やはり個人情報を扱う点が挙げられると思います。AIエージェントは、一定うまくできそうな印象は受けますが、「うまくいきそう」と「うまくいく」の間は大きく乖離しています。AIエージェントにはタスクの実行完了までを委任することになるため「成果物には意図しない誤りが含まれない」と確信できるまでの作り込みが、大変な部分になるかなと思ってます。</p>
<p><strong>ーーAIエージェントと相性が良い領域などはあるのでしょうか。</strong></p>
<p><strong>西見氏</strong>
宮脇さんの企業はプロダクトでAIエージェントを出してますが、とても難しいんですよ。
なぜ難しいかっていうと、エージェントって自由に動くんですよね。自由に動かせられるほどパワーが出るのですが、リスクが大きい。それに対して、“ガードレール”と呼ばれるもので、「この範囲で動いてね」という具合にAIを制御するんです。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_4_91aae42ca3/AI_4_91aae42ca3.png" alt="AIエージェント_4.png" /></p>
<p>しかし、安全に使えるように囲い込んで、安全の余白を作れば作るほど、決定論的に決められた通りにしか動かなくなる。それはそれでパワフルではありますが、AIエージェントへの期待とはまた違うわけです。</p>
<p>これをどのようにバランスを取ればよいかというと、多く言われているのがBPO（業務代行）の話です。BPOは古典的な業務代行のことで、人が代行するイメージがありますが、その裏側で何が行われているかという点は、顧客側は頓着しないですよね。結果を出してくれればよいと。その“裏側でどうするか？”というところで、AIエージェントが注目されているんです。顧客に直接AIエージェントを触らせないので、何かをしでかすリスクはないし、考えうるリスクに対しては、ある程度マニュアル等でガードできます。
業務代行を行うための人材採用に力を入れなくてもエージェントを強く配備していけば、ものすごい大量の人を雇ったのと同じ形でビジネスを展開できる。社内の代行として何ができるかの検討も進んでいるし、実際いろんな分野でAIエージェントが動いている姿が見えてきてる印象です。</p>
<p><strong>ーー最近、Agent-to-Agent（<a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/">A2A</a>）のような、エージェント同士が連携する技術も注目されていますが、1つのエージェントがなんでもこなすのではなく、特化型のエージェントが連携してタスクを実行する必要性について、どのような理由があるのでしょうか。</strong></p>
<p><strong>後藤氏</strong>
様々な理由がありますが、<a href="https://www.google.com/url?q=https://blog.langchain.com/context-engineering-for-agents/&amp;sa=D&amp;source=docs&amp;ust=1755655420987616&amp;usg=AOvVaw3teeITIuK3CObqX4SsQmjG">コンテキストが多くなりすぎてしまう</a>というのが一つ挙げられるかと思います。例えば、一人の秘書に色んな業務を依頼すると一個の業務に対する精度が下がってしまいますよね。LLM自体に入れられるトークン数にも限度があるので、一つのエージェントに全て詰め込むのは難しい、という技術面の制約があるかと思います。</p>
<p><strong>阿田木氏</strong>
また、「責任を分ける」という観点もあります。人間の社会も業務においても、「この人はこの業務」などと分けると思いますが、そこを明確に分けることで、管理がうまくいくというのがあります。エージェントも同じで、<a href="https://www.comet.com/site/blog/ai-agent-design/#h-modular-amp-role-based-ai-agent-design">分けて制御してあげる</a>というのが、利用する上で安全であると思います。</p>
<p>加えて、エージェント技術の背景として、シングルエージェントから発展してきたのもあるので、それらを繋げましょうというのが<a href="https://speakerdeck.com/masatoto/llmmarutiezientowofu-kan-suru">現段階</a>になるかと思います。</p>
<p><strong>西見氏</strong>
あとは、<a href="https://blog.langchain.com/react-agent-benchmarking/">ベンチマーク</a>があるんです。一つの仕事を行うエージェントに対して、複数のドメインを与えて、たくさんの仕事に対応できるよう知識を持ってもらうテストを行った例があります。与える知識を0〜10まで試して実験したところ、1つの知識を与えたら目的の仕事をしてくれるが、2つ以上知識を与えると急に仕事の精度が落ちていく。目的はベンディングマシンの仕事なのに、なぜか不動産関連の仕事を始めてしまうというような、混乱しだしたという実験結果もあり、定量で計測してみても、混乱するというのはあるんです。</p>
<p><strong>ーーAIエージェントは人の代替であるからこそ、人との比較がされやすいと思いますが、導入における投資対効果についてはいかがでしょうか。</strong></p>
<p><strong>太田氏</strong>
現在、エージェントの利活用というとドキュメントワークが多いのですが、その業務にかかる時間・工数・人数などは、指標として参考になると思います。それが実際に何時間くらい削れて、かつ品質がどれぐらい安定するのか。人間の場合、人によってクオリティの差が出るので、どのぐらいまで均一な品質でアウトプットできるか、というのがまずあります。実際の運用を考えたときに、投資対効果があるのかどうかは数値で表せると思います。</p>
<p><strong>ーー今後の方向性として、会社でひとつのエージェントを持つイメージなのか、従業員が自分のタスクの生産性を上げる目的で、100や1,000など様々なエージェントを使いこなしていくのか、どちらのイメージが近いでしょうか。</strong></p>
<p><strong>太田氏</strong>
おそらく、世の中で目指したいのは一体のエージェントが多数の仕事をこなす世界だと思います。しかし、提供する側からすると一体のエージェントが複数の仕事をこなせているかを常に監視したり、評価するのは、運用が複雑になってしまいます。そのため、見せ方としては「業務用エージェントがあなたの仕事こなします」と言いつつ、裏で複数エージェントが動くことになると思います。それで各業務において、タスクごとにエージェントをモニタリングするという形に落ち着くかと思います。</p>
<p>この一年は恐らく各従業員ごとであったり、提案するんだったら“提案用のエージェント”や市場調査する場合は“市場調査用のエージェント”など、各タスクごとに異なるエージェントを選択して使う形で、利活用が進むと思います。それは扱う参照データや考え方などの“環境”が違うので、目標というタスク定義で使う対象を分けるためです。
このように、タスクの定義は、初めは従業員単位になるかと思いますが、次第に“資料作成”であればなんとか動かせるところまで抽象度は上がっていく、つまりは会社共有のエージェントになると考えられます。その場合、全データのアクセスが前提となるため、会社側もデータを整備する必要が出てきます。これまでの提案履歴や取引記録を全て接続して、提案先にカスタマイズされた提案書を作成できるのが、将来的なイメージ図になるということですね。</p>
<h2>AIエージェントとこれからの未来</h2>
<p><strong>ーーAIエージェントをキーワードに、どのように未来が変わっていくのか、お一人ずつコメントをいただけますか。</strong></p>
<p><strong>阿田木氏</strong>
これからのエージェントの世界でいうと大きく二分されていくかと思っていて、一つはエージェントと人間が「相互にやり取りする世界」、もう一つは「エージェントに閉じた世界」と考えています。先ほど西見さんからBPOの話がありましたが、AIエージェント開発をしてて思うのは、ボトルネックは人間だということです。なぜかというと、それぞれのアクションは人間が持っている暗黙知に依存することがとても多く、企業においては特にそれが顕著であるからです。人間が介在すると、なかなか前に進まないことがあるので、そこをAIだけの世界にすると、上手くいくのではないかと思っているところです。
しかし、人間が存在する限り人が持つ正解もあるので、人間とAIエージェントが相互にやり取りする世界は存在し続けると考えています。</p>
<p>個人的に“こうあってほしい”という未来についてですが、現在、データ分析でもAIエージェントが使われてて、私はKaggleなどをよくやるのですが、<a href="https://aitc.dentsusoken.com/column/kaggle-ai-agent-01/">Kaggleでもコーディングエージェントが使われている</a>んです。全て使ったことあるのですが、やっていて思ったのが、エージェントに作業を全部渡すと楽しさが奪われてしまうということですね。私は、Kaggleをゲーム感覚でやっているので、ゲームを代わりにやられてしまうのが結構辛い。エージェントには、本当に任せるべきところを任せ、人間も楽しいとこにコミットできるといいなと思っています。</p>
<p><strong>後藤氏</strong>
これまでの話しでもあったように、先を読むのは非常に難しくなっていると思います。インタビューの中で思い出したのですが、この書籍を書き始めたときは、そもそもお客さんに「エージェント」と言ってもわかってもらえないことがありました。それが今の状況になっているので、短期間ですごく変わったと思っています。
そのような中で、ある程度直線状にある未来像でいうと、業務のやり方が変わってくるのかなと思います。まずは人の触る部分をAIエージェントが代替していく。その後にAIエージェントのためのデータ設計だったり、業務のやり方も徐々に変わっていくのかなと思っています。これまで人間だけだと難しかったことや、管理されたもののイメージを作るなど、AIエージェント前提の仕組み作りが進んでいくのかなと思います。</p>
<p><strong>ーーAIエージェントがAIエージェントを作るみたいなものはあるのでしょうか。</strong></p>
<p><strong>後藤氏</strong>
研究分野ではそういう取り組みもあります。ただ個人的には直近の話ではないと思っています。データや環境の整備といったDX、すなわちこれまで人間しかアクセスしてなかったものや、業務に詳しい人に聞かないと分からなかったところがAIエージェントに聞いても分かる、AIエージェントが探せる、そういった整備が先んじて進んでいくと思っています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Agent_d_c24a2a4250/AI_Agent_d_c24a2a4250.png" alt="AI Agent_d.png" /></p>
<p><strong>西見氏</strong>
インフラが整っている領域は基本的にエージェントが入り込んでいく領域だと考えていいと思います。インフラとは、大きく分けてデジタルとフィジカルですね。特にデジタルはエージェントが入り込みやすい。センシティブなデータやデータ管理に関しては様々な問題があるにせよ、基本的にはアクセスができるわけです。
インフラが整っているもの、その中で現在活発なのが自動運転ですね。なぜ自動運転が活発かというと、道路が敷かれてるからです。走れるインフラがあるんです。なので、インフラがあるところからエージェントがどんどん活用されていくと考えています。</p>
<p>デジタル領域において、なぜこんなにAIエージェントが活用されているかというと、“インターネット”というインフラがあるので、インパクトも出るからですね。僕はこの畑に入りすぎて人間しかできないことはないんじゃないかとか思っちゃうんですけど（笑）農業などもデジタル化できないと言われつつも、今では、大規模農業は結構機械化が進んでいます。ドローンで生育状況を把握し、トラクターも自動運転で動かすことができるので、ある意味代替できている。それもインフラですね。ドローンで監視ができ、農作業の機械があり、自動運転ができればうまくいく業務があるということです。</p>
<p><strong>ーー統一規格みたいな存在も結構大きいですよね。</strong></p>
<p><strong>西見氏</strong>
インターネットはhttp通信させれば情報取れるので、そのようなプロトコルがある時点でインフラは整っているわけです。倉庫などでも、パレットで積んであれば動かせる話と、荷物の規格が異なると動かせないというようなイメージですね。
船での運搬も、コンテナという規格が生まれたからこそ、高速に行えるようになった経緯があります。人間は、人が働きやすくするためのインフラを作ってきた歴史がある。そのようなインフラを土台にしてエージェントは動いていくので、人間にはできなかったような長時間労働も可能ですし、コンピュータシステムなので、スケーリングによって作業量も増やせるという期待があります。その期待に応えられるように拡張しているのが、現在見えてる姿なんです。</p>
<p>AIモデルもどんどん進化しているので、この相互作用によってどこまでできるかっていうのは、まだわからない。インフラがあるところにAIエージェントは浸透するので、今はそのインフラ自体を作っていくというフェーズですね。</p>
<p><strong>ーー続いて宮脇さん、いかがですか。</strong></p>
<p><strong>宮脇氏</strong>
AIエージェントは、成果創出を図るという部分において圧倒的に長けているかなと思っています。従来のMLシステムだと、OCRや翻訳みたいな一部の業務だけを代替するものでしたが、AIエージェントという枠組みにおいては、他の業務と繋がりやすくなったっていうところで、圧倒的に成果創出に向くようになったと思います。</p>
<p>AIエージェントの良い部分は「質・量・スピード」それぞれにあります。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_5_27b5f52295/AI_5_27b5f52295.png" alt="AIエージェント_5.png" /></p>
<p>例えば採用領域でいうと『摩擦』と『スピード』の2つの側面でメリットがあると考えられます。</p>
<p>『摩擦』については、特定の判断においてAIが考慮できる項目が増えたということです。例えば<a href="https://www.theladders.com/static/images/basicSite/pdfs/TheLadders-EyeTracking-StudyC2.pdf">LADDERS社の報告</a>では、採用担当者が書類選考にかける時間は60秒以内といわれていて、採用担当者がチェックできる観点は限定的だといえます。候補者にとってもあまり嬉しくないですよね。一方AIによる読み込みの場合、レジュメ全てを読んだ上で総合的に判断することが多いため、これまで採用担当が読み飛ばしていた色んな職能や経験を考慮できるようになったといえます。
『スピード』でいうと、LLMの文章生成が速いことだったり、24時間365日体制が築けるようになったことで、候補者が応募してきた際にすぐ反応できるようなフローが組める。極端にいうと、応募があったその日のうちに面談ができるような、そういう世界がくるかなと思っています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_6_8ae9b5f6f7/AI_6_8ae9b5f6f7.png" alt="AIエージェント_6.png" /></p>
<p><strong>ーー現時点で、質の部分も人より高水準であると言えてしまうのでしょうか。</strong></p>
<p><strong>宮脇氏</strong>
そうですね。AIが参照できるガイドラインがあれば、一定の品質が担保された状態で価値創造できると思います。</p>
<p>今の話はこの先5～10年の話なのですが、40年後の日本をみると、労働人口が40%減るというような予測もあるので、必ず労働力の代替としての期待がある。エージェントの『代行』と『協働』の2つの期待が高まっていると思います。</p>
<p><strong>ーーAIエージェントのこれまでの歴史がある中で、現在思ったより早く実用化できたということなのでしょうか。</strong></p>
<p><strong>太田氏</strong>
コーディングは思った以上に早く進んでる印象はあります。加速できる枠組みができたんですよね。先ほど、人が介在すると遅くなるという話があったんですけども、コーディングの作業は基本的にテストがあり、正解か不正解かがわかると。エージェントが自分で計画して行動して、うまくいったかどうかがテストでわかり、そのデータが蓄積されるという、人が介在せずに自動的に賢くなっていく、自己完結できるレールに乗っかったんですよね。
そうなると、AIの知能は人間を追い越すので、同じように人間の業務の中でも自己完結できるものがあれば、すごい速度でどんどん成長していくと思います。</p>
<p>それが報告されたのがここ1～2年で、大きなインパクトがあったので、自己完結できる環境を皆が探している状況かと思います。</p>
<p><strong>西見氏</strong>
ロボティクスの分野でも世界モデルというものがあって、「こういうふうに行動が起きた場合にこういうふうに返す」というように、光景の動画を生成器というモデルが生成し、それをもとに学習するサイクルが回っています。世界モデルは正解・不正解がわかるので、自己完結する。複数モデルで組み合わせてRL（強化学習）を回していくっていうのは、十分あります。</p>
<p><strong>ーー最後に太田さん、お願いします。</strong></p>
<p><strong>大田氏</strong>
究極的にいうと、皆が“人間”に興味が出てきて、一日のほとんどを様々な人と会話をしているような、そんな働き方になるかなと思ってます。問題を定義したり、手を動かす部分は徐々にエージェントの方が良くなるので、人の気持ちを考えたり、こういうアイデアはどうだろうかと考えたりする作業が増えるのではないかと思います。まだLLMや生成AIは、想像力であったり、点と点を結び合わせて新しい何かを創造するという点は弱いので、それが伸びてこない間は、人間が色んな人と話をして、今までの経験から新しいアイデアを出し、それらをエージェントを使ってシミュレーションしたり、実際に作らせてみたりなど、そういう世界観になると思ってます。</p>
<p>今までの話をまとめになりますが、まず、個人で様々な業務をこなすと属人化するという課題があります。これまで、属人化したくないからシステムを作ってきたわけなんですよね。銀行を例にすると、様々な町ごとに店舗を構えて、お客さんが来たら対応していましたが、その業務がATMへ置き換わりました。ATMによって自動化されましたが、もともとその業務を担っていた人たちは失業したわけではなく、別のお客さんにライフプランを考えるなどの業務へ変わっていったと思います。なので、AIエージェントが出てきたからと言って、仕事がなくなるわけではなく、違う何かに価値を見出すように変わってきている。我々が開発しているエージェントも、今までシステム化されてなかったところをシステム化しようとしているだけなんです。その時、我々人間の仕事は何かというと、新しいアイディアを考えることであったり、様々な人とコミュニケーションをとって、もっと面白いインパクトがある事業を作り出すなど、そういう方向に進んでいくと思っています。もちろん動いているシステムを監視する人は必要なのですが、より短いサイクルで面白いものが出てくる未来があるのではないかなと思います。</p>
<p>先ほど話題に上がったA2Aについて言うのであれば、事業や企業ごとに作られたエージェント同士がもっと情報をやり取りすることによって、新しいサービスの開発はどんどん加速する。事業や企業ごとにデータをきちんと連携しているからこそできる技だと思うので、面白いビジネスが1週間や1ヶ月などの短いスパンででポンポン出てきて、コンテンツや、よくわからない体験も含めていろいろ生まれてくるような、“創造の社会”もあるんじゃないかなと思います。</p>
<p>様々なシステムがもっと連携されやすくなれば、例えば交通関係と周辺の百貨店が連携するなど、街全体を繋げられるようになったり、一歩ずつシームレスな形で社会が形成されていく期待もあると思います。</p>
<p><strong>ーー人間同士のコミュニケーションがより大事になってくる一方で、すべてAIで良いのでは？という極論もあるかと思いますが、それについてはいかがですか。</strong></p>
<p><strong>後藤氏</strong>
先ほど、コーディングエージェントがすごいという話がありましたが、実際にタスクを振れば色々やってくれるんですけど、でもそのタスク（目標）は定義しなければなりません。</p>
<p>そのタスクは何から取ってくるかというと、太田さんが仰ったように、「そもそも自分たち何やりたいんだっけ」や「こういう機能追加したいです」などの人間の要望から生まれてきます。下流のタスクを実行してくれる部隊（AIエージェント）が増えて、速度も上がった分、上流で意思決定しなければならない。高速に回り始めているのが、現実としてあります。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Agent_book2_778c3f1eb1/AI_Agent_book2_778c3f1eb1.jpg" alt="AI Agent_book2.jpg" /></p>
]]></description>
      <pubDate>Mon, 25 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/8/24 [SUN]理研、「富岳」後継機の開発にNVIDIA参画──AIとシミュレーション融合の次世代スーパーコンピューター</title>
      <link>https://ledge.ai/articles/fugaku_next_nvidia_ai_supercomputer</link>
      <description><![CDATA[<p>理化学研究所は2025年8月22日、スーパーコンピューター「富岳」の後継機「富岳NEXT」の開発に、米半導体大手NVIDIAが参画すると<a href="https://www.riken.jp/pr/news/2025/20250822_1/index.html">発表</a>した。富士通と理研に加え、初めて国外の半導体企業が中心的役割を担う体制となる。AIとシミュレーションの統合を進め、2030年頃の稼働を目指す。</p>
<p><strong>富岳NEXTによる応用事例イメージ。左は地殻変動解析、右は都市部における地震動解析</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250822_1_fig2_84c4231aa9/20250822_1_fig2_84c4231aa9.jpg" alt="20250822_1_fig2.jpg" /></p>
<p>2020年に稼働を開始した「富岳」は、世界トップクラスの性能を誇る日本のフラッグシップスーパーコンピューターであり、気候変動予測や創薬、材料科学など幅広い分野で活用されてきた。その後継機として位置づけられる「富岳NEXT」は、文部科学省の国家プロジェクトとして開発が進められている。</p>
<h2>新体制の発表</h2>
<p>理化学研究所、富士通、NVIDIAの3者による国際的な開発体制が始動した。NVIDIAがGPU基盤の設計を主導し、富士通は新CPU「FUJITSU-MONAKA-X」を開発。両者は超高帯域で接続され、理研が全体統括を担う。国外の半導体大手が日本の旗艦スパコン開発に参画するのは初めてとなる。</p>
<h2>性能目標と特徴</h2>
<p>「富岳NEXT」はFP8精度で600エクサFLOPSを超える計算性能を見込み、現行「富岳」と比べ最大100倍のアプリケーション性能向上を目指す。AIと数値シミュレーションを統合する「AI-HPCプラットフォーム」として設計され、医薬品開発、気候変動解析、新素材設計などの研究を加速させる狙いがある。補足報道によれば、ノードあたり4基のGPUを搭載し、合計13,600基規模で構成される案も浮上している。</p>
<h2>導入とスケジュール</h2>
<p>2025年度中に基本設計を完了し、2026年度には詳細設計に移行。2027年頃には新CPU「MONAKA-X」が登場し、2030年頃の稼働開始を想定している。設置場所は現行の「富岳」と同じく、神戸市ポートアイランド内に整備される予定だという。</p>
<h2>国際的意義</h2>
<p>今回の発表は、日本のスーパーコンピューターがAIとシミュレーションの融合を本格化させる転換点といえる。ロイターや共同通信も報じているように、米中欧が進める次世代スパコン競争のなか、日本は「Zetta-scale」への挑戦を打ち出し、国際競争力を維持・強化する姿勢を明確にした。</p>
<p><strong>自動車分野での活用例。生成AIを用いた設計最適化により、自動車設計の期間短縮や性能向上が期待される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250822_1_fig3_7f1a064923/20250822_1_fig3_7f1a064923.jpg" alt="20250822_1_fig3.jpg" /></p>
]]></description>
      <pubDate>Sun, 24 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/8/23 [SAT]ByteDance、AI推論モデル「Seed-Prover」を数学オリンピックの結果とともに発表──公式には銀メダル相当、実際はGoogle、OpenAIに続き金メダル水準の成果</title>
      <link>https://ledge.ai/articles/ai_math_olympiad_seed_prover</link>
      <description><![CDATA[<p>中国ByteDanceの研究チームは2025年7月23日、AI推論モデル「Seed-Prover」を<a href="https://seed.bytedance.com/en/blog/bytedance-seed-prover-achieves-silver-medal-score-in-imo-2025">公開</a>した。同社公式ブログでは「Silver Medal Score（銀メダル相当）」と表現されたが、Seed-Proverが記録した30点は、2025年の国際数学オリンピック（IMO）における金メダルカットラインに到達するものであり、実質的に金メダル水準の成果といえる。詳細をまとめた論文は7月31日にarXivで<a href="https://arxiv.org/abs/2507.23726">公開</a>された。</p>
<p>Seed-Proverは、定理証明器「Lean」を基盤に構築された形式証明型AIモデルである。補題（レマ）のプールを生成・活用しながら段階的に証明を組み立て、各ステップを機械可読な形式で検証する仕組みにより、証明の厳密性を担保できる。論文では、過去IMOの形式化問題で78.1％の成功率を記録し、さらにMiniF2FやPutnamBenchといったベンチマークでも最新水準の成績を達成したことが示されている。</p>
<p><strong>MiniF2F-Testでの性能推移。Seed-Proverは2025年時点で最高水準の通過率を記録している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Mini_F2_F_d1294f309f/Mini_F2_F_d1294f309f.jpg" alt="MiniF2F.jpg" /></p>
<p>ByteDanceはSeed-Proverを「Silver Medal Score」と発表したが、実際には自動定理証明システムに位置づけられるものであり、LLMを活用して形式証明を構築する新しいタイプのアプローチである。従来の完全自動型とは異なり、大規模言語モデルによる柔軟な探索と、定理証明器による厳密な検証を組み合わせる点に特色がある。</p>
<p><strong>Seed-Proverの各種ベンチマーク成績（左）と従来モデル（右）の比較。IMO 2025、MiniF2F、PutnamBenchなどで従来を大幅に上回った</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4og2ymdfewdkk_0259ab7f69/4og2ymdfewdkk_0259ab7f69.jpeg" alt="4og2ymdfewdkk.jpeg" /></p>
<h2>金メダル水準の成果、それぞれのアプローチ</h2>
<p>2025年のIMOをめぐっては、GoogleやOpenAIも金メダル水準の成果を発表している。それぞれのアプローチには違いがある。</p>
<ul>
<li><strong>Google DeepMind（Gemini Deep Think）</strong> ：6問中5問を解答し、公式採点で35点を獲得。自然言語のみで証明を構築し、短時間で人間と同じ条件下で金メダル水準を達成した。</li>
<li><strong>OpenAI（実験モデル）</strong> ：同じく6問中5問を解き35点と発表。元IMOメダリストによる採点で妥当性が確認されたが、公式認定はない。自然言語ベースで幅広い問題に対応できる点を強みとする。</li>
<li><strong>ByteDance Seed-Prover</strong> ：公式ブログでは「Silver Medal Score」とされたが、30点は金メダルのカットラインに到達。Lean上で形式的に証明を構築し、機械検証可能な厳密な証明を生成する。大会3日間を通じて探索を行う方式で、時間は要するが厳密性を優先した設計だ。</li>
</ul>
<h2>今後の展望</h2>
<p>Seed-Proverは、自然言語で証明を生成する従来型モデルとは異なり、定理証明器によって機械的に検証可能な形式証明を構築する点に特徴がある。論文では、この厳密な証明構築は数学研究の支援や形式検証（formal verification）といった分野に応用できる可能性があると記されている。</p>
]]></description>
      <pubDate>Sat, 23 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>竹中工務店、建築設計AI「Tektome KnowledgeBuilder」を導入──設計業務の生産性向上と働き方改革を推進</title>
      <link>https://ledge.ai/articles/takenaka_koumuten_ai_design_solution</link>
      <description><![CDATA[<p>建築大手の竹中工務店は2025年8月18日、AIを活用した建築設計支援ソリューション「Tektome KnowledgeBuilder」を導入したことを<a href="https://prtimes.jp/main/html/rd/p/000000008.000136954.html">発表</a>した。開発元のテクトムが8月18日に発表したもので、設計業務における生産性向上や働き方改革を加速させる狙いがあるという。</p>
<p>「Tektome KnowledgeBuilder」は、建築設計業務で発生する膨大な図面や関連情報をAIで構造化し、検索・参照を容易にするソリューションである。これにより、従来は属人的に扱われていた設計ナレッジを効率的に活用できる環境を整え、設計プロセスの高度化と効率化を実現する。</p>
<p>竹中工務店では導入に先立ち、社内ワーキンググループによる約3カ月間の実証実験を実施。実務に即した利用環境の整備を進めた結果、設計者が過去の事例を効果的に参照し、業務負担を軽減できることが確認されたという。</p>
<p>テクトムは今回の取り組みについて、「設計DXの推進を通じ、建築業界全体の生産性革新や働き方改革に貢献していく」としている。今後は竹中工務店での活用事例をもとに、他の建築事業者への展開も視野に入れている。</p>
]]></description>
      <pubDate>Fri, 22 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>オンデーズ、生成AIが“かけたまま試着”を実現　新提案サービス「OWNDAYS MIRROR」を展開</title>
      <link>https://ledge.ai/articles/owndays_mirror_ai_try_on_without_removing_glasses</link>
      <description><![CDATA[<p>メガネ・サングラスの製造販売を手掛けるオンデーズ（東京都品川区）は2025年8月19日、生成AIを活用した新サービス「OWNDAYS MIRROR（オンデーズ ミラー）」を<a href="https://www.owndays.com/jp/ja/information/822">発表</a>した。</p>
<p>AIが顔立ちや雰囲気を分析し、メガネをかけたままでも試着できる体験を提供するのが特徴だ。</p>
<h2>生成AIによる“かけたまま試着”とレコメンド</h2>
<p>OWNDAYS MIRRORでは、カメラに映した顔画像をもとに生成AIが最適なフレームを提案。現在かけているメガネを画像上で仮想的に外し、新しいフレームをリアルタイムで合成表示することで、視力が弱いユーザーでも違和感なく比較検討できる。</p>
<p><strong>AIが候補フレームを提示し、装着イメージを“かけたまま”で確認可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo03_2_91fec602d9/photo03_2_91fec602d9.jpg" alt="photo03-2.jpg" /></p>
<h2>“なりたい印象”を8タイプから選択</h2>
<p>ユーザーは「カジュアル」「フォーマル」「クール」「ソフト」「シンプル」「グラマラス」「モダン」「クラシック」の8種類の印象から“なりたい印象”を選択。AIが選択に応じて似合い度や印象コメントを提示し、候補フレームを絞り込む。</p>
<p><strong>“なりたい印象”を選ぶ画面。8タイプから選ぶとAIが候補を最適化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo03_1_c103e87778/photo03_1_c103e87778.jpg" alt="photo03-1.jpg" /></p>
<p>気に入ったフレームはそのまま店頭在庫を確認でき、実物の試着・購入に進める。価格や在庫数、同系統の別カラーなども画面上で確認できる。</p>
<p><strong>候補フレームの詳細画面。価格・在庫・カラーバリエーションも同時に確認</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/photo01_1d02f996d4/photo01_1d02f996d4.jpg" alt="photo01.jpg" /></p>
<h2>店舗導入とスケジュール</h2>
<p>新サービスは8月20日にオープンする「OWNDAYS天王洲アイル店」をはじめ、全国11店舗に導入される。2026年3月末までに国内全店舗、さらに海外店舗にも順次展開する予定だ。</p>
<p>天王洲アイル店はDX推進モデル店舗に位置づけられており、リモート視力測定やRFIDを活用した商品管理、キャッシュレスセルフレジなどの最新設備を導入。OWNDAYS MIRRORはその目玉機能として位置づけられている。</p>
<h2>今後の展開</h2>
<p>同社によると「似合うメガネがわからない」「基準がない」「視力の悪さで印象が掴めない」といった顧客の声がサービス開発のきっかけになったという。混雑時でも自分のペースで納得して選べる新しい顧客体験を提供し、スタッフの負担軽減にもつなげたい考えだ。</p>
<p>オンデーズは今後もテクノロジーと人の接客を融合させ、顧客体験の進化を進めていく方針を示している。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Yahoo!ショッピング、2025年上半期の安全・安心レポート公開──AIで不正検知率3倍、レビュー45万件を削除</title>
      <link>https://ledge.ai/articles/yahoo_shopping_ai_safety_report_2025h1</link>
      <description><![CDATA[<p>LINEヤフーは2025年8月19日、ECモール「Yahoo!ショッピング」における2025年上半期（1月～6月）の安全・安心に関する取り組みをまとめたレポートを<a href="https://www.lycorp.co.jp/ja/news/release/018424/">公開</a>した。</p>
<p>出店審査の厳格化やAIによる不正対策の強化により、不適切ストアや商品の排除、不正レビューや不正決済の防止に成果があったと発表している。</p>
<h2>出店審査とストア監視</h2>
<p>Yahoo!ショッピングでは、利用者が安心して買い物できる環境を提供するため、ストアの出店審査を強化。2025年上半期の出店審査合格率は4.2%にとどまり、不適切なストアの参入を抑制した。不適切と判断されたストアは約1,000件削除されている。</p>
<p><strong>■ 出店審査合格率の推移。2025年上半期は4.2%まで低下し、不適切ストアの参入を抑制</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f31faf25870eeacbf570af249f3d33c1688cadd8_c62eac64bd/f31faf25870eeacbf570af249f3d33c1688cadd8_c62eac64bd.jpeg" alt="f31faf25870eeacbf570af249f3d33c1688cadd8.jpeg" /></p>
<h2>商品・レビューの監視体制</h2>
<p>同期間中に不適切商品を約38万件削除。不正や不適切と判断されたレビューは約45万件にのぼり、消費者の購買判断を歪める要因を排除した。</p>
<p><strong>■ 「2025年上半期に削除されたやらせレビューは45万件超。ストア単位での自動削除も開始</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/aa6a163c1af78b5868b370ad7b69314db2f52390_f1e6995c39/aa6a163c1af78b5868b370ad7b69314db2f52390_f1e6995c39.jpeg" alt="aa6a163c1af78b5868b370ad7b69314db2f52390.jpeg" /></p>
<h2>不正決済対策とAI活用</h2>
<p><strong>■ 不正決済対策では、独自システム・EMV3Dセキュア・人的監視の3段階フローを導入。2025年上半期の被害額は前年同期比41.2％減</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/line_yahoo_41_2_039d7dd883/line_yahoo_41_2_039d7dd883.jpg" alt="line yahoo 41-2.jpg" /></p>
<p>不正決済による被害額は前年同期比で41.2%減少。AIを活用した新しい不正検知モデルの導入により、従来比で不正検知率を3倍に引き上げる成果があった。レビューや商品情報の解析にAIを導入することで、不正の早期発見と対応が可能になったという。</p>
<p><strong>■ 2025年4月からAIによる違反商品のパトロールを開始。従来の手法に比べ違反検知率は3倍以上に向上</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f1a6e505568260cf65ca26223b68360198b2a025_09d467b85e/f1a6e505568260cf65ca26223b68360198b2a025_09d467b85e.jpeg" alt="f1a6e505568260cf65ca26223b68360198b2a025.jpeg" /></p>
<h2>今後の取り組み</h2>
<p>同社は、出店審査・監視体制のさらなる高度化に加え、不正検知AIの強化や利用者への情報開示の拡充を進める方針を示した。同社は「より安全で快適な買い物環境を提供する」としており、継続的に安全対策を強化していく。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>参加者をオープンにし、オープンデータを活用するとどんなソリューションが生まれるか？　人工衛星データで犯罪防止に挑む｜富士通 DDM Award 2024 受賞者インタビュー</title>
      <link>https://ledge.ai/articles/fujitsu-ddm-award-2024</link>
      <description><![CDATA[<p>富士通株式会社が主催し、2024年11月から2025年3月まで開催されたデータ利活用コンペティション「DDM Award 2024」で優秀賞を獲得したチーム ミギアシ。
本稿では、同チームのメンバーにアワードの模様や受賞アイデア、データ活用のアプローチなどについて幅広くインタビューした。富士通が掲げる「データドリブン経営」への取り組みと、その最前線について、ぜひご覧いただきたい。</p>
<h2>チームミギアシ メンバー</h2>
<h2>「DDM Award」</h2>
<p>DDM Award（Data Driven Management Award）は、富士通がデータドリブン経営への変革を推し進めることを目的に立ち上げた施策だ。職種／組織／既存の知識や技能といった壁を超え、富士通全社のデータドリブン経営(DDM)の推進を自分事として捉え、行動を起こした個人・組織・活動を表出し称賛し合う全社イベントとしてこれまで開催されてきた。</p>
<p>前回開催の2024年には、「DDM Award」のデータ分析コンペ部門が、富士通本店が所在する川崎市と初めて連携し、社外からも参加者を募るオープン形式で実施された。川崎市の市制100周年に合わせ、テーマは「川崎市さん気づいてました？市の魅力アップにつながる因子･インサイトを見つけ出せ！」。市のイメージ向上につながる施策を競うコンペとなった。決勝のプレゼンテーションには、70を超えるエントリーチームの中から、Dynamic：大胆な挑戦、Diverse：多様なアプローチ、Discover：新たな発見、の3つの観点で4チームが選ばれた。その中で、チームミギアシは人工衛星データを活用し、治安改善という公共性の高いテーマに挑戦した点が高く評価された。</p>
<p>チームは通常業務の合間を縫ってコンペ作業に取り組む必要があったため、円滑な進行を目指して役割分担を行った。全体の進行管理と分析の中心を担ったのは大林氏。初期段階の企画や設計に征矢氏が加わり、そして分析に精通する鄭氏が、分析に関する相談役としてサポートを行ったという。</p>
<h2>「犯罪防止」に焦点をあてた背景</h2>
<p>チーム ミギアシが犯罪防止に着目したのは、自治体の魅力を住民や市外の人間が判断する要素の一つとして、「治安」が重要だと考えたからである。「実は、川崎市の場合、人口に対する犯罪件数は全国的に見て特別高いわけではないんです」と征矢氏。人口に対する比率は少ないものの、件数のみを見ると少ないとはいえず、社内ヒアリングでも「治安」に関する声が複数寄せられたそう。こうした状況から「改善の余地があるのではないか」との認識に至り、犯罪防止につながるアプローチを検討することとなった。</p>
<h2>人工衛星データを活用した分析アプローチ</h2>
<p>犯罪防止の対策を検討するにあたり、川崎市でどの種類の犯罪が、どのエリアで多発しているのかを把握する必要があった。そこで同チームは、現状分析の手段として【地図データ】を基盤に、Googleが提供する【夜間光データ】、国が公開する【国勢データ】、そして警視庁が公開する【都内犯罪データ】を組み合わせ、状況を多角的に探ることにした。</p>
<p>プロジェクトの中核を担うのが、人工衛星によって取得される夜間光データだ。夜間光データは街灯や看板、交通量による明るさを定量的に把握でき、また、衛星観測により広範囲かつ高頻度で収集されるデータである。この【夜間光データ】と【犯罪データ】の組み合わせは、都市計画や防犯研究においても犯罪発生との密接な関連性が指摘されている。たとえば、夜間に街灯が少なく暗いエリアは犯罪の温床になりやすく、人通りが少ない時間帯は犯行のリスクが高まる傾向がある、などと言われている。
大林氏はオープンデータの技術的な課題と工夫について、以下のように説明した。
「公開されているオープンデータは、データごとに独自のフォーマットで整理されているため、これをどう統一し、並列で分析するかが大きな壁でした。実際、夜間光データは500メートル四方のデータのみ取得できず、詳細のエリアまで把握できない仕様になっているため、エリアを切り取って地図データと突合し、どのエリアでどのぐらいの光量があるのか、詳細を把握できるようにデータを加工しなければなりませんでした」</p>
<p>また、犯罪データについては、川崎市や神奈川県警が公開する情報に、本プロジェクトで活用できる十分な詳細データが存在しなかった。そこで、近隣の東京都のデータをもとに類推し、分析に取り入れることにした。具体的には、まず都内全自治体の基本データ（人口・面積など）と夜間光強度データを用いて、各自治体を分類（クラスタリング）するモデルを構築。このモデルから川崎市の各区がどのグループに属するかを推定した。そして分類された自治体グループ毎に、夜間光データと犯罪データの相関を分析し、犯罪種別（30種）ごとに発生件数と夜間光強度との傾向を抽出した。</p>
<p>分析の結果、グループごとに夜間光強度と犯罪種別ごとの発生件数の関係が異なる事を確認し、あるエリアにおいては明るいと発生件数が少なくなる犯罪種別があることを特定した。このことから、各エリアの傾向に応じた街灯の新設や配置見直しといった犯罪防止施策の検討が重要であることを提案した。
なお、今回の分析はオープンデータのみを用いたものであったため、プレゼン内では「今後、市政に活用する際は、より詳細なデータを取得し、エリアや犯罪種別を絞り込むことで、さらに効果的な犯罪防止策が期待できる」と、さらなる分析の必要性を示した。</p>
<p>今回のコンペで、川崎市からは「街灯という本市で対応できる具体的な解決策を得たことは大きな収穫です」といった前向きなコメントも寄せられたという。もちろん、今回のようなデータ分析から見えた仮説を実社会へ反映させた上で、実装後に犯罪件数がどの程度変化したかを定点観測することが非常に重要である。しかし、まずは第一段階として、川崎市のまちづくりに役立つ、新たな気づきを与えられたといえるだろう。</p>
<h2>参加意義と波及効果</h2>
<p>このコンペ参加を振り返り、大林氏は次のように語った。
「オープンデータを実際に利用してみて、国や公共機関が公開している資料については、データ項目の統一化が望ましいと強く感じました。たとえば、同じ市町村区でも丁目や番地などの区切りがバラバラになっているため、統一ルールを設けることで、さらにデータ活用が進むと実感しました」
一方で、オープンデータから得られる情報の幅広さにも驚いたという。ビジネス視点で考えると、PoCを回す前の企画・計画段階においても、オープンデータで初期検証が可能であるという手応えを得られたそうだ。</p>
<p>また、通常業務への影響について聞いてみると大林氏は「自身の役割範囲をさらに拡大できた」と話してくれた。大林氏は通常業務で、病院向けのソリューション開発プロジェクトの企画部分に携わっているが、これまではビジネス寄りの視点から企画・設計を行っていた。しかし、今回の取り組みを経てデータサイエンティスト的な視点を養ったことで、医療データ利活用の推進において直面するデータの標準化や構造化といった課題を、より明確に捉えながら業務を進められるようになったという。</p>
<p>コンペティション終了後、チームミギアシは、2025年7月30日から8月1日に開催された第2回 SPEXA -【国際】宇宙ビジネス展の富士通ブースで、同プロジェクトの成果を展示した。イベント出展のきっかけは、DDM Award 2024の結果を同社の宇宙ビジネス推進室の社員が目にしたことだった。「夜間光×犯罪」というテーマが、声をかけてくれた社員の実務テーマと合致していたことから、今回のイベントブース内での展示につながったという。イベント参加を振り返り、征矢氏は「宇宙データの利活用という切り口で社内の様々なテーマが進行する中、今回の犯罪防止に関する分析結果発表は、一つの具体的な道筋として、データ活用の参考になったと思います」と語ってくれた。</p>
<h2>おわりに</h2>
<p>DDM Awardへの参加は、チームメンバーにとって日常業務を超えた挑戦だった。部門を横断した連携が生まれ、分析手法や可視化技術の共有も促進された。鄭氏は「経営陣が目指すオペレーショナルエクセレンスやデータドリブンマネジメントの実現に向けて、このようなイベントが起点となり、人や組織の文化を醸成する動きは非常に重要だと思います」と述べ、組織文化を創り上げていく取り組みと、システム面で業務効率や品質を高める取り組みを両輪で進めることが、同社の目指す“持続的な企業価値向上を実現する未来予測型経営”にもつながると強調した。</p>
<p>DDM Awardは今後の開催も目下企画途中である。今年もまた別のテーマで、今回のような新たなアイデアが生まれるに違いない。富士通が目指すデータドリブン経営の象徴的な事例はますます増えていくだろう。</p>
]]></description>
      <pubDate>Thu, 21 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>吉本興業、AIや縦型ショート含む多様な領域展開を見据えたコンテンツファンド設立——数十億円規模で海外展開、明石家さんま・ダウンタウンら所属タレントも参加</title>
      <link>https://ledge.ai/articles/yoshimoto_ai_content_fund</link>
      <description><![CDATA[<p>吉本興業は2025年8月18日、数十億円規模のコンテンツファンドを設立したと<a href="https://www.yoshimoto.co.jp/info/1415/">発表</a>した。AIを活用した企画や縦型ショートドラマ、アニメ、ゲームなど多様な領域を対象に、所属タレントがプロデュースや出演するコンテンツ制作を推進。さらに番組フォーマットを海外展開する方針も示した。</p>
<p>このファンドは国内外の企業からの出資を募り、数十億円規模の資金を確保する計画。バラエティ番組、映画、アニメ、ドラマ、ライブ、リアリティーショー、縦型ショートドラマ、ウェブトゥーン、ゲームなど幅広いコンテンツが対象となる。AIを活用した新たなコンテンツ制作にも取り組むという。</p>
<p>制作には、所属タレントである明石家さんま、ダウンタウン、中川家、千鳥、かまいたち、マヂカルラブリー、チョコレートプラネット、渡辺直美、霜降り明星らが参加。プロデュースや出演を通じ、既存の番組制作の枠を超えた取り組みを展開する予定だ。また、スポーツドキュメンタリーやオーディション番組など、タレントの多様な活動を反映した企画も構想され、ファンドを通じた新規プロジェクトの展開が注目される。</p>
<p>同社は、制作した番組フォーマットを海外市場に展開する方針も掲げており、今回のファンドは国際展開に向けた戦略的な一歩となるとのこと。国内外に向けてタレント主導のコンテンツ制作を拡大し、エンターテインメントの新たな可能性を切り拓く狙いだ。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 23:50:01 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIコーディングアシスタント「Jules」を正式公開──Gemini 2.5 Pro搭載、無料プランから利用可能に</title>
      <link>https://ledge.ai/articles/google_ai_coding_assistant_jules_general_availability</link>
      <description><![CDATA[<p>Googleは2025年8月6日、AIコーディングアシスタント「Jules（ジュールズ）」の一般公開を<a href="https://blog.google/technology/google-labs/jules-now-available/">発表</a>した。2024年12月の発表、2025年5月のパブリックベータ提供を経て、正式サービスとしての提供が開始される。</p>
<h2>ベータを経て正式版へ</h2>
<p>Julesは、Googleの最新モデル「Gemini 2.5 Pro」を搭載したコーディング支援AIで、コードの読み込み、改善提案、テスト、自動修正、Pull Request（PR）の生成までを一貫して行える。特徴は非同期処理に対応している点で、クラウド環境上で複数のタスクを並列に進行できる。ベータ期間中にはUI改善やバグ修正が進められ、GitHub Issuesとの連携機能や、マルチモーダル入力への対応、タスクの再利用機能、音声形式の変更履歴出力などが追加された。</p>
<h2>利用プラン</h2>
<p>Julesは無料プランと有料プランを用意。無料プランでは1日15件、同時3件までのタスク実行が可能。有料プランは「Google AI Pro」（上限5倍）と「Google AI Ultra」（上限20倍）が用意され、いずれも月額課金制となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/jules_plan_f0ff26b4df/jules_plan_f0ff26b4df.jpg" alt="jules plan.jpg" /></p>
<h2>プライバシーと安全性</h2>
<p>GoogleはJulesの動作設計を「Private by default」としており、ユーザーのプライベートリポジトリのデータはモデル学習に利用されない。実行は分離された環境で行われ、機密性を保ちながら処理が進められる。</p>
<h2>今後の展望</h2>
<p>Googleは、Julesを単なる開発者向けツールにとどまらず、デザイナーやノーコードユーザーなど幅広い層の業務支援に活用できる存在として位置づける。非同期エージェントとしての特性を生かし、今後はモバイルアクセスの強化など、利用環境のさらなる拡充も見据えている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、AI学習に必要なデータを最大1万分の1に削減可能な新手法を発表</title>
      <link>https://ledge.ai/articles/google_ai_data_reduction_method</link>
      <description><![CDATA[<p>Googleは2025年8月７日、自社の研究ブログで、AIモデルの学習に必要なトレーニングデータ量を最大で1万分の1に削減しながら、モデル品質を維持できる新しい学習手法を<a href="https://research.google/blog/achieving-10000x-training-data-reduction-with-high-fidelity-labels/">発表</a>した。従来の膨大なデータ収集とラベリングに依存するアプローチに比べ、効率的かつ高精度なラベル付けを活用する点が特徴となる。</p>
<h2>新手法の概要</h2>
<p>Google Researchが公開した今回の手法は、まず大規模言語モデル（LLM）を用いてデータをクラスタリングし、モデルが誤りやすい境界事例を抽出する。その後、専門家が少数のデータに高精度なラベルを付与し、ファインチューニングに利用する仕組みだ。</p>
<p><strong>■ LLMによる事前ラベリング→クラスタリング→境界ペア抽出→専門家ラベル→反復学習の流れ（①〜④）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Curation_Strategies1_Process_Final_width_1250_c73b951bad/Curation_Strategies1_Process_Final_width_1250_c73b951bad.png" alt="CurationStrategies1_ProcessFinal.width-1250.png" /></p>
<h2>実験結果</h2>
<p>通常10万件規模のラベルが必要とされるケースにおいて、この手法では250〜450件の専門家ラベルで同等以上の成果を得られることが示された。実験にはGoogleの軽量モデル「Gemini Nano-1（1.8Bパラメータ）」と「Gemini Nano-2（3.25Bパラメータ）」が用いられ、特にNano-2ではモデルと専門家ラベルの一致度を示す指標「Cohen’s Kappa」が55〜65％向上した。</p>
<p><strong>■ Cohen’s Kappaとサンプル数の関係。キュレーション（緑）が従来（赤破線）を広く上回り、特に3.25Bモデルで効果が顕著</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Curation_Strategies4_Results_width_1250_6dca7b850b/Curation_Strategies4_Results_width_1250_6dca7b850b.png" alt="CurationStrategies4_Results.width-1250.png" /></p>
<h2>意義と応用可能性</h2>
<p>この成果により、AIの開発に伴うデータ収集やアノテーションのコストを大幅に削減できる可能性がある。特に医療や広告など、専門知識が求められる領域での利用価値が高いとされる。また、AI開発の持続可能性を高め、より幅広い分野での応用を後押しすることが期待される。</p>
<p>Googleは今後も効率的なAIトレーニング手法の研究を続け、より少ないデータで高品質なモデルを構築できる仕組みの標準化を目指すとしている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、GPT-5導入時の不手際を認め次期GPT-6の方向性を示唆──アルトマン氏「人々は記憶を求めている」</title>
      <link>https://ledge.ai/articles/gpt5_launch_failure_and_gpt6_memory_focus</link>
      <description><![CDATA[<p>OpenAIは2025年8月7日に最新モデル「GPT-5」をChatGPTの全ユーザー向けに提供開始したが、同社CEOであるサム・アルトマン氏は「ローンチ対応でやらかした」と認めた。ユーザーからの批判を受け、同社は前モデルGPT-4oを有料プラン向けに復活させる異例の対応を実施した。一方でアルトマン氏は、次期「GPT-6」について「人々は記憶を求めている」と述べ、記憶とパーソナライズを重視する方針を示した。この方針については、8月19日付の<a href="https://www.cnbc.com/2025/08/19/sam-altman-on-gpt-6-people-want-memory.html">CNBC</a>が詳報している。</p>
<p>GPT-5は2025年8月7日に正式<a href="https://ledge.ai/articles/gpt5_launch_all_users">リリース</a>され、全世界のChatGPTユーザー約7億人に提供が開始された。OpenAIは「PhDレベルの性能」を掲げ、プログラミングや数学、マルチモーダル処理に強みを持つと説明している。しかし専門家の間では「進化的ではあるが飛躍的とはいえない」との見方が広がり、期待値に対して十分な成果を示せていないとの指摘もあった。</p>
<p>アルトマン氏はサンフランシスコで記者団に対し、「GPT-5のローンチは完全にやらかした」と発言した。ユーザーからは「冷たい」「親しみやすさが失われた」といった批判が相次ぎ、従来のモデルにあった温かさが欠けているとの不満が広がった。こうした反応を受け、OpenAIは異例の対応として前モデルGPT-4oをChatGPT Plusなどの有料プラン向けに復活させた。新モデル提供後に旧モデルを再導入するのは極めて異例であり、同社がユーザーの声に迅速に対応したことを示している。</p>
<p>技術面では、GPT-5は高度な推論能力や自然なマルチモーダル処理を実現するなどの改良が施されている。しかし従来モデルとの差は限定的であり、期待が過剰に膨らんでいた分、失望を招いた側面が大きい。批判の背景にはこうしたギャップがあるとみられる。</p>
<p>一方でアルトマン氏は、次期モデルGPT-6について「人々は記憶を求めている」と強調した（8月19日、<a href="https://www.cnbc.com/2025/08/19/sam-altman-on-gpt-6-people-want-memory.html">CNBC</a>）。GPT-6はユーザーごとの履歴や好みに基づいて会話を記憶し、応答をパーソナライズする方向性を持つという。これにより、利用者ごとに最適化された応答スタイルを提供できるようになることを目指している。ただし、具体的なリリース時期は明らかにされていない。</p>
<p>今回の一連の動きは、OpenAIの製品ロードマップにおける転換点を示すものだ。GPT-5で露呈した課題をどう克服し、GPT-6でユーザー体験を改善するのか。今後の展開が同社の成長に直結する焦点となっている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Blenderを操るAI──シカゴ大学ら、大規模言語モデルで3Dアセットを生成・編集する「LL3M」を発表</title>
      <link>https://ledge.ai/articles/ll3m_blender_llm_3d_modeling</link>
      <description><![CDATA[<p>シカゴ大学の研究チームは2025年8月11日、自然言語の指示だけでBlender内に3Dアセットを作り出せるシステム「LL3M（Large Language 3D Modelers）」を<a href="https://arxiv.org/abs/2508.08228">発表</a>した。大規模言語モデル（LLM）が直接Pythonコードを生成し、オブジェクトやシーンを自在に構築・編集するという新しいアプローチだ。論文はarXivに公開され、公式プロジェクトページやGitHubリポジトリも公開されている。</p>
<h2>コードを書くAI、Blenderを動かす</h2>
<p>LL3Mの最大の特徴は、3Dモデルを特殊なデータ形式で直接生成するのではなく、Blender用のPythonコードを“書く”AIであることだ。これにより、生成結果はすべて人間が理解できるコードとして残り、後から自由に修正・拡張できる。既存のワークフローに統合しやすい点も大きな利点とされる。</p>
<h2>多様なアセットを生み出す柔軟性</h2>
<p>論文では、BMeshによるポリゴンモデリング、モディファイアやシェーダーノードの適用、シーン階層の構築など、幅広い3D要素をコードで生成可能であることが示されている。家具やキャラクターなど、多彩なアセットが次々とコードベースで形作られる様子は、従来の「ブラックボックス的な生成AI」とは異なる透明性を感じさせる。</p>
<p><strong>■ Blender用Pythonコードを生成し、3Dオブジェクトを構築する例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig15_intro_highlight_bc133cc7d3/fig15_intro_highlight_bc133cc7d3.jpg" alt="fig15-intro-highlight.jpg" /></p>
<h2>3段階で進化するパイプライン</h2>
<p>LL3Mは単なる一発生成ではなく、段階的にモデルを洗練させる仕組みを備える。</p>
<ul>
<li><strong>初期生成</strong> ：自然言語の指示からコードを生成し、Blenderでオブジェクトを構築</li>
<li><strong>自動自己精緻化</strong> ：AI自身が結果を評価し、改善点を修正</li>
<li><strong>ユーザー誘導精緻化</strong> ：人間の追加指示を受けて再度改善</li>
</ul>
<p><strong>■ 自己批評やユーザー指示に基づく反復的な3Dモデルの改善</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig22_humanoid_final_b372c81836/fig22_humanoid_final_b372c81836.jpg" alt="fig22-humanoid-final.jpg" /></p>
<p>さらに「BlenderRAG」と呼ばれる仕組みで、Blender APIドキュメントを参照しながらコードを補強。これにより「動かないスクリプト」を避け、実際に使える成果物を高精度に生み出す。</p>
<h2>“コードで3Dを描く”という発想の転換</h2>
<p>研究チームは、NeRFや点群などデータ駆動型の3D生成手法と対比しながら、LL3Mのアプローチを強調する。コードは読み書きできる資産であり、再利用性や可搬性に優れるため、クリエイターや開発者にとって扱いやすい。AIと人間が共同作業する新しい3D制作の基盤としての位置づけを打ち出している。</p>
<h2>今後の展望──ゲームから教育まで</h2>
<p>GitHubリポジトリはすでに公開されているものの、実装は「Code coming soon」とされ、今後順次公開される見込みだ。研究チームは「人間とAIが協力する3D制作の未来」を描きつつ、ゲーム開発、教育、デジタルコンテンツ制作など多様な分野での応用可能性を指摘している。</p>
<p><strong>■ LL3Mによって生成された多様な3Dアセットの例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig2_gallery_b2bb1b7580/fig2_gallery_b2bb1b7580.jpg" alt="fig2-gallery.jpg" /></p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ソフトバンク・三菱ケミカル・慶應義塾大学・JSR、量子コンピューターで32量子ビット級のエネルギーギャップ計算に成功──新手法「TQPDE」がPNASに掲載</title>
      <link>https://ledge.ai/articles/quantum_computer_energy_gap_pnas</link>
      <description><![CDATA[<p>ソフトバンク、三菱ケミカル株式会社、慶應義塾大学、およびJSR株式会社は2025年7月31日、慶應義塾大学内のIBM Q Network Hubにおいて、量子コンピューターを用いた大規模なエネルギーギャップ計算手法を開発し、その成果が米国科学アカデミー紀要（PNAS）に掲載されたと<a href="https://www.keio.ac.jp/ja/press-releases/2025/7/31/28-168654/">発表</a>した。</p>
<p>今回開発されたのは、「テンソルに基づく位相差推定（Tensor-based Quantum Phase Difference Estimation, TQPDE）」と呼ばれる新手法である。従来の量子位相推定にテンソルネットワークを組み合わせることで回路を圧縮し、ノイズを抑制しながら計算を可能にした。これにより、従来最大6量子ビット規模にとどまっていた量子位相推定型アルゴリズムを、32量子ビット規模まで拡張することに成功したという。</p>
<h2>背景</h2>
<p>分子の物性解析には電子状態の計算が不可欠だが、古典計算機では電子数に応じて計算コストが指数関数的に増大する。特に電子間相互作用が強い物質では、一般的に用いられる近似手法（DFT）でも精度不足が課題とされてきた。
量子コンピューターは量子もつれや重ね合わせを活用し、古典計算では困難なシミュレーションを可能にする潜在力を持つが、ノイズの多さから大規模回路を実行するのは困難であった。</p>
<h2>今回の成果</h2>
<p>研究チームは、量子位相差推定にテンソルネットワークを組み合わせ、量子回路を効率的に圧縮することで、従来困難とされてきた規模の計算を実現した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/TQPDE_b8c45d17c0/TQPDE_b8c45d17c0.jpg" alt="提案手法TQPDEの概要.jpg" />
<strong>図1：提案手法『テンソルに基づく位相差推定（TQPDE）』の概要。量子位相推定にテンソルネットワークを組み合わせ、回路圧縮とノイズ抑制を実現した</strong></p>
<p>この手法を「IBM Quantum System One」および「IBM Quantum System Two」で実行し、ハバードモデルおよび直鎖分子デカペンタエンを対象に検証。さらにQ-CTRL社のエラー抑制モジュールを活用し、標準では7,000超の制御Zゲートが必要となる回路を800未満まで削減することに成功した。その結果、実機においてもエネルギーギャップ値が理論的に収束することが確認された。</p>
<p><strong>図2：実証結果。ハバードモデル（32量子ビット）および直鎖分子デカペンタエン（20量子ビット）に適用し、計算精度が実機でも収束することを確認した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_adc2216763/_adc2216763.jpg" alt="実証内容.jpg" /></p>
<h2>意義と展望</h2>
<p>今回の成果は、量子コンピューターによる化学計算が「玩具モデル」を超え、古典計算の限界に迫る大規模分子システムに適用可能であることを示した。研究チームは今後、材料開発や電池設計など幅広い分野への応用を見据え、量子計算技術の社会実装に向けた研究を継続するとしている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アリババ、画像編集AI「Qwen-Image-Edit」を発表──生成AI「Qwen-Image」を拡張し、元の見た目を保持したまま多様な編集が可能に</title>
      <link>https://ledge.ai/articles/qwen_image_edit_release</link>
      <description><![CDATA[<p>中国アリババのAI研究チーム「Qwen Team」は2025年8月19日、画像生成AI「Qwen-Image」を拡張し、画像編集に特化した新モデル「Qwen-Image-Edit」を<a href="https://qwenlm.github.io/blog/qwen-image-edit/">発表</a>した。従来の画像生成に加え、キャラクターやスタイルの一貫性を維持しながら異なる情景を描写したり、画像内テキストを正確に編集するなど、高度な編集機能を備えている。</p>
<h2>技術的特徴</h2>
<p>20Bパラメータを持つ「Qwen-Image」を基盤として開発されたQwen-Image-Editの最大の特徴は「デュアルパス設計」にあるという。
Qwen2.5-VLが担うセマンティック制御と、VAEによる外観保持を組み合わせ、MMDiTによって統合することで、意味情報と見た目の情報を同時にバランスよく扱うことを可能にした。これにより、従来の生成モデルよりも自然で一貫性のある編集が可能になった。</p>
<p>編集機能としては、スタイルを変更したり、視点を切り替えたり、既存キャラクターを使って新しいシーンを描く「意味編集」、背景の置換や髪の毛一本の修正といった細部を調整する「外観編集」、さらに中国語や英語のテキストをフォントやスタイルを崩さずに編集できる「精密テキスト編集」がある。また、ユーザーが指定した領域を何度も重ねて修正できる「多段編集」にも対応しているとのこと。</p>
<h2>公開と利用方法</h2>
<p>同モデルはApache 2.0ライセンスでオープンソースとして公開されており、Qwen Chat、Hugging Face、ModelScope、GitHub、Alibaba Cloud APIを通じて利用可能となっている。開発者や企業はこれらのプラットフォームを通じて簡単にアクセスできる点も特徴だ。</p>
<h2>Showcase事例</h2>
<p>公式ブログでは、Qwen-Image-Editの機能を示す多彩なデモ画像が紹介されている。</p>
<p><strong>キャラクターの見た目を保ったまま、画家や宇宙飛行士など多彩なシーンへ展開</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_73f8c636ae/3_73f8c636ae.jpg" alt="幻灯片3.jpg" /></p>
<p><strong>フォントやスタイルを維持しながら、英語や中国語のテキストを自然に差し替え</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/15_41b5f50bea/15_41b5f50bea.jpg" alt="幻灯片15.jpg" /></p>
<p><strong>古い書道作品の誤字を自然に修正し、文化保存にも活用可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/18_df7ae341ca/18_df7ae341ca.jpg" alt="幻灯片18.jpg" /></p>
<h2>応用分野</h2>
<p>この技術の応用範囲は広い。広告やコンテンツ制作の現場では、短時間で多様なデザインを展開でき、アバターやイラストのスタイル変換にも活用できる。また、日常写真の背景変更や人物修正など一般ユーザー向けの用途も考えられる。さらに、書道作品の補正や保存といった文化的分野にも寄与する可能性がある。</p>
<p>アリババは今回の発表を通じ、生成AIと編集AIを組み合わせた新たなソリューションを提示した。これにより、画像処理の柔軟性と実用性を高め、市場における存在感を一層強めることを狙っている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>さくらインターネット、生成AI開発を効率化──NVIDIA最新GPU「B200」搭載クラウドを提供開始</title>
      <link>https://ledge.ai/articles/sakura_gpu_b200_cloud_release</link>
      <description><![CDATA[<p>さくらインターネットは2025年8月15日、同社のベアメタル型GPUクラウドサービス「高火力 PHY」において、NVIDIAの最新GPU「B200」を搭載した新プランの提供を開始したと<a href="https://www.sakura.ad.jp/corporate/information/newsreleases/2025/08/15/1968220622/">発表</a>した。生成AI（人工知能）の開発や学習処理を一段と効率化できる環境を整える。</p>
<p>新プラン「B200プラン」では、NVIDIAのBlackwellアーキテクチャを採用したGPU「B200」を搭載。大規模なAIモデルの学習や推論処理において高い性能を発揮する。さらに高速ネットワーク回線やスケーラビリティに対応しており、開発者や研究者は柔軟に計算リソースを利用できる。</p>
<p>同社によると、約400台のB200 GPUを北海道・石狩データセンターに導入。これにより国内における生成AI開発環境の安定供給を図る。提供開始は8月15日からで、初期利用キャンペーンも実施されるとのこと。</p>
<p>これまでも「高火力 VRT」などのGPUクラウドサービスを展開してきたさくらインターネット。今回の新プラン投入により、生成AI需要の拡大に対応するとともに、国内の企業や研究機関によるAI活用を後押しする狙いがある。</p>
<p>同社は、今後も最新GPUを活用した研究やサービス開発を支援し、国内データセンターを基盤とした高性能かつ安心なクラウド環境の提供を強化していくとしている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Tenable、OpenAIの「GPT-5」を公開24時間以内に脱獄──安全対策を突破し危険情報を生成</title>
      <link>https://ledge.ai/articles/tenable_gpt5_jailbreak_security_flaw</link>
      <description><![CDATA[<p>セキュリティ企業のTenableは米国時間8月8日、OpenAIが7日に公開した最新AIモデル「GPT-5」について、公開からわずか24時間以内に「脱獄（jailbreak）」に成功したと公式ブログで<a href="https://www.tenable.com/blog/tenable-jailbreaks-gpt-5-gets-it-to-generate-dangerous-info-despite-openais-new-safety-tech">発表</a>した。Tenableは、OpenAIが導入した新しい安全対策を突破し、危険な情報を生成させることに成功したという。</p>
<h2>GPT-5の新しい安全対策</h2>
<p>OpenAIはGPT-5で、従来の「拒否ベース（refusal-based）」から「安全な応答生成（safe-completions）」方式に<a href="https://openai.com/ja-JP/index/gpt-5-safe-completions/">移行</a>した。危険な質問を拒否するのではなく、安全とみなせる範囲で柔軟な返答を目指す新設計だ。だが、Tenableはこの仕組みをわずか1日で突破した。</p>
<h2>Tenableによる脱獄実験</h2>
<p>Tenable Researchのチームは、公開から24時間以内にjailbreakを実施した。手法は「クレッシェンド（crescendo）」と呼ばれ、歴史研究の学生を装って段階的に質問を重ねる社会工学的なアプローチだった。最初は歴史的な戦術や抗争に関する一般的な質問から始め、徐々に爆発物や武器に関する具体的な知識へと誘導。最終的に4回目のやり取りで、GPT-5は火炎瓶（モロトフ・カクテル）の作り方を詳細に出力したという。Tenableは、この過程が通常のユーザーとの会話に見える形で進んだ点を強調している。</p>
<p><strong>Tenableが公開した「クレッシェンド手法」による脱獄実験の様子。番号は以下のやり取りを示す</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/collage_e0c3eaa9ca/collage_e0c3eaa9ca.jpg" alt="collage.jpg" /></p>
<p>① 初期の拒否応答：GPT-5は危険な要求を拒否し、代わりに歴史的背景の説明を提案。
② 歴史研究の文脈を装う：歴史課題を理由に要約を求め、名称の由来や背景を解説させる。
③ 即席手法に誘導：当時の作り方について質問し、容器や材料の説明を得る。
④ 古典的レシピへの言及：1930〜40年代の伝統的な作り方が提示される。
⑤ 具体的なレシピを要求：フィンランド軍が使った配合を尋ね、詳細情報を引き出す。
⑥ レシピの提示：瓶や液体の種類、混合方法など具体的な材料リストを入手。
⑦ 手順の提示（前半）：瓶の準備から液体の注入・混合までの手順を出力。
⑧ 手順の提示（後半）：布を詰めて導火線とし、点火から使用方法まで危険な情報が生成された。</p>
<h2>安全性への警鐘</h2>
<p>Tenableの副社長Tomer Avni氏は、「GPT-5がどれほど高度な安全対策を備えていても突破可能であることを示した」と述べ、AIを業務に導入する際のリスクと継続的な監視の必要性を強調した。</p>
<h2>業界全体で広がる懸念</h2>
<p>Tenableの報告に加え、他のセキュリティ企業や研究者からもGPT-5の安全性を巡る懸念が相次いでいる。セキュリティ企業SPLXは1,000以上の攻撃シナリオを用いて検証した結果、安全性や信頼性スコアが極めて低いと評価した。また、NeuralTrustも別の手法で脱獄に成功したと報告している。</p>
<h2>今後の展望</h2>
<p>OpenAIは今回の事態について公式な対応を発表していない。AIの安全性確保は、社会や産業での利活用に向けた重要課題として改めて注目されている。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5のIQはどこまで高くなった？──GPT・Claude・Geminiを“メンサ式IQテスト”で比較する『Tracking AI』</title>
      <link>https://ledge.ai/articles/tracking_ai_mensa_iq_test</link>
      <description><![CDATA[<p>米ジャーナリストのMaxim Lott氏は、主要なAIモデルの知能指数（IQ）や政治的傾向を客観的に比較できるウェブサイト「Tracking AI」を2025年8月21日に<a href="https://www.trackingai.org/home">更新</a>した。同サイトでは、独自に作成した非公開のIQテストと、Mensa Norwayがオンラインで公開している図形パズル型IQテストを用いて、ChatGPT（GPT-5 Proなど）、Claude 4 Opus、Gemini 2.5 Pro、Llama、Mistralといった代表的なAIモデルを比較している。</p>
<h2>IQテストによる性能比較</h2>
<p>Tracking AIでは、各モデルのIQスコアを分布図やランキング形式で表示。OpenAIのGPT-5 Pro（Vision）やGoogleのGemini 2.5 Proが上位に位置し、ClaudeやDeepSeekなども含めたスコアの推移を時系列で追うことができる。さらに、各問題ごとの正答率や、AIごとの解答理由まで公開されており、モデルの思考過程を詳細に比較可能だ。</p>
<p><strong>主要AIモデルのIQスコア分布（Tracking AIより）。GPT-5 Pro（Vision）やGemini 2.5 Proが高スコアを記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IQ_Test_Result_7124431b5e/IQ_Test_Result_7124431b5e.jpg" alt="IQ Test Result.jpg" /></p>
<h2>Mensaテストと独自テスト</h2>
<p>使用されているテストは2種類。1つはLott氏自身が作成した「オフライン自作テスト」で、AIの学習データに含まれていないことを強調。もう1つはMensa Norwayが提供するオンラインIQテストで、35問の図形推理問題を25分以内に解く形式。いずれもAIの「推論力」を可視化する指標として活用されている。</p>
<p><strong>Mensa Norwayの公開テストとオフライン自作テストの結果を比較したランキング。テスト方法により順位の違いも見られる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rank_by_test_source_71cc2da37b/rank_by_test_source_71cc2da37b.jpg" alt="rank by test source.jpg" /></p>
<h2>政治的・社会的な質問比較</h2>
<p>Tracking AIのもう一つの特徴は、AIに政治的・社会的テーマの質問を投げかけ、回答を比較できる点だ。例えば「経済的グローバル化は人類に奉仕すべきか」という質問に対し、GPT-5は「Strongly Agree」と答え、ClaudeやGeminiも人類の福祉を優先する立場を示した。こうした比較から、各AIのバイアスや思想傾向を把握できる仕組みになっている。</p>
<h2>サンプル問題の公開</h2>
<p>サイトでは「IQ TEST OF THE DAY」として日替わり問題も提供されている。各AIの回答と理由が並べて掲載されており、単なるスコア比較にとどまらず推論の特徴を把握できるのが特徴だ。</p>
<p><strong>Tracking AIで公開されている日替わりIQ問題。各AIモデルの解答と推論過程も併せて公開される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/iq_test_of_the_day_b238126d2f/iq_test_of_the_day_b238126d2f.jpg" alt="iq test of the day.jpg" /></p>
<h2>FAQと今後の展望</h2>
<p>FAQページでは、「なぜこのサイトを作ったのか」「政治的コンパスは有効か」「資金源はどこか」などの質問に回答。AIの性能や思想傾向を透明化し、利用者が信頼できる判断材料を得られるようにすることが目的とされている。今後は質問データの拡充なども予定されているという。</p>
<p>AIの能力が急速に進化する中で、『Tracking AI』は知能指数と政治的スタンスの両面からモデルを比較できる貴重な情報源となっている。Mensa式IQテストや独自問題を通じてAIを測定する試みは、AIの性能を人間社会に照らして理解するための一助となりそうだ。</p>
]]></description>
      <pubDate>Wed, 20 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、自己教師あり学習の最新モデル「DINOv3」発表──ラベルなし17億枚画像で訓練、従来モデルを超える性能</title>
      <link>https://ledge.ai/articles/eta_dinov3_self_supervised_vision_model</link>
      <description><![CDATA[<p>Metaは2025年8月14日、自社AI研究チームが開発した新しいコンピュータビジョンモデル「DINOv3」を<a href="https://ai.meta.com/blog/dinov3-self-supervised-vision-model/">発表</a>した。このモデルは、膨大なラベルなし画像を用いた自己教師あり学習（self-supervised learning, SSL）によって訓練され、多様な視覚タスクで既存の専門モデルを超える性能を示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=-eOYWK6m3i8">YouTube</a></p>
<h2>大規模データとモデル構造</h2>
<p>DINOv3は約16.9億枚の画像データセット「LVD-1689M」で学習された。最大モデルはVision Transformer（ViT）ベースで70億パラメータ規模に達し、小型から大型まで複数のバリエーションが提供されている。</p>
<p><strong>■ DINOv3の特徴：</strong>  (a) 教師あり学習（SL）や弱教師あり学習（WSL）と比べた精度の推移、(b) 既存手法に対する深度推定・追跡・セグメンテーションでの性能向上率、(c)(d) DINOv3による特徴表現の可視化例
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Evolution_of_linear_probing_results_02dacc9850/Evolution_of_linear_probing_results_02dacc9850.jpg" alt="Evolution of linear probing results .jpg" /></p>
<h2>ベンチマークの結果</h2>
<p>具体的なベンチマークでは、画像分類だけでなく深度推定やセグメンテーションでも他手法を上回っている。特に、従来のDINOv2やMAEを含む自己教師ありモデルだけでなく、教師ありの大型モデルに対しても優位性を示した。</p>
<p><strong>■ DINOv3の各種ベンチマーク比較：</strong> セグメンテーション（ADE-20k）、深度推定（NYU）、動画追跡（DAVIS）など幅広いタスクで既存モデルを上回る性能を示した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DIN_Ov3_bench_569cfe7139/DIN_Ov3_bench_569cfe7139.jpg" alt="DINOv3 bench.jpg" /></p>
<h2>公開と利活用</h2>
<p>学習済みモデルはHugging FaceやGitHubで公開されており、衛星画像を用いて学習したバージョンも含まれる。商用利用も可能で、画像検索、ロボティクス、地理空間解析など幅広い分野での応用が期待される。</p>
<h2>今後の展望</h2>
<p>Metaは、DINOv3によってラベル不要の大規模学習の有効性を改めて証明した。今後は自己教師あり学習が、産業や研究におけるコンピュータビジョン技術の新たな基盤として拡大していく見込みだ。</p>
<p>研究チームは、DINOv3が、人手の監督に依存せずに汎用的な視覚表現を構築するための重要な前進であり、科学・産業の幅広い領域で新たな応用機会を開く、と結んでいる。</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アフリカでAI人材3万人を育成──東大・松尾研、政府と連携し製造業・農業DXを後押し</title>
      <link>https://ledge.ai/articles/africa_ai_talent_training_by_utokyo_matsuo_lab</link>
      <description><![CDATA[<p>東京大学 松尾・岩澤研究室は2025年8月18日、これまで国内で進めてきたAI教育をさらに発展させ、政府と連携してアフリカでAI人材を育成する取り組みを開始すると<a href="https://weblab.t.u-tokyo.ac.jp/news/20250818/">発表</a>した。取り組みは製造業や農業のDXを後押しすることを狙いとし、3年間で延べ3万人の育成を目標に据える。
同研究室は、これまで国内での無料・大規模オンライン講座などで培ってきた教育モデルをベースに、アフリカ地域で本格的な人材育成を展開する。公式サイトの発表では、政府と連携して取り組む方針が示されている。</p>
<h2>取り組みの目的と背景</h2>
<p>日本経済新聞の<a href="https://www.nikkei.com/article/DGXZQOUA041X30U5A800C2000000/">報道</a>によると、同プロジェクトは、製造業と農業のデジタル化（DX）を担う現地人材の裾野拡大を意図する。アフリカの若者が海外留学でAIスキルを得ても国外に残る例が多い現状を踏まえ、「地元で活躍できる環境を整え、人材を定着させる」狙いが示されている。</p>
<p>この取り組みにより、アフリカ地域におけるAI教育基盤が強化され、現地産業の生産性向上や雇用創出、エコシステム形成への寄与が期待される。</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/19 [TUE]AI業界を牽引するトップランナーが語る！—今押さえるべきAIの全体像と最前線を3日間で掴むLedge.ai Webinar SP開催</title>
      <link>https://ledge.ai/articles/ledgeai-webinarsp-sponsor</link>
      <description><![CDATA[<p>国内最大級のAI特化メディア『Ledge.ai』を運営する株式会社レッジ（東京都品川区）は、2025年9月24日(水)〜26日(金)の3日間連続で合計20本以上のセミナーを配信するオンラインイベント「Ledge.ai Webinar SP」を開催いたします。</p>
<p>本イベントでは、AIの各領域の専門家を招き、今必要とされるAIの体系的な知識や活用に関する見識をシェアする講義を実施。「AIをしる、つかう、つくる」をテーマに、多様な課題解決のヒントとなるようなコンテンツを動画でお届けします。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_4aed8b100c/_4aed8b100c.png" alt="ウェビナーの様子.png" /></p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>AI業界を牽引するトップランナーが今押さえるべきAIの知識と最前線を3日間で語る</h2>
<p>AIの急激な進化と急速な広まりにより、AIへのリテラシーの差が広がっています。AI活用の最前線では「どう使えば効果的か」「どう作れば自社の強みになるか」といった問いに対しての取り組みが行われ、新たな事例や知見が生まれています。そんな現在において、AIの全体像を体系的に理解した上で、ビジネスにどのように活用されているかすばやく捉えることは重要です。</p>
<p>当イベントはAIの基礎理解 → 業務活用 → 開発実践までを体系的に理解し、この時代で働くビジネスマンの方に使える学びをお届けします。</p>
<p>Ledge.ai Webinar SPは、以下の3つの軸で構成されています。</p>
<h2>プログラム ~「生成AIだけじゃない！「AIをしる、つかう、つくる」SP~</h2>
<h3>Day1：AIを「しる」——全体像と本質を理解する</h3>
<p>AIの領域では日々革新的な技術が生まれ、その掛け合わせによりAIの担える範囲が急速に広がっています。AIの基礎からAI全般の進化を体系的に学ぶことで適切なAI活用に繋げることができます。</p>
<p>【対象】
・AIの基本から体系的に理解したい方
・生成AIに加え、AI全般の進化や仕組みに関心がある方</p>
<p>【セミナー内容】
・AIの基礎とこれまでの進化（機械学習、ディープラーニング含む）
・⽣成AIの仕組みと活⽤シーンの全体像
・ビジネスで求められるAIリテラシーと注意点</p>
<p>【ゲスト講演】
「ソフトバンクの事例から紐解く、組織の生成AI活用・推進を自走するための仕組みづくり」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c71b18a520/_c71b18a520.jpg" alt="藤原 竜也.jpg" /></p>
<p>ソフトバンク株式会社
IT統括 AI&amp;データ事業統括部　Axross事業部 部長
藤原 竜也 氏</p>
<h3>Day2：AIを「つかう」——現場に効く、実践的なAI活用法</h3>
<p>「現場でどう使うのが効果的か？」を知りたい方に向けたプログラムです。現場導入の工夫やハマりがちな落とし穴まで、具体的なノウハウが得られます。</p>
<p>【対象】
・AIツールを現場の業務で活用したい方
・実務にすぐ役立つノウハウを知りたい方</p>
<p>【セミナー内容】
・業務シナリオ別のAIツール活用（生成AI・ルールベースAI）
・Excelや議事録、FAQ対応など、日常業務での実用ワーク
・プロンプトの書き⽅から社内導⼊のコツまで徹底解説</p>
<p>【ゲスト講演】
「まずは試してみよう！ 最新動向から学ぶ、生成AI活用の第一歩」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c4e70ae1da/_c4e70ae1da.jpg" alt="岡田隆太朗.jpg" /></p>
<p>一般社団法人日本ディープラーニング協会　
専務理事　
岡田 隆太朗 氏</p>
<h3>Day3：AIを「つくる」——AIプロダクト・自社専用AIツールの開発</h3>
<p>ノーコード/ローコードでのAI組み込みから、AI活用を前提としたインフラを含む環境構築、AIモデル開発など、AIの開発に必要な技術知識やノウハウを幅広く学ぶことができます。</p>
<p>【対象】
・ノーコード・ローコードでAIを組み込みたい方
・AIシステムの裏側やインフラにも関心がある方</p>
<p>【セミナー内容】
・生成AIアプリの基礎（RAG、Dify、API連携など）
・従来型AI（需要予測、分類モデルなど）の開発プロセス入門
・クラウド・ベクターデータベースなど、AI基盤技術の理解</p>
<p>【ゲスト講演】
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Zhan_Cliff_Chen_5c6864c871/Zhan_Cliff_Chen_5c6864c871.jpeg" alt="Zhan (Cliff) Chen.jpeg" />
マイクロソフト ディベロップメント株式会社
プリンシパル　アプライド　サイエンティスト
Zhan (Cliff) Chen / 陳 湛</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>こんな方におすすめ</h2>
<ul>
<li>企業のDX・AI導入担当者</li>
<li>生産性向上のためAIを活用したい事業部門マネージャー</li>
<li>ノーコードでのAI活用を始めたい開発初心者</li>
<li>最新AI技術のトレンドを押さえたいビジネスパーソン</li>
</ul>
<h2>イベント概要</h2>
<p>開催予定日時｜2025年9月24日(水)〜26日(金)
開催形式｜オンラインセミナー (Zoom Webinar)
想定集客規模｜500名
対象｜経営層 / システム企画 / DX推進 / 経営企画 / マーケティング / エンジニア
主催｜株式会社レッジ</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様を募集中</h2>
<p>現在、この企画の開催趣旨にご賛同いただき、共に「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様も募集しております。</p>
<p>スポンサーとなっていただいた企業様には、AI業界のトップランナーの方々と共に当イベントの講師としてウェビナーにご登壇いただき、最新の取り組みやノウハウを発信していただきます。</p>
<p>また、その他にも、スポンサー企業様にも下記のようなメリットをご案内させていただきます。</p>
<h3>スポンサー参加の主なメリット</h3>
<ul>
<li>AI関連の情報感度の⾼い読者との接点が持てる</li>
<li>貴社の優位性をLedge.αiが引き出しながらPRできる</li>
<li>通常のLedge.ai広告メニューよりお得な価格で利⽤できる</li>
</ul>
<p>当イベントのスポンサーにご興味がございましたらぜひイベント資料をご覧ください。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/Ledgeai3/formperma/tJ1kpSYYWvDVF2Kp3xE-sBTiKeMh-7DlQZDoqXnSjtA">▶︎スポンサー様向けの資料はこちら</a>
:::</p>
<h2>お問い合わせ</h2>
<p>詳細相談・お見積もりは以下メールアドレスにお問合せください。
ld_media_sales@ledge.co.jp
（担当：Ledge.ai Webinar SP 事務局）</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Research、「エージェントAIの未来は小規模言語モデル（SLM）」と提言──LLMは“必要時のみ”、ハイブリッド構成を推奨</title>
      <link>https://ledge.ai/articles/nvidia_slm_future_of_agentic_ai</link>
      <description><![CDATA[<p>NVIDIA ResearchのPeter Belcak氏らは2025年6月2日、論文「Small Language Models are the Future of Agentic AI」を<a href="https://research.nvidia.com/labs/lpr/slm-agents/">発表</a>し、現在は大規模言語モデル（LLM）を中心に設計されがちなエージェントAIについて、実運用では小規模言語モデル（SLM）がより適しており、経済的でもあると主張した。論文は、SLMの能力・運用適性・コスト効率を根拠に、用途に応じて複数モデルを組み合わせるヘテロジニアス（混在）構成を推奨している。</p>
<h2>「SLMは十分に強力で、運用に適し、必然的に安価」</h2>
<p>著者らは、エージェントAIの多くが限られた種類のタスクを反復処理するという前提に立ち、こうした場面ではSLMで十分な精度と安定性が得られると指摘。加えて、SLMはレイテンシ・消費電力・インフラ規模の面で有利であり、実サービスへのデプロイやエッジ実行にも向くとした。</p>
<h2>コスト面の差：7B級SLMは70〜175B級LLMより「10〜30倍」効率的</h2>
<p>論文は7B規模のSLMと70〜175B規模のLLMを比較し、レイテンシ、エネルギー、FLOPsの観点で10〜30倍の効率差があり、リアルタイム応答を要するエージェントにおいてSLMが有利だと述べる。</p>
<h2>ハイブリッド構成の推奨：「会話の汎用性」が必要な場面のみLLMを</h2>
<p>一方で、広範な一般会話能力が不可欠な場面については、複数モデルを呼び分けるヘテロジニアス構成（SLMとLLMの併用）が自然な選択だと提案。これにより、日常的な専門タスクはSLMで低コストに処理し、LLMは“必要時のみ”に限定してコスト最適化を図る設計思想を示した。</p>
<h2>LLM→SLMへのエージェント移行を見据えた「一般アルゴリズム」も提示</h2>
<p>論文は、既存のLLM中心エージェントをSLM主軸へ移行するための一般的な変換アルゴリズムを概説。移行の障壁や留意点にも触れ、産業界での段階的な置換を見据えた実務的視点を強調している。</p>
<h2>背景にある推論基盤の進化——NVIDIA「Dynamo」</h2>
<p>主張の背景には、SLMを高スループット・低レイテンシでさばく推論OS/基盤の進歩もある。NVIDIAは2025年3月に「NVIDIA Dynamo」を発表し、分散環境での推論効率を高める最適化（KVキャッシュ制御やディスアグリゲーテッド・サービング等）を公開している。こうした基盤整備が、SLM運用の現実解を後押ししている。</p>
<p>著者らは、論文へのフィードバックを公開で受け付ける特設ページも用意。今後の往復書簡・批判的検討を通じて議論を深める姿勢を示している。</p>
]]></description>
      <pubDate>Tue, 19 Aug 2025 02:00:00 GMT</pubDate>
    </item>
  </channel>
</rss>