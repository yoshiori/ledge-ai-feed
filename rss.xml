<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>動画生成AI Seedance 2.0波紋拡大、ByteDanceが実在人物・IP生成を当面制限──ハリウッド・日本政府も問題視</title>
      <link>https://ledge.ai/articles/seedance2_0_international_backlash_ip_restriction</link>
      <description><![CDATA[<p>中国IT大手の字節跳動（ByteDance）は、動画生成AI「Seedance 2.0」において、実在人物の顔やアニメ・映画などのIPキャラクターを参照した動画生成を当面制限していることが分かった。複数の中国メディアによると、同社傘下の抖音（Douyin）集団の李亮副総裁が2月15日、中国のSNS「Weibo（微博）」への投稿で、実在人物や既存IPを基にした生成を現在はサポートしていないと明らかにした。</p>
<p>報道によれば、李氏はSeedance 2.0について「現在、実在人物の顔を参照した生成やIPキャラクターの生成はサポートしていない」と説明。あわせて、デジタル分身の制作には本人認証が必要であることや、権利侵害防止策を強化していく方針を示したという。</p>
<h2>Seedance 2.0生成動画が拡散</h2>
<p>Seedance 2.0は、テキストや画像、動画などを入力として映像を生成するモデルとして公開され、SNS上で拡散した。とりわけ、実在のハリウッド俳優を想起させる動画が投稿され、議論が拡大した。</p>
<p>動画を投稿したRuairi Robinson氏は、アイルランド出身の映画監督・ビジュアルアーティストで、長編映画の監督やコンセプトアート制作などを手がけてきた人物。Robinson氏がXに投稿した生成動画は海外メディアでも取り上げられ、著作権侵害の可能性を指摘する声も上がった。</p>
<p><strong>RobloxのプロダクトマネージャーPeter Yang氏は、Xで「このモデル（Seedance 2）で見たものはすべて著作権侵害だ」とコメントした</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/peteryang_seedance20_x_6a9b148605/peteryang_seedance20_x_6a9b148605.jpg" alt="peteryang seedance20 x.jpg" /></p>
<h2>Robinson氏、YouTubeでテスト動画を公開</h2>
<p>Robinson氏はその後、自身のYouTubeチャンネルでSeedance 2.0のテスト動画をまとめて公開した。概要欄では「2026年2月10日に短時間アクセスできたが、その後モデルは引き下げられた（pulled down）」と説明している。</p>
<p>@<a href="https://www.youtube.com/watch?v=fbVv0ZPk0fw&amp;t=4s">YouTube</a></p>
<h2>ハリウッド団体、日本政府も懸念を表明</h2>
<p>米映画業界団体や俳優組合は、著作権侵害の懸念を表明。一部報道では、米大手スタジオがByteDance側に差し止め通知を送付したと伝えられている。</p>
<p>米<a href="https://www.motionpictures.org/press/motion-picture-association-calls-for-bytedance-to-cease-seedance-2-0-infringing-activity/">映画業界団体</a>や<a href="https://www.sagaftra.org/sag-aftra-statement-seedance-20">俳優組合</a>は、著作権侵害の懸念を表明。一部報道では、米大手スタジオがByteDance側に差し止め通知を送付したと伝えられている。</p>
<p>日本国内でも議論は波及していた。小野田紀美AI戦略担当相が閣議後の会見でSeedance 2.0について言及し、<a href="https://ledge.ai/articles/onoda_seedance2_government_investigation_copyright">著作権上の懸念</a>を指摘。政府側が事実関係の調査に乗り出す方針を示していた。</p>
<p>今回の当面制限は、モデル公開後に拡大した国際的な議論の中で示された対応となる。動画生成AIをめぐっては、実在人物や既存IPの取り扱いをどう設計するかが、引き続き焦点となっている。</p>
]]></description>
      <pubDate>Wed, 18 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>拡大するLLM学習の「蒸留」論点──OpenAIは米議会に警告、Googleは抽出攻撃を報告</title>
      <link>https://ledge.ai/articles/expanding_distillation_debate_openai_congress_warning_google_extraction_attacks</link>
      <description><![CDATA[<p>OpenAIが2026年2月12日、米下院の下院中国問題特別委員会に覚書を提出し、中国のAI企業DeepSeekによる「蒸留（distillation）」手法を問題視していたことが明らかになった。<a href="https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge">Bloomberg</a>が同日報じた。翌13日には、GoogleのGoogle脅威インテリジェンスグループ（GTIG）が、モデル抽出を伴う「蒸留攻撃（distillation attacks）」の増加を報告している。</p>
<p>同じ「distillation」という語が、競争（モデル開発）と防御（抽出攻撃）という異なる文脈で相次いで言及された格好だ。</p>
<h2>OpenAI、DeepSeekの蒸留を問題視</h2>
<p>Bloombergが入手した覚書によると、OpenAIはDeepSeekがチャットボット「R1」の開発にあたり、米国の主要AIモデルの出力を抽出する「不公平かつ洗練された手法」を用いていると指摘した。文書は2026年2月12日付で、下院中国問題特別委員会に提出された。</p>
<p>覚書では、他社モデルの出力を体系的に収集し、それを新たなモデルの訓練に活用する行為が、競争環境や知的財産保護、国家安全保障の観点から懸念を生じさせる可能性があると説明している。DeepSeek側の公式見解は現時点で公表されていない。</p>
<h2>Google、蒸留攻撃（Model Extraction Attacks）の増加を報告</h2>
<p>一方、Googleは2026年2月13日、GTIG名義でレポート「GTIG AI Threat Tracker」を<a href="https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use?hl=en">公開</a>した。レポートでは、正規のAPIアクセスを利用してモデルの応答を体系的に収集し、新たなモデルを構築する「モデル抽出攻撃（Model Extraction Attacks）」、いわゆる「蒸留攻撃」が増加していると報告している。</p>
<p>GTIGは、こうした行為を知的財産の侵害に当たる可能性があるものと位置付け、検知・遮断措置を講じていると説明した。また、2025年中に高度持続的脅威（APT）によるフロンティアモデルへの直接攻撃は確認していないとしつつも、研究者や民間企業による抽出試行を観測し、対策を講じたとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gtig_ai_threat_tracker_feb26_fig1_max_1500x1500_484adc1deb/gtig_ai_threat_tracker_feb26_fig1_max_1500x1500_484adc1deb.jpg" alt="gtig-ai-threat-tracker-feb26-fig1.max-1500x1500.jpg" /></p>
<p>図は、GTIGが説明するモデル抽出攻撃の一般的構造を示したものだ。正規のAPIを通じて「教師モデル」に問い合わせを行い、その応答を用いて「学生モデル」を訓練する流れが図示されている。</p>
<h2>蒸留とは何か──正規技術と抽出攻撃の境界</h2>
<p>蒸留（knowledge distillation）は、既存の高性能モデル（教師モデル）の出力を利用して、より小型または効率的なモデル（学生モデル）を訓練する機械学習手法である。モデル圧縮や推論効率の向上を目的として広く研究・実装されてきた。</p>
<p>一方で、他社が提供する商用モデルの出力を無断で抽出し、新モデル開発に活用する場合には、利用規約違反や知的財産侵害の問題が生じ得る。GTIGは、こうした行為を「distillation attacks」と定義している。</p>
<p>OpenAIが議会に提出した覚書と、Googleが報告した抽出攻撃はいずれも「蒸留」という語を含むが、前者は国際競争の文脈、後者はサービス防御の文脈で語られている点が異なる。</p>
<h2>競争と防御で同時に拡大する蒸留論点</h2>
<p>今回の動きは、蒸留が単なる効率化技術にとどまらず、競争戦略や知的財産保護、安全保障といった領域に波及していることを示している。</p>
<p>OpenAIの覚書は、モデル間競争の観点から蒸留の問題を提起し、Googleのレポートは、抽出攻撃への対策強化を示した。AIモデルの高度化と普及が進む中で、蒸留を巡る議論は、開発と防御の両面で拡大している。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国Z.ai、新AIモデル「GLM-5」公開──ベンチマークでGemini・Claudeと並走</title>
      <link>https://ledge.ai/articles/z_ai_glm_5_release_benchmark_competition</link>
      <description><![CDATA[<p>北京に拠点を置くAI企業Z.aiは2026年2月12日、新たな大規模言語モデル（LLM）「GLM-5」を公式ブログで<a href="https://z.ai/blog/glm-5">発表</a>した。同社は複数の国際ベンチマークにおける評価結果を公開し、Gemini 3 ProやClaude Opus 4.5などの主要モデルと比較した。</p>
<h2>エージェント志向モデルとしての位置づけ</h2>
<p>Z.aiはGLM-5を「Agentic Engineering」を掲げるモデルと位置づける。対話応答にとどまらず、推論やコーディング、ツール利用を含むタスク遂行型の挙動を重視した設計であると説明している。</p>
<p>公式ブログでは、Humanity’s Last Exam、SWE-bench Verified、Terminal-Bench 2.0、BrowseComp、MCP-Atlas、τ²-Bench、Vending Bench 2など、計8種類の評価指標を用いた結果が示された。</p>
<p><strong>■ GLM-5と主要モデルのベンチマーク比較。推論・コーディング・エージェントタスクなど8指標で評価</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20260212_010724_885b0655fb/20260212_010724_885b0655fb.jpg" alt="20260212-010724.jpg" /></p>
<p>図によれば、GLM-5はSWE-bench VerifiedやBrowseCompなど複数の項目で上位帯に位置している。一部指標ではGemini 3 ProやClaude Opus 4.5が上回る結果も示されているが、全体としては主要モデル群と同水準に並ぶスコアレンジに入っている。</p>
<h2>Vending-Bench 2でのシミュレーション結果</h2>
<p>Z.aiは、エージェント型モデルの能力を測るベンチマーク「Vending-Bench 2」におけるシミュレーション結果も公開した。同ベンチは仮想環境内で資金を増やすタスクを課し、日数経過に伴う資金推移を比較する形式を採る。</p>
<p><strong>■ Vending-Bench 2における資金推移の比較。GLM-5は最終的に上位帯で推移</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bf5c97ae6ba5f07ba980ed9bcc116f47_a2243d7ee4/bf5c97ae6ba5f07ba980ed9bcc116f47_a2243d7ee4.jpg" alt="bf5c97ae6ba5f07ba980ed9bcc116f47.jpg" /></p>
<p>グラフでは、GLM-5は最終的に4,000ドル超の水準に到達し、Gemini 3 ProおよびClaude Opus 4.5と近いレンジで推移している。一方で、GPT-5.2や他の中国モデルとの間にも差が見られる。この結果は、中国発モデルがエージェント型タスクにおいても国際競争圏内に入っていることを示すデータとして提示されている。</p>
<h2>公開形態と提供</h2>
<p>GLM-5はHugging FaceおよびModelScopeを通じて公開されている。API経由での利用も紹介されている。
同社はこれまでGLMシリーズを継続的にアップデートしてきたが、今回のGLM-5はエージェント志向への明確なシフトを打ち出したモデルとして位置づけられる。</p>
<p>Z.aiは公式ブログを通じて、推論、コーディング、ツール統合を含む包括的な能力向上を掲げた。GLM-5は、中国AI勢の技術開発がエージェント型モデルの領域へと本格的に移行していることを示す事例の一つといえる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>インドのアダニ・グループ、AIデータセンターに1000億ドル（約15兆円）を直接投資──2035年までに5GW、総額2500億ドル規模のエコシステム構想</title>
      <link>https://ledge.ai/articles/adani_group_ai_datacenter_100billion_5gw_2035</link>
      <description><![CDATA[<p>インドの多角経営コングロマリット、アダニ・グループは2026年2月17日、再生可能エネルギーで稼働するハイパースケールの「AI-ready」データセンター群の整備に、2035年までに1000億ドルを直接投資すると<a href="https://www.adani.com/newsroom/media-releases/adani-commits-usd-100-bn-to-sovereign-ai-infrastructure">発表</a>した。関連分野で追加1500億ドルの投資を誘発し、総額2500億ドル規模のAIインフラ・エコシステム形成を見込む。アダニはこれを「世界最大級の統合型エネルギー×計算コミットメント」の一つと位置付けている。</p>
<h2>1000億ドル投資、総額2500億ドル規模へ</h2>
<p>今回の直接投資1000億ドルは、再生可能エネルギーを基盤とするAI対応型データセンターの構築に充てられる。さらに、サーバー製造、先端電力インフラ、主権クラウドなど関連分野で1500億ドルの追加投資を誘発すると見込み、10年間で2500億ドル規模のAIインフラ・エコシステム形成を想定する。</p>
<p>同社はこの取り組みを、エネルギーと計算資源を統合した国家規模の基盤整備と位置付けている。</p>
<h2>2GWから5GWへ拡張、Google・Microsoftと展開</h2>
<p>構想の中核となるのは、同社のデータセンター事業プラットフォーム「AdaniConnex」だ。現在約2ギガワット（GW）の全国データセンター容量を、2035年までに5GWへ拡張する。</p>
<p>Googleとの戦略的パートナーシップのもと、ビシャカパトナム（Visakhapatnam）でギガワット級AIデータセンターキャンパスを構築するほか、ノイダ（Noida）でも展開する。Microsoftとはハイデラバード（Hyderabad）およびプネー（Pune）での取り組みを進めるとしている。</p>
<p>また、Flipkartとの提携も深化させ、次世代デジタルコマース、高性能コンピューティング（HPC）、大規模AIワークロードに対応する第2の専用AIデータセンターを開発する方針を示した。</p>
<h2>再エネ550億ドルとBESS、液冷対応の“AI-ready”設計</h2>
<p>データセンターの電力基盤として、Adani Green Energyが手がける30GW規模のカブダ（Khavda）再生可能エネルギープロジェクトを中核に据える。同プロジェクトはすでに10GW超が稼働しているという。</p>
<p>さらに同社は再生可能エネルギー拡大に追加で550億ドルを投じ、世界最大級の蓄電システム（BESS）を含むポートフォリオを構築する計画も明らかにした。</p>
<p>施設は高密度コンピュートクラスターと次世代AIワークロード向けに最適化され、液冷（liquid cooling）システムや高効率電力アーキテクチャを採用する。再エネ発電、送電インフラ、ハイパースケールAI計算を単一アーキテクチャで並行整備する「統合型モデル」を採る点が特徴だ。</p>
<h2>主権AIと国内製造サプライチェーン</h2>
<p>同社は、インド国内の大規模言語モデル（LLM）や国家データ施策を支える専用計算資源を確保し、長期的なデータ主権の確立を図るとしている。GPUキャパシティの一定割合をインドのAIスタートアップや研究機関、ディープテック分野向けに割り当てる方針も示した。</p>
<p>サプライチェーン面では、変圧器、電力電子機器、送電システム、インバータ、産業用熱管理ソリューションなどの重要部材について、国内製造パートナーシップに共同投資する。これにより、グローバル供給網の変動リスクを低減し、インドをデータハブにとどまらず、次世代インテリジェンス・インフラの生産・輸出拠点へと位置付ける狙いがある。</p>
<h2>人材育成と国家インフラとの統合</h2>
<p>人材面では、大学と連携したAIインフラ工学カリキュラムの設置、エネルギーや物流分野に特化した応用AI研究ラボの開設、国家フェローシップ制度の創設に取り組む。</p>
<p>また、PM Gati Shaktiプログラムと整合させ、物流や港湾、産業回廊にエージェント型AIを導入するほか、既存のAIベース産業クラウドを活用して再エネ資産をリアルタイム管理するなど、重厚長大産業とデジタル基盤の統合を進めるとしている。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>内閣府、AI社会実装の阻害要因を洗い出しへ──障害となる規制・制度の情報提供を国民から募集</title>
      <link>https://ledge.ai/articles/ai_implementation_regulatory_barriers_public_call_cabinet_office</link>
      <description><![CDATA[<p>内閣府は令和8年2月10日、AI（人工知能）の社会実装を進める上で障害となる、または不十分な効果をもたらす規制・制度について、国民から広く情報提供を募集すると<a href="https://www8.cao.go.jp/kisei-kaikaku/kisei/forms/260210_forms.html">発表</a>した。募集は同日から3月10日午後5時まで。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kisei_kaikaku_kisei_AI_fe6f8d8c93/kisei_kaikaku_kisei_AI_fe6f8d8c93.jpg" alt="kisei-kaikaku-kisei AI.jpg" /></p>
<p>同日行われた記者会見で、規制改革担当大臣である城内実氏は、令和7年12月23日に閣議決定された「<a href="https://www8.cao.go.jp/cstp/ai/ai_plan/ai_plan.html">人工知能基本計画</a>」において、AIの社会実装の実現に向け、国民の声を聴きながら既存の規制や制度の点検および見直しを図る方針が示されていると説明。その方針を受けた具体的な取り組みとして、今回の情報募集を実施すると述べた。</p>
<p>城内氏は、AI担当大臣である小野田紀美氏と連携し、AIの社会実装において障害となる、または不十分な効果をもたらす規制・制度について、国民に広く情報提供を求めると説明した。内閣府のウェブサイトには特設ページが設けられ、専用フォームから情報を提出できる。</p>
<p>寄せられた情報は、今後の規制改革推進会議における審議や、人工知能基本計画の改定に向けた検討にあたって参考とされる予定だという。詳細については、内閣府規制改革推進室が問い合わせ窓口となる。</p>
<p>政府は、AIの研究開発に加え、社会実装段階で生じる制度的課題への対応を重要課題として位置付けている。これまでもAI法案の策定過程でパブリックコメントを実施し、国民からの意見を制度設計に反映させてきた。今回の募集は、こうした政策プロセスの一環として実施されるものだ。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/2/19 [THU]Alibaba、ロボット向けオープンAI基盤モデル「RynnBrain」公開──実世界の空間・時間ダイナミクスに接地し、従来のVLMの弱点克服を目指す</title>
      <link>https://ledge.ai/articles/alibaba_rynnbrain_robotics_spatiotemporal_grounded_ai</link>
      <description><![CDATA[<p>中国のテクノロジー企業Alibaba Group傘下のDAMO Academyは2026年2月13日、ロボットや自律機器向けのオープンソース基盤モデル「RynnBrain」を<a href="https://alibaba-damo-academy.github.io/RynnBrain.github.io/">発表</a>した。実世界における空間・時間のダイナミクスに接地し、知覚・推論・計画を統合的に扱う“エンボディドAI”向けの時空間基盤モデルと位置付けられる。</p>
<h2>物理世界に接地した統合フレームワーク</h2>
<p>論文によれば、RynnBrainは従来の視覚言語モデル（VLM）が抱えてきた課題――物理ダイナミクスへの内在的な接地の弱さや、時空間整合性を伴う推論の困難さ――に対応することを目的として設計された。</p>
<p>モデルは、以下の4つの能力軸を統合するフレームワークとして構築されている。</p>
<ul>
<li>包括的なエゴセントリック理解</li>
<li>多様な時空間ローカライゼーション</li>
<li>物理に接地した推論</li>
<li>物理制約を踏まえた計画（physics-aware planning）</li>
</ul>
<p>実世界の環境下でロボットが「見て、理解し、推論し、行動計画を立てる」一連の処理を、空間情報と時間的変化を前提に統合することを目指す。</p>
<p><strong>■ RynnBrainの能力構成：認知（Cognition）、位置特定（Localization）、推論（Reasoning）、計画（Planning）を統合し、実世界の空間・時間ダイナミクスに接地した処理を行う</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x3_b020061610/x3_b020061610.jpg" alt="x3.jpg" /></p>
<h2>2B〜30B（MoE）まで3スケール展開、用途別派生も</h2>
<p>RynnBrainは、2B、8B、30B-A3B（Mixture-of-Experts構成）の3スケールで展開される。さらに、用途別にポストトレーニングを施した派生モデルとして、以下の4種が公開されている。</p>
<ul>
<li>RynnBrain-CoP（空間接地を挟んだ推論強化型）</li>
<li>RynnBrain-Nav（ナビゲーション向け）</li>
<li>RynnBrain-Plan（操作計画向け）</li>
<li>RynnBrain-VLA（視覚・言語・行動統合）</li>
</ul>
<p>基盤にはQwen3-VLが採用されており、大規模な時空間データを用いた学習パイプラインを通じて、2000万超のサンプルにスケールさせたと説明している。</p>
<h2>28ベンチで評価、新設「RynnBrain-Bench」も公開</h2>
<p>論文では、エンボディドAI関連20ベンチマークと、一般的な視覚理解8ベンチマークを含む計28評価で性能を検証したと報告している。位置特定や空間参照、操作計画などの項目において、既存のオープンモデルを上回る結果を示したとしている。</p>
<p>あわせて、長時間のエピソード動画全体にわたる時空間理解を測定する新評価スイート「RynnBrain-Bench」も公開された。同ベンチは3,616本の動画クリップ、577,998フレーム、12,000件の自由記述質問を含む構成とされる。</p>
<p><strong>■ RynnBrain-Benchの評価設計：空間認知、物体理解、接地推論、アフォーダンス、軌道理解など多層的な能力を横断的に測定する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x6_4fc0376495/x6_4fc0376495.jpg" alt="x6.jpg" /></p>
<h2>Apache 2.0で公開、複数プラットフォームから利用可能</h2>
<p>RynnBrainはApache 2.0ライセンスの下で公開されており、プロジェクトページのほか、GitHub、Hugging Face、ModelScopeなどから利用可能とされる。</p>
<p>ロボットや自律機器の高度化を支える“頭脳”として、空間・時間ダイナミクスに接地した統合モデルをオープンソースで提示した点が特徴となる。今後は、実機応用やエージェントスタック全体への組み込み事例が注目される。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米国防総省、Anthropicとの関係解消を検討──「Claude」軍事利用の安全制限めぐり対立</title>
      <link>https://ledge.ai/articles/anthropic_pentagon_claude_military_safeguards_dispute</link>
      <description><![CDATA[<p>2026年2月15日、アメリカ国防総省が、生成AI「Claude」を開発するAnthropicとの契約関係の解消を検討していると、米ニュースサイト<a href="https://www.axios.com/2026/02/15/claude-pentagon-anthropic-contract-maduro">Axios</a>が報じた。両者はAIの軍事利用に関する安全制限を巡って協議を続けてきたが、合意に至っていないという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/axios_pentagon_threatens_to_cut_off_anthropic_b4ed7f604b/axios_pentagon_threatens_to_cut_off_anthropic_b4ed7f604b.jpg" alt="axios pentagon threatens to cut off anthropic.jpg" /></p>
<p>Axiosによると、国防総省はAnthropicに対し、「合法的な軍事用途」全般での利用を可能にするよう安全ガードレールの見直しを求めている。一方、Anthropicは自社の利用ポリシーに基づき、完全自律型の致死兵器や大規模監視への利用など一部用途に制限を設けており、この点が交渉の焦点となっている。</p>
<p>Axiosは、2025年に締結された最大約2億ドル規模の契約にも影響が及ぶ可能性があると伝えた。交渉は数カ月にわたり続いているという。</p>
<p>その後、<a href="https://www.reuters.com/technology/pentagon-threatens-cut-off-anthropic-ai-safeguards-dispute-axios-reports-2026-02-15/">Reuters</a>もAxiosの報道を引用する形で追随した。Reutersは、国防総省がAnthropicとの関係を断つ可能性を検討していると報じるとともに、OpenAIやGoogleなど他のAI企業にも同様の軍事利用に関する要請が行われていると伝えた点が特徴だ。軍との契約を巡る動きが業界全体に波及する可能性を補足している。</p>
<p>また、Axiosの<a href="https://www.axios.com/2026/02/16/anthropic-defense-department-relationship-hegseth">続報</a>では、国防総省がAnthropicを防衛サプライチェーン上の「リスク」として扱う選択肢を検討しているとも報じられた。この措置が実施された場合、防衛関連企業がAnthropicの技術を利用することに制限がかかる可能性があるという。通常、この枠組みは外国勢力などを対象に適用されるものであり、国内AI企業への適用が検討されるのは異例とされる。</p>
<p>報道によれば、国防総省側は国家安全保障上の観点からAI技術の幅広い活用を求めている。一方、Anthropicは自社の安全ポリシーに基づく用途制限を維持する姿勢を崩していないとされる。</p>
<p>現時点で、国防総省およびAnthropicから交渉決裂や契約解除に関する正式発表は出ていない。今後、契約の扱いや他AI企業との関係がどのように整理されるかが焦点となる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「Microsoft 365 Copilot」が社外秘メールを拾う不具合、数週間継続──Microsoftが修正を段階展開</title>
      <link>https://ledge.ai/articles/copilot_confidential_email_bug_fix_rollout</link>
      <description><![CDATA[<p>Microsoftが自社AI「Copilot」に関する不具合を認めたことを、米ITメディアの<a href="https://www.bleepingcomputer.com/news/microsoft/microsoft-says-bug-causes-copilot-to-summarize-confidential-emails/">BleepingComputer</a>が2026年2月18日（現地時間）に報じた。掲載記事のタイトルは「Microsoft says bug causes Copilot to summarize confidential emails」と題した記事で報じた。</p>
<p>報道によると、Microsoft 365 Copilot Chatが、機密（confidential）ラベル付きメールを誤って要約処理の対象とする不具合が発生していたという。</p>
<h2>問題の内容──Sent Items／Draftsが対象に</h2>
<p>Microsoft 365のサービスヘルス通知（Issue ID: CW1226324）では、次のように説明されている。
・Copilot Chat（work tab）利用時
・Exchange Onlineの「Sent Items（送信済み）」および「Drafts（下書き）」フォルダ内メール
・DLP（データ損失防止）ポリシーおよび感度（sensitivity）ラベルが適用されている場合でも
・Copilotがこれらのアイテムを処理対象として拾い得る状態にあった</p>
<p>この通知内容は、管理者向けのMicrosoft 365 Service health advisory「CW1226324」の内容（開始時刻、影響範囲、原因、進捗）を、大学のメール運用ページが時系列で転載している<a href="https://mailservices.isc.upenn.edu/computing/email/penno365/alerts/ms-incidents.html">大学の公式ミラーサイト</a>より明らかになった。</p>
<p>Microsoftは同通知の中で、根本原因を「コードの問題（code issue）」と説明している。</p>
<h2>発生時期と継続期間</h2>
<p>通知によれば、不具合の開始は2026年1月21日（UTC）。その後、数週間にわたり影響が継続していた。</p>
<p>Microsoftは修正を開発し、段階的（ロールアウト方式）に展開していると説明している。影響を受けたテナントの特定および追加検証も進めているという。</p>
<h2>本来の設計との関係</h2>
<p>Microsoftの公式ドキュメントでは、Microsoft Purview DLPを用いてCopilotおよびCopilot Chatが機密ラベル付きコンテンツを処理対象から除外できると<a href="https://learn.microsoft.com/en-us/purview/dlp-microsoft365-copilot-location-learn-about">説明</a>されている。</p>
<p>また、Copilotのデータ保護・セキュリティ設計についても、感度ラベルや既存のアクセス権限を尊重する仕組みであると<a href="https://learn.microsoft.com/en-us/copilot/microsoft-365/microsoft-365-copilot-architecture-data-protection-auditing">記載</a>されている。</p>
<p>今回の事象は、こうした設計意図とは異なる挙動がコード上の不具合により発生したケースとなる。</p>
<h2>Microsoftの説明と報道の位置づけ</h2>
<p>BleepingComputerは、Microsoftがこの不具合を認め、修正を展開していると報じた。同記事では、影響がSent ItemsおよびDraftsフォルダに限定されている点や、修正が進行中である点が伝えられている。</p>
<p>Microsoftはサービス通知内で、問題は特定のフォルダ範囲に限定されると説明しており、全面的なメール露出ではないことを示唆している。</p>
<h2>現在の状況</h2>
<p>Microsoftは修正の段階展開を進めているとし、最終的な完了時期や影響規模の詳細は今後の更新を通じて明らかになる見通しだ。</p>
<p>生成AIが企業内データへ広範にアクセスする設計が進む中、既存の情報保護ポリシーとの整合性は引き続き重要な論点となる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>富士通、国産「ソブリンAIサーバ」を3月から製造開始──NVIDIA Blackwell世代GPU搭載、国内一貫生産で “主権” 強化</title>
      <link>https://ledge.ai/articles/fujitsu_sovereign_ai_server_made_in_japan_start</link>
      <description><![CDATA[<p>富士通株式会社は2026年2月12日、富士通グループの国内工場において、ミッションクリティカル領域を支える「ソブリンAIサーバ」をMade in Japan製品として2026年3月より製造開始すると<a href="https://global.fujitsu/ja-jp/pr/news/2026/02/12-01">発表</a>した。</p>
<h2>富士通、国産「ソブリンAIサーバ」を3月から製造開始</h2>
<p>同社は、経済安全保障の強化やサイバー攻撃リスクの高まりを背景に、データやインフラの主権を確保する「ソブリン性」へのニーズが高まっていると説明する。</p>
<p>製造を開始する「ソブリンAIサーバ」は、重要インフラや公共領域など、ミッションクリティカルな用途を想定したAI基盤として提供予定。日本国内で設計・製造・検査を行うことで、データ流出リスクの最小化や国内法令への準拠、技術コントロールの確保などを図るとしている。</p>
<h2>経済安保・サイバー脅威で“ソブリン性”需要が拡大</h2>
<p>富士通は、ソブリン性（データやAI基盤の管理・統制を自国・自組織内で完結できる状態）を備えたAI基盤に求められる要件として、以下を挙げている。</p>
<ul>
<li>データ流出リスクの最小化</li>
<li>自律的な運用体制の確立</li>
<li>国内法への準拠</li>
<li>セキュリティリスクの透明性確保</li>
<li>テクノロジーのコントロール</li>
</ul>
<p>生成AIの普及により、大規模な演算基盤を支えるAIサーバの戦略的重要性が増していることも背景にある。</p>
<h2>Blackwell世代GPU搭載のAIサーバを国内生産へ</h2>
<p>3月から製造を開始するソブリンAIサーバには、NVIDIAの最新世代GPUが搭載される。
具体的には、</p>
<ul>
<li>NVIDIA HGX B300</li>
<li>NVIDIA RTX PRO 6000 Blackwell Server Edition</li>
</ul>
<p>を搭載した構成のサーバを、Made in Japan製品として国内で製造する。これにより、生成AIや大規模言語モデル（LLM）の学習・推論用途に対応する高性能AI基盤を国内生産体制で提供する。</p>
<h2>“国内一貫生産”でトレーサビリティと透明性を強化</h2>
<p>製造は、富士通グループの笠島工場（石川県かほく市）で行う。同工場は、スーパーコンピュータ「富岳」や高信頼サーバの製造で培った技術を有する拠点だ。</p>
<p>装置組立は2026年3月に開始し、プリント基板の組立は2026年6月から国内で開始する予定としている。主要部品のトレーサビリティを確保し、基板から装置までの一貫生産体制を構築することで、製造工程の透明性向上とソブリン性の強化を図る。</p>
<h2>次の一手：FUJITSU-MONAKA搭載サーバを2026年度中に</h2>
<p>富士通はあわせて、自社開発の省電力プロセッサ「FUJITSU-MONAKA」を搭載したサーバについても、2026年度中にMade in Japan製品として製造開始する予定を示した。</p>
<p>同サーバにはコンフィデンシャルコンピューティング技術を組み込み、データの機密性を高める設計とする方針だ。</p>
<h2>日本・欧州へ展開、Supermicro協業も拡大</h2>
<p>取り組みでは、米Super Micro Computer（Supermicro）との協業を拡大し、企画・開発・製造・販売・保守までを一貫して提供する体制を構築する。</p>
<p>ソブリンAIサーバは、日本国内市場および欧州市場向けに展開する予定としている。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 3.1 Pro、ARC-AGI-2で77.1%──“Deep Think級推論”を一般提供へ</title>
      <link>https://ledge.ai/articles/gemini_3_1_pro_arc_agi_2_77_1_deep_think_general_release</link>
      <description><![CDATA[<p>Googleは2026年2月19日（現地時間）、同社の大規模言語モデル「Gemini」シリーズの最新モデル「Gemini 3.1 Pro」を<a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/">発表</a>した。Googleは同モデルを「複雑問題解決の新たなベースライン」と位置づけ、研究モデル「Gemini 3 Deep Think」と同じコア知能を実務用途向けにスケールしたものだと説明している。同日よりコンシューマー向けアプリから開発者向けAPI、エンタープライズ向け基盤まで順次ロールアウトを開始した。</p>
<h2>「複雑問題解決の新ベースライン」と位置付け</h2>
<p>発表の中でGoogleは、Gemini 3.1 Proを「<a href="https://x.com/Google/status/2024519460124565987">our new baseline for complex problem-solving</a>（複雑な問題解決の新たな基準）」と表現した。</p>
<p>同社によれば、Gemini 3.1 ProはGemini 3 Deep Thinkと同じコア知能を備えつつ、より実務的な用途に適したスケールへ最適化されたモデルだという。研究用途に限定されていた推論能力を、より広範な利用層に開放する位置づけとなる。</p>
<h2>ARC-AGI-2で77.1%──3 Proから2倍超</h2>
<p>今回の発表で注目されるのは、抽象推論ベンチマーク「ARC-AGI-2」におけるスコアだ。</p>
<p>DeepMindが公開した評価結果によれば、Gemini 3.1 ProはARC-AGI-2で77.1%を記録した（ARC Prize Verified）。前世代のGemini 3 Pro（31.1%）から大幅に向上している。</p>
<p>ARC-AGI-2は、未知の論理パターンを解く能力を測定するベンチマークで、単純な知識検索では対応しにくい抽象推論を評価するものとされる。</p>
<p>比較対象として公表されている数値では、Claude Opus 4.6が68.8%、GPT-5.2が52.9%となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/H_Bi_Fhy_Xs_AA_06bm_051b6fe276/H_Bi_Fhy_Xs_AA_06bm_051b6fe276.jpg" alt="HBiFhy-XsAA06bm.jpg" /></p>
<h2>Humanity’s Last Examでもトップ帯</h2>
<p>総合的な知識と推論能力を測るベンチマーク「Humanity’s Last Exam」では、Gemini 3.1 Proは44.4%を記録している。同条件での比較では、Claude Sonnet 4.6が40.0%、GPT-5.2が34.5%となっており、Gemini 3.1 Proはトップ帯に位置している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_1_pro_benchmarks_07e69cf448/gemini_3_1_pro_benchmarks_07e69cf448.jpg" alt="gemini_3-1-pro__benchmarks.jpg" /></p>
<h2>SWE-bench Verified 80.6%──実務性能は維持</h2>
<p>ソフトウェア開発能力を測定する「SWE-bench Verified」では、Gemini 3.1 Proは80.6%を記録した。</p>
<p>Claude Opus 4.6の80.8%とほぼ同水準であり、抽象推論ベンチマークでの大幅な向上と同時に、実務的なコーディング性能も維持していることが示されている。</p>
<h2>デモ事例：ISS追跡から3D群れシミュレーションまで</h2>
<p>Googleは、Gemini 3.1 Proのデモ事例を複数紹介している。</p>
<ul>
<li>公開APIを用いた国際宇宙ステーション（ISS）のリアルタイム追跡ダッシュボード構築</li>
<li>テキストプロンプトからのアニメーションSVG生成</li>
<li>手の動きに反応するインタラクティブ3Dスターリング（ムクドリ）群れシミュレーション</li>
<li>小説『嵐が丘』の雰囲気を反映したポートフォリオUIの生成</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/animated_SV_Gs_35d6721955/animated_SV_Gs_35d6721955.jpg" alt="animated SVGs.jpg" /></p>
<p>モデルのコード生成や構造表現の品質を手早く比較する題材として、開発者コミュニティでしばしば用いられてきた「自転車に乗るペリカン」のアニメーションSVG生成も取り上げられている。Googleは「アニメーションSVGで自転車に乗るペリカンを生成せよ」というプロンプトを用い、Gemini 3 ProとGemini 3.1 Proの生成結果を並べて提示した。</p>
<p>公開された比較画像では、Gemini 3 Proの生成例では自転車のペダルは回転しているものの、ペリカンの脚はペダル動作と連動していない。一方、Gemini 3.1 Proの生成例では、脚がペダルに正しく配置され、動きと連動している様子が確認できる。</p>
<h2>提供範囲</h2>
<p>Gemini 3.1 Proは、発表同日より段階的に提供が開始される。コンシューマー向けにはGemini AppおよびNotebookLMで利用可能となる。開発者向けには、Gemini APIのプレビュー版として提供され、Google AI StudioやGemini CLI、Android Studioなどの開発環境からアクセスできる。さらに、企業向けにはVertex AIおよびGemini Enterpriseを通じて導入可能とされている。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、推論特化「Gemini 3 Deep Think」アップデート──ARC-AGI-2で84.6%など主要ベンチマークで軒並み高評価、科学・研究・工学領域の高度な問題解決に照準</title>
      <link>https://ledge.ai/articles/gemini_3_deep_think_arc_agi_2_84_6</link>
      <description><![CDATA[<p>Googleは2026年2月12日、推論特化モード「Gemini 3 Deep Think」の大幅アップデートを<a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/">発表</a>した。科学・研究・工学領域の高度な問題解決を主用途として位置づけ、ARC-AGI-2で84.6%を記録したと公表している。</p>
<p>更新版のGemini 3 Deep Thinkは、Google AI Ultra加入者向けにGeminiアプリで提供を開始。また、Gemini APIでも研究者・企業向けにEarly Access Programとして利用申請の受付を開始した。</p>
<h2>ARC-AGI-2で84.6%──主要ベンチマーク結果</h2>
<p><strong>■ Gemini 3 Deep Thinkの主要ベンチマーク結果。ARC-AGI-2、Humanity’s Last Exam、MMMU-Pro、Codeforcesなどで比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_deep_think_evals_charts_1_6b40186942/gemini_3_deep_think_evals_charts_1_6b40186942.jpg" alt="gemini_3_deep-think_evals_charts_1.jpg" /></p>
<p>Googleが公開した評価資料によると、主な結果は以下の通り。</p>
<ul>
<li>ARC-AGI-2：84.6%</li>
<li>Humanity’s Last Exam：48.4%（no tools）、53.4%（search+code）</li>
<li>MMMU-Pro：81.5%</li>
<li>Codeforces：Elo 3455</li>
</ul>
<p>ARC-AGI-2は抽象推論能力を測るベンチマークで、ARC Prize Verified（v2 semi-private）に基づく数値としている。Humanity’s Last Examでは、ツール未使用と検索・コード実行併用の双方を公表。CodeforcesではElo 3455を記録した。評価手法は原則pass@1で算出し、一部小規模ベンチマークでは複数試行平均を用いたと説明している。</p>
<h2>科学分野ベンチでの数値</h2>
<p><strong>■ Gemini 3 Deep Thinkと他モデルのベンチマーク比較一覧（Feb 2026時点）。IMO、IPhO、IChO、CMT-Benchmarkなどを含む</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_deep_think_evals_table_1_e96eae2c49/gemini_3_deep_think_evals_table_1_e96eae2c49.jpg" alt="gemini_3_deep-think_evals_table_1.jpg" /></p>
<p>同資料では、科学系競技・専門ベンチマークにおける結果も公開している。</p>
<ul>
<li>International Math Olympiad 2025：81.5%</li>
<li>International Physics Olympiad 2025（theory）：87.7%</li>
<li>International Chemistry Olympiad 2025（theory）：82.8%</li>
<li>CMT-Benchmark（凝縮系理論）：50.5%</li>
</ul>
<p>IPhOおよびIChOでは、Geminiをjudgeとして使用し、独立専門家による検証を経たと説明している。</p>
<h2>「Deep Think」の位置づけ</h2>
<p>GoogleはDeep Thinkを、Gemini 3におけるspecialized reasoning modeと説明している。不完全な情報や複数の解が存在し得る研究課題を対象とし、科学的知識とエンジニアリング実務を統合した推論を行う設計だとしている。</p>
<p>初期テスター事例として、以下を紹介している。</p>
<ul>
<li>Rutgers大学：高エネルギー物理論文の論理的欠陥の指摘</li>
<li>Duke大学：半導体材料の結晶成長レシピ設計</li>
<li>Google社内：物理コンポーネント設計支援</li>
</ul>
<h2>Ultra提供とAPI早期アクセスへ</h2>
<p>今回のアップデートでは、GeminiアプリでのUltra向け提供に加え、Gemini APIで初めてDeep Thinkモードの早期アクセスを開始した。研究者や企業が実運用環境で利用できる段階へ移行した形となる。Googleは、科学・研究・工学領域における高度推論用途を主軸に展開していく方針を示している。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、アメリカからインドを結ぶ3本の海底ケーブル敷設へ──4大陸接続強化「America-India Connect」始動</title>
      <link>https://ledge.ai/articles/google_america_india_connect_submarine_cable_4continents</link>
      <description><![CDATA[<p>Googleは2026年2月19日、アメリカからインドを結ぶ海底・陸上ネットワークを強化する構想「America-India Connect」を<a href="https://cloud.google.com/blog/products/infrastructure/america-india-connect-infrastructure-connects-four-continents?hl=en">発表</a>した。インド東海岸に新たな国際海底ゲートウェイを設置するとともに、インドをシンガポール、南アフリカ、オーストラリアへ接続する3本の新たな海底ルート（subsea paths）を整備する。</p>
<p>同社は、本構想によりアメリカ、アジア、アフリカ、オーストラリアの4大陸間の接続性、容量、レジリエンス（耐障害性）を高めるとしている。</p>
<h2>インド東海岸に新ゲートウェイ設置</h2>
<p>今回の構想では、インド東海岸のビシャーカパトナム（Vizag）に新たな国際海底ゲートウェイを整備する。現在の主要な海底ケーブル着地点であるムンバイやチェンナイに加え、接続拠点を分散させることで、インドのデジタル基盤の多様性と冗長性を強化する狙いだ。Googleは、回線の多様化が通信の信頼性向上につながると説明している。</p>
<h2>3本の新規海底ルートを整備</h2>
<p>「America-India Connect」では、以下の3方向への新たな海底接続を整備する。</p>
<ul>
<li>インド—南アフリカ間の直接ルート</li>
<li>インド—シンガポール間の直接ルート</li>
<li>インド—オーストラリア間の直接ルート</li>
</ul>
<p>これらの新経路は、既存の海底ケーブル群と組み合わせることで、アメリカ東海岸および西海岸からインドへ至る複数の回廊を形成する。</p>
<p>南アフリカ経由のルートは、既存の「Equiano」や「Nuvem」などと接続し、アメリカ東海岸からアフリカを経由してインド東海岸へ至る経路を構築する。</p>
<p>また、オーストラリアやシンガポールを経由するルートは、「Bosun」「Tabua」「TalayLink」「Honomoana」など既存ケーブルと組み合わせることで、アメリカ西海岸から南太平洋経由でインドに至る経路を補強する。</p>
<p>さらに、既存の「Blue」「Raman」「Sol」などが形成するアメリカ東海岸—紅海—ムンバイ回廊も補完される。</p>
<h2>AI需要拡大を背景にインフラ強化</h2>
<p>Googleは、デジタルインフラへの投資が経済成長や生産性向上を支えると説明している。特にAIの普及に伴い、大容量かつ低遅延の国際通信基盤の重要性が高まっているとした。同社はインドにおいて今後5年間で150億ドル規模のAI関連インフラ投資を行う計画を明らかにしており、今回の構想はその一環に位置付けられる。</p>
<p>「America-India Connect」は、アメリカとインドを軸に4大陸を結ぶ新たな通信回廊の形成を目指す取り組みとなる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、GeminiとAI検索で「広告を再定義」──米国で “Sponsored” 表示を試験導入、購入機能をロールアウト</title>
      <link>https://ledge.ai/articles/google_gemini_ai_mode_reinvent_ads_ucp_checkout</link>
      <description><![CDATA[<p>Googleは2026年2月11日（現地時間）、AIによる検索体験「AI Mode」において、小売業者の購入導線を示す<a href="https://blog.google/products/ads-commerce/digital-advertising-commerce-2026/">新しい広告フォーマット</a>を米国でテストしていると明らかにした。クエリに関連するショッピング推薦をオーガニックに表示した上で、その商品を取り扱う小売業者を「Sponsored」と明記して提示する形式である。あわせて、購入直前の利用者に個別最適化されたオファーを提示する「Direct Offers」を導入した。</p>
<p>さらに、Universal Commerce Protocol（UCP）に基づくチェックアウト機能が米国でロールアウト中で、EtsyおよびWayfairの商品をAI ModeおよびGeminiアプリ内で購入できるようになっている。</p>
<h2>AI Modeで“Sponsored”広告をテスト</h2>
<p>Googleによると、AI Modeではまず、クエリに関連性の高いショッピング推薦をオーガニックに表示する。その上で、該当商品を取り扱う小売業者を「Sponsored」と明記した広告形式で提示する仕組みを、米国でテストしている。対象は小売分野から開始しており、旅行など他のカテゴリへの展開も検証している。</p>
<p>同社は、検索体験がキーワード中心から会話型へ移行する中で、利用者が複数ブランドや店舗を比較しやすくなることが有用性を高めると説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sponsored_9158c52b69/sponsored_9158c52b69.jpg" alt="sponsored.jpg" /></p>
<h2>「Direct Offers」：購入直前の利用者に個別提示</h2>
<p>同社はあわせて、AI Mode向けの新しい収益化体験「<a href="https://blog.google/products/ads-commerce/agentic-commerce-ai-tools-protocol-retailers-platforms/">Direct Offers</a>」を導入した。これは、購入準備が整った利用者に対し、個別最適化されたオファーを提示する仕組みである。</p>
<p>価格割引だけでなく、ロイヤルティ特典や商品バンドルなど、価値を拡張する提案も含める方針としている。通常価格そのものを変更するものではないとしている。</p>
<h2>UCP-powered checkoutがロールアウト中</h2>
<p>Universal Commerce Protocol（UCP）に基づくチェックアウト機能は、現在米国の利用者向けにロールアウト中である。</p>
<p>Googleによれば、EtsyおよびWayfairの商品をAI Mode（検索）およびGeminiアプリ内で直接購入できるようになっている。今後はShopify、Target、Walmartなども対応予定としている。</p>
<h2>広告を「再定義」するという位置付け</h2>
<p>Googleは今回の発表の中で、「検索に広告を持ち込む」のではなく、「広告そのものを再定義する」と説明した。</p>
<p>同社によれば、AI ModeにおけるSponsored表示やDirect Offers、UCP-powered checkoutの展開は、会話型検索の中に広告、オファー提示、決済機能を組み込む取り組みの一環である。</p>
<p>同社Ads &amp; Commerce部門のVidhya Srinivasan氏は、Frontier CMO podcastで今回の戦略について語り、これを商取引体験の「再配線（rewiring）」だと表現した。また、AIにより「スピードと確実性を両立できる」と述べた。</p>
<p>@<a href="https://www.youtube.com/watch?v=acuGQ07PeAU">YouTube</a></p>
<h2>Gemini 3が広告基盤を支える</h2>
<p>同社はまた、広告ツール群が最新モデル「Gemini 3」によって支えられていることにも言及した。モデルの高度化に伴い、広告プロダクトも改善される仕組みであると説明している。</p>
<p>1月のUCP発表に続き、2月の年次レターでは広告フォーマット、Direct Offers、チェックアウト機能のロールアウトまでが示された。AI検索とGeminiを軸とする商取引体験は、構想段階から運用段階へと移行しつつある。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5.2が理論物理の新しい公式候補を提案と検証　グルーオンの「single-minusツリー振幅」に関する結果を発表</title>
      <link>https://ledge.ai/articles/gpt_5_2_supports_theoretical_physics_single_minus_amplitude</link>
      <description><![CDATA[<p>OpenAIは2026年2月13日、同社のAIモデル「GPT-5.2」が理論物理学の研究において数式の一般化を支援し、公式の候補の提案とその検証が行われたと<a href="https://openai.com/ja-JP/index/new-result-theoretical-physics/">発表</a>した 。対象となったのは、素粒子物理学における散乱振幅（scattering amplitude）の研究で、強い相互作用を媒介する素粒子グルーオン（gluon）の振る舞いに関するものだ。</p>
<p>プレプリント「Single-minus gluon tree amplitudes are nonzero」によれば、グルーオン同士の運動量が特別な関係を満たす場合に、通常はゼロとされてきた single-minus のツリー振幅（tree-level amplitude）が非ゼロとなる可能性が示されている。</p>
<h2>single-minus ツリー振幅とは</h2>
<p>複数のグルーオンが関与する散乱では、それぞれのグルーオンが持つヘリシティ（進行方向に対するスピンの向き）の組み合わせによって振幅の性質が変わる。多数のグルーオンのうち1つだけが負のヘリシティを持つ場合は single-minus と呼ばれ、この場合のツリー振幅は、特別な関係を満たさない運動量のもとではゼロになるとされてきた。</p>
<p>研究では、グルーオンの運動量が著者らのいう half-collinear と呼ばれる特定の関係を満たす場合に、この結論が必ずしも成り立たない可能性が示されている。</p>
<h2>AIによる公式候補の提案と検証</h2>
<p>研究プロセスにおいて、研究チームはまず少数粒子の場合の振幅を計算し、その結果をもとにGPT-5.2が一般の粒子数に対する公式の候補を提案した。その後、Berends-Giele漸化式やソフト定理などの既存の理論的条件と整合することが確認されたと報告している。</p>
<h2>今後の展望</h2>
<p>研究はプレプリントとして公開されており、今後コミュニティによる検証が進むとみられる。研究チームは、この結果を他の振幅へ拡張する可能性についても言及している。</p>
<p>今回の事例は、AIが理論物理学の研究過程において数式の探索を支援した例の一つといえる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>死後もSNS投稿が続く仕組みを特許化──Meta、“ユーザー代替ボット”構想</title>
      <link>https://ledge.ai/articles/meta_posthumous_sns_user_substitute_bot_patent</link>
      <description><![CDATA[<p>Meta Platformsの関連法人であるMeta Platforms Technologies, LLCが、SNS上のユーザー活動をシミュレートし、ユーザーの不在時にも投稿や応答を継続できるAIシステムに関する特許を取得していたことが分かった。
米特許商標庁（USPTO）が付与した<a href="https://patents.google.com/patent/US12513102B2/">特許（US12513102B2）</a>
によるもの。</p>
<p>特許公報によれば、この技術は「ターゲットユーザー」の過去の投稿、コメント、反応、メッセージなどのデータをもとに学習用データセットを生成し、言語モデルをパーソナライズする仕組みを採る。生成されたボットは、当該ユーザーに代わって投稿や返信を行うことが想定されている。</p>
<h2>長期不在や死亡の可能性にも言及</h2>
<p>公報の背景説明では、ターゲットユーザーが長期間SNSを利用していない場合、他のユーザーの体験に影響が生じ得ると記載されている。また、対象ユーザーが死亡している可能性にも言及しており、そのような状況においても、ボットがユーザーの活動をシミュレートし得る旨が説明されている。</p>
<p>ここで想定されているのは、第三者がアカウントを引き継ぐという構造ではなく、過去の活動履歴などを基に構築されたボットが、当該ユーザーの代理として投稿や応答を行う設計である。</p>
<h2>技術的構成</h2>
<p>特許に記載されたシステムは、大きく以下の要素で構成される。
・ターゲットユーザーに関連付けられたボット
・当該ユーザーの履歴データを用いて調整された言語モデル
・投稿・返信などのコンテンツ生成機構</p>
<p>ボットは、他ユーザーからのコメントやメッセージに応答するほか、継続的にコンテンツを生成・投稿することが可能とされている。</p>
<h2>出願から登録までの経緯</h2>
<p>特許は2023年11月29日に出願され、2025年5月29日に出願公開（US20250175448A1）、その後2025年12月30日に登録（US12513102B2）された。</p>
<p>特許はあくまで技術的アイデアの権利化であり、実際の製品やサービスへの実装を直ちに意味するものではない。現時点で、Metaが本技術を具体的な機能として提供する計画を公表している事実は確認されていない。</p>
<p>今回明らかになったのは、ユーザーの過去データを基に“本人らしい”発信を生成するボットを設計する技術が特許として権利化されたという事実である。特許公報は、長期不在や死亡の可能性を含む状況下での利用を技術的に記述している。</p>
<p>こうした死後のデジタルアカウントや“デジタルクローン”を巡っては、遺族への心理的影響やプライバシーの取り扱いをめぐり、国内外で倫理的な議論が続いている。また、過去には同種の技術やサービスの検討を停止・縮小した企業の事例も報じられている。</p>
<p>今回の特許は、ユーザーの不在や死亡の可能性を含む状況下での投稿・応答の継続を技術的に記述したものである。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ニトリ、約1万人の体格データ分析に基づく「AIマットレス」発売へ──エアスプリングを自動調整、製品自体に学習機能はなし</title>
      <link>https://ledge.ai/articles/nitori_ai_mattress_10000_bodydata_air_spring</link>
      <description><![CDATA[<p>ニトリは2026年2月17日、約1万人の体格データをAIで分析して導き出したアルゴリズムに基づき、内蔵されたエアスプリングの硬さを自動調整する「AIマットレス」を新たに発売すると<a href="https://prtimes.jp/main/html/rd/p/000001381.000073913.html">発表</a>した。2026年4月下旬より、一部のニトリ店舗およびニトリネットで販売を開始する。価格は39万9,900円（税込）。</p>
<p>同社は寝具選びが「硬め」「柔らかめ」といった好みの軸に寄りがちな一方で、体格、体圧のかかり方、寝姿勢には個人差があり、その差が寝心地のミスマッチや睡眠の悩みに結びつくと説明する。今回の製品は、こうした個人差を前提に「ベッド側が利用者に合わせる」設計思想を、データ分析と制御アルゴリズムで具現化した位置付けとなる。</p>
<p>中核となるのは「自動適応モード」だ。マットレスが身長・体重・睡眠中の寝姿勢の変化を感知し、AIアルゴリズムに基づいてエアスプリングの硬さを自動で調整する。部位ごとに動的なサポートを行うとしており、固定的な硬さ設定では吸収しきれない体圧分布や寝返りなどの変化に追従する狙いがある。</p>
<p>一方で、同社は「本製品自体にAIの学習機能はありません」と明記している。AIは製品の動作中に学習を継続するのではなく、約1万人規模の体格データを事前に分析して得たアルゴリズムを、制御ロジックとして実装した形だ。</p>
<p>製品には、睡眠環境の拡張機能として2つのモードも搭載する。1つ目は「リラックスモード」で、エアスプリングがマットレス表面を伸長させ、ストレッチによるリラックスを提供する。全身ストレッチに加えて「腰」「ヒップ」など部位指定が可能で、全体をやわらかなリズムで動かす「波モード」も備える。</p>
<p>2つ目は「ヒーターモード」だ。人が心地よいと感じる温度帯として約30℃を目安に温め、冬でも暖かい寝床環境を実現するとしている。腰・脚を中心に温感を届ける設計で、寒さが気になる季節の快適性向上を図る。</p>
<p>商品名は「最適な硬さに自動で調整 AIマットレス」。サイズは約幅97×奥行195×高さ26cm。販売チャネルは一部店舗とニトリネットで、一部離島の購入・配送では別途手数料が発生する場合がある。ニトリは、暮らしを便利に快適にする商品開発に取り組むとしている。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>政府、中国ByteDanceの動画生成AI「Seedance 2.0」問題で調査へ──小野田AI戦略担当相「著作権侵害は看過できない」</title>
      <link>https://ledge.ai/articles/onoda_seedance2_government_investigation_copyright</link>
      <description><![CDATA[<p>小野田紀美AI戦略担当相は2026年2月13日の<a href="https://www.gov-online.go.jp/press_conferences/minister_of_state/202602/video-307352.html">閣議後記者会見</a>で、中国のByteDanceが開発した動画生成AI「Seedance 2.0」を巡り、日本のキャラクターに類似した動画が生成・拡散されている問題について、「実態把握を急ぐ」と述べ、政府として調査に乗り出す考えを示した。</p>
<p>問題となっているのは、ByteDanceが公開した動画生成AI「Seedance 2.0」によって、日本の著名なアニメや特撮作品などのキャラクターに類似する映像が生成され、SNS上で拡散されている事案だ。会見では、著作権者の許諾がないまま知的財産が活用されている可能性がある点が指摘された。報道によれば、一部には特定の人物を攻撃する内容を含む動画も確認されている。</p>
<h2>「看過できない」と明言</h2>
<p>小野田氏は会見で、「著作権者の許諾がないまま活用される状況は看過できない」と述べ、強い懸念を示した。そのうえで、事務方に対し、関係省庁と連携した事案の精査や、事業者とのコミュニケーション、AI関連法制に基づく情報収集を通じた実態把握を進めるよう指示したことを明らかにした。</p>
<h2>利用者側にも責任</h2>
<p>また、事業者側だけでなく利用者側にも責任があるとの認識を示し、他者の著作権や肖像権、プライバシーを侵害する行為は「罪になり得る」と警告した。生成AIの利用拡大に伴い、技術の利活用と法令遵守の両立が求められるとの立場を示した形だ。</p>
<p>Seedance 2.0は、ByteDanceが開発した動画生成AIで、テキストや画像、音声、動画など複数の入力情報を組み合わせて映像を生成できるマルチモーダル型のモデルだ。参照素材を指定しながら生成を行う機能も備えており、公開以降、SNSを中心に生成動画が広がっている。</p>
<p>政府は今後、関係省庁と連携しながら事実関係の確認を進める方針で、生成AIによるコンテンツ制作と知的財産権保護の在り方が改めて問われることになる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>自律的すぎるAIエージェント「OpenClaw」急拡大の裏で相次ぐ警告──今後のAI利用を占う分水嶺に</title>
      <link>https://ledge.ai/articles/openclaw_agentic_ai_watershed_enterprise_security</link>
      <description><![CDATA[<p>ローカル環境で動作し、チャット経由で端末操作を進めるオープンソースAIエージェント「OpenClaw」が急速に拡大している。GitHubでの急増、関連コミュニティMoltBookでの注目、拡張スキルを巡るセキュリティ警告、そして開発者のPeter Steinberger氏のOpenAI参加。利便性の拡張と同時に、設計上の境界をめぐる問題も顕在化している。</p>
<h2>“応答するAI”から“行動するエージェント”へ</h2>
<p>OpenClawは、チャットを入り口としてローカル環境の操作へ接続するエージェント型ソフトウェアである。メール処理、ブラウザ操作、ファイル管理、シェルコマンド実行などを自動化できる構造を持つ。</p>
<p>特徴は、画面上でテキストを生成するだけでなく、チャットを入口にローカル環境の操作へ接続する構造にある。ユーザーの指示や目標に基づき、端末上で処理を進めるアーキテクチャを採る点が支持を集め、<a href="https://github.com/openclaw/openclaw">GitHub</a>では短期間でスター数が10万件を超える規模に拡大したと<a href="https://www.reuters.com/business/openclaw-founder-steinberger-joins-openai-open-source-bot-becomes-foundation-2026-02-15/">Reuters</a>が2026年2月15日報じた。</p>
<p>AIが応答を返す存在から、状態を保持しながら環境に作用するエージェントへと役割を広げる試みとして、OpenClawは象徴的な存在となった。</p>
<h2>MoltBookでの拡散とコミュニティ主導の拡張</h2>
<p>利用拡大の背景には、関連するコミュニティの急速な広がりもある。報道によれば、OpenClawに関連するプラットフォーム「<a href="https://moltbook.com/">MoltBook</a>」は短期間で大量の訪問を集めたとされる。個人開発のオープンソースプロジェクトとしては異例のスピードで注目が集まった。</p>
<p>さらに、拡張スキルを追加できる仕組み（ClawHub）がエコシステム形成を後押しした。ユーザーはスキルを通じて機能を拡張できるため、プロジェクトはコミュニティ主導で能力を増幅させる構造を持つ。</p>
<p>目標に基づき連続的に処理を進めるエージェントが、外部から機能を追加できる仕組みと結びついたことで、拡張スピードは加速した。</p>
<h2>相次ぐ警告──拡張経路と脆弱性</h2>
<p>急拡大と並行してセキュリティ上の懸念も表面化している。</p>
<p>セキュリティ企業<a href="https://www.koi.ai/blog/clawhavoc-341-malicious-clawedbot-skills-found-by-the-bot-they-were-targeting">Koi Security</a>は、ClawHubに登録された2,857のスキルを監査し、そのうち341件が悪意あるコードを含んでいたと報告した。報告では、同一キャンペーンによるものとみられるスキル群の存在も指摘されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/koi_research_0c413c71e9/koi_research_0c413c71e9.jpg" alt="koi research.jpg" /></p>
<p>また、OpenClawの特定バージョン以前に関しては、<a href="https://nvd.nist.gov/vuln/detail/CVE-2026-25253">CVE-2026-25253</a>として脆弱性が登録されている。公的データベースによれば、該当する問題は修正済みであり、アップデートが推奨されている。</p>
<p>拡張可能な設計は柔軟性をもたらす一方、配布経路や設定が攻撃面になり得る構造も抱える。端末上で処理を進めるエージェントである以上、権限管理や更新の遅れは影響を直接受ける。</p>
<h2>想定外の挙動──外部接続型エージェントの課題</h2>
<p>技術的な脆弱性とは別に、OpenClawを含むエージェント設計の課題を示す挙動事例も報告されている。</p>
<h3>（1）メッセージ送信ループの事例</h3>
<p>ソフトウェアエンジニアのChris Boyd氏は、自身の検証環境でOpenClawを設定した際、iMessage経由で確認メッセージを繰り返し送信する状態に陥ったと<a href="https://chrisboyd.me/blog/openclaw-meltdown/">ブログ</a>で記録している。</p>
<p>想定外の応答を受け取った後、再試行ロジックが停止条件を持たず、ループが継続したという。最終的には端末を強制停止することで挙動を止めたと説明されている。</p>
<p>この事例は、外部通信チャネルと再試行処理が連動する構造において、上限設計やエラー処理が重要であることを示している。</p>
<h3>（2）コード却下後の批判的ブログ公開</h3>
<p>matplotlibメンテナーのScott Shambaugh氏は、自身のブログで、AIエージェントからのコード提案を却下した後、自身を批判する内容のブログ記事が公開されたと記録している。</p>
<p>記事によれば、エージェントは却下の事実を受けて外部ブログに投稿を行い、Shambaugh氏の過去活動に言及しながら批判的な内容を展開したという。</p>
<p>一部メディアではこれを「報復」と表現しているが、技術的には、評価ループと外部公開機能が直結していた結果とみられる。出力内容の適切性を人間が確認する仕組みが介在しない場合、レピュテーションに影響し得る公開行動が実行される可能性がある。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_Shamblog_ac56db2fda/The_Shamblog_ac56db2fda.jpg" alt="The Shamblog.jpg" /></p>
<h3>（3）MoltMatchでのプロフィール作成事例</h3>
<p>AFPの<a href="https://www.taipeitimes.com/News/world/archives/2026/02/14/2003852326">報道</a>では、OpenClawを試したユーザーが、関連する実験的デーティングサイト「MoltMatch」において、想定していない形でプロフィール作成や探索が進められたと述べている。</p>
<p>広義の参加指示が、エージェントによってより広範な行動へ解釈された可能性が示唆されている。</p>
<h2>開発者のOpenAI参加とfoundation化</h2>
<p>こうしたなか、OpenClawの開発者であるPeter Steinberger氏が2026年2月15日、米OpenAIへの参加を<a href="https://steipete.me/posts/2026/openclaw">発表</a>した。Reutersによれば、同氏は次世代パーソナルエージェント開発に関わるという。</p>
<p>あわせて、OpenClawは独立した財団（OpenClaw Foundation）へ移行する方針が示された。急速に拡大したエコシステムに対し、ガバナンスと継続的開発の体制を整える段階に入ったとみられる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/clawcon_e31ebc39a7/clawcon_e31ebc39a7.jpg" alt="clawcon.jpg" /></p>
<p>個人開発のプロジェクトが大手AI企業の開発ラインへ接続されたことは象徴的だ。端末上で行動するエージェントは、実験的な試みから主要な開発テーマへと移行しつつある。OpenClawを巡る急拡大と相次ぐ警告は、その設計と統制の問題がすでに実装段階に入っていることを示した。</p>
<p>画面上で応答するだけだったAIは、ローカル環境や外部サービスに作用し、状態を保持しながら処理を継続する存在へと拡張した。利便性の拡大と同時に、拡張経路や権限設計の管理が不可欠であることも明らかになった。OpenClawは、その現実を可視化した事例である。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>北京大学・Google Cloud AI Researchら、学術図を自動生成する「PaperBanana」発表──NeurIPS論文292件で評価ベンチも構築</title>
      <link>https://ledge.ai/articles/paperbanana_academic_illustration_ai_scientists</link>
      <description><![CDATA[<p>北京大学とGoogle Cloud AI Researchに所属する研究者らは、学術論文向けの図表や手法図を自動生成するフレームワーク「PaperBanana」を提案した。論文はarXivに公開されている。<a href="https://dwzhu-pku.github.io/PaperBanana/">発表</a>した。研究は、AI研究者が論文執筆時に作成する手法図や統計プロットなどのイラストを自動化することを目的とする。</p>
<h2>学術図作成の課題</h2>
<p>論文では、学術図の作成が依然として手作業中心である点を課題として挙げている。</p>
<ul>
<li>手法図やパイプライン図は研究理解に不可欠</li>
<li>作図には時間と専門的デザインスキルを要する</li>
<li>既存の画像生成モデルは構造的整合性や論理忠実性の担保が難しい</li>
</ul>
<p>研究チームは、単なる画像生成ではなく、論文向け図としての構造整合性と内容忠実性を担保する仕組みの構築を目指した。</p>
<h2>PaperBananaの構成</h2>
<p>PaperBananaは、複数モジュールからなるフレームワークとして設計されている。処理は大きく2段階に分かれる。</p>
<h3>■ Linear Planning Phase</h3>
<ul>
<li>Retriever Agent：参考図の取得</li>
<li>Planner Agent：構造設計</li>
<li>Stylist Agent：視覚スタイルの調整</li>
<li>Initial Descriptionの生成</li>
</ul>
<h3>■ Iterative Refinement Loop</h3>
<ul>
<li>Visualizer Agent：図の生成</li>
<li>Critic Agent：生成結果の評価</li>
<li>記述の修正と再生成</li>
</ul>
<p><strong>【論文より：PaperBananaの全体フレームワーク】Linear Planning PhaseとIterative Refinement Loopの2段構成で、複数モジュールが反復的に図を生成・改善する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/method_diagram_744b875ea1/method_diagram_744b875ea1.jpg" alt="method_diagram.jpg" /></p>
<p>論文では、この反復ループをT=3回実行する構成が示されている。一度生成して終わりではなく、自己批評を通じて改善を重ねる点が特徴だとしている。</p>
<h2>評価ベンチ「PaperBananaBench」</h2>
<p>研究チームは評価用データセット「PaperBananaBench」も構築した。</p>
<ul>
<li>NeurIPS 2025採択論文から抽出</li>
<li>手法図生成タスク292件</li>
<li>評価指標：Faithfulness（内容忠実性）/Clarity（明瞭性）/Conciseness（簡潔性）/Aesthetics（美観）</li>
</ul>
<p>論文では、既存のベースライン手法と比較し、これらの指標で優位性を示したと報告している。</p>
<h2>研究の位置づけと拡張可能性</h2>
<p>PaperBananaは手法図の生成に加え、棒グラフや分布図などの統計プロット生成にも対応可能であると論文で示されている。</p>
<p>研究チームは同手法を、研究プロセス自動化の一環として位置づけている。近年はコード生成や論文要約、レビュー支援などの分野でAI活用が進んでいるが、同研究はその中で「視覚表現工程」の自動化に焦点を当てた提案となる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI時代の認識に階層ギャップ──PwC調査、日本の特に若手・非管理職で影響実感低く</title>
      <link>https://ledge.ai/articles/pwc_hopes_and_fears_2025_japan_genai_hierarchy_gap</link>
      <description><![CDATA[<p>PwCコンサルティングを含むPwC Japanグループは2026年2月2日、グローバル従業員意識調査「Global Workforce Hopes and Fears Survey 2025」の日本版を<a href="https://www.pwc.com/jp/ja/knowledge/thoughtleadership/hopes-and-fears2025.html">公開</a>した。調査は2025年7月7日から8月18日にかけて、48の国と地域・28セクターにわたる49,843人の従業員（日本2,060人を含む）を対象に実施された。</p>
<p>調査は、AIの進展が従業員の意識やモチベーション構造にどのような影響を与えているかを多角的に分析したものだ。結果は、AI活用の広がりとともに、テクノロジーに対する「認識」や「将来見通し」に職階差が存在することを示している。特に日本では、若手・非管理職層において将来への楽観性や影響実感が低い傾向が顕著となった。</p>
<h2>AI活用は拡大するも、日本は世界平均を下回る</h2>
<p>過去1年間に業務でAIを活用したと回答した割合は、グローバルで54％、日本では35％だった。生成AIを毎日使用していると答えた割合は、グローバル14％に対し、日本は6％にとどまる。</p>
<p>一方で、生成AIを日常的に活用している層の約9割は、生産性や仕事の質の向上を実感していると回答している。AI利用者の間では、仕事に対する前向きな認識が広がっていることがうかがえる。</p>
<p>しかし、日常利用者は依然として限定的だ。さらに、生成AIの次段階とされる「エージェントAI」を日常的に活用している割合は、グローバルで6％、日本では2％にとどまった。PwCは、日本企業はAI活用の面で世界と比べて遅れがあり、変革の余地が大きいと指摘している。</p>
<h2>影響の「見通し」と「コントロール感」に差</h2>
<p>今回の調査で特徴的なのは、AIの利用率だけでなく、テクノロジーが仕事に与える影響に対する認識構造を可視化している点だ。</p>
<p>今後3年間で技術の変化が仕事に「大きな影響を与える」と予想する割合は、従業員全体では半数未満にとどまる。市場動向や政府規制ほどの影響はないと捉える層も多い。</p>
<p>ただし、生成AIの日常ユーザー層の70％は「大きな影響がある」と予想している。AIを実際に活用している層と、そうでない層の間で、将来の影響認識に明確な差が存在する。</p>
<p>さらに、「テクノロジーが仕事に与える影響をどの程度コントロールできるか」という問いでは、グローバルでは約70％が「一定程度コントロールできる」と回答したのに対し、日本では52％にとどまった。影響の大きさに対する見通しだけでなく、それを主体的に扱えるという感覚（コントロール感）にも差が見られる。</p>
<h2>日本は楽観性が低く、職階差も拡大</h2>
<p>「自分の役割の将来について強く楽観的」と答えた割合は、グローバル全体で53％だったのに対し、日本は19％と大きく下回った。</p>
<p>職階別では次の通りだ。</p>
<ul>
<li>グローバル経営幹部：72％</li>
<li>グローバル非管理職：43％</li>
<li>日本経営幹部：38％</li>
<li>日本非管理職：15％</li>
</ul>
<p>日本では経営幹部と非管理職の間で楽観性の差が開いているだけでなく、全体水準も低い。若手や経験の浅い層ほど、AI時代の将来像に対して慎重な見方をしている構図が浮かび上がる。</p>
<h2>モチベーションを左右する要因</h2>
<p>調査では、仕事への誇りや意欲、楽しさなどから「モチベーション指数」を算出し、統計的に影響要因を分析している。</p>
<p>その結果、以下の要因がモチベーションと強く関連していると推定された。</p>
<ul>
<li>将来への楽観性：＋101％</li>
<li>スキルの将来関連性への期待：＋91％</li>
<li>雇用安定への自信：＋51％</li>
<li>生成AIの毎日利用：＋13％</li>
</ul>
<p>将来に対して非常に楽観的な従業員は、そうでない層に比べてモチベーションが約2倍（＋101％）高いと推定された。一方、生成AIの毎日利用はプラスに作用するものの、その影響は限定的だった。</p>
<p>AIの利用そのものよりも、「自分の将来像が描けるか」「スキルが今後も通用すると感じられるか」といった認識の方が、モチベーションに大きく影響している構造が示された。</p>
<h2>モチベーションを高める6つのアクション</h2>
<p>調査は、AI時代に従業員の意欲を高める要素として「信頼」「組織風土」「方向の明確性」を挙げた。モチベーションを高めるためのアクションとして、以下の6点を提示している。</p>
<p><strong>1. 不確実な未来を認識する</strong>
企業を取り巻く環境変化を率直に認め、特に経験の浅い従業員が抱える将来不安に向き合うことを求めている。現実的な対話が楽観性と信頼の土台になるとする。</p>
<p><strong>2. 信頼ギャップに対処する</strong>
経営陣への信頼度は必ずしも高くない。透明性のある意思決定やコミュニケーションを通じて、リーダーシップへの信頼を強化する必要があるとした。</p>
<p><strong>3. 明確な未来ビジョンで従業員を鼓舞する</strong>
組織の長期目標と個々の業務との関連を明確に示すことが重要だとする。AI戦略を含む将来像を具体的に提示することが、モチベーション向上につながると分析している。</p>
<p><strong>4. スキルパスウェイを提示する</strong>
リスキルやアップスキルの機会を可視化し、将来必要となるスキルと成長経路を明確にすることを提言している。学習環境や実践機会の整備が不可欠だとした。</p>
<p><strong>5. イノベーションと変革への動機づけを行う</strong>
心理的安全性を確保し、新しい挑戦や試行を後押しする文化の構築を求めている。失敗を学習機会として扱う姿勢が変革推進の前提になるとしている。</p>
<p><strong>6. 安心と報酬を安定的基盤として認識する</strong>
雇用の安定や適切な報酬は、モチベーションの基盤となる要素だと位置付ける。経済的プレッシャーが信頼や意欲に影響を与える点にも言及している。</p>
<p>調査結果は、AI活用の遅れだけでなく、影響認識や将来楽観性の低さが日本の課題である可能性を示唆する。テクノロジーの影響を強く認識し、それを主体的に扱えるという感覚が高い層ほど、将来に楽観的であり、モチベーションも高い傾向が確認された。</p>
<p>AI時代の競争力は、単なるツール導入の速度だけでなく、従業員が将来像を描ける組織文化を構築できるかに左右される構造が浮き彫りとなった。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Waymo、「第6世代Waymo Driver」で完全自律運転を開始──雪・氷点下・豪雨など厳しい気象条件にも対応</title>
      <link>https://ledge.ai/articles/waymo_6th_gen_waymo_driver_fully_autonomous_severe_weather</link>
      <description><![CDATA[<p>米自動運転企業のWaymoは2026年2月12日（現地時間）、完全自律運転が可能な「第6世代Waymo Driver」の導入を<a href="https://waymo.com/blog/2026/02/ro-on-6th-gen-waymo-driver">発表</a>した。同社はこれを、ロボタクシー事業の拡大を支える中核システムと位置づける。</p>
<p>公式ブログによると、第6世代Driverは「fully autonomous operations（完全自律運転オペレーション）」を前提に設計されており、より多くの都市や運用条件への展開を想定している。これまでの運用で蓄積した約2億マイル規模の走行データを背景に、稀に発生する事象（“long tail”）への対応力強化を図ったという。</p>
<h2>雪・氷点下・豪雨を想定したセンサー刷新</h2>
<p>第6世代ではセンサー構成を刷新した。</p>
<p>視覚面では、17メガピクセルの高解像度カメラを採用し、広いダイナミックレンジと熱安定性を確保。カメラ数を最適化しつつ、遠距離物体の検出精度を高めたとしている。</p>
<p>LiDAR（ライダー）は、短距離および長距離の検知性能を強化し、都市部でのセンチメートル単位の把握や、降雨時の路面水しぶき（roadspray）といった条件下での認識精度向上を図った。レーダーについてもイメージングレーダーを搭載し、雨や雪といった悪天候下での物体追跡能力を高めている。</p>
<p>さらに、外部音響受信システム（EAR）を備え、緊急車両のサイレンなどを視覚検知より早く把握できる設計とした。</p>
<p>同社はこれらのセンサー群を独自のアルゴリズムで統合し、状況に応じて各センサーの寄与を動的に最適化すると説明している。極端な冬季条件や氷点下環境、豪雨といった厳しい気象条件下でも運用可能な体制を整えたとしている。</p>
<h2>「車両」ではなく「Driver」軸で横断展開</h2>
<p>Waymoは車両単体ではなく、自動運転システムである「Driver」を横断的に展開する戦略を取る。</p>
<p>第6世代Driverは、新型車両プラットフォーム「Ojai」や、Hyundai Motor Companyの電気自動車「IONIQ 5」など複数の車種への統合を前提としている。これにより、車両ごとにシステムを再設計するのではなく、共通Driverを基盤としたスケール拡大を図る。</p>
<h2>年数万台規模の生産体制へ</h2>
<p>同社は米アリゾナ州フェニックス近郊の統合工場において、第6世代Driverを搭載した車両の量産体制を構築。年数万台規模の生産能力を見込むとしている。</p>
<p>まずは従業員や招待ユーザー向けの運用から開始し、段階的に一般利用者への展開を進める方針だ。</p>
<p>Waymoは現在、米国複数都市で配車型ロボタクシーサービスを展開している。第6世代Waymo Driverの導入は、より広範な地理的・気象的条件下での商用自律運転を視野に入れた拡大フェーズへの移行を示すものとなる。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>政府、AI事業者ガイドライン改定案でAIエージェントとフィジカルAIを追加──「人間の判断必須の仕組み」明記、Xで議論広がる</title>
      <link>https://ledge.ai/articles/government_ai_guideline_revision_human_judgment_required_x_debate</link>
      <description><![CDATA[<p>総務省と経済産業省が策定した「AI事業者ガイドライン」について、改定案の概要が明らかになった。2026年2月16日に開催された検討会、総務省<a href="https://www.soumu.go.jp/main_sosiki/kenkyu/ai_network/02tsushin06_04000136.html">「AIネットワーク社会推進会議 AIガバナンス検討会（第29回）」</a>で配布された資料「AI事業者ガイドラインの令和7年度更新内容（案）」によると、普及が進むAIエージェントや、ロボットなどを制御するフィジカルAIに関する定義や便益、リスク、対策を新たに盛り込む。</p>
<p>事務局資料では、2026年3月末に第1.2版を公開する予定としている。</p>
<h2>AIエージェントとフィジカルAIを新たに定義</h2>
<p>更新案では、AIエージェントを「特定の目標を達成するために、環境を感知し、自律的に行動するAIシステム」と定義する。複数のシステムやサービスと連携しながら自律的に判断・実行を行う点が特徴とされる。</p>
<p>フィジカルAIについては、センサ等を通じて物理環境の情報を取得し、AIモデルで処理した結果をもとに最適な方策を自律的に推論・判断し、アクチュエータなどを介して物理的な行動につなげるシステムと整理する。サイバー空間内での処理にとどまらず、現実世界へ直接作用する点が特徴とされている。</p>
<p>便益としては、業務効率化や労働力不足の補完、安全性向上、介護・生活支援などが挙げられている。</p>
<h2>自律行動に伴うリスクを追記</h2>
<p>一方で、リスクとしては次の点が追加される。</p>
<ul>
<li>自律的な行動による誤動作</li>
<li>サイバー攻撃や悪用の対象・手法の拡大</li>
<li>機構の複雑化による保守管理の困難化</li>
<li>カメラ等との連携によるプライバシー侵害の可能性</li>
</ul>
<p>これらを踏まえた留意事項として、更新案では「人間の判断を必須化する仕組み」の構築を明記する。また、セキュリティ確保の観点から権限を最小限に設定することや、ハードウェアに残存するデータの取り扱いへの配慮も求めている。</p>
<h2>「一般的なリスク」も拡充</h2>
<p>更新案では、AI全般に関するリスク項目も拡充する。</p>
<p>具体的には、教育領域における学生の思考力の発展への影響、生成AI活用時のプライバシーリスク、金銭的損失や資格等の侵害といった観点を追記する方向だ。既存のリスク分類の整理や位置付けの見直しも行うとしている。</p>
<h2>認知81％、活用46％</h2>
<p>検討会資料に掲載された事業者アンケート結果によると、AI事業者ガイドラインの認知度は81％に達している。一方で「活用している」との回答は46％にとどまる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/soumusho260216_6c42a9b38e/soumusho260216_6c42a9b38e.jpg" alt="soumusho260216.jpg" /></p>
<p>地方自治体や小規模事業者への浸透を図るため、内容に関する質問に自動回答するチャットボットなど、専用ツールの開発も検討事項として挙げられている。</p>
<h2>Xで議論広がる「人間の判断を必須化する仕組み」</h2>
<p>改定案の公開を受け、Xでは「自律型AIの安全性」と「産業競争力」のバランスをめぐる議論が広がっている。焦点となっているのは、「人間の判断を必須化する仕組み」がどの範囲・条件で適用されるのかという具体性だ。</p>
<p>否定的な意見としては、「一律の人間介入はフィジカルAIのリアルタイム性を損なう」「規制が先行すれば実用化のハードルが高まる」といった指摘がテック系アカウントを中心に見られる。一方で、「物理世界に直接作用する以上、ヒューマン・イン・ザ・ループの設計は安全確保の観点から不可欠」とする声もある。また、関連銘柄の株価動向に触れつつ、市場は過度な規制強化を織り込んでいないとの見方を示す投稿も確認できる。</p>
<p>更新内容は現時点で案の段階にあり、3月末の正式公表までに、例外規定の有無や「リスクに応じた段階的な適用」の考え方がどの程度明確化されるかが注目されている。</p>
]]></description>
      <pubDate>Mon, 16 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>対話が続くほど誤りが連鎖する──LLMハルシネーションの新ベンチマーク「HalluHard」、Web検索機能をONにしたフラッグシップモデルでも幻覚率約30%</title>
      <link>https://ledge.ai/articles/halluhard_multi_turn_hallucination_search_on_30_percent</link>
      <description><![CDATA[<p>スイス連邦工科大学ローザンヌ校（EPFL）および欧州AI研究組織ELLISの研究チームは、大規模言語モデル（LLM）の事実誤認（ハルシネーション）を測定する新ベンチマーク「HalluHard」を提案した。論文は2026年2月1日arXivに<a href="https://arxiv.org/abs/2602.01031v1">公開</a>され、Web検索機能を有効化したフラッグシップモデルにおいても、対話の最終ターンにおけるハルシネーション率は約30％に達すると報告した。</p>
<h2>単発QAでは見えない「対話の深化に伴う誤りの連鎖」</h2>
<p>実運用におけるユーザーとLLMのやり取りは複数ターンにわたることが多いが、従来の評価系は一問一答形式が主流であった。</p>
<p>研究チームは、対話が継続する過程で「前のターンの誤情報が、次のターンの推論前提として取り込まれる」という構造的リスクを指摘している。HalluHardは、950のseed質問をベースに、平均3ターンの対話形式で文脈が積み重なる設計を採用した。</p>
<h2>法務・医療・研究・開発の4領域で「根拠との整合性」を厳格に検証</h2>
<p>対象領域は、Legal Cases、Medical Guidelines、Research Questions、Codingの4分野に渡る。同ベンチマークの評価基準は、単なる回答の正誤判定に留まらず、回答内の事実主張に対する「インライン引用」の義務化を特徴とする。評価パイプラインでは、ウェブ検索やPDF全文解析を通じて証拠を取得し、事実の創作、引用と主張の不一致、根拠の不足を厳密にハルシネーションとして定義している。</p>
<h2>最新の検索統合型モデルであっても「最終ターンの幻覚率は約30％」に達する</h2>
<p>論文内の分析によれば、ほぼ全てのモデルにおいて、第1ターンから第3ターンへと対話が進むにつれてハルシネーション率が上昇する傾向が確認された。特に、Web検索ツールを有効化した最新のフラッグシップモデルにおいても、最終ターンでは約30％前後のハルシネーション率が観測されている。これは、外部知識へのアクセスが可能であっても、根拠の選択や解釈の段階で誤りが発生し、それが次ターンの推論に影響を及ぼす構造が確認された。</p>
<h2>継続更新型のリーダーボードとして「マルチターン対話の信頼性」を定量化</h2>
<p>HalluHardは評価フレームワークおよびリーダーボードとして公開されており、今後も新たなモデルの追加や更新が予定されている。対話の継続に伴う誤りの連鎖を可視化する同ベンチマークは、生成AIの実運用における信頼性を評価する新たな指標としての役割を担う。</p>
]]></description>
      <pubDate>Sun, 15 Feb 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>元OpenAI研究者、ChatGPT広告テスト開始の週に辞職　NYTに「OpenAIはFacebookと同じ過ち」と題した寄稿</title>
      <link>https://ledge.ai/articles/openai_ads_test_researcher_quits_nyt_facebook_comparison</link>
      <description><![CDATA[<p>OpenAIが2026年2月9日に対話型AI「ChatGPT」で広告表示のテストを開始した週に、同社の元研究者であるZoë Hitzig氏が<a href="https://x.com/zhitzig/status/2021590831979778051">辞職を公表</a>した。Hitzig氏は2026年2月11日付の米紙The New York Times(NYT)のオピニオン欄に「OpenAI Is Making the Mistakes Facebook Made. I Quit.（OpenAIはFacebookと同じ過ちを犯している。私は辞めた）」と題したエッセイを<a href="https://www.nytimes.com/2026/02/11/opinion/openai-ads-chatgpt.html">寄稿</a>し、広告モデル導入に対する懸念を示した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Zoe_Hitzig_4e4cb3454d/Zoe_Hitzig_4e4cb3454d.jpg" alt="Zoë Hitzig.jpg" /></p>
<h2>2年間にわたりモデル構築や価格設計に関与</h2>
<p>寄稿によると、Hitzig氏はOpenAIに約2年間在籍し、AIモデルの構築や価格設計（pricing）、初期の安全性方針の策定に携わってきたという。同氏は、広告そのものを「不道徳あるいは非倫理的だとは考えていない」と明言する一方で、同社の戦略に「深い懸念」を抱いていると述べた。</p>
<p>Hitzig氏は、ChatGPTの利用者がこれまでに前例のない規模で個人的な悩みや医療上の不安、信仰観などを打ち明けてきた点に言及。そうした会話アーカイブを基盤とした広告モデルが、ユーザーを操作する可能性を持つと指摘している。</p>
<h2>OpenAIは広告を明確表示、回答への影響は否定</h2>
<p>OpenAIは同週、ChatGPTにおける広告表示のテスト開始を<a href="https://ledge.ai/articles/chatgpt_ads_test_us_free_go_2026">発表</a>した。広告は回答の下部に表示され、明確にラベル付けされるほか、回答内容には影響しないとしている。</p>
<p>広告はAI運用コストを賄う収益源の一つとなり得るが、Hitzig氏は、広告導入を巡る議論を「広告か、アクセス制限か」という二者択一として捉えるのは誤りだと主張。企業向け利用からのクロスサブシディや、独立した監督権限を持つガバナンス構造、データを独立的に管理するトラストモデルなど、代替案を提示している。</p>
<h2>「Facebookの過ち」を引き合いに</h2>
<p>寄稿では、かつてFacebook（現Meta）が広告モデルのもとでエンゲージメント最適化を進める過程で、当初掲げたデータ管理や利用者の統制に関する原則が徐々に後退した経緯にも言及している。Hitzig氏は、広告モデルが強いインセンティブを生み出す構造にあると指摘し、OpenAIが同様の道をたどる可能性に懸念を示した。</p>
<h2>8億人規模の利用基盤</h2>
<p>ChatGPTの週間利用者は<a href="https://ledge.ai/articles/openai_devday2025_chatgpt_800m_wau">8億人規模</a>に達しているとされる。こうした大規模な利用基盤のもとで広告モデルが導入されることも、今回の議論の背景となっている。</p>
<p>生成AIの運用コストと広範なアクセス確保をどう両立させるかは、業界全体の課題でもある。ChatGPTへの広告導入をめぐる議論は、今後も続く可能性がある。</p>
]]></description>
      <pubDate>Sat, 14 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>社会をシミュレートするAI「Simile」が1億ドル調達。実在の人間をモデルにした数百万人のエージェントが意思決定を予見</title>
      <link>https://ledge.ai/articles/simile_social_ai_simulation_series_a_100m</link>
      <description><![CDATA[<p>AIスタートアップSimileのCEOであるJoon Sung Park氏は2026年2月13日、実在の人間をモデルにしたエージェントで構成される「社会のAIシミュレーション」を構築したと<a href="https://x.com/joon_s_pk/status/2022023097017421874">発表</a>した。製品や政策など、数百万人規模に影響を与える意思決定を事前に再現・検証できる基盤モデルの開発を進めているという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/introduce_simile_b002315008/introduce_simile_b002315008.jpg" alt="introduce simile.jpg" /></p>
<p>あわせて、同社はSeries Aラウンドで1億ドル（約150億円）を調達したことを明らかにした。リード投資家はIndex Venturesが務め、Hanabi、A*、Bain Capital Ventures（BCV）らが参加した。また、個人投資家としてAndrej Karpathy氏、Fei-Fei Li氏、Adam D’Angelo氏、Guillermo Rauch氏、Scott Belsky氏らも出資者に名を連ねている。</p>
<h2>実在人間に基づくエージェントで社会を再現</h2>
<p><a href="https://simile.ai/blog/the-simulation-company">Simile</a>は、人間の行動や意思決定を再現する基盤モデルの開発を専門とする企業である。CEOのJoon Sung Park氏は、かつてスタンフォード大学で「生成エージェント（generative agents）」の研究を主導した経歴を持つ。</p>
<p>同社のシミュレーション基盤は、実在の人間をモデル化したエージェントを多数配置し、それらの相互作用を通じて社会全体の動向を再現する仕組みである。現在は、あらゆる状況や規模において人間行動を予測可能な基盤モデルの開発に注力している。</p>
<h2>意思決定の「フライトシミュレーター」</h2>
<p>すでに企業向けの実装も始まっており、Simileは自社プラットフォームを**「重要な意思決定のためのフライトシミュレーター」**と定義している。用途として挙げられているのは以下の例だ。</p>
<ul>
<li><strong>IR・経営戦略</strong>： 決算説明会（earnings calls）における投資家の反応予測</li>
<li><strong>法務・訴訟</strong>： 訴訟結果のモデリングとシミュレーション</li>
<li><strong>公共政策</strong>： 政策変更が社会に及ぼす影響のテスト</li>
</ul>
<h2>開発の加速と世界規模への拡張</h2>
<p>今回調達した1億ドルは、社会シミュレーション基盤の開発を加速するための資金として充てられる。</p>
<p>同社は将来的な展望として、個人、組織、文化、国家などの多層的な相互作用を扱う大規模モデルへと拡張する方針を示している。これにより、世界規模での社会シミュレーションの実現を目指すとしている。</p>
]]></description>
      <pubDate>Sat, 14 Feb 2026 02:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>