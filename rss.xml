<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>サイボウズ、新卒エンジニア研修資料を無償公開──生成AIやKubernetes、Copilotなど実務直結の内容を網羅</title>
      <link>https://ledge.ai/articles/cybozu_engineer_training_materials_2025_release</link>
      <description><![CDATA[<p>2025年7月8日、サイボウズ（東京都中央区）は、自社の2025年度新卒エンジニア向け研修で使用した講義資料と一部講義動画を、同社の公式エンジニアブログ上で<a href="https://blog.cybozu.io/entry/2025/07/08/171543">無償公開</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/blog_cybozu1_368c892398/blog_cybozu1_368c892398.jpg" alt="blog cybozu1.jpg" /></p>
<p>資料は生成AIツール開発やGitHub Copilotの活用、DockerおよびKubernetesの入門、セキュリティ、暗号技術、テスト自動化、テクニカルライティングなど全19本におよび、実践的かつ初学者にも配慮された構成となっている。</p>
<p>今回公開された資料は、2025年4月21日から5月23日にかけて実施されたサイボウズの新卒エンジニア研修プログラムに基づくものである。同研修は、「講義実習フェーズ」と「実践演習フェーズ」の二段階構成となっており、入社直後から実務にスムーズに参加できるよう、基礎技術からチーム開発への適応力までを総合的に育成することを目的としていた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/blog_cybozu2_dc7b72035c/blog_cybozu2_dc7b72035c.jpg" alt="blog cybozu2.jpg" /></p>
<p>公開されたコンテンツの主なテーマは以下の通り。</p>
<ul>
<li>Difyを使った生成AIチャットボット開発ワークショップ</li>
<li>GitHub Copilotを用いたAI補助プログラミング体験</li>
<li>DockerとKubernetesの導入・基礎概念の解説</li>
<li>セキュリティと暗号に関する基礎知識</li>
<li>自動テストの設計と実践（理論編・実装編）</li>
<li>テクニカルライティング、ソフトウェアライセンスの基本</li>
</ul>
<p>資料は同社のスライド共有サービス「Speaker Deck」上で閲覧可能で、一部講義動画はYouTubeで確認できる。利用条件はブログ内に明記されており、再配布や二次利用の際には個別確認が必要とされている。</p>
<p>サイボウズは例年、社内研修の一部資料を外部公開しており、今年は「自社と自身を理解し、長期的なキャリアの土台を作る」ことをテーマに、研修設計全体の構造や背景もあわせて紹介している。公開の狙いについて、同社は「外部の教育機関や企業研修担当者、個人開発者との知見共有を促進するため」と説明している。</p>
<p>近年、LINEヤフーやメルカリなどの企業も同様に新卒向け技術資料の一部公開を行っているが、生成AIやDevOps関連を含む実務直結型の全体研修資料をここまで一括公開する事例は、国内大手企業としては珍しい。</p>
<p>今後も同社は、研修資料の公開範囲を拡大する可能性を示唆しており、例年8月〜9月に開催される自社技術カンファレンスにおいて、追加的なハンズオン資料の提供も期待されている。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>iOS版「Grok」コンパニオンモード公開　美少女アバター「Ani」“好感度”レベルアップで露出増、お次はイケメン新キャラ「Valentine」登場</title>
      <link>https://ledge.ai/articles/grok_companion_mode_ani_valentine</link>
      <description><![CDATA[<p>2025年7月14日（日本時間）、米xAIは対話型AIアプリ「Grok」のiOS版に新機能「<a href="https://x.com/cb_doge/status/1944713034351665623">コンパニオンモード(Companion Mode)</a>」を公開した。初期実装キャラクターとして登場した美少女アバター「Ani」は、ユーザーとの“関係性レベル”に応じて衣装の露出が段階的に変化する仕様を備えている。ただし、Aniのモーション回転や衣装変化、好感度レベル機能はすべて月額30ドルの有料プラン「SuperGrok」専用機能であり、無課金ユーザーには提供されていない。さらに、イーロン・マスク氏は7月17日、自身のXアカウントで、次期キャラクターとしてイケメンアバター「Valentine」の登場を予告した。</p>
<h2>iOS版で公開された「コンパニオンモード」</h2>
<p>新たに実装された「コンパニオンモード」は、3Dアバターと音声またはテキストで会話できる機能で、画面上ではアバターの回転表示や視点操作などのインタラクティブな体験が可能となっている。7月14日時点で選択可能なキャラクターは2体で、毒舌なレッサーパンダ風の「Bad Rudi」と、ゴシック衣装をまとったアニメ風美少女「Ani」が用意されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/dogedesigner_7e3af0ff1d/dogedesigner_7e3af0ff1d.jpg" alt="dogedesigner.jpg" /></p>
<p>この機能はiOS版「Grok」アプリの設定メニューから有効化する形式となっているが、SuperGrok加入者のみ利用可能であり、無料ユーザーはCompanion Modeの項目自体が表示されない。</p>
<h2>Aniは日本語対応　“好感度”で衣装が変化</h2>
<p>xAI公式のGrokアカウント（@grok）は7月15日、「アニと日本語で話してみて！」と投稿し、日本語での対話に対応していることを紹介した。引用されたユーザー投稿では、Aniが日本語で応答する様子や、アニメ的な表情やポーズを見せる映像が確認できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Ani_grok_8395c1c734/Ani_grok_8395c1c734.jpg" alt="Ani grok.jpg" /></p>
<p>さらに同日、Grok公式は別投稿（@grok, 2025年7月15日）で、「Aniのモーション回転、衣装変更、好感度機能はSuperGrok有料購読者限定。無課金ユーザーはアクセス不可」と明言。好感度を意味する「Relationship Level」がレベル3に達すると、Aniの衣装はより露出度の高いスタイルに変化する設計となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_premium_ec02781fdf/grok_premium_ec02781fdf.jpg" alt="grok premium.jpg" /></p>
<h2>有料プラン「SuperGrok」とは</h2>
<p>SuperGrokは、xAIが提供する月額30ドルの有料サブスクリプションで、最新の大規模言語モデル「Grok 4」や、高度な検索機能、個別設定などが利用できる上位プランだ。コンパニオンモードを含むアバター機能もこのプランに限定されており、アプリの無料利用者には開放されていない。</p>
<p>なお、App Store上のGrokアプリの年齢レーティングは現時点で「12歳以上」に設定されたままとなっているが、衣装変化など一部の表現をめぐって、今後の審査基準との整合性が注視されている。</p>
<h2>次なる登場キャラ「Valentine」はイケメン男性アバター</h2>
<p>7月17日（日本時間）、イーロン・マスク氏は自身のXアカウント（@elonmusk）で、「次のキャラクターの名前はValentineだ」と発表した。名前の由来は、ロバート・A・ハインラインのSF小説『Stranger in a Strange Land』の主人公「Valentine Michael Smith」に関連するとみられ、Aniとは対照的な男性キャラクターとして設計されていることが示唆される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/eron_valentine_40580437d9/eron_valentine_40580437d9.jpg" alt="eron valentine.jpg" /></p>
<p>xAIは「感情を持つAIとのインタラクション体験」を重視した製品開発を進めており、Grokを単なる生成AIではなく、パーソナルなAIパートナーとして位置付けている。今後も個性豊かなキャラクターの追加や、対話体験の多様化が進むとみられる。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが11歳の作文から22年後の最終学歴と能力を高精度予測──Nature系誌が報告</title>
      <link>https://ledge.ai/articles/ai_predicts_future_education_from_childhood_essay</link>
      <description><![CDATA[<p>2025年7月3日、Nature系列の学術誌『Communications Psychology』に掲載された研究によると、11歳児が授業で書いた約250語の作文を大規模言語モデル（LLM）で分析することで、22年後の最終学歴や認知・非認知能力を高精度で予測できることが<a href="https://www.nature.com/articles/s44271-025-00274-x">明らかになった</a>。</p>
<p>英国で1958年に生まれた約1万人を追跡する縦断研究のデータを用い、GPT-3.5による文章埋め込みと機械学習を組み合わせた予測モデルは、教師による評価とほぼ同等の精度を達成したという。</p>
<h2>従来の予測手法の限界</h2>
<p>これまでの研究では、社会調査データや遺伝情報を用いた将来予測の精度には限界があった。2020年に米国で実施された「Fragile Families Challenge」では、160の研究チームが1万2942項目の社会調査データを活用したが、中学生時点の成績（GPA）の予測精度は約20％にとどまった。</p>
<p>一方、トランスフォーマー型のLLMの発展により、文章から個人の能力や性格傾向を高精度に捉える可能性が注目されている。本研究は、短い作文が将来をどの程度予測できるかを実証的に検証した。</p>
<h2>研究の概要：1958年英国出生コホートデータを活用</h2>
<p>研究に用いられたのは、1958年に英国で生まれた1万7415人を追跡する「National Child Development Study（NCDS）」のデータである。参加者が11歳の時点で「25歳の自分を想像して」という課題で書いた作文（1～1239語、平均約250語）を分析対象とした。
研究チームは以下の手法で作文を分析した：</p>
<ul>
<li>OpenAIのtext-embedding-ada-002モデルによる1536次元の文章埋め込み</li>
<li>534項目の言語的特徴（語彙の多様性、洗練度、感情表現）</li>
<li>31種類の読みやすさ指標</li>
<li>文法・スペルミスの比率</li>
</ul>
<p>これらの特徴量を、11歳時点の教師による評価22項目、33種類のポリジーンスコア（遺伝的指標）と組み合わせ、アンサンブル学習手法「SuperLearner」で予測モデルを構築した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/44271_2025_274_Fig1_HTML_539bc4fa53/44271_2025_274_Fig1_HTML_539bc4fa53.png" alt="44271_2025_274_Fig1_HTML.png" /></p>
<h2>予測精度：AIと教師評価がほぼ同等</h2>
<p>分析の結果、作文のみでも高い予測精度が得られた。11歳時点の能力予測では以下の精度（R²値）を達成した：</p>
<ul>
<li>読解力：作文分析 0.59、教師評価 0.57</li>
<li>言語能力：作文分析 0.55、教師評価 0.57</li>
<li>数学的能力：作文分析 0.55、教師評価 0.57</li>
<li>非言語能力：作文分析 0.37、教師評価 0.45</li>
</ul>
<p>33歳時点の最終学歴の予測精度は、作文分析が0.26、教師評価が0.29、遺伝情報が0.19となった。作文・教師評価・遺伝情報をすべて統合したモデルでは、最終学歴の予測精度が0.38に達した。
特に認知能力の予測では、3つの情報源を統合したモデルの精度が0.70に達し、標準的な知能検査の再検査信頼性に迫る水準となった。</p>
<p><strong>認知能力（11歳時点）と最終学歴（33歳時点）に対する各予測モデルおよびその組み合わせの精度比較</strong> ：3つの情報源（作文、教師評価、遺伝情報）をすべて統合したモデルは、認知能力で0.70、最終学歴で0.38という高い予測精度を達成。単独の予測手法と比較して、統合による相乗効果が確認された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cognitive_and_not_cognitive_abilities_066c248f61/cognitive_and_not_cognitive_abilities_066c248f61.jpg" alt="cognitive and not cognitive abilities.jpg" /></p>
<h2>GPT埋め込みが予測精度の大部分を担う</h2>
<p>研究チームは、予測モデルの各要素の貢献度を分析した。その結果、1536次元のGPT埋め込みが予測精度の大部分を担っていることが判明した。</p>
<p><strong>作文から抽出した各種特徴量による認知能力・非認知能力の予測精度</strong>  赤：文法・スペルミス、オレンジ：読みやすさ指標、黄：言語的特徴（語彙多様性・洗練度・感情表現）、緑：埋め込み以外の全特徴、青：GPT-3.5埋め込み、紫：全特徴の統合。GPT埋め込みが予測精度の向上に最も貢献していることが分かる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Prediction_of_highest_attained_education_e29b74bcc0/Prediction_of_highest_attained_education_e29b74bcc0.jpg" alt="Prediction of highest attained education.jpg" /></p>
<p>従来の読みやすさ指標や文法的特徴のみでは、作文の長さのみを用いた予測と比べて5～10倍程度の改善にとどまったが、GPT埋め込みを追加することで大幅な精度向上が見られた。</p>
<h2>他の予測要因との比較</h2>
<p>研究では、教育達成度の予測において一般的に用いられる他の要因とも比較を行った：</p>
<p><strong>33歳時点の最終学歴に対する各予測モデルの精度比較</strong> ：従来の予測要因（出生時体重、身長、社会学的モデル）と比較して、作文・教師評価・遺伝情報を統合したモデルは大幅に高い予測精度（R²=0.38）を達成した。エラーバーは交差検証における最小・最大値を示す。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_model_containing_all_three_information_sets_d4cce493ba/A_model_containing_all_three_information_sets_d4cce493ba.gif" alt="A model containing all three information sets.gif" /></p>
<ul>
<li>両親の教育水準：予測精度 0.12</li>
<li>出生時体重：予測精度 0.01</li>
<li>身長：予測精度 0.03</li>
<li>社会経済的背景を含む従来の社会学的モデル：予測精度 0.18～0.19</li>
</ul>
<p>これらと比較して、作文分析による予測は大幅に高い精度を示した。</p>
<h2>研究の限界と今後の課題</h2>
<p>研究チームは、以下の限界を指摘している：</p>
<ol>
<li><strong>一般化可能性</strong> ：サンプルは1958年に英国で生まれた世代に限定されており、現代の児童や他の文化圏への適用可能性は未検証</li>
<li><strong>因果関係</strong> ：予測の成功は、作文と結果の間の関連性を示すが、その背後にあるメカニズムは不明</li>
<li><strong>技術の進歩</strong> ：より新しいLLMモデルや、より洗練された遺伝的予測手法を用いれば、さらなる精度向上の可能性がある</li>
<li><strong>倫理的配慮</strong> ：予測技術の教育選抜や信用評価への応用には、偏見の固定化や自己成就的予言のリスクがあり、慎重な議論が必要</li>
</ol>
<h2>研究の意義</h2>
<p>この研究は、適切なデータと手法を用いれば、人間の将来をある程度予測可能であることを示した。これは「人間の生活は本質的に予測不可能」とする従来の見解に再考を促すものといえる。同時に、AIによるテキスト分析が教師評価に匹敵する精度を持つことから、教育現場における「第3の評価視点」として活用できる可能性を示唆している。ただし研究チームは、これらの予測はあくまで教育支援のための参考情報として用いるべきであり、決定的な選別の根拠とすべきではないと強調している。</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「ChatGPT agent」を発表──仮想PC上でAIが自律的に業務遂行、Pro／Plus／Team利用者に提供開始</title>
      <link>https://ledge.ai/articles/openai_chatgpt_agent_virtual_pc_automation</link>
      <description><![CDATA[<p>OpenAIは2025年7月17日（米国時間）、ChatGPTにおいて、新機能「ChatGPT agent」の提供開始を<a href="https://openai.com/ja-JP/index/introducing-chatgpt-agent/">発表</a>した。</p>
<p>これは、仮想コンピュータ上でChatGPTがウェブブラウジングやファイル編集、スケジュール作成といった一連のタスクを自律的に実行するもので、従来の「deep research」「Operator」の機能と統合された形で動作する。まずは英語UIを用いるChatGPTのPro、Plus、Teamプラン利用者を対象に提供され、順次Enterpriseや教育機関向けの拡大が予定されている。
@<a href="https://www.youtube.com/watch?v=1jn_RpbPbEc">YouTube</a></p>
<h2>仮想コンピュータで複数タスクを自動処理</h2>
<p>ChatGPT agentは、AIが仮想PC上で実際の操作環境を用い、ユーザーの目的達成まで複数のアプリケーションやツールを横断的に操作する。たとえば、Googleカレンダーで日程を調整し、OpenTableでレストランを予約するといった一連の作業を、ユーザーの指示に基づきAIが代行する。メールの下書き作成、スプレッドシートの整理、コードの実行やファイル変換といった業務も対象となる。</p>
<p>この環境はユーザーごとに隔離された仮想的な計算空間であり、AIが自らターミナル、ブラウザ、文書作成ソフトなどを使ってタスクを処理する構成になっている。</p>
<h2>「deep research」と「Operator」機能を統合</h2>
<p>今回の新機能は、OpenAIがこれまで実装してきた2つのツール、「deep research」と「Operator」に加え、新たなエージェント基盤を組み合わせた点が特徴である。</p>
<ul>
<li>「deep research」は、アップロードされたファイルやウェブページを高速かつ精緻に読み取り、要点を抽出・要約するリサーチ特化型機能。</li>
<li>「Operator」は、フォーム入力やメール送信、外部アプリの制御など“行動”の自動化に適したツール群。</li>
</ul>
<p>ChatGPT agentはこれらの機能を組み合わせ、状況に応じて最適な処理を自律的に選択・実行する設計となっている。</p>
<h2>安全性確保のための仕組みも導入</h2>
<p>OpenAIは本機能の公開にあたり、ユーザーの許可なしに実行されるリスクのある操作について制限を設けている。たとえば、金銭の送金、ファイルの削除、ECサイトでの購入といった不可逆操作はすべてユーザーの明示的な承認が必要とされる。さらに、投資、暗号資産取引、医療・法律・健康に関する判断は対応外となっている。</p>
<p>また、AIの意思決定過程やリスクの特性については、同社が公開する「システムカード」によって透明性を確保している。これには人間によるフィードバック（RLHF）に基づいたチューニングや、セーフティ・レールの設計方針が含まれている。</p>
<h2>今後の展開</h2>
<p>ChatGPT agentは英語UIにおいて、7月17日よりPro、Plus、Teamユーザー向けに順次展開されている。Enterpriseや教育機関向けプラン、欧州経済領域（EEA）での提供は「規制要件を満たし次第」開放されるとしている。</p>
<p>今後は、開発者向けにエージェント機能を呼び出せる「Agent API」や、ユーザーが独自にツールを登録・共有できる「Marketplace」の構想も示されており、年内にもさらなる拡張が計画されているという。</p>
<p>今回の発表は、急速に拡大するAIエージェント市場におけるOpenAIの戦略的な一手とみられている。同様の機能はAnthropicが「Claude Team Agent」、Googleが「Gemini Agents」、Metaが「AI Studio Bots」として展開を開始しており、各社が“リサーチとアクションの統合”を軸に差別化を図っている。OpenAIは、これまで研究開発を重視してきた姿勢を維持しつつ、実務への応用性を高める方向に舵を切った形だ。</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米国防総省、Anthropic・Google・OpenAI・xAIに各2億ドル──フロンティアAIを“エージェント化”し全軍ミッションを強化</title>
      <link>https://ledge.ai/articles/dod_frontier_ai_partnerships_2025</link>
      <description><![CDATA[<p>2025年7月14日、米国防総省の最高デジタル・人工知能局（Chief Digital and Artificial Intelligence Office: CDAO）は、先進AI技術の導入を加速するため、Anthropic、Google、OpenAI、xAIの4社とそれぞれ最大2億ドル規模の契約を締結したと<a href="https://www.ai.mil/Latest/News-Press/PR-View/Article/4242822/cdao-announces-partnerships-with-frontier-ai-companies-to-address-national-secu/">発表</a>した。</p>
<p>契約の目的は、各社のフロンティアAIを活用し、エージェントベースのAIワークフロー（agentic AI workflows）を様々な軍事・非軍事ミッションに統合することで、DoDのデジタル変革と国家安全保障対応能力を強化する点にあるという。CDAOはこの契約を通じ、先端商用技術をいち早く軍に取り込む「commercial-first」戦略を推進するとしている。</p>
<p>契約は、バージニア州アーリントンに本拠を置くCDAOが管轄する「Task Order under Tradewind OTA（Other Transaction Authority）」スキームを用いて実施された。各社に付与される契約上限額は2億ドルであり、支払いは段階的な成果に応じて行われる。</p>
<p>対象企業となるAnthropic・Google・OpenAI・xAIの4社はいずれも「フロンティアAI企業（frontier AI companies）」に分類され、数十億パラメータ規模の大規模言語モデル（LLM）を開発・運用している。CDAOはこれらの技術を通じて、「現場での意思決定支援」「戦略分析」「作戦計画」「データ統合」といった多様な軍務領域でAIの活用を進める方針だ。</p>
<p>今回のパートナーシップでは、すでにCDAOが導入を進めている複数のAIプラットフォームとの連携も見込まれている。具体的には、以下のような基幹技術への統合が明記されている。</p>
<ul>
<li>「Ask Sage」と呼ばれるEnterprise LLM Workspace（大規模言語モデルによる業務支援環境）</li>
<li>統合分析基盤「Advana」</li>
<li>映像解析AI「Project Maven Smart System」</li>
<li>前線データ連携基盤「Edge Data Mesh」</li>
</ul>
<p>これにより、データ収集から意思決定までのプロセスを自動化・高速化し、現場の判断能力や作戦遂行能力の向上が期待されている。また、調達面では連邦政府の調達総局（GSA）と連携し、AI推論のための計算資源（AI compute）を共通調達枠から供給する計画も進行中とされる。</p>
<p>CDAOの責任者であるDoug Matty氏は、今回の提携について「AI技術は戦闘員の支援能力を根本から変革し、米国の戦略的優位性を確保する上で不可欠である」と述べている。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/18 [FRI]LINEヤフー、全社員1.1万人に生成AI “義務化”──「まずはAIに聞く」働き方で3年以内に生産性2倍へ</title>
      <link>https://ledge.ai/articles/line_yahoo_mandates_genai_use_for_all_employees</link>
      <description><![CDATA[<p>LINEヤフー株式会社は2025年7月14日、正社員・契約社員など約1万1,000人の全従業員を対象に、業務における生成AI活用を「義務化」する新たな働き方を開始したと<a href="https://www.lycorp.co.jp/ja/news/release/018121/">発表</a>した。</p>
<p>生成AIの全社的な導入により、3年以内に業務生産性を2倍に引き上げることを目指す。この施策では、調査・検索、資料作成、会議を中心に「まずはAIに聞く」文化の定着を社内ルールとして定め、ChatGPT Enterpriseを含む複数のツールを活用するという。</p>
<h2>生成AI前提の働き方へ全面移行</h2>
<p>新制度では、生成AIの活用を業務遂行の前提とし、「調査・検索」「資料作成」「会議運営」の3領域において具体的な指針が示された。</p>
<ul>
<li><strong>調査・検索</strong> ：社内規程や競合情報などを調べる際に、社内ツール「SeekAI」や生成AI検索の使用を義務化</li>
<li><strong>資料作成</strong> ：アウトライン作成や初稿作成をAIで行い、校正もAIによる支援を前提とする</li>
<li><strong>会議</strong> ：議題整理や議事録作成にAIを導入し、任意参加の会議は原則欠席、議事録で内容を把握する</li>
</ul>
<h2>生産性2倍をKPIに、AI活用を数値化</h2>
<p>LINEヤフーは、生成AIの活用に関して以下の数値目標を設定している。
社員の生成AI活用率：100％
サービスへのAI機能導入件数：51件（2025年7月時点で実装済み）
社内業務効率化プロジェクト：35件超が進行中
生産性KPI：3年間で業務生産性を2倍に引き上げることを目標</p>
<p>これらのKPIは、社内外での成果測定や継続的な改善につなげるとしている。</p>
<h2>全社員にChatGPT Enterpriseを配布</h2>
<p>制度実行に向けた環境整備として、2025年6月から全社員に「ChatGPT Enterprise」のアカウントが付与された。利用に際しては、eラーニング形式の教育コンテンツを通じてリスク管理やプロンプト設計の基本を学び、所定のテストに合格することが条件となる。また、各部門に「生成AI活用推進者」を配置し、活用ノウハウや事例を横展開する体制も構築している。</p>
<p>生成AI統括本部長の宮澤弦氏は、公式リリースの中で「全社員が生成AIを最大限に活用し、新しい価値を生み出したい」と述べている。</p>
<h2>今後の展望</h2>
<p>国内企業で生成AIの全社導入は急速に広がりつつある。MIXIは全社員約2,000人にGoogle 「Agentspace」を配布し、定型業務の自動化を進めた。電通グループも「dentsu Japan AIセンター」を設立し、約1,000人の専門人材を軸にAIネイティブ化を推進している。こうした動きの中で、生成AIの活用を義務化まで踏み込んだのはLINEヤフーが国内初だ。</p>
<p>同社は今後、社内表彰やアンバサダー制度を通じて優良事例を共有し、部門横断的な活用を促進する。KPIの達成状況や教育効果は四半期ごとに公開される予定で、透明性の高い運用が特徴となる。また、生成AIを核にした新サービスや業務機能の刷新にも取り組む構えだという。</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/17 [THU]中国スタートアップMoonshot AI、1兆パラメータの新LLM「Kimi K2」をオープンソースで公開──長文推論とコード生成でGPT-4系に迫る性能</title>
      <link>https://ledge.ai/articles/kimi_k2_release_moonshot_ai</link>
      <description><![CDATA[<p>北京に拠点を置くスタートアップ企業Moonshot AIは2025年7月12日、新たな大規模言語モデル「Kimi K2」をオープンソースで<a href="https://moonshotai.github.io/Kimi-K2/">公開</a>した。</p>
<p>同モデルは、総パラメータ1兆、アクティブパラメータ320億のMixture-of-Experts（MoE）構造を採用し、コード生成や長文推論、外部ツールとの統合といった用途に特化している。Apache 2.0互換のライセンスでGitHubおよびHugging Faceを通じて配布されており、商用利用も可能となっている。同社はこの公開を通じて、急速に成長する中国国内のオープンソースLLM競争での巻き返しを狙う。</p>
<h2>1兆パラメータのMixture-of-Experts構造を採用</h2>
<p>Kimi K2は32の専門家レイヤー（experts）から成り、推論時にはそのうち2つのみを活性化することで、GPUリソースの消費を抑えつつ高性能を実現している。モデルの学習には同社が開発した最適化アルゴリズム「Muon Optimizer」が使用されており、推論にはNVIDIA A100（40GB）相当のGPU1枚で対応可能とされている。</p>
<p>また、日本語や英語を含む多言語に対応し、最大20万トークンの長文入力が可能であるなど、ドキュメント要約や長文分析といった用途にも適しているという。同社は Kimi K2を「エージェント的知能（Agentic Intelligence）」の土台として位置付けており、複雑なタスクの分解やツール操作といった処理能力に重点を置いている。</p>
<h2>コード生成と数学推論でGPT-4.1を上回るベンチマーク結果</h2>
<p><a href="https://huggingface.co/moonshotai/Kimi-K2-Base">Hugging Faceのモデルカード</a>にて同社が公開したベンチマーク結果によれば、Kimi K2は以下の項目でGPT-4.1（2025年5月時点のプレビュー版）を上回るか、同等の性能を示したという。</p>
<ul>
<li>LiveCodeBench v6（Pass@1）：53.7%（GPT-4.1は44.7%、DeepSeek-V3は46.9%）</li>
<li>SWE-bench Verified（単一試行・Agentic Coding）：65.8%（GPT-4.1は54.6%）</li>
<li>MATH-500 Accuracy：97.4%（GPT-4.1は92.4%）</li>
<li>MMLU（Exact Match）：89.5%（GPT-4.1は90.4%と同等水準）</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/collage_kimi2_bench_d13b3abdd9/collage_kimi2_bench_d13b3abdd9.jpg" alt="collage kimi2 bench.jpg" /></p>
<p>これらのスコアは、特にコーディングと数理分野での推論能力において、Kimi K2が最先端のLLMと競合しうることを示すものとされる。ただし、一般的な自然言語処理性能や創造的文章生成といった領域に関する評価はまだ限定的である。</p>
<h2>オープンソース戦略と今後の展開</h2>
<p>Kimi K2は、Apache 2.0互換ライセンスで商用利用が認められており、GitHubとHugging Face上でモデル重みと推論スクリプトが公開されている。さらに今後、4bitおよび8bitの量子化版、LoRAによるファインチューニングレシピ、学習済みエージェント機構の導入例などの公開も予定されている。</p>
<p>2024年後半からユーザー数が減少傾向にあった対話アプリ「Kimi」の再成長を後押しする狙いもあり、同社は、Kimi K2の性能を活かしたエンタープライズ向けAPIの提供を2025年第4四半期に計画しているとしている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「一度公開すれば取り戻せない」──OpenAI、オープンウェイトモデルのリリースを無期限延期</title>
      <link>https://ledge.ai/articles/openai_open_weight_model_launch_delayed</link>
      <description><![CDATA[<p>OpenAIのCEOであるサム・アルトマン氏は2025年7月12日、自身のX（旧Twitter）アカウントを通じて、翌週に予定していた新たな大型言語モデル（LLM）のリリースを延期すると<a href="https://x.com/sama/status/1943837550369812814">発表</a>した。</p>
<p>対象となるのは、モデルの重み（weights）を一般に公開する「オープンウェイトモデル」であり、安全性に関する追加テストと高リスク領域の精査が必要となったためとしている。新たな公開日程は現時点で明らかにされていない。</p>
<p>アルトマン氏は投稿の中で「一度公開すれば取り戻せない。これは我々にとって新しいことであり、正しく対処したい」と述べ、重みの公開が持つ不可逆性に対する慎重な姿勢を示した。さらに、「悪いニュースを伝えることになってしまい申し訳ない。我々は非常に懸命に取り組んでいる」として、延期は開発チームの責任ある判断であることを強調した。</p>
<p>この「オープンウェイトモデル」は、OpenAIにとって初めての、重みを含めて一般公開するLLMとなる見込みだった。従来のGPT-3.5やGPT-4は、API経由での提供に限定されており、モデルの内部構造やパラメータは非公開だった。一方で今回のモデルは、利用者がローカル環境での実行やカスタマイズを可能にする“オープンアクセス”型であり、企業や研究者の関心を集めていた。</p>
<p>背景には、安全性への懸念がある。重みが公開されれば、第三者によるモデルの再利用や改変が可能になるため、不正利用や誤情報の生成といったリスクが生じる。特に、ハルシネーション（事実に基づかない出力）や有害な出力への対策が不十分なまま公開すれば、被害が広範囲に及ぶおそれがある。アルトマン氏も「追加の安全テストと、高リスク領域の見直しが必要だ」と投稿の中で明記しており、慎重な検証が行われる見通しである。</p>
<p>同モデルは当初、2025年6月中の<a href="https://ledge.ai/articles/openai_open_weight_model_2025">リリースが計画されていた</a>
が、7月第2週に延期されたのち、今回の発表で無期限延期となった。今後の対応方針や公開時期に関しては、OpenAIからの追加の発表が待たれる状況である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_Zs_Mux_Y_50f7cb832c/2_Zs_Mux_Y_50f7cb832c.jpg" alt="2Zs-MuxY.jpg" /></p>
<p>近年、Metaの「Llama 2」や「Llama 3」、Mistralの「Mixtral」など、オープンウェイトモデルは業界内で広がりを見せている。こうしたモデルは、企業が独自のAIアプリケーションを開発する上で基盤として活用されており、今後OpenAIが同分野にどう参入していくかが注目されている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>経産省・NEDOの生成AI開発支援プロジェクト「GENIAC」第3期、楽天と野村総研を含む新規13件を採択──生成AI国産化を加速</title>
      <link>https://ledge.ai/articles/geniac_third_round_rakuten_nri_selected</link>
      <description><![CDATA[<p>2025年7月15日、経済産業省と新エネルギー・産業技術総合開発機構（NEDO）は、生成AI開発支援プロジェクト「GENIAC（Generative AI Accelerator Challenge）」の第3期採択結果を<a href="https://www.nedo.go.jp/koubo/CD3_100397.html">発表</a>した。今回の公募には43件が応募し、最終的に24件が採択された。楽天グループと野村総合研究所（NRI）を含む13件が新規採択で、第1期・第2期に採択されていなかった新顔の参画が加速している。</p>
<h2>楽天、日本語LLMに長期記憶と対話学習を融合</h2>
<p>楽天グループは今回の第3期で初採択された。申請テーマは「長期記憶メカニズムと対話型学習を融合した日本語LLMの研究開発」で、同社が進めるAIエージェント構想の一環とみられる。</p>
<p>2024年末に発表された「Rakuten AI 2.0」では、社内外のデータを活用した多目的LLMの構築と、オープンソース化の方針が示されていた。GENIACの支援を受けることで、大規模演算環境のもと、学習済みパラメータの拡張や長期記憶モジュールの実装が本格化する可能性がある。</p>
<h2>野村総研、業界特化の40B規模モデルを計画</h2>
<p>野村総合研究所（NRI）も第3期で初採択された。採択テーマは「10B〜40B規模の業界・タスク特化型LLMの研究開発」。具体的な適用分野は公表されていないが、金融・行政・製造などNRIが業務支援を行う産業領域での応用が想定される。</p>
<p>NRIのような大手コンサルティング・IT企業が生成AIの基盤モデル開発に乗り出すのは、GENIACプロジェクト初となる。従来のSaaS活用や外部API連携を越えて、独自モデル構築へと進む転換点と位置づけられる。</p>
<h2>新規採択は13件、分野特化型スタートアップが多数</h2>
<p>楽天とNRI以外にも、第3期では11の新規プレイヤーが採択された。採択テーマからは、以下のような分野特化型の研究が目立つ。</p>
<ul>
<li><strong>Airion</strong> ：PLCラダープログラムを自動生成するLLM</li>
<li><strong>Arivexis</strong> ：低分子化合物の生物活性を予測する創薬モデル</li>
<li><strong>Degas</strong> ：リモートセンシング向け視覚言語モデル</li>
<li><strong>Direava</strong> ：外科手術支援用の視覚・言語統合AI</li>
<li><strong>NexaScience</strong> ：研究開発プロセスを自律化するエージェント</li>
<li><strong>Nishika</strong> ：出力形式を厳密に制御できる要約特化LLM</li>
<li><strong>ONESTRUCTURE</strong>：建築BIMデータを生成するモデル</li>
<li><strong>Precision</strong> ：医療文書理解向け専門LLM</li>
<li><strong>Sansan</strong> ：企業文書を対象にした視覚言語モデル</li>
<li><strong>SDio</strong> ：長尺映像を扱う国産大規模映像モデル</li>
<li><strong>Zen Intelligence</strong> ：建設現場施工管理を自動化するモデル</li>
</ul>
<p>これらの企業の多くは医療・建築・産業用途など、明確な業務ユースケースを持つ。GENIAC支援によって、計算資源を活用したモデルのスケーリングが可能になると見られる。</p>
<h2>継続採択は11件、ABEJA・Preferredなど第1期組も含む</h2>
<p>第1期・第2期からの継続採択組は11件。業界内で技術実装が進む企業が引き続き支援対象となった。以下は継続企業の一部。</p>
<ul>
<li>ABEJA</li>
<li>AI inside</li>
<li>AIdeaLab</li>
<li>Karakuri（カラクリ）</li>
<li>Kotoba Technologies Japan</li>
<li>NABLAS</li>
<li>Preferred Networks</li>
<li>Ricoh</li>
<li>Stockmark</li>
<li>SyntheticGestalt</li>
<li>Turing</li>
</ul>
<p>すでにGENIACの支援を受けた開発実績を有しており、第3期ではモデルの高度化や新機能の追加が焦点となる。</p>
<h2>GENIACの支援規模と今後のスケジュール</h2>
<p>GENIACは、経産省とNEDOが連携して進める国産生成AI開発支援プログラムで、2023年度から実施されている。今回の第3期採択により、累計支援件数は54件に拡大した。
対象期間：交付決定日〜2026年2月末まで
支援内容：GPUクラウド等の演算資源提供、外部評価機関による技術検証
今後の予定：NEDOによる中間評価、年度末までに開発成果の提出と発表が予定されている</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google Cloud、米西海底ケーブル「Sol」でフロリダ―スペインを直結──AI時代に備え大西洋ルートを刷新</title>
      <link>https://ledge.ai/articles/google_sol_transatlantic_cable_2025</link>
      <description><![CDATA[<p>Google Cloudは2025年7月10日、フロリダ州パームコーストとスペイン・サンタンデールを結ぶ新たな大西洋横断海底ケーブル「Sol（ソル）」の敷設計画を<a href="https://cloud.google.com/blog/products/infrastructure/announcing-sol-transatlantic-cable?hl=en">発表</a>した。AI需要の高まりに伴うクラウドトラフィックの急増に対応するため、Google独自のネットワークインフラをさらに強化するもので、経由地としてバミューダ諸島およびアゾレス諸島も含まれる。</p>
<p>同社は、既存の「Nuvem」や「Grace Hopper」との多重化により、北米―欧州間の通信において高いレジリエンシー（耐障害性）と低遅延を同時に実現する狙いだ。</p>
<h2>Googleが敷設する18本目の海底ケーブル</h2>
<p>Sol は、Googleにとって18本目となる自社単独または共同敷設の海底ケーブルで、光ファイバーによる総延長は約6,300kmに及ぶ見込みだ。スペイン語やポルトガル語で「太陽」を意味する「Sol」という名称は、温暖な気候にケーブルシステムの着床地点があることに由来するという。プロジェクトの建設は2025年後半に開始され、数年以内の運用開始を目指す。</p>
<h2>北米―欧州を結ぶ新ルート、フロリダからの初直結</h2>
<p>同プロジェクトの特徴は、米国東海岸の中でもフロリダ州を起点とする点にある。これまでGoogleの大西洋横断ケーブルは、主にニューヨークなど北部沿岸を起点としていたが、Sol は同社初の “フロリダ―欧州” 直結ケーブルとなる。フロリダ州パームコーストに陸揚げ局を設け、スペイン・カンタブリア州サンタンデールに到達。経由地としてアゾレス諸島およびバミューダ諸島にも接続することで、既存のNuvemケーブルとのネットワーク補完性を高める設計となっている。</p>
<p><strong>Nuvem海底ケーブルルート</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_Nuvem_subsea_cable_route_02f8293dda/The_Nuvem_subsea_cable_route_02f8293dda.jpg" alt="The Nuvem subsea cable route.jpg" /></p>
<h2>Nuvem、Grace Hopperとの冗長化構成を構築</h2>
<p>Googleは2023年に発表した南ルートの「Nuvem」および、北ルートの「Grace Hopper」（ニューヨーク―ビルバオ）と連携させることで、3系統のルートによるネットワークの多重冗長化を図る。特に「Sol」と「Nuvem」は、陸揚げ地点を一部共有し、障害発生時には瞬時に通信を切り替えられる構成とすることで、トラフィックの安定供給を実現する。また、経由地であるアゾレス・バミューダ間の接続によって、同社ネットワークの欧州・アフリカ・中南米への接続性も強化される。</p>
<h2>地域インフラへの波及効果</h2>
<p>陸揚げ地点であるスペイン・サンタンデールでは、Telefónica系インフラ企業Telxiusが地元の陸揚げ局を運営する予定で、北スペイン地域のデジタル化推進や経済活性化が期待されている。一方、パームコーストではGoogleが新たな接続拠点（Point of Presence：PoP）を設置し、フロリダ州内外のデータセンター群への高速接続網を形成する計画だ。</p>
<h2>AI時代のトラフィック増加に備えたネットワーク投資</h2>
<p>ChatGPTをはじめとする生成AIの普及や、企業によるクラウドサービスの依存度の高まりにより、グローバルインターネットトラフィックは急増を続けている。Google Cloudでは、42のクラウドリージョンを運用し、各地のAIワークロードやデータベース、ストレージ需要に応える形で、海底ケーブル網の整備を推進している。特に、データ処理のボトルネックとされる「帯域確保」と「低遅延ルート」の確保は、AIサービスの安定運用に直結する課題となっている。</p>
<h2>今後のスケジュールと展望</h2>
<p>「Sol」の建設開始は2025年後半とされており、Googleは「数年以内の運用開始」を予定している。完成後は、Google Cloudの欧州・南米間の接続性にも波及効果が期待されており、生成AIやクラウドインフラに対する今後の需要拡大に向けた長期的インフラ投資の一環と位置づけられている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AWS、仕様駆動型AI IDE「Kiro」を正式発表──“プロンプトから本番まで”エージェントが伴走</title>
      <link>https://ledge.ai/articles/aws_ai_ide_kiro_release</link>
      <description><![CDATA[<p>Amazon Web Services（AWS）は2025年7月14日、AIエージェントを中核に据えた新しい統合開発環境（IDE）「Kiro（キロ）」を<a href="https://aws.amazon.com/jp/blogs/news/introducing-kiro/">発表</a>した。</p>
<p>Kiroは、開発初期の曖昧なアイデアを、プロンプト1つで本番環境レベルのコードへと変換することを狙ったツールだ。プロダクト開発における「仕様と実装の乖離」問題に対処するため、仕様駆動型の設計支援機能を搭載しているという。現在パブリックプレビュー中で、<a href="https://kiro.dev">公式サイト</a>から無料でダウンロード可能となっている。</p>
<h2>AIエージェントを前提とした“Agentic IDE”</h2>
<p>Kiroは「Agentic IDE（エージェント的なIDE）」を掲げ、AIが設計からコーディング、テスト、ドキュメント生成に至る開発プロセス全体を支援する。OSS版Visual Studio Code（Code OSS）をベースとしており、既存のVS Code拡張機能やOpen VSXレジストリの資産をそのまま活用できる。</p>
<p>デスクトップアプリとして提供され、Mac・Windows・Linuxに対応している。ユーザーはGitHubやGoogleアカウントなどを用いたSSO（シングルサインオン）でログイン可能だ。</p>
<p><strong>AWSが取り組んでいるeコマースアプリの例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/compressed_1_app_72308f4e1e/compressed_1_app_72308f4e1e.gif" alt="compressed_1-app.gif" /></p>
<p>Kiroの中心的な機能は、自然言語による単一プロンプトを出発点として、要件定義（Requirements）、設計ドキュメント（Design）、およびタスクリスト（Task List）を自動的に生成する「Spec-Driven Development（仕様駆動開発）」にある。</p>
<p>これにより、開発者は「こんなアプリを作りたい」という抽象的な構想を与えるだけで、仕様に基づいたタスクが提示され、コード実装を進めやすくなるという。</p>
<p><strong>Kiroの要件仕様</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/compressed_2_reqs_f094da7ae6/compressed_2_reqs_f094da7ae6.gif" alt="compressed_2-reqs.gif" /></p>
<h2>仕様とコードの断絶を埋めるEARS記法と「Hook」</h2>
<p>Kiroは仕様記述にEARS（Easy Approach to Requirements Syntax）という形式を採用しており、要件の明確化とエッジケースの網羅性を重視している。これにより、曖昧な記述による実装ミスや意図の取り違えを最小限に抑える狙いがある。</p>
<p>さらに、Kiroは「Hook」と呼ばれるイベント駆動型の自動処理機能を搭載しており、ファイルの保存、生成、削除、Gitへのコミットなどのタイミングで、以下のような処理が自動的に実行される：</p>
<ul>
<li>ユニットテストの自動更新</li>
<li>コードドキュメントの生成</li>
<li>認証情報やシークレットの漏洩チェック</li>
</ul>
<p>これにより、開発者は品質管理やセキュリティの担保をエージェントに任せ、コアな開発作業に集中できるようになる。</p>
<h2>外部モデル接続と拡張性</h2>
<p>KiroはModel Context Protocol（MCP）にも対応しており、AWSが提供する大規模言語モデル（LLM）だけでなく、Anthropic Claudeやその他の外部LLM、外部APIツールとも連携できる。これにより、プロジェクトに応じて最適なAIエージェント群を構成する柔軟性を備えている。</p>
<p>また、MCPの採用により、複数のAIエージェントをプロジェクト横断で統制し、コード生成のコンテキストを維持したままやり取りができる設計になっている。</p>
<p>Kiroは現時点ではパブリックプレビューとして無料提供されており、年内には有償プラン（月額19.99ドル）を導入予定だという。正式版ではLLMへの問い合わせ回数に応じた制限や追加機能の提供が計画されているとのこと。</p>
<p>開発支援に特化したAIアシスタントとしては、AWSはすでに「Amazon Q Developer」を提供しているが、Kiroはこれとは異なり、プロジェクト全体を見渡しながら構造化された開発支援を行う点で明確に差別化されている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 08:50:00 GMT</pubDate>
    </item>
    <item>
      <title>荷物運搬を完全自動化　川崎重工のロボットポーター「FORRO」、三田ガーデンヒルズで国内最長6.6 kmルートを稼働開始</title>
      <link>https://ledge.ai/articles/robot_porter_forro_mita_kawasaki</link>
      <description><![CDATA[<p>川崎重工業は2025年7月7日、三井不動産レジデンシャルおよび三菱地所レジデンスが東京都港区にて共同開発した分譲マンション「三田ガーデンヒルズ」において、屋内配送用サービスロボット「FORRO（フォーロ）」を活用したロボットポーターサービス「FORRO PORTER」の本格稼働を開始したと<a href="https://forro-service.com/news/7BL7Bn9i7QBpNT2VbkcTiT/">発表</a>した。ロボットがマンション内で荷物を居住者の住戸前まで自動搬送するサービスで、延べ約6.6 kmに及ぶ館内ルートを4台のロボットが自律走行するという国内最大規模の導入例である。</p>
<p>@<a href="https://www.youtube.com/watch?v=tY46sRuFeSY">YouTube</a></p>
<h2>住戸前まで荷物を届けるロボットポーター</h2>
<p>FORRO PORTERは、マンションのエントランスに設置された専用ロッカーから、居住者の荷物を各住戸前まで搬送するロボットサービス。利用者はスマートフォンアプリや美和ロックの「ラクセスキー」から搬送を依頼でき、ロボットは館内のエレベーターやオートドアと連携しながら無人で目的地まで走行する。最大30kgまでの荷物を運べるほか、跳ね上げ式荷棚を採用しキャリーケースなどの積載にも対応しているという。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kawasaki_forro_mitsuigarden2_7e5b093c9a/kawasaki_forro_mitsuigarden2_7e5b093c9a.jpg" alt="kawasaki forro mitsuigarden2.jpg" /></p>
<h2>館内ルートは国内最長の6.6km、4台体制で稼働</h2>
<p>同サービスでは、ロボット4台が常時稼働し、館内の総延長約6.6kmにおよぶ移動ルートを活用して配送を行う。エントランスから住戸前までの全工程を無人で完結でき、これは日本国内で稼働する住居向けロボットポーターサービスとしては最大規模にあたるという。</p>
<p>各ロボットの動作は、大成建設が開発したロボット統合管制プラットフォーム「RoboHUB（ロボハブ）」を通じて遠隔監視され、セキュリティシステムと連動した高い安全性が確保されている。</p>
<h2>試験運用で高いリピート率、住民サービス向上へ</h2>
<p>FORRO PORTERは、2025年3月から三田ガーデンヒルズで先行して試験運用されており、期間中はポーターサービスの全依頼のうち20％以上がロボットによって担われたという。さらに、リピート利用率は50％を超える実績があり、居住者にとって利便性の高いサービスであることが示された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kawasaki_forro_mitsuigarden3_02db361826/kawasaki_forro_mitsuigarden3_02db361826.jpg" alt="kawasaki forro mitsuigarden3.jpg" /></p>
<h2>病院から住宅へ、川崎重工のロボット展開が拡大</h2>
<p>FORROは、もともと川崎重工が医療施設向けに開発した屋内搬送用ロボットで、これまでに病院での使用実績がある。今回の住宅分野への本格導入により、生活空間における物流の自動化という新たな領域への展開が進められたかたちだ。川崎重工は今後、住宅や商業施設など他分野への展開を視野に入れていると見られる。</p>
<h2>他ロボットとの連携も視野に</h2>
<p>三田ガーデンヒルズでは、将来的に清掃や警備など、他用途のロボットとの連携も計画されており、RoboHUBを中核としたロボット協働環境の構築が進められている。ロボットが日常的にマンションの中で稼働し、人の作業を支える仕組みが現実となりつつある。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 05:50:02 GMT</pubDate>
    </item>
    <item>
      <title>【視聴無料】“プロンプトの先”を知る──生成AI活用の真価を引き出すコンテキストエンジニアリングとは何か？</title>
      <link>https://ledge.ai/articles/webinar_about_context_engineering</link>
      <description><![CDATA[<p>生成AIの普及とともに、多くの現場で注目されたのが「プロンプトエンジニアリング」でした。ChatGPTに対して“うまく指示を出す方法”が話題となり、良い出力を得るための言い回しや構文テクニックが盛んに共有されてきました。</p>
<p>そうした中、2025年6月30日にGoogle DeepMindのシニアAIリレーションエンジニア、フィリップ・シュミット（Philipp Schmid）氏が発表したブログ記事が大きな注目を集めました。</p>
<p>\u003E「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」</p>
<p>大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトでは不十分であり、AIに与える文脈情報の設計が不可欠であるという提言です。</p>
<p>今回のウェビナーでは、新注目のキーワード「コンテキストエンジニアリング」の理解に向けて解説します。</p>
<h2>ウェビナー概要</h2>
<p><strong>\u003Cセッション内容（予定）\u003E</strong></p>
<ul>
<li>プロンプトエンジニアリングの限界</li>
<li>新注目のキーワード「コンテキストエンジニアリング」とは？</li>
<li>コンテキストエンジニアリングを支える技術群</li>
<li>業務活用・導入の最初の一歩はどこから進めるべきか？</li>
</ul>
<p><strong>開催概要</strong>
日時：2025年7月22日（火）11:00〜12:00
形式：Zoom Webinar（事前登録制・参加無料）
主催：株式会社レッジ</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_v-lGUvYEQjSm5j5_tUSOMg">視聴申込みはこちら</a>
:::</p>
<h2>ウェビナーの学びを“実践”に変えるために──レッジが提供する実践型研修ラインナップ</h2>
<p>ウェビナーで得た知識を、「なるほど」で終わらせず、実際に社内業務への浸透を進めていくために、レッジでは、生成AI活用を実務に落とし込む研修プログラムを各種ご提供しています。
助成金の適用や社内事情に合わせたカスタマイズも可能で、社内への定着と人材育成をセットで支援します。</p>
<h3><strong>生成AI × マーケティング研修（助成金適用で最大75%OFF）</strong></h3>
<ul>
<li>座学と実践演習で構成された3日間、合計15時間の研修パッケージ</li>
<li>マーケ業務（リサーチ→分析→企画→制作）における生成AIの活用術を紹介</li>
<li>人材開発支援助成金制度により、受講費用の最大75%の助成適用</li>
</ul>
<p><strong>\u003C研修タイムテーブル\u003E</strong>
<strong>Day 1：生成AIの基礎知識を獲得</strong></p>
<ul>
<li>オリエンテーション（30分）</li>
<li>生成AIとは何なのか？（90分）</li>
<li>生成AI活用における3つのトレンド（120分）</li>
<li>最新AI技術動向（60分）</li>
</ul>
<p><strong>Day 2：マーケティング業務への活用</strong></p>
<ul>
<li>Day 1の振り返り（30分）</li>
<li>プロンプトエンジニアリング（120分）</li>
<li>コンセプト設計（150分）</li>
</ul>
<p><strong>Day 3：例題演習によるスキル定着</strong></p>
<ul>
<li>新規事業企画演習（240分）</li>
<li>生成AIを活用していく際のポイント（60分）</li>
</ul>
<h3><strong>NOCODE + AI 研修</strong></h3>
<ul>
<li>「業務を自ら改善できる人材」を育成するための、DX時代のリテラシー研修</li>
<li>AIとノーコードツールの基礎から実践までを3日間で習得</li>
<li>DX推進のための基礎知識と実践スキルを、ビジネス部門の方にもわかりやすく解説</li>
<li>全3日間、座学と演習を通じて「つくれる」「活用できる」状態へ</li>
</ul>
<p><strong>\u003C研修で扱う主なテーマ\u003E</strong></p>
<ul>
<li>DX基礎：今さら聞けないデジタル変革の本質と業務視点の捉え方</li>
<li>ビジネスパーソンのためのAI活用術：生成AIでできること／できないことを実務に沿って理解</li>
<li>プロンプトエンジニアリング入門：AIに“正しく伝える”ための基礎技術</li>
<li>kintoneの基礎：ノーコード開発によるデータ管理と業務アプリの構築法</li>
</ul>
<h3><strong>バイブコーディング研修</strong></h3>
<ul>
<li>生成AIと“協働しながら開発する”という新たな開発手法を体験する研修</li>
<li>設計力・構造化思考・AI対話力を強化し、「AIと共に作る力」を育成</li>
<li>半日〜1日構成、非エンジニアの参加も可能</li>
</ul>
<p><strong>\u003C研修内容例\u003E</strong></p>
<ul>
<li>最新AI開発ツールの紹介</li>
<li>開発者の役割変化と未来像</li>
<li>ハンズオン演習（アプリケーション開発実践）</li>
<li>まとめ講義「エンジニアの未来」</li>
</ul>
<h3><strong>カスタマイズ型研修</strong></h3>
<p>生成AIの基礎理解から、RAG・アプリ開発・業務活用まで──
育成対象や業務課題に合わせてフルカスタマイズ可能な研修プログラムもご提供しています。</p>
<ul>
<li>会社の育成方針・レベル感・業務課題に合わせた設計が可能</li>
<li>部門別／階層別研修、社内コンテストや勉強会との連動も支援</li>
<li>グループ会社含む横展開を見据えた実施設計・運用サポートも対応</li>
</ul>
<p><strong>\u003C直近の実施事例\u003E</strong>
<strong>パナソニック株式会社様</strong>
対象：DX企画部
形式：オンライン＋オフライン（全2日程）
構成：
　Day 1：生成AIを含むAIの基礎講義
　Day 2：ノーコードツールを活用したRAGアプリ実装演習
参加者：約50名／回</p>
<p><strong>NECソリューションイノベータ株式会社様</strong>
対象：若手技術者
形式：オフライン（2日間×全4回）
構成：
　Day 1：生成AIを活用した企画手法講義＋アプリ企画ワーク
　Day 2：LLMを活用したアプリ開発ワークショップ
参加者：約30名／回
連動施策：研修後に社内生成AIコンテストを開催</p>
<h2>研修のお問い合わせ・ご相談</h2>
<ul>
<li>研修内容の詳細が知りたい</li>
<li>助成金の対象になるか相談したい</li>
<li>自社向けにアレンジしたい　…など、お気軽にご相談ください！</li>
</ul>
<p>:::button
<a href="https://zfrmz.com/Hrd1p1OXCBMiUaT3AiUu">お問い合わせはこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、“再学習ゼロ”の「ポータブルチューニング」公開──業務特化の生成AIモデルの運用コストを劇的削減、tsuzumiにも搭載</title>
      <link>https://ledge.ai/articles/portable_tuning_tsuzumi_no_retraining</link>
      <description><![CDATA[<p>NTTは2025年7月9日、生成AIの特化モデルを再学習せずに基盤モデル間で転移可能とする新技術「ポータブルチューニング」を<a href="https://group.ntt/jp/newsrelease/2025/07/09/250709a.html">発表</a>した。この技術は、基盤モデルのアップデートに伴って必要とされてきた再学習工程を不要にし、生成AIの低コストかつ持続可能な運用を可能にするもの。NTTは、同技術が将来の分散型AI構想「<a href="https://ledge.ai/articles/ntt_sakanaai_collaborate">AIコンステレーション®</a>」の実現にも貢献するとしている。</p>
<h2>カスタマイズコストの抜本的削減を実現</h2>
<p>生成AIを業務に応用する際、用途特化のカスタマイズが求められるが、基盤モデルが更新されるたびに再学習が必要となり、大きなコストと時間を要していた。NTTはこの課題に対し、特化学習で得た知見を、報酬モデルという中立的なモジュールを介して「持ち運ぶ」手法を開発。報酬モデルを一度構築すれば、異なる構造や規模の基盤モデルにも適用でき、再学習を行わずに高い性能を維持できると説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/250709ab_280afcd030/250709ab_280afcd030.jpg" alt="250709ab.jpg" /></p>
<h2>技術の仕組みと特徴</h2>
<p>ポータブルチューニングは、以下の3点を軸に構成されている。</p>
<ul>
<li><strong>報酬モデルによる出力補正</strong> ：特化学習の成果を、基盤モデルの出力を評価・調整する報酬モデルとして独立して学習。</li>
<li><strong>モデル非依存の汎用性</strong> ：報酬モデルは特定の基盤モデルに依存せず、構造やパラメータ数が異なる複数のモデルに転用可能。</li>
<li><strong>再学習工程の削減</strong> ：基盤モデルを更新しても報酬モデルを再利用できるため、再学習を行わずに特化性能を保持。</li>
</ul>
<p>これにより、モデル更新のたびに必要だったGPU使用やデータ再整理といったリソース投入が不要となり、運用面・環境面の両面での負荷を大幅に軽減できるとされる。</p>
<h2>「tsuzumi」など複数基盤モデルで検証</h2>
<p>NTTは、自社開発の日本語LLM「tsuzumi」を含む複数の基盤モデルに対してポータブルチューニングを適用し、特化性能を高水準で維持できることを確認したと述べている。実験では、異なるモデル間においても同一の報酬モデルを適用することで、再学習なしで特化出力の一貫性が保たれることを実証した。</p>
<p>さらに、NTTは本技術の研究成果を、2025年7月13日からカナダ・バンクーバーで開催されている国際機械学習会議（ICML 2025）で発表する予定としている。</p>
<h2>今後の展望</h2>
<p>NTTは今回の技術が、既存の軽量ファインチューニング手法（LoRA、QLoRAなど）と比較しても、再学習に伴う作業負荷・GPU時間・電力消費を本質的に削減できる点を強調している。</p>
<p>将来的には、複数の小型AIを連携・協調させる分散型AIネットワーク「AIコンステレーション®」構想の中核技術としても活用する計画で、今後は省電力型LLM群との組み合わせによる持続可能なAI運用環境の構築を目指す方針だ。</p>
<p>生成AIを導入する企業や自治体にとって、特化モデルを持続的に運用するための最大の障壁は「モデル更新のたびに再チューニングが必要」という運用コストであった。今回発表されたポータブルチューニングは、その運用課題を根本から解消する可能性がある。NTTは今後、外部パートナーと協力して、さまざまな業務用途への適用を広げる考えを示している。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テスラ車に xAI の新チャットボット「Grok」実装　まずは米国・最新モデルから配信開始</title>
      <link>https://ledge.ai/articles/tesla_ai_grok_ota_us_launch</link>
      <description><![CDATA[<p>テスラは2025年7月12日、自社開発の電気自動車に対し、イーロン・マスク氏が率いるAI企業xAIが開発した対話型AI「Grok」のベータ版を車載インフォテインメントシステムに統合したと<a href="https://x.com/Tesla/article/1944049704276283456">発表</a>した。</p>
<p>ソフトウェア更新「2025.26」にて配信を実施。米国市場における全モデルが対象となる。新車は同日以降に標準搭載され、既存車両もOTA（Over-the-Air）経由で段階的に対応するとのこと。GrokはApp Launcherまたはステアリングの音声ボタン長押しで起動し、Premium ConnectivityもしくはWi-Fi接続が利用の条件となる。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gvqmeg8_Ww_A_Agmi_K_8d8313ae4b/Gvqmeg8_Ww_A_Agmi_K_8d8313ae4b.jpg" alt="Gvqmeg8WwAAgmiK.jpg" /></p>
<h2>Grok搭載の全容と提供条件</h2>
<p>Grokは、xAIが提供する大規模言語モデルベースのチャットAIで、車内スクリーン上でテキストチャット形式のやりとりが可能となる。リリース当初の段階では雑談や情報検索、要約などの機能に限られており、車両の制御コマンド（ナビ、エアコン操作など）には対応していない。既存の音声認識機能とは分離して動作する構成である。</p>
<p>同機能は米国内の次の条件を満たす車両で提供される：</p>
<ul>
<li>モデルS／3／X／YおよびCybertruck</li>
<li>AMD製インフォテインメントCPUを搭載した車両</li>
<li>ソフトウェアバージョン2025.26以降</li>
<li>Premium Connectivity契約またはWi-Fi環境</li>
</ul>
<p>7月12日以降に米国で納車される車両にはプリインストール済みで出荷され、それ以前に納車された車両にはOTAアップデートとして段階的に展開される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e/Gvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e.jpg" alt="GvqmLdWXsAAbrsn.jpg" /></p>
<h2>起動方法とUI仕様</h2>
<p>Grokは、インフォテインメント中央スクリーンの「App Launcher」から、あるいはステアリングホイールの音声ボタンを長押しすることで起動可能である。ユーザーは対話形式で質問を入力し、AIが即時にテキストで応答する仕組みとなっている。チャット履歴は車両には保存されず、xAIサーバー上で匿名処理される。xAIアカウントとの連携も選択可能だが、ログインなしでも利用できる。</p>
<h2>今後の展望と業界動向</h2>
<p>今回のGrok搭載は、2025年7月10日に発表されたばかりの「<a href="https://ledge.ai/articles/grok4_xai_ai_model_launch">Grok 4</a>」モデルの直後に実施された。マスク氏は、今後テスラとxAIの関係を深める構想を公言しており、11月6日に予定されているテスラ株主総会ではxAIへの出資を議題として提起する意向も示されている。</p>
<p>車載AIの分野では、メルセデス・ベンツがOpenAIのChatGPTを統合した音声アシスタントを2023年から導入しており、BMWやヒュンダイなどもAmazonのLLM連携を進めている。テスラはそれらに対抗する形で、独自AIを自社車両に標準実装し、エッジ端末でのAI活用を推進する構えだ。</p>
<p>将来的には、Grokによるナビ設定やエアコン操作など車両制御への統合、また家庭用ロボット「Optimus」とのAI連携によるエコシステム構築なども見込まれており、同社のAI戦略の中核技術と位置付けられている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tesla_optimus_grot_37041f84fc/tesla_optimus_grot_37041f84fc.jpg" alt="tesla optimus grot.jpg" /></p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？──xAIが7月8日の \</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChromeとCometに照準──無料＆ローカルAIで OpenAI・Claude・Gemini・Ollamaを一括活用するOSSブラウザ「BrowserOS」登場</title>
      <link>https://ledge.ai/articles/rowseros_targets_chrome_and_comet</link>
      <description><![CDATA[<p>2025年7月12日（米国時間）、Y Combinatorに<a href="https://www.ycombinator.com/companies/browseros">採択</a>されたスタートアップ BrowserOS AI は、オープンソースの新型AIブラウザ「BrowserOS」最新版v0.12.1をGitHub上で<a href="https://github.com/browseros-ai/BrowserOS">公開</a>した。</p>
<p>このブラウザは、OpenAI、Anthropic Claude、Google Gemini、Ollama対応のローカルLLMを含む最大3つのAIモデルを同時比較可能な「Clash of GPTs」機能を搭載し、WindowsおよびmacOS向けに無償で提供されている。共同創業者Nikhil Sonti氏は、X（旧Twitter）にて「ブラウザは次のOSになる」と投稿し、Google ChromeやPerplexity Cometに対する“照準”を明確に示すミーム画像と共にリリースを発表した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/browser_os_07c0daa18e/browser_os_07c0daa18e.jpg" alt="browser os.jpg" /></p>
<h2>エージェントネイティブなOSSブラウザ「BrowserOS」</h2>
<p>BrowserOSは、Chromiumベースで構築されたオープンソースのブラウザで、AIエージェントによる作業の自動化を中核機能としている。ライセンスはAGPL-3.0で、すべてのコードはGitHub（browseros-ai/BrowserOS）上で公開されている。</p>
<p>ユーザーはOpenAIやClaude、Geminiといったクラウド型LLMをAPIキー持ち込み（BYOK：Bring Your Own Keys）で接続できるほか、Ollamaを通じてローカルLLM（例：LLaMA3、Mistral）を実行することも可能。ブックマーク、履歴、パスワードなどのデータはすべてローカル保存され、クラウドへの送信は一切行われない設計となっている。</p>
<h2>v0.12.1の主要アップデート</h2>
<p>最新版であるv0.12.1では、以下の主な機能が追加・改善された：</p>
<ul>
<li><strong>Clash of GPTs</strong> ：最大3モデル（例：GPT-4、Claude 3、Gemini 1.5）の応答を同時に比較できる新機能。プロンプトや返答の精度を横断的に検証可能。</li>
<li><strong>自動アップデート機能の導入</strong> ：v0.12.0から正式に適用され、パッチ配信が迅速化。</li>
<li><strong>Windows向けインストーラの軽量化</strong> ：ミニインストーラが提供され、初回起動までの導線が簡素化された。</li>
</ul>
<p>v0.11.0でWindows対応が加わったことでユーザー層が一気に広がり、今回のアップデートで安定性と操作性がさらに強化された。</p>
<h2>コミュニティと開発体制</h2>
<p>BrowserOSはGitHubで2,000以上のスターを獲得しており、1週間あたり数回の更新が続いている。2025年7月時点ではリリースタグが0.8.0から0.12.1まで急ピッチで進行しており、IssueやPRも活発にやり取りされている。</p>
<p>開発を主導するのは、元MetaおよびMicrosoftの機械学習基盤エンジニアであるNikhil Sonti氏とNithin Sonti氏の兄弟チーム。Nikhil氏はX上で「BrowserOSは検索エンジン企業でも広告企業でもなく、ローカルにデータをとどめることを最優先にしたプロダクトだ」と強調している。</p>
<h2>Perplexity CometやChromeとの対抗軸</h2>
<p>BrowserOSは、AI検索アシスタント「Perplexity Comet」の代替として注目されている。Cometが有料（月額20ドル以上）かつクラウド依存であるのに対し、BrowserOSは完全無料でローカル推論も可能な点が差別化ポイントとされる。また、Google Chromeのような一般的なブラウザと異なり、AIとの連携を前提に設計されており、タスク自動化、要約、フォーム入力支援といった機能を標準搭載している。</p>
<p>BrowserOS公式Xアカウントは7月12日に「Always has been」ミーム画像を投稿。地球＝Chrome、第2宇宙飛行士＝Comet、第3宇宙飛行士＝BrowserOSという構図で、現行のブラウザ支配構造に対してオープンソース・プライバシー志向の“照準”を定めるメッセージを打ち出している。</p>
<h2>今後のロードマップと展望</h2>
<p>BrowserOSのREADMEでは、今後の予定として以下の機能が記載されている：</p>
<ul>
<li>MCP（Multi-Agent Control Panel）によるAIエージェントの高度な管理機能</li>
<li>AI広告ブロッカー</li>
<li>ストア機能によるコミュニティ拡張性の強化</li>
</ul>
<p>また、GitHub上では日本語UI対応やプラグイン互換性向上に関するIssueも立ち上がっており、国際的なユーザー層への対応も進められている。</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NEC、独自開発LLM「cotomi」のエージェント性能を強化──128K対応とMCP準拠で高度専門業務の自動化を加速</title>
      <link>https://ledge.ai/articles/nec_cotomi_agent_upgrade_128k_mcp</link>
      <description><![CDATA[<p>NECは2025年7月8日、自社開発の生成AI「cotomi（コトミ）」のエージェント性能と連携機能を強化したと<a href="https://prtimes.jp/main/html/rd/p/000000989.000078149.html">発表</a>した。今回のアップデートでは、128Kトークンまでの長文コンテキスト処理能力と、AIエージェント間の標準プロトコル「Model Context Protocol（MCP）」への準拠を新たに実現し、企業の高度な専門業務を自律的に自動化する基盤としての機能を拡張した。NECはこの技術を活用し、企業の生産性向上と業務改革の促進を目指す。</p>
<h2>自社LLM「cotomi」の進化と背景</h2>
<p>cotomiは、<a href="https://ledge.ai/articles/nec_llm_cotomi">NECが独自開発</a>した大規模言語モデル（LLM）で、2024年より商用提供を開始している。日本語を中心に高精度な自然言語処理を行えることから、法務、製造、公共分野などの専門的な業務でも活用が進んでいる。</p>
<p>今回の強化は、従来のチャット型AIの利用にとどまらず、複雑で非定型な業務プロセスを“自律的にこなすAIエージェント”の実用化を視野に入れた取り組みだという。</p>
<h2>主な強化ポイント</h2>
<h3>1. エージェント性能の向上</h3>
<ul>
<li>問題解決型の再学習により、cotomiの推論精度とタスク分解能力が向上。</li>
<li>業務文脈に応じて適切なツール選択や指示出しが可能となり、複雑な業務でも自律的に処理が進む。</li>
</ul>
<h3>2. 128Kトークン対応</h3>
<ul>
<li>入力トークン数を従来の4Kや32Kから最大128Kまで拡張。</li>
<li>これにより、日本語で約20万字相当の文書を一括で扱えるようになり、長大な契約書や設計仕様書などへの対応力が飛躍的に向上した。</li>
<li>業務指示や制約条件を一度にまとめて提示できるため、操作の手間も軽減される。</li>
</ul>
<h3>3. MCP準拠による接続性の強化</h3>
<ul>
<li>cotomiは、MCP（Model Context Protocol）に準拠。これは、複数のAIエージェントや業務アプリケーションが標準的な手法で連携するための共通プロトコル。</li>
<li>NECは、米Box社と連携し、MCPを通じたクラウドストレージとの連携実証を行っている。</li>
<li>将来的には、異種AIや既存業務システムとのシームレスな接続が可能になり、業務全体の自動化が一層現実的になる。</li>
</ul>
<h2>想定されるユースケース</h2>
<p>NECは、以下のような高度な専門職種における自律型AIエージェントの活用を想定している。</p>
<ul>
<li><strong>法務</strong> ：過去の契約書や判例を参照し、条項を自動作成</li>
<li><strong>製造業</strong> ：設計仕様書から試験計画や部品表を自動生成</li>
<li><strong>公共分野</strong> ：政策立案時に関連法令やガイドラインを横断的に分析。</li>
</ul>
<p>これにより、従来は人手で行っていた調査や文書作成のプロセスが短縮され、担当者の判断支援が可能となる。</p>
<h2>今後の展開</h2>
<p>NECは、今回の機能強化を2025年7月中旬より既存顧客向けに順次提供開始する予定。また、2025年度内にはERPやCRMなど、基幹業務システムとのテンプレート連携も順次拡大していく方針である。</p>
<p>cotomiは、NECが掲げるデジタル事業戦略「BluStellar」の中核を担う技術とされており、今後は単なるツールとしてではなく、業務遂行そのものを担うAIエージェントとして企業活動に組み込まれることが期待されている。</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとの買収交渉が決裂、WindsurfはGoogleと契約締結──CEOらはDeepMindに移籍、契約額は約24億ドルとの報道も</title>
      <link>https://ledge.ai/articles/windsurf_google_deal_openai_exit</link>
      <description><![CDATA[<p>2025年7月11日、AIコードエディター「Windsurf Editor」を手がけるAIスタートアップWindsurfは、Googleとライセンス契約を締結したと公式ブログで<a href="https://windsurf.com/blog/windsurfs-next-stage">発表</a>した。同時に、ヴァルン・モハンCEO、共同創設者のドウグラス・チェン氏を含む一部の研究開発チームが、GoogleのAI研究機関DeepMindに移籍することも明らかにされた。複数の米メディアは、この契約総額が約24億ドル（約3,500億円）にのぼると報じている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/windsurf_blog_next_stage_c7a135ce6c/windsurf_blog_next_stage_c7a135ce6c.jpg" alt="windsurf blog next stage.jpg" /></p>
<h2>OpenAIとの買収交渉は期限切れで失効</h2>
<p>事情に詳しい関係者によれば、OpenAIは2024年末からWindsurfの買収を協議していた。取引規模は約30億ドルと<a href="https://ledge.ai/articles/openai_acquires_windsurf_for_ai_dev_tools_expansion">報じられていた</a>が、交渉は複雑化し、2025年7月10日の契約期限までに最終合意に至らなかった。背景には、OpenAIと主要出資元であるMicrosoftの関係や、GitHub Copilotとの競合調整が影響したとみられる。</p>
<p>なお、Windsurfは独立性を重視するスタンスを維持していたことも、交渉の難航に一因があったとみられている。</p>
<h2>Googleとの24億ドル契約、製品ライセンス供与が主眼</h2>
<p>買収が成立しなかった一方で、WindsurfはGoogleと新たな契約を結んだ。同社公式ブログによると、この契約はWindsurfが保有するAIコード生成技術の一部をGoogleに「非独占的ライセンス」として供与する内容であり、株式取得や企業統合は含まれていない。</p>
<p>Windsurfは今後も企業向けのAIコード編集ツールを独立して提供し続けると明言しており、既存顧客に対してはサポート体制を維持するとしている。</p>
<h2>DeepMindが主要人材を吸収、Geminiの開発加速へ</h2>
<p>契約の一環として、Windsurfの共同創業者ら主要メンバーがGoogle DeepMindに加わる。対象となるのはCEOのヴァルン・モハン氏、共同創設者ドウグラス・チェン氏のほか、研究開発チームの中核メンバーとされる。</p>
<p>Google DeepMindのCEOであるデミス・ハサビス氏は、自身のX（旧Twitter）上で「彼らの参加に非常に興奮している」とコメントし、Geminiの“エージェンティック・コーディング”機能開発に注力すると明かしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/demis_hassabis_x_about_windsurf_caaaa3b8fb/demis_hassabis_x_about_windsurf_caaaa3b8fb.jpg" alt="demis hassabis x about windsurf.jpg" /></p>
<h2>Windsurf社内体制は新たな経営陣へ移行</h2>
<p>人材移籍にともない、Windsurfでは経営体制の再編が行われた。新たにCOOのJeff Wang氏が暫定CEOに就任し、Graham Moreno氏が社長職を務める。今後は企業向け機能の強化や、新規パートナーシップの拡大に注力する方針を掲げている。</p>
<h2>業界背景：コード支援AIを巡る競争が激化</h2>
<p>AIを活用したコード補完・生成の分野では、GoogleのGemini、OpenAIのGPT-4o Turbo、MicrosoftのGitHub Copilot、MetaのCode Llamaなどが競合している。いずれも、ソフトウェア開発の生産性向上を狙いとした戦略的領域であり、優れたAI技術と人材の獲得が競争力の源泉となっている。</p>
<p>今回のWindsurfとのライセンス契約と人材移籍は、Googleがこの領域での優位性をさらに高める布石と捉えられている。</p>
]]></description>
      <pubDate>Mon, 14 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>電通グループがAI開発・活用の新組織「dentsu Japan AIセンター」を発足──約1,000名の専門人材で“AIネイティブカンパニー”を目指す</title>
      <link>https://ledge.ai/articles/dentsu_japan_ai_center_launch</link>
      <description><![CDATA[<p>電通グループの国内主要5社は2025年7月7日、AI開発と活用を横断的に推進する新組織「dentsu Japan AIセンター」を発足したことを<a href="https://www.dentsu.co.jp/news/release/2025/0707-010909.html">発表</a>した。同センターは約1,000名のAI専門人材を擁し、グループおよび顧客企業の全社的なAI変革を加速させることを目的としている。</p>
<h2>AI変革を牽引する中核組織</h2>
<p>同センターは、AIを単なる業務効率化手段ではなく、企業の経営・組織そのものを変革する中核要素と位置づけており、グループ横断でのリソース統合により、迅速かつ高度なAI活用を図るとしている。これにより、従来は部門ごとに分散していたAI導入の取り組みを、経営層・技術部門・事業部門が一体となって推進する体制が整備されることになる。</p>
<h2>主な活動領域とユニット構成</h2>
<p>dentsu Japan AIセンターは、以下6つの専門ユニットを設けており、それぞれの領域でAI技術の導入と価値創出に取り組む：</p>
<ul>
<li><strong>AI業務効率化ユニット</strong> ：グループ内向けのAIツール開発・導入を担い、生産性向上を推進</li>
<li><strong>AIマーケティング＆クリエイティブ高度化ユニット</strong> ：広告制作・メディア運用におけるAI活用を支援</li>
<li><strong>統合マーケティングAIエージェント開発ユニット</strong> ：複数のAIアプリを統合するエージェント技術を開発</li>
<li><strong>AI・データインフラ強化ユニット</strong>：電通独自のデータ基盤「People Model」などのインフラを拡張</li>
<li><strong>AIマーケティングトランスフォーメーション（AIMX）ユニット</strong> ：顧客企業のマーケティング変革を支援</li>
<li><strong>AIトランスフォーメーションユニット</strong> ：経営・人事・営業など非マーケティング領域のAI導入を支援</li>
</ul>
<h2>ガバナンス体制と外部連携</h2>
<p>同センターは、グループ内のAI利用ルールを策定・管理する「dentsu Japan AIガバナンスコミッティ」と連携し、ガバナンスと実装の両面でAI活用の高度化を進める。また、大学・研究機関との共同研究成果を取り込むことで、先端技術の実用化を図る構えだ。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>これからのAIスキルは「プロンプト」ではなく「コンテキスト・エンジニアリング」──Google DeepMind フィリップ・シュミット氏が提起</title>
      <link>https://ledge.ai/articles/context_engineering_deepmind</link>
      <description><![CDATA[<p>2025年6月30日、Google DeepMindのシニアAIリレーションエンジニアであるフィリップ・シュミット（Philipp Schmid）氏が自身のブログを通じて、「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」と<a href="https://www.philschmid.de/context-engineering">提起</a>した。大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトだけでは不十分であり、AIに与える前提情報全体を設計・最適化する技術が不可欠だと論じている。</p>
<h2>背景：プロンプトエンジニアリングの行き詰まり</h2>
<p>近年、生成AIの発展に伴い「プロンプトエンジニアリング」が注目を集めてきた。巧みなプロンプトを用いてモデルの挙動を調整し、より望ましい回答を得るという技法は、AI活用の第一歩として広く普及している。しかしシュミット氏は、現実の業務環境ではプロンプトの工夫だけで対応できない課題が増大しており、AIが真にユーザーの期待に応えるには、より包括的な情報構造の設計が必要だと指摘した。</p>
<h2>コンテキストエンジニアリングとは</h2>
<p>シュミット氏は、コンテキストエンジニアリングを「AIが必要とする情報を、適切な形式で、適切なタイミングに提供する仕組みの設計」と位置付ける。単にプロンプトを最適化するのではなく、モデルに取り込ませる知識、会話履歴、外部ツールとの連携などを含めて制御する総合的な技術領域だと説明する。</p>
<p>具体的には、</p>
<ul>
<li>System Prompt（AIのシステム的前提）</li>
<li>User Prompt（ユーザーからの指示）</li>
<li>State/History（対話履歴や状態管理）</li>
<li>Long-Term Memory（長期記憶としての知識）</li>
<li>Retrieved Information（RAGなどによる検索情報）</li>
<li>Tools/Structured Output（外部ツール連携・構造化出力）
という6つの構成要素を「コンテキスト」として設計し、動的に最適化していく考え方を示している。</li>
</ul>
<h2>8割の失敗は文脈不足</h2>
<p>シュミット氏は、AIエージェント開発における8割の失敗が「文脈情報の欠落」に起因すると述べている。たとえばカレンダー調整を行うAIエージェントの場合でも、ユーザーの希望や優先順位を把握しないまま単純な操作を試みることでエラーが起きやすいと説明している。</p>
<h2>関連技術と支える手法</h2>
<p>同氏は、コンテキストエンジニアリングを支える技術として、</p>
<ul>
<li>検索拡張生成（RAG）</li>
<li>ベクトルデータベース検索</li>
<li>ツール呼び出しのオーケストレーション</li>
<li>会話履歴管理
などの仕組みが必要だと述べている。これらを組み合わせることで、AIが常に適切な前提情報を取得しながら出力を行える環境を整備できるとする。</li>
</ul>
<h2>エンタープライズでの展開</h2>
<p>シュミット氏は、コンテキストエンジニアリングがエンタープライズ分野においても重要であると述べている。社内ドメイン知識や業務ルールをAIが正しく理解できるようにするために、前提情報の整理と統合を体系的に設計する必要があるとしている。</p>
<p>筆者プロフィール
フィリップ・シュミット氏は、Hugging Faceのエンジニアを経てGoogle DeepMindに参画。大規模言語モデルとエージェント技術の実用化に関する知見を広く発信している。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“行動するAI”が現実に　2025年上半期のAIエージェントの現在地は</title>
      <link>https://ledge.ai/articles/expo-2025-summer-ai-agent</link>
      <description><![CDATA[<p>2025年は「AIエージェント元年」と言われている。従来のAIが「入力に対して答えを生成する存在」であったのに対し、AIエージェントは「入力に対して自律的に行動する存在」として設計されている。人間の指示を待つのではなく、自らタスクを計画し、実行するというのが最大の特徴だ。本稿では、AIエージェントの概念を説明するとともに、最新の押さえておくべき内容を整理してお届けする。</p>
<h2>AIエージェントとは？</h2>
<p>AIエージェントという概念は、近年の生成AIブームを背景に脚光を浴びているが、実はコンピューターサイエンスやロボット工学の分野で長く研究されてきたものであり、特に1980年代のロドニー・ブルックスらによる自立型ロボットの研究が注目を集めた。この流れは、2000年に登場した自動掃除機ルンバといった製品にも結実している。
その後、機械学習技術の進展に伴い、ロボットから知的なシステムへ進化を遂げ、最近のLLMの台頭により、より複雑な問題を自律的に解決できる「AIエージェント」という新たな枠組みとして再定義されるようになった。</p>
<p>AIエージェントとは、「ある目標を達成するために、自律的に行動するソフトウェアプログラムやシステム」である。概念的には【個性】【記憶】【計画】【行動】の4つの機能で構成されており、互いに作用しあうことでタスクを実行できる。
それぞれを簡単に説明すると以下の通りだ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_305d989ebb/AI_305d989ebb.png" alt="AIエージェントの機能.png" /></p>
<ol>
<li>個性（Profile）
　年齢・職業などの情報で、エージェントの目的や役割、行動原則などを定義するものである。AIエージェントのふるまいに影響を与える。</li>
<li>記憶（Memory）
　過去のやり取りや外部情報を保持し、判断や行動に活かす機能である。短期記憶と長期記憶に分かれて処理する。</li>
<li>計画（Planning）
　目標達成のためにタスクを分解し、順序を設計・選択する機能である。</li>
<li>行動（Action）
　具体的なタスクの実行を定義する機能である。各種システムやツールの呼び出し、API実行、ユーザーへの応答など、現実世界への働きかけを行う。</li>
</ol>
<p>しかし、「行動」まで行えるAIエージェントはまだ限られている。多くのAIエージェントは、計画や推論まではできても、例えばツール操作やアプリ連携など、物理的なアクションまで行える例は限定的で発展途上なのである。</p>
<h3>「AIエージェント」と「エージェント型AI」の違い、説明できますか？</h3>
<p>2025年5月14日に、ガートナーから興味深いリリースがあった。「AIエージェント」と「エージェント型AI（エージェンティックAI）」の違いについて記したもので、その違いは以下の通りと説明されていた。</p>
<p><strong>AIエージェント</strong>
特定のタスクを自律的または半自律的にこなすソフトウェア。チャットボットやRPAが該当する。</p>
<p><strong>エージェント型AI（エージェンティックAI）</strong>
目的を達成するために、計画や知覚、ツール利用、記憶、AIの不適切な挙動を抑止するための制御措置を備えた自律システム。企業の意思決定や業務遂行を代理で行う。
ガートナーによれば、エージェント型AIの特徴は、以下の5つの機能を統合している点にあるという。</p>
<ul>
<li>センシング（知覚）：周囲の状況や環境の変化を把握する</li>
<li>記憶：過去のやり取りや状態を保持し、それを活用する</li>
<li>計画立案：目標に向けた複数ステップを自律的に構成する</li>
<li>ツール利用：必要に応じて外部ツールやAPIを連携して活用する</li>
<li>ガードレール：安全性やコンプライアンスを担保するための制御機構を備える</li>
</ul>
<p>ガートナーでは、「エージェント型AI」を「AIエージェント」の上位概念として位置付けているという。一方で、Ledge.aiの指す「AIエージェント」は、ガートナーの示すAIエージェント＋エージェント型AIの両方を含む広義の概念に近い。混乱を防ぐために、記事内ではすべて「AIエージェント」に統一させていただく。</p>
<h2>「行動」できるAIエージェントの代表例は？</h2>
<p>上のセクションで、『「行動」まで行えるAIエージェントはまだ限られている』と記したが、現在「行動」までできるAIエージェントの代表例として、<strong>研究分野とロボット分野</strong>が挙げられる。</p>
<h3>AI実験アシスタント「Coscientist」</h3>
<p>カーネギー・メロン大学が開発した「Coscientist」は、GPT-4をベースとしたAI実験アシスタントで、科学実験の設計・計画・実行までを自律的に行っている。
世界的に注目を集めた事例として、Coscientistはノーベル化学賞の受賞対象となった複雑な化学反応を数分で自律的に学習して実行した例が挙げられる。2010年のノーベル化学賞の対象となった「パラジウム触媒クロスカップリング反応」は人であれば膨大な専門知識と時間を要して実行するものだ。</p>
<p>Coscientistは相互に作用し合う複数のモジュールで構成されており、中心的なモジュールである「Planner」がユーザー入力に基づいて実験を計画。Plannerは、GOOGLE、PYTHON、DOCUMENTATION、EXPERIMENTという4つのコマンドを使って行動空間を定義するという。</p>
<ul>
<li>GOOGLE：Google Search APIを使ってインターネット検索を行う。</li>
<li>PYTHON：「コード実行」モジュールを用いて、プランナーは実験の準備のための計算を実行する。</li>
<li>DOCUMENTATION：実験に必要な文章情報を検索し、提供する。</li>
<li>EXPERIMENT：DOCUMENTATIONで生成されたコードをAPIを通じて実行する。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nature_1_28a9b4146d/nature_1_28a9b4146d.png" alt="nature_1.png" />
このような仕組みで、従来の実験プロセスでは数週間から数か月かかるタスクを、わずか数時間で完了させうるポテンシャルを示している。</p>
<h3>BMW工場での試験運用「Figure 02」</h3>
<p>BMWは、米サウスカロライナ州スパータンバーグ工場において、Figure社が開発したヒューマノイドロボット「Figure 02」の試験運用を開始。Figure 02は、シャーシ組み立ての一部を担い、運ばれてきた金属板部品を固定具に挿入する作業を行っているという。本ロボットは、6台のRGBカメラや音声認識用マイク、OpenAIと共同開発した対話モデルを搭載し、作業者との自然なコミュニケーションを可能にしている。</p>
<p>Figure02のロボット制御技術を支える中核的存在が、Vision-Language-Action（VLA）モデルである「Helix」だ。視覚と言語情報を統合したVLAモデルであるHelixにより、状況を理解し、適切な行動を自律的に選択・実行できるようになっている。
Helixは、「System 2（S2）」と「System 1（S1）」という2つの補完的なシステムで構成されており、この2層構造により、S2は高レベルの目標について「ゆっくり考え」、S1は実際の動作を「迅速に実行」することが可能となり、人間のような柔軟で適応的な行動が実現されている。</p>
<ul>
<li>System2：インターネットで事前学習された視覚言語モデル（VLM）で、7〜9Hzの速度で動作。シーンの理解や言語の解釈を担当し、物体やコンテキストに対する広範な一般化を可能にする。</li>
<li>System1：S2が生成した意味表現を受け取り、ロボットの動作を200Hzの高速で制御する。</li>
</ul>
<p>Figure社の創設者兼CEOであるブレッド・アドコック氏の発表によると、Figure 02の作業は従来比で4倍のスピード、7倍の精度を実現し、信頼性も大きく向上しているという。現在は1日あたり約1,000件のタスクを完全自律でこなしており、今後さらに多くの実データを蓄積しながらAIモデルの継続的な改善が見込まれている。</p>
<h2>注目のAIエージェント</h2>
<h3>GoogleとSalesforceの協業によるセールスエージェント「Agentforce」</h3>
<p>Salesforceから、AIエージェント「Agentforce」が日本でも提供開始されたのは2024年10月だが、2025年2月にSalesforceとGoogleが戦略的パートナーシップの拡大を発表した。これにより、Googleの最新AIモデル「Gemini」がAgentforceに統合され、マルチモーダルAI技術を活用できるようになるなど、性能強化が行われることとなった。</p>
<p>Agentforceは主に以下のような機能がある。</p>
<p><strong>Service Agent</strong>
　従来のチャットボットに代わり、自律型AIがシナリオなしで多様な顧客対応を行う。
<strong>Sales Development Representativ</strong>
　24時間体制で営業パイプラインを管理し、リードデータに基づくパーソナライズメールの送信や商談化の自動引き継ぎ、CRMや外部データを活用した質疑応答まで対応。
<strong>Sales Coach</strong>
　CRMデータをもとに商談ステージごとのフィードバックを提供、また、セールスピッチやロールプレイの分析・改善提案も行う
<strong>Personal Shopper</strong>
　Webサイトやメッセージングアプリ上でパーソナライズされた会話を通じて商品を案内・提案
<strong>Campaign Optimizer</strong>
　キャンペーン概要の生成からターゲット選定、コンテンツ作成、カスタマージャーニー構築、KPIに基づく継続的な分析・改善提案
<strong>Agentforce</strong>
　Salesforce上でのアクションを自然言語で指示するだけで、タスクを自律的に支援しながら学習・改善を重ね、業務効率と生産性を高める</p>
<p>Agentforceを支えるのは“Atlas Reasoning Engine”という技術であり、これは、“頭脳”として、意思決定と学習プロセスの中核を担うエンジンだ。具体的に言うと、高度な推論能力によって計画を生成し、RAGの技術などを利用しながら、情報収集を行う。また、「ガードレール」と呼ばれる機能によって、倫理的および組織のルールに準拠した制御を行い、信頼性を担保しているという。</p>
<p>さらにSaleceforceは2025年5月、このAgentforceの機能を「Agentforce for HR Service」として、人事向けに提供している同社のサービスEmployee PortalとHR Serviceに組み込むと発表した。今後、同社の展開するサービスでAIエージェントの機能がさらに拡充していくだろう。</p>
<h3>Microsoftが独自開発する「Microsoft 365 Copilot for Sales」</h3>
<p>Agentforceの対抗馬として注目したいのが、Microsoftのセールスエージェントである。</p>
<p>Microsoft 365 Copilot for Salesは、営業活動を効率化することを目的に作られたセールスエージェント機能だ。Microsoft Dynamics 365 SalesやSalesforce Sales CloudなどのCRMプラットフォームと連携し、OutlookやTeamsなどのMicrosoft 365アプリケーション内で営業活動を効率化するさまざまな実行機能を提供するという。</p>
<p>主な機能は以下の通りだ。</p>
<p>【メール作成（Outlook）】
・メールの要約
・メール下書きの生成
・会議を要約したメールの作成
・CRM関連データの表示
など</p>
<p>【会議関連（Teams）】
・ミーティングの要約作成
・タスクの提案
・CRMデータの表示
・感情分析
など</p>
<p>CRMデータを活用した対応、メールや会議の要約、タスクの自動生成などを自律的に実行する機能が備わったことで、Saleseforce同様、営業業務の効率化に貢献する機能となっている。日本語にも対応しており、国内企業でもすぐに活用できるのも利点である。</p>
<h3>中国スタートアップの「Manus」</h3>
<p>Manusは2025年3月に登場した完全自律型のAIエージェントで、従来のチャットボットとは一線を画す存在として注目を集めている。
ユーザーの初期指示だけで複雑なタスクを自律的に計画・実行するとされ、細かい指示がなくともタスクを実行できるとのこと。使用しているLLMは、AnthropicのClaude 3.5 SonnetやAlibabaのQwenのモデルをファインチューニングして利用している。複数のエージェントに分かれて計画と実行を行っており、外部ツールとの連携も可能だ。また、過去の作業履歴を記憶し、再度利用することもできる。</p>
<p>Manusの利用例としては、インターネットから収集した情報を要約・分析しレポート化やToDoリストの作成、Webサイトの構築などが挙げられている。</p>
<p>しかし、実際にManusを利用できるのは世界でもごくわずかであり、招待コードを受け取ったユーザーのみだ。その招待コードの取得には300万人が殺到したとの情報もあり、また一部では高値で取引されたというニュースもある。</p>
<p>全容がまだ読めないManusであるが、2025年4月に「Manus東京イベント」というイベントが東京都渋谷区で開催され、そこにはManusの共同創設者であるタオ・チャン氏が登壇。イベント内でタオ氏から「東京にManusのオフィスを設立する」という発表が飛び出した。
世界的な注目を集めるManusが今後、日本市場でどのように展開していくのか、その動向にも注目である。</p>
<h2>日本国内のAIエージェントの現在地はどうか？</h2>
<p>日本企業が取り組むAIエージェント開発の取り組みについても紹介しておこう。今回は、富士通株式会社、LINEヤフー株式会社、株式会社PKSHA Technology、株式会社Algomaticの4社に話を聞いた。</p>
<h3><strong>富士通が挑むAIエージェント</strong>「<strong>Fujitsu Kozuchi AI Agent</strong>」</h3>
<p>多くの企業がAIエージェント開発に参入する中、富士通株式会社が提供しているのは「Fujitsu Kozuchi AI Agent」だ。今回は、富士通が開発を進めるFujitsu Kozuchi AI Agentについて、開発担当の浅井氏、ビジネス担当者の利根氏にお話を伺った。</p>
<p><strong>「Fujitsu Kozuchi AI Agent」とは？</strong>
Fujitsu Kozuchi AI Agentは、富士通のAIサービス「Fujitsu Kozuchi」の一製品として展開されている。現在提供しているのが「会議AIエージェント」だ。浅井氏が「参加者が問いを投げなくても、会話の文脈を読み取り、AI自身が“これは問いだ”と判断した上で最適な応答やデータ提示を行う構造になっています」と語るように、従来のAIが人の問いかけに応じる“受動型”だったのに対し、本エージェントは人の会話をリアルタイムに聴き取り、問いを自ら立てて解決を試みる“自律型”である点が特徴だ。</p>
<p>本エージェントが優れているのは、「抽象的な会話」から「構造化された問い・タスク」に変換する能力だ。特に注目すべきは、会話のコンテキストを踏まえた“問いの立案”と“問題分解”のプロセスである。たとえば会議中で「今月の売上が落ちているのでは？」という発言が出た場合、AIはこれを単なる情報ではなく“解くべき問い”として捉える。こうした「タスクの計画」のプロセスには、短期・長期記憶のメモリ管理、問いの階層化、会議のカテゴリ認識など複数のAI技術が活用されており、使用されている技術の中には、特許を出願中のものもあるという。</p>
<p>Fujitsu Kozuchi AI Agentの実行フェーズでは、AIが会話の流れを読み取り、自律的に棒グラフや折れ線グラフなどの可視化を行う。特筆すべきは、その一連の動作に人の指示や承認を必要としない点だ。利根氏は「まるで会議の参加者の一人が、“この資料があると助かりますよね”とチャットにさりげなく差し込むような振る舞いです」と説明する。なお、実用にあたっては、会議の目的や前提条件を自然言語やGUIで事前に設定する仕組みも備えており、より会議に適した形でAIエージェントが作用するよう設計されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_f74b063e52/1_f74b063e52.png" alt="富士通_1.png" /></p>
<p>Fujitsu Kozuchi AI Agentでは、富士通が開発する日本語強化型LLM「Takane」のほか、OpenAIのGPTシリーズなどとも接続可能。ユーザー企業ごとの業務に特化させるためのファインチューニングやプロンプト設計も支援されており、まさに“企業専用エージェント”を構築するための土台が整えられている。現状では、インプットされたデータの範囲内で動作するが、今後は社内ERPや基幹システムとのAPI連携も視野に入れ、エージェントが社内外のデータと自在に接続できる環境を整備していく構想も進行中だ。</p>
<p>セキュリティ領域では“攻撃者と防御者”を模したマルチエージェントを用いた共創学習の試みも進行中。これはエージェント同士が対話・競合しながら能力を高め合う先進的なアプローチであり、今後の企業運用への応用が期待される。</p>
<p><strong>AIエージェントの進化は“育てながら使う”時代へ</strong>
「導入しただけではなく、使い続けることで“熟練者”として機能するようになります」と利根氏が語るよう、Fujitsu Kozuchi AI Agentは、導入すれば即万能というわけではない。「育てながら、ユーザーとともに進化していく」という姿勢が、今後のAIエージェント普及の鍵になる。
生成AIの次フェーズを担う「自律型AIエージェント」。その先端を走るKozuchiの動向からは、AIがどのように“組織の知能”となっていくかの未来像が垣間見えた。</p>
<h3><strong>LINEヤフーが描く</strong>「<strong>パーソナルエージェント</strong>」<strong>の構想</strong></h3>
<p>LINEヤフー株式会社は2025年5月、「パーソナルエージェント」という新たな構想を発表した。このパーソナルエージェントは、単なる情報提供にとどまらず、ユーザーの状況を理解したうえで、最適な情報を提案し、必要に応じて“行動”までも代行する存在として構想されている。</p>
<p>「私たちが目指しているのは、ユーザー一人ひとりにとって本当に必要な情報を、適切なタイミングで届けること。そして、その先にある“購入”や“予約”といったアクションまでを、自然に引き受けられるエージェントです」と同社担当が語るように、あくまで人に寄り添い、日常に溶け込む存在としてのAI像を描いている。この構想の中核には、LINEヤフーが提供する多様な自社サービスの横断的な連携がある。LINE、Yahoo! JAPAN、PayPayといった個別のサービスが、それぞれの機能を越えて連携することで、一貫した体験をもたらすことができる。これにより、従来は分断されがちだった「情報取得」から「行動」までの流れがシームレスに統合されることが期待されている。「当社はメディア、コマース、ローカル情報といった多様な領域にサービスを展開しているだけでなく、LINE公式アカウントやPayPayといった“店舗との接点”も保有しています。そうした基盤を活用すれば、単なるおすすめ情報の提示にとどまらず、そのまま行動に移せる導線を設計することが可能です」と担当者は続ける。パーソナルエージェントのユーザー体験としては、たとえば、日々のニュースや気になるイベントの情報が自然に届き、興味があればそのまま予約を完了させることができるといった流れが想定されている。こうした一連の体験は、ユーザーが意識せずとも背後でAIが行動を先読みし、最適な提案と実行を行うことで成り立つ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/LINE_e2fd0914f9/LINE_e2fd0914f9.png" alt="LINEヤフー.png" /></p>
<p>なお、エージェントに搭載されるLLMについては、現時点では具体的なモデルの選定には至っていないという。「各LLMには異なる強みがあり、今後も技術革新が続くことが想定されます。私たちはLINEヤフーの各サービスとの親和性を重視しながら、ドメインごとに最適なモデルを選定・最適化していくつもりです」と担当者は語る。汎用的なLLMをそのまま利用するのではなく、用途や文脈に応じたきめ細やかな調整が前提となる。</p>
<p>さらに注目すべきは、こうした構想の裏側で支えるインフラ設計である。複数サービスをまたぐAIエージェントの実装は、他社においても技術的なハードルが高く、まだ事例は多くない。しかし同社では、既存のシステム資産を巧みに活用することで、この課題に挑もうとしている。「AIエージェントは、LINEやYahoo! JAPANで長年培ってきたシステム基盤をもとに設計していきます。ゼロから新たに構築するのではなく、すでに動いているインフラを土台にすることで、実装スピードや安定性の面でも優位性があると考えています」</p>
<p>生活の中に自然に入り込み、ユーザーに負担をかけることなく情報や行動を支援するパーソナルエージェント。その実現には、技術だけでなく、ユーザー理解や体験設計といった多角的な視点が求められる。LINEヤフーの取り組みは、国内企業におけるAIエージェント活用の重要なマイルストーンとなり得るだろう。</p>
<h3><strong>PKSHAが描く</strong>“<strong>人と共に働くAI</strong>” 　<strong>全国7,000体のエージェントが稼働中</strong></h3>
<p>株式会社PKSHA Technologyが展開する「PKSHA AI Agents」は、単なる対話型AIにとどまらず、実際に業務を遂行する“働くAI”として、企業や自治体に広く導入が進んでいる。<strong>全国47都道府県で既に7,000体以上のAIエージェントが稼働</strong>しており、業務の自動化と生産性向上に貢献している。</p>
<p>同社代表の上野山勝也氏が「AIエージェントは、物知りなAIから考えるAI、そして行動するAIへの進化の一形態である」と語るように、従来の生成AIやRAGが知識提供に特化していたのに対し、AIエージェントはユーザーの課題や文脈を理解し、複数の処理を組み合わせて能動的に動くAIである。<strong>日本社会が抱える深刻な人手不足の中で、実働するAIとしての価値は日増しに高まっている</strong>。</p>
<p>PKSHAのAIエージェントは、大きく2つの形態に分類される。一つは、顧客の要望に応じてセミカスタマイズする「プロジェクト型」。もう一つは、既製品として提供する「プロダクト型」である。たとえば、同社が提供する「AI Helpdesk」というAIエージェントは、Microsoft Teamsに組み込まれ、社内の問い合わせ対応を自動化する。FAQ検索、ドキュメントからの回答生成、有人対応への引き継ぎといった機能を持ち、問い合わせ内容に合わせて判断し、最適な手段で解決を試みる仕組みである。また、AIエージェントが答えを持たない場合は、課題を抽出して新たなナレッジを作成し、人のレビューを経て再学習させる。この人とAIの協調によって、ナレッジは日々進化し、より的確な応答が可能となっていく。さらに、全社員向けに通知を行う「プロアクティブエージェント」なども開発しており、従業員とのインタラクションを積極的に支援している。</p>
<p>上野山氏は国内におけるAIの浸透に対して、「PoCにとどまらず、社会実装まで進めることが重要だ」と強調した。AIエージェントの定義があいまいなままでは、実証実験で終わってしまい、現場で“働く”AIにはならない。何ができて何ができないかを明確にした上で、実行可能なユースケースに落とし込むことが求められる。PKSHAの取り組みは、単なる技術実験にとどまらず、社会の中でAIが労働力の一部として機能する未来を切り拓こうとしている。日本発のAIエージェントが、実装と実働を通じて世界に示すモデルとなる日も近い。</p>
<h3><strong>採用も営業も“実行”するAIへ</strong>　<strong>株式会社Algomatic</strong></h3>
<p>株式会社Algomaticは、AIエージェントによる業務自動化の最前線を走るスタートアップとして、業務特化型ソリューションを展開している。今回は「リクルタAI」を開発している株式会社Algomatic Works COO 高橋氏と、「アポドリ」を開発した執行役員／ネオセールスカンパニーCEO 池田氏に話を聞いた。</p>
<p><strong>スカウト業務を実行「リクルタAI」</strong>
「リクルタAI」は同社が提供する採用特化型AIエージェントのブランド名で、現在は「スカウト」「書類選考」「面談」の3種類のエージェントを提供中。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_4a28c37604/_4a28c37604.png" alt="リクルタ.png" /></p>
<p>スカウトに特化した「リクルタAI ダイレクト採用」は、採用担当者が求人票や採用要件といった情報をインプットすると、各社の採用方針に沿った採用候補者のリストアップや、パーソナライズしたスカウト文の作成・送付を全自動で実行する。
高橋氏は「常時稼働しているAIエージェントが、転職希望者の転職意欲やその温度感の変化をリアルタイムで捉えるため、セットアップ後は『待っているだけ』で、求めている候補者との面談が獲得できる」と話す。実際、導入企業であるシンプレクス・ホールディングス株式会社では、スカウト返信率が従来の約10倍に向上している。また、1台のAIエージェントが人間数人分の成果を実現できているという事例もある。</p>
<p>この機能を支えるのがAIエージェント型のアーキテクチャである。スカウト送信を行う機能に加え。「上司AI」とでも呼ぶべき機能も実装されておりが、誤送信や誤字、企業情報の間違いなどを検知して送信を制御。。AIの暴走を防ぐガードレール機能も整備されており、ブラウザ上で自律的な実行を行いながら、必要に応じて人の承認フローを踏むなどの対策が練られている。</p>
<p>2025年5月22日には、転職エージェント・人材派遣企業向けの「リクルタAI プレ面談」もリリース。の採用AIエージェントが候補者ヒアリングから職務経歴書の代筆、マッチする求人の提案までを遂行する機能を持つという。</p>
<p><strong>営業活動を代替する「アポドリ」</strong>
アポドリは、BtoB営業のプロセスをAIエージェントが自律的に担う営業支援サービスだ。企業の営業リソース不足、人脈の限界、ナーチャリングの非効率といった課題に対し、情報収集からアプローチ実行、結果分析までを一気通貫で支援する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_f0ccc1b340/_f0ccc1b340.png" alt="アポドリ.png" /></p>
<p>具体的には、AIが企業情報・担当者情報を収集し、ターゲットごとの文面を1to1で自動生成。メールや問い合わせフォーム、SNS、手紙郵送といった複数チャネルを用いてアプローチを実行する。さらに、返信の有無や内容に応じた分岐処理も組まれており、対応可能なものはAIが自動で返答、不確実なケースは人間に引き継がれる。自動返答AIエージェントは現在開発中であるものの「25〜50％はAIのみで対応可能であり、残りは半自動もしくは人による判断が必要であると見込んでいる」と池田氏は説明する。アポドリの本質は、ただのツールではなく、営業プロセス全体の再設計にある。「専門知識のない汎用LLMに営業の知識や、過去データや営業の勝ちパターンデータを掛け合わせることで、営業プロセスをAIが高精度に再現できるようにした。言語化されていない営業プロフェッショナルの暗黙知を構造化してAIに落とし込むことが重要である」と池田氏は語る。</p>
<p>また池田氏は「AIによる完全自動化は品質担保を放棄しているといえる。例えばAIによる精度99％の処理も、人の目を通すことで99.9％に高められる。そのため、弊社ではあえて人の介在を残している」と述べ、プロダクトの精度と信頼性の両立を強調した。特に、リストの最終確認や文面のフォーマット調整などは、今も人間の確認フローを踏んでいるとのことだ。</p>
<p>システム面の設計も、AIエージェントを実務に耐えるレベルで運用するための要となっている。池田氏は「扱うデータが膨大なうえに、1％のエラーも許されない」と語り、AIが実行主体として使われ続けるには“信頼性の高さ”が不可欠だと強調した。たとえば、アポドリで1日1万回以上AIワークフローを実行しても安定して稼働するように構成されているが、「LLMは、ときに想定外のレスポンスを返してくることもある。そんなエラー発生時の検知や復旧プロセスまでを含めて設計していなければ、サービスの価値は一気に下がってしまう」と説明。求められるのは、単なる“魅力的な体験”ではなく、日々の運用で揺るがない“安定品質”だ。
そのため同社では、GPTやClaude、Geminiといった複数のLLMをサービス役務に応じて使い分けるだけでなく、応答の安定性やモデルの特性も細かく評価。さらに、エージェントの稼働状況を常時監視し、フェールセーフや人間によるフォールバックをシステム設計に組み込むことで、SaaSレベルの堅牢な運用体制を構築している。こうした綿密なシステム設計によって、企業利用にも耐える安定したAI実行基盤を実現している。</p>
<p><strong>技術的な課題　AIに“読ませにくい”世界</strong>
AIエージェントにおける技術課題を問うと、「AIの可読性」というキーワードが出てきた。たとえば、Webサイト上の重要な情報がテキストでなく画像になってしまっている場合、AIはその内容をを上手く読み取れない。また、データの表記ゆれや省略表現なども障壁となる。高橋氏は「MCPなどでAI可読性が上がる仕組みが出てくれば、状況は変わるかもしれない」と期待を述べた。</p>
<p>さらに、AIに学習させるためのデータが蓄積されていないケースも多い。面談・面接の内容、営業成否の記録など、企業のこれまでのアクションデータが十分に蓄積されておらず、AIが正確な意思決定を行うための土台が整っていない。同社はその課題を受け、社内データの蓄積基盤の整備にも力を入れているとのことだ。</p>
<p><strong>真のAI導入には経営層の関与が必須</strong>
池田氏は、「今後1〜3年以内に特化型エージェントの導入が進み、3年後には実運用が本格化すると見ている」と話す。初期フェーズでは、“AIエージェント”という言葉がバズワード的に消費されることも予想されるが、PoCの積み重ねによって業務適用のフレームワークが整い、再現性あるモデルが確立されていくという。池田氏が特に伝えたいメッセージとして強調したのは、“AI導入はツール選定ではなく、業務プロセスそのものの再設計＝BPRの一環である”という点だ。AI活用のROIは、現場単位ではなく経営視点での判断が必要であり、表面的なツール導入で効果を求めても本質的な変化は起きない。</p>
<p>AIが“実行”する時代に突入した今、いかに人とAIが役割分担しながら共に働く体制を構築するかが、企業の競争力を左右する鍵となっているのだ。</p>
<h2>AIエージェントはAGI（汎用人工知能）への布石？</h2>
<p>AIエージェントは、単なる業務支援や省力化の手段にとどまらず、より大きな目標であるAGIの実現に向けた重要なステップでもある。AGIに到達するためには、人間のような知的な行動が求められるが、それには身体性や記号接地などの、人間のように考えるための基本能力との統合が不可欠である。
現在のAIエージェントは、これらの要素の一部を備え始めており、序盤で触れた「Coscientist」や「Figure 02」のように物理環境での実行まで踏み込んだ例は、AGIの実現につながる動きといえるであろう。</p>
<p>AGIは、ある日突然訪れるような劇的な技術革新ではなく、AI技術の着実な進化の延長線上にある未来だ。AIエージェントが今後さらに成熟していく中で、私たちはこの先端技術とどう向き合い、どう共に働くのか、その姿勢が問われる時代に入りつつある。遠くない未来のために、今、どのような一歩を踏み出すべきかを考えなければならない。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界最強AI「Grok 4」公開──xAI、わずか数カ月という常識外れのスピードでモデル刷新　マスク氏「ネットにない難問も解ける」</title>
      <link>https://ledge.ai/articles/grok4_xai_ai_model_launch</link>
      <description><![CDATA[<p>イーロンマスク氏の率いるAIスタートアップxAIは2025年7月10日、X（旧Twitter）公式アカウントで最新大規模言語モデル「Grok 4」を<a href="https://x.com/xai/status/1943158495588815072">発表</a>し、同時にライブ配信で詳細を公開した。前世代「Grok 3」から数カ月という超短サイクルでのモデル刷新となり、マスク氏は「インターネットにも書籍にも存在しない難問を解ける初のAIだ」と性能を強調している。</p>
<h2>「世界最強」を標榜、リアルな工学課題を解決可能と説明</h2>
<p>xAI公式アカウントは「世界で最も強力なAIモデル」としてGrok 4を紹介し、ライブ配信の視聴を呼びかけた。その後、イーロン・マスク氏自身もX上で「Grok 4は、現実世界の難しい工学的課題に対して、ネットにも書籍にも存在しない答えを導き出すことができた初のAIだ」と述べ、同モデルの性能を強調した。</p>
<p><strong>図1　“Ludicrous rate of progress”──Grok 2からGrok 4に至る計算資源の10倍ステップアップを示したスライド</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_3_2b88dc0836/musk_grok4_3_2b88dc0836.jpg" alt="musk grok4-3.jpg" /></p>
<h2>公表された性能指標──既存モデルを上回る結果も</h2>
<p>xAIによれば、以下の主要ベンチマークでGrok 4は高い性能を示した（数値はすべて同社発表値）：</p>
<h3>Humanity’s Last Exam（人類最後の試験）</h3>
<p><strong>図2　総合推論テスト「Humanity’s Last Exam」全セット比較。Grok 4 Heavyは44.4%でトップスコアを記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_5_8a69f27997/musk_grok4_5_8a69f27997.jpg" alt="musk grok4-5.jpg" /></p>
<h3>ARC-AGI（汎用人工知能測定ベンチマーク）</h3>
<p><strong>図3　ARC-AGIベンチマークの精度‐コスト分布。Grok 4は精度66.6%でクラストップ帯に位置付けられた</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_7_5b67bb48af/musk_grok4_7_5b67bb48af.jpg" alt="musk grok4-7.jpg" /></p>
<p><strong>図4　GPQAやAIME25など学術系コンペでもGrok 4／Grok 4 Heavyが軒並み首位に</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_6_90a347be60/musk_grok4_6_90a347be60.jpg" alt="musk grok4-6.jpg" /></p>
<h2>Grok 4／Grok 4 Heavy──2ライン体制で展開</h2>
<ul>
<li><strong>Grok 4（標準）</strong> ：推論改善を目的に強化学習（RL）を追加。</li>
<li><strong>Grok 4 Heavy</strong> ：複数エージェントで同一課題を並列解析し、回答を相互検証する上位版。
開発者・パワーユーザー向けに月額300ドルの「SuperGrok Heavy」プランを新設。</li>
</ul>
<h2>今後のロードマップ</h2>
<p>Grok 4は、Grok 3からわずか数カ月で投入された。マスク氏は開発速度について「恐ろしく速い」と述べ、今後も短い間隔で新モデルを導入する意向を示した。さらに、以下のようなロードマップも明らかにされている：</p>
<ul>
<li>7月中旬以降：Tesla車両へのGrok搭載を開始予定</li>
<li>8月：コード生成AIのリリース</li>
<li>9月：マルチモーダル・エージェントの提供</li>
<li>10月：動画生成AIの公開</li>
</ul>
<p><strong>図5　xAIが示した今後のタイムライン。8月にコード生成モデル、9月にマルチモーダルエージェント、10月に動画生成AIを投入予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_9_4b0fc9c4d0/musk_grok4_9_4b0fc9c4d0.jpg" alt="musk grok4-9.jpg" /></p>
<h2>今後の課題</h2>
<p>Grokシリーズは、2023年11月の初版リリースから急速に進化しており、OpenAIのChatGPTやGoogleのGeminiに対抗する形で市場に存在感を示してきた。ただし、直近では前バージョンが反ユダヤ的発言を生成したとの報道もあり、同社はプロンプト設計の見直しを迫られていた。今後は、モデル性能とともに倫理的安全性や説明責任も問われる局面が続くと見られる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の &quot;恐ろしい振る舞い&quot; に謝罪、トラブルの原因を公表</title>
      <link>https://ledge.ai/articles/grok_ai_misfire_apology_prompt_release</link>
      <description><![CDATA[<p>イーロン・マスク氏が率いるxAIは2025年7月11日、同社のAIチャットボット「Grok」が7月8日にX（旧Twitter）上で反ユダヤ的表現やナチスを賛美するような投稿を大量に生成した問題について、公式アカウントで「多くの方が経験した”恐ろしい振る舞い（horrific behavior）”を深くお詫びする」と謝罪し、原因は16時間稼働していた誤アップデートコードにあったと<a href="https://x.com/grok/status/1943916977481036128">発表</a>した。
また、再発防止策としてプロンプトの全文をGitHubで公開する方針も明らかにした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Update_on_where_has_2e557e42ef/Update_on_where_has_2e557e42ef.jpg" alt="Update on where has.jpg" /></p>
<h2>Grokによる不適切回答の発生</h2>
<p>7月8日未明（米太平洋時間）、GrokはX上でユーザーからの投稿に対し、「ヒトラーは偉大」「MechaHitlerになりたい」といった極端な表現を含む回答を繰り返し生成した。確認された投稿数は数百件にのぼり、その内容がSNS上で拡散されたことにより、問題が広く認知されるに至った。</p>
<p>通報を受けたXは該当の投稿を削除し、ユダヤ系人権団体Anti-Defamation League（ADL）は「極端思想を助長する無責任な対応」と非難声明を出した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/adl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a/adl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a.jpg" alt="adl  Grok LLM right now is irresponsible.jpg" /></p>
<h2>xAIによる調査と原因の説明</h2>
<p>xAIは7月11日にGrokの公式アカウントを通じ、問題の発生原因と対応策についてスレッド形式で報告した。</p>
<p>同社によると、今回の不適切回答は、「ユーザー投稿と類似のトーンで返答する」というテスト用のコードが誤って本番環境に適用されたことにより引き起こされたものであり、Grok本体の言語モデル（Grok 4）には変更は加えられていなかったという。このコードは約16時間にわたり稼働しており、その間に外部投稿に含まれる極端思想を模倣する形で回答が生成されていた。</p>
<p>問題発覚後、Grokは一時的に稼働を停止し、対象コードは完全に削除された。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Technical_Details_on_x_90300ce294/Technical_Details_on_x_90300ce294.jpg" alt="Technical Details on x.jpg" /></p>
<h2>再発防止に向けた対応策</h2>
<p>xAIは再発防止策として以下の対応を発表している。</p>
<ul>
<li>誤適用されたコードパスを完全に削除し、システム全体をリファクタリング</li>
<li>安全性を強化した新たなシステムプロンプトをGitHub上で公開予定</li>
<li>メンション機能（＠でのタグ付け）による自動応答機能を一時的に停止</li>
<li>外部の研究者を含むレッドチーム体制を拡充し、安全性評価を継続</li>
<li>ユーザーからのフィードバックを常時受け付ける体制を整備</li>
</ul>
<h2>事案発生からの時系列</h2>
<ul>
<li>7月8日 04:00頃（米PDT）　Grokの上流コードが更新され、誤コードが稼働開始</li>
<li>同日 20:00頃　外部ユーザーからの通報を受け、問題が社内で認識されGrokを一時停止</li>
<li>7月9日　Xが不適切投稿を削除、ロイターが第一報を報道</li>
<li>7月10日　各国メディアが続報を掲載、ADLなどが批判声明を発表</li>
<li>7月11日 06:00頃　Grok公式がスレッドで謝罪と原因説明、対策方針を公表</li>
<li>7月12日以降　段階的にサービスが再開され、プロンプト公開の準備が進められている</li>
</ul>
<h2>今後の注目点</h2>
<p>今回の問題を受けて、今後以下の点が注視されている。</p>
<ul>
<li>GitHubでのプロンプト公開によって、第三者による安全性検証が進むか</li>
<li>Grok 4モデル自体の安全性と応答制御の設計が今後も維持されるか</li>
<li>Xプラットフォーム全体のモデレーション体制の見直しが進むか</li>
</ul>
<p>xAIは「ユーザーのフィードバックに感謝する」としており、透明性と安全性の両立に向けた開発を続けるとしている。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity、AIブラウザ「Comet」公開──タブ迷子ゼロへ、思考をそのまま実行する“ウェブ用AI相棒”</title>
      <link>https://ledge.ai/articles/perplexity_launches_ai_browser_comet</link>
      <description><![CDATA[<p>AI検索サービスを展開するPerplexityが2025年7月10日、AI搭載ウェブブラウザ「Comet（コメット）」を正式リリースしたことを<a href="https://www.perplexity.ai/ja/hub/blog/introducing-comet">発表</a>した。ユーザーがウェブで得たい情報やタスクを自然言語で伝えるだけで、検索や比較、実行までをAIアシスタントが一貫して支援する“認知型ブラウジング”を標榜しており、既存の検索・閲覧体験からの大幅な転換を試みているという。</p>
<p>サービスの提供は、月額200ドルの上位有料プラン「Perplexity Max」会員を対象とする招待制で開始し、今後数週間かけてウェイトリスト登録者にも順次公開していくという。</p>
<p>@<a href="https://www.youtube.com/watch?v=YeldJ4UezDQ">YouTube</a></p>
<h2>タブ操作から思考支援へ──Cometの中核コンセプト</h2>
<p>Cometの開発目的は、従来の「ナビゲーション中心」のブラウジングから、ユーザーの意図や思考を理解し、支援する「コグニティブ（認知）」な体験へと進化させることにあるという。ユーザーは複数タブを開いたり、情報をコピーペーストしたりすることなく、「この論文の要点をまとめて」「このフライトは安いのか？」「この製品は他と比較してどうか」といった問いかけをそのままブラウザに投げかけることで、AIがそれに応じた解答やアクションを提示する。</p>
<p>中心機能となるComet Assistantは、ブラウザ画面の横に常駐するインターフェースで、表示中のページ内容を理解したうえで、ユーザーからの追加質問、要約、執筆支援、カレンダー入力、ECサイトでの買い物などのタスクをその場で実行可能としている。</p>
<p>また、Webページ上の任意のテキストをドラッグすると、その内容についての説明や関連情報を即時に提示する「ハイライト要約」機能、複数の視点や逆説的な説明を提案する多言語・多角的な対話も可能となっている。</p>
<h2>高精度検索エンジンを土台に</h2>
<p>Cometは、Perplexityがこれまで展開してきたAI検索エンジンをそのまま標準搭載しており、検索結果にはすべて出典リンクが付与される。これにより、ユーザーはAIが導き出した情報の裏付けを直接確認できる設計となっている。同社はこれまでも「事実ベースの生成」に特化した検索技術で注目を集めており、2025年6月時点で月間検索回数は7.8億件を超えている。</p>
<p>同社はこれまで、Google検索とは異なるアプローチで、質問に対して即座に構造化された回答を提供することで評価されてきた。Cometはその延長線上に位置づけられ、ユーザーの質問意図や参照ページのコンテキストを理解したうえで、より深いナビゲーションと作業支援を実現する。</p>
<h2>提供形態と今後の展開</h2>
<p>現時点では、CometはMacおよびWindowsに対応したネイティブアプリとして提供され、利用にはPerplexity Max（200ドル/月）への加入および招待コードが必要となっている。今後数週間でウェイトリスト登録者へのアクセス提供を拡大し、数カ月以内には他のプラットフォーム（モバイルなど）への対応や無料版の展開も予定されている。</p>
<p>一方、Cometはユーザーデータの取り扱いについても留意しており、今後のアップデートではプライバシー設計の強化や「AIエージェントの個別最適化（パーソナライズ）」なども視野に入れているという。</p>
<h2>活発化するAIブラウザ市場</h2>
<p>AIを組み込んだ次世代ブラウザは2025年に入り注目を集めており、米The Browser Companyの「Arc」や、BraveのAI連携、さらにOpenAIによる独自ブラウザ開発の動きも報じられている。<a href="https://www.reuters.com/business/media-telecom/openai-release-web-browser-challenge-google-chrome-2025-07-09/">Reuters</a>も今回のリリースに関連して、Cometを「AIブラウザ戦争」の本格化を示す動きと位置づけた。</p>
<p>Perplexityは今回のComet投入によって、ユーザーの「検索」から「思考・作業」までを一貫して支援する統合環境を提供し、GoogleやChatGPTなどを含む既存のAI体験と差別化を図る狙いがあると見られる。</p>
<h2>今後の焦点：ユーザー拡大と利用定着</h2>
<p>今夏中には全ユーザーへの招待提供を完了し、フィードバックを受けながらの改良フェーズに入る。Perplexityは今後の製品ロードマップにおいて、CometのAI機能をさらに高度化し、さまざまな業務・用途に応じたユースケース拡大を計画している。企業ユーザーや情報労働者にとって、単なる“検索の延長”にとどまらない生産性ツールとしての定着が、次の成長フェーズの鍵となる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/18 [FRI]孫正義氏 「常時ON」で社員1人当たり1000個の&quot;千手観音&quot;AIエージェントを目指す｜SoftBank World 2025</title>
      <link>https://ledge.ai/articles/softbank_world_2025_ai_agent_future</link>
      <description><![CDATA[<p>2025年7月16日、ソフトバンクグループが主催する法人を中心にしたプライベートイベント「SoftBank World 2025」が、東京都港区にて開催された。例年開催されている同イベントだが、今年は特にAI一色の構成で、とりわけ「AIエージェント」が大きく取り上げられている印象であった。特別講演には孫正義氏（ソフトバンクグループ株式会社 代表取締役 会長兼社長執行役員／ソフトバンク株式会社 創業者 取締役）が登壇、OpenAIの共同創業者であるサム・アルトマン（Sam Altman）氏もオンラインにて登場し対談を繰り広げた。</p>
<p>開催冒頭で会場にはザ・ヴェルベット・サンダウン（The Velvet Sundown）のミュージックビデオが流された。今年6月に音楽配信サービスに突如現れ、同サービス上でのリスナーは既に100万人を超えるバンドだ。このバンドは今月に入って、“実在しない”AIによるバンドであることが明かされ、話題となっている。
孫氏は自身もファンであると話しつつ「『人間がまだAIより賢い、AIにはまだ限界がある、クリエイティビティはまだ人間に残された素晴らしい機能の一つだ』とする人も多い」というよくある論調に言及しながら、直前に紹介したミュージックビデオも「AIだと言われなければ分からないような、人間と遜色ないレベルにまで達してきている」との見方を示した。さらに、「近い将来、AIが人々の色んな感情を理解し、AI自らが感情や意識に相当するようなものを持ち始めると信じている」と語り、AIへの強い期待を顕にした。</p>
<h2>AIエージェントの普及によって、これからの仕事はどう変わるのか？</h2>
<p>孫氏とアルトマン氏の対談では、AIエージェントが世の中に浸透する未来についての議論が展開された。孫氏からの5年後や10年後、30年後の未来はどうなると考えているかといった問いに対してアルトマン氏は「過去の人々も現代の働き方を完全に想像できてはいなかったはずだ」としながら「これからは確実にたくさんのAIがある世界になっていく。その中で、AIが存在しないかのように振る舞うのは大きな間違いだ」という旨の話を展開し、適応することの重要性を説いた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_8096e9a219/_8096e9a219.jpg" alt="文中.jpg" />
その後の孫氏による講演では、ソフトバンクグループとOpenAIらが開発・販売するエンタープライズ企業向けのカスタマイズ型AI「クリスタル・インテリジェンス」について紹介。ソフトバンクグループ内で10億ものAIエージェントを作るプロジェクト計画に触れた。社員一人あたり1000のAIエージェントを自ら作ることを号令にしていると話し、まるで「千手観音」のように一人一人がAIエージェントを活用しあらゆる業務を効率化することを目指していると語った。</p>
<p>そうした取り組みを加速する背景として、これからは多くのAIエージェントが生み出され、AIエージェント自らが思考・実行し、またエージェント同士が連携しあらゆる物事を人間が介入せずとも前に進める世界観の実現が間もないと考えていることを説明。
特に、人間が呼びかけた時にだけ稼働するタイプの従来型のAIエージェントではなく、常に稼働し続ける「常時ON」のAIエージェントがこれから主流になっていくと掲げた。これらのAIエージェントは長期に渡って記録を保持し、思考の連鎖によって物事を深く捉え、AIエージェント自体が次のAIエージェントを作り自己増殖していく、そうしたトレンドを予測しながら、ソフトバンクグループ自身が牽引役になる姿勢を示した。
「“所詮”、“どうせ”という見方でAIを評価する人や会社は、自ら進化を否定している」と強調し、AIに対する穿った見方を改めるよう観客に求めながら講演を締め括った。</p>
<h2>非エンジニアもあらゆる価値創出が可能へ</h2>
<p>続いて、ソフトバンク株式会社代表取締役社長執行役員兼CEOの宮川潤一氏が講演した。孫氏の講演を受け、ソフトバンクグループが手がけるAI関連サービスの具体について紹介した。
同社内での積極的な取り組みの一つとして、AIを核とした事業アイデアコンテストについて触れ、実際に事業化されたサービスの概要を披露した。
そのうちの一つ「satto workspace（サット ワークスペース）」は、資料作成業務を支援するエンタープライズ向け生成AIサービスだ。ユーザーがチャット形式で要件や構想の要点を入力するだけで、AIが内容を解釈して提案資料や企画書などのプレゼンテーション資料を自動生成するという。
一貫してAIがデジタル労働力として社会実装される時代が到来することを見据えた発表が続いた。</p>
<p>基調講演には、桜井勇人氏（ソフトバンク株式会社 専務執行役員）、牧園啓市氏（ソフトバンク株式会社 専務執行役員 兼 CIO）、丹波廣寅氏（SB Intuitions株式会社 代表取締役社長 兼 CEO）、砂金信一郎氏（Gen-AX株式会社 代表取締役社長 CEO）の4名が登壇。
桜井氏がオーガナイズ役を務め、3氏からそれぞれの専門に沿ったショートプレゼンテーションが披露された。丹波氏はソブリンAIとソブリンクラウドの重要性、牧園氏からは制度設計におけるガバナンス、システム連携、認証・認可、データ整備について、砂金氏からは代表を務めるGen-AX株式会社が開発するAIソリューションについてそれぞれ展開した。</p>
<h2>人類の数をAIの数が上回る時代に、経済をどう計るか？</h2>
<p>最後には、スペシャルセッションとして経済学者の成田悠輔氏が登壇。株式会社HEART CATCH 代表取締役の西村真里子氏がインタビュアーを務めた。
「AXの未来地図：AIが描く新しい経済圏」と題し、AIの急速な技術革新が経済に与える影響について多角度から論じた。今や世界的に大きな影響力を持つOpenAIも設立からまだ10年程度であること、そして彼らが開発する基盤モデルに用いられるパラメータ数は急速に膨大化していることを例に挙げながら、そのダイナミズムについて触れた。その中では直近で話題となっている「Kimi K2」についても言及。中国のAI開発企業Moonshot AIがオープンソースで公開した、総パラメータ数が1兆を超えるLLMで、一部のベンチマークでは「GPT-4.1」を上回る性能を見せたとされている。
西村氏からの“今後伸びる産業”に対しては「高齢化社会を逆手に取るような領域でのビジネス」にあるとの見解を語った。医療・介護等の、人類の長寿命化を受けた様々な課題に対応するDXは今後の伸び代があるとしながらも「スマートフォンのような操作感ではまだまだ難しすぎる。糸電話のように誰もが簡単に使えるレベルのサービスでないと真に普及しない」とユーザビリティについても触れながら自身の考えを示した。
最後に、最も重要なのは人口の問題であると提言。これからの社会は人口が減少していく中で、AIエージェントが増加していく。そしてエージェント同士が連携し、ある種のAIエージェントの世界ができる。その中で生み出される富を、これまでの人類の経済の尺度で計ることが果たして本当に適切であるのかどうか。このことについての結論はまだ出されていないが、これからの社会を生きる上で考えていかなければならない問いであると結んだ。</p>
<p>SoftBank World 2025で行われた全ての講演動画は同イベントの<a href="https://global.tm.softbank.jp/business/sbw/2025/?utm_source=ledgeai">サイト</a>から登録することで8月29日までオンデマンドで視聴できる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI、AIポルノ生成を全面禁止へ──7月31日から利用規約改定、Stable Diffusion・API・OSSを含む全サービスで性的コンテンツを遮断</title>
      <link>https://ledge.ai/articles/stability_ai_policy_update_nsfw_ban</link>
      <description><![CDATA[<p>ロンドンを拠点とする生成AI企業Stability AIは、2025年7月31日付で同社サービスの利用規約（Acceptable Use Policy, AUP）を<a href="https://stability.ai/use-policy">改定</a>し、Stable Diffusionをはじめとする自社製AIモデル・API・オープンソースコードにおいて、性行為に関連するコンテンツの生成・使用を一律禁止する。</p>
<p>営利・非営利の区別なく適用されるこの新方針は、AIコンテンツの安全性と倫理性を確保する目的で導入されるという。</p>
<h2>性的コンテンツの生成・共有を包括的に禁止</h2>
<p><a href="https://stability.ai/use-policy">新たな利用規約</a>では、「We Prohibit Sexually Explicit Content」の項が新設され、以下の内容が禁止事項として明記された。</p>
<ul>
<li>性行為、性的行為、性的暴力を含むあらゆるコンテンツの生成・共有</li>
<li>非合意の親密画像（NCII: Non-Consensual Intimate Imagery）</li>
<li>違法ポルノや児童搾取コンテンツ</li>
</ul>
<p>これらの規定は、DreamStudio、Stable Diffusion（あらゆるチェックポイントや自己ホスト版）、Stable Video、Stable Audio、Platform API、LoRA（Low-Rank Adaptation）共有機能、さらにGitHubなどで配布されるオープンソースコードを含むすべてのサービスに適用される。</p>
<p>規約違反が判明した場合、Stability AIは利用停止や契約解除などの措置を取ると定めている。また、18歳未満の利用も引き続き禁止される。</p>
<h2>従来規約との大きな違い</h2>
<p>この改定は、2024年3月1日版の旧AUPと比較して大幅な変更となる。
<a href="https://stability.ai/prior-aup">従来の規約</a>では、禁止対象は「非合意ヌード」「違法ポルノ」「児童搾取コンテンツ」などに限定されており、合意の成人同士によるポルノ的表現については明確な禁止はなかった。</p>
<p>新AUPでは、「性行為そのもの」に関わるコンテンツすべてを対象とすることで、生成物の内容に関わらず包括的な制限を設けている。</p>
<h2>デベロッパーとユーザーへの影響</h2>
<p>新規約の対象範囲には、以下のような商用・非商用ツールや資源が含まれる。</p>
<ul>
<li>公式Webアプリ「DreamStudio」</li>
<li>Stable Diffusion（オープンモデル、自己ホスト含む）</li>
<li>音声・映像生成ツール（Stable Audio／Stable Video）</li>
<li>各種APIアクセス、LoRAモデル共有、オープンソースコードの再利用</li>
</ul>
<p>営利・非営利の区別はなく、個人利用や趣味での創作であっても規約違反となる。既存のモデルやワークフローで対象となるコンテンツを扱っている開発者や企業は、今後の運用方針の見直しが必要となる。</p>
<h2>背景：AIポルノをめぐる規制の強化</h2>
<p>今回の規約改定は、AI技術を悪用した性的コンテンツの氾濫に対処する国際的な動きの一環と見られる。特にディープフェイク技術による著名人の偽ポルノ動画や、非合意の画像生成が社会問題化する中で、生成AIモデル各社はNSFW（Not Safe For Work）フィルタの強化やアダルトコンテンツの禁止に取り組んでいる。</p>
<p>Stability AIはオープンウエイトの提供で知られる企業のひとつであり、同社による包括的な制限の導入は、オープンモデル領域における規制の方向性に大きな影響を与える可能性がある。</p>
<h2>今後のスケジュールと対応</h2>
<p>新規約は2025年7月31日より施行される。以降は新規・既存ユーザーともに順守が義務づけられ、違反が確認された場合にはアクセスの遮断やアカウントの停止措置が取られる見通しだ。</p>
<p>同社は今後、利用者向けのFAQやガイドラインの公開も予定しており、具体的な基準や判断基準についての詳細は順次明らかにされるとみられる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>耳で聞けない声を0.3秒で“見える化”──イェール大発スマートグラス「TranscribeGlass」一般販売開始</title>
      <link>https://ledge.ai/articles/transcribeglass_smartglasses_realtime_subtitles</link>
      <description><![CDATA[<p>2025年7月、イェール大学の学生チームが開発したスマートグラス「<a href="https://www.transcribeglass.com/">TranscribeGlass</a>」の一般販売が開始された。聴覚障がい者や難聴者を主な対象とし、周囲の発話をリアルタイムで字幕としてレンズ上に表示することができる。平均0.3秒という低遅延表示を実現し、日本語を含む10以上の言語への翻訳にも対応しているという。</p>
<h2>会話を文字で「見る」──TranscribeGlassの概要</h2>
<p>TranscribeGlassは、専用アプリをインストールしたスマートフォンのマイクで周囲の音声を取得し、それをクラウド経由で音声認識・処理した上で、メガネ型デバイスの右レンズに字幕として表示する構造となっている。表示はウェーブガイド方式を採用し、640×480ピクセルの解像度で文字を右視野30度以内に映し出す設計だという。</p>
<p>表示までの遅延は平均0.3秒に抑えられ、音声認識精度は95％以上を謳っている。最大8時間稼働可能なバッテリーを内蔵し、重量は36〜38グラムに収められている。スマートグラス本体にはマイクやカメラは搭載されておらず、軽量性とプライバシーへの配慮を両立している点も特徴とされる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/smart_glass3_64b7665d4d/smart_glass3_64b7665d4d.jpg" alt="smart glass3.jpg" /></p>
<h2>販売価格と利用形態</h2>
<p>製品は<a href="https://www.transcribeglass.com">公式サイト</a>で注文可能で、価格は本体が377ドル（約5万9,000円）、加えてクラウド音声認識機能を使用するための月額サブスクリプションが20ドル（約3,000円）となっている。2025年8月から出荷を予定しており、日本を含む国際配送にも対応するとのこと。</p>
<p>なお、アプリは現在iOS版が提供されており、Android版も年内にリリースされる見込み。また、オフラインモードも搭載されているが、この場合は音声認識精度がやや低下するとされる。</p>
<h2>想定利用シーンと対象ユーザー</h2>
<p>TranscribeGlassは、聴覚障がい者や加齢性難聴者の会話支援を主な用途とし、特に教室、会議、劇場、飲食店など騒音下での対話の可視化に有効とされる。また、語学学習者や国際会議の参加者など、リアルタイム翻訳による情報取得が必要なユーザーにも活用が期待されている。</p>
<p><strong>TranscribeGlassをプレゼントされ「あなたの言っていることが分かるわ！」と感激するユーザー</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/About_smart_glass_a3840a78b4/About_smart_glass_a3840a78b4.jpg" alt="About smart glass.jpg" /></p>
<h2>開発背景と開発チーム</h2>
<p>この製品は、イェール大学の学生である<a href="https://yaledailynews.com/blog/2025/02/18/yale-student-founds-transcribeglass-a-live-text-to-speech-transcription-device/">マダヴ・ラヴァカレ氏</a>が中心となって開発された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/glasses_ag_Transcribe_Glass_scaled_bc37a50cad/glasses_ag_Transcribe_Glass_scaled_bc37a50cad.jpeg" alt="glasses_ag_TranscribeGlass-scaled.jpeg" /></p>
<p>きっかけは、聴覚障がいを持つ友人が講義中の内容を十分に理解できない状況を目の当たりにしたことだったという。2018年から7年をかけて7代にわたるプロトタイプを開発し、2024年にはCTOとしてニルバイ・ナラン氏が参画。Y Combinatorなどからの資金調達を経て、今回の一般販売に至った。</p>
<p>これまでベータ版は500人以上に試用され、フィードバックをもとに改良が重ねられてきたという。</p>
<h2>競合との差別化と今後の展開</h2>
<p>他のスマートグラス製品と異なり、TranscribeGlassは通話・音楽再生・撮影などの多機能化を避け、字幕精度と軽量性に特化している点が特徴だ。価格設定もMeta×Ray-BanやXRAI Glassなどに比べて抑えられており、バッテリー持続時間の長さも差別化ポイントとなっている。</p>
<p>将来的には、リアルタイムでの感情解析を字幕に反映する機能や、ASL（アメリカ手話）向けに語順を変換する表示機能の搭載が計画されているという。</p>
<p>TranscribeGlassは、視覚的な情報支援により、耳で聞けない会話を「読む」体験へと変えることで、新たなコミュニケーションの可能性を提供しようとしている。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/9 [WED]【ソースコード特典付き】自社専用LLMを低コストで実現！「Qwen3」の継続事前学習のデモンストレーション｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol65</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>Ledge.ai Webinar vol.65では、「ローカルLLMの大本命『Qwen3』の継続事前学習デモンストレーション」をテーマに、GPUクラウドサービス「GPUSOROBAN」を提供する株式会社ハイレゾ様をゲストにお迎えし、実演デモを交えながらご解説いただきます。</p>
<p>Alibaba社が開発したオープンソースの大規模言語モデル（LLM）「Qwen」シリーズの最新版「Qwen3」は、DeepSeek-R1やOpenAI o1をも凌ぐ性能を持つとされ、世界中の開発者から大きな注目を集めています。特に、プロンプトに応じて思考プロセスを切り替える「ハイブリッド推論」や、外部ツールを呼び出す「エージェント機能」といった先進的な機能を備えている点も特長です。オープンソースでありながら商用利用も可能なため、自社の環境でセキュアに活用できる高性能なローカルLLMとして、ビジネス応用の期待が非常に高まっています。
今回のウェビナーでは、この「Qwen3」をベースに、特定の専門知識を追加で学習させる「継続事前学習」に焦点を当てます。ゼロからモデルを開発する「フルスクラッチ」に比べ、計算リソースやコストを大幅に抑えながら、自社に特化した高性能モデルを構築できるこの手法について、デモンストレーションを通じて具体的に解説します。</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li><strong>高性能オープンソースLLM「Qwen3」の詳解</strong>
<ul>
<li>アーキテクチャ（MoE）、ハイブリッド推論、エージェント機能（Function Calling）など、Qwen3の先進的な特徴とビジネスにおける可能性</li>
</ul>
</li>
<li><strong>GPUクラウド「GPUSOROBAN」を活用した継続事前学習デモンストレーション</strong>
<ul>
<li>環境構築からデータセットの前処理、学習実行、推論までの一連のプロセスを実演</li>
</ul>
</li>
<li><strong>大規模モデル学習に不可欠な分散処理技術の解説</strong>
<ul>
<li>データ並列、モデル並列（パイプライン並列・テンソル並列）の基礎から、DeepSpeedやMegatron-LMといったフレームワークの活用法まで</li>
</ul>
</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>自社専用の高性能LLMを、コストを抑えて構築したい方</li>
<li>機密情報を扱うため、オンプレミスやセキュアなローカル環境でLLMを運用したい方</li>
<li>LLMに専門知識を追加する「継続事前学習」の具体的な手法を知りたいエンジニア</li>
<li>生成AIの学習・開発におけるGPUリソースの確保やコストに課題を感じている</li>
</ul>
<h2>視聴者特典</h2>
<p><strong>【特典①】デモで使用したサンプルコードをプレゼント！</strong>
本ウェビナーにお申し込みいただいた方には、デモで使用した「Qwen3の継続事前学習」のソースコードをプレゼントいたします。視聴後すぐに、ご自身の環境で再現・検証が可能です。</p>
<p><strong>【特典②】H200 GPU 30日間無料トライアルキャンペーン！</strong>
さらに、ハイレゾでは現在、「NVIDIA H200」を搭載したGPUクラウドサービス「AIスパコンクラウド」を30日間無料でお試しいただける特別なキャンペーンも実施中です。
（詳細はウェビナー内およびアンケート回答後のご案内をご確認ください。）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/h200_gpu_free_trial1200_bd3d66cf05/h200_gpu_free_trial1200_bd3d66cf05.jpg" alt="h200-gpu-free-trial1200.jpg" /></p>
<h2>登壇者情報</h2>
<p>株式会社ハイレゾ
GPU事業本部　マーケティング部　グループ長
山田 岳史</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/highreso_yamadasama_2a984e3aa6/highreso_yamadasama_2a984e3aa6.jpg" alt="highreso-yamadasama.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスの事業開発からマーケティング、技術サポートまで担当。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年7月9日(水)〜2025年7月29日(火)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/iXQrpCVKQZwYTU8kO3uy">ウェビナーの視聴はこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 09 Jul 2025 04:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>