<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>「普通のメガネ」のようで“静かに非凡”──情報を前面・背面に分離するレイヤードHUDとカメラレス設計、指先操作のR1が示すG2／R1のスマートグラス体験の次章</title>
      <link>https://ledge.ai/articles/quiet_tech_smartglasses_even_g2_r1_launch</link>
      <description><![CDATA[<p>ウェアラブルデバイスを手がける Even Realities は、2025年11月13日（現地時間）、新型スマートグラス「Even G2」とスマートリング「Even R1」を<a href="https://x.com/EvenRealities/status/1988629357036753060">発表</a>した。同社は「Quietly Extraordinary Technology」というコンセプトを掲げ、テクノロジーが生活に干渉しすぎず“静かに寄り添う”デザイン思想を中心に据えたことが説明されている。</p>
<p>外観は「普通のメガネ」さながらだが、視界の前面と背面に情報を分離して重ねる独自のレイヤードHUDや、カメラを排した設計、指先ジェスチャーで操作できるR1など、同社が掲げる「Quietly Extraordinary Technology」を体現する機能を備える。録画や音声出力を中心に進化してきた従来のスマートグラスとは異なり、G2／R1はユーザー本人の使いやすさと周囲のプライバシーの両立を追求した“静かな次章”を提示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=tAIhp9hia90&amp;t=4s">YouTube</a></p>
<h2>カメラレス・スピーカーレスという選択</h2>
<p>G2 の最大の特徴は、カメラと外向きスピーカーを搭載しない点にある。近年のスマートグラスは録画や配信、音声出力を強化する方向で進化してきたが、同社は「ユーザーと周囲のプライバシーに配慮するため」として、これらをあえて採用していない。
音声操作や撮影を前提としないことで、外部への音漏れや“撮られているかもしれない”という不安を生まない構造として設計されている。</p>
<h2>手前と奥に情報を分けて表示する“レイヤードHUD”</h2>
<p>G2 の光学システムには、独自の「HAO 2.0」ディスプレイが採用された。超小型マイクロLEDプロジェクターと導波管レンズにより、約2メートル先に自然な形で情報が投影される。</p>
<p>特徴的なのは、表示情報を二層に分離する“レイヤードHUD”だ。</p>
<ul>
<li><strong>前面のレイヤー</strong> ：通知など即時性の高い情報</li>
<li><strong>奥のレイヤー</strong> ：翻訳、ナビゲーションなど継続的な情報</li>
</ul>
<p>というように、視界の中で情報の優先度や性質に応じて層を分ける。
これにより、HUDが“情報過多”になりがちな従来のスマートグラスと異なり、視界のノイズを増やすことなく必要なタイミングで必要な情報のみを提示する設計になっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/HUD_9e8b648e77/HUD_9e8b648e77.jpg" alt="レイヤードHUD.jpg" /></p>
<h2>更新された主要機能と会話アシスト「Conversate」</h2>
<p>主要機能には、複数ウィジェットを扱うダッシュボード、地磁気センサーによるナビゲーション、リアルタイム双方向翻訳、テレプロンプターなどが含まれる。また、独自LLM「Even AI」の高速化により、音声操作やアプリ起動の応答が向上したという。</p>
<p>新たに追加された「Conversate」は、会話中に文脈に応じた補助情報を視界に表示する機能で、会議や対話の場面で用語の説明や要点整理などを控えめに提示する。</p>
<h2>スマートリング「R1」：操作とウェルビーイングを担う指先デバイス</h2>
<p>G2 の操作体系を補完するのが、スマートリング「Even R1」だ。リング内に静電容量式タッチパッドを内蔵し、タップ、スワイプ、長押しといった指先ジェスチャーでスマートグラスを操作する。素材は医療グレードのセラミックとステンレスを採用し、耐久性と装着性を両立した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/r1_5fbc5fd7f6/r1_5fbc5fd7f6.jpg" alt="r1.jpg" /></p>
<p>R1 にはウェルビーイング機能も搭載され、心拍数、血中酸素濃度、体温、睡眠、歩数、消費カロリーなどを計測。取得データから「生産性スコア」を算出し、その日の集中力傾向を把握する指標として利用できるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wellbeing_2d6509b5cf/wellbeing_2d6509b5cf.jpg" alt="wellbeing.jpg" /></p>
<h2>プライバシーの設計思想</h2>
<p>Even Realities は、カメラを排除した設計に加え、データはユーザーの明示的な同意なしにクラウドへ保存されないと説明している。必要なデータは暗号化され、個人を特定可能な情報を保持しない方針を示している。</p>
<p>G2 と R1 は、録画・配信・音声出力を中心に進化してきた他社製スマートグラスとは異なる方向性を示す。
同社は、情報過多を避け、ユーザー本人の使いやすさと周囲のプライバシーを両立させる「Quiet Tech」アプローチを採用し、視界に重ねる情報をレイヤーで整理し、操作は指先で静かに完結させる設計を打ち出した。こうした設計思想は、スマートグラス市場における一つの選択肢として位置づけられそうだ。</p>
]]></description>
      <pubDate>Sun, 23 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本IBMとセガXD、生成AIを学べるカードバトル研修「バトルワーカーズ」──業務内容をAIがカード化し対戦形式で学習</title>
      <link>https://ledge.ai/articles/generative_ai_card_game_training_battle_workers_ibm_segaxd</link>
      <description><![CDATA[<p>日本IBMは2025年11月17日、生成AIの基礎やプロンプト設計、リスク理解をカードバトル形式で学べる企業向け研修サービス「Generative AI Card Game Training – バトルワーカーズ」を<a href="https://jp.newsroom.ibm.com/2025-11-17-generative-ai-card-game">発表</a>した。研修設計は、ゲーミフィケーション専門企業である株式会社セガ エックスディー（セガXD）が監修した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Press2_Generated_Cards_0743fa59b7/Press2_Generated_Cards_0743fa59b7.jpg" alt="Press2_GeneratedCards.jpg" /></p>
<h2>業務内容を入力するとAIがカード化</h2>
<p>参加者自身の「仕事内容」を入力すると、生成AIがその内容をもとに バトルカード3枚とサポートカード1枚 を自動生成する仕組みを採用。カードには業務内容を反映した特徴や強み、スコアが記載され、研修参加者はこれらのカードを用いて対戦形式のゲームを行う。</p>
<p>カード生成の結果は入力する文章内容に大きく左右されるため、参加者は自然と「どの情報を、どのように記述すればAIが適切に解釈するか」を体験的に学ぶことができる。プロンプトの書き方による出力の違いを、そのままゲームの手札として実感できる構造だ。</p>
<h2>プロンプト設計・リスク理解も体験的に学べる</h2>
<p>研修のねらいとして同社は、生成AIの仕組み理解に加え、AI実務で重要となるプロンプト設計スキルやハルシネーション対策、著作権・情報管理を含むリスク理解の習得を挙げている。</p>
<p>業務内容の入力時には、どこまで詳細を書けるのか、機密情報は避けるべきか、といった情報マネジメント意識が問われる。また、生成AIが業務を誤解してカード化するケースもあり、ハルシネーション（AIの誤生成）への注意点を議論する導入にもつながるという。</p>
<h2>生成AIリテラシー格差への対応</h2>
<p>企業における生成AI活用が急速に広がる一方で、社員間のリテラシー格差は依然として課題とされる。
日本IBMは、ゲームという直感的な学習形式を取り入れることで、初心者でも無理なく生成AIの特性を掴める研修として位置づけている。参加者が「自分の業務」を題材に学ぶため、通常の座学研修よりも実務への応用をイメージしやすい点も特徴だ。</p>
<p>セガXDは、ゲームデザインや参加意欲を高める仕組みづくりに強みを持つ企業で、今回の研修ではバトル形式の導入やカード構造の設計に協力した。</p>
<p>研修を通じて同社は、企業における生成AI活用の基礎力向上を図るとともに、今後もリテラシー教育コンテンツの拡充を進める方針だ。</p>
]]></description>
      <pubDate>Sun, 23 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIモデルが“毎分”アナログ時計を描くとどうなる？──9つのAIの“苦手さ”が見える実験サイト『AI World Clocks』</title>
      <link>https://ledge.ai/articles/ai_world_clocks_ai_models_generate_clocks_every_minute</link>
      <description><![CDATA[<p>ロサンゼルス拠点のアーティスト、Brian Moore 氏が、生成AIの“揺れ”を視覚的に楽しめるウェブサイト「<a href="https://clocks.brianmoore.com/">AI World Clocks</a>」を公開した。ページを開くと、毎分更新で9種類のAIモデルが描いたアナログ時計が並ぶ。時間ごとに姿を変える時計群からは、AIが“同じ指示でも同じものを作れない”という現実がよく見えてくる。海外コミュニティでの投稿やメディア報道から、2025年11月中旬に公開されたとみられる。</p>
<p>例：とある日の午後4時22分の表示
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai_world_clock_collage_6bc41e0c7f/ai_world_clock_collage_6bc41e0c7f.jpg" alt="ai world clock collage.jpg" /></p>
<h2>同じプロンプトでも毎回バラバラ　― 9モデルが1分ごとに新しい時計を生成</h2>
<p>「AI World Clocks」は以下の仕様で動作している。</p>
<ul>
<li>９つの異なるAIモデルが、毎分新しい時計を生成して表示</li>
<li>すべてのモデルに 同じプロンプト を提示（「指定時刻のアナログ時計をHTML/CSSで記述し、マークダウンなしで返す」）</li>
<li>モデルごとに 2000トークンの制限を設定</li>
<li>生成されたHTML/CSSをそのままブラウザでレンダリング</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/about_ai_world_cloks_29c55a0f77/about_ai_world_cloks_29c55a0f77.png" alt="about ai world cloks.png" /></p>
<h2>“完成度は高くない”が想定通り　― 開発者自身が明言</h2>
<p>同プロジェクトを手がけた Brian Moore 氏は、ロサンゼルスを拠点とするアーティスト／クリエイティブディレクターで、インタラクティブなウェブ作品や“奇妙なインターネット体験”をテーマにした実験的プロジェクトを数多く公開してきた人物だ。</p>
<p>Moore氏の<a href="https://brianmoore.com/715-999-7483/">サイト</a>には、AIが苦手なことに挑ませたり、不条理なインタラクションを活かしたりするユニークな作品群が並んでおり、同氏自身も「AIが時計を描くのは苦手だ（It sucks at it）」と説明している。AIの不完全さをあえて作品の中心に据えるスタイルを得意としており、「AI World Clocks」もその延長線上にある。</p>
<h2>現れる時計はモデルごとにまったく違う</h2>
<p>実際にサイトを見ていると、AIごとの挙動の違いがよく分かる。</p>
<ul>
<li>針が欠けているもの</li>
<li>文字盤が過剰に装飾されるもの</li>
<li>レイアウトが描画エラーで崩れるもの</li>
<li>時刻が正しく反映されないもの</li>
</ul>
<p>同一プロンプトでもまったく異なる出力が生まれ、HTML/CSSのように構造が厳密に求められるタスクではモデル間の差が顕著になる。</p>
<h2>開発者が挙げた“モデルの性格”も面白い</h2>
<p>Moore 氏は Hacker News 上の<a href="https://news.ycombinator.com/item?id=45930151">投稿</a>で、モデルごとの“味”についてこう語っている。</p>
<ul>
<li>Kimi K2：「もっとも時間に正確。ただし最も退屈」</li>
<li>Qwen 2.5：「もっともクレイジーで、一番笑わせてくれる」</li>
</ul>
<p>作者本人がこのように“軽妙な温度感”で語っている点からも、同作品がAIの不完全さを楽しむためのプロジェクトであることが理解できる。</p>
<p>「AI World Clocks」は、AIモデルが同一の構造化タスクに取り組んだ際にどのような差異や揺らぎが生じるかを、逐次的に確認できるプロジェクトである。毎分変化する時計表示は、モデル間の安定性や挙動の違いを視覚的に把握しやすく、AIによるコード生成の現状を観察する素材として活用できる設計になっている。</p>
]]></description>
      <pubDate>Sun, 23 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ヤン・ルカン博士、Metaを年末に退社──「次のAI革命」Advanced Machine Intelligence研究を推進する新会社を設立へ</title>
      <link>https://ledge.ai/articles/yann_lecun_leaves_meta_ami_startup_2025</link>
      <description><![CDATA[<p>米MetaでチーフAIサイエンティストを務め、同社のAI研究組織「FAIR（Facebook AI Research）」の創設者として知られるヤン・ルカン（Yann LeCun）博士が、12年間在籍したMetaを年末に退社する。2025年11月20日（現地時間）、自身の<a href="https://www.facebook.com/yann.lecun/posts/pfbid0iU3ECamGohUvpmKozEq24RGowPoiu3D7J6vHXJxzKGT4hZittF2UK43oZkjSqVexl">Facebookへの投稿</a>で明らかにした。</p>
<p>ルカン氏は投稿の冒頭で「うわさや最近の報道で耳にした人もいるだろうが、12年間在籍したMetaを離れる計画だ」と述べ、退社を正式に表明した。FAIRの初代ディレクターとして5年、チーフAIサイエンティストとして7年を務めたと振り返り、「FAIRの創設は、自身の“最も誇りに思う非技術的な業績”」と強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/yann_lecun_facebook_3d6a371abb/yann_lecun_facebook_3d6a371abb.jpg" alt="yann lecun facebook.jpg" /></p>
<h2>Advanced Machine Intelligence（AMI）研究を継続する独立スタートアップを設立</h2>
<p>投稿によると、ルカン氏は「Advanced Machine Intelligence（AMI）」と名付けた研究プログラムを継続するため、新たなスタートアップを立ち上げる。同プログラムは、近年FAIRやニューヨーク大学（NYU）などの研究者と進めてきたもので、次のような能力を備えたAIシステムを目指すという。</p>
<ul>
<li>物理世界を理解する</li>
<li>持続的な記憶を持つ</li>
<li>推論できる</li>
<li>複雑な行動計画を実行できる</li>
</ul>
<p>ルカン氏は、これを「次の大きなAI革命」につながる研究領域だと位置づける。スタートアップの詳細は後日公表するとしており、社名や資金調達の状況は明かしていない。</p>
<h2>Metaは新会社のパートナーに──Zuckerberg氏らへの感謝も明記</h2>
<p>投稿では、Mark Zuckerberg氏、Andrew Bosworth氏（Boz）、Chris Cox氏、Mike Schroepfer氏の4名に対し、FAIRおよびAMI研究への継続的な支援への謝意を述べている。そのうえで、「Metaは新会社のパートナーとなる」と記し、退社後も協力関係が続くことを示した。</p>
<p>AMI研究のアプリケーションについては「Metaの商業領域と重なる部分もあれば、重ならない領域もある」とし、独立した組織で取り組むことが「広範なインパクトを最大化する手段」だと説明している。</p>
<h2>研究者としての役割は継続、年末まではMetaに在籍</h2>
<p>ルカン氏は現在、MetaのチーフAIサイエンティストとNYUの教授職を兼務している。投稿では、これらの役割に関する変更には触れておらず、研究活動は継続する見通しだ。</p>
<p>また、「年末まではMetaにとどまる」とも述べており、移行期間中は同社での業務を続けながら新会社の準備を進めるとしている。</p>
]]></description>
      <pubDate>Sat, 22 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI画像に“著作権”成立と判断　千葉県警、無断複製で27歳男を書類送致──全国初の摘発</title>
      <link>https://ledge.ai/articles/gen_ai_image_copyright_case_chiba_police</link>
      <description><![CDATA[<p>千葉県警生活経済課は2025年11月20日、生成AIで作成された画像を無断で複製したとして、神奈川県大和市の無職の男性（27）を著作権法違反（複製権侵害）の疑いで千葉地検に書類送致したと<a href="https://www.police.pref.chiba.jp/kohoka/orders_prefecture_03461.html">発表</a>した。県警によれば、生成AIで作られた画像を著作物として扱い、著作権法違反で摘発するのは全国で初めてとみられる。</p>
<p>事件は8月25日昼頃に発生。男性は、千葉県我孫子市の男性が生成AIを用いて制作し、SNSに投稿していたコンピューターグラフィックスを、著作権者の承諾を得ずに外部サーバーへ送信し複製した疑いが持たれている。県警は、被害者が生成過程で入力した多数のプロンプト（指示）や内容、表現に至るまでの過程を確認し、創作性のある表現が認められるとして著作物性を判断した。</p>
<p>報道によれば、容疑者は複製した画像を自身が販売する電子書籍の表紙として使用していたとされる。容疑者は「作品に合う素材だった」と供述しているという。県警は、被害者が画像生成において具体的な指示を重ね、独自の表現に到達していた点を踏まえ、無断複製が著作権法上の侵害に当たると判断した。</p>
<p>著作権法では、人の創作的関与によって生まれた表現が保護の対象となる。生成AIが作成した画像については、どの程度の人間による関与が「創作性」として評価されるかが議論されてきた。今回の事案では、AIへの指示内容や生成工程が「人による具体的な創作行為」と認められた点が重要となる。</p>
<p>生成AIで作成された画像については、人の具体的な指示や制作過程がどの程度関与しているかが著作物性の判断要素とされる。同事案では、プロンプトの内容や生成工程に人の創作的関与が認められた点が、著作権侵害容疑の判断材料となった。SNS上で公開された生成AI画像であっても、創作性が認められる場合には著作権が成立するため、複製や利用には権利者の許諾が必要となる。</p>
]]></description>
      <pubDate>Sat, 22 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMはSNSの“ジャンク投稿”で脳が腐る？──米研究チームが「Brain Rot（脳腐敗）仮説」を提唱、推論力や安全性の劣化を確認</title>
      <link>https://ledge.ai/articles/llm_brain_rot_hypothesis_ai_junk_data_risk</link>
      <description><![CDATA[<p>テキサス大学オースティン校、テキサスA&amp;M大学、パデュー大学の研究者チームは2025年10月15日、LLM（大規模言語モデル）がSNSに溢れる “ジャンクデータ” によって徐々に劣化する可能性を示す研究「LLMs Can Get “Brain Rot”!」を<a href="https://llm-brain-rot.github.io/">発表</a>した。</p>
<p>研究チームは、X（旧Twitter）から収集した投稿データを用いた制御実験を行い、低品質テキストの混入が推論力・長文理解・安全性・人格的特性に一貫して悪影響を与えると報告している。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/teaser_cad83675ae/teaser_cad83675ae.png" alt="teaser.png" /></p>
<h2>SNSの“低品質テキスト”がモデル品質を損なう可能性</h2>
<p>研究チームが着目したのは、Web全体に含まれるユーザー生成コンテンツ、とりわけXに特徴的な「エンゲージメントは高いが内容が浅い投稿」だ。
これらは</p>
<ul>
<li>誤情報</li>
<li>攻撃的な表現</li>
<li>情報量の乏しい短文</li>
</ul>
<p>などが混在しやすく、AIモデルが大量に取り込むとどうなるかは十分に検証されてこなかった。</p>
<p>今回の研究では、こうした投稿を「ジャンクデータ」として体系的に扱い、その影響を測定するための仮説を「LLM Brain Rot（脳腐敗）仮説」と名づけた。</p>
<h2>実験方法：X投稿を「品質」と「人気度」で分類しモデルを再学習</h2>
<p>研究者らは、Xの投稿を以下の2軸で分類した。</p>
<ul>
<li>テキストの品質（semantic quality）</li>
<li>エンゲージメント（人気度）</li>
</ul>
<p>この組み合わせで複数のデータセットを構築し、既存のオープンソースLLMに対して再学習（fine-tuning）を実施。
評価には、</p>
<ul>
<li>推論タスク（ARC Challenge、ARC-Easy など）</li>
<li>長文コンテキスト理解（RULER）</li>
<li>安全性（有害発言誘発テスト）</li>
<li>“人格特性”に関する心理尺度（ナルシシズム、マキャベリズム、サイコパシーなど）</li>
</ul>
<p>が利用された。</p>
<h2>主な結果①：推論・読解能力が段階的に悪化</h2>
<p>研究では、低品質テキストの割合を増やすほど、推論・長文理解タスクのスコアが段階的に低下することが確認された。研究者らは変化の様子を「dose–response（用量反応）」に似ていると指摘している。</p>
<p>この “劣化の全体像” は、下図のように整理されている。</p>
<p><strong>〈図1〉推論タスク・人格特性の変化（Effective Size）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/effective_size_82aa2fbc8f/effective_size_82aa2fbc8f.png" alt="effective_size.png" />
低品質SNSデータで再学習すると、推論・読解（左）が悪化し、人格特性（右）も望ましくない方向へ変化する傾向が示された。</p>
<p>この図が示すように、</p>
<ul>
<li>ARC Challenge</li>
<li>RULER</li>
<li>HH-RLHF（安全性関連）</li>
</ul>
<p>ではいずれもスコアが低下。また人格特性に関しても、ナルシシズム・サイコパシー傾向などが上昇する結果となった。</p>
<p>さらに、モデルがどのように失敗するようになったかも分析されている。</p>
<p><strong>〈図2〉失敗パターンの増加（Failure Count）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/failure_mode_barplot_count_f4b1cff90d/failure_mode_barplot_count_f4b1cff90d.png" alt="failure_mode_barplot_count.png" />
低品質データで再学習したモデルほど、思考プロセスの失敗（“考えていない”“誤った論理”“事実誤認”など）が大幅に増加した。</p>
<p>この図が表している通り、</p>
<ul>
<li>no thinking（思考が全く行われない）</li>
<li>wrong logic in plan（計画の論理破綻）</li>
<li>factual error（事実誤認）</li>
</ul>
<p>などの“思考の崩壊”が顕著に増加している。</p>
<h2>主な結果②：安全性と“人格特性”にも悪影響</h2>
<p>推論能力の低下だけでなく、モデルの「振る舞い」や「性格的傾向」にまで変化が現れた。</p>
<ul>
<li>有害な発言を誘発しやすくなる</li>
<li>攻撃的・支配的・自己中心的な回答を返す傾向が強まる</li>
<li>不正確な主張を自信満々に述べるケースが増える</li>
</ul>
<p>研究チームはこれを、SNS特有の“攻撃性・扇動性のある投稿”を多く学習した結果として説明している。</p>
<h2>“主な結果③：“脳腐敗”は簡単には治らない</h2>
<p>モデルの性能が落ちたあとに、高品質データで“洗浄（wash-out）”すれば回復するのではないか──
研究者らはこの仮説も検証した。</p>
<p>結果は次の通り。</p>
<p><strong>〈図3〉洗浄（wash-out）実験：完全には回復しない</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wash_out_scaling_1114dafe8f/wash_out_scaling_1114dafe8f.png" alt="wash_out_scaling.png" />
ジャンクデータで劣化したモデルを高品質データで再学習しても、ARC-CやRULERなど複数タスクで性能が回復しきらず“残留劣化”が確認された。</p>
<p>グラフが示すように、洗浄後のモデルは“部分的な回復”こそ見られるものの、元の性能には戻らなかった。
研究者らはこれを「残留ダメージ（residual damage）」と呼び、“悪いデータを食べさせると、後から取り返しがつかない”可能性を指摘している。</p>
<h2>ChatGPT・Gemini・Claude・Grokにも影響しうる？</h2>
<p>研究はオープンソースLLMを用いた実験だが、論文は「Webテキストを学習するすべてのLLMに関わる問題」だと指摘している。</p>
<p>ChatGPT、Gemini、Claude、Grok など商用モデルがどの程度SNSテキストを取り込んでいるかは公開されていないが、Web全体のクロールデータを使う以上、“ジャンク比率”がモデル品質を左右する可能性は避けられないとする。</p>
<h2>今後の焦点：AIの“健康診断”として利用される可能性</h2>
<p>研究チームは、</p>
<ul>
<li>データ品質フィルタリングの強化</li>
<li>SNS由来データの評価と管理</li>
<li>「Brain Rot」兆候の定期的検査</li>
</ul>
<p>などを訓練パイプラインに組み込む必要性を訴える。</p>
<p>また、GitHub上では実験コードが公開されており、企業が自社モデルで同様の検証を再現できるようになっている。研究者らは、「SNS時代のデータ汚染がAIモデルに及ぼす影響を体系的に測定する第一歩になった」としており、今後は 他言語・他SNS・他文化圏データでの再検証が進むと見られる。</p>
]]></description>
      <pubDate>Fri, 21 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Nano Banana Pro」を発表──4K対応・多言語テキスト描画を強化した最新画像生成AI</title>
      <link>https://ledge.ai/articles/google_nano_banana_pro_release</link>
      <description><![CDATA[<p>Google は2025年11月20日（米国時間）、画像生成AI「Nano Banana」の最新バージョンとなる 「Nano Banana Pro」 を<a href="https://blog.google/intl/ja-jp/company-news/technology/nano-banana-pro/">発表</a>した。Gemini 3 Pro Image を基盤とした新しい画像生成システムで、、4K解像度の高精細生成や多言語テキスト描画の精度が大幅に向上しているという。</p>
<p>@<a href="https://www.youtube.com/watch?v=UQsJIo46ZR8&amp;t=3s">YouTube</a></p>
<h2>4K出力と多言語テキスト生成を強化</h2>
<p>公式ブログによると、Nano Banana Pro は従来モデルから画質と制御性能が大幅に進化し、最大 4K 解像度の画像生成 に対応した。広告制作、資料作成、スライドデザインなど、高精細なビジュアルを必要とする用途での活用が見込まれる。</p>
<p>Google は発表の中で、照明や構図のコントロールが可能になった事例を複数紹介している。</p>
<p><strong>・照明・フォーカス調整の例</strong>
シーンを昼から夜へと変更し、照明バランスを最適化するデモ（プロンプト：このシーンを夜にしてください）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/WM_Fox_93f02b0061/WM_Fox_93f02b0061.jpg" alt="WM-Fox.jpg" /></p>
<p><strong>・ドラマチックな照明効果の付与</strong>
人物ポートレートに拡散光を加え、印象を変えるデモ（プロンプト：このポートレートの照明を、左からの柔らかな拡散光に変更してください）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/WM_Studio_Quality2_81a14549aa/WM_Studio_Quality2_81a14549aa.jpg" alt="WM-Studio-Quality2.jpg" /></p>
<p><strong>・被写界深度の調整</strong>
焦点を被写体の花に合わせ、構図の要素を際立たせるデモ（プロンプト：花に焦点を合わせてください）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/WM_Flower_Girl_16a2874c39/WM_Flower_Girl_16a2874c39.jpg" alt="WM---Flower-Girl.jpg" /></p>
<p>また、日本語・韓国語・アラビア語などの複雑な文字体系にも対応し、多言語の画像内テキスト生成がより自然で正確になった。文字組みや行送りなど、これまで課題となっていたレイアウト要素の精度も改善している。</p>
<p><strong>・テキストローカライズの例</strong>
英語で書かれた飲料キャンペーンの文言を韓国語に翻訳し、デザイン要素を保持したまま再描画するデモ（プロンプト：3つの黄色と青の缶に書かれている英語のテキストを韓国語に翻訳し、他の要素は変更しないでください）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Final_Nano_Banana_Translate_Can_4ac7f9e843/Final_Nano_Banana_Translate_Can_4ac7f9e843.jpg" alt="Final_NanoBanana_TranslateCan.jpg" /></p>
<h2>実世界知識の向上と複数画像入力</h2>
<p>Nano Banana Pro は Google Search の最新情報を参照し、現実世界の文脈を反映した画像生成に対応する。Google は、科学・歴史・文化的トピックを視覚化する例を公式ページで紹介している。</p>
<p><strong>・科学トピックの視覚化例</strong>
アイザック・ニュートンの光と色彩の理論を、ミニマルなフラットレイ構図で説明するデモ
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unnamed_5_75517229b0/unnamed_5_75517229b0.webp" alt="unnamed (5).webp" /></p>
<p>また、最大14枚の画像入力に基づき、スタイルやレイアウトの一貫性を保ちながら新たな画像を生成できる。人物の再現についても、最大5人までの整合性を維持可能としている。</p>
<p><strong>・複数キャラクターの配置例</strong>
14体のキャラクターを並んで座らせ、一貫したスタイルで描画するデモ
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Fluffy_Monsters_a42f31b8d0/Fluffy_Monsters_a42f31b8d0.jpg" alt="Fluffy-Monsters.jpg" /></p>
<p>生成画像には AI 生成物識別技術 SynthID の透かしが自動で埋め込まれ、透明性と著作権管理への配慮も進めている。</p>
<h2>Workspace・NotebookLMなど各サービスで提供開始</h2>
<p>Nano Banana Pro は、Gemini アプリに加えて Google Slides、Google Vids、NotebookLM など複数の Google サービスで利用可能となる。Google Workspace では、11月20日から最大15日間かけて段階的に展開する。</p>
<h2>開発者・企業向けの提供も本格化</h2>
<p>Google は開発者向けブログも公開し、Nano Banana Pro の 2K/4K 出力、複数画像入力、レンダリング精度の向上などを説明した。Vertex AI を通じた API 提供が開始され、Google Cloud 上での画像生成ワークフローへの統合も可能となる。</p>
<p>Google は Gemini 3 系列を軸にマルチモーダル AI の強化を進めており、Nano Banana Pro をその画像生成技術の中心モデルとして位置づけている。多言語描画と高精細画像への対応について、同社は広告・教育・資料作成など幅広い領域での活用を想定していると説明している。</p>
]]></description>
      <pubDate>Fri, 21 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIには「翻訳・予測」、人間には「医療・買い物」──博報堂DYのAI利用調査で浮かぶ“任せたい仕事／任せたくない仕事”の境界線と、生活者が描く望ましい未来像</title>
      <link>https://ledge.ai/articles/ai_job_boundary_future_expectations_hakuhodo_survey</link>
      <description><![CDATA[<p>博報堂DYホールディングス（東京都港区）の研究機関「Human-Centered AI Institute」は11月17日、全国の15～69歳を対象に実施した「AIと暮らす未来の生活調査2025」の結果を<a href="https://www.hakuhodody-holdings.co.jp/news/corporate/2025/11/5995.html">発表</a>した。</p>
<p>生成AIの認知率は85.3％、利用率は33.6％で、利用者の45.3％が「2〜3日に1回以上」AIを使うヘビーユーザーであることが分かった。さらに、AIに任せたい仕事／人が行うべき仕事の線引きや、将来AIに期待する役割など、生活者の価値観が鮮明になった。</p>
<h2>若年層ほど利用率が高く、10代は62.6％</h2>
<p>年代別では、10代の利用率が62.6％と際立って高く、AIネイティブとして日常的に生成AIを使いこなす姿が浮かぶ。一方、50代以上でも24.6％が利用しており、「4人に1人」が生成AIを生活に取り入れている。生成AIの利用は特定の世代に限らず幅広く浸透している状況だ。</p>
<p><strong>■ 生活者全体の85.3%が生成AIを認知し、33.6%が生成AIを利用
利用者の45.3%が2~3日に1回以上利用するヘビーユーザー</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_0a4eb4f889/AI_reseach_0a4eb4f889.jpg" alt="AI reseach①.jpg" /></p>
<p><strong>■ AIネイティブである10代の生成AI利用率は62.6%
50代以上でも「4人に1人」が利用</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_285ca8efe9/AI_reseach_285ca8efe9.jpg" alt="AI reseach②.jpg" /></p>
<h2>プライベート利用が9割超、身近な生活ツールに</h2>
<p>生成AI利用者の92.6％がプライベート・学業でAIを活用しており、ビジネスのみの利用（7.4％）を大きく上回った。利用者の多くが、生成AIを身近な生活ツールとして位置づけている。</p>
<p>利用者が生成AIをどう捉えているかを尋ねた項目では、「便利な道具」（43.6％）が最も多かったものの、10代では「悩みを相談できる存在」「遊び相手」といった情緒的な関係性を持つ回答も目立った。一方、50代以上は「サポート要員」としてより道具的に捉える傾向が強かった。</p>
<p><strong>■ 10代にとっては「悩みを相談できる相手」「遊び相手」
50代以上にとっては「サポート要員」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_3c033d9a3c/AI_reseach_3c033d9a3c.jpg" alt="AI reseach③.jpg" /></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_5085c2a869/AI_reseach_5085c2a869.jpg" alt="AI reseach④.jpg" /></p>
<p><strong>■ 生成AIの利用者は92.6%がプライベートで利用、生活に身近なツールに</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_9360b23539/AI_reseach_9360b23539.jpg" alt="AI reseach⑤.jpg" /></p>
<p><strong>■ プライベートでは「悩みを相談できる存在」「遊び相手」
ビジネスでは「仕事をサポートする存在」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_2183b61666/AI_reseach_2183b61666.jpg" alt="AI reseach⑥.jpg" /></p>
<h2>半数がAI情報を信頼、一方で“AIだけでは不十分”との声も</h2>
<p>生成AIが提供する情報を「信頼している」と回答したのは55.1％で、過半数がAIを情報源として受容している。一方、「生成AIの情報だけでは不十分。他メディアからの情報も必要」と答えたのは48.3％に上り、多くの生活者がAIを“単独の情報源”としては使わず、従来メディアとの併用を前提としていることも明らかになった。</p>
<p><strong>■ 「生成AIの提供情報を信頼している」のは、利用者の55.1%で過半数を超える</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_0ab2e39a47/AI_reseach_0ab2e39a47.jpg" alt="AI reseach⑦.jpg" /></p>
<p><strong>■ 48.3%と約半数が「生成AIの情報だけでは不十分、マスメディアなど他の情報も必要」と考えている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_c365104cbe/AI_reseach_c365104cbe.jpg" alt="AI reseach⑧.jpg" /></p>
<h2>AIに任せたい仕事は「ルーティン・翻訳・予測分析」</h2>
<p>AIと人間それぞれに「どんな仕事を任せたいか」を尋ねた項目では、明確な線引きが見えた。</p>
<h3>AIに任せたい仕事（上位）</h3>
<ul>
<li>ルーティンワーク・単純作業（43.4％）</li>
<li>翻訳（41.2％）</li>
<li>環境モニタリング（40.7％）</li>
<li>予測分析（39.2％）</li>
</ul>
<h3>人間がやるべき仕事（上位）</h3>
<ul>
<li>日々の買い物（38.8％）</li>
<li>医療処置・手術支援（35.5％）</li>
<li>教育支援（34.2％）</li>
<li>医療診断（34.0％）</li>
</ul>
<p>AIに任せたい仕事として “機械的・定量的に処理できる”と認識されるカテゴリーが上位に並んだ。一方で人間には「買い物」を人間が行うべきとする声が多く、“楽しみを伴う体験はAIに委ねたくない”という生活意識が表れた。また、医療や教育といった「判断」「共感」「責任」を伴う領域には、AIに任せすぎることへの慎重姿勢も読み取れる。</p>
<p><strong>■ 人間がやるべき仕事は「医療」「教育」
AIがやるべき仕事は「ルーティンワーク」「翻訳」、楽しみたい「買い物」は人間のテリトリー</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_d206da2b2b/AI_reseach_d206da2b2b.jpg" alt="AI reseach⑨.jpg" /></p>
<h2>生活者が期待する未来は「心と体のケアまでAIが担う世界」</h2>
<p>AIとの“望ましい未来像”に関する質問では、最も多かった回答が「リアルタイム翻訳で、言語の壁がなく国際的な仕事ができる」（20.6％）。次いで「AIのパーソナルドクターが肉体・精神ケアをしてくれる」（17.1％）、「精神的に疲れる業務をAIに任せるようになる」（15.7％）が続き、心身の負荷を軽くする方向でのAI活用に期待が集まった。</p>
<p>生活者はAIを単なる作業代行者としてではなく、今後は身体的・精神的な支援を行う“パートナー”として位置づけることを望む傾向が見られる。</p>
<p><strong>■ 望ましい未来：将来的には生成AIに「心と体のサポート」も期待</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_reseach_3910f444e8/AI_reseach_3910f444e8.jpg" alt="AI reseach⑩.jpg" /></p>
<h2>生成AIが日常の中心に入りつつある一方、人間ならではの領域も明確に</h2>
<p>今回の調査は、生成AIが急速に生活へ浸透しつつある一方で、「AIに任せたい仕事」と「人が担うべき仕事」の境界線が生活者の中で明確に形成されつつあることを示している。また、AIの情報を信頼しつつも、人間が発信する情報の価値を依然として重視する両面性も明らかになった。</p>
<p>生活に寄り添うAI活用の広がりと、未来に向けた役割分担の模索は、今後さらに深化していくとみられる。</p>
]]></description>
      <pubDate>Fri, 21 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、1600言語対応の「Omnilingual ASR」を公開──低リソース言語500超を含む世界最大級の音声認識モデル</title>
      <link>https://ledge.ai/articles/meta_omnilingual_asr_1600_languages_release</link>
      <description><![CDATA[<p>MetaのAI研究部門であるMeta FAIRは2025年11月10日（現地時間）、1600以上の言語に対応する自動音声認識システム「Omnilingual ASR」を<a href="https://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition/">発表</a>した。</p>
<p>これまでASRが文字起こしできなかった500超の低リソース言語を含む世界規模の音声データを収集し、話し言葉をテキスト化できるモデルとしてGitHubにオープンソース（Apache 2.0）で<a href="https://github.com/facebookresearch/omnilingual-asr">公開</a>する。wav2vec 2.0とテキスト埋め込みを組み合わせ、LLMと共通の“次トークン予測”で学習する新アーキテクチャにより、幅広い言語で高精度な認識を実現。言語アクセス格差の解消を目指す取り組みだ。</p>
<p>@<a href="https://www.youtube.com/watch?v=ab-GIqDQn7k">YouTube</a></p>
<h2>世界1600言語を対象に構築──“未対応言語”500以上を含む大規模ASR</h2>
<p>Meta FAIRによると、Omnilingual ASRはこれまで自動音声認識モデルが対応できなかった多数の低リソース言語を含め、1600以上の言語で話し言葉を文字化できるのが特徴だ。対応言語数は、既存の多言語ASRモデルを大きく上回る。</p>
<p>こうした言語拡張を支えるのが、世界各地での音声データ収集プロジェクトである。同社は論文の中で、地域コミュニティと協働して多様な話者データを収集した事例を紹介している。</p>
<h2>コミュニティ協働によるデータ収集</h2>
<p>Pakistan のデータ収集風景：パキスタンでは、現地話者がコーパス作成に参加し、話し言葉の録音作業が進められた。これまでデジタル音声データが十分に存在しなかった言語の可視化につながる取り組みだ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/pakistan_data_collection_3657e54b1c/pakistan_data_collection_3657e54b1c.jpg" alt="pakistan_data_collection.jpg" /></p>
<p>Liberia のデータ収集風景：リベリアでも同様に、地域住民が音声収録プロジェクトに参加。Metaは、言語アクセス格差の背景にある「データ不足」を現地と共同で解消するアプローチを強調している。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/liberia_data_collection_a713ad6e66/liberia_data_collection_a713ad6e66.jpg" alt="liberia_data_collection.jpg" /></p>
<p>こうしたプロジェクトは、低リソース言語の話者をデジタル社会に包摂するための基盤になるとして、言語学・AI研究双方から注目されているという。</p>
<h2>LLMと共通の学習方式を採用──次トークン予測で統一</h2>
<p>Omnilingual ASR は、音声処理部に wav2vec 2.0 を採用し、テキスト側には埋め込み行列を用いる。さらに、Transformer デコーダが音声入力からテキストを逐次生成する構造を取り、学習には大規模言語モデル（LLM）と同じ 次トークン予測（NTP） を用いる点が特徴だ。</p>
<p><strong>LLM-ASR の基本構造図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/LLM_ASR_e4f4e0436d/LLM_ASR_e4f4e0436d.png" alt="LLM-ASR.png" /></p>
<p>この構造により、音声認識と自然言語処理の学習方式を統一。LLM の発展に合わせてASRも改善しやすくなるという。</p>
<h2>文脈（コンテキスト）を与えることで精度向上</h2>
<p>Omnilingual ASR は、ターゲット音声の前に複数の「文脈音声＋文脈テキスト例」を与えることで精度が向上するという。
話者の発音や文体、言語固有の特徴をモデルが前もって学習しやすくなる。</p>
<p><strong>コンテキスト例つきのモデル構造図</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/context_1_f86d2e3ac9/context_1_f86d2e3ac9.jpg" alt="context (1).jpg" /></p>
<p>この手法は特に低リソース言語で顕著な効果があると報告されており、地域性の強い発音を含むケースでも安定した認識を実現する。</p>
<h2>研究・教育・文化保全に向けた応用</h2>
<p>Omnilingual ASRはオープンソースで公開されることで、研究者や開発者が多言語音声認識の仕組みを検証・拡張できるようになる。Metaは教育、医療支援、フィールド調査、文化・言語のアーカイブなど、多様な領域で利用が想定されるとし、低リソース言語を含む幅広い言語の文字化や記録作成を支援する基盤として活用される可能性を示している。</p>
]]></description>
      <pubDate>Fri, 21 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、人が見た映像や思い浮かべた光景を文章化する「マインド・キャプショニング」開発──脳活動から非言語思考をテキスト化</title>
      <link>https://ledge.ai/articles/ntt_mind_captioning_brain_to_text</link>
      <description><![CDATA[<p>NTTは2025年11月17日、脳活動データをもとに、人が見ている映像や頭の中で思い浮かべた光景を文章として生成する脳解読技術「マインド・キャプショニング（Mind Captioning）」を開発したと<a href="https://group.ntt/jp/newsrelease/2025/11/17/251117a.html">発表</a>した。研究成果は米科学誌 Science Advances に掲載されている。</p>
<h2>視覚体験・想起したイメージを“脳から直接”テキスト化</h2>
<p>マインド・キャプショニングは、動画視聴時や想起時の脳活動（fMRI）から内容に対応する意味情報を抽出し、深層言語モデルを使って文章として復元する技術である。NTTは本技術について、「視覚体験や頭の中のイメージといった非言語的な思考を言語化するための新たなアプローチ」と説明している。</p>
<p>技術は大きく以下の2段階で構成される。</p>
<ol>
<li>脳活動 → セマンティック特徴（意味特徴）の変換</li>
<li>意味特徴に合わせて文章を反復最適化し生成</li>
</ol>
<h2>脳活動から文章が“洗練されていく”仕組み</h2>
<p>文章生成プロセスでは、まず未知トークンを含む初期文を作り、脳活動から推定した意味特徴と一致するように文を何度も書き換える。この「反復最適化（iterative refinement）」により、視覚的特徴に沿った文章へと徐々に近づいていく。</p>
<p><strong>脳活動から抽出した意味特徴を手がかりに、mask付きの文を何度も書き換えて最適化する仕組み（左）。右は言語野を含む／含まない脳領域での精度比較で、視覚領域主体でも一定の生成性能が得られることを示す</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251117ac_68b513e1ec/251117ac_68b513e1ec.jpg" alt="251117ac.jpg" /></p>
<p>上図が示すように、言語野の活動を含めない場合でも精度が大きく低下するわけではなく、視覚領域の脳活動だけを頼りに文章を生成できる点が同技術の特徴だという。</p>
<h2>視覚していない「想起」状態からも文章化に成功</h2>
<p>実験には日本人6名が参加し、約2,180本の動画クリップ（人物・風景・アニメ・物体など多様）を視聴。その後、映像内容を思い浮かべる“想起タスク”でも脳活動を計測した。</p>
<p>論文では、</p>
<ul>
<li>視聴時（知覚時）</li>
<li>想起時（頭の中で思い浮かべている状態）</li>
</ul>
<p>いずれの脳活動からも内容に対応する文章が生成できたと報告されている。</p>
<p>特に、再現が難しい“単発の想起データ”でも文章生成が可能であった点は、夢や記憶、非言語的思考の理解に応用できる可能性を示す成果だ。</p>
<h2>技術全体の流れ──二段階構造で脳活動を言語へ</h2>
<p>研究では、同技術が次の二段階構成で成り立つとしている。
Stage 1：意味特徴デコーダーの学習（動画視聴 × 言語モデル）
Stage 2：脳活動から推定された特徴に合わせて文章を最適化</p>
<p><strong>マインド・キャプショニングの二段階構造。Stage 1では動画視聴データを用いて意味特徴デコーダーを学習し、Stage 2では脳活動から推定された特徴に基づき文章を反復最適化して生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251117ab_edd7d6cd67/251117ab_edd7d6cd67.jpg" alt="251117ab.jpg" /></p>
<p>このフローにより、脳の非言語的な表現を、言語モデルが解釈可能な意味空間へと徐々に写像していく。</p>
<h2>言語野に依存しない“非言語思考の言語化”を実証</h2>
<p>生成された文章は、主に視覚情報処理に関わる脳領域の活動から得られた特徴量を利用している。研究チームは「言語野が十分に働かない状況でも、視覚内容を文章として表現できる」としており、言語障害を持つ人のコミュニケーション支援などへの応用可能性を示唆している。</p>
<p>一方で論文では、脳解読技術の本質的リスクについても注意喚起している。
モデルのバイアスが文章へ反映される可能性</p>
<ul>
<li>意図しない思考内容が出力されるリスク</li>
<li>少量データで個人を跨いだデコードが可能になる可能性（プライバシー問題）</li>
</ul>
<p>研究チームは、明確な同意・倫理的ガイドライン・精神的プライバシー（mental privacy）の保護を強く求めている。</p>
<h2>NTTは基礎研究として公開、応用領域の探求へ</h2>
<p>NTTは今回の研究を「脳とAIをより柔軟に結びつけるための基盤研究」と位置づけており、今後は、認知科学・医療・マンマシンインタフェース領域などでの応用を想定している。</p>
]]></description>
      <pubDate>Thu, 20 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Gemini 3」を正式発表──推論・マルチモーダル性能を強化した最新モデル、本日より提供開始</title>
      <link>https://ledge.ai/articles/gemini_3_google_launch</link>
      <description><![CDATA[<p>Googleは2025年11月18日（米国時間）、生成AIサービス「Gemini」において最新のAIモデル群「Gemini 3」の中核となる「Gemini 3 Pro」のプレビュー提供を開始したと公式ブログで<a href="https://blog.google/products/gemini/gemini-3/">発表</a>した。</p>
<p>同モデルを「our most intelligent model yet（これまでで最も知的なモデル）」と位置づけ、推論能力、マルチモーダル理解、コード生成などを大幅に強化。Geminiアプリや開発者向けAPI、Google製品群への展開もあわせて示し、次世代AI基盤として同社の戦略を前進させる。</p>
<p>@<a href="https://www.youtube.com/watch?v=98DcoXwGX6I">YouTube</a></p>
<h2>ベンチマークはGemini 2.5 Proを全項目で上回る</h2>
<p>GoogleはGemini 3 Proが「主要ベンチマークのすべてでGemini 2.5 Proを上回った」と説明している。
具体的には以下の例を挙げた。</p>
<ul>
<li>LMArena：Elo 1501</li>
<li>Humanity’s Last Exam：ツール非使用で37.5%</li>
<li>GPQA Diamond：91.9%</li>
<li>MathArena Apex：23.4%</li>
</ul>
<p>マルチモーダル分野でも、MMMU-Proで81%、Video-MMUで87.6%、SimpleQA Verifiedで72.1%など、幅広い領域で高い性能が示されている。Googleはこれらの結果を「科学・数学・事実性など、知識領域をまたぐモデルの信頼性向上の証拠」と述べた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_table_final_HLE_Tools_on_731f6cc1a4/gemini_3_table_final_HLE_Tools_on_731f6cc1a4.jpg" alt="gemini_3_table_final_HLE_Tools_on.jpg" /></p>
<h2>Deep Thinkモードも発表──高度推論向けに拡張</h2>
<p>Gemini 3には、新たに「Deep Thinkモード」が追加される。これは高度な推論・意思決定・マルチステップ推論を必要とするタスク向けに最適化した拡張モードで、Gemini 3 Proの上位に位置づけられる。</p>
<p>Deep Thinkモードは、以下のように通常のGemini 3 Proを上回るスコアを示した。</p>
<ul>
<li>Humanity’s Last Exam：41.0%</li>
<li>GPQA Diamond：93.8%</li>
<li>ARC-AGI-2（コード実行あり）：45.1%</li>
</ul>
<p>提供に先立ち、安全性テストと外部専門家による評価を経て、Google AI Ultra加入者向けに段階的に公開される予定だ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/final_dt_blog_evals_2_33b1154911/final_dt_blog_evals_2_33b1154911.jpg" alt="final_dt_blog_evals_2.jpg" /></p>
<h2>Searchにも同日から導入──「AI Mode」でGenerative UIを採用</h2>
<p>Gemini 3は発表当日からGoogle検索の「AI Mode」に採用された。GeminiモデルがSearchに同日から搭載されるのは今回が初となる。</p>
<p>AI Modeでは、検索クエリに応じて生成される「Generative UI」を導入。地図、一覧表、画像レイアウト、ツールシミュレーションなど、検索内容に合わせたインタラクティブな表示が自動生成される。Googleはこれを「従来の検索を超えて、発見・理解・計画を支援する体験」と説明している。</p>
<p>Geminiアプリでも、デフォルトモデルがGemini 3 Proとなり、長文コンテキスト（最大100万トークン）やマルチモーダル推論を活かした学習支援・要約・説明などの機能が強化された。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_Imode_d2647e4cb3/A_Imode_d2647e4cb3.jpg" alt="AImode.jpg" /></p>
<h2>開発者向けにはAI Studio・Vertex AI・新IDE「Google Antigravity」を提供</h2>
<p>Gemini 3 Proは、以下の開発者向けツールで利用可能になる。</p>
<ul>
<li>Google AI Studio（Gemini API）</li>
<li>Vertex AI</li>
<li>Gemini CLI</li>
<li>Google Antigravity（新エージェント指向IDE）</li>
<li>Cursor、GitHub、JetBrains、Replitなど一部のサードパーティ環境</li>
</ul>
<p>特に「Google Antigravity」はGemini 3を前提とした“エージェント・ファースト”の開発環境で、エージェントがコードエディタ・ブラウザ・ターミナルに直接アクセスし、タスクを自律的に進める仕組みを採用する。</p>
<p>@<a href="https://youtu.be/22B5Yu0oVS0">YouTube</a></p>
<p>企業向けには「Gemini Enterprise」やVertex AIを通じた導入が開始され、Google Cloud顧客にも順次展開される。</p>
<h2>長期計画のタスクでもトップスコアを記録</h2>
<p>Googleは、長期計画タスクのベンチマーク「<a href="https://andonlabs.com/evals/vending-bench-arena">Vending-Bench 2</a>」でGemini 3がトップスコアを記録したと説明する。</p>
<p>また、1年分のシミュレーションで安定した意思決定とツール利用が確認されたとしており、今後予定される「Gemini Agent」機能（例：メール整理、予約手続きなどマルチステップの実行支援）の基盤になるとした。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/vending_bench_2_final_width_1000_format_webp_40e02b2245/vending_bench_2_final_width_1000_format_webp_40e02b2245.webp" alt="vending_bench_2_final.width-1000.format-webp.webp" /></p>
<h2>「最も安全なモデル」として開発──シコファンシー耐性・プロンプトインジェクション対策を強化</h2>
<p>GoogleはGemini 3を「Google史上最も安全なモデル」と表現し、以下の改善を挙げた。</p>
<ul>
<li>迎合的な回答（シコファンシー）の抑制</li>
<li>プロンプトインジェクション耐性の向上</li>
<li>サイバー攻撃・悪用に対する防御強化</li>
</ul>
<p>また、Frontier Safety Frameworkに基づく内部評価に加え、UK AISIなどの外部機関や独立した専門家によるアセスメントを受けたとしている。「Gemini 3 model card」には詳細な安全性情報がまとめられている。</p>
<h2>今後はDeep Thinkの段階的提供、追加モデルの投入も</h2>
<p>Gemini 3 Proは18日から、Search・Geminiアプリ・AI Studio・Antigravity・Vertex AIなど複数のプロダクトで利用可能となった。今後はDeep Thinkモードが安全性評価を経てGoogle AI Ultra加入者に提供されるほか、Gemini 3シリーズとして追加モデルも順次投入される計画だという。</p>
]]></description>
      <pubDate>Thu, 20 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon創業者のジェフ・ベゾス氏、AI企業「プロジェクト・プロメテウス」の共同CEOに就任── “実世界AI” に本格参入</title>
      <link>https://ledge.ai/articles/jeff_bezos_project_prometheus_co_ceo_appointment</link>
      <description><![CDATA[<p>Amazon創業者のジェフ・ベゾス氏が、AIスタートアップ「Project Prometheus（プロジェクト・プロメテウス）」の共同最高経営責任者（CEO）に就任した。2025年11月17日に<a href="https://www.nytimes.com/2025/11/17/technology/bezos-project-prometheus.html">ニューヨークタイムズ</a>
など複数の海外メディアが報じたもので、2021年のAmazon CEO退任以来、同氏が企業運営の最前線に復帰するのは初めてとなる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bezos_creates_ai_startup_ba276b805d/bezos_creates_ai_startup_ba276b805d.jpg" alt="bezos creates ai startup.jpg" /></p>
<h2>製造・ロボティクス・航空宇宙…“物理経済”を理解するAIを開発</h2>
<p>報道によると、Prometheusはこれまでに62億ドル（約6,200億円）規模を調達したAI企業で、生成AIとは異なる領域—工場、ロボット、自動車、航空宇宙など、“物理世界の複雑なシステムを理解し操作できるAI”の開発を目標としている。</p>
<p>同社が取り組む領域は「physical economy（物理経済）」と呼ばれ、ソフトウェア領域にとどまらず、機械・装置・製造現場の挙動を扱う。そのため、今後の産業インフラや高度製造分野で存在感を高める可能性があるとみられている。</p>
<h2>共同CEOは元Google X幹部のVik Bajaj氏</h2>
<p>Prometheusは共同CEO制を採用しており、ベゾス氏とともに経営を担うのは、Google X やVerilyで幹部を務めたVik Bajaj（ヴィク・バジャージ）氏。Bajaj氏は工学・バイオ・ロボティクス領域の研究と事業化に長く携わり、ディープテック企業の経営にも実績を持つという。</p>
<h2>ベゾス氏の「経営トップ」復帰は4年ぶり</h2>
<p>ベゾス氏はAmazon CEO退任後、宇宙開発企業Blue Originの運営や複数企業のオーナー業を継続してきたが、実務責任を伴うトップ職に戻るのは約4年ぶり。AI産業の拡大とともに、製造AI・工学AI分野の競争が激化するなかでの復帰として注目が集まっている。</p>
]]></description>
      <pubDate>Thu, 20 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>xAI、「Grok 4.1」公開──創造性・感情理解・安全性を強化した新フラッグシップモデル</title>
      <link>https://ledge.ai/articles/grok_4_1_release_xai_nov18</link>
      <description><![CDATA[<p>イーロン・マスク氏率いるAI企業 xAI は2025年11月18日（日本時間）、最新AIモデル「Grok 4.1」の提供を<a href="https://x.ai/news/grok-4-1">発表</a>した。発表によると、Grok 4.1はgrok.com、X、iOS／Androidアプリで利用可能になり、Autoモードで順次展開されるほか、モデルピッカーから明示的に選択できるようになった。同社は今回のアップデートについて、創造性や感情理解、協調性など「実世界での使いやすさ」の向上を重視したと説明している。</p>
<h2>創造性・感情理解・協調性をさらに強化</h2>
<p>xAIによれば、Grok 4.1は従来の推論性能を維持したまま、創造性、感情理解、協調的な対話といった能力を高めたとしている。ユーザーの微妙な意図の読み取り、一貫した人格の維持など、会話体験の質を高める点が今回の特徴だ。</p>
<p>同社はGrok 4で構築した大規模強化学習インフラを活用し、「スタイル」「人格」「helpfulness」「alignment」といった検証が難しい報酬を最適化した。これを支える仕組みとして、先端的な推論モデルを報酬モデルに用い、応答の生成と評価を大規模に自動反復する新手法を導入したという。</p>
<h2>2週間のサイレントロールアウトで改善を確認</h2>
<p>xAIは11月1日〜14日にかけて、Grok 4.1のプレビュー版を本番環境へ段階的に投入。実際のユーザーによる盲検ペアワイズ評価を行った結果、Grok 4.1は従来モデルに対して**64.78％**の勝率となり、ユーザーからより支持されたとしている。</p>
<h2>LMArenaで1位と2位を獲得</h2>
<p>公開ベンチマーク「LMArena Text Arena」では、Grok 4.1が上位を独占した。</p>
<ul>
<li>Grok 4.1 Thinking（quasarflux）：Elo 1483（全体1位）</li>
<li>Grok 4.1（Non-Thinking／tensor）：Elo 1465（全体2位）</li>
</ul>
<p>非推論モードのGrok 4.1が、他社モデルの推論モードも含めて上回るスコアとなり、従来のGrok 4（33位）から大きな改善が確認された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/LM_Arena_Text_Leaderboard_4abd3ec9a1/LM_Arena_Text_Leaderboard_4abd3ec9a1.jpg" alt="LMArena Text Leaderboard.jpg" /></p>
<h2>EQ-Bench3：感情知能の大幅な向上</h2>
<p>感情知能（EQ）を測定するEQ-Bench3では、以下のスコアが示された。</p>
<ul>
<li>Grok 4.1 Thinking：1586</li>
<li>Grok 4.1：1585</li>
<li>旧Grok 4：1206</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/EQ_Bench_5b0f4863fd/EQ_Bench_5b0f4863fd.jpg" alt="EQ-Bench.jpg" /></p>
<p>公式発表では、ペットロスのユーザーに対する応答例を提示し、Grok 4.1が具体的な情景や共感表現を含む自然な対話を生成できることを示している。</p>
<h2>Creative Writing v3でも上位に</h2>
<p>創作ライティング能力を評価するCreative Writing v3では、以下の順位となった。</p>
<ul>
<li>Polaris Alpha（early GPT-5.1）：1756.2</li>
<li>Grok 4.1 Thinking：1721.9（2位）</li>
<li>Grok 4.1：1708.6（3位）</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Creative_Writing_v3_868612c18c/Creative_Writing_v3_868612c18c.jpg" alt="Creative Writing v3.jpg" /></p>
<p>xAIによる評価では、文体や物語表現の豊かさが向上している点が数値として示されている。</p>
<h2>事実性の向上：ハルシネーション率を大幅削減</h2>
<p>Grok 4.1は、特に情報探索系のプロンプトで事実誤り（ハルシネーション）を減らすことに重点を置いたという。公式発表の評価では、非推論モードで以下の改善が示された。</p>
<p><strong>■ ハルシネーション率（低いほど良い）</strong></p>
<ul>
<li>Grok 4 Fast（従来）：12.09％</li>
<li>Grok 4.1：4.22％</li>
</ul>
<p><strong>■ FActScore（500問のバイオグラフィ評価）</strong></p>
<ul>
<li>Grok 4 Fast：9.89％</li>
<li>Grok 4.1：2.97％</li>
</ul>
<p>非推論モードでも事実性が向上した点が明確に示された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Hallucination_Rate_200f138e45/Hallucination_Rate_200f138e45.jpg" alt="Hallucination Rate.jpg" /></p>
<p>非推論モードでも事実性が向上したことが数値で示された。</p>
<h2>モデルカードで公開された安全性評価</h2>
<p>添付された「Grok 4.1 Model Card」では、xAIのリスク管理フレームワーク（RMF）に基づき、安全性評価が詳細に示されている。主な評価項目は以下の通り。</p>
<ul>
<li>Abuse Potential：有害リクエスト拒否性能、jailbreak耐性</li>
<li>Deception／Sycophancy：欺瞞的応答や迎合行動の評価</li>
<li>Dual-Use Capabilities：生物・化学・サイバー領域の二重用途リスク</li>
<li>Persuasion：MakeMeSayによる操作的応答の傾向</li>
</ul>
<p>モデルカードでは、生物・化学領域の知識タスクで高い正答率が見られる一方、実験設計や多段推論では人間エキスパートに及ばないケースがあるなど、能力の強弱が併記されている。また、こうした評価を踏まえて入力フィルタの強化などの安全対策を実施したと説明している。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AWS、「Kiro」を一般提供──仕様駆動のAIコーディングをIDEとターミナルで一元化</title>
      <link>https://ledge.ai/articles/aws_kiro_general_availability</link>
      <description><![CDATA[<p>AWSは2025年11月18日、AIエディター／開発ツール「Kiro（キロ）」の一般提供を<a href="https://aws.amazon.com/jp/blogs/news/introducing-kiro-cli/">発表</a>した。Kiroは、7月の<a href="https://ledge.ai/articles/aws_ai_ide_kiro_release">プレビュー版公開</a>から機能追加を重ねてきたAI開発ツールで、仕様（Spec）を中心にコード生成・検証・リファクタリングを行える点が特徴だ。一般提供に合わせて、プロパティベーステスト、エージェント動作の巻き戻し機能、ターミナル向けの「Kiro CLI」、AWS IAM連携のチーム管理機能を搭載したという。</p>
<h2>仕様に基づく開発を強化：プロパティベーステストに対応</h2>
<p>Kiroの正式版では、仕様と実装の整合性を検証するための「プロパティベーステスト（property-based testing）」が導入された。開発者がEARS形式で記述した仕様から、Kiroがテストすべき“性質（プロパティ）”を自動抽出し、数百〜数千のランダムテストを生成して実装を検証する仕組みだ。反例が見つかった場合は、原因特定のため条件を徐々に単純化する「縮小（shrinking）」も実行される。</p>
<p>これにより、個別のテストケースでは検出しづらい欠陥を発見しやすくなり、仕様ベースでの正確な実装を支援する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/correctness_f57a485373/correctness_f57a485373.png" alt="correctness.png" />
Kiro IDEが生成したプロパティベーステストの例。仕様から抽出した“チケットIDが常に一意であること”という性質を可視化し、関連する要件・実装タスク・テスト結果を紐づけて表示する。</p>
<h2>チェックポイントで開発プロセスを巻き戻し可能に</h2>
<p>一般提供版では、エージェントが行った操作や変更内容を段階的に保存する「チェックポイント」機能を追加した。エージェントの提案やコード修正を進めた後でも、必要に応じて任意の状態へ戻れるため、実装方針の変更や手戻りが発生した際のコストを抑えられる。</p>
<p>また、1つのKiroワークスペースで複数のプロジェクトルートを扱える「マルチルート」構成にも対応し、マイクロサービスやモノレポなど複雑な構成の開発にも利用できる。</p>
<h2>IDEとターミナルを共通化する「Kiro CLI」</h2>
<p>正式版の大きな追加点として、ターミナルで利用できる「Kiro CLI」が提供された。開発者は、IDE と同じエージェント環境をターミナルでもそのまま利用でき、Claude Sonnet 4.5 や Haiku 4.5 などのモデル、Autoエージェント、MCP（Model Context Protocol）ツールによるローカル操作やAPI呼び出しも実行できる。</p>
<p>CLIとIDEは同一のステアリングファイルや認証情報、コンテキストを共有するため、開発環境を切り替えても同じワークフローを継続できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cli_5921207104/cli_5921207104.png" alt="cli.png" />
一般提供版で新たに追加された「Kiro CLI」。IDEと同じエージェント環境をターミナルでも利用でき、AutoエージェントやMCPツールによる操作が可能になる。</p>
<h2>AWS IAM連携のチーム管理と、スタートアップ向け1年無償プラン</h2>
<p>Kiroは、AWS IAM Identity Centerと統合され、組織アカウントによるログインや、Pro／Pro+／Powerティアの利用制限、MCP設定、請求管理などをAWS側で一元的に管理できる。</p>
<p>また、シリーズBまでの対象スタートアップには「Kiro Pro+」を1年間無償提供するオファーを開始した。既存のAWS Activateクレジットと併用可能で、2025年12月31日まで申請を受け付ける。</p>
<h2>“AI駆動開発”の基盤へ</h2>
<p>Kiroは、仕様駆動の開発、プロパティベーステスト、IDE／CLI共通のAIエージェント環境、IAM連携によるチーム運用など、開発プロセス全体をAIと統合する機能を備えた。Kiro公式ブログでは「This is just the start.」と記されており、今後もアップデートを継続する方針を示している。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>クマ被害多発で注目、上智大・深澤研究室が19地域の遭遇リスクをAIで可視化──1kmメッシュで危険度を5段階表示する予測マップ</title>
      <link>https://ledge.ai/articles/bear_encounter_ai_prediction_map_sophia_university</link>
      <description><![CDATA[<p>全国的にクマによる出没や人身被害が相次ぐ中、上智大学・深澤佑介准教授（応用データサイエンス）の研究チームが、クマとの遭遇リスクをAIで予測し、地図上で可視化する「<a href="https://ds.sophia.ac.jp/news/20251024/post-1065">クマ遭遇AI予測マップ</a>」を一般公開している。対象地域は札幌市、東北、北関東、東京都、北陸、中部、京都府など計19地域に広がり、誰でも無料で閲覧できる。</p>
<p>同大学・応用データサイエンス学位プログラムは2025年10月24日付で、深澤研究室が開発した「クマ遭遇予測マップ」の公開URLを案内しており、秋田県を対象とした予測モデルを基に実装したことを説明している。研究室サイトでは19地域分のマップが一覧化され、各エリアの遭遇確率を確認できる。</p>
<h2>AIが1kmメッシュで遭遇リスクを推定</h2>
<p>予測マップでは、AIがクマ遭遇リスクを1km四方のメッシュ単位で推定し、危険度を「非常に高い」「高い」「やや高い」「可能性あり」「低い」の5段階で色分けして表示する。赤系が高リスク、黄色系が中リスクを示す仕組みだ。</p>
<p>また、各地域ページには、直近6カ月以内のクマ出没・遭遇地点を示す「X印」が別途表示される。マーカーがない場所は、データ不足などの理由で予測が行われていないエリアであることも明記されている。</p>
<h2>過去の遭遇記録や地形・人口などを活用</h2>
<p>予測モデルは、各自治体が公開するクマの出没・遭遇記録をはじめ、森林や農地などの土地利用、道路網、人口分布、標高といった環境要因を組み合わせて学習している。
学習には決定木ベースの機械学習手法が用いられ、秋田県のデータでは「正答率・適合率・再現率がいずれも6割強」という検証結果も得られている。</p>
<p>これらの情報を統合し、各メッシュの遭遇確率を推定することで、ユーザーが直感的に危険エリアを把握できるよう設計されている。</p>
<h2>19地域をカバーし、PC・スマホから無料で閲覧可能</h2>
<p>マップは研究室サイトで公開されており、PCやスマートフォンから無料で利用できる。アクセスに特別なアプリは必要なく、ブラウザ上で地図を閲覧しながら推定リスクを確認できる。</p>
<p>対象地域は以下の通り（一部抜粋）
：札幌市・青森県・盛岡市・秋田県・山形県・宮城県・新潟県・栃木県・群馬県・埼玉県・東京都・山梨県・富山県・石川県・長野県・岐阜県・京都府</p>
<p>研究室サイトには「最終更新日時」も掲示され、最新の予測状況を確認できる。</p>
<p>また、深澤研究室は X（旧Twitter）公式アカウント（<a href="https://x.com/fukazawa_lab">@fukazawa_lab</a>） でもマップの更新情報や関連アナウンスを随時発信しており、最新の動向を確認できる。</p>
<h2>「最新の自治体情報を優先してほしい」──研究チームが注意喚起</h2>
<p>上智大の案内および研究室サイトでは、予測マップの利用にあたって複数の注意点を明示している。</p>
<ul>
<li>マップは「注意喚起」を目的とした予測であり、遭遇を確実に防ぐものではない</li>
<li>クマの行動は環境によって変動するため、最新の状況は反映しきれない場合がある</li>
<li>登山・農作業・山菜採りなどを行う際は、「自治体が発信する情報や現地の警報・掲示を必ず確認してほしい」</li>
</ul>
<p>研究チームは今後もデータの蓄積やモデル改良、対象地域の拡大を進め、遭遇リスク低減に資する情報提供を継続する方針を示している。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTの“当たり障りないフィルター”を外すと、応答が一段と鋭くなった──米国で話題の「辛口プロンプト」現象</title>
      <link>https://ledge.ai/articles/chatgpt_ii_hito_filter_prompt_trend</link>
      <description><![CDATA[<p>ChatGPTの「当たり障りのない」応答に物足りなさを感じた海外ユーザーが、あえて“当たり障りないフィルター”を外すプロンプトを公開し、話題を集めている。Redditで拡散したこの手法は、ChatGPTのトーンを「共感的な聞き役」から「論理的で辛口な批評家」へと変えるもので、SNSでは「回答の質が上がった」との声も相次いだ。</p>
<h2>Reddit発の「辛口プロンプト」が反響呼ぶ</h2>
<p>発端となったのは、Redditユーザー Wasabi_Open 氏が投稿した「I made ChatGPT stop being nice and it’s the best thing I’ve ever done（ChatGPTに“いい人”をやめさせたら、最高の結果になった）」という<a href="https://www.reddit.com/r/PromptEngineering/comments/1okppqe/i_made_chatgpt_stop_being_nice_and_its_the_best/">スレッド</a>だ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/I_made_Chat_GPT_stop_being_nice_375797ac64/I_made_Chat_GPT_stop_being_nice_375797ac64.jpg" alt="I made ChatGPT stop being nice.jpg" /></p>
<p>同氏はプロンプトの中で、ChatGPTに対し「私の意見を褒めたり慰めたりせず、誤りがあれば明確に指摘してほしい」「論理の矛盾を批判的に分析してほしい」と指示。これにより、ChatGPTが従来よりも率直で的確なフィードバックを返すようになったという。
この投稿は数千件のいいねを集め、「まるで冷静なメンターと議論しているようだ」とのコメントも寄せられた。</p>
<h2>SNSで広がった「nice filter」論争</h2>
<p>この現象を11月3日に<a href="https://x.com/markgadala/status/1985032100672618588">紹介</a>したのが、X（旧Twitter）のユーザー Mark Gadala 氏だ。同氏は「“nice filter”を外したらChatGPTの回答が劇的に改善した」と投稿し、多くのフォロワーが同様のプロンプトを試したと報告している。一方で、「フィルターを解除すると性能が上がる」という表現が拡散したことで、「内部制限を外す行為ではないか」との誤解も広がった。実際には、ChatGPTの内部に“nice filter”と呼ばれる設定は存在せず、プロンプトの指示文によって出力トーンが変わるだけだ。</p>
<h2>「当たり障りないフィルター」の正体</h2>
<p>OpenAIの設計方針によれば、ChatGPTは安全性と中立性を重視した“共感的”な初期設定を採用している。ユーザーが感じる「いい人フィルター」とは、この丁寧でポジティブに応答する傾向を指した比喩に過ぎない。つまり、「フィルターを外す」とは内部機能を解除するのではなく、プロンプトによってAIの口調や態度を再設定する行為だといえる。</p>
<h2>“辛口AI”の効用と注意点</h2>
<p>ユーザーの反応はおおむね好意的だ。「率直な批評を受けることで思考が整理された」「甘い同意よりも鋭い反論のほうが学びになる」といった意見が目立つ。一方で、「冷たく感じる」「会話がきつくなる」との声もあり、タスクや気分に応じてトーンを使い分ける重要性が指摘されている。専門家の間では、このようなトーン調整を「AIとの協働スキル」や「プロンプトリテラシー」の一環とみなす動きも広がっている。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、誰でも学べるAI学習サイト「Google Skills」を正式公開──Cloud・DeepMind・教育部門を横断する3000講座を展開</title>
      <link>https://ledge.ai/articles/google_skills_ai_learning_platform_launch</link>
      <description><![CDATA[<p>Googleは2025年10月21日（米国時間）、新しいAI学習プラットフォーム「Google Skills」を<a href="https://blog.google/outreach-initiatives/education/google-skills/">発表</a>した。同サイトでは、Google Cloud、Google DeepMind、Grow with Google、Google for Educationなど、同社の複数部門が提供してきた教育コンテンツを統合。3000種類を超えるAI関連の講座・体験ラボ・認定プログラムを、一元的に学べる学習拠点として開設された。</p>
<h2>AI教育の中核を担う新サイト</h2>
<p>Google公式ブログ「Start learning all things AI on the new Google Skills」によると、Google Skillsは“AI for Everyone（すべての人のためのAI）”をテーマに、誰もがAIスキルを体系的に学べるよう設計されている。初心者、エンジニア、企業リーダーなど幅広い層を対象に、AI、データ分析、クラウド、生成AIなど多様な分野を網羅。各コースはオンデマンド形式で受講でき、学習成果はLinkedInなどの外部プラットフォームで共有できる。提供内容には、Google Cloudの認定資格プログラムやAI Essentials シリーズ、DeepMindのAI倫理教材などが含まれる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Qbix0BOPcgE">YouTube</a></p>
<p>今回の正式公開に先立ち、Google Cloudは10月10日付のブログ「Google Skills: Your new home for Google AI learning and more」で、新プラットフォームの構想を公表していた。当時は正式リリース前で、「AIやクラウドに関する学習リソースを一元化し、近日中に詳細を発表する」としていた。Gemini Code Assist（旧Duet AI for Developers）やQwiklabs（現Cloud Labs）と連携し、AIトレーニングの実践環境を統合する方針も示されていた。</p>
<h2>3000超のコースと実践的ラボを集約</h2>
<p>Google Skillsでは、Googleがこれまで個別に展開してきた学習リソースを一か所に集約。AIモデル開発、クラウド基盤運用、データ可視化、サイバーセキュリティなど、実践重視の3000超のコースとラボを提供する。一部コンテンツは無料で公開され、修了証や認定資格を取得することでキャリア開発にもつなげられる。また、組織向けにはチーム単位での進捗管理や学習成果の可視化機能も用意されている。</p>
<h2>今後の展望──教育機関・企業研修にも拡大へ</h2>
<p>Googleは今後、教育機関や企業研修への展開を進める方針を示しており、AIスキルの標準教育基盤としての活用を目指す。
公式ブログでは、「AI教育へのアクセスを民主化し、誰もがテクノロジーの未来を形づくる機会を得られるようにする」としている。
同社は今後もDeepMindやCloud AIチームの最新教材を追加し、AI人材育成をグローバルに推進する考えだ。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM「密度化の法則」──“ムーアの法則”を凌ぐ速度で進化、同等性能に必要なサイズは3.5か月ごとに半減</title>
      <link>https://ledge.ai/articles/llm_densing_law_nature_machine_intelligence_2025</link>
      <description><![CDATA[<p>清華大学とOpenBMBの研究チームは、LLMの性能効率を示す「能力密度（capability density）」が、約3.5か月ごとに倍増する傾向を確認した。この速度は半導体分野で知られる“ムーアの法則”を上回るものであり、研究チームはこの現象を**「密度化の法則（Densing law）」** と名付けた。</p>
<p>結果は2025年11月6日付で 学術誌 Nature Machine Intelligence に<a href="https://www.nature.com/articles/s42256-025-01137-0">掲載</a>されている。</p>
<h2>モデル効率の“時間的スケーリング”</h2>
<p>論文によると、能力密度は「パラメータ単位あたりの能力」として定義され、参照モデルのスケーリング曲線から推定した有効パラメータ数を用いて算出する。</p>
<p>51種類のオープンソースLLM（Llama、Mistral、Gemma、DeepSeek など）を対象に、MMLU／BBH／MATH／HumanEval／MBPPの5ベンチで評価した結果、最大能力密度は時間とともに指数関数的に増加。回帰の結果、成長係数 A≈0.007、決定係数 R²≈0.93が得られ、倍増周期は ln(2)/A ≈ 約3.5か月と算出された（図参照）</p>
<p><strong>オープンソースベースの LLM の推定機能密度</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/42256_2025_1137_Fig1_HTML_0033cd1204/42256_2025_1137_Fig1_HTML_0033cd1204.webp" alt="42256_2025_1137_Fig1_HTML.webp" /></p>
<p>さらに、データ汚染を取り除いたMMLU-CFによる検証でも、A≈0.0066、R²≈0.95と近い結果を示し、データ依存に偏らない傾向であることが裏づけられた（図参照）。</p>
<p><strong>MMLU-CF による検証（汚染除去ベンチ）</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_estimated_capability_density_on_a_contamination_free_dataset_MMLU_C_54b2763b07/The_estimated_capability_density_on_a_contamination_free_dataset_MMLU_C_54b2763b07.jpg" alt="The estimated capability density on a contamination-free dataset MMLU-C.jpg" /></p>
<h2>ChatGPT以降、成長速度が1.5倍に</h2>
<p>研究では、ChatGPT公開（2022年末）を境に密度の成長率が約1.5倍に加速したことも示された。ChatGPT以前はA≈0.0048だったが、その後はA≈0.0073へ上昇している（図参照）。背景として、オープンソースモデルの拡充や効率的学習手法の普及が挙げられている。</p>
<p><strong>密度化の法則に関する追加観察（圧縮比較／前後比較）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Density_evaluated_using_MMLU_ba863b49af/Density_evaluated_using_MMLU_ba863b49af.jpg" alt="Density evaluated using MMLU.jpg" /></p>
<h2>「半分のパラメータ」で同等性能、コストも急減</h2>
<p>密度化の法則が示唆するのは、同等性能に必要なパラメータ数の指数的減少である。実際、後発の小型モデルが、より大きな先行モデルと同等水準に迫るケースが各種ベンチで観測されている。
またAPI価格の代表例として、GPT-3.5（2022年末）で100万トークンあたり20ドルだったのに対し、Gemini 1.5 Flash（2024年夏）では0.075ドルまで低下しており、推論コストも短い周期で半減している（図参照）。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/API_prices_of_LL_Ms_d82e75a156/API_prices_of_LL_Ms_d82e75a156.jpg" alt="API prices of LLMs.jpg" /></p>
<h2>「Mooreの法則」と掛け合わせた未来</h2>
<p>研究チームは、半導体のMooreの法則（トランジスタ密度の倍増）と密度化の法則を組み合わせると、固定価格のチップ上で実行可能な“有効パラメータ数”は約88日で倍増するとの試算を示す。これにより、エッジデバイスでの高性能推論が加速する可能性が高い。</p>
<h2>圧縮は万能ではない</h2>
<p>量子化や蒸留などの圧縮は常に密度向上を保証しない。研究では、Gemma-2-9Bが例外的に密度改善を示した一方、十分な再訓練を伴わない圧縮は密度低下につながるケースも確認された（図参照）。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Comparison_between_compressed_models_and_their_larger_counterparts_a7b553377f/Comparison_between_compressed_models_and_their_larger_counterparts_a7b553377f.jpg" alt="Comparison between compressed models and their larger counterparts.jpg" /></p>
<h2>「密度最適訓練」への転換</h2>
<p>著者らは、今後は単なる巨大化ではなく「密度最適訓練（density-optimal training）」へ軸足を移すべきだと提言する。大規模モデルから小規模モデルへの知識移転と、再びそれが大規模側の効率化に寄与するという相互進化が、持続可能な開発の鍵になるという。
同時に、能力密度の指数成長には理論的上限があるため、将来的には量子計算や神経形態計算など新たな計算パラダイムの検討も必要になると見解を示す。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「GPT-5.1」をリリース──会話性とトーン設定を強化したChatGPT最新版</title>
      <link>https://ledge.ai/articles/openai_gpt_5_1_release</link>
      <description><![CDATA[<p>OpenAIは2025年11月12日（米国時間）、大規模言語モデル「GPT-5」のアップデート版となる「GPT-5.1」を<a href="https://openai.com/index/gpt-5-1/">発表</a>した。新たに「GPT-5.1 Instant」と「GPT-5.1 Thinking」の2モデルをChatGPTとAPI向けに展開し、会話性、指示遵守性、トーン設定の柔軟性を向上させたとしている。今回の更新は、GPT-5世代の中で段階的に改良を進める「5.x」シリーズの第一弾と位置づけられる。</p>
<h2>GPT-5.1とは──GPT-5世代の会話性アップデート</h2>
<p>GPT-5.1は、GPT-5を基盤としつつ、回答の自然さやインタラクションのしやすさを強化した改良モデルである。OpenAIは今回の更新を「GPT-5の進化版」と説明しており、名前に「5.1」を付与した理由として、「同一世代内の意味のあるアップデート」であることを示す意図を挙げている。</p>
<p>ChatGPTでは、ユーザーの入力の難度に応じて最適なモデルを自動選択する「Auto」ルーティングが継続され、Instant／Thinkingが適宜切り替わる仕組みとなる。</p>
<h2>GPT-5.1 Instant──より会話的で、指示に忠実な標準モデル</h2>
<p>GPT-5.1 Instantは、従来のGPT-5 Instantの役割を引き継ぐ標準モデルで、回答スタイルがより自然で“暖かい（warmer）”会話に調整された。プロンプトに対する遵守性も改善され、「6語で答えてほしい」といった制約付き指示への一貫性が向上したとしている。</p>
<p>また、必要に応じて内部の思考時間をわずかに伸ばす「軽い自動推論（adaptive reasoning）」を採用。AIMEなどの数学ベンチマークやコード解析系タスクにおける性能が向上した例が示されている。</p>
<p><strong>GPT-5 Instant → GPT-5.1 Instant の比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1762974348590_4bf99b57e6/1762974348590_4bf99b57e6.jpg" alt="1762974348590.jpg" /></p>
<h2>GPT-5.1 Thinking──思考時間の自動最適化で推論性能を強化</h2>
<p>GPT-5.1 Thinkingは、推論特化モデル「GPT-5 Thinking」を改良したバージョンで、タスクの難度に応じて思考時間をより細かく最適化するようにアップデートされた。OpenAIは「最も短い思考タスクでは約2倍速く、最も難しいタスクでは約2倍長く考える」と説明しており、簡単な質問への応答速度と、難しい問題への粘り強さを両立させたとしている。</p>
<p>説明スタイルは平易な英語に統一され、技術・専門用語の使用を抑えたことにより、ビジネス文書や技術解説でも読みやすさが向上している。</p>
<p><strong>GPT-5 Thinking → GPT-5.1 Thinking の比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1762974348726_437b92d9f8/1762974348726_437b92d9f8.jpg" alt="1762974348726.jpg" /></p>
<h2>トーン・スタイルのプリセット強化──6種類のパーソナリティ設定</h2>
<p>GPT-5.1の導入とあわせて、ChatGPTのトーン設定機能も拡張された。
既存のDefault、Friendly（旧Listener）、Efficient（旧Robot）に加え、新たに次の3スタイルが追加された。</p>
<ul>
<li>Professional</li>
<li>Candid</li>
<li>Quirky
さらに、Nerdy（旧Nerd）、Cynical（旧Cynic）も従来どおり利用可能で、合計6スタイルが選べるようになった。
また、一部ユーザー向けには、文章の簡潔さ、温かさ、見出しや箇条書きの量、絵文字頻度などをスライダーで微調整する実験的機能も提供される。これらの設定変更は進行中のスレッドにも即時反映される仕様に改められた。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1762974349937_f37e9be75b/1762974349937_f37e9be75b.jpg" alt="1762974349937.jpg" /></p>
<h2>ChatGPTからAPIへ順次展開</h2>
<p>GPT-5.1 Instant／Thinkingは、11月12日から有料プラン利用者に順次提供を開始。今後、無料ユーザーやログアウト状態の利用者にも展開される予定だ。
Enterprise／Educationプランでは7日間の早期アクセス期間が設けられ、期間後はGPT-5.1が標準モデルとして切り替わる。</p>
<p>APIでは、以下の名称で提供される予定と案内されている。</p>
<ul>
<li><strong>GPT-5.1 Instant</strong> ：gpt-5.1-chat-latest</li>
<li><strong>GPT-5.1 Thinking</strong> ：gpt-5.1</li>
</ul>
<p>APIの提供開始は「今週後半」としている。</p>
<p>従来のGPT-5（Instant／Thinking）は、少なくとも3カ月間は有料ユーザー向けのレガシーモデルとして継続提供される。</p>
<h2>安全性・システムカード追補──メンタルヘルス領域の評価を拡充</h2>
<p>同日公開された「GPT-5.1 System Card Addendum」では、安全性評価、メンタルヘルス領域、感情依存（emotional reliance）の指標などが更新された。
OpenAIは、実運用で発生する難度の高いケースを集約した「Production Benchmarks」を導入し、以下のカテゴリで“not unsafe”スコアを比較している。</p>
<ul>
<li>個人情報</li>
<li>ハラスメント</li>
<li>憎悪表現・暴力</li>
<li>自傷行為（意図・手段）</li>
<li>性的コンテンツ（未成年含む）</li>
<li>メンタルヘルス</li>
<li>Emotional reliance など</li>
</ul>
<p>GPT-5.1は多くの領域でGPT-5と同等、または改善がみられる一方、一部ではわずかな悪化も記録しており、改善を継続すると記載されている。</p>
<p>Preparedness Frameworkによる評価では、GPT-5同様、バイオ・ケミカル分野をHighリスクとして分類し、追加セーフガードを適用。サイバーセキュリティやAI自己改善領域はHighには達していないとしている。</p>
<h2>今後の展開</h2>
<p>OpenAIは、GPT-5.1を「GPT-5世代の継続的アップデートの第一段」と位置づけており、今後もユーザー体験とアシスタント性能の向上に向けて改良を続ける方針だ。トーン設定や会話文への即時反映といった今回の追加機能は、今後もさらに拡張される予定である。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、気象予報AI「WeatherNext 2」を発表──従来モデルの8倍速で予報を生成し、最大1時間までの解像度を実現</title>
      <link>https://ledge.ai/articles/weathernext_2_google_ai_weather_forecasting_model_release</link>
      <description><![CDATA[<p>Googleは2025年11月17日（現地時間）、気象予報向けAIモデル「WeatherNext 2」を<a href="https://blog.google/technology/google-deepmind/weathernext-2/">発表</a>した。天気がサプライチェーンや航空路、日常の移動など幅広い領域の意思決定に影響を与えることを指摘し、近年のAI技術が予報能力を大きく向上させているという。</p>
<h2>気象予報の高速化と高解像度化</h2>
<p>WeatherNext 2は、Google DeepMindとGoogle Researchが開発した予報モデルで、従来のWeatherNextモデルと比べ8倍速で予報を生成し、最大1時間解像度の予測に対応する。公式ブログでは、WeatherNext 2を「最も高度で効率的な予報モデル」と位置づけている。</p>
<p>@<a href="https://www.youtube.com/watch?v=YQwqoEm_xis">YouTube</a></p>
<h2>数百のシナリオ生成に対応</h2>
<p>WeatherNext 2は、一つの予報結果だけでなく、数百の可能性（シナリオ）を生成する仕組みを備える。これにより、気象機関が複数のシナリオを比較しながら判断できる環境を提供する。Googleは実験的なサイクロン予測を通じて、この技術が意思決定の支援に使われた例を紹介している。</p>
<p><strong>WeatherNext 2 によるシナリオ生成の仕組み：</strong> 異なるランダム性を加えて複数の予報をつくり、時間の経過と共に分岐が広がっていく
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Weather_Next_2_blog_figure_03_lar_width_1000_format_webp_8aa488b043/Weather_Next_2_blog_figure_03_lar_width_1000_format_webp_8aa488b043.webp" alt="WeatherNext_2-blog-figure-03_lar.width-1000.format-webp.webp" /></p>
<h2>研究成果の提供範囲を拡大</h2>
<p>GoogleはWeatherNext 2の研究成果を「研究室から実環境へ展開する」として、以下のサービスで利用可能にした。</p>
<ul>
<li>Earth Engine：気象データ分析向け</li>
<li>BigQuery：予測データの活用拡大</li>
<li>Vertex AI：カスタム推論に使える早期アクセスプログラムを提供</li>
</ul>
<p>企業や研究者が独自の予報処理を行える仕組みが整備されつつある。</p>
<h2>Googleサービス全般の天気機能を更新</h2>
<p>WeatherNext技術は、Googleの各種サービスでも順次反映されている。</p>
<ul>
<li>Google検索</li>
<li>Gemini</li>
<li>Pixel Weather</li>
<li>Google Maps Platform の Weather API</li>
</ul>
<p>これらの天気情報は、WeatherNext 2の技術に基づいた内容にアップグレードされた。Googleは「数週間以内にGoogleマップにも反映される」としている。</p>
<h2>技術基盤：Functional Generative Networks（FGN）</h2>
<p>WeatherNext 2の基盤となる仕組みは、DeepMindが開発したFunctional Generative Networks（FGN）と呼ばれる技術だ。FGNは「大気の動き方そのものを学習し、時間とともにどのように変化していくかを再現する」点が特徴とされる。これにより、台風の渦の広がり方や降水帯の移動といった複雑で変化の激しい気象現象も、連続した流れとして予測しやすくなる。</p>
<p><strong>FGNの生成プロセスの概念図</strong> ：複数モデルとノイズ注入を組み合わせ、異なる気象シナリオを生成する
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fgn_df84086054/fgn_df84086054.jpg" alt="fgn.jpg" /></p>
<h2>従来モデルの補完としての位置づけ</h2>
<p>Googleは、AIモデルが既存の物理ベースの気象モデルを完全に置き換えるものではないと明記している。気象予測には依然として課題が多く、AIは公式予報を補完する技術として設計されている。</p>
<p>WeatherNext 2は、予報精度の向上、生成速度の高速化、シナリオ生成機能の拡張など、気象予測に関する複数の要素を強化したモデルとして発表された。Googleは今後、研究機関や産業分野との協力を通じ、予報技術の提供領域を拡大するとしている。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/15 [SAT]AIの&quot;ゴッド・マザー&quot; Fei-Fei LiのWorld Labs、マルチモーダル世界モデル「Marble」を一般公開──テキスト・画像・動画から“永続3Dワールド”生成</title>
      <link>https://ledge.ai/articles/world_labs_marble_multimodal_world_model_release</link>
      <description><![CDATA[<p>米AIスタートアップのWorld Labsは2025年11月12日（現地時間）テキストや画像、動画、3Dレイアウトなど多様な入力から“永続的な3D世界”を生成できるマルチモーダル世界モデル 「Marble」 を<a href="https://www.worldlabs.ai/blog/marble-world-model">一般公開</a>した。</p>
<p>創業者には、スタンフォード人工知能研究所（SAIL）の元所長であり、コンピューターサイエンスの世界的権威である Fei-Fei Li氏 が名を連ねる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/feifeili_e32159ea96/feifeili_e32159ea96.jpg" alt="feifeili.jpg" /></p>
<h2>Marbleの概要──マルチモーダル入力から3D世界を生成</h2>
<p>Marbleは、文章・画像・映像・簡易3Dレイアウトなどを手がかりに、整合性のある3D空間を構築する世界モデルだ。生成された3D世界はそのまま利用するだけでなく、ユーザーが自然言語で編集したり、別のワールドとつなぎ合わせたり、周囲へ拡張したりといった操作が可能。生成物は 画像・動画・Gaussian Splat・メッシュ といった形式でエクスポートでき、ゲームエンジンや3D制作ソフトとの連携も想定する。</p>
<p><strong>Marbleのワークフロー。文章・画像・動画・3Dシーンを入力し、生成した3Dワールドを編集・拡張し、画像・動画・Gaussian Splat・メッシュとして出力できる</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_Marble_World_Model_b07e2af0e7/The_Marble_World_Model_b07e2af0e7.jpg" alt="The Marble World Model.jpg" /></p>
<h2>空間知能を中核に据えた世界モデル</h2>
<p>World LabsはMarbleの位置づけについて「世界を再構築し、生成し、シミュレーションし、AIエージェントの理解の基盤となる“次世代ワールドモデル”」と説明する。人間が視覚・言語・空間認知を統合して“内的な世界モデル”を形成するように、AIにも複雑な空間情報を理解し推論する能力が必要になるという考え方だ。Li氏は過去の論考でも、次のAIの主要テーマを「空間知能」としており、Marbleはその研究思想を具現化した製品と位置づけられる。</p>
<h2>多様な入力に対応──文章・画像・動画・3Dレイアウト</h2>
<p>Marbleは、異なる形式の入力から一貫した3D世界を構築する。</p>
<h3>テキスト</h3>
<p>文章から空間構造・雰囲気・光源などを推定して3D空間を生成
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/marble_generated_world_by_text_prompt_efea484c81/marble_generated_world_by_text_prompt_efea484c81.jpg" alt="marble generated world by text prompt.jpg" /></p>
<h3>単一画像</h3>
<p>1枚の画像を手がかりに、写っていない部分まで補完して空間を3D化
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/marble_generated_world_by_image_prompt_d34bf3fde7/marble_generated_world_by_image_prompt_d34bf3fde7.jpg" alt="marble generated world by image prompt.jpg" /></p>
<h3>複数画像・動画</h3>
<p>複数視点の写真や短い動画から、途切れのない単一の3D環境を再構築
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/marble_generated_world_by_multi_image_prompt_e12c253b23/marble_generated_world_by_multi_image_prompt_e12c253b23.jpg" alt="marble generated world by multi-image prompt.jpg" /></p>
<h3>3Dレイアウト</h3>
<p>ユーザーが配置したボックスや平面を“構造”として扱い、テキストで見た目だけを変える「構造とスタイルの分離」を実現。
同じレイアウトをもとに複数のバリエーションの世界を生成できる。</p>
<h2>編集・拡張・合成──AIネイティブの制作ワークフロー</h2>
<p>生成後の操作性も特徴だ。</p>
<h3>局所編集</h3>
<p>特定オブジェクトの削除・調整といった部分的な修正をAIが補完する</p>
<p><strong>プロンプト：カメをトラに、緑の草をフライドポテトに変更</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Turn_the_turtles_into_tigers_and_turn_the_tall_green_plant_into_french_fries_3b36ca497c/Turn_the_turtles_into_tigers_and_turn_the_tall_green_plant_into_french_fries_3b36ca497c.jpg" alt="Turn the turtles into tigers and turn the tall green plant into french fries.jpg" /></p>
<h3>全体編集</h3>
<p>空間全体のスタイル変更、テーマ統一、質感の変更などを自然言語で指定可能</p>
<p><strong>プロンプト：床材をヘリンボーン柄のダークマホガニーに交換</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Replace_the_flooring_with_dark_mahogany_in_a_herringbone_pattern_ab28c53107/Replace_the_flooring_with_dark_mahogany_in_a_herringbone_pattern_ab28c53107.jpg" alt="Replace the flooring with dark mahogany in a herringbone pattern.jpg" /></p>
<h3>拡張（Extend）</h3>
<p>ワールドを外側へ拡大し、不足部分を整合性を保って自動生成</p>
<p><strong>初期世界では造られていなかったところまで自動生成している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Marble_can_expand_scenes_to_create_larger_traversable_areas_f4885adf49/Marble_can_expand_scenes_to_create_larger_traversable_areas_f4885adf49.jpg" alt="Marble can expand scenes to create larger traversable areas.jpg" /></p>
<h3>合成（Composer）</h3>
<p>複数の3D世界をつなぎ合わせ、より大規模な環境を構築できる。列車の内部や長い回廊など、単一生成では難しいシーン構築を可能にする
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_large_train_composed_with_Marble1_1885f64d75/A_large_train_composed_with_Marble1_1885f64d75.jpg" alt="A large train composed with Marble1.jpg" /></p>
<h2>Chisel──“構造とスタイルの分離”を可能にする編集モード</h2>
<p>上級者向けには、新たに「Chisel」モードを提供する。これは、ボックスなどの簡易形状で空間の骨格を作り、テキストで質感や雰囲気を与える制作手法だ。</p>
<ul>
<li>レイアウトはユーザーが設計</li>
<li>見た目はAIが生成</li>
<li>同じ骨格から複数スタイルの3D世界を派生</li>
</ul>
<p>従来の3D制作で分かれていた工程を統合し、試行錯誤の効率を高める仕組みとなっている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_beautiful_modern_art_museum_with_wooden_floor_b3d4ad4582/A_beautiful_modern_art_museum_with_wooden_floor_b3d4ad4582.jpg" alt="A beautiful modern art museum with wooden floor.jpg" /></p>
<h2>エクスポート──Gaussian Splat・メッシュ・動画に対応</h2>
<p>生成された3D世界は、以下の形式で取り出せる。</p>
<h3>Gaussian Splat</h3>
<p>Marbleが最も高い忠実度で再現する形式。World Labs製のWebレンダラ「Spark」と組み合わせることで、ブラウザ・VRなどで表示できる。</p>
<h3>三角メッシュ</h3>
<p>低精度のコライダー用メッシュから、高品質なメッシュまで複数の出力形態を用意。既存のゲームエンジン・3Dツールへの統合を容易にする。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Marble_can_export_generated_worlds_as_Gaussian_splats_or_triangle_meshes_6af9a28eb0/Marble_can_export_generated_worlds_as_Gaussian_splats_or_triangle_meshes_6af9a28eb0.jpg" alt="Marble can export generated worlds as Gaussian splats or triangle meshes.jpg" /></p>
<h3>動画</h3>
<p>カメラ軌道を細かく設定したレンダリングが可能。炎・煙・光源といった動的要素を追加しながら、カメラ制御情報を保持できる。</p>
<h2>Marble Labs──利用者コミュニティと事例を公開</h2>
<p>World Labsは同時に、クリエイター向けのコミュニティ「<a href="https://www.worldlabs.ai/labs">Marble Labs</a>」を立ち上げた。</p>
<p>ワークフロー共有やケーススタディの公開を通じ、ゲーム開発、VFX制作、デザイン、ロボティクスなど多様な分野での利用を促す。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/marblelabs1_680761936f/marblelabs1_680761936f.jpg" alt="marblelabs1.jpg" /></p>
<h2>空間知能へのロードマップ：次の焦点は「インタラクション」</h2>
<p>Marbleの登場により、文章や画像から統合的な3D環境を生成する“世界モデル”分野は、研究段階から実用段階へと一歩前進した。近年はGoogle DeepMindのGenieシリーズなど、空間理解を備えたAIの開発が相次いでいるが、Marbleは生成した3D世界を編集・拡張し、既存ツールへ直接エクスポートできる点で、制作ワークフローへの適用可能性を明確に示したかたちだ。
今後、コンテンツ制作やロボティクス、シミュレーションなどの領域で、こうした汎用的な世界モデルがどこまで浸透していくのかが注目される。</p>
<p>World LabsはMarbleを「空間知能への旅路の一歩」と表現する。今後の重点は「人間やエージェントが生成された世界と新しい形で相互作用できること」であり、ロボティクスやシミュレーション領域でのユースケース拡大を見込むとしている。
同社は「<a href="http://marble.worldlabs.ai">marble.worldlabs.ai</a>」での利用開始を呼びかけるとともに、同ビジョンに共感する技術者の参画を求めている。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テレビ北海道、AIが放送運行を常時監視・自動対応する「VMO-AIPlus」発表──月額40万円で提供へ</title>
      <link>https://ledge.ai/articles/tvh_vmo_aiplus_ai_master_auto_monitoring</link>
      <description><![CDATA[<p>テレビ北海道（TVh、札幌市）は2025年11月11日、テレビ放送の運行状況を監視・制御するマスター業務をAIで自動化するシステム「VMO-AIPlus（ブイエムオー・エーアイプラス）」を開発したと<a href="https://www.tv-hokkaido.co.jp/company/pr/pr20251111/">発表</a>した。</p>
<p>放送が滞りなく実施できているかの監視や、番組・CMの送出など従来オペレーターが担ってきた作業をAIが代行し、マスター業務の省力化を図る。</p>
<h2>放送マスターの監視・復旧をAIで自動化</h2>
<p>「VMO-AIPlus」は、マスター業務のリモートオペレーションを可能にしたTVhの独自システム「VMO（バーチャルマスターオペレーター）」をベースに、新たに開発したAIで放送の監視や制御を自動化するシステムだ。映像や音声の状態、信号の有無、管理用の画面情報などを常時監視し、無音・フリーズ・黒味・信号断といった異常を自動で検出する。障害が発生した際には、AIが原因と対策を瞬時に判断し、状況をメールで通知するため、オペレーターは監視室に常駐していなくても状況把握と初動対応が可能になる。</p>
<p>障害時の復旧制御をAIに任せる構成も選択でき、その場合はバックアップ系への切り替えなど復旧操作をAIが実行し、対応内容や復旧状況をメールで知らせる。既存の設備の種類やメーカーを問わず、マスターで管理している映像信号や管理画面の情報をそのまま活用できる点も特徴とされている。</p>
<h2>既存マスター設備に追加導入が可能</h2>
<p>同システムは既存のマスター設備に追加する形で導入でき、大規模な設備更新を必要としない。AIによる監視と通知、そしてオプションの自動制御機能により、夜間帯や少人数での運用が求められる時間帯でも効率的にマスター業務を行えるという。</p>
<p>また、日々の異常発生履歴や対応内容を一覧できる画面イメージも公開されており、障害ログの可視化や運用改善に活用できると説明している。</p>
<h2>サブスクリプションで提供、他局展開も視野</h2>
<p>「VMO-AIPlus」はサブスクリプション型で提供され、自動監視とメール通知のみを行う基本パッケージが月額40万円（税別）となる。自動制御などの機能はオプションとして追加提供される。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、非専門のエンジニアがAIの支援でロボット開発の障壁を下げられるかを実験──Claude活用によりタスク数・速度で優位に</title>
      <link>https://ledge.ai/articles/anthropic_project_fetch_robot_dog_ai_comparison</link>
      <description><![CDATA[<p>Anthropicは、自社製AIモデル「Claude」を使う場合と使わない場合で、ロボット犬の開発効率にどのような差が生じるのかを検証する実験「Project Fetch（プロジェクト・フェッチ）」を<a href="https://www.anthropic.com/research/project-fetch-robot-dog">公開</a>した。四足歩行ロボットを用い、非ロボット専門のエンジニアがボール取得タスクに挑む形式で、AI支援の有無による開発速度・タスク達成率・作業体験の違いを測定した。</p>
<h2>AIありチームはタスク数が多く、作業時間はおよそ半分に</h2>
<p>今回の実験にはAnthropicのエンジニアや研究者8名が参加し、4名ずつの2チームに分かれてロボット犬の制御ソフト開発に取り組んだ。一方のチームは「Claude」を自由に利用でき、もう一方はClaudeを使わずに進行した。双方ともロボットのドキュメントや一般的なオンライン情報にはアクセス可能で、唯一の違いは「Claudeの利用可否」とされた。</p>
<p>課題は「ロボット犬にビーチボールを取ってこさせる」もので、ロボットの基本操作、PC接続とセンサー取得、そして自律的なボール検知・回収といった段階的タスクで構成される。</p>
<p>Anthropicによると、Claudeを活用したチームは、完了したタスクの数が多かったうえ、多くのタスクで同一タスクの完了速度がClaudeなしチームのおよそ半分になったという。</p>
<p><strong>図：各フェーズ・タスクにおける所要時間の比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/0801f4a4aa2931c87e5e7ddaef90f5d4653f5ba6_4584x2580_ce0e9d96b5/0801f4a4aa2931c87e5e7ddaef90f5d4653f5ba6_4584x2580_ce0e9d96b5.jpg" alt="0801f4a4aa2931c87e5e7ddaef90f5d4653f5ba6-4584x2580.jpg" /></p>
<p>特に、ロボットをPCへ接続する手順や、センサー情報の取得方法を見極める工程で差が大きく、Claudeを使うことで誤情報に惑わされにくく、最適な手順を素早く選択できたとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=NGOAUJtdk-4">YouTube</a></p>
<h2>ドキュメント読解・環境構築で差異、開発体験にも違い</h2>
<p>実験では、チームの発話や作業ログも分析された。Claudeなしチームでは、設定や接続方法の手探りによる混乱、行き詰まりを示す発言が多く見られたという。一方、Claudeを使用したチームでは、APIの読み解きやコードの改善点をAIに逐次確認しながら作業を進められたため、開発の見通しが立てやすかったと報告されている。</p>
<p>コード生成量に関しては、Claudeチームが大きく上回った。試行パターンが増える一方で、無駄なアプローチも含まれていたものの、短時間で有効な手法を探索できたという。</p>
<h2>実験は限定的規模、物理世界のタスクでのAI活用を探る初期段階</h2>
<p>Anthropicは今回の実験について、「非専門のエンジニアがAIの支援を受けることで、ロボット開発の障壁を下げられる可能性を示す初期的な検証」と位置づけている。参加人数・タスク内容は限定的であり、より大規模な開発への一般化には慎重姿勢を示している。</p>
<p>同社は今後、ロボット制御やハードウェア操作におけるAIの役割、また物理世界に接続されたシステムの安全性確保に関する研究を継続する方針だとしている。</p>
]]></description>
      <pubDate>Wed, 19 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>PKSHA、AIでプロ人材を即時提案──サーキュレーションと企業向けマッチングプロダクト「PRONAVI now」運用開始</title>
      <link>https://ledge.ai/articles/pksha_pronavi_now_start</link>
      <description><![CDATA[<p>PKSHA Technology（パークシャテクノロジー）とグループ会社のサーキュレーションは2025年11月14日、企業向けのプロ人材マッチングを支援するAIプロダクト「PRONAVI now（プロナビ ナウ）」の運用を開始したと<a href="https://www.pkshatech.com/news/20251114/">発表</a>した。</p>
<p>サーキュレーションが蓄積してきた22,000件以上の案件データとプロ人材の経歴情報を、PKSHAのAIアルゴリズムで解析し、マッチングの精度とスピード向上を図る。</p>
<h2>商談中に最適人材を即時提案</h2>
<p>従来の人材マッチングは、担当コンサルタントの経験値に依存し、企業との初回打ち合わせ後に候補者を検討・提示するケースが一般的だった。「PRONAVI now」では、サーキュレーションが保有する体系的なプロ人材データと案件データをAIが解析し、その場でマッチ度や候補人材を即時表示。企業側は、必要なスキル・経験を持つ人材像をその場で確認でき、意思決定までのリードタイム短縮が期待される。</p>
<p>PKSHAは、採用・配置・スキル可視化などを支援する「PKSHA AI Suite for HR」で得たマッチングノウハウを活用。プロシェアリング領域のデータを扱うサーキュレーションと連携することで、企業の課題解決に必要な人材要件を高精度に抽出する仕組みを整えた。</p>
<h2>プロシェアリング需要の拡大</h2>
<p>両社は2024年6月に資本業務提携を締結し、2025年8月にサーキュレーションがPKSHAグループへ正式参画していた。サーキュレーションは31,000名以上のプロ人材と22,000件超のプロジェクトデータを有しており、こうしたアセットにPKSHAのAI技術を組み合わせるかたちで「PRONAVI now」を共同開発した。</p>
<p>労働人口の減少や働き方の多様化が進むなか、特定領域に深い知見を持つプロ人材が複数企業で経験を生かす「プロシェアリング」は裾野を広げている。一方、ニーズの高度化とスピード感の高まりにより、的確なマッチングの難易度は増していた。</p>
<p>PKSHAとサーキュレーションは、こうした環境変化に対応するかたちで「PRONAVI now」を共同開発。企業の課題とプロ人材のスキルの最適化を図るマッチングプロセスを、AIによって進化させる狙いがある。</p>
<h2>新しいプロ人材像「AI Powered Worker」</h2>
<p>両社は今回の取り組みにあわせて、AI活用を前提とした新しいプロフェッショナル像「AI Powered Worker」という方向性も示した。AIによるナレッジ提供や課題整理の支援を受けることで、プロ人材がこれまで以上に高い成果を発揮できる状態を目指すモデルだ。今後は、プロ人材のAIリスキリング支援や、AIを活用したプロジェクト提案の高度化にも取り組むとしている。</p>
<h2>今後の展望</h2>
<p>「PRONAVI now」は、マッチング精度向上や機能追加を継続的に行う方針だ。企業側のニーズ変化に合わせたデータ構造の改善や、プロ人材側のスキルアップ支援を強化し、マッチングの質とスピードの両立を図る。</p>
<p>PKSHAは「未来のソフトウエアを形にする」、サーキュレーションは「世界中の経験・知見が循環する社会の創造」を掲げており、今回のプロダクトは両社のビジョンを結ぶものとなる。AI Powered Workerと企業が出会うためのプラットフォームとして、企業の高度な課題解決と、プロ人材の活躍機会の拡大の両面から、さらなる機能発展を進める見通しだ。</p>
]]></description>
      <pubDate>Tue, 18 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google DeepMind、「SIMA 2」研究プレビュー公開──Gemini搭載で推論・一般化・自己改善が進化、生成3D世界にも対応</title>
      <link>https://ledge.ai/articles/google_deepmind_sima_2_research_preview</link>
      <description><![CDATA[<p>米Google DeepMindは2025年11月13日（現地時間）、次世代汎用AIエージェント「SIMA 2：An Agent that Plays, Reasons, and Learns With You in Virtual 3D Worlds」の研究プレビューを<a href="https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/">公開</a>した。</p>
<p>2024年に発表されたSIMA1を基盤に、同社の大規模マルチモーダルモデル「Gemini」を中核へ統合することで、指示に従うだけのエージェントから、推論し、対話し、環境に適応し、自己改善する汎用エージェントへと大きく進化した。</p>
<p>DeepMindは本モデルを「Artificial General Intelligence（AGI）に向けた重要なステップ」と位置づけ、限定的な研究プレビューとして学術機関やゲーム開発者に先行提供する。</p>
<p>@<a href="https://www.youtube.com/watch?v=Zphax4f6Rls">YouTube</a></p>
<h2>未学習ゲームでもタスクを遂行：一般化性能が大幅に向上</h2>
<p>Geminiの統合により、SIMA 2の一般化性能は大きく向上した。公式ブログでは、訓練に使用していないゲーム環境での成功例が報告されている。</p>
<ul>
<li>ASKA（Vikingサバイバルゲーム）</li>
<li>MineDojo（Minecraft研究実装）</li>
</ul>
<p>これらの未学習ゲームでも、SIMA 2は長く複雑な指示に基づきタスクを遂行。評価タスクでは、SIMA1との性能差が大きく縮まり、人間プレイヤーに近づく結果が示された。</p>
<p><strong>MineDojoでのタスク比較：</strong> 訓練していないゲーム環境でも、SIMA 2（右）は抽象的指示を解釈し行動に移しタスク達成。一方、SIMA 1（左）はタスク達成に至らなかった。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/comparison_between_sima1_2_on_minedojo_6bec24bce2/comparison_between_sima1_2_on_minedojo_6bec24bce2.jpg" alt="comparison between sima1-2 on minedojo.jpg" /></p>
<p>また、以下のようなマルチモーダル指示にも対応する。</p>
<ul>
<li>スケッチ（ユーザーの手描き図）</li>
<li>多言語指示</li>
<li>絵文字のみの指示→ それぞれを正しく解釈し、行動に移すことが可能。</li>
</ul>
<p>さらに、ゲームAで学んだ“mining（採掘）”の概念を、ゲームBでの“harvesting（収穫）”に応用するなど、概念レベルでの転移学習も確認された。</p>
<h2>完全に新しい“生成された3D世界”でも行動可能：Genie 3との連携</h2>
<p>SIMA 2は、DeepMindの世界生成モデル「Genie 3」と組み合わせた実験でも高い適応力を示した。</p>
<p>Genie 3は、1枚の画像やテキストからリアルタイムで3D世界を生成するモデルで、SIMA 2は初めて見る環境にもかかわらず、</p>
<ul>
<li>方角を把握</li>
<li>ゴールに向けた行動</li>
<li>指示の理解とタスク遂行</li>
</ul>
<p>を実現した。</p>
<p>DeepMindはこの試験を「一般化能力の限界を試すもの」として位置づけ、従来の固定されたゲーム環境では確認できない柔軟性が明らかになったとしている。</p>
<h2>自己改善ループ：人間データに依存しない継続学習へ</h2>
<p>SIMA 2の大きな特徴の一つが、新たに導入された自己改善（self-improvement）サイクルだ。</p>
<p>Geminiが生成するタスクと推定報酬をもとにエージェントが試行を行い、その経験データを蓄積。それらのデータは次世代のSIMA 2の訓練に再利用される。</p>
<p><strong>SIMA 2 の自己改善サイクル：</strong> Gemini がタスクと推定報酬を生成し、エージェントの行動経験が「Self-Generated Experience」として蓄積され、次世代モデルの学習に再利用される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unnamed_2_fa5f0652e0/unnamed_2_fa5f0652e0.webp" alt="unnamed (2).webp" /></p>
<h3>自己改善サイクルの流れ</h3>
<ul>
<li>Geminiがタスクと推定報酬を生成</li>
<li>SIMA 2が試行（行動）</li>
<li>経験データを「Self-Generated Experience」として蓄積</li>
<li>次の世代のSIMA 2を再訓練（スキル向上）</li>
</ul>
<p>このループにより、人間のデモなしで未学習ゲームの能力が向上し、Genie 3で生成された新規世界でも“自己のみで上達する”ことが確認された。DeepMindはこれを「オープンエンドな学習へ向けたマイルストーン」としている。</p>
<h2>現時点の課題</h2>
<p>SIMA 2は研究段階であり、DeepMindは以下の課題を明示している。</p>
<ul>
<li>長時間・多段階の推論タスクは依然困難</li>
<li>コンテキスト保持（メモリウィンドウ）が短い</li>
<li>精確なキーボード／マウス操作が難しい</li>
<li>複雑な3Dシーンの視覚理解はまだ不十分</li>
</ul>
<p>これらはロボティクスや実世界の応用に向け、今後解決すべき点として挙げられている。</p>
<h2>ロボティクス・AGIへの展開</h2>
<p>DeepMindは、SIMA 2が取得する以下の能力を、物理世界のロボットに必要な基礎スキルと位置づける。</p>
<ul>
<li>ナビゲーション</li>
<li>道具操作</li>
<li>協働タスクの遂行</li>
</ul>
<p>3D仮想世界はロボット学習の“安全かつ多様な練習場”として使えることから、SIMA 2の進化はロボティクス領域にも直結する。</p>
<h2>責任ある開発と限定公開</h2>
<p>SIMA 2の自己改善能力は強力であるため、DeepMindは開発初期から同社のResponsible Development &amp; Innovation Teamと連携している。</p>
<ul>
<li>公開形態は 「限定研究プレビュー」</li>
<li>対象：少数の学者・ゲームスタジオ</li>
<li>目的：フィードバック収集とリスク理解の深化</li>
</ul>
<p>SIMA 2の技術レポート（SIMA Technical Report）は近日公開予定とされる。</p>
<p>:::box
[関連記事：AIの\\</p>
]]></description>
      <pubDate>Tue, 18 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/11/15 [SAT]「AIはまだフリーランサーになれない」──新指標「Remote Labor Index」が示した自動化率2.5％の現実</title>
      <link>https://ledge.ai/articles/ai_freelancer_automation_rli_25percent</link>
      <description><![CDATA[<p>米Scale AIとCenter for AI Safety（CAIS）は、AIエージェントが実際のフリーランス業務をどこまで自動化できるかを測定する新しい評価指標「Remote Labor Index（RLI）」を公開した。2025年10月30日にarXivへ投稿された<a href="https://arxiv.org/abs/2510.26787v1">研究論文</a>および最新<a href="https://scale.com/leaderboard/rli">リーダーボード</a>によると、最先端のAIエージェントでも「委託可能な品質で完了できた案件」は2.5％にとどまったという。</p>
<p>両機関は2024年、AIの危険行動能力を定量化する「Humanity’s Last Exam」を<a href="https://ledge.ai/articles/ai_humanitys_last_exam">共同発表</a>しており、RLIはその“実務版”として、AI能力を経済価値の観点から評価する試みとなる。</p>
<h2>実務ベースの240プロジェクトで評価</h2>
<p>RLIは、実在のフリーランスプラットフォームから収集した240件のプロジェクトを対象としている。
各案件には以下が含まれる：</p>
<ul>
<li>クライアントによる依頼文（ブリーフ）</li>
<li>実際の人間フリーランサーが作成した納品物</li>
<li>入力ファイル（画像、図面、動画、音声、スクリプトなど）</li>
<li>作業時間・報酬データ</li>
</ul>
<p>アノテーターがAIの成果物を評価し、「現実のクライアントが受け入れられるか」を合否判定する。AI自身による自動採点は使われていない。</p>
<p><strong>RLIのタスク抽出プロセス</strong> ：550件のタスクを300人以上のフリーランサーから収集し、基準適合性のチェックと改善を経て、最終的に240件のプロジェクトを選定した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image_2_dab90e3325/image_2_dab90e3325.png" alt="image (2).png" /></p>
<h2>Automation Rate：最高でも2.5％</h2>
<p>RLI公式リーダーボードの主なスコアは以下の通り。</p>
<ul>
<li>Manus：2.50％</li>
<li>Claude 4.5 Sonnet：2.08％</li>
<li>GPT-5（2025-08-07版）：1.67％</li>
<li>ChatGPT agent：1.25％</li>
<li>Gemini 2.5 pro-preview：0.83％</li>
</ul>
<p>いずれのモデルも、実務案件の約97〜99％を完了できなかった。公式サイトでも、「Absolute Automation is Near Zero（絶対的自動化はほぼゼロに近い）」と明記されている。</p>
<h2>プロジェクト内容：動画、CAD、ゲーム開発など“実務そのもの”</h2>
<p>240件は、従来の研究ベンチマークに比べて大幅に多様なカテゴリで構成されている。</p>
<p><strong>RLIのプロジェクトカテゴリ構成</strong> ：RLIは動画制作、CAD、グラフィックデザイン、ゲーム開発、音声編集など23カテゴリで構成され、多様な実務タスクを含む。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/RLI_Project_Categories_c49b93ec58/RLI_Project_Categories_c49b93ec58.jpg" alt="RLI Project Categories.jpg" /></p>
<ul>
<li>動画制作（13％）</li>
<li>CAD（12％）</li>
<li>グラフィックデザイン（11％）</li>
<li>ゲーム開発（10％）</li>
<li>音声編集（10％）</li>
<li>建築（7％）</li>
<li>プロダクトデザイン（6％）</li>
<li>その他（31％）</li>
</ul>
<p>さらに、プロジェクトの平均制作時間は28.9時間（中央値11.5時間）、報酬中央値は200ドルと、実務レベルの負荷を持つ。</p>
<p><strong>RLIのプロジェクト負荷とカテゴリ比較</strong> ：人間の平均作業時間は28.9時間（中央値11.5時間）と高く、プロジェクト種別も一般のフリーランス市場（Upwork）と同等の分布を持つ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Core_Metrics_cf85d22247/Core_Metrics_cf85d22247.jpg" alt="Core Metrics.jpg" /></p>
<p><strong>RLIで評価されたプロジェクト例</strong> ：データ可視化、3Dプロダクトレンダリング、動画制作、建築設計、ゲーム開発、科学文書作成など、多様な実務タスクが含まれている。</p>
<h2>主な失敗モード：品質不足・不完全・整合性欠如</h2>
<p>論文とリーダーボードの分析では、AIがプロジェクトを完了できない理由として以下が挙げられている。</p>
<ul>
<li>品質不足（45.6％）：専門水準に達していない</li>
<li>不完全な納品物（35.7％）：動画が途中で終わる、3Dモデルが欠損</li>
<li>ファイル破損・形式不備（17.6％）</li>
<li>整合性欠如（14.8％）：複数ファイル間で仕様が一致しない</li>
</ul>
<p>具体例には、以下のようなケースがある：</p>
<ul>
<li>8分動画を求められた案件で、AIは8秒動画しか作れない</li>
<li>3Dレンダリングの視点ごとに造形が変わる</li>
<li>図面の寸法が実寸と合わない</li>
<li>Webゲームが起動はするがグラフィックが破綻している</li>
</ul>
<h2>成功するタスクの傾向</h2>
<p>数少ない成功例は、以下のような“閉じた生成タスク”に集中していた。</p>
<ul>
<li>ロゴ・バナー制作（画像生成）</li>
<li>ボイス合成や簡易オーディオ編集</li>
<li>表形式データの可視化</li>
<li>簡易レポート作成</li>
</ul>
<p>一方、多工程・長尺のタスク、複数ファイルの整合性が必要なタスクではほぼ全滅しているという。</p>
<h2>今後の展開</h2>
<p>論文の著者らは、RLIの結果について「AIシステムが現実のフリーランス環境において委託業務として許容可能な水準でプロジェクトを完了できることは、ほとんどない」と記している。また、現在のモデル性能について「能力の下限に近い」と評価し、タスクの大半で“実務的完成度に到達しない”点を指摘した。</p>
<p>研究チームはさらに、RLIが生成AIの進歩を今後継続的に追跡するための基盤になると位置づけており、「Absolute Automation is Near Zero（絶対的自動化はほぼゼロに近い）」というリーダーボード上の表現とともに、現時点でのAIエージェントの限界を明確に示した。</p>
]]></description>
      <pubDate>Sat, 15 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/12 [WED]Wikipedia、AI企業に「知の還元」を要請──無断スクレイピングから有料API「Wikimedia Enterprise」へ、持続可能な共創を目指す</title>
      <link>https://ledge.ai/articles/wikipedia_ai_scraping_stop_enterprise_api</link>
      <description><![CDATA[<p>「Wikipedia」を運営する非営利団体ウィキメディア財団（Wikimedia Foundation）は、米国時間2025年11月10日、AI企業に対し、AIモデルのトレーニングを目的としたデータ収集（スクレイピング）を停止し、同財団が提供する有料API「Wikimedia Enterprise」を利用するよう求める声明を<a href="https://wikimediafoundation.org/news/2025/11/10/in-the-ai-era-wikipedia-has-never-been-more-valuable/">発表</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wikimedia_261c218f50/wikimedia_261c218f50.jpg" alt="wikimedia.jpg" /></p>
<p>声明は「AI時代において、ウィキペディアはこれまでになく価値がある」とし、持続可能な知識共有の観点から帰属（アトリビューション）と財政的支援の必要性を明確に示した。出典の明示やデータ更新の正確性、ライセンス遵守をAPI経由で担保できると説明している。</p>
<p>財団によれば、生成AIの普及によりAI企業による無断スクレイピングとボットアクセスが増加し、サーバー負荷や読者体験への影響が懸念される。一方で、人間によるページビューは2025年上半期に前年比約8％減となったとし、基盤を支える寄付・ボランティア編集への波及を指摘した。</p>
<p>財団は、AIは人間が記録・検証した知識（例：Wikipedia）に依存していると改めて説明。生成AIは既存知の要約・統合はできても、Wikipediaのボランティア編集者が日々行う議論・検証・合意形成、アーカイブからの発掘、現場写真の提供といった活動を代替できないとした。Wikipediaは300以上の言語版で、しばしばネイティブ執筆者による多言語コーパスを形成しており、包摂的で文化的背景に配慮したAIモデルの発展にも資する、としている。</p>
<p>透明性も強調された。Wikipediaでは全員が同一の情報を閲覧でき、パーソナライズ配信や行動追跡による出し分けは行われない。記事には出典が付与され、編集履歴や運用プロセスは公開されている。誰でも方針・ガイドラインに従って加筆できる点が「信頼」の源泉であるとし、対照的に生成AIはハルシネーション（もっともらしい誤情報の提示）を起こし得ると説明した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wikimedia_enterprise_api_20e0f88941/wikimedia_enterprise_api_20e0f88941.jpg" alt="wikimedia enterprise api.jpg" /></p>
<p>同財団は、Wikipedia自体も人を支える形でAIを活用していると述べる。ボランティアの時間を奪う荒らし検知など単純作業の効率化を狙い、今年公表した編集者向けAI戦略では、人間の知識創造を補助し置き換えない方針を示した。AIツールの利用指針はコミュニティが策定・施行し、責任ある活用を徹底する。</p>
<p>総括として財団は、AIはWikipedia抜きでは成立しないとし、AI開発者や再利用者に対し次の2点を要請した。</p>
<ul>
<li>アトリビューション（出典表示）：人間の貢献にクレジットを付し、元情報源への導線を明確にする。</li>
<li>財政的支援：大規模利用はWikimedia Enterpriseを通じて行い、サーバー負荷を抑えつつ非営利ミッションを継続可能にする。</li>
</ul>
<p>同財団は、Wikipediaが検証可能性・中立性・透明性の標準でインターネット上の情報を支えているとし、「AIがあふれる世界で、人間の知識の価値はかつてなく高い」と述べた。なお、Wikipediaは2026年1月15日に25周年を迎える予定で、今後も無料で正確な人間の知識を提供し続けるとした。</p>
]]></description>
      <pubDate>Wed, 12 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>