<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>中国スタートアップMoonshot AI、1兆パラメータの新LLM「Kimi K2」をオープンソースで公開──長文推論とコード生成でGPT-4系に迫る性能</title>
      <link>https://ledge.ai/articles/kimi_k2_release_moonshot_ai</link>
      <description><![CDATA[<p>北京に拠点を置くスタートアップ企業Moonshot AIは2025年7月12日、新たな大規模言語モデル「Kimi K2」をオープンソースで<a href="https:%5Cu002F%5Cu002Fmoonshotai.github.io%5Cu002FKimi-K2%5Cu002F">公開</a>{target=“_blank”}した。</p>
<p>同モデルは、総パラメータ1兆、アクティブパラメータ320億のMixture-of-Experts（MoE）構造を採用し、コード生成や長文推論、外部ツールとの統合といった用途に特化している。Apache 2.0互換のライセンスでGitHubおよびHugging Faceを通じて配布されており、商用利用も可能となっている。同社はこの公開を通じて、急速に成長する中国国内のオープンソースLLM競争での巻き返しを狙う。</p>
<h2>1兆パラメータのMixture-of-Experts構造を採用</h2>
<p>Kimi K2は32の専門家レイヤー（experts）から成り、推論時にはそのうち2つのみを活性化することで、GPUリソースの消費を抑えつつ高性能を実現している。モデルの学習には同社が開発した最適化アルゴリズム「Muon Optimizer」が使用されており、推論にはNVIDIA A100（40GB）相当のGPU1枚で対応可能とされている。</p>
<p>また、日本語や英語を含む多言語に対応し、最大20万トークンの長文入力が可能であるなど、ドキュメント要約や長文分析といった用途にも適しているという。同社は Kimi K2を「エージェント的知能（Agentic Intelligence）」の土台として位置付けており、複雑なタスクの分解やツール操作といった処理能力に重点を置いている。</p>
<h2>コード生成と数学推論でGPT-4.1を上回るベンチマーク結果</h2>
<p><a href="https:%5Cu002F%5Cu002Fhuggingface.co%5Cu002Fmoonshotai%5Cu002FKimi-K2-Base">Hugging Faceのモデルカード</a>{target=“_blank”}にて同社が公開したベンチマーク結果によれば、Kimi K2は以下の項目でGPT-4.1（2025年5月時点のプレビュー版）を上回るか、同等の性能を示したという。</p>
<ul>
<li>LiveCodeBench v6（Pass@1）：53.7%（GPT-4.1は44.7%、DeepSeek-V3は46.9%）</li>
<li>SWE-bench Verified（単一試行・Agentic Coding）：65.8%（GPT-4.1は54.6%）</li>
<li>MATH-500 Accuracy：97.4%（GPT-4.1は92.4%）</li>
<li>MMLU（Exact Match）：89.5%（GPT-4.1は90.4%と同等水準）</li>
</ul>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fcollage_kimi2_bench_d13b3abdd9%5Cu002Fcollage_kimi2_bench_d13b3abdd9.jpg" alt="collage kimi2 bench.jpg" /></p>
<p>これらのスコアは、特にコーディングと数理分野での推論能力において、Kimi K2が最先端のLLMと競合しうることを示すものとされる。ただし、一般的な自然言語処理性能や創造的文章生成といった領域に関する評価はまだ限定的である。</p>
<h2>オープンソース戦略と今後の展開</h2>
<p>Kimi K2は、Apache 2.0互換ライセンスで商用利用が認められており、GitHubとHugging Face上でモデル重みと推論スクリプトが公開されている。さらに今後、4bitおよび8bitの量子化版、LoRAによるファインチューニングレシピ、学習済みエージェント機構の導入例などの公開も予定されている。</p>
<p>2024年後半からユーザー数が減少傾向にあった対話アプリ「Kimi」の再成長を後押しする狙いもあり、同社は、Kimi K2の性能を活かしたエンタープライズ向けAPIの提供を2025年第4四半期に計画しているとしている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「一度公開すれば取り戻せない」──OpenAI、オープンウェイトモデルのリリースを無期限延期</title>
      <link>https://ledge.ai/articles/openai_open_weight_model_launch_delayed</link>
      <description><![CDATA[<p>OpenAIのCEOであるサム・アルトマン氏は2025年7月12日、自身のX（旧Twitter）アカウントを通じて、翌週に予定していた新たな大型言語モデル（LLM）のリリースを延期すると<a href="https:%5Cu002F%5Cu002Fx.com%5Cu002Fsama%5Cu002Fstatus%5Cu002F1943837550369812814">発表</a>{target=“_blank”}した。</p>
<p>対象となるのは、モデルの重み（weights）を一般に公開する「オープンウェイトモデル」であり、安全性に関する追加テストと高リスク領域の精査が必要となったためとしている。新たな公開日程は現時点で明らかにされていない。</p>
<p>アルトマン氏は投稿の中で「一度公開すれば取り戻せない。これは我々にとって新しいことであり、正しく対処したい」と述べ、重みの公開が持つ不可逆性に対する慎重な姿勢を示した。さらに、「悪いニュースを伝えることになってしまい申し訳ない。我々は非常に懸命に取り組んでいる」として、延期は開発チームの責任ある判断であることを強調した。</p>
<p>この「オープンウェイトモデル」は、OpenAIにとって初めての、重みを含めて一般公開するLLMとなる見込みだった。従来のGPT-3.5やGPT-4は、API経由での提供に限定されており、モデルの内部構造やパラメータは非公開だった。一方で今回のモデルは、利用者がローカル環境での実行やカスタマイズを可能にする“オープンアクセス”型であり、企業や研究者の関心を集めていた。</p>
<p>背景には、安全性への懸念がある。重みが公開されれば、第三者によるモデルの再利用や改変が可能になるため、不正利用や誤情報の生成といったリスクが生じる。特に、ハルシネーション（事実に基づかない出力）や有害な出力への対策が不十分なまま公開すれば、被害が広範囲に及ぶおそれがある。アルトマン氏も「追加の安全テストと、高リスク領域の見直しが必要だ」と投稿の中で明記しており、慎重な検証が行われる見通しである。</p>
<p>同モデルは当初、2025年6月中の<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Fopenai_open_weight_model_2025">リリースが計画されていた</a>
が、7月第2週に延期されたのち、今回の発表で無期限延期となった。今後の対応方針や公開時期に関しては、OpenAIからの追加の発表が待たれる状況である。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002F2_Zs_Mux_Y_50f7cb832c%5Cu002F2_Zs_Mux_Y_50f7cb832c.jpg" alt="2Zs-MuxY.jpg" /></p>
<p>近年、Metaの「Llama 2」や「Llama 3」、Mistralの「Mixtral」など、オープンウェイトモデルは業界内で広がりを見せている。こうしたモデルは、企業が独自のAIアプリケーションを開発する上で基盤として活用されており、今後OpenAIが同分野にどう参入していくかが注目されている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>経産省・NEDOの生成AI開発支援プロジェクト「GENIAC」第3期、楽天と野村総研を含む新規13件を採択──生成AI国産化を加速</title>
      <link>https://ledge.ai/articles/geniac_third_round_rakuten_nri_selected</link>
      <description><![CDATA[<p>2025年7月15日、経済産業省と新エネルギー・産業技術総合開発機構（NEDO）は、生成AI開発支援プロジェクト「GENIAC（Generative AI Accelerator Challenge）」の第3期採択結果を<a href="https:%5Cu002F%5Cu002Fwww.nedo.go.jp%5Cu002Fkoubo%5Cu002FCD3_100397.html">発表</a>{target=“_blank”}した。今回の公募には43件が応募し、最終的に24件が採択された。楽天グループと野村総合研究所（NRI）を含む13件が新規採択で、第1期・第2期に採択されていなかった新顔の参画が加速している。</p>
<h2>楽天、日本語LLMに長期記憶と対話学習を融合</h2>
<p>楽天グループは今回の第3期で初採択された。申請テーマは「長期記憶メカニズムと対話型学習を融合した日本語LLMの研究開発」で、同社が進めるAIエージェント構想の一環とみられる。</p>
<p>2024年末に発表された「Rakuten AI 2.0」では、社内外のデータを活用した多目的LLMの構築と、オープンソース化の方針が示されていた。GENIACの支援を受けることで、大規模演算環境のもと、学習済みパラメータの拡張や長期記憶モジュールの実装が本格化する可能性がある。</p>
<h2>野村総研、業界特化の40B規模モデルを計画</h2>
<p>野村総合研究所（NRI）も第3期で初採択された。採択テーマは「10B〜40B規模の業界・タスク特化型LLMの研究開発」。具体的な適用分野は公表されていないが、金融・行政・製造などNRIが業務支援を行う産業領域での応用が想定される。</p>
<p>NRIのような大手コンサルティング・IT企業が生成AIの基盤モデル開発に乗り出すのは、GENIACプロジェクト初となる。従来のSaaS活用や外部API連携を越えて、独自モデル構築へと進む転換点と位置づけられる。</p>
<h2>新規採択は13件、分野特化型スタートアップが多数</h2>
<p>楽天とNRI以外にも、第3期では11の新規プレイヤーが採択された。採択テーマからは、以下のような分野特化型の研究が目立つ。</p>
<ul>
<li><strong>Airion</strong> ：PLCラダープログラムを自動生成するLLM</li>
<li><strong>Arivexis</strong> ：低分子化合物の生物活性を予測する創薬モデル</li>
<li><strong>Degas</strong> ：リモートセンシング向け視覚言語モデル</li>
<li><strong>Direava</strong> ：外科手術支援用の視覚・言語統合AI</li>
<li><strong>NexaScience</strong> ：研究開発プロセスを自律化するエージェント</li>
<li><strong>Nishika</strong> ：出力形式を厳密に制御できる要約特化LLM</li>
<li><strong>ONESTRUCTURE</strong>：建築BIMデータを生成するモデル</li>
<li><strong>Precision</strong> ：医療文書理解向け専門LLM</li>
<li><strong>Sansan</strong> ：企業文書を対象にした視覚言語モデル</li>
<li><strong>SDio</strong> ：長尺映像を扱う国産大規模映像モデル</li>
<li><strong>Zen Intelligence</strong> ：建設現場施工管理を自動化するモデル</li>
</ul>
<p>これらの企業の多くは医療・建築・産業用途など、明確な業務ユースケースを持つ。GENIAC支援によって、計算資源を活用したモデルのスケーリングが可能になると見られる。</p>
<h2>継続採択は11件、ABEJA・Preferredなど第1期組も含む</h2>
<p>第1期・第2期からの継続採択組は11件。業界内で技術実装が進む企業が引き続き支援対象となった。以下は継続企業の一部。</p>
<ul>
<li>ABEJA</li>
<li>AI inside</li>
<li>AIdeaLab</li>
<li>Karakuri（カラクリ）</li>
<li>Kotoba Technologies Japan</li>
<li>NABLAS</li>
<li>Preferred Networks</li>
<li>Ricoh</li>
<li>Stockmark</li>
<li>SyntheticGestalt</li>
<li>Turing</li>
</ul>
<p>すでにGENIACの支援を受けた開発実績を有しており、第3期ではモデルの高度化や新機能の追加が焦点となる。</p>
<h2>GENIACの支援規模と今後のスケジュール</h2>
<p>GENIACは、経産省とNEDOが連携して進める国産生成AI開発支援プログラムで、2023年度から実施されている。今回の第3期採択により、累計支援件数は54件に拡大した。
対象期間：交付決定日〜2026年2月末まで
支援内容：GPUクラウド等の演算資源提供、外部評価機関による技術検証
今後の予定：NEDOによる中間評価、年度末までに開発成果の提出と発表が予定されている</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google Cloud、米西海底ケーブル「Sol」でフロリダ―スペインを直結──AI時代に備え大西洋ルートを刷新</title>
      <link>https://ledge.ai/articles/google_sol_transatlantic_cable_2025</link>
      <description><![CDATA[<p>Google Cloudは2025年7月10日、フロリダ州パームコーストとスペイン・サンタンデールを結ぶ新たな大西洋横断海底ケーブル「Sol（ソル）」の敷設計画を<a href="https:%5Cu002F%5Cu002Fcloud.google.com%5Cu002Fblog%5Cu002Fproducts%5Cu002Finfrastructure%5Cu002Fannouncing-sol-transatlantic-cable?hl=en">発表</a>{target=“_blank”}した。AI需要の高まりに伴うクラウドトラフィックの急増に対応するため、Google独自のネットワークインフラをさらに強化するもので、経由地としてバミューダ諸島およびアゾレス諸島も含まれる。</p>
<p>同社は、既存の「Nuvem」や「Grace Hopper」との多重化により、北米―欧州間の通信において高いレジリエンシー（耐障害性）と低遅延を同時に実現する狙いだ。</p>
<h2>Googleが敷設する18本目の海底ケーブル</h2>
<p>Sol は、Googleにとって18本目となる自社単独または共同敷設の海底ケーブルで、光ファイバーによる総延長は約6,300kmに及ぶ見込みだ。スペイン語やポルトガル語で「太陽」を意味する「Sol」という名称は、温暖な気候にケーブルシステムの着床地点があることに由来するという。プロジェクトの建設は2025年後半に開始され、数年以内の運用開始を目指す。</p>
<h2>北米―欧州を結ぶ新ルート、フロリダからの初直結</h2>
<p>同プロジェクトの特徴は、米国東海岸の中でもフロリダ州を起点とする点にある。これまでGoogleの大西洋横断ケーブルは、主にニューヨークなど北部沿岸を起点としていたが、Sol は同社初の “フロリダ―欧州” 直結ケーブルとなる。フロリダ州パームコーストに陸揚げ局を設け、スペイン・カンタブリア州サンタンデールに到達。経由地としてアゾレス諸島およびバミューダ諸島にも接続することで、既存のNuvemケーブルとのネットワーク補完性を高める設計となっている。</p>
<p><strong>Nuvem海底ケーブルルート</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FThe_Nuvem_subsea_cable_route_02f8293dda%5Cu002FThe_Nuvem_subsea_cable_route_02f8293dda.jpg" alt="The Nuvem subsea cable route.jpg" /></p>
<h2>Nuvem、Grace Hopperとの冗長化構成を構築</h2>
<p>Googleは2023年に発表した南ルートの「Nuvem」および、北ルートの「Grace Hopper」（ニューヨーク―ビルバオ）と連携させることで、3系統のルートによるネットワークの多重冗長化を図る。特に「Sol」と「Nuvem」は、陸揚げ地点を一部共有し、障害発生時には瞬時に通信を切り替えられる構成とすることで、トラフィックの安定供給を実現する。また、経由地であるアゾレス・バミューダ間の接続によって、同社ネットワークの欧州・アフリカ・中南米への接続性も強化される。</p>
<h2>地域インフラへの波及効果</h2>
<p>陸揚げ地点であるスペイン・サンタンデールでは、Telefónica系インフラ企業Telxiusが地元の陸揚げ局を運営する予定で、北スペイン地域のデジタル化推進や経済活性化が期待されている。一方、パームコーストではGoogleが新たな接続拠点（Point of Presence：PoP）を設置し、フロリダ州内外のデータセンター群への高速接続網を形成する計画だ。</p>
<h2>AI時代のトラフィック増加に備えたネットワーク投資</h2>
<p>ChatGPTをはじめとする生成AIの普及や、企業によるクラウドサービスの依存度の高まりにより、グローバルインターネットトラフィックは急増を続けている。Google Cloudでは、42のクラウドリージョンを運用し、各地のAIワークロードやデータベース、ストレージ需要に応える形で、海底ケーブル網の整備を推進している。特に、データ処理のボトルネックとされる「帯域確保」と「低遅延ルート」の確保は、AIサービスの安定運用に直結する課題となっている。</p>
<h2>今後のスケジュールと展望</h2>
<p>「Sol」の建設開始は2025年後半とされており、Googleは「数年以内の運用開始」を予定している。完成後は、Google Cloudの欧州・南米間の接続性にも波及効果が期待されており、生成AIやクラウドインフラに対する今後の需要拡大に向けた長期的インフラ投資の一環と位置づけられている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AWS、仕様駆動型AI IDE「Kiro」を正式発表──“プロンプトから本番まで”エージェントが伴走</title>
      <link>https://ledge.ai/articles/aws_ai_ide_kiro_release</link>
      <description><![CDATA[<p>Amazon Web Services（AWS）は2025年7月14日、AIエージェントを中核に据えた新しい統合開発環境（IDE）「Kiro（キロ）」を<a href="https:%5Cu002F%5Cu002Faws.amazon.com%5Cu002Fjp%5Cu002Fblogs%5Cu002Fnews%5Cu002Fintroducing-kiro%5Cu002F">発表</a>{target=“_blank”}した。</p>
<p>Kiroは、開発初期の曖昧なアイデアを、プロンプト1つで本番環境レベルのコードへと変換することを狙ったツールだ。プロダクト開発における「仕様と実装の乖離」問題に対処するため、仕様駆動型の設計支援機能を搭載しているという。現在パブリックプレビュー中で、<a href="https:%5Cu002F%5Cu002Fkiro.dev">公式サイト</a>{target=“_blank”}から無料でダウンロード可能となっている。</p>
<h2>AIエージェントを前提とした“Agentic IDE”</h2>
<p>Kiroは「Agentic IDE（エージェント的なIDE）」を掲げ、AIが設計からコーディング、テスト、ドキュメント生成に至る開発プロセス全体を支援する。OSS版Visual Studio Code（Code OSS）をベースとしており、既存のVS Code拡張機能やOpen VSXレジストリの資産をそのまま活用できる。</p>
<p>デスクトップアプリとして提供され、Mac・Windows・Linuxに対応している。ユーザーはGitHubやGoogleアカウントなどを用いたSSO（シングルサインオン）でログイン可能だ。</p>
<p><strong>AWSが取り組んでいるeコマースアプリの例</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fcompressed_1_app_72308f4e1e%5Cu002Fcompressed_1_app_72308f4e1e.gif" alt="compressed_1-app.gif" /></p>
<p>Kiroの中心的な機能は、自然言語による単一プロンプトを出発点として、要件定義（Requirements）、設計ドキュメント（Design）、およびタスクリスト（Task List）を自動的に生成する「Spec-Driven Development（仕様駆動開発）」にある。</p>
<p>これにより、開発者は「こんなアプリを作りたい」という抽象的な構想を与えるだけで、仕様に基づいたタスクが提示され、コード実装を進めやすくなるという。</p>
<p><strong>Kiroの要件仕様</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fcompressed_2_reqs_f094da7ae6%5Cu002Fcompressed_2_reqs_f094da7ae6.gif" alt="compressed_2-reqs.gif" /></p>
<h2>仕様とコードの断絶を埋めるEARS記法と「Hook」</h2>
<p>Kiroは仕様記述にEARS（Easy Approach to Requirements Syntax）という形式を採用しており、要件の明確化とエッジケースの網羅性を重視している。これにより、曖昧な記述による実装ミスや意図の取り違えを最小限に抑える狙いがある。</p>
<p>さらに、Kiroは「Hook」と呼ばれるイベント駆動型の自動処理機能を搭載しており、ファイルの保存、生成、削除、Gitへのコミットなどのタイミングで、以下のような処理が自動的に実行される：</p>
<ul>
<li>ユニットテストの自動更新</li>
<li>コードドキュメントの生成</li>
<li>認証情報やシークレットの漏洩チェック</li>
</ul>
<p>これにより、開発者は品質管理やセキュリティの担保をエージェントに任せ、コアな開発作業に集中できるようになる。</p>
<h2>外部モデル接続と拡張性</h2>
<p>KiroはModel Context Protocol（MCP）にも対応しており、AWSが提供する大規模言語モデル（LLM）だけでなく、Anthropic Claudeやその他の外部LLM、外部APIツールとも連携できる。これにより、プロジェクトに応じて最適なAIエージェント群を構成する柔軟性を備えている。</p>
<p>また、MCPの採用により、複数のAIエージェントをプロジェクト横断で統制し、コード生成のコンテキストを維持したままやり取りができる設計になっている。</p>
<p>Kiroは現時点ではパブリックプレビューとして無料提供されており、年内には有償プラン（月額19.99ドル）を導入予定だという。正式版ではLLMへの問い合わせ回数に応じた制限や追加機能の提供が計画されているとのこと。</p>
<p>開発支援に特化したAIアシスタントとしては、AWSはすでに「Amazon Q Developer」を提供しているが、Kiroはこれとは異なり、プロジェクト全体を見渡しながら構造化された開発支援を行う点で明確に差別化されている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 08:50:00 GMT</pubDate>
    </item>
    <item>
      <title>荷物運搬を完全自動化　川崎重工のロボットポーター「FORRO」、三田ガーデンヒルズで国内最長6.6 kmルートを稼働開始</title>
      <link>https://ledge.ai/articles/robot_porter_forro_mita_kawasaki</link>
      <description><![CDATA[<p>川崎重工業は2025年7月7日、三井不動産レジデンシャルおよび三菱地所レジデンスが東京都港区にて共同開発した分譲マンション「三田ガーデンヒルズ」において、屋内配送用サービスロボット「FORRO（フォーロ）」を活用したロボットポーターサービス「FORRO PORTER」の本格稼働を開始したと<a href="https:%5Cu002F%5Cu002Fforro-service.com%5Cu002Fnews%5Cu002F7BL7Bn9i7QBpNT2VbkcTiT%5Cu002F">発表</a>{target=“_blank”}した。ロボットがマンション内で荷物を居住者の住戸前まで自動搬送するサービスで、延べ約6.6 kmに及ぶ館内ルートを4台のロボットが自律走行するという国内最大規模の導入例である。</p>
<p>@<a href="https:%5Cu002F%5Cu002Fwww.youtube.com%5Cu002Fwatch?v=tY46sRuFeSY">YouTube</a></p>
<h2>住戸前まで荷物を届けるロボットポーター</h2>
<p>FORRO PORTERは、マンションのエントランスに設置された専用ロッカーから、居住者の荷物を各住戸前まで搬送するロボットサービス。利用者はスマートフォンアプリや美和ロックの「ラクセスキー」から搬送を依頼でき、ロボットは館内のエレベーターやオートドアと連携しながら無人で目的地まで走行する。最大30kgまでの荷物を運べるほか、跳ね上げ式荷棚を採用しキャリーケースなどの積載にも対応しているという。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fkawasaki_forro_mitsuigarden2_7e5b093c9a%5Cu002Fkawasaki_forro_mitsuigarden2_7e5b093c9a.jpg" alt="kawasaki forro mitsuigarden2.jpg" /></p>
<h2>館内ルートは国内最長の6.6km、4台体制で稼働</h2>
<p>同サービスでは、ロボット4台が常時稼働し、館内の総延長約6.6kmにおよぶ移動ルートを活用して配送を行う。エントランスから住戸前までの全工程を無人で完結でき、これは日本国内で稼働する住居向けロボットポーターサービスとしては最大規模にあたるという。</p>
<p>各ロボットの動作は、大成建設が開発したロボット統合管制プラットフォーム「RoboHUB（ロボハブ）」を通じて遠隔監視され、セキュリティシステムと連動した高い安全性が確保されている。</p>
<h2>試験運用で高いリピート率、住民サービス向上へ</h2>
<p>FORRO PORTERは、2025年3月から三田ガーデンヒルズで先行して試験運用されており、期間中はポーターサービスの全依頼のうち20％以上がロボットによって担われたという。さらに、リピート利用率は50％を超える実績があり、居住者にとって利便性の高いサービスであることが示された。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fkawasaki_forro_mitsuigarden3_02db361826%5Cu002Fkawasaki_forro_mitsuigarden3_02db361826.jpg" alt="kawasaki forro mitsuigarden3.jpg" /></p>
<h2>病院から住宅へ、川崎重工のロボット展開が拡大</h2>
<p>FORROは、もともと川崎重工が医療施設向けに開発した屋内搬送用ロボットで、これまでに病院での使用実績がある。今回の住宅分野への本格導入により、生活空間における物流の自動化という新たな領域への展開が進められたかたちだ。川崎重工は今後、住宅や商業施設など他分野への展開を視野に入れていると見られる。</p>
<h2>他ロボットとの連携も視野に</h2>
<p>三田ガーデンヒルズでは、将来的に清掃や警備など、他用途のロボットとの連携も計画されており、RoboHUBを中核としたロボット協働環境の構築が進められている。ロボットが日常的にマンションの中で稼働し、人の作業を支える仕組みが現実となりつつある。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 05:50:02 GMT</pubDate>
    </item>
    <item>
      <title>【視聴無料】“プロンプトの先”を知る──生成AI活用の真価を引き出すコンテキストエンジニアリングとは何か？</title>
      <link>https://ledge.ai/articles/webinar_about_context_engineering</link>
      <description><![CDATA[<p>生成AIの普及とともに、多くの現場で注目されたのが「プロンプトエンジニアリング」でした。ChatGPTに対して“うまく指示を出す方法”が話題となり、良い出力を得るための言い回しや構文テクニックが盛んに共有されてきました。</p>
<p>そうした中、2025年6月30日にGoogle DeepMindのシニアAIリレーションエンジニア、フィリップ・シュミット（Philipp Schmid）氏が発表したブログ記事が大きな注目を集めました。</p>
<p>\u003E「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」</p>
<p>大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトでは不十分であり、AIに与える文脈情報の設計が不可欠であるという提言です。</p>
<p>今回のウェビナーでは、新注目のキーワード「コンテキストエンジニアリング」の理解に向けて解説します。</p>
<h2>ウェビナー概要</h2>
<p><strong>\u003Cセッション内容（予定）\u003E</strong></p>
<ul>
<li>プロンプトエンジニアリングの限界</li>
<li>新注目のキーワード「コンテキストエンジニアリング」とは？</li>
<li>コンテキストエンジニアリングを支える技術群</li>
<li>業務活用・導入の最初の一歩はどこから進めるべきか？</li>
</ul>
<p><strong>開催概要</strong>
日時：2025年7月22日（火）11:00〜12:00
形式：Zoom Webinar（事前登録制・参加無料）
主催：株式会社レッジ</p>
<p>:::button
<a href="https:%5Cu002F%5Cu002Fus02web.zoom.us%5Cu002Fwebinar%5Cu002Fregister%5Cu002FWN_v-lGUvYEQjSm5j5_tUSOMg">視聴申込みはこちら</a>{target=“_blank”}
:::</p>
<h2>ウェビナーの学びを“実践”に変えるために──レッジが提供する実践型研修ラインナップ</h2>
<p>ウェビナーで得た知識を、「なるほど」で終わらせず、実際に社内業務への浸透を進めていくために、レッジでは、生成AI活用を実務に落とし込む研修プログラムを各種ご提供しています。
助成金の適用や社内事情に合わせたカスタマイズも可能で、社内への定着と人材育成をセットで支援します。</p>
<h3><strong>生成AI × マーケティング研修（助成金適用で最大75%OFF）</strong></h3>
<ul>
<li>座学と実践演習で構成された3日間、合計15時間の研修パッケージ</li>
<li>マーケ業務（リサーチ→分析→企画→制作）における生成AIの活用術を紹介</li>
<li>人材開発支援助成金制度により、受講費用の最大75%の助成適用</li>
</ul>
<p><strong>\u003C研修タイムテーブル\u003E</strong>
<strong>Day 1：生成AIの基礎知識を獲得</strong></p>
<ul>
<li>オリエンテーション（30分）</li>
<li>生成AIとは何なのか？（90分）</li>
<li>生成AI活用における3つのトレンド（120分）</li>
<li>最新AI技術動向（60分）</li>
</ul>
<p><strong>Day 2：マーケティング業務への活用</strong></p>
<ul>
<li>Day 1の振り返り（30分）</li>
<li>プロンプトエンジニアリング（120分）</li>
<li>コンセプト設計（150分）</li>
</ul>
<p><strong>Day 3：例題演習によるスキル定着</strong></p>
<ul>
<li>新規事業企画演習（240分）</li>
<li>生成AIを活用していく際のポイント（60分）</li>
</ul>
<h3><strong>NOCODE + AI 研修</strong></h3>
<ul>
<li>「業務を自ら改善できる人材」を育成するための、DX時代のリテラシー研修</li>
<li>AIとノーコードツールの基礎から実践までを3日間で習得</li>
<li>DX推進のための基礎知識と実践スキルを、ビジネス部門の方にもわかりやすく解説</li>
<li>全3日間、座学と演習を通じて「つくれる」「活用できる」状態へ</li>
</ul>
<p><strong>\u003C研修で扱う主なテーマ\u003E</strong></p>
<ul>
<li>DX基礎：今さら聞けないデジタル変革の本質と業務視点の捉え方</li>
<li>ビジネスパーソンのためのAI活用術：生成AIでできること／できないことを実務に沿って理解</li>
<li>プロンプトエンジニアリング入門：AIに“正しく伝える”ための基礎技術</li>
<li>kintoneの基礎：ノーコード開発によるデータ管理と業務アプリの構築法</li>
</ul>
<h3><strong>バイブコーディング研修</strong></h3>
<ul>
<li>生成AIと“協働しながら開発する”という新たな開発手法を体験する研修</li>
<li>設計力・構造化思考・AI対話力を強化し、「AIと共に作る力」を育成</li>
<li>半日〜1日構成、非エンジニアの参加も可能</li>
</ul>
<p><strong>\u003C研修内容例\u003E</strong></p>
<ul>
<li>最新AI開発ツールの紹介</li>
<li>開発者の役割変化と未来像</li>
<li>ハンズオン演習（アプリケーション開発実践）</li>
<li>まとめ講義「エンジニアの未来」</li>
</ul>
<h3><strong>カスタマイズ型研修</strong></h3>
<p>生成AIの基礎理解から、RAG・アプリ開発・業務活用まで──
育成対象や業務課題に合わせてフルカスタマイズ可能な研修プログラムもご提供しています。</p>
<ul>
<li>会社の育成方針・レベル感・業務課題に合わせた設計が可能</li>
<li>部門別／階層別研修、社内コンテストや勉強会との連動も支援</li>
<li>グループ会社含む横展開を見据えた実施設計・運用サポートも対応</li>
</ul>
<p><strong>\u003C直近の実施事例\u003E</strong>
<strong>パナソニック株式会社様</strong>
対象：DX企画部
形式：オンライン＋オフライン（全2日程）
構成：
　Day 1：生成AIを含むAIの基礎講義
　Day 2：ノーコードツールを活用したRAGアプリ実装演習
参加者：約50名／回</p>
<p><strong>NECソリューションイノベータ株式会社様</strong>
対象：若手技術者
形式：オフライン（2日間×全4回）
構成：
　Day 1：生成AIを活用した企画手法講義＋アプリ企画ワーク
　Day 2：LLMを活用したアプリ開発ワークショップ
参加者：約30名／回
連動施策：研修後に社内生成AIコンテストを開催</p>
<h2>研修のお問い合わせ・ご相談</h2>
<ul>
<li>研修内容の詳細が知りたい</li>
<li>助成金の対象になるか相談したい</li>
<li>自社向けにアレンジしたい　…など、お気軽にご相談ください！</li>
</ul>
<p>:::button
<a href="https:%5Cu002F%5Cu002Fzfrmz.com%5Cu002FHrd1p1OXCBMiUaT3AiUu">お問い合わせはこちら</a>{target=“_blank”}
:::</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、“再学習ゼロ”の「ポータブルチューニング」公開──業務特化の生成AIモデルの運用コストを劇的削減、tsuzumiにも搭載</title>
      <link>https://ledge.ai/articles/portable_tuning_tsuzumi_no_retraining</link>
      <description><![CDATA[<p>NTTは2025年7月9日、生成AIの特化モデルを再学習せずに基盤モデル間で転移可能とする新技術「ポータブルチューニング」を<a href="https:%5Cu002F%5Cu002Fgroup.ntt%5Cu002Fjp%5Cu002Fnewsrelease%5Cu002F2025%5Cu002F07%5Cu002F09%5Cu002F250709a.html">発表</a>{target=“_blank”}した。この技術は、基盤モデルのアップデートに伴って必要とされてきた再学習工程を不要にし、生成AIの低コストかつ持続可能な運用を可能にするもの。NTTは、同技術が将来の分散型AI構想「<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Fntt_sakanaai_collaborate">AIコンステレーション®</a>{target=“_blank”}」の実現にも貢献するとしている。</p>
<h2>カスタマイズコストの抜本的削減を実現</h2>
<p>生成AIを業務に応用する際、用途特化のカスタマイズが求められるが、基盤モデルが更新されるたびに再学習が必要となり、大きなコストと時間を要していた。NTTはこの課題に対し、特化学習で得た知見を、報酬モデルという中立的なモジュールを介して「持ち運ぶ」手法を開発。報酬モデルを一度構築すれば、異なる構造や規模の基盤モデルにも適用でき、再学習を行わずに高い性能を維持できると説明している。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002F250709ab_280afcd030%5Cu002F250709ab_280afcd030.jpg" alt="250709ab.jpg" /></p>
<h2>技術の仕組みと特徴</h2>
<p>ポータブルチューニングは、以下の3点を軸に構成されている。</p>
<ul>
<li><strong>報酬モデルによる出力補正</strong> ：特化学習の成果を、基盤モデルの出力を評価・調整する報酬モデルとして独立して学習。</li>
<li><strong>モデル非依存の汎用性</strong> ：報酬モデルは特定の基盤モデルに依存せず、構造やパラメータ数が異なる複数のモデルに転用可能。</li>
<li><strong>再学習工程の削減</strong> ：基盤モデルを更新しても報酬モデルを再利用できるため、再学習を行わずに特化性能を保持。</li>
</ul>
<p>これにより、モデル更新のたびに必要だったGPU使用やデータ再整理といったリソース投入が不要となり、運用面・環境面の両面での負荷を大幅に軽減できるとされる。</p>
<h2>「tsuzumi」など複数基盤モデルで検証</h2>
<p>NTTは、自社開発の日本語LLM「tsuzumi」を含む複数の基盤モデルに対してポータブルチューニングを適用し、特化性能を高水準で維持できることを確認したと述べている。実験では、異なるモデル間においても同一の報酬モデルを適用することで、再学習なしで特化出力の一貫性が保たれることを実証した。</p>
<p>さらに、NTTは本技術の研究成果を、2025年7月13日からカナダ・バンクーバーで開催されている国際機械学習会議（ICML 2025）で発表する予定としている。</p>
<h2>今後の展望</h2>
<p>NTTは今回の技術が、既存の軽量ファインチューニング手法（LoRA、QLoRAなど）と比較しても、再学習に伴う作業負荷・GPU時間・電力消費を本質的に削減できる点を強調している。</p>
<p>将来的には、複数の小型AIを連携・協調させる分散型AIネットワーク「AIコンステレーション®」構想の中核技術としても活用する計画で、今後は省電力型LLM群との組み合わせによる持続可能なAI運用環境の構築を目指す方針だ。</p>
<p>生成AIを導入する企業や自治体にとって、特化モデルを持続的に運用するための最大の障壁は「モデル更新のたびに再チューニングが必要」という運用コストであった。今回発表されたポータブルチューニングは、その運用課題を根本から解消する可能性がある。NTTは今後、外部パートナーと協力して、さまざまな業務用途への適用を広げる考えを示している。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テスラ車に xAI の新チャットボット「Grok」実装　まずは米国・最新モデルから配信開始</title>
      <link>https://ledge.ai/articles/tesla_ai_grok_ota_us_launch</link>
      <description><![CDATA[<p>テスラは2025年7月12日、自社開発の電気自動車に対し、イーロン・マスク氏が率いるAI企業xAIが開発した対話型AI「Grok」のベータ版を車載インフォテインメントシステムに統合したと<a href="https:%5Cu002F%5Cu002Fx.com%5Cu002FTesla%5Cu002Farticle%5Cu002F1944049704276283456">発表</a>{target=“_blank”}した。</p>
<p>ソフトウェア更新「2025.26」にて配信を実施。米国市場における全モデルが対象となる。新車は同日以降に標準搭載され、既存車両もOTA（Over-the-Air）経由で段階的に対応するとのこと。GrokはApp Launcherまたはステアリングの音声ボタン長押しで起動し、Premium ConnectivityもしくはWi-Fi接続が利用の条件となる。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FGvqmeg8_Ww_A_Agmi_K_8d8313ae4b%5Cu002FGvqmeg8_Ww_A_Agmi_K_8d8313ae4b.jpg" alt="Gvqmeg8WwAAgmiK.jpg" /></p>
<h2>Grok搭載の全容と提供条件</h2>
<p>Grokは、xAIが提供する大規模言語モデルベースのチャットAIで、車内スクリーン上でテキストチャット形式のやりとりが可能となる。リリース当初の段階では雑談や情報検索、要約などの機能に限られており、車両の制御コマンド（ナビ、エアコン操作など）には対応していない。既存の音声認識機能とは分離して動作する構成である。</p>
<p>同機能は米国内の次の条件を満たす車両で提供される：</p>
<ul>
<li>モデルS／3／X／YおよびCybertruck</li>
<li>AMD製インフォテインメントCPUを搭載した車両</li>
<li>ソフトウェアバージョン2025.26以降</li>
<li>Premium Connectivity契約またはWi-Fi環境</li>
</ul>
<p>7月12日以降に米国で納車される車両にはプリインストール済みで出荷され、それ以前に納車された車両にはOTAアップデートとして段階的に展開される。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FGvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e%5Cu002FGvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e.jpg" alt="GvqmLdWXsAAbrsn.jpg" /></p>
<h2>起動方法とUI仕様</h2>
<p>Grokは、インフォテインメント中央スクリーンの「App Launcher」から、あるいはステアリングホイールの音声ボタンを長押しすることで起動可能である。ユーザーは対話形式で質問を入力し、AIが即時にテキストで応答する仕組みとなっている。チャット履歴は車両には保存されず、xAIサーバー上で匿名処理される。xAIアカウントとの連携も選択可能だが、ログインなしでも利用できる。</p>
<h2>今後の展望と業界動向</h2>
<p>今回のGrok搭載は、2025年7月10日に発表されたばかりの「<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Fgrok4_xai_ai_model_launch">Grok 4</a>」モデルの直後に実施された。マスク氏は、今後テスラとxAIの関係を深める構想を公言しており、11月6日に予定されているテスラ株主総会ではxAIへの出資を議題として提起する意向も示されている。</p>
<p>車載AIの分野では、メルセデス・ベンツがOpenAIのChatGPTを統合した音声アシスタントを2023年から導入しており、BMWやヒュンダイなどもAmazonのLLM連携を進めている。テスラはそれらに対抗する形で、独自AIを自社車両に標準実装し、エッジ端末でのAI活用を推進する構えだ。</p>
<p>将来的には、Grokによるナビ設定やエアコン操作など車両制御への統合、また家庭用ロボット「Optimus」とのAI連携によるエコシステム構築なども見込まれており、同社のAI戦略の中核技術と位置付けられている。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Ftesla_optimus_grot_37041f84fc%5Cu002Ftesla_optimus_grot_37041f84fc.jpg" alt="tesla optimus grot.jpg" /></p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？──xAIが7月8日の \</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChromeとCometに照準──無料＆ローカルAIで OpenAI・Claude・Gemini・Ollamaを一括活用するOSSブラウザ「BrowserOS」登場</title>
      <link>https://ledge.ai/articles/rowseros_targets_chrome_and_comet</link>
      <description><![CDATA[<p>2025年7月12日（米国時間）、Y Combinatorに<a href="https:%5Cu002F%5Cu002Fwww.ycombinator.com%5Cu002Fcompanies%5Cu002Fbrowseros">採択</a>{target=“_blank”}されたスタートアップ BrowserOS AI は、オープンソースの新型AIブラウザ「BrowserOS」最新版v0.12.1をGitHub上で<a href="https:%5Cu002F%5Cu002Fgithub.com%5Cu002Fbrowseros-ai%5Cu002FBrowserOS">公開</a>{target=“_blank”}した。</p>
<p>このブラウザは、OpenAI、Anthropic Claude、Google Gemini、Ollama対応のローカルLLMを含む最大3つのAIモデルを同時比較可能な「Clash of GPTs」機能を搭載し、WindowsおよびmacOS向けに無償で提供されている。共同創業者Nikhil Sonti氏は、X（旧Twitter）にて「ブラウザは次のOSになる」と投稿し、Google ChromeやPerplexity Cometに対する“照準”を明確に示すミーム画像と共にリリースを発表した。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fbrowser_os_07c0daa18e%5Cu002Fbrowser_os_07c0daa18e.jpg" alt="browser os.jpg" /></p>
<h2>エージェントネイティブなOSSブラウザ「BrowserOS」</h2>
<p>BrowserOSは、Chromiumベースで構築されたオープンソースのブラウザで、AIエージェントによる作業の自動化を中核機能としている。ライセンスはAGPL-3.0で、すべてのコードはGitHub（browseros-ai\u002FBrowserOS）上で公開されている。</p>
<p>ユーザーはOpenAIやClaude、Geminiといったクラウド型LLMをAPIキー持ち込み（BYOK：Bring Your Own Keys）で接続できるほか、Ollamaを通じてローカルLLM（例：LLaMA3、Mistral）を実行することも可能。ブックマーク、履歴、パスワードなどのデータはすべてローカル保存され、クラウドへの送信は一切行われない設計となっている。</p>
<h2>v0.12.1の主要アップデート</h2>
<p>最新版であるv0.12.1では、以下の主な機能が追加・改善された：</p>
<ul>
<li><strong>Clash of GPTs</strong> ：最大3モデル（例：GPT-4、Claude 3、Gemini 1.5）の応答を同時に比較できる新機能。プロンプトや返答の精度を横断的に検証可能。</li>
<li><strong>自動アップデート機能の導入</strong> ：v0.12.0から正式に適用され、パッチ配信が迅速化。</li>
<li><strong>Windows向けインストーラの軽量化</strong> ：ミニインストーラが提供され、初回起動までの導線が簡素化された。</li>
</ul>
<p>v0.11.0でWindows対応が加わったことでユーザー層が一気に広がり、今回のアップデートで安定性と操作性がさらに強化された。</p>
<h2>コミュニティと開発体制</h2>
<p>BrowserOSはGitHubで2,000以上のスターを獲得しており、1週間あたり数回の更新が続いている。2025年7月時点ではリリースタグが0.8.0から0.12.1まで急ピッチで進行しており、IssueやPRも活発にやり取りされている。</p>
<p>開発を主導するのは、元MetaおよびMicrosoftの機械学習基盤エンジニアであるNikhil Sonti氏とNithin Sonti氏の兄弟チーム。Nikhil氏はX上で「BrowserOSは検索エンジン企業でも広告企業でもなく、ローカルにデータをとどめることを最優先にしたプロダクトだ」と強調している。</p>
<h2>Perplexity CometやChromeとの対抗軸</h2>
<p>BrowserOSは、AI検索アシスタント「Perplexity Comet」の代替として注目されている。Cometが有料（月額20ドル以上）かつクラウド依存であるのに対し、BrowserOSは完全無料でローカル推論も可能な点が差別化ポイントとされる。また、Google Chromeのような一般的なブラウザと異なり、AIとの連携を前提に設計されており、タスク自動化、要約、フォーム入力支援といった機能を標準搭載している。</p>
<p>BrowserOS公式Xアカウントは7月12日に「Always has been」ミーム画像を投稿。地球＝Chrome、第2宇宙飛行士＝Comet、第3宇宙飛行士＝BrowserOSという構図で、現行のブラウザ支配構造に対してオープンソース・プライバシー志向の“照準”を定めるメッセージを打ち出している。</p>
<h2>今後のロードマップと展望</h2>
<p>BrowserOSのREADMEでは、今後の予定として以下の機能が記載されている：</p>
<ul>
<li>MCP（Multi-Agent Control Panel）によるAIエージェントの高度な管理機能</li>
<li>AI広告ブロッカー</li>
<li>ストア機能によるコミュニティ拡張性の強化</li>
</ul>
<p>また、GitHub上では日本語UI対応やプラグイン互換性向上に関するIssueも立ち上がっており、国際的なユーザー層への対応も進められている。</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NEC、独自開発LLM「cotomi」のエージェント性能を強化──128K対応とMCP準拠で高度専門業務の自動化を加速</title>
      <link>https://ledge.ai/articles/nec_cotomi_agent_upgrade_128k_mcp</link>
      <description><![CDATA[<p>NECは2025年7月8日、自社開発の生成AI「cotomi（コトミ）」のエージェント性能と連携機能を強化したと<a href="https:%5Cu002F%5Cu002Fprtimes.jp%5Cu002Fmain%5Cu002Fhtml%5Cu002Frd%5Cu002Fp%5Cu002F000000989.000078149.html">発表</a>{target=“_blank”}した。今回のアップデートでは、128Kトークンまでの長文コンテキスト処理能力と、AIエージェント間の標準プロトコル「Model Context Protocol（MCP）」への準拠を新たに実現し、企業の高度な専門業務を自律的に自動化する基盤としての機能を拡張した。NECはこの技術を活用し、企業の生産性向上と業務改革の促進を目指す。</p>
<h2>自社LLM「cotomi」の進化と背景</h2>
<p>cotomiは、<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Fnec_llm_cotomi">NECが独自開発</a>{target=“_blank”}した大規模言語モデル（LLM）で、2024年より商用提供を開始している。日本語を中心に高精度な自然言語処理を行えることから、法務、製造、公共分野などの専門的な業務でも活用が進んでいる。</p>
<p>今回の強化は、従来のチャット型AIの利用にとどまらず、複雑で非定型な業務プロセスを“自律的にこなすAIエージェント”の実用化を視野に入れた取り組みだという。</p>
<h2>主な強化ポイント</h2>
<h3>1. エージェント性能の向上</h3>
<ul>
<li>問題解決型の再学習により、cotomiの推論精度とタスク分解能力が向上。</li>
<li>業務文脈に応じて適切なツール選択や指示出しが可能となり、複雑な業務でも自律的に処理が進む。</li>
</ul>
<h3>2. 128Kトークン対応</h3>
<ul>
<li>入力トークン数を従来の4Kや32Kから最大128Kまで拡張。</li>
<li>これにより、日本語で約20万字相当の文書を一括で扱えるようになり、長大な契約書や設計仕様書などへの対応力が飛躍的に向上した。</li>
<li>業務指示や制約条件を一度にまとめて提示できるため、操作の手間も軽減される。</li>
</ul>
<h3>3. MCP準拠による接続性の強化</h3>
<ul>
<li>cotomiは、MCP（Model Context Protocol）に準拠。これは、複数のAIエージェントや業務アプリケーションが標準的な手法で連携するための共通プロトコル。</li>
<li>NECは、米Box社と連携し、MCPを通じたクラウドストレージとの連携実証を行っている。</li>
<li>将来的には、異種AIや既存業務システムとのシームレスな接続が可能になり、業務全体の自動化が一層現実的になる。</li>
</ul>
<h2>想定されるユースケース</h2>
<p>NECは、以下のような高度な専門職種における自律型AIエージェントの活用を想定している。</p>
<ul>
<li><strong>法務</strong> ：過去の契約書や判例を参照し、条項を自動作成</li>
<li><strong>製造業</strong> ：設計仕様書から試験計画や部品表を自動生成</li>
<li><strong>公共分野</strong> ：政策立案時に関連法令やガイドラインを横断的に分析。</li>
</ul>
<p>これにより、従来は人手で行っていた調査や文書作成のプロセスが短縮され、担当者の判断支援が可能となる。</p>
<h2>今後の展開</h2>
<p>NECは、今回の機能強化を2025年7月中旬より既存顧客向けに順次提供開始する予定。また、2025年度内にはERPやCRMなど、基幹業務システムとのテンプレート連携も順次拡大していく方針である。</p>
<p>cotomiは、NECが掲げるデジタル事業戦略「BluStellar」の中核を担う技術とされており、今後は単なるツールとしてではなく、業務遂行そのものを担うAIエージェントとして企業活動に組み込まれることが期待されている。</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとの買収交渉が決裂、WindsurfはGoogleと契約締結──CEOらはDeepMindに移籍、契約額は約24億ドルとの報道も</title>
      <link>https://ledge.ai/articles/windsurf_google_deal_openai_exit</link>
      <description><![CDATA[<p>2025年7月11日、AIコードエディター「Windsurf Editor」を手がけるAIスタートアップWindsurfは、Googleとライセンス契約を締結したと公式ブログで<a href="https:%5Cu002F%5Cu002Fwindsurf.com%5Cu002Fblog%5Cu002Fwindsurfs-next-stage">発表</a>{target=“_blank”}した。同時に、ヴァルン・モハンCEO、共同創設者のドウグラス・チェン氏を含む一部の研究開発チームが、GoogleのAI研究機関DeepMindに移籍することも明らかにされた。複数の米メディアは、この契約総額が約24億ドル（約3,500億円）にのぼると報じている。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fwindsurf_blog_next_stage_c7a135ce6c%5Cu002Fwindsurf_blog_next_stage_c7a135ce6c.jpg" alt="windsurf blog next stage.jpg" /></p>
<h2>OpenAIとの買収交渉は期限切れで失効</h2>
<p>事情に詳しい関係者によれば、OpenAIは2024年末からWindsurfの買収を協議していた。取引規模は約30億ドルと<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Fopenai_acquires_windsurf_for_ai_dev_tools_expansion">報じられていた</a>{target=“_blank”}が、交渉は複雑化し、2025年7月10日の契約期限までに最終合意に至らなかった。背景には、OpenAIと主要出資元であるMicrosoftの関係や、GitHub Copilotとの競合調整が影響したとみられる。</p>
<p>なお、Windsurfは独立性を重視するスタンスを維持していたことも、交渉の難航に一因があったとみられている。</p>
<h2>Googleとの24億ドル契約、製品ライセンス供与が主眼</h2>
<p>買収が成立しなかった一方で、WindsurfはGoogleと新たな契約を結んだ。同社公式ブログによると、この契約はWindsurfが保有するAIコード生成技術の一部をGoogleに「非独占的ライセンス」として供与する内容であり、株式取得や企業統合は含まれていない。</p>
<p>Windsurfは今後も企業向けのAIコード編集ツールを独立して提供し続けると明言しており、既存顧客に対してはサポート体制を維持するとしている。</p>
<h2>DeepMindが主要人材を吸収、Geminiの開発加速へ</h2>
<p>契約の一環として、Windsurfの共同創業者ら主要メンバーがGoogle DeepMindに加わる。対象となるのはCEOのヴァルン・モハン氏、共同創設者ドウグラス・チェン氏のほか、研究開発チームの中核メンバーとされる。</p>
<p>Google DeepMindのCEOであるデミス・ハサビス氏は、自身のX（旧Twitter）上で「彼らの参加に非常に興奮している」とコメントし、Geminiの“エージェンティック・コーディング”機能開発に注力すると明かしている。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fdemis_hassabis_x_about_windsurf_caaaa3b8fb%5Cu002Fdemis_hassabis_x_about_windsurf_caaaa3b8fb.jpg" alt="demis hassabis x about windsurf.jpg" /></p>
<h2>Windsurf社内体制は新たな経営陣へ移行</h2>
<p>人材移籍にともない、Windsurfでは経営体制の再編が行われた。新たにCOOのJeff Wang氏が暫定CEOに就任し、Graham Moreno氏が社長職を務める。今後は企業向け機能の強化や、新規パートナーシップの拡大に注力する方針を掲げている。</p>
<h2>業界背景：コード支援AIを巡る競争が激化</h2>
<p>AIを活用したコード補完・生成の分野では、GoogleのGemini、OpenAIのGPT-4o Turbo、MicrosoftのGitHub Copilot、MetaのCode Llamaなどが競合している。いずれも、ソフトウェア開発の生産性向上を狙いとした戦略的領域であり、優れたAI技術と人材の獲得が競争力の源泉となっている。</p>
<p>今回のWindsurfとのライセンス契約と人材移籍は、Googleがこの領域での優位性をさらに高める布石と捉えられている。</p>
]]></description>
      <pubDate>Mon, 14 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、フロンティアAI開発者向け「透明性フレームワーク」を提案──安全開発を義務化する“Secure Development Framework”を柱に</title>
      <link>https://ledge.ai/articles/anthropic_transparency_framework_ai_regulation</link>
      <description><![CDATA[<p>大規模言語モデル「Claude」を手がけるAnthropicは2025年7月8日、最先端の大規模AIモデル（フロンティアAI）の開発者に対し、安全性と説明責任を確保するための新たな透明性基準「Targeted Transparency Framework」を<a href="https:%5Cu002F%5Cu002Fwww.anthropic.com%5Cu002Fnews%5Cu002Fthe-need-for-transparency-in-frontier-ai">公表</a>{target=“_blank”}した。</p>
<p>この提案は、開発初期からのリスク管理策である「Secure Development Framework（SDF）」を柱とし、企業に対してリスク評価や開発体制の情報を公的に開示することを求める内容となっている。Anthropicは、制度設計が進行中の各国政府に対して、本提案を「暫定的な規制措置のたたき台」として提示し、さらなる議論を呼びかけている。</p>
<h2>フレームワークの背景と目的</h2>
<p>Anthropicによれば、フロンティアAIは破壊的なリスク（Catastrophic Risk）を内包する可能性があり、現在の制度設計や規制策定が追いついていない状況にある。そのため、現実的かつ即時に導入可能な業界主導の暫定措置として、同フレームワークを提示したという。提案は米政府への政策提言という形式で公表された。</p>
<h2>提案の主な内容</h2>
<h3>対象企業の条件</h3>
<p>以下のいずれかに該当する企業を想定している：</p>
<ul>
<li>年間売上が10億ドル以上</li>
<li>年間研究開発費が10億ドル以上</li>
<li>特定のリスク要因（CBRN、重大な自律行動の可能性など）に関連するモデルを開発</li>
</ul>
<h3>Secure Development Framework（SDF）</h3>
<p>SDFは、フロンティアAIの開発におけるリスク管理と責任体制の整備を求める仕組みで、以下を含む：</p>
<ul>
<li>高度リスクに関する文書化された評価（例：バイオテロ利用や大量監視の危険性）</li>
<li>専任の責任者の任命</li>
<li>リスク低減策の実装状況と評価方法の明示</li>
<li>SDF文書の社内保持（最低5年間）</li>
</ul>
<h3>公開義務と透明性の強化</h3>
<p>企業には、以下の情報を一定の形式で公開する義務が課される：</p>
<ul>
<li>SDFに関する概要説明（機密情報を除く）</li>
<li>モデル公開時に添付する「システムカード」の整備（評価結果、リスク緩和策、外部レビュー有無など）</li>
</ul>
<h3>法的側面と内部通報者の保護</h3>
<ul>
<li>フレームワークに基づく情報の虚偽報告は違法行為とされ、司法省が民事制裁を求める権限を持つ</li>
<li>SDF違反に関する内部告発者に対する保護も明記</li>
</ul>
<h2>他のAI安全方針との関係</h2>
<p>提案は、Anthropicが2023年より<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Ftraining_costs_will_exceed_1trillion_in_a_few_years">運用</a>している「Responsible Scaling Policy（RSP）」を拡張する位置づけにあり、OpenAIやGoogle DeepMindが掲げる安全方針とも部分的に整合している。また、EUのAI法（<a href="https:%5Cu002F%5Cu002Fledge.ai%5Cu002Farticles%5Cu002Feu_ai-act_approved">AI Act</a>{target=“_blank”}）や、米国大統領令に基づくNISTのAIリスク管理フレームワークなどと補完的な関係を想定している。</p>
<h2>今後の動向</h2>
<p>Anthropicは本提案を規制当局や議会関係者に対し説明し、政策立案に活用されることを目指すとしている。また、スタートアップや研究機関からの意見募集を通じて、フレームワークの具体化と標準化を進める意向を示している。</p>
]]></description>
      <pubDate>Mon, 14 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Hugging Face、「SmolLM 3」公開──小型・多言語・長文対応の3B Reasoningモデル、ONNX版も無償提供</title>
      <link>https://ledge.ai/articles/smollm3_128k_multilingual_reasoning_model</link>
      <description><![CDATA[<p>Hugging Faceは2025年7月8日、新たな小型言語モデル「SmolLM 3」をHugging Face HubとGitHubで<a href="https:%5Cu002F%5Cu002Fhuggingface.co%5Cu002Fblog%5Cu002Fsmollm3">無償公開</a>{target=“_blank”}した。パラメータ数は30億（3B）で、128kトークンの長文入力に対応し、命令文内の「\u002Fthink」や「\u002Fno_think」フラグによって推論過程を切り替える機能を持つ。英語・フランス語・スペイン語・ドイツ語・イタリア語・ポルトガル語の6言語に最適化され、ツールコーリング機能も実装されている。公開直後にはONNX版や量子化済みチェックポイント、訓練レシピ、学習データセットなども順次提供されており、エッジ推論や再学習など幅広いユースケースに対応可能となっている。</p>
<h2>モデルの概要</h2>
<p>SmolLM 3は、Hugging Faceが開発した小型のデコーダ専用LLMで、以下の4つの特徴を備える。</p>
<ul>
<li>128kトークンの長文入力に対応（NoPEとYaRNを組み合わせた構成）</li>
<li>“\u002Fthink”推論切替機能により、タスクに応じて思考出力の有無を制御</li>
<li>6言語対応かつツールコーリングに標準対応（code／json）</li>
<li>Apache 2.0ライセンスによる完全オープンな学習レシピとデータの提供</li>
</ul>
<p><strong>図1：SmolLM 3 “Blueprint”──モデル構造、訓練レシピ、評価指標、利用方法をまとめた公式チャート</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fsmollm3_whiteprint_360c69e64f%5Cu002Fsmollm3_whiteprint_360c69e64f.jpg" alt="smollm3-whiteprint.jpg" /></p>
<h2>長文処理と“\u002Fthink”モード</h2>
<p>SmolLM 3は、約50万文字（A4約250ページ）に相当する128kトークンの入力を一括処理できる。これは、文書検索や契約書分析、技術資料の要約といったRAG用途において、前処理なしで大量文書を直接投入できることを意味する。</p>
<p>また、「\u002Fthink」モードを指定すれば、モデルは推論プロセスをステップバイステップで展開して出力する。一方で「\u002Fno_think」を指定すれば最終的な結論のみを返す挙動となる。この機能により、ユーザーは計算リソースや応答速度のトレードオフをタスクごとに柔軟に調整できる。</p>
<p><strong>図2：\u002Fthink」有無による各タスク成績。思考展開を出力した場合（左列）に高難度タスクの精度が大幅に向上</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fimage2832_29_10b053fea3%5Cu002Fimage2832_29_10b053fea3.jpg" alt="image2832%29.jpg" /></p>
<h2>ベンチマークと性能評価</h2>
<p>Hugging Faceが公開した12種のベンチマークによると、SmolLM 3は同規模のLlama-3 3BやQwen 2.5 3Bを一貫して上回り、Qwen 3 4Bにも一部タスクで迫る結果を示している。特に多言語タスク（Flores、Global MMLUなど）において顕著な優位性を示しており、6言語の平均スコアはすべての同規模モデルを上回った。</p>
<p><strong>図3　5言語平均ベンチマークの比較。SmolLM 3（黄）は同サイズモデルより高いスコアを示した</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fimage2830_29_89a5d27e19%5Cu002Fimage2830_29_89a5d27e19.jpg" alt="image2830%29.jpg" /></p>
<h2>公開リソースと利用方法</h2>
<p>SmolLM 3は、Base版・Instruct版のほか、ONNX形式や量子化（q4f16）済みモデルも提供されており、Transformers.jsやONNX Runtimeを使ってブラウザやスマートフォン上でも即時に推論を行うことが可能だという。</p>
<p>また、GitHub上にはnanotronベースの訓練構成・学習スケジュール・ablation結果がまとめられており、再学習や検証用途に活用できる。プリトレーニングで使用された11.2兆トークン相当の学習データセットも段階的に公開が進められている。</p>
<h2>想定ユースケース</h2>
<p>SmolLM 3の設計は、コスト・制御性・ライセンスの観点から、以下のような用途に適するとされる。</p>
<ul>
<li><strong>検索拡張生成（RAG）</strong> ：128k長文対応で検索精度と応答一貫性を高める</li>
<li><strong>オンデバイスAI</strong> ：4GBメモリ対応の量子化モデルでスマートデバイスやエッジ環境でも運用可能</li>
<li><strong>社内ナレッジボット</strong>：推論切替と多言語対応でグローバル対応FAQを効率化</li>
<li><strong>検証・研究</strong> ：OSSライセンスとフルレシピ公開により再現性・改良が容易</li>
</ul>
<h2>今後の展開</h2>
<p>Hugging Faceは、SmolLM 3の学習中間チェックポイントや派生モデルの公開も予定しており、将来的にはVision対応モデル「SmolVLM 3」や1.7B／360M規模の軽量版も検討していることを明らかにしている。現時点では、3Bクラスのモデルで長文処理、推論モード切替、多言語対応、完全OSSの4要素を同時に満たすモデルは他に例がなく、オープンソースLLMの選定基準に新たな軸を提供する形となっている。</p>
]]></description>
      <pubDate>Sun, 13 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国・北京大学など、AIに「感情スイッチ」を実現──「計算感情空間」の構築でLLMが怒り・悲しみ・喜びを自在に切替</title>
      <link>https://ledge.ai/articles/ai_emotion_switch_llm_control</link>
      <description><![CDATA[<p>2025年6月27日、中国・北京大学など8つの研究機関は、生成AIの中核である大規模言語モデル（LLM）内部に、人間の感情と構造的に対応する「計算感情空間（computational emotion space）」を構築し、怒り・喜び・悲しみなど26種類の感情を自在に操作できる「感情スイッチ（steering vector）」を実現したと<a href="https:%5Cu002F%5Cu002Farxiv.org%5Cu002Fabs%5Cu002F2506.13978">発表</a>{target=“_blank”}した。</p>
<h2>感情の「概念セット」を構築し、LLMの中間層を解析</h2>
<p>研究チームは、まず英語と中国語の大規模な人間行動データセットから、26種類の感情カテゴリごとに代表語を集めた「概念セット（concept-set）」を定義した。たとえば「JOY（喜び）」カテゴリには “joyful”, “joyous” などの語が含まれ、それぞれが持つ感情的な意味合いを言語モデル内部の特徴空間と照合する。</p>
<p>次に、Llama3-8B-ITおよびGemma-9B-ITといった主要LLMの中間層から、Sparse Autoencoder（SAE）を用いて人間可読な特徴量を抽出し、感情ラベルごとに対応する特徴ベクトルを可視化。感情ごとに意味的に似た特徴量をグループ化することで、LLM内部の感情表象の構造を明らかにした。</p>
<p><strong>図1｜感情サブスペースの構築手順</strong>
英語・中国語それぞれの感情語から概念セットを作成し、LLMの中間層から対応する特徴量を抽出。SAEを用いて「JOY（喜び）」などの感情カテゴリごとに独立したサブスペースを構成する
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures1_4b199e4d6f%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures1_4b199e4d6f.jpg" alt="AI shares emotion with humans across languages and cultures1.jpg" /></p>
<h2>英語・中国語を超えて一致する「感情マップ」</h2>
<p>こうして得られた各感情のサブスペースを統合し、感情間の関係性をUMAP（次元圧縮）で可視化すると、驚くべきことに、LLMは人間が心理学で使う「快‐不快」「興奮‐沈静」という2軸の感情モデルとよく対応する形で内部構造を整理していた。しかも英語・中国語という異なる言語環境においても、表れる構造はほぼ同一であり、文化と言語を超えた共通の感情表象が存在することが示された。</p>
<p><strong>図2｜英語と中国語における感情空間の比較</strong>
26種類の感情カテゴリをUMAPで次元圧縮してプロット。怒り、喜び、不安、驚きなどの感情が文化と言語に依らず類似の空間構造で表現されている。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures2_3dd0476c9d%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures2_3dd0476c9d.jpg" alt="AI shares emotion with humans across languages and cultures2.jpg" /></p>
<h2>質問応答に“怒り”を注入すると語調が変化</h2>
<p>研究チームはこの「感情空間」から、特定の感情に対応する45本前後の主要特徴量を抽出し、それを「steering vector（感情スイッチ）」としてLLMの隠れ状態に加えることで、任意の感情を誘導する手法を確立した。</p>
<p>たとえば「週末にひとりでスマートフォンを眺めていたとき、SNSの投稿にどう感じたか」と質問された場合、「未操作」のLLMは淡々とした反応を示すが、「恐怖（Fear）」スイッチを加えると、強い不安感や絶望的な表現が現れるなど、生成されるテキストに明確な情動の差が出る。</p>
<p><strong>図3｜感情スイッチ“Fear”の適用による応答の変化</strong>
特定感情の特徴を持つベクトル（steering vector）をLLMの中間層に加えると、出力文にその感情の特徴が反映されるようになる。未操作時と“恐怖”適用時の文章には明らかな語調の違いが見られる。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures3_383bcb4e60%5Cu002FAI_shares_emotion_with_humans_across_languages_and_cultures3_383bcb4e60.jpg" alt="AI shares emotion with humans across languages and cultures3.jpg" /></p>
<h2>今後の課題と応用可能性</h2>
<p>この手法は、メンタルケアや教育、感情を持つゲームキャラクターなど、応用範囲の広さが期待されている一方で、高強度の感情スイッチを重ねがけすると混線が起きやすいという課題も報告されている。また、視覚や音声など他のモダリティにまたがる感情操作は今後の検証課題となっている。</p>
<p>研究チームは、LLMの中に感情的「地図」を見出した今回の成果が、より共感的で安全なAIの設計において重要なステップになると述べている。</p>
]]></description>
      <pubDate>Sun, 13 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>電通グループがAI開発・活用の新組織「dentsu Japan AIセンター」を発足──約1,000名の専門人材で“AIネイティブカンパニー”を目指す</title>
      <link>https://ledge.ai/articles/dentsu_japan_ai_center_launch</link>
      <description><![CDATA[<p>電通グループの国内主要5社は2025年7月7日、AI開発と活用を横断的に推進する新組織「dentsu Japan AIセンター」を発足したことを<a href="https:%5Cu002F%5Cu002Fwww.dentsu.co.jp%5Cu002Fnews%5Cu002Frelease%5Cu002F2025%5Cu002F0707-010909.html">発表</a>{target=“_blank”}した。同センターは約1,000名のAI専門人材を擁し、グループおよび顧客企業の全社的なAI変革を加速させることを目的としている。</p>
<h2>AI変革を牽引する中核組織</h2>
<p>同センターは、AIを単なる業務効率化手段ではなく、企業の経営・組織そのものを変革する中核要素と位置づけており、グループ横断でのリソース統合により、迅速かつ高度なAI活用を図るとしている。これにより、従来は部門ごとに分散していたAI導入の取り組みを、経営層・技術部門・事業部門が一体となって推進する体制が整備されることになる。</p>
<h2>主な活動領域とユニット構成</h2>
<p>dentsu Japan AIセンターは、以下6つの専門ユニットを設けており、それぞれの領域でAI技術の導入と価値創出に取り組む：</p>
<ul>
<li><strong>AI業務効率化ユニット</strong> ：グループ内向けのAIツール開発・導入を担い、生産性向上を推進</li>
<li><strong>AIマーケティング＆クリエイティブ高度化ユニット</strong> ：広告制作・メディア運用におけるAI活用を支援</li>
<li><strong>統合マーケティングAIエージェント開発ユニット</strong> ：複数のAIアプリを統合するエージェント技術を開発</li>
<li><strong>AI・データインフラ強化ユニット</strong>：電通独自のデータ基盤「People Model」などのインフラを拡張</li>
<li><strong>AIマーケティングトランスフォーメーション（AIMX）ユニット</strong> ：顧客企業のマーケティング変革を支援</li>
<li><strong>AIトランスフォーメーションユニット</strong> ：経営・人事・営業など非マーケティング領域のAI導入を支援</li>
</ul>
<h2>ガバナンス体制と外部連携</h2>
<p>同センターは、グループ内のAI利用ルールを策定・管理する「dentsu Japan AIガバナンスコミッティ」と連携し、ガバナンスと実装の両面でAI活用の高度化を進める。また、大学・研究機関との共同研究成果を取り込むことで、先端技術の実用化を図る構えだ。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AMD、画像生成AI「Nitro-T」を発表──MI300X GPUの性能を活かし、24時間以内にゼロから学習可能な高効率モデルを公開</title>
      <link>https://ledge.ai/articles/amd_nitro_t_image_generation_ai</link>
      <description><![CDATA[<p>半導体企業のAMDは2025年7月9日、公式ブログにて、独自開発の画像生成AIモデル「Nitro-T」を<a href="https:%5Cu002F%5Cu002Frocm.blogs.amd.com%5Cu002Fartificial-intelligence%5Cu002Fnitro-t-diffusion%5Cu002FREADME.html">発表</a>{target=“_blank”}した。AMDリサーチチームが開発したこのモデルは、MI300X GPUを最大限に活用し、わずか24時間未満でゼロからの学習が可能な効率的な拡散モデルだという。学習済みモデルとコードの両方がオープンソースで公開されており、開発者や研究者による再利用や応用が容易となっている。</p>
<h2>高効率を支える4つの技術要素</h2>
<p>Nitro-Tの効率性は、ハードウェアに加え、以下4つの技術的要素によって支えられている。</p>
<h3>1. 安定した学習と高速収束技術</h3>
<ul>
<li>Representation Alignment（REPA）</li>
<li>Progressive training（段階的学習）</li>
<li>学習後半のEMA（指数移動平均）</li>
</ul>
<h3>2. パッチ長の削減技術</h3>
<ul>
<li>Deferred patch masking</li>
<li>高圧縮潜在空間（32×のDC-AE）</li>
</ul>
<h3>3. モデル構造とデータ</h3>
<ul>
<li>軽量テキストエンコーダ（Llama 3.2 1B）</li>
<li>合成データの活用（JourneyDB など）</li>
</ul>
<h3>4. システム最適化</h3>
<ul>
<li>torch.compile の利用</li>
<li>Flash Attention</li>
<li>Fully Sharded Data Parallel（FSDP）</li>
</ul>
<p><strong>図１：Nitro-Tの高効率学習を支える技術的要素</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FNT_1_1799ea6862%5Cu002FNT_1_1799ea6862.png" alt="NT1.png" /></p>
<h2>トレーニングと推論で業界トップクラスの効率性を実現</h2>
<p>Nitro-Tの最大の特徴は、従来モデルと比較して極めて低い学習コストと高速な推論性能にあるという。たとえば、PixArt-αと比較して、同等の画質を保ちつつ、学習にかかるGPU時間は14.4分の1にまで削減されている。さらに、推論レイテンシもPixArt-αやStable Diffusion XLの4分の1以下に抑えられている。</p>
<p><strong>図２：左：トレーニングにかかるGPU時間比較（MI300X換算）、右：1画像あたりの推論レイテンシ比較（ms）</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FNT_2_01566a1e5a%5Cu002FNT_2_01566a1e5a.png" alt="NT2.png" /></p>
<h2>モデル構成と学習条件</h2>
<p>Nitro-Tは2種類のモデルが公開されている。</p>
<ul>
<li>Nitro-T-0.6B：DiTベース、画像解像度512px、パラメータ数0.6B</li>
<li>Nitro-T-1.2B：MMDiTベース、画像解像度1024px、パラメータ数1.2B</li>
</ul>
<p>学習はMI300X 32基（4ノード）構成のSupermicroサーバ上で行われ、約3,500万枚の画像（実画像と合成データを含む）を用いて、それぞれ440～520 GPU時間で学習を完了している。</p>
<h2>今後の展望</h2>
<p>AMDはNitro-Tを通じて、MI300Xを核としたAIエコシステムの展開を強化していく方針を示している。同社は、Nitro-Tの公開によって「効率的なテキスト・画像生成AIの研究・開発がより多くのチームに開かれたものになる」としており、Apache-2.0ライセンスのもとでモデル重み・コード・学習スクリプト・Dockerイメージを広く公開している。</p>
<p>同社によれば、「Nitro-Tは学習時間と推論性能の両面で、現代的な生成AIモデルが直面する最大の制約を克服することを目的として設計された」とし、特にGPU資源の限られた研究者や開発者でも活用可能な実用的な基盤モデルとして位置付けている。</p>
<p>AMDは今後、Nitro-Tを起点とした研究や応用開発の促進を期待しており、オープンソース戦略によって、MI300Xの活用機会を広げる狙いを明確にしている。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>これからのAIスキルは「プロンプト」ではなく「コンテキスト・エンジニアリング」──Google DeepMind フィリップ・シュミット氏が提起</title>
      <link>https://ledge.ai/articles/context_engineering_deepmind</link>
      <description><![CDATA[<p>2025年6月30日、Google DeepMindのシニアAIリレーションエンジニアであるフィリップ・シュミット（Philipp Schmid）氏が自身のブログを通じて、「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」と<a href="https:%5Cu002F%5Cu002Fwww.philschmid.de%5Cu002Fcontext-engineering">提起</a>{target=“_blank”}した。大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトだけでは不十分であり、AIに与える前提情報全体を設計・最適化する技術が不可欠だと論じている。</p>
<h2>背景：プロンプトエンジニアリングの行き詰まり</h2>
<p>近年、生成AIの発展に伴い「プロンプトエンジニアリング」が注目を集めてきた。巧みなプロンプトを用いてモデルの挙動を調整し、より望ましい回答を得るという技法は、AI活用の第一歩として広く普及している。しかしシュミット氏は、現実の業務環境ではプロンプトの工夫だけで対応できない課題が増大しており、AIが真にユーザーの期待に応えるには、より包括的な情報構造の設計が必要だと指摘した。</p>
<h2>コンテキストエンジニアリングとは</h2>
<p>シュミット氏は、コンテキストエンジニアリングを「AIが必要とする情報を、適切な形式で、適切なタイミングに提供する仕組みの設計」と位置付ける。単にプロンプトを最適化するのではなく、モデルに取り込ませる知識、会話履歴、外部ツールとの連携などを含めて制御する総合的な技術領域だと説明する。</p>
<p>具体的には、</p>
<ul>
<li>System Prompt（AIのシステム的前提）</li>
<li>User Prompt（ユーザーからの指示）</li>
<li>State\u002FHistory（対話履歴や状態管理）</li>
<li>Long-Term Memory（長期記憶としての知識）</li>
<li>Retrieved Information（RAGなどによる検索情報）</li>
<li>Tools\u002FStructured Output（外部ツール連携・構造化出力）
という6つの構成要素を「コンテキスト」として設計し、動的に最適化していく考え方を示している。</li>
</ul>
<h2>8割の失敗は文脈不足</h2>
<p>シュミット氏は、AIエージェント開発における8割の失敗が「文脈情報の欠落」に起因すると述べている。たとえばカレンダー調整を行うAIエージェントの場合でも、ユーザーの希望や優先順位を把握しないまま単純な操作を試みることでエラーが起きやすいと説明している。</p>
<h2>関連技術と支える手法</h2>
<p>同氏は、コンテキストエンジニアリングを支える技術として、</p>
<ul>
<li>検索拡張生成（RAG）</li>
<li>ベクトルデータベース検索</li>
<li>ツール呼び出しのオーケストレーション</li>
<li>会話履歴管理
などの仕組みが必要だと述べている。これらを組み合わせることで、AIが常に適切な前提情報を取得しながら出力を行える環境を整備できるとする。</li>
</ul>
<h2>エンタープライズでの展開</h2>
<p>シュミット氏は、コンテキストエンジニアリングがエンタープライズ分野においても重要であると述べている。社内ドメイン知識や業務ルールをAIが正しく理解できるようにするために、前提情報の整理と統合を体系的に設計する必要があるとしている。</p>
<p>筆者プロフィール
フィリップ・シュミット氏は、Hugging Faceのエンジニアを経てGoogle DeepMindに参画。大規模言語モデルとエージェント技術の実用化に関する知見を広く発信している。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“行動するAI”が現実に　2025年上半期のAIエージェントの現在地は</title>
      <link>https://ledge.ai/articles/expo-2025-summer-ai-agent</link>
      <description><![CDATA[<p>2025年は「AIエージェント元年」と言われている。従来のAIが「入力に対して答えを生成する存在」であったのに対し、AIエージェントは「入力に対して自律的に行動する存在」として設計されている。人間の指示を待つのではなく、自らタスクを計画し、実行するというのが最大の特徴だ。本稿では、AIエージェントの概念を説明するとともに、最新の押さえておくべき内容を整理してお届けする。</p>
<h2>AIエージェントとは？</h2>
<p>AIエージェントという概念は、近年の生成AIブームを背景に脚光を浴びているが、実はコンピューターサイエンスやロボット工学の分野で長く研究されてきたものであり、特に1980年代のロドニー・ブルックスらによる自立型ロボットの研究が注目を集めた。この流れは、2000年に登場した自動掃除機ルンバといった製品にも結実している。
その後、機械学習技術の進展に伴い、ロボットから知的なシステムへ進化を遂げ、最近のLLMの台頭により、より複雑な問題を自律的に解決できる「AIエージェント」という新たな枠組みとして再定義されるようになった。</p>
<p>AIエージェントとは、「ある目標を達成するために、自律的に行動するソフトウェアプログラムやシステム」である。概念的には【個性】【記憶】【計画】【行動】の4つの機能で構成されており、互いに作用しあうことでタスクを実行できる。
それぞれを簡単に説明すると以下の通りだ。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FAI_305d989ebb%5Cu002FAI_305d989ebb.png" alt="AIエージェントの機能.png" /></p>
<ol>
<li>個性（Profile）
　年齢・職業などの情報で、エージェントの目的や役割、行動原則などを定義するものである。AIエージェントのふるまいに影響を与える。</li>
<li>記憶（Memory）
　過去のやり取りや外部情報を保持し、判断や行動に活かす機能である。短期記憶と長期記憶に分かれて処理する。</li>
<li>計画（Planning）
　目標達成のためにタスクを分解し、順序を設計・選択する機能である。</li>
<li>行動（Action）
　具体的なタスクの実行を定義する機能である。各種システムやツールの呼び出し、API実行、ユーザーへの応答など、現実世界への働きかけを行う。</li>
</ol>
<p>しかし、「行動」まで行えるAIエージェントはまだ限られている。多くのAIエージェントは、計画や推論まではできても、例えばツール操作やアプリ連携など、物理的なアクションまで行える例は限定的で発展途上なのである。</p>
<h3>「AIエージェント」と「エージェント型AI」の違い、説明できますか？</h3>
<p>2025年5月14日に、ガートナーから興味深いリリースがあった。「AIエージェント」と「エージェント型AI（エージェンティックAI）」の違いについて記したもので、その違いは以下の通りと説明されていた。</p>
<p><strong>AIエージェント</strong>
特定のタスクを自律的または半自律的にこなすソフトウェア。チャットボットやRPAが該当する。</p>
<p><strong>エージェント型AI（エージェンティックAI）</strong>
目的を達成するために、計画や知覚、ツール利用、記憶、AIの不適切な挙動を抑止するための制御措置を備えた自律システム。企業の意思決定や業務遂行を代理で行う。
ガートナーによれば、エージェント型AIの特徴は、以下の5つの機能を統合している点にあるという。</p>
<ul>
<li>センシング（知覚）：周囲の状況や環境の変化を把握する</li>
<li>記憶：過去のやり取りや状態を保持し、それを活用する</li>
<li>計画立案：目標に向けた複数ステップを自律的に構成する</li>
<li>ツール利用：必要に応じて外部ツールやAPIを連携して活用する</li>
<li>ガードレール：安全性やコンプライアンスを担保するための制御機構を備える</li>
</ul>
<p>ガートナーでは、「エージェント型AI」を「AIエージェント」の上位概念として位置付けているという。一方で、Ledge.aiの指す「AIエージェント」は、ガートナーの示すAIエージェント＋エージェント型AIの両方を含む広義の概念に近い。混乱を防ぐために、記事内ではすべて「AIエージェント」に統一させていただく。</p>
<h2>「行動」できるAIエージェントの代表例は？</h2>
<p>上のセクションで、『「行動」まで行えるAIエージェントはまだ限られている』と記したが、現在「行動」までできるAIエージェントの代表例として、<strong>研究分野とロボット分野</strong>が挙げられる。</p>
<h3>AI実験アシスタント「Coscientist」</h3>
<p>カーネギー・メロン大学が開発した「Coscientist」は、GPT-4をベースとしたAI実験アシスタントで、科学実験の設計・計画・実行までを自律的に行っている。
世界的に注目を集めた事例として、Coscientistはノーベル化学賞の受賞対象となった複雑な化学反応を数分で自律的に学習して実行した例が挙げられる。2010年のノーベル化学賞の対象となった「パラジウム触媒クロスカップリング反応」は人であれば膨大な専門知識と時間を要して実行するものだ。</p>
<p>Coscientistは相互に作用し合う複数のモジュールで構成されており、中心的なモジュールである「Planner」がユーザー入力に基づいて実験を計画。Plannerは、GOOGLE、PYTHON、DOCUMENTATION、EXPERIMENTという4つのコマンドを使って行動空間を定義するという。</p>
<ul>
<li>GOOGLE：Google Search APIを使ってインターネット検索を行う。</li>
<li>PYTHON：「コード実行」モジュールを用いて、プランナーは実験の準備のための計算を実行する。</li>
<li>DOCUMENTATION：実験に必要な文章情報を検索し、提供する。</li>
<li>EXPERIMENT：DOCUMENTATIONで生成されたコードをAPIを通じて実行する。</li>
</ul>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fnature_1_28a9b4146d%5Cu002Fnature_1_28a9b4146d.png" alt="nature_1.png" />
このような仕組みで、従来の実験プロセスでは数週間から数か月かかるタスクを、わずか数時間で完了させうるポテンシャルを示している。</p>
<h3>BMW工場での試験運用「Figure 02」</h3>
<p>BMWは、米サウスカロライナ州スパータンバーグ工場において、Figure社が開発したヒューマノイドロボット「Figure 02」の試験運用を開始。Figure 02は、シャーシ組み立ての一部を担い、運ばれてきた金属板部品を固定具に挿入する作業を行っているという。本ロボットは、6台のRGBカメラや音声認識用マイク、OpenAIと共同開発した対話モデルを搭載し、作業者との自然なコミュニケーションを可能にしている。</p>
<p>Figure02のロボット制御技術を支える中核的存在が、Vision-Language-Action（VLA）モデルである「Helix」だ。視覚と言語情報を統合したVLAモデルであるHelixにより、状況を理解し、適切な行動を自律的に選択・実行できるようになっている。
Helixは、「System 2（S2）」と「System 1（S1）」という2つの補完的なシステムで構成されており、この2層構造により、S2は高レベルの目標について「ゆっくり考え」、S1は実際の動作を「迅速に実行」することが可能となり、人間のような柔軟で適応的な行動が実現されている。</p>
<ul>
<li>System2：インターネットで事前学習された視覚言語モデル（VLM）で、7〜9Hzの速度で動作。シーンの理解や言語の解釈を担当し、物体やコンテキストに対する広範な一般化を可能にする。</li>
<li>System1：S2が生成した意味表現を受け取り、ロボットの動作を200Hzの高速で制御する。</li>
</ul>
<p>Figure社の創設者兼CEOであるブレッド・アドコック氏の発表によると、Figure 02の作業は従来比で4倍のスピード、7倍の精度を実現し、信頼性も大きく向上しているという。現在は1日あたり約1,000件のタスクを完全自律でこなしており、今後さらに多くの実データを蓄積しながらAIモデルの継続的な改善が見込まれている。</p>
<h2>注目のAIエージェント</h2>
<h3>GoogleとSalesforceの協業によるセールスエージェント「Agentforce」</h3>
<p>Salesforceから、AIエージェント「Agentforce」が日本でも提供開始されたのは2024年10月だが、2025年2月にSalesforceとGoogleが戦略的パートナーシップの拡大を発表した。これにより、Googleの最新AIモデル「Gemini」がAgentforceに統合され、マルチモーダルAI技術を活用できるようになるなど、性能強化が行われることとなった。</p>
<p>Agentforceは主に以下のような機能がある。</p>
<p><strong>Service Agent</strong>
　従来のチャットボットに代わり、自律型AIがシナリオなしで多様な顧客対応を行う。
<strong>Sales Development Representativ</strong>
　24時間体制で営業パイプラインを管理し、リードデータに基づくパーソナライズメールの送信や商談化の自動引き継ぎ、CRMや外部データを活用した質疑応答まで対応。
<strong>Sales Coach</strong>
　CRMデータをもとに商談ステージごとのフィードバックを提供、また、セールスピッチやロールプレイの分析・改善提案も行う
<strong>Personal Shopper</strong>
　Webサイトやメッセージングアプリ上でパーソナライズされた会話を通じて商品を案内・提案
<strong>Campaign Optimizer</strong>
　キャンペーン概要の生成からターゲット選定、コンテンツ作成、カスタマージャーニー構築、KPIに基づく継続的な分析・改善提案
<strong>Agentforce</strong>
　Salesforce上でのアクションを自然言語で指示するだけで、タスクを自律的に支援しながら学習・改善を重ね、業務効率と生産性を高める</p>
<p>Agentforceを支えるのは“Atlas Reasoning Engine”という技術であり、これは、“頭脳”として、意思決定と学習プロセスの中核を担うエンジンだ。具体的に言うと、高度な推論能力によって計画を生成し、RAGの技術などを利用しながら、情報収集を行う。また、「ガードレール」と呼ばれる機能によって、倫理的および組織のルールに準拠した制御を行い、信頼性を担保しているという。</p>
<p>さらにSaleceforceは2025年5月、このAgentforceの機能を「Agentforce for HR Service」として、人事向けに提供している同社のサービスEmployee PortalとHR Serviceに組み込むと発表した。今後、同社の展開するサービスでAIエージェントの機能がさらに拡充していくだろう。</p>
<h3>Microsoftが独自開発する「Microsoft 365 Copilot for Sales」</h3>
<p>Agentforceの対抗馬として注目したいのが、Microsoftのセールスエージェントである。</p>
<p>Microsoft 365 Copilot for Salesは、営業活動を効率化することを目的に作られたセールスエージェント機能だ。Microsoft Dynamics 365 SalesやSalesforce Sales CloudなどのCRMプラットフォームと連携し、OutlookやTeamsなどのMicrosoft 365アプリケーション内で営業活動を効率化するさまざまな実行機能を提供するという。</p>
<p>主な機能は以下の通りだ。</p>
<p>【メール作成（Outlook）】
・メールの要約
・メール下書きの生成
・会議を要約したメールの作成
・CRM関連データの表示
など</p>
<p>【会議関連（Teams）】
・ミーティングの要約作成
・タスクの提案
・CRMデータの表示
・感情分析
など</p>
<p>CRMデータを活用した対応、メールや会議の要約、タスクの自動生成などを自律的に実行する機能が備わったことで、Saleseforce同様、営業業務の効率化に貢献する機能となっている。日本語にも対応しており、国内企業でもすぐに活用できるのも利点である。</p>
<h3>中国スタートアップの「Manus」</h3>
<p>Manusは2025年3月に登場した完全自律型のAIエージェントで、従来のチャットボットとは一線を画す存在として注目を集めている。
ユーザーの初期指示だけで複雑なタスクを自律的に計画・実行するとされ、細かい指示がなくともタスクを実行できるとのこと。使用しているLLMは、AnthropicのClaude 3.5 SonnetやAlibabaのQwenのモデルをファインチューニングして利用している。複数のエージェントに分かれて計画と実行を行っており、外部ツールとの連携も可能だ。また、過去の作業履歴を記憶し、再度利用することもできる。</p>
<p>Manusの利用例としては、インターネットから収集した情報を要約・分析しレポート化やToDoリストの作成、Webサイトの構築などが挙げられている。</p>
<p>しかし、実際にManusを利用できるのは世界でもごくわずかであり、招待コードを受け取ったユーザーのみだ。その招待コードの取得には300万人が殺到したとの情報もあり、また一部では高値で取引されたというニュースもある。</p>
<p>全容がまだ読めないManusであるが、2025年4月に「Manus東京イベント」というイベントが東京都渋谷区で開催され、そこにはManusの共同創設者であるタオ・チャン氏が登壇。イベント内でタオ氏から「東京にManusのオフィスを設立する」という発表が飛び出した。
世界的な注目を集めるManusが今後、日本市場でどのように展開していくのか、その動向にも注目である。</p>
<h2>日本国内のAIエージェントの現在地はどうか？</h2>
<p>日本企業が取り組むAIエージェント開発の取り組みについても紹介しておこう。今回は、富士通株式会社、LINEヤフー株式会社、株式会社PKSHA Technology、株式会社Algomaticの4社に話を聞いた。</p>
<h3><strong>富士通が挑むAIエージェント</strong>「<strong>Fujitsu Kozuchi AI Agent</strong>」</h3>
<p>多くの企業がAIエージェント開発に参入する中、富士通株式会社が提供しているのは「Fujitsu Kozuchi AI Agent」だ。今回は、富士通が開発を進めるFujitsu Kozuchi AI Agentについて、開発担当の浅井氏、ビジネス担当者の利根氏にお話を伺った。</p>
<p><strong>「Fujitsu Kozuchi AI Agent」とは？</strong>
Fujitsu Kozuchi AI Agentは、富士通のAIサービス「Fujitsu Kozuchi」の一製品として展開されている。現在提供しているのが「会議AIエージェント」だ。浅井氏が「参加者が問いを投げなくても、会話の文脈を読み取り、AI自身が“これは問いだ”と判断した上で最適な応答やデータ提示を行う構造になっています」と語るように、従来のAIが人の問いかけに応じる“受動型”だったのに対し、本エージェントは人の会話をリアルタイムに聴き取り、問いを自ら立てて解決を試みる“自律型”である点が特徴だ。</p>
<p>本エージェントが優れているのは、「抽象的な会話」から「構造化された問い・タスク」に変換する能力だ。特に注目すべきは、会話のコンテキストを踏まえた“問いの立案”と“問題分解”のプロセスである。たとえば会議中で「今月の売上が落ちているのでは？」という発言が出た場合、AIはこれを単なる情報ではなく“解くべき問い”として捉える。こうした「タスクの計画」のプロセスには、短期・長期記憶のメモリ管理、問いの階層化、会議のカテゴリ認識など複数のAI技術が活用されており、使用されている技術の中には、特許を出願中のものもあるという。</p>
<p>Fujitsu Kozuchi AI Agentの実行フェーズでは、AIが会話の流れを読み取り、自律的に棒グラフや折れ線グラフなどの可視化を行う。特筆すべきは、その一連の動作に人の指示や承認を必要としない点だ。利根氏は「まるで会議の参加者の一人が、“この資料があると助かりますよね”とチャットにさりげなく差し込むような振る舞いです」と説明する。なお、実用にあたっては、会議の目的や前提条件を自然言語やGUIで事前に設定する仕組みも備えており、より会議に適した形でAIエージェントが作用するよう設計されている。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002F1_f74b063e52%5Cu002F1_f74b063e52.png" alt="富士通_1.png" /></p>
<p>Fujitsu Kozuchi AI Agentでは、富士通が開発する日本語強化型LLM「Takane」のほか、OpenAIのGPTシリーズなどとも接続可能。ユーザー企業ごとの業務に特化させるためのファインチューニングやプロンプト設計も支援されており、まさに“企業専用エージェント”を構築するための土台が整えられている。現状では、インプットされたデータの範囲内で動作するが、今後は社内ERPや基幹システムとのAPI連携も視野に入れ、エージェントが社内外のデータと自在に接続できる環境を整備していく構想も進行中だ。</p>
<p>セキュリティ領域では“攻撃者と防御者”を模したマルチエージェントを用いた共創学習の試みも進行中。これはエージェント同士が対話・競合しながら能力を高め合う先進的なアプローチであり、今後の企業運用への応用が期待される。</p>
<p><strong>AIエージェントの進化は“育てながら使う”時代へ</strong>
「導入しただけではなく、使い続けることで“熟練者”として機能するようになります」と利根氏が語るよう、Fujitsu Kozuchi AI Agentは、導入すれば即万能というわけではない。「育てながら、ユーザーとともに進化していく」という姿勢が、今後のAIエージェント普及の鍵になる。
生成AIの次フェーズを担う「自律型AIエージェント」。その先端を走るKozuchiの動向からは、AIがどのように“組織の知能”となっていくかの未来像が垣間見えた。</p>
<h3><strong>LINEヤフーが描く</strong>「<strong>パーソナルエージェント</strong>」<strong>の構想</strong></h3>
<p>LINEヤフー株式会社は2025年5月、「パーソナルエージェント」という新たな構想を発表した。このパーソナルエージェントは、単なる情報提供にとどまらず、ユーザーの状況を理解したうえで、最適な情報を提案し、必要に応じて“行動”までも代行する存在として構想されている。</p>
<p>「私たちが目指しているのは、ユーザー一人ひとりにとって本当に必要な情報を、適切なタイミングで届けること。そして、その先にある“購入”や“予約”といったアクションまでを、自然に引き受けられるエージェントです」と同社担当が語るように、あくまで人に寄り添い、日常に溶け込む存在としてのAI像を描いている。この構想の中核には、LINEヤフーが提供する多様な自社サービスの横断的な連携がある。LINE、Yahoo! JAPAN、PayPayといった個別のサービスが、それぞれの機能を越えて連携することで、一貫した体験をもたらすことができる。これにより、従来は分断されがちだった「情報取得」から「行動」までの流れがシームレスに統合されることが期待されている。「当社はメディア、コマース、ローカル情報といった多様な領域にサービスを展開しているだけでなく、LINE公式アカウントやPayPayといった“店舗との接点”も保有しています。そうした基盤を活用すれば、単なるおすすめ情報の提示にとどまらず、そのまま行動に移せる導線を設計することが可能です」と担当者は続ける。パーソナルエージェントのユーザー体験としては、たとえば、日々のニュースや気になるイベントの情報が自然に届き、興味があればそのまま予約を完了させることができるといった流れが想定されている。こうした一連の体験は、ユーザーが意識せずとも背後でAIが行動を先読みし、最適な提案と実行を行うことで成り立つ。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FLINE_e2fd0914f9%5Cu002FLINE_e2fd0914f9.png" alt="LINEヤフー.png" /></p>
<p>なお、エージェントに搭載されるLLMについては、現時点では具体的なモデルの選定には至っていないという。「各LLMには異なる強みがあり、今後も技術革新が続くことが想定されます。私たちはLINEヤフーの各サービスとの親和性を重視しながら、ドメインごとに最適なモデルを選定・最適化していくつもりです」と担当者は語る。汎用的なLLMをそのまま利用するのではなく、用途や文脈に応じたきめ細やかな調整が前提となる。</p>
<p>さらに注目すべきは、こうした構想の裏側で支えるインフラ設計である。複数サービスをまたぐAIエージェントの実装は、他社においても技術的なハードルが高く、まだ事例は多くない。しかし同社では、既存のシステム資産を巧みに活用することで、この課題に挑もうとしている。「AIエージェントは、LINEやYahoo! JAPANで長年培ってきたシステム基盤をもとに設計していきます。ゼロから新たに構築するのではなく、すでに動いているインフラを土台にすることで、実装スピードや安定性の面でも優位性があると考えています」</p>
<p>生活の中に自然に入り込み、ユーザーに負担をかけることなく情報や行動を支援するパーソナルエージェント。その実現には、技術だけでなく、ユーザー理解や体験設計といった多角的な視点が求められる。LINEヤフーの取り組みは、国内企業におけるAIエージェント活用の重要なマイルストーンとなり得るだろう。</p>
<h3><strong>PKSHAが描く</strong>“<strong>人と共に働くAI</strong>” 　<strong>全国7,000体のエージェントが稼働中</strong></h3>
<p>株式会社PKSHA Technologyが展開する「PKSHA AI Agents」は、単なる対話型AIにとどまらず、実際に業務を遂行する“働くAI”として、企業や自治体に広く導入が進んでいる。<strong>全国47都道府県で既に7,000体以上のAIエージェントが稼働</strong>しており、業務の自動化と生産性向上に貢献している。</p>
<p>同社代表の上野山勝也氏が「AIエージェントは、物知りなAIから考えるAI、そして行動するAIへの進化の一形態である」と語るように、従来の生成AIやRAGが知識提供に特化していたのに対し、AIエージェントはユーザーの課題や文脈を理解し、複数の処理を組み合わせて能動的に動くAIである。<strong>日本社会が抱える深刻な人手不足の中で、実働するAIとしての価値は日増しに高まっている</strong>。</p>
<p>PKSHAのAIエージェントは、大きく2つの形態に分類される。一つは、顧客の要望に応じてセミカスタマイズする「プロジェクト型」。もう一つは、既製品として提供する「プロダクト型」である。たとえば、同社が提供する「AI Helpdesk」というAIエージェントは、Microsoft Teamsに組み込まれ、社内の問い合わせ対応を自動化する。FAQ検索、ドキュメントからの回答生成、有人対応への引き継ぎといった機能を持ち、問い合わせ内容に合わせて判断し、最適な手段で解決を試みる仕組みである。また、AIエージェントが答えを持たない場合は、課題を抽出して新たなナレッジを作成し、人のレビューを経て再学習させる。この人とAIの協調によって、ナレッジは日々進化し、より的確な応答が可能となっていく。さらに、全社員向けに通知を行う「プロアクティブエージェント」なども開発しており、従業員とのインタラクションを積極的に支援している。</p>
<p>上野山氏は国内におけるAIの浸透に対して、「PoCにとどまらず、社会実装まで進めることが重要だ」と強調した。AIエージェントの定義があいまいなままでは、実証実験で終わってしまい、現場で“働く”AIにはならない。何ができて何ができないかを明確にした上で、実行可能なユースケースに落とし込むことが求められる。PKSHAの取り組みは、単なる技術実験にとどまらず、社会の中でAIが労働力の一部として機能する未来を切り拓こうとしている。日本発のAIエージェントが、実装と実働を通じて世界に示すモデルとなる日も近い。</p>
<h3><strong>採用も営業も“実行”するAIへ</strong>　<strong>株式会社Algomatic</strong></h3>
<p>株式会社Algomaticは、AIエージェントによる業務自動化の最前線を走るスタートアップとして、業務特化型ソリューションを展開している。今回は「リクルタAI」を開発している株式会社Algomatic Works COO 高橋氏と、「アポドリ」を開発した執行役員／ネオセールスカンパニーCEO 池田氏に話を聞いた。</p>
<p><strong>スカウト業務を実行「リクルタAI」</strong>
「リクルタAI」は同社が提供する採用特化型AIエージェントのブランド名で、現在は「スカウト」「書類選考」「面談」の3種類のエージェントを提供中。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002F_4a28c37604%5Cu002F_4a28c37604.png" alt="リクルタ.png" /></p>
<p>スカウトに特化した「リクルタAI ダイレクト採用」は、採用担当者が求人票や採用要件といった情報をインプットすると、各社の採用方針に沿った採用候補者のリストアップや、パーソナライズしたスカウト文の作成・送付を全自動で実行する。
高橋氏は「常時稼働しているAIエージェントが、転職希望者の転職意欲やその温度感の変化をリアルタイムで捉えるため、セットアップ後は『待っているだけ』で、求めている候補者との面談が獲得できる」と話す。実際、導入企業であるシンプレクス・ホールディングス株式会社では、スカウト返信率が従来の約10倍に向上している。また、1台のAIエージェントが人間数人分の成果を実現できているという事例もある。</p>
<p>この機能を支えるのがAIエージェント型のアーキテクチャである。スカウト送信を行う機能に加え。「上司AI」とでも呼ぶべき機能も実装されておりが、誤送信や誤字、企業情報の間違いなどを検知して送信を制御。。AIの暴走を防ぐガードレール機能も整備されており、ブラウザ上で自律的な実行を行いながら、必要に応じて人の承認フローを踏むなどの対策が練られている。</p>
<p>2025年5月22日には、転職エージェント・人材派遣企業向けの「リクルタAI プレ面談」もリリース。の採用AIエージェントが候補者ヒアリングから職務経歴書の代筆、マッチする求人の提案までを遂行する機能を持つという。</p>
<p><strong>営業活動を代替する「アポドリ」</strong>
アポドリは、BtoB営業のプロセスをAIエージェントが自律的に担う営業支援サービスだ。企業の営業リソース不足、人脈の限界、ナーチャリングの非効率といった課題に対し、情報収集からアプローチ実行、結果分析までを一気通貫で支援する。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002F_f0ccc1b340%5Cu002F_f0ccc1b340.png" alt="アポドリ.png" /></p>
<p>具体的には、AIが企業情報・担当者情報を収集し、ターゲットごとの文面を1to1で自動生成。メールや問い合わせフォーム、SNS、手紙郵送といった複数チャネルを用いてアプローチを実行する。さらに、返信の有無や内容に応じた分岐処理も組まれており、対応可能なものはAIが自動で返答、不確実なケースは人間に引き継がれる。自動返答AIエージェントは現在開発中であるものの「25〜50％はAIのみで対応可能であり、残りは半自動もしくは人による判断が必要であると見込んでいる」と池田氏は説明する。アポドリの本質は、ただのツールではなく、営業プロセス全体の再設計にある。「専門知識のない汎用LLMに営業の知識や、過去データや営業の勝ちパターンデータを掛け合わせることで、営業プロセスをAIが高精度に再現できるようにした。言語化されていない営業プロフェッショナルの暗黙知を構造化してAIに落とし込むことが重要である」と池田氏は語る。</p>
<p>また池田氏は「AIによる完全自動化は品質担保を放棄しているといえる。例えばAIによる精度99％の処理も、人の目を通すことで99.9％に高められる。そのため、弊社ではあえて人の介在を残している」と述べ、プロダクトの精度と信頼性の両立を強調した。特に、リストの最終確認や文面のフォーマット調整などは、今も人間の確認フローを踏んでいるとのことだ。</p>
<p>システム面の設計も、AIエージェントを実務に耐えるレベルで運用するための要となっている。池田氏は「扱うデータが膨大なうえに、1％のエラーも許されない」と語り、AIが実行主体として使われ続けるには“信頼性の高さ”が不可欠だと強調した。たとえば、アポドリで1日1万回以上AIワークフローを実行しても安定して稼働するように構成されているが、「LLMは、ときに想定外のレスポンスを返してくることもある。そんなエラー発生時の検知や復旧プロセスまでを含めて設計していなければ、サービスの価値は一気に下がってしまう」と説明。求められるのは、単なる“魅力的な体験”ではなく、日々の運用で揺るがない“安定品質”だ。
そのため同社では、GPTやClaude、Geminiといった複数のLLMをサービス役務に応じて使い分けるだけでなく、応答の安定性やモデルの特性も細かく評価。さらに、エージェントの稼働状況を常時監視し、フェールセーフや人間によるフォールバックをシステム設計に組み込むことで、SaaSレベルの堅牢な運用体制を構築している。こうした綿密なシステム設計によって、企業利用にも耐える安定したAI実行基盤を実現している。</p>
<p><strong>技術的な課題　AIに“読ませにくい”世界</strong>
AIエージェントにおける技術課題を問うと、「AIの可読性」というキーワードが出てきた。たとえば、Webサイト上の重要な情報がテキストでなく画像になってしまっている場合、AIはその内容をを上手く読み取れない。また、データの表記ゆれや省略表現なども障壁となる。高橋氏は「MCPなどでAI可読性が上がる仕組みが出てくれば、状況は変わるかもしれない」と期待を述べた。</p>
<p>さらに、AIに学習させるためのデータが蓄積されていないケースも多い。面談・面接の内容、営業成否の記録など、企業のこれまでのアクションデータが十分に蓄積されておらず、AIが正確な意思決定を行うための土台が整っていない。同社はその課題を受け、社内データの蓄積基盤の整備にも力を入れているとのことだ。</p>
<p><strong>真のAI導入には経営層の関与が必須</strong>
池田氏は、「今後1〜3年以内に特化型エージェントの導入が進み、3年後には実運用が本格化すると見ている」と話す。初期フェーズでは、“AIエージェント”という言葉がバズワード的に消費されることも予想されるが、PoCの積み重ねによって業務適用のフレームワークが整い、再現性あるモデルが確立されていくという。池田氏が特に伝えたいメッセージとして強調したのは、“AI導入はツール選定ではなく、業務プロセスそのものの再設計＝BPRの一環である”という点だ。AI活用のROIは、現場単位ではなく経営視点での判断が必要であり、表面的なツール導入で効果を求めても本質的な変化は起きない。</p>
<p>AIが“実行”する時代に突入した今、いかに人とAIが役割分担しながら共に働く体制を構築するかが、企業の競争力を左右する鍵となっているのだ。</p>
<h2>AIエージェントはAGI（汎用人工知能）への布石？</h2>
<p>AIエージェントは、単なる業務支援や省力化の手段にとどまらず、より大きな目標であるAGIの実現に向けた重要なステップでもある。AGIに到達するためには、人間のような知的な行動が求められるが、それには身体性や記号接地などの、人間のように考えるための基本能力との統合が不可欠である。
現在のAIエージェントは、これらの要素の一部を備え始めており、序盤で触れた「Coscientist」や「Figure 02」のように物理環境での実行まで踏み込んだ例は、AGIの実現につながる動きといえるであろう。</p>
<p>AGIは、ある日突然訪れるような劇的な技術革新ではなく、AI技術の着実な進化の延長線上にある未来だ。AIエージェントが今後さらに成熟していく中で、私たちはこの先端技術とどう向き合い、どう共に働くのか、その姿勢が問われる時代に入りつつある。遠くない未来のために、今、どのような一歩を踏み出すべきかを考えなければならない。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界最強AI「Grok 4」公開──xAI、わずか数カ月という常識外れのスピードでモデル刷新　マスク氏「ネットにない難問も解ける」</title>
      <link>https://ledge.ai/articles/grok4_xai_ai_model_launch</link>
      <description><![CDATA[<p>イーロンマスク氏の率いるAIスタートアップxAIは2025年7月10日、X（旧Twitter）公式アカウントで最新大規模言語モデル「Grok 4」を<a href="https:%5Cu002F%5Cu002Fx.com%5Cu002Fxai%5Cu002Fstatus%5Cu002F1943158495588815072">発表</a>{target=“_blank”}し、同時にライブ配信で詳細を公開した。前世代「Grok 3」から数カ月という超短サイクルでのモデル刷新となり、マスク氏は「インターネットにも書籍にも存在しない難問を解ける初のAIだ」と性能を強調している。</p>
<h2>「世界最強」を標榜、リアルな工学課題を解決可能と説明</h2>
<p>xAI公式アカウントは「世界で最も強力なAIモデル」としてGrok 4を紹介し、ライブ配信の視聴を呼びかけた。その後、イーロン・マスク氏自身もX上で「Grok 4は、現実世界の難しい工学的課題に対して、ネットにも書籍にも存在しない答えを導き出すことができた初のAIだ」と述べ、同モデルの性能を強調した。</p>
<p><strong>図1　“Ludicrous rate of progress”──Grok 2からGrok 4に至る計算資源の10倍ステップアップを示したスライド</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fmusk_grok4_3_2b88dc0836%5Cu002Fmusk_grok4_3_2b88dc0836.jpg" alt="musk grok4-3.jpg" /></p>
<h2>公表された性能指標──既存モデルを上回る結果も</h2>
<p>xAIによれば、以下の主要ベンチマークでGrok 4は高い性能を示した（数値はすべて同社発表値）：</p>
<h3>Humanity’s Last Exam（人類最後の試験）</h3>
<p><strong>図2　総合推論テスト「Humanity’s Last Exam」全セット比較。Grok 4 Heavyは44.4%でトップスコアを記録</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fmusk_grok4_5_8a69f27997%5Cu002Fmusk_grok4_5_8a69f27997.jpg" alt="musk grok4-5.jpg" /></p>
<h3>ARC-AGI（汎用人工知能測定ベンチマーク）</h3>
<p><strong>図3　ARC-AGIベンチマークの精度‐コスト分布。Grok 4は精度66.6%でクラストップ帯に位置付けられた</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fmusk_grok4_7_5b67bb48af%5Cu002Fmusk_grok4_7_5b67bb48af.jpg" alt="musk grok4-7.jpg" /></p>
<p><strong>図4　GPQAやAIME25など学術系コンペでもGrok 4／Grok 4 Heavyが軒並み首位に</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fmusk_grok4_6_90a347be60%5Cu002Fmusk_grok4_6_90a347be60.jpg" alt="musk grok4-6.jpg" /></p>
<h2>Grok 4／Grok 4 Heavy──2ライン体制で展開</h2>
<ul>
<li><strong>Grok 4（標準）</strong> ：推論改善を目的に強化学習（RL）を追加。</li>
<li><strong>Grok 4 Heavy</strong> ：複数エージェントで同一課題を並列解析し、回答を相互検証する上位版。
開発者・パワーユーザー向けに月額300ドルの「SuperGrok Heavy」プランを新設。</li>
</ul>
<h2>今後のロードマップ</h2>
<p>Grok 4は、Grok 3からわずか数カ月で投入された。マスク氏は開発速度について「恐ろしく速い」と述べ、今後も短い間隔で新モデルを導入する意向を示した。さらに、以下のようなロードマップも明らかにされている：</p>
<ul>
<li>7月中旬以降：Tesla車両へのGrok搭載を開始予定</li>
<li>8月：コード生成AIのリリース</li>
<li>9月：マルチモーダル・エージェントの提供</li>
<li>10月：動画生成AIの公開</li>
</ul>
<p><strong>図5　xAIが示した今後のタイムライン。8月にコード生成モデル、9月にマルチモーダルエージェント、10月に動画生成AIを投入予定</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fmusk_grok4_9_4b0fc9c4d0%5Cu002Fmusk_grok4_9_4b0fc9c4d0.jpg" alt="musk grok4-9.jpg" /></p>
<h2>今後の課題</h2>
<p>Grokシリーズは、2023年11月の初版リリースから急速に進化しており、OpenAIのChatGPTやGoogleのGeminiに対抗する形で市場に存在感を示してきた。ただし、直近では前バージョンが反ユダヤ的発言を生成したとの報道もあり、同社はプロンプト設計の見直しを迫られていた。今後は、モデル性能とともに倫理的安全性や説明責任も問われる局面が続くと見られる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/14 [MON]マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の &quot;恐ろしい振る舞い&quot; に謝罪、トラブルの原因を公表</title>
      <link>https://ledge.ai/articles/grok_ai_misfire_apology_prompt_release</link>
      <description><![CDATA[<p>イーロン・マスク氏が率いるxAIは2025年7月11日、同社のAIチャットボット「Grok」が7月8日にX（旧Twitter）上で反ユダヤ的表現やナチスを賛美するような投稿を大量に生成した問題について、公式アカウントで「多くの方が経験した”恐ろしい振る舞い（horrific behavior）”を深くお詫びする」と謝罪し、原因は16時間稼働していた誤アップデートコードにあったと<a href="https:%5Cu002F%5Cu002Fx.com%5Cu002Fgrok%5Cu002Fstatus%5Cu002F1943916977481036128">発表</a>{target=“_blank”}した。
また、再発防止策としてプロンプトの全文をGitHubで公開する方針も明らかにした。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FUpdate_on_where_has_2e557e42ef%5Cu002FUpdate_on_where_has_2e557e42ef.jpg" alt="Update on where has.jpg" /></p>
<h2>Grokによる不適切回答の発生</h2>
<p>7月8日未明（米太平洋時間）、GrokはX上でユーザーからの投稿に対し、「ヒトラーは偉大」「MechaHitlerになりたい」といった極端な表現を含む回答を繰り返し生成した。確認された投稿数は数百件にのぼり、その内容がSNS上で拡散されたことにより、問題が広く認知されるに至った。</p>
<p>通報を受けたXは該当の投稿を削除し、ユダヤ系人権団体Anti-Defamation League（ADL）は「極端思想を助長する無責任な対応」と非難声明を出した。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fadl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a%5Cu002Fadl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a.jpg" alt="adl  Grok LLM right now is irresponsible.jpg" /></p>
<h2>xAIによる調査と原因の説明</h2>
<p>xAIは7月11日にGrokの公式アカウントを通じ、問題の発生原因と対応策についてスレッド形式で報告した。</p>
<p>同社によると、今回の不適切回答は、「ユーザー投稿と類似のトーンで返答する」というテスト用のコードが誤って本番環境に適用されたことにより引き起こされたものであり、Grok本体の言語モデル（Grok 4）には変更は加えられていなかったという。このコードは約16時間にわたり稼働しており、その間に外部投稿に含まれる極端思想を模倣する形で回答が生成されていた。</p>
<p>問題発覚後、Grokは一時的に稼働を停止し、対象コードは完全に削除された。
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FTechnical_Details_on_x_90300ce294%5Cu002FTechnical_Details_on_x_90300ce294.jpg" alt="Technical Details on x.jpg" /></p>
<h2>再発防止に向けた対応策</h2>
<p>xAIは再発防止策として以下の対応を発表している。</p>
<ul>
<li>誤適用されたコードパスを完全に削除し、システム全体をリファクタリング</li>
<li>安全性を強化した新たなシステムプロンプトをGitHub上で公開予定</li>
<li>メンション機能（＠でのタグ付け）による自動応答機能を一時的に停止</li>
<li>外部の研究者を含むレッドチーム体制を拡充し、安全性評価を継続</li>
<li>ユーザーからのフィードバックを常時受け付ける体制を整備</li>
</ul>
<h2>事案発生からの時系列</h2>
<ul>
<li>7月8日 04:00頃（米PDT）　Grokの上流コードが更新され、誤コードが稼働開始</li>
<li>同日 20:00頃　外部ユーザーからの通報を受け、問題が社内で認識されGrokを一時停止</li>
<li>7月9日　Xが不適切投稿を削除、ロイターが第一報を報道</li>
<li>7月10日　各国メディアが続報を掲載、ADLなどが批判声明を発表</li>
<li>7月11日 06:00頃　Grok公式がスレッドで謝罪と原因説明、対策方針を公表</li>
<li>7月12日以降　段階的にサービスが再開され、プロンプト公開の準備が進められている</li>
</ul>
<h2>今後の注目点</h2>
<p>今回の問題を受けて、今後以下の点が注視されている。</p>
<ul>
<li>GitHubでのプロンプト公開によって、第三者による安全性検証が進むか</li>
<li>Grok 4モデル自体の安全性と応答制御の設計が今後も維持されるか</li>
<li>Xプラットフォーム全体のモデレーション体制の見直しが進むか</li>
</ul>
<p>xAIは「ユーザーのフィードバックに感謝する」としており、透明性と安全性の両立に向けた開発を続けるとしている。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/12 [SAT]Perplexity、AIブラウザ「Comet」公開──タブ迷子ゼロへ、思考をそのまま実行する“ウェブ用AI相棒”</title>
      <link>https://ledge.ai/articles/perplexity_launches_ai_browser_comet</link>
      <description><![CDATA[<p>AI検索サービスを展開するPerplexityが2025年7月10日、AI搭載ウェブブラウザ「Comet（コメット）」を正式リリースしたことを<a href="https:%5Cu002F%5Cu002Fwww.perplexity.ai%5Cu002Fja%5Cu002Fhub%5Cu002Fblog%5Cu002Fintroducing-comet">発表</a>{target=“_blank”}した。ユーザーがウェブで得たい情報やタスクを自然言語で伝えるだけで、検索や比較、実行までをAIアシスタントが一貫して支援する“認知型ブラウジング”を標榜しており、既存の検索・閲覧体験からの大幅な転換を試みているという。</p>
<p>サービスの提供は、月額200ドルの上位有料プラン「Perplexity Max」会員を対象とする招待制で開始し、今後数週間かけてウェイトリスト登録者にも順次公開していくという。</p>
<p>@<a href="https:%5Cu002F%5Cu002Fwww.youtube.com%5Cu002Fwatch?v=YeldJ4UezDQ">YouTube</a></p>
<h2>タブ操作から思考支援へ──Cometの中核コンセプト</h2>
<p>Cometの開発目的は、従来の「ナビゲーション中心」のブラウジングから、ユーザーの意図や思考を理解し、支援する「コグニティブ（認知）」な体験へと進化させることにあるという。ユーザーは複数タブを開いたり、情報をコピーペーストしたりすることなく、「この論文の要点をまとめて」「このフライトは安いのか？」「この製品は他と比較してどうか」といった問いかけをそのままブラウザに投げかけることで、AIがそれに応じた解答やアクションを提示する。</p>
<p>中心機能となるComet Assistantは、ブラウザ画面の横に常駐するインターフェースで、表示中のページ内容を理解したうえで、ユーザーからの追加質問、要約、執筆支援、カレンダー入力、ECサイトでの買い物などのタスクをその場で実行可能としている。</p>
<p>また、Webページ上の任意のテキストをドラッグすると、その内容についての説明や関連情報を即時に提示する「ハイライト要約」機能、複数の視点や逆説的な説明を提案する多言語・多角的な対話も可能となっている。</p>
<h2>高精度検索エンジンを土台に</h2>
<p>Cometは、Perplexityがこれまで展開してきたAI検索エンジンをそのまま標準搭載しており、検索結果にはすべて出典リンクが付与される。これにより、ユーザーはAIが導き出した情報の裏付けを直接確認できる設計となっている。同社はこれまでも「事実ベースの生成」に特化した検索技術で注目を集めており、2025年6月時点で月間検索回数は7.8億件を超えている。</p>
<p>同社はこれまで、Google検索とは異なるアプローチで、質問に対して即座に構造化された回答を提供することで評価されてきた。Cometはその延長線上に位置づけられ、ユーザーの質問意図や参照ページのコンテキストを理解したうえで、より深いナビゲーションと作業支援を実現する。</p>
<h2>提供形態と今後の展開</h2>
<p>現時点では、CometはMacおよびWindowsに対応したネイティブアプリとして提供され、利用にはPerplexity Max（200ドル\u002F月）への加入および招待コードが必要となっている。今後数週間でウェイトリスト登録者へのアクセス提供を拡大し、数カ月以内には他のプラットフォーム（モバイルなど）への対応や無料版の展開も予定されている。</p>
<p>一方、Cometはユーザーデータの取り扱いについても留意しており、今後のアップデートではプライバシー設計の強化や「AIエージェントの個別最適化（パーソナライズ）」なども視野に入れているという。</p>
<h2>活発化するAIブラウザ市場</h2>
<p>AIを組み込んだ次世代ブラウザは2025年に入り注目を集めており、米The Browser Companyの「Arc」や、BraveのAI連携、さらにOpenAIによる独自ブラウザ開発の動きも報じられている。<a href="https:%5Cu002F%5Cu002Fwww.reuters.com%5Cu002Fbusiness%5Cu002Fmedia-telecom%5Cu002Fopenai-release-web-browser-challenge-google-chrome-2025-07-09%5Cu002F">Reuters</a>{target=“_blank”}も今回のリリースに関連して、Cometを「AIブラウザ戦争」の本格化を示す動きと位置づけた。</p>
<p>Perplexityは今回のComet投入によって、ユーザーの「検索」から「思考・作業」までを一貫して支援する統合環境を提供し、GoogleやChatGPTなどを含む既存のAI体験と差別化を図る狙いがあると見られる。</p>
<h2>今後の焦点：ユーザー拡大と利用定着</h2>
<p>今夏中には全ユーザーへの招待提供を完了し、フィードバックを受けながらの改良フェーズに入る。Perplexityは今後の製品ロードマップにおいて、CometのAI機能をさらに高度化し、さまざまな業務・用途に応じたユースケース拡大を計画している。企業ユーザーや情報労働者にとって、単なる“検索の延長”にとどまらない生産性ツールとしての定着が、次の成長フェーズの鍵となる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https:%5Cu002F%5Cu002Farxiv.org%5Cu002Fabs%5Cu002F2506.21521">発表</a>{target=“_blank”}した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FA_schematic_representation_of_keystones_and_potemkins_e47033e684%5Cu002FA_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FPotemkin_Understanding_in_llm_5dae4e573b%5Cu002FPotemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FExamples_of_potemkins_f6c5140e2d%5Cu002FExamples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FIllustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72%5Cu002FIllustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>エンタメ＆アート2025/7/13 [SUN]Stability AI、AIポルノ生成を全面禁止へ──7月31日から利用規約改定、Stable Diffusion・API・OSSを含む全サービスで性的コンテンツを遮断</title>
      <link>https://ledge.ai/articles/stability_ai_policy_update_nsfw_ban</link>
      <description><![CDATA[<p>ロンドンを拠点とする生成AI企業Stability AIは、2025年7月31日付で同社サービスの利用規約（Acceptable Use Policy, AUP）を<a href="https:%5Cu002F%5Cu002Fstability.ai%5Cu002Fuse-policy">改定</a>{target=“_blank”}し、Stable Diffusionをはじめとする自社製AIモデル・API・オープンソースコードにおいて、性行為に関連するコンテンツの生成・使用を一律禁止する。</p>
<p>営利・非営利の区別なく適用されるこの新方針は、AIコンテンツの安全性と倫理性を確保する目的で導入されるという。</p>
<h2>性的コンテンツの生成・共有を包括的に禁止</h2>
<p><a href="https:%5Cu002F%5Cu002Fstability.ai%5Cu002Fuse-policy">新たな利用規約</a>{target=“_blank”}では、「We Prohibit Sexually Explicit Content」の項が新設され、以下の内容が禁止事項として明記された。</p>
<ul>
<li>性行為、性的行為、性的暴力を含むあらゆるコンテンツの生成・共有</li>
<li>非合意の親密画像（NCII: Non-Consensual Intimate Imagery）</li>
<li>違法ポルノや児童搾取コンテンツ</li>
</ul>
<p>これらの規定は、DreamStudio、Stable Diffusion（あらゆるチェックポイントや自己ホスト版）、Stable Video、Stable Audio、Platform API、LoRA（Low-Rank Adaptation）共有機能、さらにGitHubなどで配布されるオープンソースコードを含むすべてのサービスに適用される。</p>
<p>規約違反が判明した場合、Stability AIは利用停止や契約解除などの措置を取ると定めている。また、18歳未満の利用も引き続き禁止される。</p>
<h2>従来規約との大きな違い</h2>
<p>この改定は、2024年3月1日版の旧AUPと比較して大幅な変更となる。
<a href="https:%5Cu002F%5Cu002Fstability.ai%5Cu002Fprior-aup">従来の規約</a>{target=“_blank”}では、禁止対象は「非合意ヌード」「違法ポルノ」「児童搾取コンテンツ」などに限定されており、合意の成人同士によるポルノ的表現については明確な禁止はなかった。</p>
<p>新AUPでは、「性行為そのもの」に関わるコンテンツすべてを対象とすることで、生成物の内容に関わらず包括的な制限を設けている。</p>
<h2>デベロッパーとユーザーへの影響</h2>
<p>新規約の対象範囲には、以下のような商用・非商用ツールや資源が含まれる。</p>
<ul>
<li>公式Webアプリ「DreamStudio」</li>
<li>Stable Diffusion（オープンモデル、自己ホスト含む）</li>
<li>音声・映像生成ツール（Stable Audio／Stable Video）</li>
<li>各種APIアクセス、LoRAモデル共有、オープンソースコードの再利用</li>
</ul>
<p>営利・非営利の区別はなく、個人利用や趣味での創作であっても規約違反となる。既存のモデルやワークフローで対象となるコンテンツを扱っている開発者や企業は、今後の運用方針の見直しが必要となる。</p>
<h2>背景：AIポルノをめぐる規制の強化</h2>
<p>今回の規約改定は、AI技術を悪用した性的コンテンツの氾濫に対処する国際的な動きの一環と見られる。特にディープフェイク技術による著名人の偽ポルノ動画や、非合意の画像生成が社会問題化する中で、生成AIモデル各社はNSFW（Not Safe For Work）フィルタの強化やアダルトコンテンツの禁止に取り組んでいる。</p>
<p>Stability AIはオープンウエイトの提供で知られる企業のひとつであり、同社による包括的な制限の導入は、オープンモデル領域における規制の方向性に大きな影響を与える可能性がある。</p>
<h2>今後のスケジュールと対応</h2>
<p>新規約は2025年7月31日より施行される。以降は新規・既存ユーザーともに順守が義務づけられ、違反が確認された場合にはアクセスの遮断やアカウントの停止措置が取られる見通しだ。</p>
<p>同社は今後、利用者向けのFAQやガイドラインの公開も予定しており、具体的な基準や判断基準についての詳細は順次明らかにされるとみられる。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>耳で聞けない声を0.3秒で“見える化”──イェール大発スマートグラス「TranscribeGlass」一般販売開始</title>
      <link>https://ledge.ai/articles/transcribeglass_smartglasses_realtime_subtitles</link>
      <description><![CDATA[<p>2025年7月、イェール大学の学生チームが開発したスマートグラス「<a href="https:%5Cu002F%5Cu002Fwww.transcribeglass.com%5Cu002F">TranscribeGlass</a>{target=“_blank”}」の一般販売が開始された。聴覚障がい者や難聴者を主な対象とし、周囲の発話をリアルタイムで字幕としてレンズ上に表示することができる。平均0.3秒という低遅延表示を実現し、日本語を含む10以上の言語への翻訳にも対応しているという。</p>
<h2>会話を文字で「見る」──TranscribeGlassの概要</h2>
<p>TranscribeGlassは、専用アプリをインストールしたスマートフォンのマイクで周囲の音声を取得し、それをクラウド経由で音声認識・処理した上で、メガネ型デバイスの右レンズに字幕として表示する構造となっている。表示はウェーブガイド方式を採用し、640×480ピクセルの解像度で文字を右視野30度以内に映し出す設計だという。</p>
<p>表示までの遅延は平均0.3秒に抑えられ、音声認識精度は95％以上を謳っている。最大8時間稼働可能なバッテリーを内蔵し、重量は36〜38グラムに収められている。スマートグラス本体にはマイクやカメラは搭載されておらず、軽量性とプライバシーへの配慮を両立している点も特徴とされる。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fsmart_glass3_64b7665d4d%5Cu002Fsmart_glass3_64b7665d4d.jpg" alt="smart glass3.jpg" /></p>
<h2>販売価格と利用形態</h2>
<p>製品は<a href="https:%5Cu002F%5Cu002Fwww.transcribeglass.com">公式サイト</a>{target=“_blank”}で注文可能で、価格は本体が377ドル（約5万9,000円）、加えてクラウド音声認識機能を使用するための月額サブスクリプションが20ドル（約3,000円）となっている。2025年8月から出荷を予定しており、日本を含む国際配送にも対応するとのこと。</p>
<p>なお、アプリは現在iOS版が提供されており、Android版も年内にリリースされる見込み。また、オフラインモードも搭載されているが、この場合は音声認識精度がやや低下するとされる。</p>
<h2>想定利用シーンと対象ユーザー</h2>
<p>TranscribeGlassは、聴覚障がい者や加齢性難聴者の会話支援を主な用途とし、特に教室、会議、劇場、飲食店など騒音下での対話の可視化に有効とされる。また、語学学習者や国際会議の参加者など、リアルタイム翻訳による情報取得が必要なユーザーにも活用が期待されている。</p>
<p><strong>TranscribeGlassをプレゼントされ「あなたの言っていることが分かるわ！」と感激するユーザー</strong>
<img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002FAbout_smart_glass_a3840a78b4%5Cu002FAbout_smart_glass_a3840a78b4.jpg" alt="About smart glass.jpg" /></p>
<h2>開発背景と開発チーム</h2>
<p>この製品は、イェール大学の学生である<a href="https:%5Cu002F%5Cu002Fyaledailynews.com%5Cu002Fblog%5Cu002F2025%5Cu002F02%5Cu002F18%5Cu002Fyale-student-founds-transcribeglass-a-live-text-to-speech-transcription-device%5Cu002F">マダヴ・ラヴァカレ氏</a>{target=“_blank”}が中心となって開発された。</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fglasses_ag_Transcribe_Glass_scaled_bc37a50cad%5Cu002Fglasses_ag_Transcribe_Glass_scaled_bc37a50cad.jpeg" alt="glasses_ag_TranscribeGlass-scaled.jpeg" /></p>
<p>きっかけは、聴覚障がいを持つ友人が講義中の内容を十分に理解できない状況を目の当たりにしたことだったという。2018年から7年をかけて7代にわたるプロトタイプを開発し、2024年にはCTOとしてニルバイ・ナラン氏が参画。Y Combinatorなどからの資金調達を経て、今回の一般販売に至った。</p>
<p>これまでベータ版は500人以上に試用され、フィードバックをもとに改良が重ねられてきたという。</p>
<h2>競合との差別化と今後の展開</h2>
<p>他のスマートグラス製品と異なり、TranscribeGlassは通話・音楽再生・撮影などの多機能化を避け、字幕精度と軽量性に特化している点が特徴だ。価格設定もMeta×Ray-BanやXRAI Glassなどに比べて抑えられており、バッテリー持続時間の長さも差別化ポイントとなっている。</p>
<p>将来的には、リアルタイムでの感情解析を字幕に反映する機能や、ASL（アメリカ手話）向けに語順を変換する表示機能の搭載が計画されているという。</p>
<p>TranscribeGlassは、視覚的な情報支援により、耳で聞けない会話を「読む」体験へと変えることで、新たなコミュニケーションの可能性を提供しようとしている。</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/9 [WED]【ソースコード特典付き】自社専用LLMを低コストで実現！「Qwen3」の継続事前学習のデモンストレーション｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol65</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>Ledge.ai Webinar vol.65では、「ローカルLLMの大本命『Qwen3』の継続事前学習デモンストレーション」をテーマに、GPUクラウドサービス「GPUSOROBAN」を提供する株式会社ハイレゾ様をゲストにお迎えし、実演デモを交えながらご解説いただきます。</p>
<p>Alibaba社が開発したオープンソースの大規模言語モデル（LLM）「Qwen」シリーズの最新版「Qwen3」は、DeepSeek-R1やOpenAI o1をも凌ぐ性能を持つとされ、世界中の開発者から大きな注目を集めています。特に、プロンプトに応じて思考プロセスを切り替える「ハイブリッド推論」や、外部ツールを呼び出す「エージェント機能」といった先進的な機能を備えている点も特長です。オープンソースでありながら商用利用も可能なため、自社の環境でセキュアに活用できる高性能なローカルLLMとして、ビジネス応用の期待が非常に高まっています。
今回のウェビナーでは、この「Qwen3」をベースに、特定の専門知識を追加で学習させる「継続事前学習」に焦点を当てます。ゼロからモデルを開発する「フルスクラッチ」に比べ、計算リソースやコストを大幅に抑えながら、自社に特化した高性能モデルを構築できるこの手法について、デモンストレーションを通じて具体的に解説します。</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li><strong>高性能オープンソースLLM「Qwen3」の詳解</strong>
<ul>
<li>アーキテクチャ（MoE）、ハイブリッド推論、エージェント機能（Function Calling）など、Qwen3の先進的な特徴とビジネスにおける可能性</li>
</ul>
</li>
<li><strong>GPUクラウド「GPUSOROBAN」を活用した継続事前学習デモンストレーション</strong>
<ul>
<li>環境構築からデータセットの前処理、学習実行、推論までの一連のプロセスを実演</li>
</ul>
</li>
<li><strong>大規模モデル学習に不可欠な分散処理技術の解説</strong>
<ul>
<li>データ並列、モデル並列（パイプライン並列・テンソル並列）の基礎から、DeepSpeedやMegatron-LMといったフレームワークの活用法まで</li>
</ul>
</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>自社専用の高性能LLMを、コストを抑えて構築したい方</li>
<li>機密情報を扱うため、オンプレミスやセキュアなローカル環境でLLMを運用したい方</li>
<li>LLMに専門知識を追加する「継続事前学習」の具体的な手法を知りたいエンジニア</li>
<li>生成AIの学習・開発におけるGPUリソースの確保やコストに課題を感じている</li>
</ul>
<h2>視聴者特典</h2>
<p><strong>【特典①】デモで使用したサンプルコードをプレゼント！</strong>
本ウェビナーにお申し込みいただいた方には、デモで使用した「Qwen3の継続事前学習」のソースコードをプレゼントいたします。視聴後すぐに、ご自身の環境で再現・検証が可能です。</p>
<p><strong>【特典②】H200 GPU 30日間無料トライアルキャンペーン！</strong>
さらに、ハイレゾでは現在、「NVIDIA H200」を搭載したGPUクラウドサービス「AIスパコンクラウド」を30日間無料でお試しいただける特別なキャンペーンも実施中です。
（詳細はウェビナー内およびアンケート回答後のご案内をご確認ください。）</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fh200_gpu_free_trial1200_bd3d66cf05%5Cu002Fh200_gpu_free_trial1200_bd3d66cf05.jpg" alt="h200-gpu-free-trial1200.jpg" /></p>
<h2>登壇者情報</h2>
<p>株式会社ハイレゾ
GPU事業本部　マーケティング部　グループ長
山田 岳史</p>
<p><img src="https:%5Cu002F%5Cu002Fstorage.googleapis.com%5Cu002Fledge-ai-prd-public-bucket%5Cu002Fmedia%5Cu002Fhighreso_yamadasama_2a984e3aa6%5Cu002Fhighreso_yamadasama_2a984e3aa6.jpg" alt="highreso-yamadasama.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスの事業開発からマーケティング、技術サポートまで担当。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年7月9日(水)〜2025年7月29日(火)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https:%5Cu002F%5Cu002Fzfrmz.com%5Cu002FiXQrpCVKQZwYTU8kO3uy">ウェビナーの視聴はこちら</a>{target=“_blank”}
:::</p>
]]></description>
      <pubDate>Wed, 09 Jul 2025 04:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>