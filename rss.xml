<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Meta Reality Labs「ProMemAssist」：ユーザーの“話しかけていいタイミング”を推定するスマートグラス</title>
      <link>https://ledge.ai/articles/promemassist_smartglasses_meta</link>
      <description><![CDATA[<p>Metaの研究チームは2025年7月28日、ユーザーの作業メモリ状態をリアルタイムに推定し、声をかけるべきかどうかを判断するスマートグラス向けシステム「ProMemAssist」を<a href="https://arxiv.org/abs/2507.21378">発表</a>した。</p>
<p>視覚および音声から得られるマルチモーダル情報をもとに、タスク文脈や注意リソースを推測し、助言を送るべきか否かを計算する。論文はユーザーインタフェース技術の国際会議「UIST 2025」に採択された。</p>
<p><strong>ProMemAssist のシステム全体図。ユーザーの視覚・音声情報を取り込み、作業メモリモデルで現在のタスク文脈を推定し、適切なタイミングで音声アシストを通知する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/system_workflow_8d208f273c/system_workflow_8d208f273c.png" alt="system-workflow.png" /></p>
<h2>作業メモリモデルを実装した初のスマートグラス支援技術</h2>
<p>ProMemAssistは、ユーザーが現在何をしており、どの程度注意を割いているかを推定するために、認知心理学の作業メモリモデルを応用している。視覚（visuospatial）と音声（phonological）情報をそれぞれの短期記憶ストアに一時保存し、それらを統合して「エピソードバッファ」として文脈を把握する構成となっている。</p>
<p>たとえば、テーブルの上にある「フォーク」「スプーン」「ワインボトル」などの視覚情報と、「今夜は4人でディナーだ」といった音声から、ユーザーが「ディナーテーブルを準備している」と推論される。このように、ProMemAssistはユーザーの行動を「エピソード」としてメモリ上に保持する。</p>
<h2>「助言の価値」と「割り込みのコスト」を比較し、通知を制御</h2>
<p>助言を送信するかどうかは、LLM（大規模言語モデル）によって生成されたメッセージの「価値」と、現在のユーザーの作業状況に割り込む「コスト」とのバランスに基づいて判断される。メモリには容量制限があり、新しい情報が入るたびに、重要性や関連性が低い古い情報は置き換えられる。</p>
<p><strong>作業メモリ内の視覚・音声アイテムの構成。Recency（新しさ）、Relevance（関連性）、Importance（重要性）によってアイテムの保持／置換が決定される。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wm_displacement_e6750e4c01/wm_displacement_e6750e4c01.png" alt="wm-displacement.png" /></p>
<p>論文では、メモリアイテムには「新しさ（Recency）」「関連性（Relevance）」「重要性（Importance）」の3指標が与えられ、干渉を最小化するように情報が維持される様子が図示されている。アシストの例としては「フォークが足りないかもしれません」「ボトルを倒さないように注意してください」といった助言が生成され、タイミングを精査したうえで通知される。</p>
<p><strong>通知の可否判断フロー。現在のエピソードとの干渉度と、生成されたアシストの価値を比較し、通知の閾値を超える場合のみ提示される。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wm_interference_48a0b79e4e/wm_interference_48a0b79e4e.png" alt="wm-interference.png" /></p>
<h2>実証実験：助言回数は少なく、しかし有用</h2>
<p>ProMemAssistは、Meta Reality Labsの研究チームにより、12名の成人被験者を対象に実証実験が行われた。被験者は以下の4種類のタスクを実施し、それぞれにおいてアシストの有用性が検証された。
ディナーテーブルの設営
旅行カバンのパッキング
ワークスペースの整理整頓
趣味用品（バスケットボール、文房具など）の片付け</p>
<p><strong>ユーザー評価実験で実施されたタスク例。ディナーテーブル設営、旅行パッキング、ワークスペースの片付けなど、日常的な作業においてProMemAssistの有用性が検証された。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/task_setting_cd7937f7c3/task_setting_cd7937f7c3.png" alt="task-setting.png" /></p>
<p>比較対象として、タスク文脈を考慮せずにLLMが単に助言を生成・提示するベースラインが設定された。評価の結果、ProMemAssistは助言の数が少なかったにもかかわらず、被験者からの有用性スコアが高かった。また、NASA-TLXに基づくフラストレーションの評価指標においても有意に低下した（p = 0.043）ことが報告されている。</p>
<h2>プロトタイプ構成と将来的展望</h2>
<p>現段階では、ProMemAssistは商用ARグラスに外部カメラ・マイクを装着し、処理はノートPC上で行う構成となっている。システムは1秒ごとにユーザーの作業メモリ状態を更新し、必要に応じて音声でアシストを提示する。グラス自体にはスピーカーが非搭載のため、音声は外部端末から再生される。</p>
<p>今後は、オンデバイス処理の実装や、スピーカー内蔵型グラスとの統合により、完全スタンドアロンでの運用が見込まれている。また、対人コミュニケーションが重要な介護現場や接客業、共同作業環境での展開も視野に入れているという。</p>
]]></description>
      <pubDate>Sat, 09 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>トヨタ、「Woven City」Phase1を9月25日正式開業──ロケット企業含む12社が“実証都市”に参画</title>
      <link>https://ledge.ai/articles/toyota_woven_city_phase1_launch_2025</link>
      <description><![CDATA[<p>トヨタ自動車とウーブン・バイ・トヨタは2025年8月4日、静岡県裾野市で建設中の実証都市「Toyota Woven City（ウーブン・シティ）」のフェーズ1が、9月25日（木）に正式開業すると<a href="https://woven.toyota/jp/our-latest/20250804/">発表</a>した。開業に合わせ、ロケット開発を手がけるインターステラテクノロジズなど新たに12社が実証パートナープログラム「Inventors」に参画。これにより、同プログラムの参加企業は計19社に拡大した。</p>
<h2>360人が暮らす“リアルな検証都市”が始動</h2>
<p>Woven Cityは、実環境での技術実証を目的にトヨタが構想した未来型都市。フェーズ1では約4.7ヘクタール（47,000㎡）の敷地に、住宅や商業施設、オフィスなどを整備し、最終的に約360人の居住者（Weavers）が生活する予定。住民にはトヨタグループの従業員とその家族が中心となる。</p>
<p>都市内では、モビリティ、ロボティクス、エネルギー、水素インフラ、スマートホームなどの技術が導入され、実際の暮らしの中で継続的な実証が行われる。2026年度には、外部ビジターの受け入れも予定されている。</p>
<h2>Inventorsプログラムに12社が新規参画</h2>
<p>技術検証を担う企業群「Inventors」には、新たに12社が加わった。</p>
<ul>
<li><strong>インターステラテクノロジズ株式会社</strong> （宇宙関連）：ロケットの量産体制構築に向けた共同検証を計画</li>
<li><strong>共立製薬株式会社</strong> （ヘルスケア）：人とペットが共生する社会モデルを構築</li>
<li>トヨタグループの10社（株式会社豊田自動織機、株式会社ジェイテクト、トヨタ車体株式会社、豊田通商株式会社、株式会社アイシン、株式会社デンソー、トヨタ紡織株式会社、トヨタ自動車東日本株式会社、豊田合成株式会社、トヨタ自動車九州株式会社）</li>
</ul>
<p>上記12社に加え、同年1月に公表したダイキン工業株式会社、ダイドードリンコ株式会社、日清食品株式会社、UCCジャパン株式会社、株式会社増進会ホールディングス、およびトヨタとWbyTを合わせた計19社の参画が決まっているとのこと。</p>
<p>Inventorsは、都市内の住民からのフィードバックを得ながら、各社が製品やサービスをリアルな環境で検証し、社会実装を目指す取り組み。今後はトヨタ以外のスタートアップや研究機関も対象としたアクセラレータープログラムの実施が予定されており、その詳細は8月25日に発表される見通しだ。</p>
<h2>「CES 2020」構想から約5年、ついに都市が始動</h2>
<p>Woven Cityは、2020年の「CES」で構想が発表され、Bjarke Ingels Group（BIG）が都市設計を担当。全体では約70ヘクタールの敷地に段階的に建設される計画で、今回開業するフェーズ1はその最初の実装フェーズとなる。</p>
<p>道路は「自動運転専用」「歩行者＋パーソナルモビリティ」「自然散策路」の3層で構成され、“編まれた都市（Woven）”の名が示すとおり、人と技術が調和するインフラ構造が特徴とされる。</p>
<h2>今後の展望</h2>
<p>トヨタはWoven Cityを「モビリティカンパニー」への転換を象徴する実証都市と位置付け、都市機能を横断するオープンプラットフォームとして活用していく。9月の開業後は、参画企業と居住者の協働によるリアルなテストが順次進められ、2026年度以降には一般公開や外部連携も本格化する予定だという。</p>
]]></description>
      <pubDate>Sat, 09 Aug 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テキスト一行で3D世界が動く──Google DeepMind、新AIモデル「Genie 3」を公開</title>
      <link>https://ledge.ai/articles/genie_3_text_to_3d_world_generation</link>
      <description><![CDATA[<p>Google DeepMindは2025年8月5日、テキスト入力からインタラクティブな3D世界をリアルタイム生成できるAIモデル「Genie 3」を<a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/">発表</a>した。</p>
<p>Genie 3は、解像度720p・毎秒24フレームで再生可能な環境を生成し、ユーザーの行動に応じてオブジェクトの変化や環境の動的な反応を数分間維持できるという。生成された世界内では、キャラクターの移動や物体の操作、気象条件の変化なども即座に再現される。</p>
<h2>テキストから“遊べる世界”を即時生成</h2>
<p>Genie 3は、ユーザーが与えた短いテキストプロンプトや画像をもとに、実際に操作可能な世界を即座に構築するAIモデルである。入力は非常にシンプルで、「雷雨の夜の森」「宇宙船が着陸した火山地帯」といった自然言語だけで、複雑な3D環境が数秒で構築される。生成された環境は、プレイヤーが自由に歩き回り、オブジェクトに干渉できる設計になっている。</p>
<h2>Genie 2からの進化点</h2>
<p>前身である<a href="https://ledge.ai/articles/genie2_3d_world_model_ai_training">Genie 2</a>（2024年12月発表）では、画像を入力として2Dインタラクティブ環境を生成する機能が中心だった。これに対してGenie 3は、テキストだけで環境を立体的に構築し、3D的な物理挙動や環境変化を表現できる点が大きな進化とされる。また、Genie 3では、ユーザーの行動履歴を内部メモリとして保持することで、環境内の状態が継続的に更新される設計となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/unnamed_1_84e786f1a7/unnamed_1_84e786f1a7.webp" alt="unnamed (1).webp" /></p>
<h2>公開デモで示された生成性能</h2>
<p>YouTubeで公開されたデモ映像では、テキスト「a cyberpunk city in the desert」（砂漠の中のサイバーパンク都市）を入力すると、数秒でネオンが光る都市が生成され、プレイヤーキャラクターがその中を移動。さらに「a stormy forest」（嵐の森）といったプロンプトでは、雷が鳴り響く中で風に揺れる木々や飛散する葉がリアルタイムで描写され、環境内の天候も再現されていた。</p>
<p>@<a href="https://www.youtube.com/watch?v=PDKhUknuQDg&amp;t=1s">YouTube</a></p>
<h2>AGIへの布石としての位置づけ</h2>
<p>DeepMindは公式ブログで、Genie 3を「汎用エージェントの訓練に不可欠な『世界モデル（world model）』の進化形」と表現している。生成環境内での行動やフィードバックを通じて、エージェント（AI）がより効率的に学習できる場を提供することが目的であり、同社はこの技術をAGI（汎用人工知能）研究の基盤の一つとして位置づけている。</p>
<h2>今後の展開</h2>
<p>現時点では、Genie 3は招待制のテストプログラムを通じて一部の研究者・開発者に限定公開されている。今後数か月をかけて、学術研究機関やクリエイター向けにAPIやツールキットの段階的な提供が予定されているが、具体的な一般公開時期は明示されていない。</p>
<p>DeepMindの取り組みは、OpenAIの「World Simulation」やMetaの「Builder World」など、他の大手AI企業が展開する“世界生成AI”領域とも重なる。ロボティクスや自律エージェント開発において、リアルなシミュレーション環境は重要な役割を担っており、Genie 3の技術は、ゲーム開発・仮想教育・都市設計・産業訓練といった分野でも応用が期待される。</p>
]]></description>
      <pubDate>Sat, 09 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Gartner、「日本におけるクラウドとAIのハイプ・サイクル：2025年」を発表──AIエージェントが”過度な期待”のピークに、RAGは幻滅期へ</title>
      <link>https://ledge.ai/articles/gartner_cloud_ai_hypecycle_2025_japan</link>
      <description><![CDATA[<p>ガートナージャパン（以下Gartner）は2025年8月5日、日本市場におけるクラウドおよびAI関連技術の成熟度とビジネス価値に関する予測をまとめたレポート「日本におけるクラウドとAIのハイプ・サイクル：2025年」を
<a href="https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20250805-cloudai-hc">発表</a>した。</p>
<p>このレポートは、企業のITおよびビジネスリーダーがクラウドやAI技術の導入判断を行ううえでの指針となるもので、今回は計34の技術を「AI／産業革命」「クラウド」「マイグレーション」の3つの観点で位置づけている。</p>
<h2>クラウドの再定義──AIを支える基盤へ</h2>
<p>Gartnerはこのレポートにおいて、クラウド・コンピューティングという名称が登場して20年が経過する中、クラウドが企業の既存システムを支えるだけでなく、AIや生成AI、AIエージェント、エージェント型AI、マルチエージェントの開発を推進する基盤へと進化していると指摘した。</p>
<p>さらに、数億人規模のユーザーにAGI（Artificial General Intelligence：汎用人工知能）を提供可能なハイパーAIスーパーコンピュータへと変貌を遂げつつあるとしている。企業は、クラウドを単なるITインフラではなく、AIによる産業革命クラスのインパクトをもたらす基盤として捉える必要があるという。</p>
<h2>ハイプ・サイクルにおける注目技術の位置づけ</h2>
<p>レポートでは、34の技術を5つの成熟度段階に分類している。</p>
<h3>▸ 黎明期（17項目）</h3>
<ul>
<li><strong>エージェント型AI（エージェンティックAI）</strong></li>
<li><strong>MCP（Model Context Protocol）</strong></li>
<li><strong>A2A（Agent-to-Agent）プロトコル</strong></li>
<li><strong>フィジカルAI</strong></li>
<li><strong>M2C（Mainframe-to-Cloud）マイグレーション</strong></li>
<li>AIオーケストレーション</li>
<li>AIネットワーキング</li>
<li>AIファクトリ</li>
<li>World Model（世界モデル）</li>
<li>QCaaS（量子コンピューティング・クラウド・サービス）</li>
<li>インダストリAI</li>
<li>ハイパーAIスーパーコンピュータ</li>
<li>マルチエージェント・システム　など</li>
</ul>
<h3>▸ 過度な期待のピーク期（7項目）</h3>
<ul>
<li><strong>AIエージェント</strong></li>
<li><strong>V2C（Virtual-to-Cloud）マイグレーション</strong></li>
<li><strong>再仮想化</strong></li>
<li>LLM（大規模言語モデル）プラットフォーム・サービス</li>
<li>クラウドAIサービス　など</li>
</ul>
<h3>▸ 幻滅期（7項目）</h3>
<ul>
<li><strong>RAG（検索拡張生成）</strong></li>
<li><strong>IaC（Infrastructure as Code）</strong></li>
<li>クラウドネイティブ</li>
<li>クラウド・レジリエンス</li>
<li>サイト・リライアビリティ・エンジニアリング　など</li>
</ul>
<h3>▸ 啓発期・生産性の安定期</h3>
<ul>
<li>FinOps</li>
<li>プラットフォームエンジニアリング</li>
<li>インダストリクラウド</li>
<li>ソブリンクラウド</li>
<li>分散クラウド</li>
<li>BMaaS（サービスとしてのベアメタル）</li>
</ul>
<h2>技術動向の特徴と課題：AI技術の急速な進展と過熱リスク</h2>
<p>全般的にAIは、ベンダーの投資が非常に活発であると同時に、ユーザー側の関心も持続的に高まっており、実践的な取り組みも加速度的に進展している。Gartnerは、AIは比較的早い段階で成熟期に達すると予測している。</p>
<p>一方で、AI領域の多くのイノベーションは過熱（ハイプ）しやすい傾向があり、特に「エージェント型AI」はその典型だという。同社は、2027年末までにエージェント型AI導入プロジェクトの40%以上が、コストの高騰やビジネス価値の不明確さ、不十分なリスクコントロールを理由に中止になるとの見解を示している。</p>
<h2>クラウド技術の成熟化の遅れ</h2>
<p>クラウド関連技術は登場から相応の年月が経過しているにもかかわらず、企業における活用が限定的にとどまっており、成熟には想定以上の時間を要しているという。</p>
<h2>RAGの幻滅期への移行</h2>
<p>注目すべきは、多くの企業が取り組んでいるRAG（検索拡張生成）が幻滅期に入ったことだ。RAGの精度向上に苦心している企業が多く、この状況が続くと生成AI全体の期待度の低下につながる可能性があるとGartnerは警告している。</p>
<h2>Gartnerアナリストの見解</h2>
<p>GartnerのディスティングイッシュトVPアナリストである亦賀忠明氏は、以下のように述べている。
「企業は、クラウドを、既存システムのマイグレーション先としてのみならず、新たなビジネス・サービスの基盤、さらにはAIによる産業革命クラスのインパクトをもたらす基盤として捉える必要があります」</p>
<p>また、AIエージェントへの過度な期待について「AIエージェントウォッシングに留意しながら、過度な期待や過小評価に陥らず、自社に合った導入戦略と展開のタイミングを見極める必要がある。データ基盤整備や人材のケイパビリティ（スキル・マインドセット・スタイル）獲得を着実に進めていくことが重要」と助言している。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTTデータとMistral AI、欧州発の安全・持続可能なプライベートAIをグローバル展開へ</title>
      <link>https://ledge.ai/articles/nttdata_mistral_private_ai_partnership</link>
      <description><![CDATA[<p>NTTデータとMistral AIは2025年7月29日、安全性と持続可能性を両立させた企業向けプライベートAIソリューションの共同開発およびグローバル展開に関する包括的提携を<a href="https://uk.nttdata.com/news/ntt-data-mistral-ai-sustainable-secure-private-ai-enterprises">発表</a>した。両社は、金融・保険・公共セクターなど規制の厳しい業界を対象に、欧州およびアジア太平洋地域での提供を進める方針を示した。</p>
<h2>データ主権を巡る環境</h2>
<p>生成AIの活用が広がる中で、EUやアジア太平洋地域では個人情報保護規制やデータ主権に対応したAI導入が喫緊の課題となっている。こうした背景を受け、Mistral AIはオープンウェイトの大規模言語モデル（LLM）を提供する企業として注目されており、NTTデータは同分野におけるシステム構築と運用支援の実績を活かす形で協業に乗り出した。</p>
<p>今回の提携は、両社の強みを融合し、クライアント企業が社内データを安全に活用しつつ、環境負荷を抑えたAI活用を実現することを目的としている。</p>
<h2>提携の3つの柱：開発・実装・市場展開</h2>
<p>NTTデータとMistral AIは、以下の3点を柱とした取り組みを展開するとしている。</p>
<ul>
<li><strong>技術開発</strong> ：エネルギー効率の高いプライベートLLMの構築とチューニングを共同で行う。</li>
<li><strong>ユースケース実装</strong> ：欧州およびアジア太平洋地域を対象に、エージェント型コールセンターなどの業務にAIを実装。特に、規制産業に対応した自然言語処理モデルの導入が想定されている。</li>
<li><strong>共同販売体制</strong> ：フランス、ルクセンブルク、スペイン、シンガポール、オーストラリアにおいて営業チームを共同編成し、サービスの市場浸透を図る。</li>
</ul>
<p>この提携における実装第1弾として、知的財産管理大手のDennemeyer社との協力による特許情報検索AIアプリケーションの開発が進められている。また、ルクセンブルクでは同国の金融業界向けに、AI活用を支える“ソブリンAI”インフラの構築を進行中だという。</p>
<h2>両社の体制と今後の展開</h2>
<p>NTTデータは、Mistral AIとの協業を推進する専門組織「Mistral AI Center of Excellence」を設立し、1,000人規模の体制で支援を行う。また、Mistral AIは、NTTデータの技術者を対象に認定プログラムや技術トレーニングを提供する計画で、技術面での連携も強化される。</p>
<p>今後は、業界別モデルや多言語対応型モデルの共同開発を予定しており、特に日本語・フランス語に最適化されたLLMの実装も視野に入っている。さらに、低炭素なデータセンター活用によってAI運用時のScope 3排出量を削減し、企業のサステナビリティ戦略にも寄与する方針だ。</p>
<p>NTTデータのCEOであるAbhijit Dubey氏は、「責任あるAIを社会実装することが我々の使命であり、本提携はそのための重要なステップである」と述べている。一方、Mistral AIのCEOであるArthur Mensch氏は、「最高水準のプライバシーと制御性を備えたAIソリューションを提供する」として、主権型AIの価値を強調した。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、最新AI基盤モデル『GPT-5』を発表 — 誤差性能を大幅向上させ、既存製品ラインを統合した成熟の新エンジン、無料ユーザーを含む全ユーザーに提供開始</title>
      <link>https://ledge.ai/articles/gpt5_launch_all_users</link>
      <description><![CDATA[<p>OpenAIは2025年8月7日（現地時間）、最新の生成AIモデル「GPT-5」を<a href="https://openai.com/index/introducing-gpt-5/">発表</a>した。</p>
<p>推論能力・速度・応答品質を向上させた統合型エンジンで、ChatGPTでは無料ユーザーを含む全ユーザーが利用可能となる。発表は同社本社からのライブ配信で行われ、CEOサム・アルトマン氏が「私たちがこれまでに作った中で最も知的で、最も使いやすいAIだ」と述べ、教育や創作支援、ビジネス利用など幅広い活用を呼びかけた。</p>
<h2>GPT-5の概要と提供範囲</h2>
<p>GPT-5は、推論特化の「Thinking」、高速応答の「Fast」、リアルタイム会話の「Realtime」という3つのモデルを統合した新アーキテクチャを採用。利用状況やタスク内容に応じて最適なモデルを自動的に切り替える。</p>
<p>ChatGPTでは無料・有料すべての利用者に提供され、従来必要だったモデル選択が不要になった。開発者向けには、API経由でStandard／Mini／Nanoの3サイズが提供される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt_5_mano_mini_c973a3ace2/gpt_5_mano_mini_c973a3ace2.jpg" alt="gpt-5 mano mini.jpg" /></p>
<h2>技術的特徴と性能向上</h2>
<p>GPT-5は「Ph.D.級」の推論能力を備え、従来モデルと比べて知性・速度・信頼性のすべてを向上。コーディング分野ではSWE-Benchベンチマークで74.9%のスコアを記録し、前世代（o3）の69.1%を上回ったという。
トークン効率の改善や、コード内のバグ検出精度の向上も報告されている。UIデザインや文章生成の品質も向上し、専門領域から日常利用まで幅広いニーズに対応する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/coding_chart_4_side_ba38108ba3/coding_chart_4_side_ba38108ba3.jpg" alt="coding chart (4)-side.jpg" /></p>
<h2>ライブ配信での発表とデモ</h2>
<p>発表イベントでは、CEOのアルトマン氏が次のように語った。
「GPT-5は、あなたが知っている最も賢い人物を超える知性を持ち、その力をポケットの中に届けます。これからの時代、この技術はあらゆる人の生活と仕事の一部になるでしょう。」
開発チームは、教育分野での個別学習支援、創作活動のアイデア生成、ビジネスにおける資料作成や分析などのデモを披露。無料ユーザー解放の方針や、誤情報削減・応答検証などの安全性向上策についても説明した。</p>
<h2>開発者向け提供</h2>
<p>APIでは、処理速度やコストのバランスを選べる3サイズを用意。トークン数やツール呼び出し回数を削減する効率化も実現している。
ソフトウェア開発支援ツールを提供するCursor社のCEOは、「隠れたバグを見抜く能力は、我々が見た中で最も優れている」と評価している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_cursor_d4299f865f/gpt5_cursor_d4299f865f.jpg" alt="gpt5 cursor.jpg" /></p>
<h2>今後の展望</h2>
<p>GPT-5は、Microsoft Copilotなどのパートナー製品にも順次展開される予定。OpenAIはモデル統合によるユーザー体験の簡略化を今後も進め、安全かつ信頼性の高いAIの普及を目指すとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=0Uu_VJeVVfo">YouTube</a></p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/8 [FRI]キリン、AI 役員「CoreMate」を経営戦略会議に常設──12 人格 × 10 年分データで意思決定を高速化</title>
      <link>https://ledge.ai/articles/kirin_ai_exec_coremate_decision_support</link>
      <description><![CDATA[<p>キリンホールディングス株式会社は2025年8月4日、独自開発したAI役員「CoreMate（コアメイト）」を2025年7月以降のキリングループ経営戦略会議に本格導入したと<a href="https://www.kirinholdings.com/jp/newsroom/release/2025/0804_02.html">発表</a>した。</p>
<p>CoreMateは、12の専門人格によって構成され、同社が過去10年間に蓄積してきた取締役会・経営戦略会議の資料や外部情報を学習済み。経営層の“右腕”として、多面的な論点提示やディスカッション支援を行うことで、意思決定の高度化とスピードアップを目指す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub2_4aefc3e255/sub2_4aefc3e255.jpg" alt="sub2.jpg" /></p>
<p>CoreMateは、経営戦略や重点テーマに対して12の異なる人格がそれぞれの立場・視点で意見を提示し、リアルタイムに論点を深堀りする。たとえば「サステナビリティ」「リスク管理」「ブランド戦略」といった専門性を持つ人格が、会議中に起案内容へフィードバックを加えることで、経営層は従来よりも多角的かつ迅速に判断を下せるようになる。</p>
<p>AIの基盤には、キリンホールディングスが過去10年間に実施した取締役会および経営戦略会議の議事録、関連資料、さらに外部の最新市場情報などが学習データとして組み込まれている。会議前には起案者がCoreMateと対話形式で資料のブラッシュアップを行う「壁打ち機能」も備えられており、資料の質向上と準備時間の短縮が期待されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_e503abd6a4/sub1_e503abd6a4.png" alt="sub1.png" /></p>
<p>CoreMateの活用は、グループ全体で年間30回以上実施される経営戦略会議を中心に進められており、今後は取締役会やグループ内の事業会社における戦略会議への導入も検討されている。また、リアルタイムでの議論の可視化や、より自然な対話が可能な会話型インターフェースの追加開発も視野に入れているという。</p>
<p>この取り組みは、同社が掲げる長期的なデジタル戦略「KIRIN Digital Vision 2035（KDV2035）」の一環として位置づけられており、「人がやらなくてよい仕事をゼロにする」「人と共に価値を生み出す仕事を加速する」という2本柱を支える中核技術とされている。CoreMateは、同ビジョンの実現に向けた象徴的なプロジェクトと位置づけられており、人的リソースの最適化と経営スピードの両立を支援する。</p>
<p>キリンホールディングスは、AI技術の実装を通じて経営判断におけるデータ駆動型の意思決定を強化し、持続的な成長と市場環境への柔軟な対応を図る構えだ。</p>
]]></description>
      <pubDate>Fri, 08 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>イーロン・マスク氏のNeuralink、英NHSと提携し欧州初の臨床試験へ──脳チップ競争激化、競合Synchronは“思考でiPad操作”映像公開</title>
      <link>https://ledge.ai/articles/neuralink_uk_trial_vs_synchron_ipad_demo</link>
      <description><![CDATA[<p>イーロン・マスク氏が率いるスタートアップ企業Neuralinkは2025年8月1日、イギリス・ロンドンおよびニューカッスルで、同社の脳インプラント「N1」を用いる臨床試験「GB-PRIME」を開始すると<a href="https://neuralink.com/updates/gb-prime-study-launch/">発表</a>した。対象は四肢まひを伴う神経疾患患者で、思考によってデジタルおよび物理デバイスを操作できるかを評価する。Neuralinkにとって欧州初の臨床試験となるこの動きに先立ち、競合のSynchronは脳内デバイスでiPadを操作する様子を公開し、脳コンピュータ・インターフェース（BCI）分野の国際競争が激化している。</p>
<h2>脳とマシンをつなぐ「BCI」、Neuralinkの米国試験から始動</h2>
<p>脳–コンピュータ・インターフェース（BCI）は、脳の神経活動を読み取って信号処理し、コンピュータや機械装置を直接制御する技術である。Neuralinkは2016年に創業され、BCIを通じて四肢まひ患者が意思を持って機器を操作できる未来を目指している。</p>
<p>同社が開発した「N1」インプラントは、直径約25mm、厚さわずか8mmの円盤型デバイスで、1024個の電極を内蔵し、64本の極細なスレッドを脳の運動皮質に挿入する。これらのスレッドは、同社製の手術ロボット「R1」によって自動的に埋め込まれる。</p>
<p>米国では2024年1月、FDA（米食品医薬品局）の承認を得て、初のヒト臨床試験「PRIME Study（Precise Robotically Implanted Brain–Computer Interface）」し、最大10人を対象とする早期治験。2025年7月時点で5人の被験者にN1を埋め込み済みで、信号安定性とデバイス操作能力のデータ収集が続く。</p>
<p><strong>Neuralink初の被験者が思考でオンラインチェスをプレイする様子</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/neuralink_live_chess_2c1ffce5c1/neuralink_live_chess_2c1ffce5c1.jpg" alt="neuralink live chess.jpg" /></p>
<h2>米国から欧州へ、Neuralinkが臨床の舞台を拡大</h2>
<p>Neuralinkは2024年、米国での初のヒト臨床試験「PRIME Study」で、すでに5人の被験者に脳インプラント「N1」を埋め込んでいる。今回の「GB-PRIME」はこの米国での知見を基に、英国における同様のプロトコルでの評価を目的とした臨床試験であり、同社にとって欧州初の展開となる。</p>
<h2>「GB-PRIME」の試験概要と対象</h2>
<p>試験は以下の2つの病院を拠点に行われる：</p>
<ul>
<li>University College London Hospitals（UCLH）</li>
<li>Newcastle upon Tyne Hospitals
対象となるのは、脊髄損傷や筋萎縮性側索硬化症（ALS）などにより重度の四肢まひを持つ最大7人の患者。Neuralinkは、被験者の脳内に直径25mm、1024の電極を備えたN1デバイスを自社開発の手術ロボット「R1」によって自動的に埋め込む。</li>
</ul>
<p>試験では、脳波信号の安定性、安全性、ならびに思考によるカーソルや機器の操作能力を主要な評価項目とする。</p>
<h2>英国当局の規制承認を取得済み</h2>
<p>同試験は、英国医薬品・医療製品規制庁（MHRA）によって治験申請（Clinical Trial Authorization：CTA）が承認され、研究倫理審査委員会（Research Ethics Committee：REC）も通過している。取得されたデータは、英国のデジタル医療規格に準拠して管理されるという。</p>
<h2>Synchronが公開した“iPadを思考で操作”の実演映像</h2>
<p>Neuralinkの欧州進出と時期を同じくして、競合であるSynchron（米国）は、脳に埋め込んだデバイス「Stentrode」によって思考だけでiPadを操作する様子を撮影したデモ動画を8月4日にYouTube上で<a href="https://www.youtube.com/watch?v=YK8r5vdpozA">公開</a>した。映像では、患者が文字入力やアプリ起動、ホーム画面の操作を行う様子が確認できる。</p>
<p>SynchronのStentrodeは、開頭手術を必要とせず、頸静脈経由で血管内にデバイスを留置する「低侵襲」な手法を採用している。すでに10人以上に埋め込まれており、Appleの新しいBCI HID（Human Interface Device）プロトコルに対応したソフトウェアとの統合も進行中とされている。</p>
<p>@<a href="https://www.youtube.com/watch?v=YK8r5vdpozA">YouTube</a></p>
<h2>競争激化するBCI分野、資金調達も活発化</h2>
<p>Neuralinkは2025年7月に約6億5000万ドルの資金を新たに調達し、累計調達額は約13億ドル、企業評価額はおよそ90億ドルに達したとされている。一方、SynchronもシリーズCまでで1億ドル以上を調達しており、Bezos ExpeditionsやARCH Venture Partners、Khosla Venturesなどが出資。2026年の米FDAへの正式な製品承認申請を予定しているという。</p>
<h2>今後の展望</h2>
<p>Neuralinkは、今後カナダやUAEなど複数の国で同様の臨床試験を展開する計画を明かしている。イーロン・マスク氏は「最終的には健常者への認知機能拡張も視野に入れている」と発言しており、倫理的・規制的課題との対話が引き続き焦点となる見通しだ。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Hugging Face CEO、「コードを書くようにLLMも自前で訓練すべき」と訴え――Nanotron公開で“企業製AI”の時代が現実味</title>
      <link>https://ledge.ai/articles/custom_llm_huggingface_nanotron</link>
      <description><![CDATA[<p>Hugging FaceのCEOであるClément Delangue氏は2025年8月4日、自身のX（旧 Twitter）に<a href="https://x.com/ClementDelangue/status/1952048356710039700">投稿</a>し、「すべてのテクノロジー企業は、Deepseek R1  Llama、GPT-5といった 独自の大規模言語モデル（LLM）を訓練でき、かつ訓練すべきだ」と呼びかけた。</p>
<p>投稿には「Every tech company can and should train their own Deepseek R1, Llama or GPT5, just like every tech company writes their own code.」という一文が添えられており、ソフトウェア開発の延長としてモデル開発を捉えるべきだとのメッセージが込められている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/clement_delangue_32591c644f/clement_delangue_32591c644f.jpg" alt="clement delangue.jpg" /></p>
<h2>専用LLM開発のハードルはすでに下がった</h2>
<p>Delangue 氏が “自社訓練” を促す背景には、近年のコスト低減とオープンソース化の進展がある。たとえば 2024 年末に公開された Deepseek R1 は推定 550 万ドルで訓練されたとされ、同規模モデルとしては低コストの事例となった。さらに Meta の Llama 3、そして OpenAI が次期フラッグシップとして準備を進める GPT-5 も、フォークや追加学習を前提に採用されるケースが増えている。
クラウド型 GPU クラスタや公開データセットが急速に整い、かつては巨額の資金を要した LLM 訓練が中堅企業でも射程に入る環境が整いつつある。</p>
<h2>Nanotronが後押しする“作れる AI”</h2>
<p>Hugging Face は7月30日、分散学習フレームワーク 「Nanotron」 と、その運用ノウハウをまとめた 「Ultra-Scale Playbook」 をProプラン加入者向けに無料提供 すると発表した。Delangue氏は X で「Free for @huggingface pro users」と明言しており、同社の有償サブスクリプション（個人25ドル／月〜）に登録している開発者が追加コストなく利用できる仕組みだ。</p>
<p>Playbook には</p>
<ul>
<li>100億パラメータ超モデル を訓練するステップバイステップ手順</li>
<li>GPU クラスタ最適化や障害対応などの実務ノウハウ</li>
<li>Databricks や Lambda Labs など外部インフラとの接続例
が収録されており、研究機関・スタートアップが“自社LLM”に踏み出す際のガイドとして機能するという。</li>
</ul>
<h2>企業が自前モデルに踏み切る理由</h2>
<p>Delangue氏の主張は、すでに複数の産業分野で進む「自社専用LLM」開発の潮流と一致する。とくに以下のようなニーズに対応する目的で、LLMを自社開発・内製化する動きがみられる。</p>
<ul>
<li><strong>機密データの保持</strong> ：顧客情報や製造ノウハウなど、外部クラウドに預けられないデータを安全に活用可能</li>
<li><strong>推論コストの削減</strong> ：自社ホスティングにより、API利用料の継続的負担を回避</li>
<li><strong>法令・ガバナンスへの準拠</strong> ：業界ごとのコンプライアンス要件に合わせたモデル調整が容易
他方で、GPU 調達競争や高品質データの確保、人材不足といった課題は依然として残る。</li>
</ul>
<p>Delangue氏の発言は、AI業界が「買うAI（API利用）」から「作るAI（内製モデル）」へのシフトを迎えているという見方を反映している。今後は、独自モデルをいかに迅速に開発し運用できるか が企業競争力の重要指標となりそうだ。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT、週次利用者7億人へ──3月から2億人増、1年で4倍に</title>
      <link>https://ledge.ai/articles/chatgpt_weekly_users_700_million</link>
      <description><![CDATA[<p>2025年8月4日、米OpenAIは、対話型AI「ChatGPT」の週間アクティブユーザー（WAU）が今週中にも世界で7億人を超える見通しであることを明らかにした。これは、同社プロダクト責任者ニック・ターレイ氏がX（旧Twitter）上に<a href="https://x.com/nickaturley/status/1952385556664520875">投稿</a>した内容および関連報道に基づく。3月末時点でのWAUは5億人であり、約4カ月で2億人の増加となる。2024年時点と比較すると、年間で約4倍の成長となる。</p>
<h2>新機能と法人利用の拡大</h2>
<p>急成長の要因として、2025年3月に追加されたGPT-4ベースの高精度画像生成機能や、会話の文脈を継続して記憶できる「メモリ機能」など、ユーザーの実用性を高めるアップデートが影響しているとみられる。また、法人向けのChatGPT Enterpriseプラン契約社数も増加傾向にあり、2025年6月時点で500万社に達したことが報告されている。これは3月時点から200万社の増加に相当する。</p>
<p>アプリ市場調査会社Sensor Towerによると、ChatGPTの1ユーザーあたりの平均利用頻度は月12日以上、1日の平均利用時間は約16分とされている。</p>
<h2>年間売上は20億ドル超　評価額は5,000億ドル視野に</h2>
<p><a href="https://www.reuters.com/business/openai-eyes-500-billion-valuation-potential-employee-share-sale-source-says-2025-08-06/">ロイター</a>の報道によると、OpenAIの収益性も急速に高まっており、ChatGPT関連事業を含めた年間売上は20億ドル（約2,800億円）を超えるとの市場推計が出ている。また、社員保有株の売却計画に関連して、同社の企業評価額は5,000億ドル（約70兆円）規模に達する可能性があると報じられている。</p>
<h2>競合との競り合いが激化　GoogleやAnthropicも拡大路線へ</h2>
<p>業界全体としては、Googleの「Gemini」アプリが月間4億5,000万MAU（Monthly Active Users）を維持しており、OpenAIと並んで高い利用者数を記録している。また、Anthropicが開発するClaudeなどの他の大手モデルもユーザー獲得を進めており、生成AI市場におけるシェア争いが一層激化している。</p>
<h2>今後の展開：ポケット内デバイスで稼働する超高性能AIを示唆</h2>
<p>OpenAIは次世代モデル「GPT-5」を開発中と報じられており、2025年8月中にも発表される可能性が指摘されている。あわせて、ChatGPTには生活支援やメンタルヘルスなどウェルネス領域の機能強化が計画されているとの情報もある。
8月6日には、同社のサム・アルトマン最高経営責任者（CEO）がXで次のように投稿した。</p>
<p>someday soon something smarter than the smartest person you know will be running on a device in your pocket, helping you with whatever you want.</p>
<p>this is a very remarkable thing.</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/remarkable_thing_sama_gpt5_30a5cb690c/remarkable_thing_sama_gpt5_30a5cb690c.jpg" alt="remarkable thing sama gpt5.jpg" /></p>
<p>アルトマン氏は、ポケット内のデバイス上で“最も賢い人物より賢い”AIが近い将来稼働するとの見通しを示した。</p>
]]></description>
      <pubDate>Thu, 07 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI が“OSS 戦線”に参入：推論最適化モデル『gpt-oss』、Hugging Face と GitHub で即日配布</title>
      <link>https://ledge.ai/articles/openai_gpt_oss_open_weight_release</link>
      <description><![CDATA[<p>OpenAIは米国時間の2025年8月5日、推論最適化されたオープンウェイト言語モデル<a href="https://openai.com/open-models/">「gpt-oss-120b」と「gpt-oss-20b」</a>を発表し、同日中にHugging Face、GitHub、AWS上で<a href="https://openai.com/index/introducing-gpt-oss/">一般公開</a>した。</p>
<p>両モデルはApache 2.0ライセンスの下で提供され、商用利用や改変、再配布が自由に許可されている。o4-mini相当の性能を備えながらも、80GB GPUまたは一般的な16GBメモリのローカル環境での動作を想定しており、開発者や研究者が安全性と性能を両立したLLMを自前のインフラ上で運用できることを目指すとしている。</p>
<h2>ローカル運用を前提としたMoE構造、2モデル同時公開</h2>
<p>gpt-oss-120bは、36層・128エキスパート構成のMixture-of-Experts（MoE）アーキテクチャを採用しており、推論時には同時に4つのエキスパートのみが活性化される設計となっている。これにより、アクティブなパラメータは約33Bに抑えられ、メモリ効率を向上させた。gpt-oss-20bも同様の構成で、こちらは32エキスパート・24層構造で、一般的な16GBメモリのPC環境でも実行可能とされている。</p>
<p>両モデルは最大128kトークンの長文コンテキストに対応し、推論モードも3段階（low、medium、high）で調整可能。すべてのChain-of-Thought（CoT）出力を開示することで、透明性と制御性を両立している。</p>
<h2>o4-miniと同等の性能、ヘルスケア分野では上回る評価も</h2>
<p>OpenAIによると、gpt-oss-120bはMMLU、HellaSwag、AI2 Reasoning Challenge（ARC）、AIME2025といった代表的なベンチマークにおいて、ChatGPT搭載モデルであるo4-miniと同等の推論性能を発揮している。特に、ヘルスケア分野の評価セットであるHealthBenchなどでは一部で上回る結果も見られたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt_oss_model_performance_a5920564a4/gpt_oss_model_performance_a5920564a4.jpg" alt="gpt oss model performance.jpg" /></p>
<p>軽量版の20bモデルも、同社のo3-miniより高い精度を示すタスクが複数確認されており、軽量ながらも高性能な選択肢として注目される。</p>
<h2>Apache 2.0 ライセンスでの公開と配布形態</h2>
<p>今回のgpt-ossは、Apache 2.0ライセンスの下で公開されている。これにより、商用利用や改変、再配布が広く許容され、企業や研究者にとって導入ハードルが大きく下がる。</p>
<p>モデルは<a href="https://openai.com/index/gpt-oss-model-card/">モデルカード</a>、GitHubのリポジトリ、Dockerコンテナ、Ollamaレシピなどを通じて提供されており、AWS BedrockやSageMakerなどとも統合されている。インフラ制約のある現場でも、即座に利用できる設計となっている。</p>
<h2>Preparedness Framework に基づく安全性評価と外部レビュー</h2>
<p>OpenAIは、本モデルをリリースするにあたり、自社の「Preparedness Framework」に基づく<a href="https://ledge.ai/articles/openai_preparedness_safety-advisory-group">安全性評価</a>を実施したと説明している。悪意ある利用を想定したadversarial fine-tuningや外部専門家によるリスクレビューを経たうえで、「生物学的合成、サイバー攻撃、化学兵器の設計といった高リスク能力には到達していない」と判断し、公開に踏み切った。</p>
<p>また、全ての推論に対するChain-of-Thought（思考過程）の開示によって、モデルの透明性と制御性を向上させており、開発者に対しても「責任ある利用と検証」を促している。</p>
<h2>企業・研究機関での先行導入とOSSコミュニティへの期待</h2>
<p>gpt-ossの公開に伴い、AI Sweden、Orange、Snowflakeなどの企業・研究機関がすでに導入を開始しており、リアルタイムデータ処理や独自評価基盤の構築などでの活用が進んでいる。OpenAIは今後、開発者からのフィードバックを集め、次世代モデルの設計や安全性強化に役立てる方針も示している。</p>
<p>このリリースは、Metaの「Llama 3」やMistral、DeepSeekといった他のOSSモデル群に対抗する形で、OpenAIが再び“開放”に舵を切った動きと位置付けられる。これにより、生成AIの開発エコシステムにおける「クローズド vs オープン」の構図にも変化が生じる可能性がある。</p>
<h2>Altman氏「これは世界で最も使いやすいオープンモデル」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt_oss_sama_a2095daa89/gpt_oss_sama_a2095daa89.png" alt="gpt oss sama.png" /></p>
<p>OpenAIのサム・アルトマンCEOは同日のX投稿で「gpt-ossは最先端のオープンウェイト推論モデルであり、o4-miniに匹敵する実性能をローカル環境（小型版はスマートフォンでも動作）で発揮できる。世界で最も使いやすいオープンモデルだと信じている」と述べた。この発言は、“閉鎖”中心と見られてきたOpenAIが本格的にOSS領域へ踏み込む姿勢を示すものであり、開発者コミュニティに向けた強いメッセージとなっている。</p>
]]></description>
      <pubDate>Wed, 06 Aug 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMO対策でAI検索最適化──GMO NIKKO、「GMO AI最適化ブースト」提供開始</title>
      <link>https://ledge.ai/articles/llmo_optimization_gmo_ai_boost</link>
      <description><![CDATA[<p>GMO NIKKOは2025年8月1日、生成AIによる検索結果で企業の公式情報が引用・表示されやすくなるよう支援する新サービス「GMO AI最適化ブースト」の提供を開始したことを<a href="https://www.koukoku.jp/release/250801/">発表</a>した。</p>
<p>サービスは、LLMO（Large Language Model Optimization）に対応し、ChatGPT、Gemini、Google AI Overviewsなどの主要生成AIを対象に、情報構造やコンテンツを最適化する。GMO NIKKOは、生成AI分析ツールを提供するAI Hackと業務提携し、企業サイトの調査から改善までをワンストップで支援する体制を整えたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gmo_llmo_65892443be/gmo_llmo_65892443be.jpg" alt="gmo llmo.jpg" /></p>
<h2>AI主導の「ゼロクリック検索」への対応が急務に</h2>
<p>生成AIの普及により、検索ユーザーがAIの回答のみで情報収集を完結させる「ゼロクリック検索」が拡大している。この動きにより、従来のSEO施策だけでは企業の公式情報が検索経路から外れやすくなる傾向が強まっている。</p>
<p>調査会社Gartnerは「2026年までに従来型の検索トラフィックが25％減少する」と予測しており、生成AIに最適化された新たな広報・情報発信戦略が求められている。</p>
<h2>AIに“引用される”情報構造を構築</h2>
<p>「GMO AI最適化ブースト」では、以下の支援を通じて生成AIに引用されやすい情報環境の構築を目指す。</p>
<ul>
<li><strong>可視性診断</strong> ：ChatGPTやGemini、Google AI Overviewsなどにおける自社情報の掲載状況を5つの指標でスコア化。</li>
<li><strong>競合との比較分析</strong> ：他社との引用・露出の差分を可視化し、優先的に改善すべき領域を特定。</li>
<li><strong>技術的最適化支援</strong> ：schema.orgによる構造化、FAQ整備、llms.txt設定などでAIが情報を正確に解釈できる構造を整備。</li>
<li><strong>生成AI向けコンテンツ制作</strong> ：AIが引用しやすい形式でFAQ、用語集、専門記事などを制作。</li>
<li><strong>サイテーション強化</strong> ：信頼性向上のため、外部メディアや権威サイトでの第三者言及を促進。</li>
<li><strong>継続的な可視化レポート</strong> ：AIによる引用状況を月次でレポートし、改善提案を実施。</li>
</ul>
<p>これらの施策は、AI Hackの分析ツールと50項目を超える独自チェックリストをもとに実行される。</p>
<h2>今後の展望</h2>
<p>同サービスはGMO NIKKOが直接提供し、料金は個別見積もり方式（2025年8月時点で価格は非公開）で対応する。</p>
<p>同社は今後、「GMO AI最適化ブースト」を生成AI時代における新たな広報施策の業界標準として展開していく方針だ。あわせて、レピュテーション管理や危機対応などを含む周辺ソリューションの拡充にも取り組むとしている。</p>
]]></description>
      <pubDate>Wed, 06 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Autopilot死亡事故で2億4,300万ドル賠償──Teslaは控訴表明もXで「手動運転は過去の遺物」と意に介さず</title>
      <link>https://ledge.ai/articles/tesla_autopilot_liability_verdict_2025</link>
      <description><![CDATA[<p>2025年8月1日、フロリダ州マイアミの連邦地裁で、Teslaの運転支援機能「Autopilot」に関連する2019年の死亡事故をめぐる民事訴訟の評決が下された。陪審団は、事故の責任の一部がTeslaにあると判断し、同社に対し2億4,300万ドル（約360億円）の損害賠償金の支払いを命じた。このニュースは、<a href="https://www.nbcnews.com/news/us-news/tesla-autopilot-crash-trial-verdict-partly-liable-rcna222344">NBC</a>など複数の米メディアが同日報じた。一方でTeslaは、同日公式X（旧Twitter）アカウントにて「手動運転は過去の遺物」とも取れる投稿を行い、判決と対照的なスタンスを示した。</p>
<h2>フロリダ州での事故、Autopilot作動中に歩道の人を死亡させる</h2>
<p>事故が発生したのは2019年4月25日、フロリダ州デルトラビーチ。Tesla Model Sが赤信号の交差点に進入し、路肩に停車していたSUVに衝突。衝突の影響で歩道にいた22歳のナイベル・ベナビデス・レオン氏が死亡し、同乗していた男性も重傷を負った。</p>
<p>裁判では、事故当時にAutopilotが作動していたこと、本来は高速道路向けに設計された同機能が信号や交差点のある一般道路でも使用可能だった点、さらにドライバーの注意散漫時に作動する警告機能の有効性などが争点となった。</p>
<p>複数の報道によれば、陪審はドライバーに67％、Teslaに33％の過失があると認定。損害賠償金は補償的損害1億2,900万ドル、懲罰的損害2億ドルで構成されており、懲罰的損害の全額がTeslaに対して課された。</p>
<h2>控訴の方針とSNS投稿の温度差</h2>
<p>報道によれば、Teslaはこの判決について「事実に反する」として控訴する方針を示している。</p>
<p>判決が報じられた日、同社は公式Xアカウントに
“In the future, people will find it wild that manual driving was a daily task, not a weekend thrill”（訳：将来の人々にとって、手動運転が毎日の作業だったなんて信じられないことになるだろう）と<a href="https://x.com/Tesla/status/1952102455405171036">投稿</a>。</p>
<p>この投稿には、歩行補助器を使う高齢女性が「昔の人は、重さ2トンもの“走る凶器”を時速70マイルで、疲れていようが気が散っていようが――もっとひどい状態でも――毎日のように運転していたのよ」と話しているのに対し、付き添いの若い女性が「Sure grandma, let’s get you to bed（はいはいおばあちゃん、もう寝ようね）」と声をかけるインターネット・ミーム画像が添付されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tesla_x_2be13c4150/tesla_x_2be13c4150.jpg" alt="tesla x.jpg" /></p>
<h2>今後の法的・技術的影響</h2>
<p>TeslaがAutopilotに関連して重大な損害賠償責任を問われたのは今回が初めてとされる。これにより、米国家運輸安全委員会（NTSB）や米運輸省道路交通安全局（NHTSA）が進める調査や、運転支援機能に関する規制・基準の見直しが加速する可能性がある。</p>
<p>Teslaは引き続き完全自動運転の実現を目指しているが、今回の評決は、その進展に対して法的・社会的な検証と制約が強まることを示す一例となった。</p>
]]></description>
      <pubDate>Tue, 05 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>直感で解くAI──Google、Gemini「Deep Think」を月額36,800円のUltra向けに提供開始</title>
      <link>https://ledge.ai/articles/gemini_deep_think_ultra_launch</link>
      <description><![CDATA[<p>Googleは2025年8月1日、生成AI「Gemini」シリーズのアプリにおいて、新たな推論モード「Deep Think」の提供を開始したことを<a href="https://blog.google/products/gemini/gemini-2-5-deep-think/">発表</a>した。この機能は、同社の最上位サブスクリプションプラン「Google AI Ultra」（月額36,800円、英語版のみ）に限定されており、人間の直感的な問題解決力を模倣するよう設計された強化推論アルゴリズムを搭載しているという。Deep Thinkは、複雑な数学的課題や高度なコーディング問題などに対し、従来よりも長い推論時間と強化学習技術を用いて、多角的かつ創造的な解を導き出すことを可能にする。</p>
<p>@<a href="https://www.youtube.com/watch?v=QoXRfTb7ves&amp;t=2s">YouTube</a></p>
<h2>Deep Thinkとは</h2>
<p>Deep Thinkは、Gemini 2.5モデルの高度な推論モードとして設計され、以下の特性を持つ：</p>
<ul>
<li>一つの問題に対して複数の仮説を同時に生成・検証する「並列思考」アプローチを採用</li>
<li>通常の推論時間（数秒）を拡張し、数十秒に及ぶ処理時間を許容することで、より複雑な解答を可能にする</li>
<li>解答の精度を逐次改善するために、強化学習（Reinforcement Learning）を活用</li>
<li>GeminiのWeb版およびiOS/Androidアプリで利用可能（英語版に限定）</li>
</ul>
<p><strong>同一のプロンプトに基づき生成されたボクセルアートの比較</strong> ：左からGemini 2.5 Flash、2.5 Pro、2.5 Deep Thinkの出力結果。Deep Thinkでは、構造の複雑さ、色彩の多様性、空間的レイアウトにおいて、明らかな飛躍が確認できる
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_5_deep_think_blog_image_pagoda_width_1000_format_webp_596a05a56a/2_5_deep_think_blog_image_pagoda_width_1000_format_webp_596a05a56a.webp" alt="2-5-deep-think_blog-image_pagoda.width-1000.format-webp.webp" /></p>
<p>同社は、Deep Thinkの導入により単なる事実の再構成では対応できない高度な問題や創造的タスクにおいて、AIの実用性が高まると説明している。</p>
<p>拡張推論にかかる計算資源と処理時間のコストを考慮し、Deep Thinkは、Google AIの最上位プラン「Ultra」利用者のみに提供される。同社は今後の利用状況と安定性を確認したうえで、他プランへの展開を検討するとしている。</p>
<ul>
<li>Ultraプラン：月額36,800円（米国では\$249）、個人および法人利用者向けに設計</li>
<li>Gemini Advancedで提供されていた機能を包含し、Gemini 1.5 Ultraモデルに基づく</li>
</ul>
<h2>ベンチマークと技術的特徴</h2>
<p>Googleは、Deep Think搭載モデルがいくつかの技術的ベンチマークにおいて高い性能を示したと公表している。</p>
<ul>
<li>2025年版IMO（国際数学オリンピック）模擬試験でブロンズ相当の成績</li>
<li>ソフトウェア開発の性能評価であるLiveCodeBench V6において上位3位に入る</li>
<li>ベータ版時と比較して推論速度を約20％短縮し、解答の一貫性も向上</li>
</ul>
<p>技術面では、強化学習（RLHF）に加え、AIフィードバック（RLAIF）による報酬設計を組み合わせたアプローチが用いられており、長時間かけて「考える」プロセスが正式に製品仕様として取り入れられた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/all_benchmarks_blog_width_1000_format_webp_a61e103f81/all_benchmarks_blog_width_1000_format_webp_a61e103f81.webp" alt="all_benchmarks_blog.width-1000.format-webp.webp" /></p>
<h2>競合との位置づけ</h2>
<p>Deep Thinkのアプローチは、OpenAIのGPT-4oにおける「System Thinking」や、AnthropicのClaude Maxが持つ「Reflection」モードと類似した領域に位置づけられる。</p>
<ul>
<li>Googleは「多ステップ問題解決において最大30％の精度向上が見られた」と発表</li>
<li>マルチモーダル機能（画像や音声による入力）は現時点でベータ扱いであり、今後のアップデートで強化される見込み</li>
</ul>
<h2>セキュリティとガバナンス対策</h2>
<p>Googleは、出力の長文化に伴うリスクへの対応として、安全性・倫理面の強化にも取り組んでいるという。</p>
<ul>
<li>社内AI Red Teamおよび外部リサーチパートナーによる事前評価を実施</li>
<li>出力監視フィルタの調整により、有害コンテンツのリスクを低減</li>
</ul>
<h2>今後の展望</h2>
<p>GoogleのGeminiチームは公式ブログにて、「Deep ThinkはGeminiの“思考能力”を次のレベルへ引き上げる取り組みの第一歩だ」と述べている。特に、長時間の推論を活用した複雑な意思決定や創造的な発想が求められる分野での応用に期待を寄せており、「今後さらに思考時間と演算資源を増やすことで、より高精度なAIモデルを段階的に提供していく方針」としている。</p>
<p>また、開発者向けAPIの公開や、Deep Thinkモードの多言語対応、下位プランへの展開についても、「安定運用が確認でき次第、対象を広げていく」と説明している。2025年内に開催予定の「Gemini Dev Day」では、さらなる詳細と開発ロードマップが公開される見通しである。</p>
]]></description>
      <pubDate>Tue, 05 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テキストから”超リアルな写真っぽい画像”を生成　Black Forest Labs、オープンライセンスの新モデル「FLUX.1 Krea [dev]」で挑む“ポスト AI ルック”</title>
      <link>https://ledge.ai/articles/flux1_krea_open_image_model_release</link>
      <description><![CDATA[<p>Stable Diffusion　のオリジナル開発陣が設立したBlack Forest Labs（BFL）は2025年7月31日、テキストから写真のようなリアルな画像を生成できる最新の画像生成モデル「FLUX.1 Krea [dev]」を<a href="https://bfl.ai/announcements/flux-1-krea-dev">発表・公開</a>した。</p>
<p>モデルは12B（120億）パラメーターのRectified Flow Transformerを採用し、Krea AIとの共同開発によって、従来の「AIっぽさ」を意図的に排除したビジュアル表現を可能にしている。非商用用途での利用に限り、オープンウェイト形式で配布されており、Hugging Faceからダウンロードできる。</p>
<h2>“意見を持つ”画像生成モデル</h2>
<p>FLUX.1 Krea [dev]は、Krea AIが開発した高精細な実写風モデル「Krea 1」をベースに再訓練されており、BFL独自の審美的判断を加味した“opinionated（意見を持つ）”生成スタイルが特徴。過度な彩度や人工的な質感、非現実的な肌の表現といった“AIルック”を避け、現実に即した写実性を重視する仕上がりとなっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/447cb391bb54864ff4c9e478d311fd1ad2badd21_3072x2560_a7bc5402d7/447cb391bb54864ff4c9e478d311fd1ad2badd21_3072x2560_a7bc5402d7.jpg" alt="447cb391bb54864ff4c9e478d311fd1ad2badd21-3072x2560.jpg" /></p>
<h2>主な特徴と技術仕様</h2>
<ul>
<li>モデルサイズ：12BパラメーターのRectified Flow Transformerを採用し、従来の拡散モデルと比較して収束速度と品質を両立。</li>
<li>出力解像度：標準で1024×1024ピクセルの画像を生成可能。今後はアップスケーリングにも対応予定。</li>
<li>プロンプト追従性：Krea 1の特徴を維持しつつ、ガイダンス蒸留によりより正確なプロンプト適合を実現。</li>
<li>対応環境：ComfyUI、Diffusers、Together AI、Replicateなど、主要なUIやAPIに対応。</li>
</ul>
<p><strong>Black Forest Labs 各モデルの ELO レーティング比較</strong> ：最新モデル 「FLUX.1 Krea [dev]」は 1,011 ポイントを記録し、商用向けの「FLUX.1 [pro] v1.1」に迫る性能を示した
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/63a9e1e322f8db4e5af_85409d34bd/63a9e1e322f8db4e5af_85409d34bd.jpg" alt="63a9e1e322f8db4e5af.jpg" /></p>
<h2>オープンウェイトでの提供</h2>
<p>FLUX.1 Krea [dev]は、非商用利用に限り自由に使用可能なライセンス（v1.1.2）で提供されている。モデルデータはHugging Face上で公開されており、研究者・開発者・クリエイターはローカル環境やクラウド上での導入が可能。商用利用を希望する場合は、別途Black Forest Labsとのライセンス契約が必要となる。</p>
<h2>安全性と倫理対策</h2>
<p>BFLは、安全性確保のために以下の対策を講じている。</p>
<ul>
<li>IWF（Internet Watch Foundation）との連携によるCSAM（児童性的虐待コンテンツ）およびNCII（非同意性的画像）対策。</li>
<li>内部および外部によるアドバーサリアル評価テストを通過し、公開済みの他のオープン画像モデルよりも安全性が高いと判断。</li>
<li>オープン配布にあたって、使用時のフィルタリングや手動レビューをユーザーに義務づけ。</li>
</ul>
<h2>今後の展開</h2>
<p>BFLは今後、FLUX.1 Krea [dev]を軸としたシリーズの展開を予定しており、高解像度対応モデル「FLUX Ultra」や、テキスト＋画像のマルチモーダル入力に対応する「FLUX.1 Kontext」などの開発にも取り組んでいる。また、さまざまなAIスタックとの連携により、リアルなビジュアル生成のオープンスタンダードを確立していく方針だ。</p>
]]></description>
      <pubDate>Tue, 05 Aug 2025 01:30:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、検索「AIモード」に画像・PDF質問や学習計画機能を追加──“新学期シーズン”に向けてアップデート</title>
      <link>https://ledge.ai/articles/google_ai_mode_back_to_school_update</link>
      <description><![CDATA[<p>Googleは2025年7月29日（米国時間）、検索ページ上の「AIモード（AI Overviews）」に新たな機能を追加したと<a href="https://blog.google/products/search/ai-mode-updates-back-to-school/">発表</a>した。この機能は2025年2月から米国を中心にテスト提供されているもので、今回のアップデートは「Back-to-School（新学期）シーズン」に向けたものであると説明している。新機能として、画像やPDFに対する質問機能や、学習計画を視覚的に整理できる「Canvas」パネル、カメラを用いたリアルタイム質問機能「Search Live」などが実装され、主に学生や教育関係者向けの検索活用を想定している。</p>
<h2>新たに実装された主な機能</h2>
<h3>画像・PDF質問対応</h3>
<p>デスクトップ環境でも画像をアップロードして質問できるようになった。例えば、問題や講義スライドの画像をアップし、内容について質問することが可能。さらに、数週間以内にはPDFファイルのアップロードにも対応予定としており、教材の理解支援に利用できるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/summarise_these_files_0574e0e343/summarise_these_files_0574e0e343.jpg" alt="summarise these files.jpg" /></p>
<h3>Canvas（キャンバス）機能</h3>
<p>学習計画や旅行準備などを整理するための新パネル「Canvas」がAIモードに追加された。複数セッションを跨いで関連情報を保持し、生成AIによる要約・構造化を行うことが可能である。また、ファイルのアップロードと連携することで、パーソナライズされた学習ガイドの生成にも対応する予定だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ask_ai_mode_canvas_18b41d8f1a/ask_ai_mode_canvas_18b41d8f1a.jpg" alt="ask ai mode canvas.jpg" /></p>
<h3>Search Live（リアルタイムカメラ質問）</h3>
<p>Google Lensと連携し、スマートフォンのカメラを使ってその場の映像に基づいて質問する機能「Search Live」が試験導入された。たとえば、手元の理科の実験器具やグラフをカメラで映し、それについての解説をその場でAIから得ることができる。</p>
<p>@<a href="https://www.youtube.com/watch?v=OnwKhkVrvnE&amp;t=5s">YouTube</a></p>
<h3>Webページに対する検索支援強化</h3>
<p>近日中に、Chromeのアドレスバーをクリックすると、ドロップダウンの候補に「このページについてGoogleに質問する（Ask Google about this page）」という新しいオプションが表示されるようになり、そのままAIモードを通じて深掘り検索が行えるという。同社は、これが、ChromeでGoogleレンズを使って検索するもう一つの方法となると説明している。</p>
<h2>提供範囲と利用条件</h2>
<p>現在これらの機能は、AIモード対応地域である米国およびインドの英語版ユーザーに向けて提供されている。また、「Canvas」および「Search Live」機能については、「Search Generative Experience（SGE）」の拡張機能として、Google Labs登録ユーザーから順次展開される形式をとっている。</p>
<h2>背景：AIモードの進化</h2>
<p>AIモードは、Google検索に生成AIを統合した「AI Overviews」として2024年に発表され、2025年2月からはAI Modeとしてラボ機能としてのテストが始まっていた。5月には米国内で正式に提供開始され、Gemini 2.5ベースのカスタムモデルが搭載されている。今回のアップデートは、その進化の一環として、教育利用のシナリオに焦点を当てたものとされている。</p>
<p>Googleは本機能群について、「学習から日常的な調査、買い物支援に至るまで、検索体験をエンドツーエンドでサポートするもの」と位置づけており、今後はGoogle Driveとの連携拡張なども視野に入れているという。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ラーニング2025/8/4 [MON]AIエージェントの可能性と活用のリアル　『現場で活用するためのAIエージェント実践入門』刊行記念ウェビナー｜視聴無料</title>
      <link>https://ledge.ai/articles/webinar-vol66</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>2025年は「AIエージェント元年」。生成AIの急速な進化を背景に、目標に応じて自律的に判断・行動する“AIエージェント”に大きな期待が寄せられています。その活用領域は、顧客対応や業務自動化、ナレッジ検索、意思決定支援など急速に広がり、すでに多くの企業が実証・導入を開始。実運用フェーズに移行しつつあるのが現状です。
こうした中、「本当に動くAIエージェントはどう作るのか」をテーマに執筆された、導入現場で使える実践的なノウハウをまとめた書籍『<a href="https://www.amazon.co.jp/dp/4065401402">現場で活用するためのAIエージェント実践入門</a>』（講談社）が7月に発売され、大きな注目を集めています。</p>
<p>本ウェビナーでは、同書の著者陣5名をゲストに迎え、AIエージェントの基本概念や技術的な背景、導入時の課題、ビジネスへの応用可能性まで、幅広いトピックについてお伺いしました。</p>
<p>AIエージェントに関心のある方や、現在導入を検討・推進されている方にとって必見の内容です。
視聴をご希望の方は、以下のフォームよりご登録のうえ、ぜひご覧ください。</p>
<p>:::button
<a href="https://zfrmz.com/wtVBx4BjLIMrlndfC0Xm">ウェビナーの視聴はこちら（無料）</a>
:::</p>
<h3>ウェビナー内容</h3>
<ul>
<li>AIエージェントとは何か？その歴史と定義</li>
<li>「エージェント型AI」と「エージェンティックAI」の違い</li>
<li>なぜ今、AIエージェントが注目されているのか</li>
<li>導入・展開に立ちはだかる技術的・組織的課題</li>
<li>AIエージェント活用はどう進めるべきか</li>
<li>AIエージェントはどうのように作るのか・相性の良い領域</li>
<li>エージェント導入のROI</li>
<li>AIエージェントが創る未来</li>
</ul>
<h3>このような方におすすめ</h3>
<ul>
<li>AI導入を検討中のビジネスリーダーの方</li>
<li>IT部門・情報システム担当の方</li>
<li>DX推進担当の方</li>
<li>AIエージェントに関心があり、情報収集を進めている方</li>
</ul>
<h2>登壇者情報</h2>
<p><strong>Sakana AI株式会社</strong>
<strong>太田真人</strong>
Applied Research Engineerとして、AIエージェントの社会実装に取り組む。前職の株式会社電通総研では、AIの技術調査やPoCを主導。対外的にもAIエージェントに関する最新情報の発信をしている。</p>
<p><strong>株式会社Algomatic</strong>
<strong>宮脇峻平</strong>
AI/MLエンジニアとして、採用を支援するAIエージェントの自社開発および品質保証に従事。2019年より自然言語処理に取り組み、現在は学術研究員として東北大学大学院に所属。雑談対話応答や質問応答タスクのコンペティションにも参加。</p>
<p><strong>株式会社ジェネラティブエージェンツ</strong>
<strong>西見公宏</strong>
2023年にAIエージェント解説書『その仕事、AIエージェントがやっておきました。』(技術評論社)を上梓し、その流れで共同創業者2名と共にAIエージェントの開発・利活用を専門に扱う株式会社ジェネラティブエージェンツを2024年3月に創業。共著に『LangChainとLangGraphによるRAG・AIエージェント[実践]入門』(技術評論社)。「本当に業務に使える」AIエージェントの開発に注力している。</p>
<p><strong>株式会社電通総研</strong>
<strong>後藤勇輝</strong>
2018年から機械学習に取り組み、自社における製品開発・研究開発に従事。近年は生成AIの可能性に注目し、技術とビジネスの両面から価値創出に取り組んでいる。著書に『PyTorch実践入門 ディープラーニングの基礎から実装へ』(マイナビ出版)、『アジャイルとスクラムによる開発手法 Azure DevOpsによるプロフェショナルスクラムの実践』(マイナビ出版)がある。</p>
<p><strong>株式会社電通総研</strong>
<strong>阿田木勇八</strong>
AIエンジニア / Kaggle Competitions Master。大学卒業後、大手医療機器メーカーに入社。製造現場やKaggleなどでデータ分析のスキルを磨く。その後、AIソリューションの提供側に興味をもち、2021年に電通総研に入社。機械学習を用いた製品開発、さまざまなAIモデル開発・改善案件に従事。現在は自然言語処理を扱う機能のソリューション開発に従事しており、2023年から生成AIエージェントの研究開発に取り組む。Kaggleでは、tacoriceとして参加している。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年8月4日(月)〜 2025年8月22日(金)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/wtVBx4BjLIMrlndfC0Xm">ウェビナーの視聴はこちら（無料）</a>
:::</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、Photoshop βを全面刷新：生成AI「Firefly」駆動の合成・高解像度化・共同作業ツールを一挙投入</title>
      <link>https://ledge.ai/articles/adobe_photoshop_beta_firefly_upscale_collab_update</link>
      <description><![CDATA[<p>Adobeは2025年7月29日（現地時間）、画像編集ソフト「Photoshop」のβ版（デスクトップ／Web／モバイル向け）に、AI生成技術「Adobe Firefly」を活用した5つの新機能を追加したと<a href="https://blog.adobe.com/en/publish/2025/07/29/powerful-new-photoshop-innovations-creators-creative-pros">発表</a>した。これにより、合成画像の自然な一体化、高解像度への自動変換、不要物の除去精度向上、複数人による編集プロジェクトの一元管理、AIモデル選択による生成画像の調整が可能となる。新機能は同日から順次、βチャンネルのユーザー向けに提供が開始された。</p>
<h3>Harmonize（β）</h3>
<p>合成時に発生する「浮いた印象」を回避するため、AIが光源、色調、影などの視覚要素を解析し、自動的に合成対象のレイヤーに調和処理を行う。Adobeが2024年のAdobe MAXで発表していた研究開発プロジェクト「Project Perfect Blend」の成果をベースにしている。</p>
<h3>Generative Upscale（β）</h3>
<p>画像の高解像度化を行う生成AI機能で、最大8メガピクセルまで拡張可能。既存の拡大処理では発生しやすかったディテールの劣化を抑え、SNS向けのリサイズや印刷物制作への活用が想定されている。</p>
<p><strong>■ Generative Upscale適用前（左）と適用後（右）の比較</strong> ：ディテールが強化され、ノイズが大幅に低減されている
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_12ff7544ace3898ddf1bdc5f9ee1db53083203e6a_fc8147feb6/media_12ff7544ace3898ddf1bdc5f9ee1db53083203e6a_fc8147feb6.webp" alt="media_12ff7544ace3898ddf1bdc5f9ee1db53083203e6a.webp" /></p>
<h3>Removeツールの強化</h3>
<p>不要物の除去に使用されるRemoveツールがFirefly Image Model 3にアップグレードされ、背景生成の自然さとアーティファクト（不自然な痕跡）の低減が図られた。小物の除去から人物の除去まで幅広い用途に対応する。</p>
<p><strong>■ Removeツールの処理例。スケートパークの背景から複数の人物を自然に除去している</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_1a8c2968a877a9bd91827b2a3b5e7822e2e70fc0f_24dbe3458c/media_1a8c2968a877a9bd91827b2a3b5e7822e2e70fc0f_24dbe3458c.webp" alt="media_1a8c2968a877a9bd91827b2a3b5e7822e2e70fc0f.webp" /></p>
<h3>Projects（β）</h3>
<p>複数人での編集やレビューを想定した共有スペース。PSDファイルや関連画像、コメントなどを一元的に管理でき、チーム内外とのリアルタイムな協働を可能にする。Web版Photoshop上でリンクを介してアクセスでき、ファイルの重複やバージョン違いによる混乱を防ぐ。</p>
<h3>Generative AI Model Picker</h3>
<p>Generative FillおよびExpand使用時に、使用するFireflyモデル（Image 1／Image 3）を選択できるようになった。これにより、スタイルや出力品質に応じたAIモデルの切り替えが可能となる。</p>
<p>これらの新機能は、Photoshopのデスクトップ版およびWeb版のβチャンネルで即日提供されており、モバイル向けにはiOSのEarly Access版にてHarmonizeが先行導入されている。Android版については、2025年6月に公開された正式アプリへの今後の機能追加が予定されている。</p>
<p>Photoshopには2023年以降、Fireflyモデルを中核とした生成AI機能（Generative Fill、Generative Expandなど）が順次搭載されており、今回のアップデートはその延長線上にある。また、AdobeはPhotoshopの35周年を迎える本年、プロフェッショナルクリエイターの生産性向上とAI編集の即応性をより一層高める構えだ。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIの予測能力が人間の平均を超える時代へ──DeepMindらが描く「スーパー予測者AI」の未来像</title>
      <link>https://ledge.ai/articles/ai_superforecaster_path</link>
      <description><![CDATA[<p>2025年7月25日、Google DeepMindの研究者らを含む国際的な研究チームは、大規模言語モデル（LLM）が将来の出来事を予測する精度において、すでに平均的な個人を上回り、専門家レベルに迫っている可能性があるとする論文を<a href="https://arxiv.org/abs/2507.19477">発表</a>した。</p>
<p>研究者らは、最新のLLMがすでに平均的な人間の予測精度を上回っており、専門家クラスに急速に近づいていると分析。その一方で、今後の課題やリスクにも明確に言及し、持続的な性能向上と社会実装に向けた道筋を提示している。</p>
<h2>AIはすでに「平均的人間」を超えている</h2>
<p>同論文では、イベント予測タスクの精度を評価するため、ForecastBenchと呼ばれる最新ベンチマークを用いて複数のLLMを比較。その結果、以下のようなブライヤー・スコア（Brier Score）が報告された（値が小さいほど高精度）：</p>
<ul>
<li>Claude 3.5 Sonnet：0.122</li>
<li>GPT-4o：0.133</li>
<li>一般的な人間（中央値）：0.121</li>
<li>スーパー予測者（人間専門家の集合知）：0.096</li>
</ul>
<p>これにより、Claude 3.5やGPT-4oといったモデルがすでに「平均的人間」と同等か、それをわずかに上回る予測能力を有していることが確認された。論文では、「既存のLLMはスーパー予測者レベルには届かないが、その差は着実に縮小している」と指摘されている。</p>
<h2>精度向上の鍵は「強化学習」と「動的情報」</h2>
<p>予測精度の向上に寄与した技術的要因として、研究者らは以下の3点を挙げている：</p>
<ul>
<li><strong>強化学習（Outcome-based RL）</strong> ：Polymarketなどの市場予測データを用いてモデルに「結果に基づく報酬」を与える。実際、R1-14Bというモデルはこの方式によりGPT-4oと同等のスコアを記録した。</li>
<li><strong>Deep Research型推論</strong> ：ウェブ検索や統計データベースを用いた情報取得を内包し、根拠付きの予測を自動生成するアプローチ。</li>
<li><strong>大規模データセットの導入</strong> ：10万件以上の多様な予測データを取り入れることで、モデルの汎化性能を高める。</li>
</ul>
<p>研究チームは、静的な事前学習だけでは不十分であり、リアルタイムな世界変化に適応する動的学習が必要であると主張している。</p>
<h2>現実世界は「ノイズだらけ」かつ「報酬が乏しい」</h2>
<p>性能向上の一方で、論文では3つの主要課題が指摘されている：</p>
<ul>
<li><strong>ノイズとスパース性</strong> ：予測対象となる事象はまばらかつ非構造的であり、正確なラベルを得るのが困難。→ 解決策：仮説イベントの生成やベイズネットによる構造化学習。</li>
<li><strong>知識のカットオフ問題</strong> ：モデルが最新の情報を参照できず、旧情報に基づく予測を行うリスク。→ 解決策：市場データやリアルタイム統計の利用。</li>
<li><strong>単純報酬構造の限界</strong> ：正解／不正解の2値評価では、微妙な判断や確率論的学習が困難。→ 解決策：カウンターファクト（反実仮想）や補助的報酬を導入。</li>
</ul>
<p>これらの課題に対応することで、LLMの予測精度はさらに向上する可能性があるという。</p>
<h2>予測AIの応用可能性とリスク</h2>
<p>論文では、LLMによる予測技術が次のような社会的用途に活用できると示唆されている：</p>
<ul>
<li><strong>政策決定支援</strong> ：気候変動対策や経済政策の効果を事前にシミュレーション。</li>
<li><strong>金融・投資判断</strong> ：市場動向の予測によるリスク管理。</li>
<li><strong>公衆衛生対策</strong> ：感染症の拡大予測と医療資源の最適配分。</li>
<li><strong>取引と交渉</strong> ：意思決定支援ツールとしてのAIアドバイザリ機能。</li>
</ul>
<p>一方で、AIの予測が現実に影響を与える「自己成就的予言」のリスクや、悪意ある操作（プロンプト攻撃や情報誘導）に対する脆弱性も指摘されている。</p>
<h2>今後の展望：「人間＋AI」による未来予測へ</h2>
<p>研究チームは、最終的な目標として「人間とAIの協調によるスーパー予測者AIの実現」を掲げている。AI単体での予測精度向上だけでなく、人間の判断や専門知識と組み合わせた“協調予測”が重要になるという立場だ。</p>
<p>LLMの予測能力はまだ発展途上にあるが、技術的基盤と社会制度が整えば、未来の意思決定を根拠とともに支援する新しい情報インフラとしての役割を果たすことが期待される。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/5 [TUE]Anthropicが企業向けLLMで OpenAI を逆転──Menlo 北米での調査、32 %シェアで首位に</title>
      <link>https://ledge.ai/articles/anthropic_tops_enterprise_llm_market_2025_midyear</link>
      <description><![CDATA[<p>米ベンチャーキャピタルのMenlo Venturesは2025年7月31日、企業における大規模言語モデル（LLM）の導入実態を調査したレポート「2025 Mid-Year LLM Market Update」を<a href="https://menlovc.com/perspective/2025-mid-year-llm-market-update/">発表</a>した。調査によると、AnthropicのClaudeシリーズが企業利用において32％のシェアを獲得し、OpenAI（25％）を抜いて首位に立った。調査対象は北米を中心とした150社以上の技術責任者で、実運用中のAPIに基づいた数値だという。</p>
<h2>企業向けLLM市場、Anthropicが32％で首位に</h2>
<p>企業が本番環境で利用しているLLMプロバイダーのシェアは以下の通り</p>
<ul>
<li>Anthropic（Claude）：32％</li>
<li>OpenAI（GPT）：25％</li>
<li>Google（Gemini）：20％</li>
<li>Meta（Llama）：9％</li>
<li>DeepSeek：1％
2023年末の同様の調査ではOpenAIが50％以上の圧倒的シェアを持っていたが、半年間で大幅に後退し、代わってAnthropicが首位に立った。</li>
</ul>
<h2>Claudeシリーズ躍進の要因はコード生成とエージェント適性</h2>
<p>Anthropicが企業利用で支持を拡大した要因として、Menloは次の2点を挙げている。</p>
<ul>
<li><strong>コード生成性能の優位性</strong> ：開発者の支持はAnthropicが42％で、OpenAIの21％を大きく上回った。特にClaude 3.5 Sonnet以降、ソースコード生成やレビュー精度に関する評価が高まっている。</li>
<li><strong>エージェント化への対応</strong> ：Claude 3.5 Sonnetや今後のClaude 4系において、検証付き強化学習（RLVR）を用いたタスク実行能力の強化が進められ、社内業務の一部自動化に成功した企業が増加しているという。</li>
</ul>
<h2>LLM支出は半年で倍増、閉鎖型モデルが依然優位</h2>
<p>2025年上半期における企業のLLM支出は、前年同期の3.5億ドルから8.4億ドルに倍増した。主な要因は、PoC（概念実証）から本番環境への移行が加速したことによる。</p>
<p>また、依然としてクローズドソースのプロプライエタリモデル（Anthropic、OpenAI、Googleなど）が主流である。Menloはその理由として、パフォーマンス面の安定性と導入容易性を挙げている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_closed_source_vs_open_source_scaled_e220aacfdc/3_closed_source_vs_open_source_scaled_e220aacfdc.webp" alt="3-closed-source_vs_open-source-scaled.webp" /></p>
<h2>選定基準は「精度」「セキュリティ」「コスト」「拡張性」</h2>
<p>企業がLLMを選定する際の重視点として、Menloは以下の4点を挙げている。</p>
<ul>
<li>回答品質と精度</li>
<li>データプライバシーおよびセキュリティ対応</li>
<li>推論コスト</li>
<li>APIやRAGなどの拡張性
特にセキュリティ基準が厳格な業種（金融、医療、官公庁など）では、個別カスタマイズや内部検証が可能なプロバイダーが優先される傾向が強い。</li>
</ul>
<h2>オープンソース採用は伸び悩み、Meta Llamaが9％で最多</h2>
<p>一方、オープンソース系のLLMは全体の13％にとどまっており、MetaのLlamaがそのうちの9％を占める。導入には大規模なリソースが必要なうえ、中国製モデルに対するリスク懸念もあり、採用が限定的となっている。</p>
<h2>今後の注目点</h2>
<p>Menloはレポートの中で、今後の市場動向として以下の点に注目している。</p>
<ul>
<li>Anthropicの“エージェント・ファースト”戦略がどの程度実運用に耐えうるか</li>
<li>OpenAIやGoogleの巻き返し策（API料金改定、マルチモーダル強化など）の効果</li>
<li>複数LLMの組み合わせによるハイブリッド運用の広がり</li>
</ul>
<p>企業向けLLM市場は急拡大を続けており、今後数四半期でシェア構造がさらに変化する可能性があるとしている。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「理論がないAI/LLM」に情報幾何学から新たな解釈の可能性　──“曲がった”ニューラルネットワークが引き起こす爆発的記憶、京大らが高次相互作用の数理に突破口</title>
      <link>https://ledge.ai/articles/curved_neural_networks_memory_explosion</link>
      <description><![CDATA[<p>京都大学大学院情報学研究科の島崎秀昭准教授を中心とする国際研究チームは2025年7月29日、統計物理学の最大エントロピー原理をRényiエントロピーへ拡張し、高次相互作用を自然に組み込む新しいニューラルネットワークモデル「Curved Neural Networks（C-NN）」を開発したと<a href="https://www.kyoto-u.ac.jp/ja/research-news/2025-07-29-0">発表</a>した。</p>
<p>この成果は、2025年7月24日付で英科学誌『<a href="https://www.nature.com/articles/s41467-025-61475-w">Nature Communications</a>』に掲載された。</p>
<h2>高次相互作用を取り込む幾何学的アプローチ</h2>
<p>研究は、京都大学の島崎准教授をはじめ、バスク応用数学センター（BCAM）のMiguel Aguilera研究員、株式会社アラヤのPablo A. Morales主任研究員、英国サセックス大学のFernando E. Rosas助教らによる国際共同研究によって進められた。</p>
<p>従来のニューラルネットワークは、ノード間のペア相互作用（2体関係）のみを基本として構築されてきたため、三者以上が同時に関わるような「高次相互作用（higher-order interactions）」を理論的に扱うには限界があった。</p>
<p>研究チームは、確率分布の空間を「統計多様体」として捉え、その空間に曲率（curvature）を導入することで、追加のパラメータを用いることなく高次相互作用を記述可能とした。具体的には、最大エントロピー原理をRényiエントロピーに基づいて拡張し、指数分布の変形によって高次の結合が自然に導かれる新しい枠組みを構築している。</p>
<p><strong>■ 統計多様体の“葉構造”と高次相互作用の対応：</strong>
上：ノード（青）同士の複数リンクが三角形や四面体として重なり合い、三者以上の同時作用（高次相互作用）を表す。
右：曲率が 0（平坦）の場合、階層ごとに分離したサブマニフォールドEr0\mathcal{E}^0_rEr0 が存在する。
左：曲率 γ≠0\gamma <br />
eq 0γ=0 を導入すると空間が折り重なり、1つのパラメータで高次相互作用 E1γ,E2γ,…\mathcal{E}^\gamma_1, \mathcal{E}^\gamma_2,\dotsE1γ,E2γ,… が自然に内包される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294/Higher_order_decomposition_resulting_from_the_foliation_of_a_statistical_e46b758294.jpg" alt="Higher-order decomposition resulting from the foliation of a statistical.jpg" /></p>
<h2>3つの特徴：爆発・自己調整・容量拡張</h2>
<p>C-NNには、以下のような重要な性質が確認された。</p>
<h3>爆発的記憶想起（Explosive Recall）</h3>
<p>エネルギーや温度パラメータがわずかに変化しただけで、記憶状態が瞬時に切り替わる「爆発的相転移」現象が観測された。これは、人間のひらめきに類似した挙動とされる。</p>
<h3>自己調節アニーリング（Self-regulating Annealing）</h3>
<p>ネットワーク内部のエネルギー状態に応じて「有効温度」が自律的に調整され、最適な記憶検索状態へ滑らかに遷移する仕組みが確認された。これは、従来の外部制御型アニーリングを不要にする。</p>
<h3>記憶容量とロバスト性の制御</h3>
<p>空間の曲率を定める単一パラメータγを調整することで、記憶容量の上限と誤り耐性（ロバスト性）のバランスを柔軟に制御可能であることが、解析とシミュレーションにより示された。</p>
<p>これらの性質は、いずれも個別にプログラムされたアルゴリズムによるものではなく、ネットワーク空間の幾何学的構造そのものから自発的に生じるとされている。</p>
<h2>理論と実装への橋渡し</h2>
<p>研究では、統計物理におけるレプリカ法を用いてモデルの性質を解析。曲率が負の多様体を用いたC-NNでは、従来型のHopfieldネットワークと比較して、記憶容量（格納可能なパターン数）が増加し、スピングラス状態（迷子状態）の発生が抑制されることが明らかとなった。</p>
<p>この結果は、計算資源を抑えながらも、より迅速で信頼性の高いメモリ検索や意思決定を可能とするネットワーク設計につながると期待されている。</p>
<h2>今後の展望</h2>
<p>C-NNの枠組みは、以下のような多様な領域への応用が見込まれる。</p>
<ul>
<li><strong>脳神経科学</strong> ：スパース発火や急激な記憶想起の数理的記述に貢献</li>
<li><strong>次世代AI設計</strong> ：Transformerや拡散モデルのエネルギー地形の再解釈</li>
<li><strong>ロボティクス／エッジA</strong> I：小型・省電力環境下での高速推論</li>
<li><strong>Explainable AI（XAI）</strong> ：幾何学パラメータによる構造的可視性の向上</li>
</ul>
<p>今後は、C-NNの学習アルゴリズムの一般化、生体神経活動との比較、フォトニック回路など物理実装との統合といった方向での発展が見込まれる。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/6 [WED]三菱UFJ銀行、200超の業務スキルを持つ自律型AIエージェント導入──Salesforce 「Agentforce for Financial Services」 日本初採用</title>
      <link>https://ledge.ai/articles/mufg_salesforce_ai_agentforce_launch</link>
      <description><![CDATA[<p>三菱UFJ銀行は8月1日、金融業界向けに特化した自律型AIエージェント「Agentforce for Financial Services」を導入すると<a href="https://www.salesforce.com/jp/news/press-releases/2025/08/01/mufg-customer-news-2/">発表</a>した。</p>
<p>提供元はセールスフォース・ジャパンで、同製品の日本国内における初の採用事例となる。同銀行は、CRM基盤である「Financial Services Cloud（FSC）」上にAIを組み込み、面談前後の情報提示や業務フォローアップを自動化することで、営業支援と顧客体験の質を向上させる狙いだ。</p>
<h2>金融機関向けに事前学習済みのAIエージェント</h2>
<p>「Agentforce for Financial Services」は、金融業務に特化して設計されたAIエージェントで、あらかじめ200種類を超える営業支援スキルを搭載している。面談の準備段階では顧客ごとのニーズや関心に関するインサイトを提示し、面談中には質問への応答や関連情報の提供、面談後には自動でタスクを生成・管理するなど、営業プロセス全体を自律的に支援する機能を持つ。</p>
<h2>SalesforceとMUFG、FSCを基盤に連携深化</h2>
<p>三菱UFJ銀行は2025年4月から、セールスフォースの金融特化型CRMである「Financial Services Cloud」を営業現場に導入しており、営業担当者が顧客情報を即時に把握できる体制を構築してきた。今回のAIエージェント導入は、その次のステップとして、FSCに蓄積された過去の営業履歴や顧客データを即座に活用できるAI基盤の整備を意味する。</p>
<h2>営業現場の業務をAIが代替、提案の質とスピードを両立</h2>
<p>Agentforceによって営業担当者は、より付加価値の高い活動に集中できるようになる。AIが面談準備からフォローアップまでの一連の業務を補完・代替することで、業務負荷を軽減すると同時に、提案の質とスピードを向上させることが可能となる。</p>
<h2>導入企業・提供企業のコメント</h2>
<p>三菱UFJ銀行の武井優・上席調査役は、「今回のAgentforce導入を通じて、営業支援と顧客体験の質が大きく向上すると期待している」とコメントしている。また、セールスフォース・ジャパンの田村英則・専務執行役員は、「金融業界で即時に活用可能なデジタル労働力として、Agentforceを提供し続ける」と述べている。</p>
<h2>今後の展開</h2>
<p>三菱UFJ銀行は今後、AIエージェントの適用領域を段階的に拡大し、FSCを基盤とした営業支援インフラの整備をさらに進める方針だ。一方、セールスフォースは専門チームによる導入支援とともに、他の金融機関への横展開を視野に、Agentforceの国内展開を強化していくとしている。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI、AIポルノ生成を全面禁止へ──7月31日から利用規約改定、Stable Diffusion・API・OSSを含む全サービスで性的コンテンツを遮断</title>
      <link>https://ledge.ai/articles/stability_ai_policy_update_nsfw_ban</link>
      <description><![CDATA[<p>ロンドンを拠点とする生成AI企業Stability AIは、2025年7月31日付で同社サービスの利用規約（Acceptable Use Policy, AUP）を<a href="https://stability.ai/use-policy">改定</a>し、Stable Diffusionをはじめとする自社製AIモデル・API・オープンソースコードにおいて、性行為に関連するコンテンツの生成・使用を一律禁止する。</p>
<p>営利・非営利の区別なく適用されるこの新方針は、AIコンテンツの安全性と倫理性を確保する目的で導入されるという。</p>
<h2>性的コンテンツの生成・共有を包括的に禁止</h2>
<p><a href="https://stability.ai/use-policy">新たな利用規約</a>では、「We Prohibit Sexually Explicit Content」の項が新設され、以下の内容が禁止事項として明記された。</p>
<ul>
<li>性行為、性的行為、性的暴力を含むあらゆるコンテンツの生成・共有</li>
<li>非合意の親密画像（NCII: Non-Consensual Intimate Imagery）</li>
<li>違法ポルノや児童搾取コンテンツ</li>
</ul>
<p>これらの規定は、DreamStudio、Stable Diffusion（あらゆるチェックポイントや自己ホスト版）、Stable Video、Stable Audio、Platform API、LoRA（Low-Rank Adaptation）共有機能、さらにGitHubなどで配布されるオープンソースコードを含むすべてのサービスに適用される。</p>
<p>規約違反が判明した場合、Stability AIは利用停止や契約解除などの措置を取ると定めている。また、18歳未満の利用も引き続き禁止される。</p>
<h2>従来規約との大きな違い</h2>
<p>この改定は、2024年3月1日版の旧AUPと比較して大幅な変更となる。
<a href="https://stability.ai/prior-aup">従来の規約</a>では、禁止対象は「非合意ヌード」「違法ポルノ」「児童搾取コンテンツ」などに限定されており、合意の成人同士によるポルノ的表現については明確な禁止はなかった。</p>
<p>新AUPでは、「性行為そのもの」に関わるコンテンツすべてを対象とすることで、生成物の内容に関わらず包括的な制限を設けている。</p>
<h2>デベロッパーとユーザーへの影響</h2>
<p>新規約の対象範囲には、以下のような商用・非商用ツールや資源が含まれる。</p>
<ul>
<li>公式Webアプリ「DreamStudio」</li>
<li>Stable Diffusion（オープンモデル、自己ホスト含む）</li>
<li>音声・映像生成ツール（Stable Audio／Stable Video）</li>
<li>各種APIアクセス、LoRAモデル共有、オープンソースコードの再利用</li>
</ul>
<p>営利・非営利の区別はなく、個人利用や趣味での創作であっても規約違反となる。既存のモデルやワークフローで対象となるコンテンツを扱っている開発者や企業は、今後の運用方針の見直しが必要となる。</p>
<h2>背景：AIポルノをめぐる規制の強化</h2>
<p>今回の規約改定は、AI技術を悪用した性的コンテンツの氾濫に対処する国際的な動きの一環と見られる。特にディープフェイク技術による著名人の偽ポルノ動画や、非合意の画像生成が社会問題化する中で、生成AIモデル各社はNSFW（Not Safe For Work）フィルタの強化やアダルトコンテンツの禁止に取り組んでいる。</p>
<p>Stability AIはオープンウエイトの提供で知られる企業のひとつであり、同社による包括的な制限の導入は、オープンモデル領域における規制の方向性に大きな影響を与える可能性がある。</p>
<h2>今後のスケジュールと対応</h2>
<p>新規約は2025年7月31日より施行される。以降は新規・既存ユーザーともに順守が義務づけられ、違反が確認された場合にはアクセスの遮断やアカウントの停止措置が取られる見通しだ。</p>
<p>同社は今後、利用者向けのFAQやガイドラインの公開も予定しており、具体的な基準や判断基準についての詳細は順次明らかにされるとみられる。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>東大・松尾研の無料オンラインAI講座、累計7.5万人突破──30超の講座で“2040年326万人デジタル人材不足”に挑む</title>
      <link>https://ledge.ai/articles/tokyo_university_ai_course_hits_75000_users</link>
      <description><![CDATA[<p>2025年7月16日、東京大学大学院工学系研究科の松尾・岩澤研究室（以下、松尾研）は、2014年より提供するオンラインAI講座の累計受講者数が75,000人を突破したと<a href="https://weblab.t.u-tokyo.ac.jp/news/2025-07-16/">発表</a>した。</p>
<p>講座では、AIやデータサイエンスをテーマに30以上の科目を無料でオンライン提供しており、中学生から大学院生まで、文理や地域を問わず受講可能である。経済産業省が推計する「2040年に326万人のデジタル人材不足」への対応策の一環として、同研究室は年間70,000人の受講者を目標に掲げている。</p>
<h2>累計7.5万人到達の背景</h2>
<p>松尾研のAI講座は2014年にスタートし、10年余りで急速に受講者数を伸ばしてきた。特に直近では、2024年度に約27,000人が受講し、2025年度には年間70,000人の受講者を目指すとしている。学年や専攻に関係なく、AIに関心を持つ学生に向けて門戸を広げてきたことが、大きな広がりを見せる要因となっている。</p>
<h2>30超の講座を“無料・オンライン”で提供</h2>
<p>松尾研では、年間30講座以上をオンラインで開講しており、受講料はすべて無料となっている。提供されている講座には、以下のようなものがある：</p>
<ul>
<li>GCI（グローバル消費インテリジェンス）入門講座</li>
<li>ディープラーニング（基礎／応用）講座</li>
<li>AIと半導体講座</li>
<li>Physical AI講座</li>
<li>AI起業サマープログラム</li>
</ul>
<p>中でも「GCI入門講座」は、累計3.1万人以上が受講しており、最も人気の高い講座の一つだという。</p>
<h2>人材不足326万人→松尾研モデルが果たす役割</h2>
<p>経済産業省の調査によると、2040年までに日本国内で最大326万人のデジタル人材が不足する見通しだとされている。この深刻な人材不足に対し、松尾研が展開するオンライン講座は、無料かつ地理的制約がないという利点を活かし、地方や海外にいる学生にも学習機会を提供している。こうした取り組みは、教育格差の是正と人材育成の底上げの両面で一定の効果を発揮していると考えられる。</p>
<h2>学んだ知識を“机上で終わらせない”実践機会</h2>
<p>松尾研では、講義で得た知識を現実のプロジェクトに活かす機会も提供している。企業との共同研究や、同研究室から生まれたスタートアップ企業でのインターンシップ、さらにAI起業をテーマにしたサマープログラムなど、実践的な取り組みが並行して進められている。受講者が自身のキャリアや事業化に直結させることができる点が、他の教育プログラムとの差別化要因となっている。</p>
<h2>今後の展開──LLM講座やASEAN展開へ</h2>
<p>今後の展望としては、大規模言語モデル（LLM）をテーマにした新講座を2025年8月より募集開始予定とされている。また、ASEANやアフリカ諸国への展開も本格化しており、グローバルな教育体制の整備が進んでいる。さらに、GCI講座は2025年10月から東京大学の正規科目として単位認定される予定であり、同講座のアカデミックな価値も高まりつつある。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>家電価格のロボ誕生　Unitree R1、87万円で歩く・走る・側転する25 kgヒューマノイド</title>
      <link>https://ledge.ai/articles/unitree_r1_5900usd_humanoid_robot</link>
      <description><![CDATA[<p>中国のロボット開発企業Unitree Roboticsは2025年7月25日、新型ヒューマノイド「Unitree R1」を<a href="https://www.unitree.com/R1">発表</a>した。価格は5,900ドル（約87万円）とされ、一般的な家庭用家電並みの価格帯に設定されている。</p>
<p>製品は全高1.21メートル、重量25キログラムの軽量ボディに26個のアクチュエーターを備え、歩行や走行、さらには側転やハンドスプリングといった高難度の動作を実現する。発表は上海で行われ、現在は主に研究機関や教育機関向けに出荷が計画されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=v1Q4Su54iho">YouTube</a></p>
<h2>5,900ドルの価格戦略と市場への位置づけ</h2>
<p>R1はヒューマノイドロボットとしては異例の低価格帯となる5,900ドル（中国国内価格は39,900元）から販売される。比較対象として、Unitree自身が開発するより上位モデル「G1」は約1万6,000ドル、また他社製のBoston Dynamics「Atlas」やTesla「Optimus」といった機種は数万ドルから数十万ドルに達するとされる。R1はこれらと比べて大幅に価格を抑えており、「普及型ヒューマノイド」のカテゴリに位置付けられる。</p>
<h2>軽量設計と26軸モーションによる高い機動性</h2>
<p>R1の本体はアルミニウム合金や複合素材を用いた軽量構造で、バッテリー込みで約25キログラムに抑えられている。各部位には以下のようなアクチュエーター（自由度）が割り当てられている。</p>
<ul>
<li>両腕に計10自由度（5自由度×2）</li>
<li>両脚に計12自由度（6自由度×2）</li>
<li>腰部に2自由度</li>
<li>EDU版では頭部に追加の2自由度</li>
</ul>
<p>これにより、R1は人間に近い複雑な動作が可能となり、発表時のデモンストレーションでは、歩行・小走り・回転・ジャンプ・側転などを披露した。また、映像内ではパンチやキックなどの模擬動作も確認されており、用途の幅広さがうかがえる。</p>
<h2>センサー・通信・駆動性能</h2>
<p>R1には以下のようなセンサーおよび機能が搭載されている。</p>
<ul>
<li>ステレオ深度カメラ</li>
<li>4マイクアレイによる音声入力</li>
<li>スピーカー搭載による音声出力</li>
<li>通信機能：Wi-FiおよびBluetooth 5.2</li>
<li>バッテリー駆動時間：約1時間（稼働環境に依存）</li>
</ul>
<p>制御用CPUは標準版で8コアの一般プロセッサが搭載され、上位のEDU版ではJetson OrinベースのAIモジュール（推論性能40～100 TOPS）を採用している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0/4905f964d28c4e9cba75f2e1cf9591ba_1920x2370_df7d15caf0.jpg" alt="4905f964d28c4e9cba75f2e1cf9591ba_1920x2370.jpg" /></p>
<h2>教育・研究向けのEDUモデルも展開</h2>
<p>同社はR1の教育用途向けバージョン「EDU版」も同時に発表している。EDU版は以下の機能拡張を含む。</p>
<ul>
<li>AI推論性能を強化したJetson Orin搭載</li>
<li>頭部の2軸モーター追加</li>
<li>デクスターズハンド（多関節ハンド）オプション</li>
<li>保証期間は標準版8カ月に対し、EDU版は12カ月</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138/0705e5d2e5fd49989ca513716c9f50d3_1920x1606_28f4382138.jpg" alt="0705e5d2e5fd49989ca513716c9f50d3_1920x1606.jpg" /></p>
<p>研究開発やロボットコンテスト等での利用が想定されており、実装の自由度や拡張性を重視した設計が特徴となっている。</p>
<h2>上位機種との関係と市場戦略</h2>
<p>Unitreeはすでにヒューマノイドロボット「G1」や大型モデル「H1」を展開しているが、R1はその下位に位置するエントリーモデルと見られている。これまで高額な製品が主流だったヒューマノイド市場に対し、R1は価格の障壁を取り払い、新たな顧客層（教育機関、個人開発者、小規模研究機関など）への訴求を狙う。</p>
<h2>今後の展開と業界への影響</h2>
<p>公式発表では量産時期や出荷スケジュールの詳細は明かされていないが、R1は今後の展示会や開発者向けイベントでの出展が予想されている。家庭用製品並みの価格帯と高度な運動性能を併せ持つR1の登場は、ヒューマノイドロボットの導入障壁を下げ、教育・研究・開発領域における普及を後押しする可能性がある。</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【ソースコード特典付き】MCP × ローカルLLMで作る次世代AIエージェント｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol68</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>Ledge.ai Webinar vol.68では、「MCP×ローカルLLMによるAIエージェント構築」をテーマに、GPUクラウドサービス「GPUSOROBAN」を提供する株式会社ハイレゾ様をゲストにお迎えし、実演デモを交えながらご解説いただきます。</p>
<p>LLMを外部のツールやデータソースと連携させるための標準プロトコルとして注目を集める「MCP（Model Context Protocol）」。
まるで様々なデバイスを接続できるUSB-Cポートのように、異なるLLMやツールをスムーズに繋ぐことから「AIのUSB-Cポート」とも呼ばれています。</p>
<p>このMCPを活用することで、これまで個別の実装が必要だったツール連携の複雑さ（M×N問題）を解消し、より効率的に高度なAIエージェントを構築することが可能になります。</p>
<p>今回のウェビナーでは、MCPの基本概念から、MCPとローカルLLMと組み合わせたAIエージェントの具体的な実装方法まで、デモンストレーションを交えて分かりやすく解説します。</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li>MCP（Model Context Protocol）の概要とAIエージェント開発における重要性</li>
<li>複数のMCPツール（Web検索、RAG、データベース、ファイルシステム）と連携するAIエージェントの実装デモ</li>
<li>ローカル環境で実行可能なオープンソースLLMを用いたAIエージェントの構築方法</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>AIエージェント開発の最新動向を知りたい方</li>
<li>MCP（Model Context Protocol）の概念や実装方法に興味がある方</li>
<li>ローカルLLMを活用してMCPツールと連携させる方法を知りたい方</li>
<li>GPUリソースを効率的に活用しながらAI開発を進めたい方</li>
</ul>
<h3><strong>視聴者特典</strong></h3>
<p><strong>【特典①】デモで使用したサンプルコードをプレゼント！</strong>
本ウェビナーのアンケートにご回答いただいた方全員に、デモで使用したソースコードをプレゼントいたします。視聴後すぐに、ご自身の環境で再現・検証が可能です。</p>
<p><strong>【特典②】H200 GPU 30日間無料トライアルキャンペーン！</strong>
さらに、ハイレゾでは現在、「NVIDIA H200」を搭載したGPUクラウドサービス「AIスパコンクラウド」を30日間無料でお試しいただける特別なキャンペーンも実施中です。
（詳細はウェビナー内およびアンケート回答後のご案内をご確認ください。）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/h200_gpu_free_trial1200_bd3d66cf05/h200_gpu_free_trial1200_bd3d66cf05.jpg" alt="h200-gpu-free-trial1200.jpg" /></p>
<h2>登壇者情報</h2>
<p>株式会社ハイレゾ
マーケティング部　グループ長
山田 岳史</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/highreso_yamadasama_2a984e3aa6/highreso_yamadasama_2a984e3aa6.jpg" alt="highreso-yamadasama.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスのマーケティング担当。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年8月4日(月)〜2025年8月25日(月)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/4XTvrjWktQ90sj9eW7xE">ウェビナーの視聴はこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 04 Aug 2025 00:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>