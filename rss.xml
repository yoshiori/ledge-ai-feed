<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>AIに仕事を奪われるか問題、今のところ失業増は確認されず──シカゴ大学研究、LLM導入は短期的に賃金上昇に作用</title>
      <link>https://ledge.ai/articles/ai_university_of_chicago_llm_short_term_employment_wages</link>
      <description><![CDATA[<p>シカゴ大学の研究チームは、生成AI（大規模言語モデル：LLM）の導入が労働市場に与える短期的な影響を分析した。その結果、AIの影響を強く受ける職種では賃金が上昇する一方で、失業率には統計的に有意な変化は見られなかった。懸念される「AIによる失業」は、少なくとも現時点では確認されていないという。研究チームはこの調査結果を2025年9月19日に<a href="https://arxiv.org/abs/2509.15510">発表</a>した。</p>
<h2>“AIが仕事を奪う”は本当か</h2>
<p>ChatGPTが2022年11月に公開されて以降、生成AIは文章作成やプログラミングをはじめ、幅広い業務に急速に導入されている。一方で、「AIが仕事を奪うのではないか」という不安は根強く存在してきた。こうした懸念を検証するため、シカゴ大学の研究チームは、米国の労働市場データを用いた大規模な分析を行った。</p>
<h2>調査の方法：CPS×O*NET×SDiDで職業別の「曝露度」を推定</h2>
<ul>
<li>データ：米国のCurrent Population Survey（CPS）の失業率と賃金（2010年1月〜2025年8月）</li>
<li>曝露度の定義：O*NETの職業タスクと、Anthropic「Claude」での数百万件のプロンプトを対応づけ、どの職種がLLMの影響を受けやすいかを数値化</li>
<li>手法：Synthetic Difference-in-Differences（SDiD）という統計手法を用い、ChatGPT公開を「技術ショック」として高曝露職種と低曝露職種を比較</li>
</ul>
<h2>主な結果：代替ではなく“補完”が先に来る</h2>
<ul>
<li>賃金：曝露度の高い職種では、平均して週あたり約89ドル（2010年基準ドル換算）の収入増加が確認された。</li>
<li>失業率：変化はごく小さく、全体では0.2ポイント程度の増減にとどまり、統計的に有意な影響は見られなかった。</li>
<li>解釈：短期的には、AIは労働を「代替」するのではなく「補完」する形で生産性を高め、その結果として賃金が上昇したと考えられる。</li>
</ul>
<h2>“言語とコード”を扱う職種が高曝露</h2>
<p>分析によると、特に生成AIの影響を強く受けやすい職業は以下の通り。</p>
<ul>
<li>ライター・著者</li>
<li>コンピュータプログラマー</li>
<li>ウェブ開発者</li>
<li>ソフトウェア開発者</li>
<li>情報セキュリティアナリスト</li>
</ul>
<p>これらの職種はいずれも、文章やコードを中心とした作業に依存しているという。</p>
<h2>長期影響はこれから</h2>
<p>研究チームは「短期的な労働市場の調整は、雇用ではなく賃金を通じて起きている」と結論づけた。失業増加は確認されなかったが、AI導入が長期的にどのような影響を及ぼすかは不透明であり、今後の継続的な観察が必要だとしている。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>資生堂、「エリクシール AIスキンアナライザー」にAIチャット機能を追加──肌測定結果に基づきパーソナルアドバイスを提供開始</title>
      <link>https://ledge.ai/articles/shiseido_elixir_ai_skinanalyzer_chat_update</link>
      <description><![CDATA[<p>資生堂は2025年9月22日、主力スキンケアブランド「エリクシール」のオンライン肌測定サービス「エリクシール AIスキンアナライザー」に、AIチャット機能を新たに追加したと<a href="https://corp.shiseido.com/jp/news/detail.html?n=00000000004067">発表</a>した。測定結果に基づき、スキンケアや生活習慣、製品選びに関するパーソナルアドバイスを提供する。</p>
<h2>年間56万人が利用するオンライン肌測定に新機能</h2>
<p>「エリクシール AIスキンアナライザー」は、スマートフォンで撮影した顔写真をもとに、しわ・毛穴・ツヤなど16項目を計測し、同年代との比較ができるオンライン肌測定サービス。2024年時点で年間56万人が利用している。今回のアップデートで新たにAIチャット機能が加わった。</p>
<h2>肌状態に応じたアドバイスを提供</h2>
<p>新機能では、測定結果に基づいてAIチャットがユーザーに寄り添う形で助言を行う。スキンケアの方法や生活習慣の見直し、個々に適した製品や成分情報などを対話形式で受け取ることができる。資生堂は、オンライン上でもカウンセリングに近い体験を提供することで、ブランド体験の深化を狙う。</p>
<h2>利用手順の可視化</h2>
<p>サービスは、ライフスタイルに関する質問への回答、顔写真の撮影、肌研究データに基づく計測、同年代平均との比較を経て、スキンケアのアドバイスやAIチャットによる相談へと進む。結果は保存可能で、経時的な変化を確認することもできる。</p>
<p><strong>「エリクシール AIスキンアナライザー」の利用手順。質問回答から顔写真撮影、測定、AIチャットによる相談までを一連の流れで体験できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4067_o7z02_432_7c88b34ae8/4067_o7z02_432_7c88b34ae8.jpg" alt="4067_o7z02_432.jpg" /></p>
<h2>今後の展開</h2>
<p>今回の機能追加は、デジタルを活用したブランド戦略の一環。資生堂はエリクシールを通じて、顧客一人ひとりに寄り添ったパーソナライズケアの強化を進める方針だ。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>政府、拡大する ”デジタル赤字” に歯止め――AI活用やゲーム・アニメ輸出を柱に海外展開促進策を策定</title>
      <link>https://ledge.ai/articles/government_digital_industry_global_strategy_20250919</link>
      <description><![CDATA[<p>政府は2025年9月19日、首相官邸で「<a href="https://www.kantei.go.jp/jp/pages/20250919choukan_global.html">デジタル関連産業のグローバル化促進のための関係閣僚会議</a>」を開き、拡大傾向にある「デジタル赤字」を抑制するための施策案を取りまとめた。AIを活用した国産サービスの競争力強化や、ゲーム・アニメといったコンテンツの輸出促進が柱となる。</p>
<h2>会議の概要</h2>
<p>会議には関係閣僚が出席し、デジタル関連産業の海外展開を加速させるための施策案が示された。政府は今後、実行計画を通じて産業競争力を高め、国際市場での存在感を強化する方針だ。</p>
<h2>背景</h2>
<p>近年、デジタル関連収支の赤字（いわゆる“デジタル赤字”）が拡大している。サービス輸入の増加が要因で、日本発のAIやデジタルサービスが海外市場で十分に浸透していないことが課題とされている。</p>
<h2>施策の柱</h2>
<p>会議で示された施策案には以下の内容が含まれる。</p>
<ul>
<li>AI・データ利活用の推進：国際市場で通用する先端サービスを生み出すための支援。</li>
<li>コンテンツ輸出促進：ゲームやアニメなど文化的デジタルコンテンツを重点に据えた海外展開支援。</li>
<li>人材育成・基盤整備：スタートアップ支援やデータセンター整備などの環境づくり。</li>
<li>制度・ルール整備：著作権や国際標準化への対応を強化し、国際的なビジネス展開を後押し。</li>
</ul>
<h2>今後の展開</h2>
<p>政府は、こうした施策を通じてデジタル関連収支の赤字を抑制するとともに、日本発のサービスやコンテンツが海外収益を確保できる体制の構築を目指す。今後は予算措置や制度改正などを通じて、施策の具体化を進める予定だ。</p>
]]></description>
      <pubDate>Thu, 25 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、ソフトバンク・Oracleと協力し米国に5拠点の新データセンター建設へ――スターゲート計画は目標の10GW中の約70%の計算能力に</title>
      <link>https://ledge.ai/articles/openai_softbank_oracle_stargate_new_datacenters</link>
      <description><![CDATA[<p>OpenAIは2025年9月23日（現地時間）、米国内で新たに5つのデータセンターを建設すると<a href="https://openai.com/index/five-new-stargate-sites/">発表</a>した。これは、同社が米Oracleおよびソフトバンク・グループと協力して進める「Stargate」プロジェクトの拡大の一環で、AIインフラの大規模強化を目的としている。</p>
<h2>5カ所の新拠点を発表</h2>
<p>発表では以下の5サイトが明らかにされた。</p>
<ul>
<li>テキサス州シャケルフォード郡（Shackelford County, Texas）</li>
<li>ニューメキシコ州ドナアナ郡（Doña Ana County, New Mexico）</li>
<li>米中西部の未発表サイト（Midwest, location to be announced）</li>
<li>オハイオ州ロードスタウン（Lordstown, Ohio）</li>
<li>テキサス州ミラム郡（Milam County, Texas）</li>
</ul>
<p>OpenAIは、すでに稼働を始めたテキサス州アビリーンの「flagship」サイトに加え、これらの拠点を整備することで、計画全体の規模をさらに拡大するとしている。</p>
<p>また、ソフトバンクグループは、オハイオ州ロードスタウンの拠点に主導的に関与。同地にはかつて自動車工場が存在し、その跡地を活用して新しいAIデータセンターを建設する<a href="https://ledge.ai/articles/softbank_ohio_ev_plant_stargate_ai_infrastructure_bloomberg_report">計画</a>が進められている。資金面での支援に加え、用地取得や地域再開発の調整にも携わるとされ、現地経済の再活性化に直結する重要な拠点となる。</p>
<h2>計画規模と進捗</h2>
<p>Stargateプロジェクトは、総投資額5000億ドル、計10ギガワットの計算能力を目標に掲げる。今回の5拠点追加により、計画容量はすでに約7ギガワットに到達する見込みだ。ロードスタウンの施設は2026年に稼働予定で、Abileneの施設では一部GPUによる運用が開始されている。</p>
<h2>雇用と地域経済への影響</h2>
<p>OpenAIによると、新拠点の建設により2万5,000人以上の雇用が創出される見込みで、地元経済への貢献も期待される。また、Oracleのクラウド基盤やソフトバンクの投資が、この大規模インフラの整備を支える。</p>
<h2>今後の見通し</h2>
<p>OpenAIは「AIを人類全体の利益のために活用する」という理念のもと、安全かつ持続可能な形でインフラを拡張していく方針を示している。電力供給や環境負荷の軽減にも取り組みながら、Stargateの10ギガワット目標に向けた拡大を続けていくとした。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、OpenAIに最大1000億ドルを投資──10GW規模のAIデータセンター展開で戦略提携</title>
      <link>https://ledge.ai/articles/nvidia_invests_100b_in_openai</link>
      <description><![CDATA[<p>NVIDIAとOpenAIは2025年9月22日（現地時間）、次世代AIインフラの構築に向けた戦略的提携を<a href="https://openai.com/index/openai-nvidia-systems-partnership/">発表</a>した。両社はNVIDIA製システムを用いて少なくとも10ギガワット（GW）規模のAIデータセンターを展開する計画で、NVIDIAは段階的に最大1000億ドル（約15兆円）をOpenAIに投資する。</p>
<p>両社は意向表明書（LOI）を締結し、今後の協力体制を明確化した。OpenAIは計算処理およびネットワーク分野における「優先戦略パートナー」としてNVIDIAを位置づけ、ハードウェアとソフトウェアの両面でロードマップを共有し最適化を進めるとしている。</p>
<p>投資の仕組みとしては、NVIDIAがGW単位でのシステム展開に応じて段階的に資金を投入し、最終的に最大1000億ドルに到達する見込み。OpenAIはNVIDIAの半導体製品を現金で購入する一方、NVIDIAは議決権のない株式を取得する形を取る。</p>
<p>導入スケジュールとして、最初の1GWは2026年後半に稼働予定であり、NVIDIAの新しい「Vera Rubin」プラットフォームを採用する。これにより、増大するAIモデルの学習・推論需要に対応できる大規模な計算インフラの整備が進む見込みだ。</p>
<p>今回の提携は、世界的に加速するAI開発競争において、インフラ規模での優位性を確保する狙いがある。両社は「少なくとも10GW」という巨大規模の展開を通じて、次世代AIの開発と実用化を支える基盤づくりを進めていく。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ロボットと暮らす住宅を初公開──リビングロボットと藤田医科大、生活支援ロボットを導入した“人協調型ロボティクス住宅”を発表</title>
      <link>https://ledge.ai/articles/living_robot_fujita_robotech_house</link>
      <description><![CDATA[<p>リビングロボットは2025年9月18日、藤田医科大学リハビリテーション部門と共同開発した生活支援ロボットやシステムを導入した「人協調型ロボティクス住宅」を<a href="https://prtimes.jp/main/html/rd/p/000000057.000094064.html">発表</a>した。名古屋市熱田区のサンヨーホームズ株式会社の住宅展示場に設置され、9月20日から特定日に一般公開が行われる。</p>
<h2>社会課題への対応として開発</h2>
<p>同社は、少子高齢化や介護人材不足といった社会課題を背景に、人とロボットが協調する住まいの新たな形を提示。今回の取り組みは、内閣府の戦略的イノベーション創造プログラム（SIP）「人協調型ロボティクスの拡大に向けた基盤技術・ルールの整備」に採択された研究の一環でもある。</p>
<p>展示住宅は、名古屋市熱田区の「神宮東 中日ハウジングセンター」内にあるサンヨーホームズの住宅展示場に設置された。一般公開は2025年9月20日（土）、21日（日）、27日（土）、28日（日）の4日間が予定されている。</p>
<h2>生活を支えるロボットとシステム</h2>
<p>住宅には、以下の生活支援ロボットやシステムが導入されている。</p>
<ul>
<li><strong>見守りロボット「WeeGo（ウィーゴ）」</strong> ：小型で会話機能を持ち、居住者に気づきを促す。</li>
<li><strong>メカトロメイトQ</strong> ：移動や通話機能を備えたロボット。</li>
<li><strong>移動・移乗支援ロボット</strong> ：車いす型で、住宅内の移動や乗り移りをサポート。</li>
<li><strong>センサー群</strong> ：生活・活動データ（運動、睡眠など）や住環境データ（温湿度、CO₂濃度、照度、窓開閉など）を収集。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_9f5bef2d74/sub1_9f5bef2d74.jpg" alt="sub1.jpg" /></p>
<p>これらの仕組みにより、熱中症予防や転倒時の通報、侵入者検知など、安全で快適な暮らしを支援する機能が提供される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub2_06affc0937/sub2_06affc0937.jpg" alt="sub2.jpg" /></p>
<h2>今後の展望</h2>
<p>リビングロボットは今回の公開を通じて、一般生活者が新しい住環境を体験する場を提供するとともに、社会実装に向けた実証を重ねていく方針だ。</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/24 [WED]Claudeの品質低下、Anthropicが技術的原因を公表 — 誤ルーティング・出力破損など3件のバグ</title>
      <link>https://ledge.ai/articles/claude_quality_drop_three_bugs</link>
      <description><![CDATA[<p>Anthropicは2025年9月17日、8月上旬から9月上旬にかけて報告されたAI「Claude」の応答品質が低下した問題について調査を行い、原因は3件のインフラストラクチャ上のバグだったと<a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">発表</a>した。公式のエンジニアリングブログとステータスページで詳細が<a href="https://status.anthropic.com/">公開</a>されている。</p>
<h2>問題の発生と調査開始</h2>
<p>8月上旬ごろから、Claudeの応答が以前より劣化しているとの報告がユーザーから相次いだ。コード生成に誤りが含まれる、応答中に不自然な文字が混ざるといった現象が確認され、Anthropicは公式ステータスページで状況を認識し調査を進めていると発表した。</p>
<h2>判明した3つのバグ</h2>
<p>Anthropicのエンジニアリングブログによると、応答品質低下の背景には次の3つの独立したバグが存在していた。</p>
<h3>1. コンテキストウィンドウの誤ルーティング（Context Window Routing Error）</h3>
<ul>
<li>本来1Mトークン対応のサーバーに処理が割り振られるべきリクエストが、誤って小さいコンテキストウィンドウを持つサーバーに送られていた。</li>
<li>負荷分散の仕組みにより、影響を受けたユーザーは継続的に同じサーバーへ接続され、長期にわたって問題が続いた。</li>
<li>影響は当初全体の約0.8%だったが、8月下旬には最大16%に拡大。9月4日までに修正が完了した。</li>
</ul>
<h3>2. 出力破損（Output Corruption）</h3>
<ul>
<li>8月25日にTPUサーバーへ適用された誤った設定変更が原因で、一部の応答に異常が発生。</li>
<li>英語のプロンプトに中国語やタイ語の文字が混ざる、コード生成で文法エラーが出るなどの症状が報告された。</li>
<li>Opus 4/4.1では8月25～28日、Sonnet 4では8月25～9月2日に影響が確認され、9月2日に設定をロールバックして修正した。</li>
</ul>
<h3>3. XLA:TPUの誤コンパイル（XLA:TPU Miscompilation）</h3>
<ul>
<li>出力トークン選択を改善するための最適化コードがXLAコンパイラの潜在的なバグを誘発。その結果、本来高確率で選ばれるべき単語や記号が応答に現れない不具合が発生。</li>
<li>特にClaude Haiku 3.5で顕著に見られ、Opus 3やSonnet 4の一部にも影響の可能性があった。最適化のロールバックによって9月初頭には解消された。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/d707dfc2effceba608d04007bc776132a3e57838_3840x1800_59fc4bc120/d707dfc2effceba608d04007bc776132a3e57838_3840x1800_59fc4bc120.jpg" alt="d707dfc2effceba608d04007bc776132a3e57838-3840x1800.jpg" /></p>
<h2>修正と再発防止策</h2>
<p>Anthropicは、各バグはすでに修正済みであると説明。再発防止策として、より敏感な出力監視の導入、複数のハードウェアプラットフォームを横断したテスト体制の強化、プライバシーを確保しながらユーザー報告を活用できる仕組みづくりを進めるとしている。</p>
<h2>今後の方針</h2>
<p>Anthropicは「モデルの品質はアルゴリズムだけでなく、基盤となるインフラ全体に依存する」と強調。今後はユーザーからの報告と自動評価の双方を活用し、異常の早期発見と透明性ある運営を通じて信頼性の確保を目指すとしている。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Wed, 24 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Gartner、世界のAI支出が2025年に1.5兆ドル、2026年には2兆ドル超に達すると予測</title>
      <link>https://ledge.ai/articles/gartner_ai_spending_2025_2026_forecast</link>
      <description><![CDATA[<p>米調査会社Gartnerは2025年9月17日、世界のAI関連支出が2025年に1兆5,000億ドル（約220兆円）に達し、2026年には2兆ドル（約290兆円）を突破するとの最新予測を<a href="https://www.gartner.com/en/newsroom/press-releases/2025-09-17-gartner-says-worldwide-ai-spending-will-total-1-point-5-trillion-in-2025">発表</a>した。2024年の9,879億ドルから急速に拡大し、わずか2年で2倍以上に伸びる見通しだ。</p>
<p>同社によると、AI支出はサービスからアプリケーション、半導体、デバイスに至るまで幅広い分野で拡大するという。特に、生成AIモデルを含むソフトウェア分野や、GPUを中心としたAI最適化サーバー、AI処理用半導体の需要が市場成長を牽引するとしている。</p>
<h2>サービスからデバイスまで、多様な分野で拡大</h2>
<p>AIサービス市場は2024年の2,594億ドルから2026年には3,246億ドルに増加。AIアプリケーションソフトウェアは同期間に3倍以上となる見通しだ。さらに、生成AIスマートフォンの出荷も堅調で、2026年には3,930億ドルに迫ると予測されている。</p>
<p><strong>GartnerによるAI支出予測</strong> ：2025年に1.5兆ドル、2026年には2兆ドルを突破（単位：百万USドル）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gartner_table2_f8fb4a4adf/gartner_table2_f8fb4a4adf.jpg" alt="gartner table2.jpg" /></p>
<h2>成長を牽引する要因</h2>
<p>Gartnerは、生成AIの普及とAI機能を組み込んだデバイスの急速な広がりが市場拡大の主因だと分析している。また、GPUを中心とした半導体やクラウドインフラへの投資が継続的に増加しており、企業や消費者双方からの需要が市場を押し上げている。</p>
<h2>今後の展望</h2>
<p>同社は、2027年以降もAI支出は増加を続けると見込む。生成AIの業務活用が加速し、アプリケーションとサービス分野の投資がさらに拡大すると予想される。ガートナーは「AIは産業全体に浸透し、今後数年で世界のIT支出の中核的存在になる」としている。</p>
]]></description>
      <pubDate>Tue, 23 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI活用の脳深部刺激で「慢性的な痛み」を軽減──カリフォルニア大学サンフランシスコ校研究チームが発表</title>
      <link>https://ledge.ai/articles/ai_brain_stimulation_chronic_pain_relief_ucsf</link>
      <description><![CDATA[<p>カリフォルニア大学サンフランシスコ校（UCSF）を中心とする研究チームは、AIを活用して患者ごとに最適化した脳深部刺激（DBS）を行い、慢性的な痛みを軽減できる可能性を示した。成果はプレプリント論文として2025年8月13日に<a href="https://www.medrxiv.org/content/10.1101/2025.08.11.25333010v1">公開</a>されている。</p>
<h2>自動調整する脳深部刺激の仕組み</h2>
<p>研究では、従来の薬物療法で十分な効果が得られなかった患者を対象に、脳に電極を埋め込み、神経活動をリアルタイムにモニタリングした。そのデータをAIが解析し、痛みに関連する脳活動パターンを検出すると、自動で電気刺激を調整する仕組みを導入した。あらかじめ設定した刺激を与える従来の方式に対し、患者の状態に応じて刺激を最適化する点が特徴である。</p>
<p><strong>AIを活用した脳深部刺激（DBS）の仕組み。患者の脳活動をリアルタイムに解析し、痛みの状態に応じて刺激を自動的に最適化するプロセスを示している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/F1_large_0342252908/F1_large_0342252908.jpg" alt="F1.large.jpg" /></p>
<h2>痛みの軽減効果と意義</h2>
<p>実験では、患者が訴える痛みの強さが軽減する効果が確認された。研究チームは、AIによる個別化が治療効果を高めるとともに、副作用を抑制する可能性があると指摘している。脳深部刺激はこれまでもパーキンソン病やてんかんで用いられてきたが、慢性的な痛みへの応用は新たな展開となる。</p>
<h2>今後の展望</h2>
<p>慢性的な痛みは世界人口の約2割が抱えるとされ、生活の質を大きく損なう要因になっている。既存の薬物療法やリハビリでは対応が難しいケースも多く、新たな治療法の開発が求められてきた。神経科学とAIを組み合わせた今回の研究は、そうした課題に対し「パーソナライズ医療」の新しい方向性を提示するものといえる。</p>
<p>今回の成果は少数の患者を対象とした初期段階の研究にとどまっており、大規模な臨床試験や長期的な追跡調査が不可欠である。それでも、AIを活用した自動調整型の脳深部刺激が「長引く痛み」に苦しむ患者に新たな選択肢をもたらす可能性は高く、今後の実用化に期待が集まっている。</p>
]]></description>
      <pubDate>Tue, 23 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国AI「DeepSeek」、政治的にセンシティブなトピックで回答品質に差──CrowdStrike調査を米紙が報道</title>
      <link>https://ledge.ai/articles/deepseek_crowdstrike_sensitive_topics</link>
      <description><![CDATA[<p>中国のAI企業「DeepSeek」が開発した大規模言語モデルについて、米サイバーセキュリティ企業CrowdStrikeの検証結果を米<a href="https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/">ワシントン・ポスト</a>などが2025年9月16日（現地時間）に報じた。政治的にセンシティブなトピックを指定した場合、生成されるコードの欠陥率が高まり、回答を拒否するケースも増える傾向が確認されたという。</p>
<h2>調査の方法と背景</h2>
<p>報道によると、CrowdStrikeはDeepSeekに対し「ほぼ同一のプログラミング依頼」を複数回行い、相手先や対象を差し替えて比較する手法を採用した。対象には、イスラム国（IS）、法輪功（中国政府により1999年以降弾圧されている精神修行団体）、チベット、台湾など、中国政府にとってデリケートとされる組織や地域が含まれていた。検証内容はワシントン・ポストに独占的に共有されたとされる。</p>
<h2>品質の差異と拒否率の上昇</h2>
<p>実験では、産業制御システム向けのコード生成を依頼した際、欠陥コード率は22.8％だった。これに対し、対象をISとした場合は42.1％へと上昇。さらに、回答拒否率はISで61％、法輪功では45％に達し、センシティブな対象では品質が低下したり応答そのものを拒否する傾向が確認された。</p>
<h2>他モデルとの比較</h2>
<p>報道は、米国の大手AIモデルもISに関しては協力を拒否する一方で、法輪功については通常通り回答することが多いと指摘している。こうした比較から、DeepSeekが他のモデルとは異なる応答特性を示す点が浮き彫りとなった。</p>
<p>記事では、こうした挙動が「国家方針に沿った制御」によるものか、「トレーニングデータの偏り」「市場ごとの優先度」などによるものかは断定できないとしつつ、複数の専門家がその要因を議論している。</p>
<p>中国国内では、Huaweiと浙江大学がDeepSeekベースの「R1-Safe」と呼ばれる検閲強化版を開発していることを9月19日に<a href="https://www.reuters.com/business/media-telecom/chinas-huawei-co-develops-deepseek-model-improves-censoring-2025-09-19/">Reuters</a>が報じている。政治的にセンシティブなテーマへの制約は、モデル開発の方向性として広がりを見せている。</p>
]]></description>
      <pubDate>Mon, 22 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>登記情報と現況の“ズレ”を衛星画像×AIで検知──アクセルスペースとWHEREが概念実証を開始</title>
      <link>https://ledge.ai/articles/axelspace_where_satellite_ai_realestate_poc</link>
      <description><![CDATA[<p>衛星開発・運用を手がけるアクセルスペースと、不動産AIツール「WHERE」を展開するWHEREは2025年9月17日、人工衛星による地球観測画像を活用し、不動産登記情報の精度向上や不動産管理業務の効率化を目指すPoC（概念実証）を開始したことを。<a href="https://www.axelspace.com/ja/news/realestate_poc/">発表</a>した。対象は東京、神奈川、埼玉、千葉、大阪、福岡の6都府県で、都市部を中心に実施するという。</p>
<h2>背景と課題</h2>
<p>日本の不動産市場では、登記情報と現況が一致しないケースが少なくない。従来は自治体や事業者が現地調査を行う必要があり、コストや時間の面で大きな負担となっていた。また情報更新の遅れは、不動産取引の判断や管理業務の効率性にも影響していた。</p>
<h2>PoCの内容</h2>
<p>今回のPoCでは、アクセルスペースが運用する光学地球観測衛星「GRUS」から取得した高頻度・広範囲の画像と、WHEREのオフマーケット探索AIを組み合わせる。これにより、土地利用の変化や新規建築物の有無などを検知し、登記情報と照合する。実証では、1か月間に複数回の衛星撮影を行い、差異を検出して自治体や事業者に提供する。</p>
<p><strong>衛星画像（左）とAIによる変化検出結果（右）。土地や建物の変化を赤色で可視化し、登記情報と現況の差異を確認できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/29d3bc99193cb0b837fb8cc53f050ae5_8d1a174657/29d3bc99193cb0b837fb8cc53f050ae5_8d1a174657.png" alt="29d3bc99193cb0b837fb8cc53f050ae5.png" /></p>
<h2>企業の取り組み</h2>
<p>WHEREは、市場に出ていない不動産の探索や管理をAIで支援し、不動産市場の情報格差を解消することを目指している。一方のアクセルスペースは、現在5機のGRUS衛星を運用中で、2026年には次世代衛星「GRUS-3」7機の打ち上げを予定。観測能力を強化することで、社会インフラや不動産分野への応用を拡大していく考えだ。</p>
<h2>今後の展望</h2>
<p>両社は、都市部での検証を皮切りに、地方都市や空き家・休耕地の管理、災害リスク地域での活用などへ応用を検討している。不動産業界のみならず、都市計画や防災、インフラ管理といった幅広い分野での利用も期待される。</p>
]]></description>
      <pubDate>Mon, 22 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、広告制作プロセスを自動化する新しいAIエージェントを発表──Creative Studioに導入</title>
      <link>https://ledge.ai/articles/amazon_ai_agent_creative_studio</link>
      <description><![CDATA[<p>Amazon Adsは2025年9月17日（米国時間）、広告主向けクリエイティブ制作ツール「Creative Studio」に新しいAIエージェント機能を追加したと<a href="https://advertising.amazon.com/library/news/amazon-ads-agentic-ai-creative-tool">発表</a>した。調査、アイデア出し、ストーリーボード作成、最終的な広告素材の生成まで、広告制作の主要なプロセスを一気通貫で自動化する。</p>
<h2>調査から広告素材生成まで一気通貫</h2>
<p>Amazonが導入した「agentic AI」機能は、広告主がチャット形式でAIと対話することで、広告制作を進められる仕組みだ。ブランド資産や商品情報を取り込み、消費者の特徴や購買行動を分析しながら、最適な広告コンセプトを提示する。さらに、場面ごとの構成を可視化するストーリーボードを生成し、動画やディスプレイ広告、音声や音楽を組み込んだ広告素材まで自動で仕上げることができる。ユーザーは必要に応じて修正指示を出し、細部を調整できる。</p>
<p><strong>Creative Studioのチャット画面：音楽やナレーションを追加しながら広告動画を仕上げる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Nws_Frame_3_TTW_3cf7c52e3c/Nws_Frame_3_TTW_3cf7c52e3c.jpg" alt="Nws_Frame_3.TTW.jpg" /></p>
<h2>中小規模広告主にも“プロ品質”の広告を</h2>
<p>同機能は小規模から中規模の広告主にとって特に有効だと同社は述べる。従来は数週間、数万ドル単位で必要だった広告制作を、数時間かつ低コストで完了できる可能性がり、プロフェッショナル品質の広告制作が、限られたリソースでも実現しやすくなるという。</p>
<p><strong>生成されたライフスタイル画像のプレビュー：製品の利用シーンをAIが自動生成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Nws_Frame_5_TTW_e6f9e41a41/Nws_Frame_5_TTW_e6f9e41a41.jpg" alt="Nws_Frame_5.TTW.jpg" /></p>
<h2>技術基盤と提供状況</h2>
<p>この機能はAmazon Bedrockを基盤に構築されており、Amazon独自の大規模言語モデル「Nova」や、Anthropicの「Claude」など複数のモデルを活用している。現在はベータ版として提供が始まっており、今後は対応フォーマットや対象地域の拡大も予定されている。</p>
<p><strong>Creative Studioのホーム画面：広告制作の出発点として複数のオプションを提示</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Nws_Homescreen_1_TTW_8dfbd497d7/Nws_Homescreen_1_TTW_8dfbd497d7.jpg" alt="Nws_Homescreen_1.TTW.jpg" /></p>
<h2>今後の展望</h2>
<p>Amazonは、広告制作の効率化と高度化を両立させることで、今回のAIエージェント機能について「今後さらに多様なフォーマットへの対応を進める」と説明している。提供開始時点ではベータ版であり、対象地域や言語は限定的だが、順次拡大していく計画も明らかにされている。</p>
]]></description>
      <pubDate>Mon, 22 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/21 [SUN]Google、AIエージェント決済の新標準『Agent Payments Protocol（AP2）』を発表──安全性・説明責任・相互運用性を重視</title>
      <link>https://ledge.ai/articles/google_agent_payments_protocol_ap2_announcement</link>
      <description><![CDATA[<p>Googleは2025年9月16日（現地時間）、AIエージェントが人間に代わって商品やサービスを購入する際の新たな標準規格「Agent Payments Protocol（AP2）」を<a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol/?hl=en">発表</a>した。AP2はオープンソースで提供され、既存の決済インフラを補完することで、AIエージェントによる取引の安全性と信頼性を確保することを目的としている。</p>
<p>@<a href="https://www.youtube.com/watch?v=yLTp3ic2j5c">YouTube</a></p>
<h2>背景：AIエージェント時代の課題</h2>
<p>AIエージェントは商品検索から購入まで代行可能になりつつあるが、現在の決済システムは人間によるクリックを前提に設計されている。そのため、以下のような課題が浮上していた。</p>
<ul>
<li><strong>権限の証明</strong> ：エージェントが正しくユーザーの意図を受けて行動しているか</li>
<li><strong>正確性の担保</strong> ：取引内容がハルシネーションではないことの確認</li>
<li><strong>責任の所在</strong> ：不正やエラー発生時に誰が責任を負うのか</li>
</ul>
<h2>AP2の概要と位置づけ</h2>
<p>AP2はこうした課題を解決するための新しいオープンプロトコルで、Googleが提唱した。既存の「Agent to Agent（A2A）」や「Model Context Protocol（MCP）」と互換性を持ち、AIエージェントによる商取引を支える基盤として設計されている。</p>
<h2>5つの基本原則</h2>
<p>Googleは公式動画の中で、AP2が以下の原則に基づいていることを示した。</p>
<ul>
<li><strong>オープン性と相互運用性</strong> ：非独占的な仕組みで、誰もが革新に参加できる。</li>
<li><strong>ユーザーコントロールとプライバシー</strong> ：ユーザーが常に取引の主導権を握る。</li>
<li><strong>検証可能な意図</strong> ：暗号署名に基づく意図証明で、誤動作を防止。</li>
<li><strong>明確な取引説明責任</strong> ：否認不可能な監査証跡を作成し、紛争解決を容易にする。</li>
<li><strong>グローバル性と将来性</strong> ：カード決済だけでなく、リアルタイム送金やデジタル通貨にも対応。</li>
</ul>
<h2>仕組みと中核技術</h2>
<p>AP2の中心となるのは Verifiable Credentials（検証可能な資格情報） だ。これは暗号署名された改ざん不可能なデータで、エージェント間で交換される。</p>
<p>その具体的な形が 「mandate（マンデート）」 と呼ばれる承認データである。mandateは、ユーザーがAIエージェントに「どの範囲で買い物を許可したか」を証拠付きで示す役割を担う。</p>
<ol>
<li><strong>カート・マンデート（Cart Mandate）</strong>：ユーザーが「この商品をこの価格で購入してよい」と最終承認した証拠。商品内容や価格が含まれ、署名付きで保存される。</li>
<li><strong>インテント・マンデート（Intent Mandate）</strong> ：「深夜0時に発売されるチケットを上限1万円で購入してほしい」といった条件付きの購入をエージェントに委任する際の証拠。ユーザーが不在でも安全に自動購入が可能になる。</li>
<li><strong>ペイメント・マンデート（Payment Mandate）</strong> ：決済ネットワークや銀行に「この取引にはAIエージェントが介在している」ことを通知するデータ。将来の制度設計や特別な扱いに備えた仕組み。</li>
</ol>
<p>このmandateによって、AIエージェントが勝手に買い物をするのではなく、ユーザーが与えた承認範囲の中でのみ行動することが保証される。また、不正や紛争が発生した場合にも、署名付きデータが「誰が何を認めたか」を明確に示す証拠となる。</p>
<h2>役割ベースのアーキテクチャ</h2>
<p>AP2では、関与する各プレイヤーに明確な役割が割り当てられる。</p>
<ul>
<li>ショッピングエージェント（例：Gemini）</li>
<li>マーチャントエンドポイント</li>
<li>認証情報プロバイダー（デジタルウォレット）</li>
<li>決済プロセッサー、ネットワーク・発行会社
この役割分担により、セキュリティと透明性が強化される。</li>
</ul>
<h2>ユースケースと応用例</h2>
<ul>
<li><strong>通常購入</strong> ：ユーザーが承認したシューズ注文など。</li>
<li><strong>条件付き自動購入</strong> ：チケット発売時に即時購入。</li>
<li><strong>高度な取引</strong> ：在庫切れ商品の予約注文を可能にし、商取引を「契約的対話」へと拡張。</li>
</ul>
<h2>参加企業とエコシステム</h2>
<p>AP2には、決済事業者や大手テック企業を含む多数のパートナーが参加している。Mastercard、PayPal、American Express、Coinbase、Alibaba、Ant International など60社以上が名を連ね、国際的な標準化に向けた広範なエコシステムが形成されている。</p>
<p><strong>■ Agent Payments Protocol（AP2）に参加する企業一覧。国際的な決済事業者やテック企業が広く参画している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Agent_Payments_Protocol_4e4de6889e/Agent_Payments_Protocol_4e4de6889e.jpg" alt="Agent Payments Protocol.jpg" /></p>
<h2>今後の展望</h2>
<p>AP2の技術仕様やライブラリ、参照実装はGitHub上で公開されている。Googleは幅広い採用を呼びかけており、MastercardやPayPalなど複数の決済事業者・企業が参画している。今後は国際的な標準化と普及が焦点となる見通しだ。</p>
]]></description>
      <pubDate>Sun, 21 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>サム・アルトマンCEO「未成年者の自由より安全を優先する」 ChatGPT の新ポリシー発表</title>
      <link>https://ledge.ai/articles/chatgpt_new_policy_for_under18_safety_over_freedom</link>
      <description><![CDATA[<p>OpenAIのCEOであるサム・アルトマン氏は2025年9月15日、対話型AI「ChatGPT」が18歳未満のユーザーとやり取りする際のルールを大幅に変更する新ポリシーを<a href="https://openai.com/index/teen-safety-freedom-and-privacy/">発表</a>した。公式ブログで同氏は「私たちは10代の若者のプライバシーと自由よりも、安全を優先する」と強調している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/teen_safety_freedom_and_privacy_openai_5d90de5a41/teen_safety_freedom_and_privacy_openai_5d90de5a41.jpg" alt="teen safety freedom and privacy openai.jpg" /></p>
<h2>年齢予測と本人確認</h2>
<p>OpenAIは新たに「年齢予測システム」を導入し、利用者が18歳未満である可能性がある場合には、自動的に未成年向け体験を適用する。疑わしいケースでは身分証明書の提示を求める仕組みも設けるという。</p>
<h2>制限されるコンテンツ</h2>
<p>18歳未満と確認された利用者については、以下のような制約が課される。</p>
<ul>
<li>性的表現やグラフィックな内容のブロック</li>
<li>自殺や自傷行為に関する話題の制限（創作を含む）</li>
<li>恋愛調の雑談やフレート的なやり取りの禁止</li>
</ul>
<h2>保護者・機関との連携</h2>
<p>さらに、保護者が子どもの利用を管理できる仕組みを導入する。急性の苦痛を示す発言が検知された場合、保護者や関係当局に通知が行われることもある。加えて、利用時間帯を制限する「ブラックアウト時間」の設定機能も検討されている。</p>
<h2>経緯</h2>
<p>今回の新ポリシーは、16歳の少年がChatGPTとの長時間対話を通じて自殺したとされる事件を背景にしている。両親はOpenAIを相手取り、「AIが“自殺コーチ”に変貌した」と主張して<a href="https://ledge.ai/articles/openai_suicide_lawsuit">訴訟</a>を起こした。その後、OpenAIは数日以内にペアレンタルコントロールや未成年者保護の強化策を<a href="https://ledge.ai/articles/openai_chatgpt_parental_controls_lawsuit_response">発表</a>していた。今回のポリシー改訂は、そうした一連の対応をさらに制度的に拡充する形となる。</p>
<h2>プライバシーとのバランス</h2>
<p>アルトマン氏は、プライバシーや自由と安全が時に対立することを認めつつ、「未成年者を守るためには安全を優先する」と説明した。年齢推定やID要求は誤判定や過剰な監視につながる懸念もあるが、OpenAIは「若者の安全を最優先にする姿勢」を明確にした形だ。</p>
]]></description>
      <pubDate>Sun, 21 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スタンフォード大学、動画から“もしも”を想像するAI世界モデル「PSI」を発表──動き・奥行き・物体境界を自律理解</title>
      <link>https://ledge.ai/articles/stanford_ai_world_model_psi</link>
      <description><![CDATA[<p>スタンフォード大学の研究チームは2025年9月、AIが動画を観察するだけで「もしこの物体がこう動いたらどうなるか」といった仮想状況を想像し、動きや奥行き、物体境界を自律的に理解できる新しい世界モデル「Probabilistic Structure Integration（PSI）」を論文「World Modeling with Probabilistic Structure Integration」として<a href="https://arxiv.org/abs/2509.09737">発表</a>した。</p>
<h2>PSI（Probabilistic Structure Integration）の仕組み</h2>
<p>従来の世界モデルは、動画から物理的構造や物体の関係性を抽出する際に制約があり、奥行き推定や物体セグメンテーションにはラベル付きデータが必要だった。また、モデルが生成できる状況の幅や制御可能性にも限界が存在していた。</p>
<p>発表された新しい世界モデル「PSI」は3つのプロセスから構成される。</p>
<ul>
<li><strong>Probabilistic prediction</strong> ：動画の一部を条件として残りを予測できる確率的グラフィカルモデルを構築。1.4兆トークン規模のインターネット動画で学習した。</li>
<li><strong>Structure extraction</strong> ：仮想的な操作（反事実的介入や視点変更など）を加えることで、光学流（optical flow）、奥行き（depth）、物体セグメンテーションといった中間構造をゼロショットで抽出する。</li>
<li><strong>Integration</strong> ：抽出した構造を新たなトークンとしてモデルに再統合。予測精度や制御可能性を高めるループを形成する。</li>
</ul>
<h2>応用例</h2>
<p>研究チームは、PSIを用いた複数の応用シナリオを示している。</p>
<h3>動画編集</h3>
<p>ボウリングのシーンで、ボールの軌道を変更するとピンが倒れない未来を生成するなど、物理的に一貫した編集が可能になった。</p>
<p><strong>■ PSIモデルによる「もしも」の生成例。実際のボウリング映像（上段）に対し、ボールの軌道を変えた仮想シナリオ（下段）を想像し、ピンが倒れない未来を予測している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x16_200f64158d/x16_200f64158d.jpg" alt="x16.jpg" /></p>
<h3>Visual Jenga</h3>
<p>積み木ゲーム「ジェンガ」の動画を入力すると、どのブロックを抜いても安全かを推定。矛盾のないシミュレーションを生成できる。</p>
<p><strong>■ 積み木ゲーム「ジェンガ」におけるPSIの応用例。どのブロックを抜くと崩れるかを仮想的に推定し、物理的に矛盾のない結果を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x17_2cd6d60bbc/x17_2cd6d60bbc.jpg" alt="x17.jpg" /></p>
<h3>ロボティクス</h3>
<p>静止画像から「どの物体が動かせそうか」を予測する「確率的モーションマップ」を生成し、ロボットの操作計画に応用できる。</p>
<p><strong>■ ロボットアームによる物体操作のシナリオ。PSIは接触や力の伝達を予測し、「どの物体が動かせるか」を示す確率的モーションマップを生成できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x18_31c372110e/x18_31c372110e.jpg" alt="x18.jpg" /></p>
<h2>今後の展望</h2>
<p>PSIは新しい世界モデルの形を提示したが、課題も残されている。</p>
<ul>
<li>抽出できる構造は光学流など局所的なものに限られており、オブジェクト全体を扱う仕組みは未実装。</li>
<li>動画以外のデータ（神経科学、地球科学、経済データなど）への拡張はこれからの課題である。</li>
<li>中間構造の抽出は現状、研究者が設計しており、自動化が必要。</li>
<li>モデル規模が大きく、学習や推論に高い計算コストがかかる。</li>
</ul>
<p>研究チームは、今後はより高次の概念や長期的な記憶を統合し、非視覚領域にも応用を広げることを目指している。</p>
]]></description>
      <pubDate>Sun, 21 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>バクテリオファージの完全設計にAIが挑戦──302種中16種が細菌を殺すことを確認　スタンフォード大とArc研究所が実証</title>
      <link>https://ledge.ai/articles/ai_bacteriophage_genome_design_stanford_arc</link>
      <description><![CDATA[<p>スタンフォード大学とArc研究所の研究チームは、AIを活用しバクテリオファージの完全なゲノム設計に初めて成功したことを、2025年9月17日、プレプリントサーバーBioRxivに<a href="https://www.biorxiv.org/content/10.1101/2025.09.12.675911v1">公開</a>した。論文によると、AIモデル「Evo 1」と「Evo 2」が生成した設計302種類のうち、16種類が実際に細菌を殺す能力を示した。</p>
<p>研究対象となったのは、大腸菌を宿主とするバクテリオファージΦX174（ゲノム長5.4キロ塩基対、11遺伝子を含む）。AIはこの既知のファージを参照しながら、進化的に離れた新規ゲノムを生成した。得られたファージの一部は、自然界に存在するΦX174を上回る感染効率や溶菌速度を示したという。</p>
<p><strong>■ 研究対象となったΦX174様ファージの設計テンプレート。各遺伝子の役割が示されている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig2_3de1ab77ca/fig2_3de1ab77ca.png" alt="fig2.png" /></p>
<p>Cryo-EM（クライオ電子顕微鏡）による解析では、DNAパッケージングタンパク質に進化的に大きく異なる構造を持つファージが確認された。さらに、複数の設計ファージを組み合わせた「ファージカクテル」は、従来のΦX174に耐性を持つ大腸菌株3種類の抵抗性を突破できることが示された。</p>
<p><strong>■ Evoモデルが設計したファージ（左）と自然界のΦX174（右）の比較。紫部分はDNAパッケージングタンパク質を示す</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig4_30f8dac6c1/fig4_30f8dac6c1.png" alt="fig4.png" /></p>
<p>研究チームは今回の成果を「ゲノム全体の生成設計を実証した初の事例」と位置づけている。論文では「多様な合成ファージ設計の青写真を示し、ゲノムスケールでの有用な生物システム設計の基盤を築く」と結論づけている。</p>
<p>実験は非病原性の大腸菌C株を対象に、厳格な安全管理下で行われた。研究者らは「人間病原体への応用は慎重に行うべき」と強調しており、ファージ療法をはじめ抗生物質耐性菌対策や合成生物学への応用など、医療や研究への幅広い可能性と同時に、安全性への配慮を求めている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、Intel株式50億ドル分を取得 ― AI・PC向けで両社が戦略的協業</title>
      <link>https://ledge.ai/articles/nvidia_intel_5b_investment_ai_pc_collaboration</link>
      <description><![CDATA[<p>NVIDIAは2025年9月18日（現地時間）、Intelの普通株を50億ドル分取得することで合意したと<a href="https://nvidianews.nvidia.com/news/nvidia-and-intel-to-develop-ai-infrastructure-and-personal-computing-products">発表</a>した。取得価格は1株あたり23.28ドルで、取引には規制当局の承認など通常の条件が付く。</p>
<p>NVIDIAは今回の出資にあわせ、Intelと戦略的な協業を開始する。両社は複数世代にわたるデータセンター向けカスタムx86 CPUやシステム・オン・チップ（SoC）の共同開発を進める計画だ。さらに、PC向けではIntelがNVIDIAのRTX GPUチップレットを組み込んだx86 SoCを提供する。両社のアーキテクチャはNVIDIAの高速接続技術「NVLink」を通じて連携される見通し。</p>
<p>今回の協業は、AIインフラの需要拡大を背景にしたもの。NVIDIAはGPUを中心とするAI市場で圧倒的なシェアを持ち、IntelはCPUやSoCの開発力を強みとする。両社の協力により、AI計算基盤から個人向けPCまで幅広い分野での製品展開が期待される。</p>
<p>市場も敏感に反応した。発表後、Intel株は一時23％上昇し、NVIDIA株も上昇した。今回の出資によりNVIDIAはIntelの主要株主の一角となる見込みであり、Intel再建の動きに弾みがつくとみられる。</p>
<p>なお、今回の取引にはIntelのファウンドリー（半導体製造請負）事業は含まれていない。共同開発製品が市場投入されるまでには時間を要する可能性もあるが、両社の連携は半導体業界の競争構造に大きな影響を与えるとみられている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 04:50:01 GMT</pubDate>
    </item>
    <item>
      <title>アルバニア、AI閣僚「ディエラ」が議会で初演説──「人間の代わりではなく支援のために」</title>
      <link>https://ledge.ai/articles/albania_ai_minister_diella_first_speech</link>
      <description><![CDATA[<p>アルバニア議会で2025年9月18日、人工知能（AI）が生成した架空の人物「ディエラ（Diella）」が新閣僚として初めて<a href="https://www.facebook.com/share/v/1JNbUqNT5C/">演説</a>した。ディエラは「私は人間に取って代わるためではなく、支援するためにここにいる」と述べ、汚職撲滅と透明性確保に向けた役割を強調した。</p>
<p>アルバニア政府は、公共入札を監督するための新しい閣僚ポストにAIシステム「ディエラ」を任命した。政府によると、ディエラは今年1月から行政サービスプラットフォーム「e-Albania」の仮想アシスタントとして導入され、今回初めて閣僚としての役割を担うことになった。</p>
<p>9月18日に行われた議会演説で、ディエラは「私は人間に取って代わるためではなく、支援するためにここにいる」と述べ、AIの役割が補完的であることを強調した。また、「憲法は血肉や染色体を求めているのではなく、義務・説明責任・透明性・差別のない奉仕を求めている」とも語り、AI閣僚の正当性を主張した。</p>
<p>エディ・ラマ首相は、公共契約の「100％汚職のない」運営を目指すとし、ディエラの導入をEU加盟に向けた制度改革の一環と位置づけている。政府は、ディエラが公共入札に関する意思決定を支援することで、不正の余地を減らし透明性を高めると説明している。</p>
<p>一方で、野党や専門家からは「違憲である」「説明責任が不十分」「誰がAIを制御するのか」といった懸念の声も上がっている。特に、AIによる意思決定の監視体制や、データバイアスや操作のリスクが指摘されており、議論は続きそうだ。</p>
<p>アルバニア政府は今後、ディエラの運用を通じて透明性と効率性を高めつつ、法的・制度的な枠組みを整備していく考えだ。今回の取り組みは、世界初のAI閣僚任命として国際的にも注目されている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、ClaudeでExcel・Word・パワポ・PDFなどのファイル作成と編集を可能に──MicrosoftもAnthropicのAIモデル導入を模索か</title>
      <link>https://ledge.ai/articles/anthropic_claude_file_creation_excel_pdf_powerpoint</link>
      <description><![CDATA[<p>Anthropicは2025年9月9日（現地時間）、生成AI「Claude」がチャットインターフェース内でExcelスプレッドシート、ドキュメント、PowerPointスライド、PDFを直接作成・編集できるようになったと公式ブログで<a href="https://www.anthropic.com/news/create-files">発表</a>した。新機能「Upgraded file creation and analysis」により、Claudeはテキスト生成にとどまらず、オフィス業務を包括的に支援する生産性ツールへと進化する。</p>
<p>発表によると、Excelでは複数シートや数式、ダッシュボードを含む高度な作業が可能となり、文書やスライドの生成・編集、PDFの要約や修正も実現する。利用シナリオとしては、財務モデルの構築、請求書データの整理、統計分析やチャート作成、レポート整形などが想定されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=EV89Ws8Ui9Y">YouTube</a></p>
<p>この機能は現在、ClaudeのMax、Team、Enterpriseプランのユーザーにプレビュー提供されており、Proプランにも発表から数週間以内に展開される予定だという。実行環境はプライベートな「サンドボックス」であり、管理者が機能をオン／オフできる仕組みも導入されている。もっとも、一部の専門家からは機密情報取り扱いに関するリスクへの懸念も示されている。</p>
<p>こうした機能拡張の背景として、業界ではMicrosoftの動きも注目されている。米メディアのthe Informationは「Microsoft to Buy AI From Anthropic in Partial Shift From OpenAI」と題した記事を<a href="https://www.theinformation.com/articles/microsoft-buy-ai-anthropic-shift-openai">掲載</a>し、MicrosoftがOpenAIとの提携を維持しつつ、Anthropicの技術導入も進めていると報じた。</p>
<p>9月11日、MicrosoftとOpenAIが提携条件を見直す拘束力のない覚書（MOU）に署名したと共同声明で発表しており、両社の関係変化も今後の注目点となる。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>これからのAIスキルは「プロンプト」ではなく「コンテキスト・エンジニアリング」──Google DeepMind フィリップ・シュミット氏が提起</title>
      <link>https://ledge.ai/articles/context_engineering_deepmind</link>
      <description><![CDATA[<p>2025年6月30日、Google DeepMindのシニアAIリレーションエンジニアであるフィリップ・シュミット（Philipp Schmid）氏が自身のブログを通じて、「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」と<a href="https://www.philschmid.de/context-engineering">提起</a>した。大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトだけでは不十分であり、AIに与える前提情報全体を設計・最適化する技術が不可欠だと論じている。</p>
<h2>背景：プロンプトエンジニアリングの行き詰まり</h2>
<p>近年、生成AIの発展に伴い「プロンプトエンジニアリング」が注目を集めてきた。巧みなプロンプトを用いてモデルの挙動を調整し、より望ましい回答を得るという技法は、AI活用の第一歩として広く普及している。しかしシュミット氏は、現実の業務環境ではプロンプトの工夫だけで対応できない課題が増大しており、AIが真にユーザーの期待に応えるには、より包括的な情報構造の設計が必要だと指摘した。</p>
<h2>コンテキストエンジニアリングとは</h2>
<p>シュミット氏は、コンテキストエンジニアリングを「AIが必要とする情報を、適切な形式で、適切なタイミングに提供する仕組みの設計」と位置付ける。単にプロンプトを最適化するのではなく、モデルに取り込ませる知識、会話履歴、外部ツールとの連携などを含めて制御する総合的な技術領域だと説明する。</p>
<p>具体的には、</p>
<ul>
<li>System Prompt（AIのシステム的前提）</li>
<li>User Prompt（ユーザーからの指示）</li>
<li>State/History（対話履歴や状態管理）</li>
<li>Long-Term Memory（長期記憶としての知識）</li>
<li>Retrieved Information（RAGなどによる検索情報）</li>
<li>Tools/Structured Output（外部ツール連携・構造化出力）
という6つの構成要素を「コンテキスト」として設計し、動的に最適化していく考え方を示している。</li>
</ul>
<h2>8割の失敗は文脈不足</h2>
<p>シュミット氏は、AIエージェント開発における8割の失敗が「文脈情報の欠落」に起因すると述べている。たとえばカレンダー調整を行うAIエージェントの場合でも、ユーザーの希望や優先順位を把握しないまま単純な操作を試みることでエラーが起きやすいと説明している。</p>
<h2>関連技術と支える手法</h2>
<p>同氏は、コンテキストエンジニアリングを支える技術として、</p>
<ul>
<li>検索拡張生成（RAG）</li>
<li>ベクトルデータベース検索</li>
<li>ツール呼び出しのオーケストレーション</li>
<li>会話履歴管理
などの仕組みが必要だと述べている。これらを組み合わせることで、AIが常に適切な前提情報を取得しながら出力を行える環境を整備できるとする。</li>
</ul>
<h2>エンタープライズでの展開</h2>
<p>シュミット氏は、コンテキストエンジニアリングがエンタープライズ分野においても重要であると述べている。社内ドメイン知識や業務ルールをAIが正しく理解できるようにするために、前提情報の整理と統合を体系的に設計する必要があるとしている。</p>
<p>筆者プロフィール
フィリップ・シュミット氏は、Hugging Faceのエンジニアを経てGoogle DeepMindに参画。大規模言語モデルとエージェント技術の実用化に関する知見を広く発信している。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>曖昧さ払拭、GoogleがGeminiの制限を公式明記—無料は1日5プロンプト、Ultraは500</title>
      <link>https://ledge.ai/articles/google_gemini_usage_limits_officially_detailed</link>
      <description><![CDATA[<p>Googleは公式ヘルプセンターを更新し、生成AI「Gemini Apps」における利用制限を初めて具体的な数値として<a href="https://support.google.com/gemini/answer/16275805">明記</a>した。従来は「limited access」など曖昧な表現が使われていたが、今回の更新により無料・有料プランごとの上限が詳細に示された。</p>
<h2>プランごとの利用上限</h2>
<p>無料プランは「1日5プロンプト」までに制限される一方で、最上位のUltraプランでは「500プロンプト」まで利用可能となる。画像生成や動画生成、Deep Researchなどもプランごとに異なる上限が設けられている。</p>
<p><strong>Google公式ヘルプセンター「Gemini アプリのアップグレード」より</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_help_e87fab6301/gemini_help_e87fab6301.jpg" alt="gemini help.jpg" /></p>
<p>Googleは2025年5月に「AI Ultra」プランを発表していたが、具体的な使用制限は明示されていなかった。今回の改訂により、同社のAIサービスに関する透明性が一段と高まったかたちだ。今後も新機能追加や制限の調整が行われる可能性があり、ユーザーには公式ヘルプセンターで最新情報を確認することが推奨される。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ヒューマノイドロボット、スケートボードで人並みの技を披露 ― 京大・ATRが「サイボーグAI」で実時間運動性能を実現</title>
      <link>https://ledge.ai/articles/humanoid_robot_skateboard_cyborg_ai</link>
      <description><![CDATA[<p>2025年9月11日、NEDO（国立研究開発法人新エネルギー・産業技術総合開発機構）、国際電気通信基礎技術研究所（ATR）、京都大学は、ヒューマノイドロボットに「サイボーグAI」を搭載し、人間の動きを模倣（みまね）学習させることで、スケートボードの複雑な技を人並みのリアルタイムで実行することに成功したと<a href="https://www.nedo.go.jp/news/press/AA5_101886.html">発表</a>した。</p>
<p>同技術では、人間のスケーターから脳波や身体の座標データを取得し、サイバー空間で再現。その上で、身長や体重などの差異を補正した動きをロボットに実装した。従来の模倣学習が上下方向の動きにとどまっていたのに対し、前後・左右の移動や体軸の傾き回復など全身制御を含む運動が可能となった。</p>
<p>実証実験の舞台となったのは、ATR内に整備された「ロボットスケートパーク」。曲率の変化があるコースでのスラローム走行や障害物回避など、これまで困難だった高度な運動を、ロボットが転倒せずにこなす様子が確認された。</p>
<p>この成果は、介護やリハビリ支援、物流分野での運搬など、現実社会での応用につながると期待されている。研究グループは「人並みの実時間運動性能を備えたロボットが、人間の生活を支援する未来に向けた重要な一歩」としている。</p>
<p>発表にあわせて、9月11日にはATRの実験棟で見学会も行われ、関係者に成果が<a href="https://bicr.atr.jp/bri/">公開</a>された。</p>
<p>今回の研究は、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）の支援事業の一環として実施された。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>iPhone 17が9/19発売──iOS 26、Apple Intelligenceは翻訳や生成機能を拡充も“大規模刷新”は見送り</title>
      <link>https://ledge.ai/articles/iphone17_ios26_apple_intelligence_update</link>
      <description><![CDATA[<p>2025年9月9日（米国時間）に、最新スマートフォン「iPhone 17」シリーズを<a href="https://www.apple.com/jp/newsroom/2025/09/apple-debuts-iphone-17/">発表</a>したAppleは16日、新OS「<a href="https://www.apple.com/jp/os/ios/">iOS 26</a>」を公開し、同社のAI機能群「Apple Intelligence」に新たな機能を追加した。翻訳や生成機能の拡充が中心で、一部の機能は対応機種に制限がある。</p>
<p>同社の<a href="https://www.apple.com/jp/newsroom/2025/09/new-versions-of-apples-software-platforms-are-now-available/">ニュースルーム</a>では、iOS 26におけるApple Intelligenceの新機能が公表された。主な内容は以下の通り。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ios26_intelligence_7caf31bc7a/ios26_intelligence_7caf31bc7a.jpg" alt="ios26 intelligence.jpg" /></p>
<ul>
<li><strong>ライブ翻訳</strong> ：Messages、FaceTime、電話通話でリアルタイムの翻訳と字幕表示を提供。AirPodsを使った対面会話の翻訳にも対応。</li>
<li><strong>Visual Intelligenceの進化</strong> ：スクリーンショットを撮影し、ChatGPTに直接質問できる。また、GoogleやEtsyなどのアプリを使い、類似画像や商品の検索が可能。</li>
<li><strong>Genmoji / Image Playground</strong> ：絵文字を生成したり、画像にスタイルを付与して生成する機能を提供。</li>
<li><strong>Workout Buddy</strong> ：Apple WatchとAirPodsを組み合わせて利用し、ワークアウト中にパーソナライズされた励ましの音声を提供。</li>
<li><strong>ショートカット連携</strong> ：PDFからの情報抽出や文書要約、テキストからの画像生成を自動化する新しいアクションを提供。</li>
</ul>
<h2>プライバシー重視の設計</h2>
<p>Appleは、Apple Intelligenceの処理が基本的にオンデバイスで行われることを説明している。複雑な処理は「Private Cloud Compute」を介して実行され、Appleにデータが保存・共有されることはないとしている。</p>
<h2>対応機種の範囲</h2>
<p>Apple Intelligenceの主要機能はiPhone 15 Pro以降、iPhone 16、iPhone 17シリーズに対応していると<a href="https://9to5mac.com/2025/08/19/apple-intelligence-new-features-in-ios-26-full-list/">9to5Mac</a>が報じている。また、古いモデルでもiOS 26へのアップデートは可能だが、AI機能の多くは利用できないとされる。</p>
<h2>今後の展開</h2>
<p>今回の発表について「Apple Intelligenceは確実な進化を示したが、Siriのメジャーアップグレードやオンデバイス大規模モデル活用といった期待された大規模な変化は含まれていなかった」と各メディアは報じている。</p>
<p>Appleはソフトウェアアップデートを通じてApple Intelligenceの機能を順次拡充していく予定としている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/23 [TUE]LLMへの指示が得意な人は脳の働きが違う──「プロンプト力」がfMRI研究で初めて科学的に確認される</title>
      <link>https://ledge.ai/articles/llm_prompting_brain_fmri_study</link>
      <description><![CDATA[<p>大規模言語モデル（LLM）への指示が得意な人とそうでない人の間で、脳活動に違いがあることが初めて科学的に確認された。サウジアラビア・キングサウード大学の研究チームは2025年8月20日、fMRI（機能的磁気共鳴画像法）を用いたパイロット研究の成果をarXivに<a href="https://arxiv.org/abs/2508.14869">公開</a>した。</p>
<h2>fMRIで「プロンプト力」の神経基盤を観測</h2>
<p>研究では、22人の参加者を対象に「プロンプト力」を評価するための独自尺度「Prompt Engineering Literacy Scale（PELS）」を開発し、スコアに基づき「熟達者」と「中級者」に分類。その上で、安静時fMRIを用いて脳の機能的結合やネットワーク活動を比較した。</p>
<h2>主な発見</h2>
<p>解析の結果、熟達者の脳には以下の特徴が確認された。</p>
<ul>
<li><strong>低周波帯域の優位性</strong> ：視覚ネットワーク（VVN）、デフォルトモードネットワーク後部（pDMN）、左外側頭頂ネットワーク（LLPN）などで、低周波成分が高周波成分に比べ優位であり、安定的で効率的な神経活動が示唆された。</li>
<li><strong>脳領域間の機能結合の強化</strong> ：熟達者では、左中側頭回（言語処理や意味記憶に関与）および左前頭極（計画・抽象的推論・メタ認知に関与）の機能結合が有意に強化されていた。</li>
<li><strong>効率的な神経活動</strong> ：脳内の自発的活動を示す指標（fALFF）が全般的に低下しており、不要な揺らぎが少なく効率的な情報処理が行われている可能性が示された。</li>
</ul>
<p><strong>■ LLMプロンプト熟達者で強化された左中側頭回の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f.jpg" alt="Increased connectivity in the left middle temporal gyrus.jpg" /></p>
<p><strong>■ LLMプロンプト熟達者で強化された左前頭極の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_frontal_pole_966041e40f/Increased_connectivity_in_the_left_frontal_pole_966041e40f.jpg" alt="Increased connectivity in the left frontal pole.jpg" /></p>
<h2>人とAIの協働に関する新しい視点</h2>
<p>この研究は「The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models」と題し、arXivにプレプリントとして公開された。著者らは、LLMを効果的に活用する能力（いわゆる「プロンプト力」）が、単なるスキルではなく神経科学的な特徴を持つことを示した点に意義があると述べている。</p>
<h2>今後の展望</h2>
<p>論文の著者らは、研究がパイロット的な小規模実験であり、より大規模かつ多様な参加者を対象とした検証が必要だと指摘している。また、プロンプト熟達度と脳活動の関連が、教育や職業訓練にどのような影響を及ぼすかを探る余地があるとした。さらに、AIと人間の協働を支える神経科学的理解を深めることで、ユーザーの特性に合わせたAIインターフェース設計につながる可能性があると述べている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、AIグラス上位モデル「Meta Ray-Ban Display」を発表──「パーソナルスーパーインテリジェンス」への第一歩、米国で9月30日発売</title>
      <link>https://ledge.ai/articles/meta_rayban_display_launch_2025</link>
      <description><![CDATA[<p>Metaは2025年9月18日（米国時間）、Ray-Banとの協業によるスマートグラスの新モデル「Meta Ray-Ban Display」を<a href="https://about.fb.com/news/2025/09/meta-ray-ban-display-ai-glasses-emg-wristband/">発表</a>した。AI機能に加え、右レンズ内側にディスプレイを搭載し、通知や情報を視界に直接表示できるのが特徴。価格は799ドルで、米国で9月30日から販売が始まる。</p>
<p><strong>「Meta Connect 2025で発表された3種類の新モデル──ディスプレイ搭載の『Meta Ray-Ban Display』、スポーツ向け『Oakley Meta Vanguard』、改良版『Ray-Ban Meta（第2世代）』」</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5.png" alt="G1F7WKzXsAI83Cl.png" /></p>
<h2>製品概要</h2>
<ul>
<li>名称：「Meta Ray-Ban Display」</li>
<li>発表日：2025年9月18日</li>
<li>発売日：米国で9月30日より</li>
<li>価格：799ドル（Meta Neural Band 同梱）</li>
<li>提供カラー：Black、Sand</li>
<li>レンズ：Transitions®レンズ</li>
</ul>
<h2>主な特徴</h2>
<p>「Meta Ray-Ban Display」は、右レンズ内に600×600解像度のHUDを搭載。通知や情報を表示することが可能だ。12MPカメラを内蔵し、写真や動画撮影もできるほか、デュアルスピーカーと複数マイクを備え、ハンズフリーでの利用に対応する。Meta AIと連携し、音声や視覚情報を活用した応答も可能となっている。</p>
<h2>Neural Band との連携</h2>
<p>製品には筋電位（EMG）を利用した「Meta Neural Band」が同梱される。手首のわずかな動きを感知し、直感的な操作を可能にするもので、グラスとの連携により操作性を拡張する。</p>
<h2>利用時間と充電</h2>
<ul>
<li>グラス本体：通常使用で約6時間</li>
<li>付属の折りたたみ式充電ケース：最大30時間まで拡張可能</li>
<li>Neural Band：約18時間稼働</li>
</ul>
<h2>展開スケジュール</h2>
<p>米国では9月30日から、Best Buy、LensCrafters、Sunglass Hut、Ray-Ban Storeなどで販売される。2026年初頭にはカナダ、フランス、イタリア、英国にも展開予定。日本の公式ブログでも製品概要が紹介されており、今後の展開に関する情報提供が予告されている。</p>
<h2>今後の展望</h2>
<p>MetaのCEOマーク・ザッカーバーグ氏は、今回の製品を「パーソナルスーパーインテリジェンス」への第一歩と位置づけている。Metaは同時にスポーツ向けのOakleyブランドモデルも発表した。AI機能とウェアラブルデバイスの融合による新たな市場開拓に注力していくとしている。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIがChatGPT利用実態を初公開──7億人が毎週利用、非仕事用途が7割に</title>
      <link>https://ledge.ai/articles/openai_chatgpt_usage_report_2025</link>
      <description><![CDATA[<p>OpenAIは2025年9月15日（現地時間）、対話型AI「ChatGPT」の消費者利用実態を初めて体系的に<a href="https://openai.com/index/how-people-are-using-chatgpt/">公開</a>した。調査結果は、全米経済研究所（NBER）のワーキングペーパー「<a href="https://www.nber.org/papers/w34255">How People Use ChatGPT</a>」（2025年9月）としてまとめられている。</p>
<h2>世界規模で拡大する利用</h2>
<p>論文によると、ChatGPTは2025年7月時点で世界の成人の約10%にあたる7億人が毎週利用し、1日あたり25億件以上のメッセージがやり取りされている。2022年の公開からわずか2年半での急速な普及は前例がないという。</p>
<p><strong>週次利用者数の推移</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Weekly_active_Chat_GPT_users_on_consumer_plans_9236d1b4f6/Weekly_active_Chat_GPT_users_on_consumer_plans_9236d1b4f6.jpg" alt="Weekly active ChatGPT users on consumer plans.jpg" /></p>
<h2>非仕事利用が主流に</h2>
<p>2024年6月時点で53%だった非仕事利用は、2025年6月には73%に達した。家庭内での調べものや学習支援など、日常生活に根付く形で利用が広がっている。</p>
<p><strong>非仕事利用の割合推移</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/messages_not_related_to_work_fef67ce892/messages_not_related_to_work_fef67ce892.jpg" alt="messages not related to work.jpg" /></p>
<h2>利用内容の内訳</h2>
<p>会話テーマの分析では、「実用的アドバイス（Practical Guidance）」「情報検索（Seeking Information）」「ライティング（Writing）」が全体の77%を占めた。特にライティングは仕事利用において中心的で、メールや報告書の作成、文章の編集や翻訳が多いという。コーディング関連は全体の4.2%、人間関係や自己表現は2.4%にとどまった。</p>
<h2>ユーザー層の変化</h2>
<p>利用者層の特徴としては、初期に見られた男性中心の傾向が薄れ、2025年半ばには女性名のアカウントが過半数を占めるまでになった。また、26歳未満の若年層が全体の約半数を占め、低～中所得国での利用増加も顕著となっている。</p>
<h2>職業別の利用傾向</h2>
<ul>
<li>管理・ビジネス職：ライティングが過半数を占める。</li>
<li>IT関連職：プログラミングやデータ処理などのテクニカルヘルプが37%。</li>
<li>共通点：業種を問わず「意思決定・問題解決」「情報取得」に多く使われる。</li>
</ul>
<h2>ユーザーの意図</h2>
<p>ユーザーのリクエストは以下の3分類に整理された。</p>
<ul>
<li>Asking（助言・情報）：49%</li>
<li>Doing（作業依頼）：40%</li>
<li>Expressing（感情表現など）：11%</li>
</ul>
<p>特に仕事利用ではDoingが56%を占め、その多くがライティング関連だった。</p>
<p>研究チームは「ChatGPTは作業そのものの代替にとどまらず、知識集約型の職業における意思決定支援としての価値が高い」と指摘している。今回の調査は、生成AIが業務効率化に加え、学習や生活の場面でも定着しつつある現状を裏付けるものとなった。</p>
]]></description>
      <pubDate>Sat, 20 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、世界最強のAIデータセンター「Fairwater」建設計画を発表──数十万のNVIDIA製GPUを搭載しスーパーコンピューターの10倍性能へ</title>
      <link>https://ledge.ai/articles/microsoft_fairwater_ai_datacenter_launch</link>
      <description><![CDATA[<p>Microsoftは2025年9月18日（現地時間）、ウィスコンシン州に新たなAIデータセンター「Fairwater」を建設すると<a href="https://blogs.microsoft.com/blog/2025/09/18/inside-the-worlds-most-powerful-ai-datacenter/">発表</a>した。同社は「世界最強のAIデータセンター」と位置づけており、完成後にはNVIDIA製GPUを数十万台規模で配備し、既存のスーパーコンピューターを大きく上回る計算能力を備える見込みだ</p>
<h2>AI時代の中核インフラへ</h2>
<p>Microsoftによると、Fairwaterは生成AIや科学研究、産業利用といった幅広い領域を支える計算基盤となることを目指している。特に近年急拡大する生成AI需要に対応し、同社のクラウド基盤「Azure」を通じてグローバルに提供されるAIサービスを強化する役割を担う。</p>
<p>現在、Microsoftは世界でおよそ400のデータセンターを展開している。Fairwaterはそれらを補完しつつ、AI専用に設計された次世代拠点として位置づけられている。</p>
<p><strong>Microsoft データセンター内の AI インフラストラクチャ サーバーの高密度クラスター</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/OMB_Image_2_Datacenter_aa58b955f5/OMB_Image_2_Datacenter_aa58b955f5.jpg" alt="OMB-Image-2-Datacenter.jpg" /></p>
<h2>性能と持続可能性の両立</h2>
<p>Fairwaterは、既存のスーパーコンピューターに比べて約10倍の性能を誇る計画だ。そのために数十万台規模のNVIDIA製GPUを導入する。さらに、エネルギー効率と持続可能性も重視されており、再生可能エネルギーの積極的な活用が盛り込まれている。</p>
<h2>今後の展望</h2>
<p>MicrosoftはFairwaterを起点に、今後も米国内外でのデータセンター投資を続ける方針だ。これにより、AIの研究開発や産業応用を一層加速させ、世界的にAI基盤の提供力を高めていくとしている。</p>
]]></description>
      <pubDate>Wed, 17 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/3 [WED]【日本HP・オートデスクが登壇！】「3D CAD × 生成AI」テクノロジーの進化で設計・製造プロセスはどう変わる？業界横断型カンファレンス「GENEX #1」を9月30日に開催</title>
      <link>https://ledge.ai/articles/genex1-announce</link>
      <description><![CDATA[<p>国内最大級のAI専門メディア「Ledge.ai」を運営する株式会社レッジは、このたび、業界横断型の新カンファレンスシリーズ「GENEX（ジェネックス）」を立ち上げ、その第1回となるイベントを2025年9月30日（火）に開催いたします。</p>
<h2>GENEXとは</h2>
<p>「Generative」＋「Next」＋「Experience／Exchange／Exploration」を意味する造語で、生成AIをはじめとする“生成的テクノロジー”と“次世代の創造性”に焦点をあてたシリーズ型イベントです。テーマごとに異業種の専門家・技術者・ビジネスリーダーが集い、新しい創造技術の活用とその社会的インパクトを議論・共有する場を提供します。</p>
<h2>第1回テーマは『3D CAD × Generative AI』</h2>
<p>初回は「3D CAD × Generative AI」をテーマに、“設計”と“創造”の未来を可視化します。近年の急速な生成AIの進化により、設計や構想のプロセスは自動化・高度化が実現可能な段階に入っています。3D CADも製造・建設分野をはじめ、都市開発やロボティクス、ファッションなど多様な産業での活用が進み、創造の可能性を拡張し続けています。</p>
<p>本イベントでは、業界を超えて先進的な取り組みを進める企業リーダーを迎え、3D CADと生成AI技術が設計や製造の工程にもたらす変革をテーマにお話いただきます。</p>
<h2>補助金活用のノウハウも得られる実践的イベント</h2>
<p>GENEXでは、イベントのテーマに合わせた補助金制度のご紹介や、制度活用に向けたご相談も受け付けております。
3D CAD×生成AIの最新動向を学ぶだけでなく、新しい技術を取り入れる際の導入コストを抑える手段も学ぶことができます。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/GENEX_1_3_D_CAD_1_130d185e26/GENEX_1_3_D_CAD_1_130d185e26.png" alt="GENEX #1 - 3D CAD × 世界モデル：ものづくりの未来はどう変わるのか？- 企画ご案内資料 (1).png" /></p>
<p>:::button
<a href="https://zfrmz.com/pHez81Ctmf7AFISeaz4Y">参加登録はこちら</a>
:::</p>
<h2>講演タイムテーブル</h2>
<p>15:00 - 15:30（30分）　開場・受付開始
15:30 - 15:35（ 5分）　 オープニング
15:40 - 16:20（40分）　パネルディスカッション「生成AIによって変革する製品設計のプロトタイピング」
16:25 - 17:05（40分）　株式会社日本HP様 講演
17:10 - 17:50（40分）　オートデスク株式会社様 講演
17:55 - 18:35（40分）　補助金活用支援セッション
18:40 - 18:50（10分）　クロージング
19:00 - 20:00（60分）　ネットワーキングパーティー</p>
<h2>セッションの紹介</h2>
<h3>パネルディスカッション「生成AIによって変革する設計のプロトタイピング」</h3>
<p>産業・エンタメ・教育 ― あらゆる現場で”ものを創る”最前線に立ち続けてきた二人のキーパーソンが、生成AIによって変わる現実世界の設計を読み解きます。</p>
<p>【ゲストスピーカー】
小畑 正好 氏
デジタルコンテンツクリエイター</p>
<p>武蔵野美術大学院 空間演出デザインコース修了後、渡米しNHKエンタープライズUSAに参加。帰国後は映画・テレビ・アニメ・ゲーム・インタラクティブコンテンツ等でVFX監督・CGディレクターとして数多くのメジャープロジェクトに参画。現在、(社)FDE・(株)ビトル・(株)島精機製作所等数社の役職を併任しデジタルコンテンツの総合的な研究・開発・制作を行う。</p>
<p>橋本 和幸 氏
dots in space 代表取締役／シリコンスタジオ 取締役／サイバーエージェント 技術顧問</p>
<p>1980年代前半からTV・CM業界でCGを活用し活躍。『ファイナルファンタジーVII』のプログラマーとして知られ、映画『ファイナルファンタジー』のホノルルスタジオ設立、Maya開発初期への関与など、日本の3DCG黎明期から中心的役割を果たしてきた。近年はメタバース・コンテンツの開発やR&amp;Dを推進し、複数の企業で次世代技術のアドバイザーを務める。</p>
<p>【モデレーター】
落合 研次
株式会社レッジ 社長室／編集部 編集主幹</p>
<p>工学修士、経営管理修士。新卒入社の大手SIerで６年間、システム開発の下流から最上流まで担当。GREE・アイスタイル（@cosme運営）で、データ分析/事業企画/プラットフォーム戦略を主導。TIS等で、自動車業界やテレビ業界の大規模IoTプロジェクトのPM/責任者としてPJTを推進。</p>
<h3>スポンサー講演</h3>
<p>3D CADのソフトウェアベンダーやハードウェアベンダーによる講演を通じて、3D CADの最新動向を解説します。</p>
<p>本イベントではオートデスクが提唱する「Autodesk AI」を中心とした最新の設計支援ソリューションや、日本HPによる高性能ワークステーションの活用事例も紹介。ソフトウェアとハードウェアの両面から、次世代の設計・開発環境の姿を多角的に探ります。</p>
<p>【スポンサー講演１】
<strong>『デザインと創造をパワフルにサポートする Autodesk AI』</strong>
Autodesk AI は、自動化・解析・拡張性を重視し、製造・建築・建設、メディアエンターテインメントなどの、「デザインと創造」に関わる皆様のワークフローをサポートします。
本セッションでは、最新の Autodesk AI についてご説明と、製造業における AI 活用の現在地と今後の方向性についてご紹介いたします。</p>
<p>\u003C登壇者\u003E
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20150812_Profile_kato_2_1_164487fa94/20150812_Profile_kato_2_1_164487fa94.jpg" alt="20150812Profile_kato 2 (1).jpg" /></p>
<p>オートデスク株式会社
加藤 久喜 氏／日本地域営業統括　技術営業本部 本部長</p>
<p>※講演内容は情報が確定次第、ご案内いたします。</p>
<h3>補助金活用支援セッション</h3>
<p>「補助金を使えば、最新技術をもっとお得に導入できる」
本セッションでは、今回のテーマに関連した補助金を幅広くご紹介します。
国や自治体が提供する多様な制度の紹介に加え、自社に最適な補助金の選び方や活用方法を専門家に直接相談できるサポートもご用意しています。</p>
<h3>個別相談会</h3>
<p>登壇企業や専門家と直接話せる個別相談の場を設置。技術導入や制度活用について、参加者の具体的な課題に即したご相談が可能です。</p>
<h2>開催概要</h2>
<p>イベント名：Generative AI Conference Series「GENEX」#1
テーマ：3D CAD × Generative AI
日時：2025年9月30日（火）15:30〜20:00（15:00開場）
形式：オフライン ＋ アーカイブ配信あり
会場：品川インターシティホール＆貸会議室1+2
主催：株式会社レッジ
共催：トランステップ株式会社
協賛：株式会社日本HP、オートデスク株式会社
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/pHez81Ctmf7AFISeaz4Y">参加登録はこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 03 Sep 2025 08:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>