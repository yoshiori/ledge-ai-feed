<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>平面から立体へ──部品を縦に積み上げる「3Dチップ」でAI処理のスループットは従来の2Dチップ比で約4倍に　スタンフォード大学、カーネギーメロン大学などの研究チーム</title>
      <link>https://ledge.ai/articles/3d_chip_ai_throughput_4x_stanford_cmu</link>
      <description><![CDATA[<p>部品や回路を平面ではなく縦方向に積み上げる「3Dチップ」を用いることで、AI処理のスループットが従来の2Dチップと比べて約4倍に向上することが分かった。</p>
<p>スタンフォード大学、カーネギーメロン大学などの研究チームは、米国の商用半導体ファウンドリで製造したチップを用いてこの成果を実証した。研究成果は、2025年12月10日から開催された<strong>IEEE国際電子デバイス会議（IEDM）</strong> （第71回）で<a href="https://engineering.stanford.edu/news/scientists-and-us-foundry-achieve-3d-chip-breakthrough-accelerate-ai">発表</a>された。</p>
<h2>AIの性能を縛る「メモリの壁」と、平面チップの限界</h2>
<p>近年のAIシステムでは、計算能力そのもの以上に、メモリと演算回路の間で発生する大量のデータ転送が性能の制約となっているという。研究チームによると、大規模言語モデルのようなAIでは、メモリから計算ユニットへ膨大な情報を頻繁に移動させる必要があり、処理速度がデータ供給に追いつかない状態が生じやすい。こうした現象は、半導体分野では「メモリの壁」と呼ばれてきた。</p>
<p>また、従来の2Dチップでは、回路やメモリが単一の平面上に配置されるため、データは限られた配線を長距離移動する必要がある。トランジスタの微細化によって性能向上を図る手法についても、物理的な限界に近づきつつあると研究者らは指摘しており、この制約を「微細化の壁」と位置付けている。</p>
<h2>回路を「縦に積む」3Dチップ、モノリシック構造の特徴</h2>
<p>研究チームが開発した3Dチップは、こうした二つの壁を構造面から克服することを目的としたものだという。発表によると、超薄型の回路層を縦方向に積層し、それらを高密度な垂直配線で接続することで、メモリと演算回路を物理的に極めて近い距離に配置したとされる。</p>
<p>この構造について研究者らは、高層ビル内で多数のエレベーターが人の移動を支える仕組みに例えて説明している。多数の垂直経路を確保することで、データの移動量と速度を同時に高める狙いがあるという。</p>
<p>今回の成果の特徴として、研究室レベルの試作にとどまらず、「モノリシック3D」と呼ばれる構造のチップを、実際の商用半導体ファウンドリで製造した点が挙げられる。研究チームによれば、個別に作成したチップを後から積層する従来手法とは異なり、各層を連続的に積み上げる低温プロセスを用いることで、非常に高密度な層間接続を実現したという。</p>
<h2>実測で約4倍、将来は12倍──AI向け半導体への影響</h2>
<p>ハードウェア試験の結果について、研究チームは、試作チップが従来の2Dチップと比べてスループットで約4倍の性能向上を示したと報告している。さらに、より多くの層を積み上げた将来構成を想定したシミュレーションでは、実際のAIワークロードにおいて最大で約12倍の性能向上が見込まれるとしている。</p>
<p>これらの評価には、Metaのオープンソース大規模言語モデル「LLaMA」を基にした処理も含まれているという。</p>
<p>また、研究チームは、性能面だけでなくエネルギー効率の改善余地についても言及している。データ移動距離を大幅に短縮することで、処理速度と消費電力のバランスを示す指標である「エネルギー遅延積（EDP）」において、将来的に100倍から1,000倍規模の改善につながる可能性があると説明している。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【AI歴史年表】AIはダートマス会議から数えて来年で70周年！起源から生成AI革命までのAI全史を振り返る──Ledge.ai年末年始特集「&apos;25 to &apos;26」から注目コンテンツを特別公開！</title>
      <link>https://ledge.ai/articles/70year_history_of_ai_from_the_dartmouth_conference</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>2026年は、人工知能（AI）研究が正式に始動した歴史的な瞬間、1956年のダートマス会議から70周年という記念すべき節目を迎える。この70年間、AIは期待と幻滅の波を乗り越え、ついに人類の創造性を拡張する「生成AI」の時代へと到達した。この壮大な進化の軌跡を、各時代のエポックメイキングな出来事とともに紹介する。</p>
<h2>1. AIの誕生、最初の挫折と基礎構築 (1956–1979)</h2>
<p>人工知能（AI）は、1956年のダートマス会議でJ.マッカーシーらによって正式に分野として確立された。このダートマス会議で若手の中心となったJ.マッカーシー、M.ミンスキー、A.ニューウェルの3人はいずれも1927年生まれ、30歳を少し過ぎたところだ。ダートマス会議後、この3人はそれぞれスタンフォード大学、MIT、カーネギーメロン大学で活動し、AI研究の世界的な拠点が形成されていく。</p>
<p>初期の成功として、1958年にはF.ローゼンブラットが脳を模倣した初の学習可能モデルであるパーセプトロンを発表し、1966年にはJ.ワイゼンバウムが初の対話型システムであるELIZAを開発した。また、NNの学習においては、1967年に甘利俊一が確率的勾配降下法という後のディープラーニングの基礎となる最適化手法を発表するなど、技術的な基盤も築かれ始めていた。</p>
<p>しかし、この楽観的なブームは短期間で終焉を迎える。1969年、M.ミンスキーらがパーセプトロンの限界証明を行い、単層NNでは複雑な問題が解けないことを示唆した結果、AI研究への資金が大幅に削減され、最初の「冬の時代」が到来した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_70_AI_2ddf249970/01_70_AI_2ddf249970.jpg" alt="表01_70AI.jpg" /></p>
<p>この停滞期においても、後のAIの土台となる研究は継続された。日本では、1972年に甘利俊一が脳の記憶を模倣した連想記憶モデルを発表し、1979年には福島邦彦が、後の畳み込みニューラルネットワーク（CNN）の原型となるネオコグニトロンという階層型のNNモデルを開発した。この時期の日本の研究者の貢献は、AIの次の飛躍に向けた重要な種を蒔いたと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>2. AI研究の転換期における三つの潮流 (1980–1996)</h2>
<p>1980年代から1990年代前半にかけて、AI研究は、1970年代の停滞期を脱するため、異なる哲学に基づいた三つの潮流が並立した。</p>
<p>まず、記号主義（知識ベース）AIの流れを極限まで推し進めようとする試みがあった。その代表が1984年にD.レナートによって開始されたCycプロジェクトである。このプロジェクトは、人間が持つ膨大な常識をすべて手作業で知識ベースに構築し、究極のエキスパートシステムを実現することを目指した。これは、記号主義AIの可能性を探る壮大な挑戦であったが、同時に知識を形式化し獲得することの難しさを浮き彫りにした。</p>
<p>次に、長らく停滞していたニューラルネットワーク（NN）研究が息を吹き返した。この復活は、1982年にJ.ホップフィールドが、甘利俊一の先行研究と同系統の連想記憶モデルを、統計物理学の手法を用いて再発見したことに端を発する。これにより、NNが「記憶」のメカニズムを持つことが示唆された。決定的なブレイクスルーとなったのは、1986年にG.ヒントンらが多層NNを効率的に学習させる誤差逆伝播法（Backpropagation）を普及させたことである。この手法の登場は、NNが単層の限界を乗り越え、複雑なパターン認識を扱えるようになる第2次NNブームを牽引した。</p>
<p>そして第三の潮流として、従来の複雑な推論中心のAIに異を唱える行動ベースAIが登場した。1991年、iRobotの創業者でもあるR.ブルックスは、包摂アーキテクチャという新しい考え方を提唱し、その具体例として小型六本足ロボットのGenghisを開発した。これは、中央の知識ベースを持たず、環境からのセンサー情報に基づいて直接行動することで、現実世界でのタスク実行を重視するアプローチである。この研究は、AI研究の主流を、抽象的な推論から知覚と行動の統合へとシフトさせるきっかけとなり、その後のロボット工学に大きな影響を与えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/02_70_AI_204dc3e658/02_70_AI_204dc3e658.jpg" alt="表02_70AI.jpg" /></p>
<p>このように、1980年代から90年代前半は、知識ベースの限界と挑戦、NNの劇的な復活、そして現実世界指向の新しいパラダイムの誕生という、複数の試行錯誤を通じて、後のAI発展の基礎が築かれた重要な転換期であったと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>3. データと計算力によるAIの夜明け～ディープラーニングの衝撃 (1997–2016)</h2>
<p>1990年代後半から2010年代にかけてのAI研究は、インターネットの普及によるデータの爆発的な増加と、計算機能力の飛躍的な向上という二つの外部要因に強く支えられた。この時期、AIは「知識ベース」から「データ駆動」へとパラダイムを完全に転換し、特定のタスクで人間の能力を超える成果を上げ始めた。</p>
<p>まず、AIは特定の知的ゲームにおいて、人間を凌駕する能力を示した。1997年には、IBMのDeep Blueがチェスの世界チャンピオン、ガルリ・カスパロフに勝利し、「探索と計算」に特化したAIの能力を世界に示した。この頃、インターネットの本格的な普及は、AI研究の間接的な基盤を構築していた。Web上の膨大な情報（ビッグデータ）を分析するデータマイニングや統計的手法が発展し、AI研究も経験的なデータから知識を抽出する方向に傾倒していった。</p>
<p>AIに真のブレイクスルーをもたらしたのは、ニューラルネットワーク（NN）の進化であった。2006年、G.ヒントンらがディープラーニングを提唱し、多層NNを効率的に学習させる手法（深層化）に成功した。これは、増大するインターネット上のビッグデータを扱うために、極めて重要な進歩であった。この技術の有効性は、様々な分野で証明され始めた。2011年には、IBMのWatsonが、膨大な非構造化データ（書籍、記事など）から答えを導き出す能力により、米国の人気クイズ番組『ジェパディ！』で歴代チャンピオンに勝利した。そして2012年、ヒントンらが開発したAlexNetが、大規模な画像認識コンテスト（ILSVRC 2012）で圧倒的な性能を見せつけ、ディープラーニングが画像認識の主流技術となることを決定づけた。</p>
<p>この時期のAI研究の集大成となったのが、Google DeepMindによるAlphaGoの成功である。2016年、AlphaGoは、人間の直感と深い洞察力が求められる囲碁において、世界トップ棋士であるイ・セドル九段に勝利した。この勝利は、チェスのような「探索」だけでなく、「直感的な判断」が必要とされる領域でもAIが人間を超越したことを意味し、ディープラーニングと強化学習を組み合わせたAIが、人類の「知性の最後の砦」の一つを突破した歴史的な瞬間であった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/03_70_AI_00677c2be5/03_70_AI_00677c2be5.jpg" alt="表03_70AI.jpg" /></p>
<p>この1997年から2016年にかけて、AIはインターネットによって供給されるデータと、高性能なGPUによって可能になった計算力を武器に、ディープラーニングという核技術を獲得し、次の「生成AI」時代への道筋を明確に作ったのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>4. 生成AI革命の勃発 (2017–2022)</h2>
<p>2017年から2022年の期間は、AI研究史上最も劇的な変革期であり、技術的なブレイクスルーと、それによる生成AI革命の勃発が特徴である。</p>
<p>この変革の起点は、2017年にGoogleが発表したTransformerモデルにあった。このモデルは、入力データ内の重要度を把握する「注意機構（Attention）」を採用し、計算を並列処理できるようになったため、大規模で深いネットワークの学習を可能にし、大規模言語モデル（LLM）の時代の扉を開いた。</p>
<p>このアーキテクチャを基盤に、2018年にOpenAIがGenerative Pre-trained Transformer（GPT）を開発し、LLMの基礎を築いた。さらに2020年には、モデルを大きくするほど性能が向上するというスケーリング則が確立され、LLMの巨大化戦略が主流となった。また、同年には拡散モデルが実用化され、高精度な画像生成AIの道も開かれた。</p>
<p>そして2022年、AIは一気に社会へ浸透した。LLMの推論能力を飛躍的に高める思考の連鎖（CoT）などの手法が開発される一方、Midjourneyなどの対話型画像生成AIが普及した。極めつけは、同年後半にOpenAIからリリースされたChatGPTである。人間と遜色ない自然な対話能力を持つChatGPTは、リリース後わずか約2か月で月間アクティブユーザー数1億人を突破し、生成AIブームを世界中に巻き起こした。</p>
<p>一方で、技術の急速な発展に伴い、AIの倫理と安全性に関する議論も本格化した。2017年にはアシロマ会議が開かれ、AIの安全な開発と利用に向けた「アシロマAI 23原則」が策定されたことも、この時期の重要な出来事である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/04_70_AI_28c3fdc49a/04_70_AI_28c3fdc49a.jpg" alt="表04_70AI.jpg" /></p>
<p>この5年間で、AIは「認識」から「創造」の領域へと能力を拡張し、人類の生活を一変させる新たなステージへと進んだのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>5. 70周年の展望：AIと人類の未来 (2023年～)</h2>
<h3>5-1. 2023～2025年におけるAIと人類の状況</h3>
<p>2023年から2025年は、生成AI（Generative AI）技術が社会全体に急速に浸透した「AIの実用化元年」とも呼ぶべき変革期であった。特に大規模言語モデル（LLM）の進化により、AIは単なる自動化ツールから、人間の協働者や代行者へとその役割を急速に拡大した時期である。</p>
<p>日常生活においては、AIはスマートフォンや家電に深く組み込まれ、ルーティン作業の自動化、情報検索の高度化、そして個別化された健康管理の提供を通じて、人々の生活効率を向上させた。教育分野では、AIチューターや個別学習プログラムの利用が一般化し、生徒一人ひとりの進捗に合わせたカスタマイズ教育が主流となった一方で、教師は教材作成や評価の負担が軽減され、より対話的な指導に注力できるようになった。エンターテイメント領域では、AIによる画像、音楽、動画の生成が爆発的に増加し、コンテンツ制作の民主化が進んだ。また、AIを活用したパーソナライズされたゲーム体験や、没入型のMR/VRコンテンツも普及した。</p>
<p>ビジネスにおいては、AI導入が業務効率を大幅に向上させ、産業構造の再編を促した。ここでは利用形態に明確な対比が見られた。一つは、コーディングや文書作成などの専門作業において人間の作業を支援・加速するコパイロット型AIであり、これは人間の意思決定が最終的に介在する協調的な形態である。もう一つは、人間からの指示を基に複数のタスクを自律的に計画・実行し、ビジネスプロセスや顧客対応を代行・自動化するAIエージェントの進化である。この対比は、業務におけるAIの自律性の度合いを示す重要な指標となった。</p>
<p>政治においては、AIによる情報分析と政策立案支援が進み、行政の効率化が図られた。しかし同時に、AIが生成するディープフェイクや誤情報が選挙や世論形成に与える影響が重大な社会問題となり、各国でAIの倫理的利用と規制に関する議論が加速した。この時期、人類はAIの利便性を享受しつつも、その倫理性、安全性、社会への影響に対する向き合い方を確立する過渡期にあるのが現状である。</p>
<h3>5-2. 未来のAI：相乗効果と応用のグランドビジョン</h3>
<p>未来のAI技術 (AI_future) の進化は、現在の技術の単なる延長ではない。それは、基礎技術の「積」による指数関数的な相乗効果と、応用領域の「和」による社会的な価値の最大化によって実現されるビジョンである。
Ledge.aiでは、このビジョンを、以下のように定式化して考えている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_formula_ff6d7ead4c/ai70th_formula_ff6d7ead4c.png" alt="ai70th_formula.png" /></p>
<h3>■SYNERGY（相乗効果：積の力）による性能の飛躍</h3>
<p>現在のAI技術 (AI_current) は、四つの主要な基礎技術が掛け合わされる（積Π）ことで、その性能を劇的に高める。これらの技術は、それぞれがAIの抱える限界を突破する鍵となる。</p>
<ul>
<li><strong>量子コンピューター (Quantum) :</strong> AIの処理速度と複雑な問題解決能力に演算能力のブレイクスルーをもたらし、現行のスーパーコンピューターでは不可能な領域の学習と計算を可能にする。</li>
<li><strong>Web3 技術 (Web3):</strong> ブロックチェーンや分散型台帳技術により、AIが扱うデータと意思決定プロセスに透明性と信頼性を与え、分散化された環境での安全なAI連携を実現する。</li>
<li><strong>核融合エネルギー (Fusion):</strong> ほぼ無限かつクリーンなエネルギー源を提供することで、大規模な計算資源の制約を完全に緩和し、膨大なデータを用いた学習（超大規模モデル）を経済的かつ環境負荷なく実行可能にする。</li>
<li><strong>データインフラ (DataInfra):</strong> 5G/6Gや次世代ストレージ技術が実現する高速・大容量データ処理基盤が、AIのリアルタイムな学習と推論を支える。</li>
</ul>
<p>これらの技術が個別に進化するのではなく、相互に作用し合う（積）ことで、AIはこれまでにないレベルの知性を獲得する。</p>
<h3>■APPLICATION（応用価値：和の力）による社会実装</h3>
<p>性能が飛躍的に向上したAIは、様々な応用領域へ展開され、その価値を社会へ還元する。これらの応用領域は、AIの価値を社会的効用として積み重ねていく（和Σ）役割を担う。</p>
<ul>
<li><strong>Robotics (ロボティクス):</strong> 高度な知性を持つAIが、物理的な世界で活動するロボットと統合され、自動化・遠隔操作・協調作業を飛躍的に進化させる。</li>
<li><strong>MR (複合現実):</strong> AIがMR環境を分析・最適化し、人間とAIが直感的かつシームレスに連携する新たなインターフェースと作業空間を提供する。</li>
<li><strong>Autonomous Driving (自動運転):</strong> 複雑で予測不可能な環境においても、AIがリアルタイムに安全な判断を下し、交通システム全体を最適化することで社会インフラを革新する。</li>
<li><strong>Social Engineering (社会システムへの適用):</strong> 都市計画、医療、教育などの大規模な社会システムにAIが組み込まれ、データの分析と最適化を通じて社会全体の効率と公平性を向上させる。</li>
</ul>
<p>結論として、未来のAIは、基礎技術の「積」によって知性の限界を超え、応用領域の「和」を通じて私たちの生活、産業、そして社会構造そのものを根本から変革するグランドビジョンである。</p>
<p>金融分野でのいわゆる”AIバブル”は、早晩弾ける可能性がある。しかし、AI技術は着実な進歩が予想される。このようなグランドビジョンのもと、人類とAIの未来を創造していただければ幸いである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/12 [FRI]諸説あるAGIの定義をスタンフォード大などが明確化、「教養ある成人」がモデルケース──GPT-4は27%、GPT-5は約6割に到達と試算</title>
      <link>https://ledge.ai/articles/agi_definition_stanford_gpt4_27_gpt5_60</link>
      <description><![CDATA[<p>スタンフォード大学やUCバークレー、MITなどの研究者を含む国際チームは、AIの到達度を測る新しい枠組みを提示した論文「A Definition of AGI」を<a href="https://arxiv.org/abs/2510.18212v3">公開</a>した。これまで曖昧だったAGI（汎用人工知能）の定義について、同チームは「教養ある成人（well-educated adult）の認知の幅と熟達度にマッチするAI」と明確化。加えて、人間の知能研究で広く使われるCHC（Cattell-Horn-Carroll）理論に基づき、10種類の認知ドメインでAIモデルを評価する「AGIスコア」を提案した。</p>
<p>今回の枠組みに基づく試算では、GPT-4は27%、GPT-5は約57〜58%に到達しているとされる（100%が「教養ある成人の平均レベル」に相当）。論文のPDF版では57%、公式サイトや解説資料では58%と表記されており、約6割前後の水準と整理できる。</p>
<h2>AGIをめぐる“動くゴールポスト”問題を解消へ</h2>
<p>研究チームが強調するのは、AGIという用語の曖昧さだ。企業・研究者・メディアで異なる意味合いで使われてきた結果、実際にどの能力を満たせばAGIと呼べるのかが明確でなく、「モデルが進化するたびにゴールが後ろにずれる」として批判もあった。</p>
<p>Center for AI Safety（CAIS）はニュースレターの中で、この曖昧さが研究目標、社会的リスク評価、政策議論を複雑化してきたと指摘している。今回の提案は、こうした状況に対し「包括的でテスト可能な定義」を与える試みと位置づけられる。</p>
<h2>10の認知ドメインを10%ずつ評価する「AGIスコア」</h2>
<p>論文が提示する枠組みでは、人間の認知能力を10の中核ドメインに分解し、それぞれを「10%」の重みで評価する。ドメインは以下の通り。</p>
<ul>
<li>一般知識</li>
<li>読解・文章</li>
<li>数学</li>
<li>推論（問題解決・抽象化）</li>
<li>作業記憶・注意制御</li>
<li>長期記憶の保存と検索</li>
<li>視覚処理</li>
<li>聴覚処理</li>
<li>処理速度</li>
<li>中央実行系（複数能力の統合）</li>
</ul>
<p>研究チームはこれらの領域を、人間の心理測定バッテリー（知能検査など）の形式に合わせて評価タスク化。AIモデルを人間の標準スコアにマッピングしたうえで、各分野を合成して「AGIスコア（0〜100%）」として算出する。</p>
<p><strong>■ AGIを構成する10の認知ドメイン（CHC理論に基づく）：</strong> 一般知識・読解・数学・推論・記憶・知覚・速度など、人間の認知を広範にカバーし、各領域を10%ずつ評価してAGIスコアを算出する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_8_1eb9f5c414/x2_8_1eb9f5c414.png" alt="x2 (8).png" /></p>
<p>この枠組みの特徴は、一部の領域だけ優れていてもAGIとは見なされない点にある。たとえば「読解や知識」では人間レベルであっても、「長期記憶」や「視覚処理」が極端に低ければ、スコアは上がらない。</p>
<h2>GPT-5は約6割──強い領域と“ほぼゼロ”の領域が共存</h2>
<p>論文および公式サイトのデータによると、GPT-4とGPT-5には以下のような特徴がある。</p>
<ul>
<li>GPT-4：AGIスコア27%</li>
<li>GPT-5：AGIスコア約57〜58%（約6割）</li>
</ul>
<p><strong>■ GPT-4 と GPT-5 の10ドメイン能力比較：</strong> GPT-5 は読解・数学・推論などで高スコアを示す一方、長期記憶や視覚・聴覚処理などの基盤能力は依然として低く、“ギザギザ”なプロファイルが特徴となっている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_5c3108a876/x1_5c3108a876.png" alt="x1.png" /></p>
<p>高いスコアを示すのは「一般知識」「読解・文章」「数学」「推論」といったデータ駆動型の領域で、人間を上回るケースもある。一方で、</p>
<ul>
<li>長期記憶の保存・検索</li>
<li>視覚的推論</li>
<li>聴覚処理</li>
<li>処理速度（リアルタイム性）</li>
</ul>
<p>といった基盤的能力では、多くのモデルが極めて低いスコアにとどまっており、ほぼゼロに近い領域も存在する。</p>
<p>研究チームは、現行の大規模言語モデルは「部分的には人間を超えるが、能力の分布がギザギザで、総合的な認知としては成人レベルに達していない」と整理している。</p>
<h2>政策・規制議論への影響も──共通の“物差し”が登場</h2>
<p>AGIの定義が明確化されたことで、今後は次のような領域で議論が進む可能性がある。</p>
<ul>
<li><strong>米上院で進むAI安全法案の議論：</strong> 規制対象となるAIモデルをどの基準で選定するか、共通の指標が求められていた。</li>
<li><strong>企業のロードマップ策定：</strong> 「AGIにどれだけ近いか」を定量的に示せることで、開発の透明性や説明責任が高まる可能性。</li>
<li><strong>研究コミュニティでの基準化：</strong> 進捗を測る複数のベンチマークが乱立してきた中で、総合的な認知評価として採用される可能性。</li>
</ul>
<p>ただし研究チームは、今回の枠組みが「最終版の定義」ではなく、今後の議論の叩き台であることも強調している。</p>
<h2>今後の焦点：長期記憶・知覚・実世界タスク</h2>
<p>GPT-5が約6割に到達した一方、AGI達成には大きなギャップが残されている。特に論文が指摘するのは、次のような領域だ。</p>
<ul>
<li>長期記憶の安定した形成と参照</li>
<li>視覚・聴覚などマルチモーダル知覚の統合</li>
<li>現実世界での連続的タスク遂行（エージェント的行動）</li>
</ul>
<p>研究チームは、これらの領域が改善すれば、AGIスコアが急速に伸びる可能性があるとしている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Kindleで「本に直接質問」──Amazon、ネタバレを避けて即座に回答するAI機能「Ask this Book」を米国のiOSアプリで提供開始</title>
      <link>https://ledge.ai/articles/amazon_kindle_ask_this_book_ios_us</link>
      <description><![CDATA[<p>Amazonは米国時間12月11日、電子書籍サービス「Kindle」において、読書中の文章をハイライトするだけで、書籍内容についてAIに質問できる新機能「Ask this Book」を米国で提供開始したことを<a href="https://www.aboutamazon.com/news/books-and-authors/kindle-recaps-feature-ebook-series-refreshers">発表</a>した。まずは米国向けのKindle iOSアプリで利用できる。</p>
<p>「Ask this Book」は、読者が書籍内の文章を選択すると、その箇所に関連する質問をAIに投げかける機能だ。物語の展開や登場人物の関係、文章の意味などについて、読書体験を中断することなく即座に回答を得られる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_37126bc831/2_37126bc831.gif" alt="ダウンロード (2).gif" /></p>
<p>AIの回答は読者がその時点までに読み進めた内容に基づいて生成される。これにより、未読部分に触れる「ネタバレ」を避ける設計だ。回答内容はコピーや共有ができず、書籍を購入またはレンタルしているユーザーのみが利用可能。</p>
<p>提供開始時点では、対応するのは米国のKindle iOSアプリに限られている。Amazonは今後、他のプラットフォームや端末への展開も検討しているとしているが、具体的な時期や対象地域については明らかにしていない。</p>
<p>Amazonは近年、KindleにおけるAI活用を段階的に拡充している。シリーズ作品の内容を要約し、次巻を読む前に振り返るためのAI機能「Kindle Recaps」もその一例だ。「Ask this Book」は、読書中の疑問をその場で解消する用途に位置付けられており、用途に応じて異なるAI機能を組み合わせる形となる。</p>
<p>同社は、これらのAI機能について、読書そのものを置き換えるものではなく、読者の理解を補完するための仕組みだと説明している。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>エンジニアリング2025/12/16 [TUE]Anthropic、AIエージェント開発における”スキル”重視の新設計思想を提示──「IQ300数学の天才から経験豊富な税務専門家へ」、スキル中心アーキテクチャの全体像を解説</title>
      <link>https://ledge.ai/articles/anthropic_ai_agents_build_skills_paradigm</link>
      <description><![CDATA[<p>Anthropicに所属するBarry Zhang氏とMahesh Murag氏は、2025年11月21日に開催された開発者向けイベント「AI Engineer Code Summit」で<a href="https://www.youtube.com/watch?v=CEvIs9y1uog">講演</a>を行い、AIエージェント開発における新たな設計思想を提示した。講演の模様は、同イベントを主催する開発者コミュニティ「AI Engineer」のYouTubeチャンネルで、12月9日に動画として公開されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=CEvIs9y1uog&amp;t=183s">YouTube</a></p>
<p>両氏は講演の中で、現在主流となりつつある「AIエージェント」を多数構築するアプローチに疑問を投げかけ、「エージェントではなくスキルを構築すべきだ」と主張した。汎用的な知性を持つAIエージェントが、実務において専門家として振る舞うことの難しさを課題として挙げ、その解決策として「スキル」という新しい概念を提示している。</p>
<p>具体的には、業務に必要な手続き的知識を「スキル」として明示的にパッケージ化し、エージェントが必要に応じて段階的に読み込むアーキテクチャを紹介した。このスキル中心のアプローチは、AIエージェントの実用性や拡張性を高めるだけでなく、専門知識の再利用や共有、さらにはAI自身による継続的な学習の基盤となる可能性がある。本記事では、AI Engineer Code Summitで語られた講演内容をもとに、Anthropicの研究者が示したAIエージェント開発の新パラダイムと、その全体像を整理する。</p>
<h2>現代のAIエージェントが抱える課題──「優秀だが経験不足」というジレンマ</h2>
<p>AIエージェントは近年、推論能力やツール利用能力の向上によって急速に注目を集めている。一方で、実務の現場では「期待したほど使えない」と感じられるケースも少なくない。講演で両氏は、その理由を分かりやすい比喩で説明した。</p>
<p><strong>■「IQ300の数学の天才」と「経験豊富な税務専門家」の対比で示される、AIエージェントの課題</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genius_iq300_1526483afb/genius_iq300_1526483afb.jpg" alt="①genius iq300.jpg" /></p>
<p>「あなたの税務処理を任せるなら、IQ300の数学の天才と、長年の経験を持つ税務専門家のどちらを選びますか？」という問いだ。多くの場合、選ばれるのは後者だろう。税務のような専門業務では、生の知性よりも、確立された手続きを一貫して実行できる経験の方が重要だからだ。</p>
<p>現在のAIエージェントは、この「IQ300の天才」に近い存在だと両氏は指摘する。高い汎用知性を備えている一方で、実務に必要な前提知識や暗黙知を最初から持っているわけではなく、専門家としての経験値が不足している。その結果、以下のような課題に直面する。</p>
<ul>
<li>業務特有の文脈や前提を十分に理解できない</li>
<li>専門的な手順やノウハウを効率よく身につけられない</li>
<li>特定のチームやユーザーと長期間協業しても、その経験が蓄積されない</li>
</ul>
<p>こうした課題を踏まえ、Anthropicは従来のエージェント構築の考え方そのものを見直す必要があると提起した。</p>
<h2>Anthropicが提唱する解決策──「エージェント」ではなく「スキル」という発想</h2>
<p>両氏が提示した解決策の中心にあるのが、「スキル」という概念だ。これは、エージェントそのものを高度化するのではなく、エージェントに付与する専門知識の持たせ方を再設計するという発想に基づいている。</p>
<p><strong>■ Anthropicが示すAIスタックの整理。スキルはアプリケーション層に位置づけられる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/moving_up_the_stack_f254f9be32/moving_up_the_stack_f254f9be32.jpg" alt="②moving up the stack.jpg" /></p>
<p>Anthropicの考えでは、エージェントはあくまで汎用的な推論主体として位置づけられるべき存在だ。専門家としての振る舞いは、エージェント自身がその場で学習するのではなく、事前に整理された手続き的知識を「スキル」として与えることで実現する。</p>
<p>このアプローチにより、エージェントは未知の分野を即興的に推論するのではなく、すでに確立された専門家のやり方に沿って行動できるようになる。結果として、実務で求められる一貫性や再現性を確保しやすくなるという。</p>
<h2>「スキル」とは何か──手続き的知識をフォルダとして扱う設計</h2>
<p>講演で定義された「スキル」は、エージェントのための構成可能な手続き的知識をパッケージ化した、整理されたファイル群である。具体的には、単なるフレームワークや抽象APIではなく、誰もが理解できる「フォルダ」という形で実装される。</p>
<p><strong>■ スキルは特別なフレームワークではなく、手続き的知識をまとめたフォルダとして定義される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/skills_are_just_folders_fe2866b20f/skills_are_just_folders_fe2866b20f.jpg" alt="③skills are just folders.jpg" /></p>
<p>スキルの中には、以下のような要素が含まれる。</p>
<ul>
<li>スキルの目的や使い方を記述したドキュメント</li>
<li>実行可能なスクリプトやテンプレート</li>
<li>補助的な設定ファイルや例</li>
</ul>
<p>この設計の特徴は、特別なツールや専用環境を必要としない点にある。Gitによるバージョン管理や、クラウドストレージでの共有など、既存の開発者ワークフローと自然に統合できる。</p>
<p>また、スキルはランタイム時に段階的に読み込まれる。最初にエージェントへ提示されるのは、スキルの存在を示すメタデータのみで、必要と判断された場合にのみ詳細な指示やファイルが読み込まれる。この仕組みにより、コンテキストウィンドウの消費を抑えつつ、多数のスキルを併用することが可能になる。</p>
<h2>急速に拡大するスキルエコシステム──基盤・サードパーティ・エンタープライズ</h2>
<p>スキルの仕組みは、すでに活発なエコシステムを形成しつつある。講演によれば、公開から短期間で数千のスキルがコミュニティによって作成されているという。</p>
<p><strong>■ スキルは「基盤」「パートナー」「エンタープライズ」の3層で構成されるエコシステムを形成している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_skills_ecosystem_d01ca1d0cb/the_skills_ecosystem_d01ca1d0cb.jpg" alt="④the skills ecosystem.jpg" /></p>
<p>スキルは大きく、次の3つに分類できる。</p>
<p>まず「基盤スキル」は、エージェントに新たな汎用能力や特定分野の能力を付与するものだ。プロ品質のオフィス文書作成や、科学研究向けデータ解析などが例として挙げられた。</p>
<p>次に「サードパーティスキル」は、外部企業が自社製品とAIエージェントを連携させるために開発したスキルだ。ブラウザ自動化ツールや、ナレッジ管理サービスと連携するスキルが紹介された。</p>
<p>最後に「エンタープライズスキル」は、企業やチーム内で蓄積された業務ノウハウをエージェントに教えるためのものだ。社内独自の業務プロセスや、チーム固有の開発ルールをスキルとして共有することで、組織全体の生産性向上につなげられる。</p>
<p>講演では、特に非エンジニアの専門家がスキルを作成している点が注目すべき動きとして紹介された。金融、法務、採用などの分野で、専門知識を持つ人々が自らAIを強化していることは、このアプローチの有効性を示す事例といえる。</p>
<h2>スキルを前提にした汎用エージェントのアーキテクチャ</h2>
<p>スキルは、AIエージェント全体のアーキテクチャの中で重要な役割を担う。講演では、汎用エージェントを構成する要素として、次の4点が示された。</p>
<ul>
<li>モデルの思考と入出力を管理するエージェントループ</li>
<li>ファイル操作やコード実行を可能にするランタイム環境</li>
<li>外部APIやデータと接続するMCP（Model Context Protocol）サーバー</li>
<li>手続き的専門知識を提供するスキルライブラリ</li>
</ul>
<p><strong>■ MCPサーバー、エージェント、ファイルシステム上のスキルの関係を示した汎用エージェントの基本構成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/skills_the_complete_picture_900b270496/skills_the_complete_picture_900b270496.jpg" alt="⑤skills the complete picture.jpg" /></p>
<p>この構成により、エージェントは汎用性を保ったまま、スキルとMCPを組み合わせることで特定の業務や業界に適応できる。Anthropicは、金融やライフサイエンスといった分野向けにサービスを迅速に展開できた事例を紹介し、このアーキテクチャの柔軟性を示した。</p>
<h2>スキルの共有と自己生成──Anthropicが描く今後の展望</h2>
<p>Anthropicは、スキルを単なる機能拡張ではなく、AI能力を共有・進化させる基盤として位置づけている。スキルが複雑化するにつれ、テストやバージョン管理、依存関係の明示といったソフトウェア開発の手法を取り入れる重要性も指摘された。</p>
<p><strong>■ スキルは評価・バージョン管理・構成可能性を備え、ソフトウェアとして進化していく</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/exploring_how_skills_evolve_484db0b197/exploring_how_skills_evolve_484db0b197.jpg" alt="⑥exploring how skills evolve.jpg" /></p>
<p>さらに講演では、AI自身がスキルを生成する可能性にも言及された。Claudeはすでに「スキルクリエイター」として、ユーザーのためにスキルを作成できるとされており、今後は対話を通じて学んだ手続き的知識をスキルとして保存する方向性が示されている。</p>
<p>こうした仕組みが実現すれば、AIが学んだ内容は一時的な記憶ではなく、再利用可能な知識資産として蓄積されることになる。Anthropicが掲げる「あなたと30日間働いたClaudeは、初日のClaudeより優れている」という目標に向けて、スキルは重要な役割を果たすと位置づけられている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、AIエージェント標準「MCP」をLinux Foundation傘下へ移管──Agentic AIの共通基盤化へ</title>
      <link>https://ledge.ai/articles/anthropic_mcp_linux_foundation_aaif_transfer</link>
      <description><![CDATA[<p>Anthropicは2025年12月10日、同社が開発してきたAIエージェント向けの標準仕様「Model Context Protocol（MCP）」を、Linux Foundation傘下に新設された「Agentic AI Foundation（AAIF）」へ移管すると<a href="https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation">発表</a>した。</p>
<p>Anthropicはこれまで、対話型AI「Claude」を中心としたエコシステムの中でMCPを提唱・整備してきた。エージェントが自律的にタスクを実行する「Agentic AI」への関心が高まる中、MCPはその基盤技術の一つとして注目されている。</p>
<p>今回の移管により、MCPの仕様管理や将来の拡張は、Linux Foundation傘下のAAIFが担う。AAIFは、AIエージェント分野における共通基盤の整備と標準化を目的として新設された組織で、複数の企業や開発者コミュニティが参加する中立的な運営体制を採る。</p>
<p>Linux Foundationによると、AAIFはMCPのほか、Blockが開発したエージェント関連プロジェクト「goose」や、OpenAIが提唱するエージェント仕様「AGENTS.md」などの初期プロジェクトを受け入れ、AIエージェント分野における共通基盤の整備を進めるとしている<a href="https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/">Linux Foundationの発表</a>。</p>
<p>Anthropicは、MCPの創始者として引き続き技術的な貢献を行う一方、主導権はコミュニティ側に委ねられる。</p>
<p>Linux Foundationは、LinuxやKubernetesなど、業界横断的なソフトウェア基盤を中立的に運営してきた実績を持つ。AI分野ではすでに「LF AI &amp; Data」を通じてオープンな研究・開発を支援しており、今回のAAIF設立とMCP受け入れは、Agentic AIを巡る標準化の動きを一段進めるものとなる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/aaif_social_media_image_e440cd3697/aaif_social_media_image_e440cd3697.webp" alt="aaif_social media image.webp" /></p>
<p>AIエージェントを巡っては、各社が独自の実装やフレームワークを競う一方で、相互運用性やベンダーロックインへの懸念も指摘されてきた。Anthropicが自社主導で開発してきたMCPをLinux Foundation傘下へ移管したことは、競争領域と共通基盤を切り分け、エコシステム全体の拡大を優先する姿勢を示す動きといえる。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIは駆け出しの開発者を置き換えられない──AWSのガーマンCEO、WIREDのポッドキャストで3つの理由を説明</title>
      <link>https://ledge.ai/articles/aws_garman_ai_cannot_replace_entry_level_developers</link>
      <description><![CDATA[<p>米Amazon Web Services（AWS）のマット・ガーマンCEOは2025年12月16日、WIREDのポッドキャスト番組「The Big Interview」に<a href="https://www.wired.com/story/the-big-interview-podcast-matt-garman-ceo-aws/">出演</a>し、生成AIの普及が進む中でも駆け出しの開発者（若手開発者）をAIで置き換える発想は適切ではないとの見解を示した。
同氏は、若手層をAIで代替する考え方について「長期的な会社づくりを目指すなら成り立たない」と述べ、その理由を3点に分けて説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wired_matt_garman_ae1c2bae43/wired_matt_garman_ae1c2bae43.jpg" alt="wired matt garman.jpg" /></p>
<p>WIREDの対談でガーマン氏は、近年一部で語られている「ジュニア社員をAIに置き換える」という発想に触れ、少なくともソフトウェア開発者については合理的ではないと語った。そのうえで、若手開発者を「置き換える」対象として捉えるのではなく、AIツールの活用によって働き方や役割が変化していく可能性を示しつつ、企業が長期的な視点で人材を育成する重要性を強調した。</p>
<h2>理由1：駆け出し層ほどAIツールに慣れており、活用の担い手になり得る</h2>
<p>ガーマン氏が最初に挙げた理由は、駆け出しの開発者ほどAIツールに習熟している場合が多いという点だ。対談では、最も若手の層が生成AIなどの新しいツールに最も慣れていることが少なくないと述べ、AIによって置き換える対象というよりも、むしろAIから価値を引き出す中心的な担い手になり得るとの趣旨を示した。</p>
<h2>理由2：コスト最適化の観点でも、駆け出し層の置き換えは合理的でない</h2>
<p>2点目として同氏は、若手開発者は一般に人件費が相対的に低いことを挙げた。コスト最適化を目的として人員構成を見直す場合であっても、駆け出し層は「最も安い部類」に属することが多く、そこだけをAIに置き換えるという発想は合理的ではないとの見方を示している。</p>
<h2>理由3：採用・育成の断絶はタレントパイプラインを損ない、長期的に組織が成り立たない</h2>
<p>3点目としてガーマン氏は、タレントパイプライン（若手を採用し、育成し、次世代へとつなげる流れ）を途切れさせるリスクを指摘した。若手を採用せず、メンタリングや育成を行わない状態が続けば、組織の健全性が損なわれる可能性があるという。</p>
<p>同氏は、採用したばかりの若手が最良のアイデアをもたらすことがある点にも触れ、「新しい血」が入ることで会社に活気や新しい発想が生まれると説明した。駆け出しの開発者を採らないという判断は、長期的な会社づくりを目指す企業にとっては“成り立たない（nonstarter）”と述べている。</p>
<h2>「仕事は変わる」──ガーマン氏が見通すAI導入後の働き方</h2>
<p>一方でガーマン氏は、AIエージェントの普及によって仕事の内容や進め方が変わること自体は避けられないとの認識も示した。対談では、自社の従業員に対して「仕事は変わる」と伝えていると語り、数年前に成功していたやり方が来年も同じように通用するとは限らないと述べている。</p>
<p>その上で、AIによって担当範囲が広がり、より大きな影響を与えられるようになる可能性がある一方、学び方や働き方を柔軟に変えられなければ、変化の速い環境で後れを取ることもあり得るとした。雇用全体への影響については不確実性があるとしながらも、中長期的にはAIが新たな経済的機会を生み、失われる仕事以上に新しい仕事が生まれる可能性が高いとの見方を示している。</p>
<p>ただし、短期的には職種によって人手が減る局面が起こり得るとも言及し、企業側の役割として、訓練やリスキリングを通じて人材を再配置していく必要があるとの考えも示した。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国、国家級「未来ネットワーク基盤」699日が1.6時間に──ネットワークを“計算機”に変える実験が始まる</title>
      <link>https://ledge.ai/articles/china_distributed_ai_computing_ceni_launch</link>
      <description><![CDATA[<p>中国で、全国規模の研究用ネットワーク基盤が正式に稼働した。中国国営メディア「<a href="https://www.stdaily.com/web/gdxw/2025-12/04/content_441822.html">科技日報</a>」は2025年12月4日、「未来网络基础设施（CENI）」が国家検定を通過し、運用段階に入ったと報じた。同基盤は、情報通信分野における国家重大科技基礎施設として整備されてきたものだという。</p>
<p>科技日報によると、CENIは計算資源を各地に分散配置し、高速ネットワークで接続する構成を採る。単一拠点に計算能力を集約するのではなく、ネットワーク上で計算やデータ処理を行う点が特徴とされている。</p>
<h2>72TBの天文データ転送で確認された性能差</h2>
<p>記事では、CENIの性能を示す実証例として、大規模な天文観測データの転送試験が紹介されている。試験は12月3日、江苏省の未来网络创新研究院で実施された。</p>
<p>対象となったのは、「中国天眼（FAST）」関連の観測データで、データ量は約72TB。贵州师范大学の分センターから、華中科技大学天文系のデータセンターへ転送された。従来の一般的なインターネット環境では、この規模のデータ転送に約699日を要していたという。</p>
<p>一方、CENIを用いた場合、同じデータは約1.6時間で転送が完了した。科技日報は、この結果をもって、従来方式との間に大きな性能差が確認されたとしている。</p>
<p><strong>■ 500メートル口径球面電波望遠鏡（FAST、中国天眼）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fast_865bfb86dd/fast_865bfb86dd.jpg" alt="fast.jpg" /></p>
<h2>確定性ネットワークによる帯域・遅延の保証</h2>
<p>転送試験では、確定性ネットワーク（中国語では「确定性网络」）と非確定性ネットワークの比較も行われた。いずれも帯域50Gbpsの条件で構築され、同時にデータ転送を実施。さらに、外部から50Gbpsの干渉トラフィックを加える試験が行われた。</p>
<p>その結果、確定性ネットワークでは転送速度がほぼ維持されたのに対し、非確定性ネットワークでは速度が急激に低下し、1Gbps未満まで落ち込んだとされる。科技日報は、CENIが提供するのは単なる高速通信ではなく、帯域や遅延、パケット損失が事前に制御・保証される通信環境である点を強調している。</p>
<h2>国家検定を通過、研究用途向けに運用開始</h2>
<p>CENIは、南京で国家レベルの検定を通過した。検定委員会は、同施設が建設目標を全面的に達成し、情報通信分野における重要な技術成果を生み出したと評価したという。</p>
<p>科技日報は、CENIを「我国信息通信领域首个国家重大科技基础设施」と位置づけている。商用サービスとしての提供を目的としたものではなく、研究機関や産業界が新たなネットワーク技術や応用を検証するための基盤として整備された点が特徴だ。</p>
<h2>全国40都市を結ぶ試験ネットワークの構成</h2>
<p>CENIの構想は2013年に始まり、10年以上をかけて整備が進められてきた。現在は全国40都市を結び、光伝送距離は5万5000キロメートルを超えるという。7×24時間の運用が可能で、複数の異なるネットワークや業務を並行して試験できる構成となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ceni_hefei_c058f2fb27/ceni_hefei_c058f2fb27.jpg" alt="ceni-hefei.jpg" /></p>
<p>科技日報では、この規模を、全国レベルで新しいネットワーク設計や運用方式を検証できる点に意義があるとしている。</p>
<h2>AI学習や算力連携に向けた活用例</h2>
<p>科技日報では、AI分野での活用例にも触れている。千億パラメータ規模の大規模モデルを跨域で協調学習させた場合、確定性ネットワークを利用することで、学習に要する時間を短縮できる可能性が示された。</p>
<p>一方で、CENIはAI専用の基盤として紹介されているわけではない。科技日報は、同施設を中国全体の計算資源を効率的に連携させる「算力网」構想や、「东数西算」工程に向けた試験基盤の一つとして位置づけている。</p>
<p>「未来网络基础设施」は、高速通信網や大規模データセンターの代替ではなく、ネットワークと計算を一体として扱う設計を、国家規模で検証するための研究基盤であると科技日報はまとめた。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Cloudflare　2025年を振り返って「Radar 2025 Year in Review」公開──AIクローリングと主要サービスへの通信集中が鮮明に</title>
      <link>https://ledge.ai/articles/cloudflare_2025_ai_crawling_major_services_traffic</link>
      <description><![CDATA[<p>Cloudflareは、同社ネットワークで観測されたインターネット通信の動向をまとめた年次レポート「Radar 2025 Year in Review」を<a href="https://radar.cloudflare.com/year-in-review/2025#internet-traffic-growth">公開</a>した。2025年のインターネットでは、生成AI関連のクローラーを含む自動化されたアクセスが存在感を増す一方、トラフィックが一部の主要サービスに集中する傾向が改めて浮き彫りになった。</p>
<p>同レポートは、Cloudflareが世界中で運用するエッジネットワークやDNSリゾルバーなどを通じて得られた観測データをもとに、2025年の通信トラフィック、サービス利用、セキュリティ動向などを多角的に整理したものだ。</p>
<h2>AI時代のクローリングが示した通信の転換点</h2>
<p>Radar 2025 Year in Reviewでは、2025年のインターネット通信において、検索エンジン向けの従来型クローラーに加え、生成AIに関連するクローラーの活動が顕著になった点が強調されている。Cloudflareは、こうした動きを単なるトラフィック量の増加ではなく、通信の構造が変化しつつある兆候として捉えている。</p>
<p><strong>■ 2025年を通じて、生成AI関連を含む各種クローラーのリクエストが継続的に観測された。Cloudflare Radarは、AIボットと従来型クローラーの通信量を並列に可視化している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai_bot_c1ac1e0c43/ai_bot_c1ac1e0c43.jpg" alt="ai bot.jpg" /></p>
<p>生成AI向けクローラーは、Webページを検索結果に反映するための従来のクロールとは異なり、学習や要約、回答生成といった用途を前提に巡回する点が特徴とされる。Radarでは、こうしたAIクローラーの通信が、一定の割合を占めるまでに拡大している実態が示されている。</p>
<p>Cloudflareはまた、ボットによるアクセスが必ずしも悪意あるものではない点にも言及している。検索やAIサービスの品質向上に寄与する「正当なボット」がある一方で、過剰なクロールや意図しない負荷を生むアクセスも存在しており、Web運営においては人間と自動化された通信を区別して扱う重要性が増しているとする。</p>
<h2>トラフィックが集まった主要サービス群</h2>
<p>Radar 2025 Year in Reviewでは、2025年を通じてどのようなサービスにトラフィックが集中したのかについても整理されている。検索、ソーシャルメディア、動画配信、クラウド関連サービスといった分野では、引き続き一部の大規模プラットフォームが高い通信量を維持した。</p>
<p><strong>■ 2025年はGoogleをはじめとする既存の大規模インターネットサービスが、引き続き高いトラフィックを維持した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/internet_services_2d645b8411/internet_services_2d645b8411.jpg" alt="internet services.jpg" /></p>
<p>Cloudflareは、こうした傾向をインターネット利用の「重心」が特定のサービス群に集約されつつある状況として示している。特に、日常的に利用されるインフラ的なサービスほど安定したトラフィックを確保しており、利用先の固定化が進んでいる様子がうかがえる。</p>
<p>また、生成AI関連サービスについても、2025年には一過性の話題ではなく、日常的にアクセスされる存在としてトラフィック上に現れるようになった点が示された。人間による直接利用と、AIクローラーによるアクセスが混在することで、通信の内訳がより複雑化していることも特徴として挙げられている。</p>
<h2>可視化が示す2025年のインターネット像</h2>
<p>Cloudflareは、Radarを通じて「どの通信が、誰によって発生しているのか」を可視化する重要性を強調している。2025年のインターネットは、人間の利用だけでなく、AIやボットによる自動化された通信が前提となりつつあり、セキュリティ対策やトラフィック制御においても、こうした前提を踏まえた対応が求められているという。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>月額3万6400円の「Google AI Ultra」に最強推論モード──Geminiアプリに、思考するAI「Deep Think」モードの実装</title>
      <link>https://ledge.ai/articles/gemini_3_deep_think_google_ai_ultra_launch</link>
      <description><![CDATA[<p>Googleは2025年12月4日（現地時間）、Geminiアプリに新たな推論モード「Gemini 3 Deep Think」を追加したと<a href="https://blog.google/products/gemini/gemini-3-deep-think/">発表</a>した。</p>
<p>同社はブログで、「Today, we’re rolling out Gemini 3 Deep Think mode to Google AI Ultra subscribers in the Gemini app.」と述べており、最上位サブスクリプションプラン「Google AI Ultra」の加入者を対象に、Geminiアプリで順次ロールアウトしている。利用するには、モデル選択で「Gemini 3 Pro」を選び、プロンプト入力欄から「Deep Think」モードをオンにする。</p>
<h2>高難度課題向けに推論能力を強化</h2>
<p>公開された「Gemini 3 Deep Think」は、回答を出力する前に複数の推論ステップを挟むことで、従来よりも深い推論ができるよう設計されたモードだ。Googleはブログで、同モードが「meaningful improvement in reasoning capabilities」を提供し、複雑な数学・科学・論理推論に取り組む場面を想定していると説明している。</p>
<p>具体的には、高度な並列推論（advanced parallel reasoning）を用いて複数の仮説を同時に探索するアプローチを採用することで、問題解決の過程を強化しているという。これにより、単に次の単語を即座に予測するのではなく、複数の候補を比較しながら解答に至るプロセスを踏めるとしている。</p>
<p>Googleは、Gemini 3 Deep Thinkが高難度ベンチマークで次のようなスコアを記録したと紹介している。</p>
<ul>
<li>Humanity’s Last Exam：ツールなしで 41.0%</li>
<li>ARC-AGI-2：コード実行ありで 45.1%</li>
</ul>
<p>同社は、これらの結果について「industry leading」「unprecedented（前例のない）」と表現しており、深い推論が求められるベンチマークにおいて業界トップレベルの性能を示したと位置づけている。また、今回のGemini 3 Deep Thinkは、国際数学オリンピック（IMO）や国際大学対抗プログラミングコンテスト（ICPC）World Finalsで「gold-medal standard」とされる水準に達した「Gemini 2.5 Deep Think」の系譜にあると説明されている。</p>
<h2>利用対象は「Google AI Ultra」加入者</h2>
<p>日本向けの公式プランページでは、Google AI Ultraの料金は月額3万6400円（税込）と案内されている。現時点（2025年12月8日）では、GeminiアプリでのDeep ThinkおよびGemini Agentについては「米国のみ、英語のみで利用可能」とされており、機能レベルでは提供地域に制限が設けられている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界中の建物27.5億棟を3D化──ミュンヘン工科大、初の“完全グローバル”建物3Dデータセットを公開</title>
      <link>https://ledge.ai/articles/global_building_atlas_tum_global_3d_building_dataset</link>
      <description><![CDATA[<p>ミュンヘン工科大学（Technical University of Munich：TUM）の研究チームは2025年12月2日、世界中の建物を網羅した高解像度3D建物データセット「GlobalBuildingAtlas」を<a href="https://www.tum.de/en/news-and-events/all-news/press-releases/details/all-the-worlds-buildings-available-as-3d-models-for-the-first-time">公開</a>した。建物の形状ポリゴンと高さ情報を統合し、地球上の建物約27.5億棟をLoD1（簡易レベル）の3Dモデルとして再構成したもので、全球規模で一貫した3D建物データセットは初めてだという。</p>
<p>GlobalBuildingAtlasは、都市構造の把握や人口分布の推定、防災や気候変動対策などへの活用を想定して設計された。TUMは公式発表の中で、同データセットにより「世界中の建物が初めて3Dモデルとして利用可能になる」としている。</p>
<h2>建物データを「全球」で扱うという試み</h2>
<p>これまで、建物データは国や地域ごとに整備状況が大きく異なり、全球レベルでは不完全なカバレッジや粗い解像度にとどまっていた。特に建物の高さや体積といった立体情報は、地域限定のLiDAR測量や航空測量に依存するケースが多く、世界全体を同一基準で扱うことは難しかった。</p>
<p>GlobalBuildingAtlasは、こうした課題に対し、建物単位での一貫した全球カバレッジを目指した取り組みとして位置づけられている。研究チームは、既存のオープン建物データと衛星観測データを統合し、品質を重視した形で再構築したとしている。</p>
<h2>データセットの規模と構成</h2>
<p>GlobalBuildingAtlasがカバーする建物数は約27.5億棟にのぼる。各建物について、2Dの建物ポリゴンに加え、推定された高さ情報が付与され、LoD1レベルの3Dモデルが生成されている。論文によると、建物高さの推定が行われた建物は全体の97％以上を占める。</p>
<p><strong>■ GlobalBuildingAtlasの構築プロセス概要。光学衛星画像から建物高さを推定し、全球規模の3D建物モデルを生成している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Global_Building_Atlas_fig1_82822b2f78/Global_Building_Atlas_fig1_82822b2f78.png" alt="GlobalBuildingAtlas fig1.png" /></p>
<p>建物高さは、約3メートル四方の空間解像度で推定されており、従来の全球規模の建物高さデータと比べて大幅に高精細だ。これにより、都市全体の立体構造や建物体積を、より細かな粒度で分析できるようになったとしている。</p>
<h2>高さ推定と3D化のアプローチ</h2>
<p>GlobalBuildingAtlasの構築には、光学衛星画像と機械学習モデルが用いられている。研究チームは、PlanetScopeの光学衛星画像を入力とし、単眼画像から建物高さを推定するモデルを開発した。</p>
<p>この手法の特徴は、高価なLiDARデータや航空測量に依存せず、全球で一貫して取得可能な光学衛星データのみを用いている点にある。論文では、複数地域での検証を通じて、高さ推定の精度や誤差特性についても評価が行われている。</p>
<h2>建物の「体積」を扱えることの意味</h2>
<p>建物データはこれまで、主に平面積や建物数といった2次元的な指標で扱われてきた。しかし、都市の密度や居住実態を把握する上では、高さを含む立体情報が重要になる。</p>
<p>GlobalBuildingAtlasでは、建物体積を用いた分析が可能となり、論文中では人口分布や経済指標との関係についても検証が行われている。研究チームは、体積ベースの指標が、都市化の度合いや地域差をより適切に反映する可能性があるとしている。</p>
<h2>ミュンヘン工科大学が示す活用の方向性</h2>
<p>TUMは、本データセットを都市計画や防災、インフラ整備、気候変動対策などの基盤データとして位置づけている。特に、統計データや測量インフラが十分に整備されていない地域において、都市構造を把握するための補完的な情報源になると説明している。</p>
<h2>データ提供と可視化の取り組み</h2>
<p>GlobalBuildingAtlasは、研究用途を中心としたオープンデータとして公開されている。データセットに加え、ブラウザ上で建物の3D分布を確認できるインタラクティブな3D地図も提供されており、全球規模の建物構造を視覚的に把握することができる。</p>
<p><strong>■ GlobalBuildingAtlasがカバーする全球の建物分布。約27.5億棟の建物が一貫した基準で収録されている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/overview_fig3_d0765fe792/overview_fig3_d0765fe792.jpg" alt="overview fig3.jpg" /></p>
<h2>精度評価と今後の課題</h2>
<p>一方で、論文では地域による推定精度の差についても言及されている。高層建築が集中する都市部では高さの過小推定が見られるケースがあり、教師データの不足する地域では誤差が大きくなる傾向があるという。</p>
<p><strong>■ 地域別に見た建物高さ推定の誤差分布。高層建築が集中する都市部では過小推定が見られるケースがある。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Global_Building_Atlas_fig6_80eb2dea64/Global_Building_Atlas_fig6_80eb2dea64.png" alt="GlobalBuildingAtlas fig6.png" /></p>
<p>研究チームは今後、学習データの拡充やモデル改良を通じて精度向上を図るとともに、将来的にはより詳細な3D表現への発展も視野に入れている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIに「長期記憶」を与える新アーキテクチャ「Titans」と設計理論のフレームワーク「MIRAS」を発表</title>
      <link>https://ledge.ai/articles/google_ai_long_term_memory_titans_miras</link>
      <description><![CDATA[<p>Google Researchは2025年12月4日、AIモデルに長期的な記憶能力を持たせるための新たなアーキテクチャ「Titans」と、その設計思想を統一的に説明するフレームワーク「MIRAS」を<a href="https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/">発表</a>した。</p>
<p>Transformerを中心とする既存の大規模言語モデルが抱えてきた「長い文脈を扱うほど計算コストが増大し、重要な情報を保持しにくい」という課題に対し、推論時に記憶を学習・更新するという新しいアプローチを提示している。</p>
<h2>Transformerの限界と「記憶」の再定義</h2>
<p>TransformerはAttention機構によって高精度な依存関係のモデリングを可能にしてきた一方、計算量がコンテキスト長の二乗に比例するという制約を持つ。このため、極端に長い文書や時系列データを扱う際には効率面・性能面の両方で課題があった。</p>
<p>Google Researchは、Attentionを「短期記憶」、それを補完する仕組みとして「長期記憶」を明確に分離して設計する必要があると位置づけた。</p>
<h2>推論時に学習する「Titans」の中核</h2>
<p>Titansの中心となるのは「Neural Long-Term Memory Module」と呼ばれる長期記憶モジュールだ。このモジュールは、再学習を行うことなく、推論時に入力を受け取りながら記憶を更新する。単なるキー・バリューキャッシュとは異なり、過去の情報をモデル内部のパラメータとして蓄積できる点が特徴だ。</p>
<p><strong>■ Titansの全体構成：</strong> Attentionによる短期記憶に加え、推論時に更新されるNeural Memory（長期記憶）を統合。入力の重要度に応じて記憶を更新しつつ、固定パラメータとは独立して動作する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Titans_1_Overview_width_1250_e2f30e7bc8/Titans_1_Overview_width_1250_e2f30e7bc8.png" alt="Titans-1-Overview.width-1250.png" /></p>
<p>Titansでは、長期記憶の統合方法として以下の3つの構成を提示している。</p>
<ul>
<li><strong>MAC（Memory as a Context）：</strong> 記憶を文脈としてAttentionに渡す方式</li>
<li><strong>MAG（Memory as a Gate）：</strong> 記憶によってAttention出力を制御する方式</li>
<li><strong>MAL（Memory as a Layer）：</strong> 記憶を独立したレイヤーとして組み込む方式</li>
</ul>
<p>特にMAC構成は、長距離依存関係を扱うタスクで高い性能を示したという。</p>
<h2>「驚き」に基づく選択的記憶と忘却</h2>
<p>Titansはすべての情報を無差別に記憶するのではなく、予測誤差が大きい、いわゆる「驚き（surprise）」の高いトークンを優先的に長期記憶へ反映する設計を採用している。
また、weight decayやモメンタムを用いた更新により、不要になった情報を忘却できる仕組みも備える。これにより、従来の線形RNNやゲート型モデルでは難しかった「完全な記憶の消去」も可能になるという。</p>
<h2>2Mトークン超でも性能を維持</h2>
<p>論文では、言語モデリング、常識推論、needle-in-a-haystackタスク、DNA解析、時系列予測など幅広いベンチマークで評価を実施。BABILongやRULERといった長文タスクでは、GPT-4やRAGを併用した大規模モデルを含む既存手法を上回る結果を示した。
有効なコンテキスト長は200万トークンを超えても性能が維持されることが確認されている。</p>
<h2>設計理論「MIRAS」が示す統一的枠組み</h2>
<p>MIRASは、Titansを含むさまざまなシーケンスモデルを「連想記憶システム」として捉え直すためのフレームワークだ。</p>
<p>設計要素を</p>
<ol>
<li>記憶構造</li>
<li>想起のための目的関数（attentional bias）</li>
<li>保持・忘却を制御するゲート</li>
<li>記憶の学習アルゴリズム</li>
</ol>
<p>の4点に整理し、Transformerや線形RNN、Titansを同一の理論枠組みで説明できるとしている。</p>
<p><strong>■ MIRASフレームワークの概念図：</strong> 記憶構造、想起基準（attentional bias）、保持・忘却（retention gate）、学習アルゴリズムの4要素で、TitansやTransformerを含むシーケンスモデルを統一的に説明する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/miras_framework_47bb139255/miras_framework_47bb139255.jpg" alt="miras framework.jpg" /></p>
<p>MIRASを基に、Moneta、Yaad、Memoraといった新たなモデル群も提案されており、タスク特性に応じた記憶設計の可能性が示された。</p>
<h2>推論時学習という新たな方向性</h2>
<p>Google Researchは、TitansをMIRASフレームワークの具体例の一つと位置づけている。外部検索に依存するRAGや、巨大な固定コンテキストを用意する方法とは異なり、「推論時に学習する記憶」を内包したAI設計が、今後の長文・長期推論の重要な方向性となる可能性を示した形だ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、ディズニー要請受けAI生成動画を削除──OpenAIとは対照的な対応に</title>
      <link>https://ledge.ai/articles/google_disney_ai_generated_videos_removed_variety</link>
      <description><![CDATA[<p>Googleが、ディズニーからの削除要請を受け、ディズニーキャラクターを描いたAI生成動画を数十本削除していたことが分かった。米<a href="https://variety.com/2025/film/news/google-removes-ai-videos-disney-characters-cease-desist-1236608015/">Variety</a>が2025年12月12日に報じた。</p>
<p>Varietyによると、削除されたのはYouTube上に投稿されていたAI生成動画で、ミッキーマウスやマーベル作品、スター・ウォーズ、『ザ・シンプソンズ』など、ディズニー傘下のキャラクターが描写されていたという。ディズニーはこれらの動画について、著作権侵害の可能性があるとして、Googleに対し正式な削除要請（cease and desist）を送付したとされる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/variety_disney_google_4a027dbfad/variety_disney_google_4a027dbfad.jpg" alt="variety disney google.jpg" /></p>
<p>GoogleはVarietyの取材に対し、当該動画を削除した事実を認めている。一方で、削除対象の詳細や、今後の対応方針については明らかにしていない。</p>
<p>ディズニーは近年、生成AIによる自社キャラクターの無断利用に対して警戒を強めている。Varietyは、今回の削除要請が単発の対応ではなく、AI生成コンテンツ全般に対する管理を強化する動きの一環である可能性を指摘している。</p>
<p>こうした対応は、ディズニーが生成AIの活用自体を一律に拒否しているわけではない点と対照的だ。ディズニーは2025年12月11日、OpenAIと3年間のライセンス契約を締結し、動画生成AI「Sora」において、ディズニー、マーベル、ピクサー、スター・ウォーズなど200以上の公式キャラクターの利用を<a href="https://ledge.ai/articles/disney_openai_sora_character_license">認めている</a>。</p>
<p>Varietyが伝える今回のGoogleの事例は、同じ生成AIを巡る動きでありながら、企業ごとに異なる対応が取られている現状を示している。OpenAIとはライセンス契約を結ぶ一方で、Googleに対しては削除要請という形で対処しており、どの企業が、どの条件下でディズニーの知的財産を扱えるのか、その線引きがより明確になりつつあることがうかがえる。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/18 [THU]Google、「Gemini 3 Flash」公開　“Pro級の推論”を低遅延・低コストで、Geminiアプリの既定モデルに</title>
      <link>https://ledge.ai/articles/google_gemini_3_flash_default_model_release</link>
      <description><![CDATA[<p>Googleは2025年12月17日（現地時間）同社の生成AIモデル「Gemini 3」ファミリーに新たに「Gemini 3 Flash」を追加し、提供を開始したことを<a href="https://blog.google/products/gemini/gemini-3-flash/">発表</a>した。Gemini 3 Flashは、スピードを重視しながらも高度な推論能力とマルチモーダル機能を維持する点を特徴としており、一般ユーザー向けのGeminiアプリでは既定モデルとして展開される。</p>
<p>@<a href="https://www.youtube.com/watch?v=rPXBDSf-Hwg">YouTube</a></p>
<p>Googleによると、Gemini 3 Flashは「高速性、知能、コスト効率のバランス」を重視して設計されたモデルで、日常的な知識労働からソフトウェア開発まで、幅広いユースケースを想定している。同社は、Gemini 3の次世代インテリジェンスをGoogle製品全体に広げる役割を担うモデルだと位置づけている。</p>
<h2>推論ベンチマークで示された“Pro級”の性能</h2>
<p>公式ブログでは、Gemini 3 Flashの性能を示す指標として、複数の評価ベンチマークが公開された。高度な専門知識を問う「GPQA Diamond」では90.4％、「Humanity’s Last Exam」ではツール非使用条件で33.7％を記録したとしている。Googleは、これらの結果が、より大規模なフロンティアモデルに匹敵する水準だと説明している。</p>
<p>また、マルチモーダル理解能力を測る「MMMU Pro」では81.2％に到達し、Gemini 3 Proと同等レベルの性能を示したという。推論能力とマルチモーダル処理を両立している点が、Gemini 3 Flashの重要な特徴とされている。</p>
<p><strong>■ Gemini 3 Flashと他モデルを比較した公式ベンチマーク。推論、マルチモーダル理解、コーディングなど幅広い指標で、上位モデルに近いスコアを示している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_flash_final_benchmark_t_width_1000_format_webp_1aa4e26a6b/gemini_3_flash_final_benchmark_t_width_1000_format_webp_1aa4e26a6b.webp" alt="gemini-3-flash_final_benchmark-t.width-1000.format-webp.webp" /></p>
<p>加えて、ソフトウェア開発分野では、コード生成や修正能力を評価する「SWE-bench Verified」で78％を記録し、Gemini 2.5系やGemini 3 Proを上回ったとしている。Googleは、反復的な開発作業やエージェント型ワークフローに適したモデルだと説明している。</p>
<h2>「2.5 Pro比で3倍高速」、コスト効率も前面に</h2>
<p>速度面では、外部評価機関Artificial Analysisによる測定結果として、Gemini 3 Flashは「Gemini 2.5 Proと比べて最大で約3倍高速」と説明されている。加えて、同等のタスクを処理する際に必要なトークン数が平均で約30％少なく、コスト効率にも優れるという。</p>
<p>開発者向けの価格設定は、入力が100万トークンあたり0.50ドル、出力が同3ドル。音声入力は100万トークンあたり1ドルとされている。Googleは、低遅延かつ高頻度での利用を想定した価格体系だとしている。</p>
<p><strong>■ 性能（スコア）とコストの関係を示した比較グラフ。Gemini 3 Flashは、Gemini 3 Proに近い性能帯を保ちながら、Flash系モデルらしい価格帯に位置づけられている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_flash_pareto_graph_dec1_width_1000_format_webp_cf3f26591a/gemini_3_flash_pareto_graph_dec1_width_1000_format_webp_cf3f26591a.webp" alt="gemini-3-flash_pareto_graph_dec1.width-1000.format-webp.webp" /></p>
<h2>開発者向けにはAPI・CLI・企業向け基盤で提供</h2>
<p>Gemini 3 Flashは、Google AI StudioのGemini APIを通じてプレビュー提供されるほか、コマンドラインから利用できる「Gemini CLI」、エージェント開発向けプラットフォーム「Google Antigravity」でも利用可能とされている。企業向けには、Vertex AIおよびGemini Enterpriseを通じた提供が行われる。</p>
<h2>Geminiアプリでは「追加料金なし」で利用可能</h2>
<p>Gemini 3 Flashは、一般ユーザー向けのGeminiアプリでは既定モデルとして提供され、追加料金なしで利用可能とされている。また、Google検索の「AI Mode」でも、全ユーザーを対象に段階的な無料提供が始まっている。</p>
<p>なお、Geminiアプリには使用量の上限があり、ProやUltraといった有料サブスクリプションでは、より大きな利用枠が適用される</p>
<h2>有料プランや開発用途では従量課金が適用</h2>
<p>一方、Gemini 3 Flashは開発用途や企業向けサービスでも提供される。Google AI Studioを通じたGemini APIや、Vertex AI、Gemini Enterpriseといった企業向け基盤では、利用量に応じた従量課金が発生する。
公式ブログでは、Gemini 3 Flashの価格として、入力が100万トークンあたり0.50ドル、出力が同3ドル、音声入力は100万トークンあたり1ドルが提示されている。Googleは、低遅延かつ高頻度での利用を想定した価格体系だとしており、開発者や企業での実運用を意識した設計であることを強調している。</p>
<h2>検索AIモードにも展開</h2>
<p>Gemini 3 Flashは、Google検索の「AI Mode」でも既定モデルとして段階的にロールアウトされる。検索AIモードでは、質問の意図を分解して整理した回答や、リアルタイムのローカル情報、関連リンクの提示などを特徴としている。
Googleは、Gemini 3 ProやGemini 3 Deep Thinkとあわせてモデルラインアップを拡充し、一般ユーザーから開発者、企業利用までをカバーする体制を整えていく方針だ。Gemini 3 Flashは、その中でスピードと実用性を担う中核モデルとして位置づけられている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、MCPを全サービスに展開──Gemini時代の「AI×クラウド接続」を標準化</title>
      <link>https://ledge.ai/articles/google_mcp_all_services_gemini_ai_cloud_standardization</link>
      <description><![CDATA[<p>Googleは2025年12月11日、生成AIモデル「Gemini」などのAIエージェントと、同社のクラウドサービスを接続するための共通基盤として、Model Context Protocol（MCP）の公式サポートを開始したと<a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services">発表</a>した。Googleは今後、同社が提供するすべてのサービスにおいて、段階的に接続用のMCPサーバをGoogle側が用意・運用する形で提供していく方針だ。</p>
<h2>MCP：AIとサービスをつなぐ共通プロトコル</h2>
<p>MCPは、生成AIやAIエージェントが外部ツールやデータソース、APIと、安全かつ標準化された方法で接続するためのオープンプロトコルである。GoogleはこのMCPを、自社クラウドサービスとAIを結ぶ「共通の接続レイヤー」として公式に採用した。</p>
<p>今回Googleが提供するMCPサーバは、サーバの構築や運用、スケーリングをすべてGoogleが担う仕組みとなっている。開発者は自らサーバを立ち上げたり管理したりする必要がなく、MCPクライアントを通じてGoogleの各種サービスに直接接続できる。認証や権限制御についても、既存のGoogle Cloudのセキュリティ基盤と連携している。</p>
<h2>まずはMapsやBigQueryなど主要サービスから対応</h2>
<p>発表時点でMCPサーバに対応している主なサービスには、Google Maps、BigQuery、Google Compute Engine、Google Kubernetes Engine（GKE）などが含まれる。これらのサービスは、位置情報、データ分析、計算資源、コンテナ管理といった機能を提供しており、AIエージェントが実際の処理や操作を行うための基盤として利用できる。</p>
<p>Googleは、これらの初期対応サービスにとどまらず、今後すべてのGoogleサービスで同様の仕組みを提供する計画を示している。公式ブログでは、今後数カ月以内にCloud Run、Cloud Storage、Spanner、Looker、Pub/Sub、Cloud Logging、Cloud Monitoring、Security Operations（SecOps）、Android Management APIなどにも対応を広げる予定だとしている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「ルンバ」のiRobotがついに破産手続き開始、中国Picea傘下で事業は継続──アイロボットジャパン「アフターサービスこれまで通り」Chapter 11申請受け声明</title>
      <link>https://ledge.ai/articles/irobot_chapter11_picea_business_continuity</link>
      <description><![CDATA[<p>ロボット掃除機「ルンバ」で知られる米iRobot Corporationは2025年12月、連邦破産法第11章（Chapter 11）に基づく再編手続きを開始したと<a href="https://media.irobot.com/2025-12-14-iRobot-Announces-Strategic-Transaction-to-Drive-Long-Term-Growth-Plan">発表</a>した。</p>
<p>同社は中国の掃除機メーカーPicea Robotics（関連会社Santrum Hong Kongを含む）による買収を受け入れ、債務整理後も事業を継続する方針だ。これを受け、日本法人のアイロボットジャパンは「事業はこれまで通り継続する」との声明を<a href="https://www.irobot-jp.com/press/pdf/20251215_2.pdf">発表</a>している。</p>
<p>iRobotによると、今回のChapter 11申請は清算を目的としたものではなく、事業継続を前提とした再編手続きとして進められる。あらかじめ主要条件を合意した「プレパッケージ型」の再編で、中国Picea Roboticsとの間で締結した再編支援契約（Restructuring Support Agreement）に基づき、裁判所の監督下で手続きを進めるという。</p>
<h2>中国Piceaが全株式を取得、iRobotは非公開化へ</h2>
<p>再編計画では、主要サプライヤーかつ担保権者でもあるPicea Roboticsが、iRobotの普通株式100％を取得する。再編完了後、iRobotはPiceaの完全子会社となり、非公開企業として再スタートを切る見通しだ。再編プロセスの完了は2026年2月上旬を予定している。</p>
<p>米証券取引委員会（SEC）に提出された開示資料によれば、再編に伴い既存の普通株式は消却され、現在の株主は再編後のiRobotの持ち分を取得しない見込みとされている。</p>
<h2>日本法人「事業はこれまで通り」</h2>
<p>iRobotは、Chapter 11手続き中および再編完了後も通常の事業運営を継続すると説明している。これを受け、アイロボットジャパンも公式声明で、製品販売やカスタマーサポート、保証対応、アプリやクラウドサービスについて「事業はこれまで通り」継続すると明らかにした。日本市場のユーザーや販売チャネルへの直接的な影響は限定的とされる。</p>
<h2>これまでの経緯と今回の位置づけ</h2>
<p>iRobotは家庭用ロボット掃除機市場の先駆者として「ルンバ」ブランドを展開してきたが、近年は競争の激化やコスト上昇を背景に、厳しい経営環境が続いていた。Ledge.aiではこれまで、Amazonによる買収計画の白紙撤回や、2025年に入って表面化した事業危機について報じてきた。</p>
<p>今回のChapter 11申請と中国Picea傘下への移行は、そうした流れの延長線上に位置づけられる。iRobotはこの戦略的取引によりバランスシートを立て直し、ロボティクスおよびスマートホーム分野での長期的な成長を目指すとしている。</p>
<p>今後は、裁判所による再編計画の承認を経て、新体制下での事業運営が本格化する見通しだ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>JCB、日本IBMとAIパートナーシップ──生成AI「watsonx」で基幹システム開発を革新、設計〜テストで約20%効率化も</title>
      <link>https://ledge.ai/articles/jcb_ibm_ai_partnership_watsonx_core_system_development</link>
      <description><![CDATA[<p>JCBと日本IBMは2025年12月17日、日本IBMが持つコンサルティング力およびテクノロジーの知見を活用し、JCBのシステム分野におけるAIによる変革を実現することを目的としたAIパートナーシップを締結したと<a href="https://prtimes.jp/main/html/rd/p/000001303.000011361.html">発表</a>した。</p>
<p>両社は、生成AIを「開発の共同パートナー」と位置づけ、基幹システムの設計・開発・テストといったIT開発プロセス全体の高度化を図る。日本IBMの生成AI基盤「watsonx」を活用し、品質向上と開発スピードの両立、さらには開発コストの最適化を目指す。</p>
<h2>生成AIを前提とした基幹システム開発へ</h2>
<p>JCBは、国内外の決済を支える基幹システム群を対象に、AIを組み込んだ新たな開発モデルの確立を進めている。今回のパートナーシップでは、日本IBMがこれまで培ってきた業務改革やシステム開発のコンサルティング知見と、生成AIを含む先端技術を組み合わせ、次世代のIT開発手法を構築する。</p>
<p>具体的には、設計からテストまでの各工程に生成AIを組み込み、人手に依存してきた作業の効率化と品質の平準化を図る。これにより、金融インフラとして求められる高い信頼性を維持しながら、開発生産性の向上を目指すとしている。</p>
<h2>COBOLコード生成やテスト自動化など具体的ユースケース</h2>
<p>両社はすでに複数の基幹システムで生成AIの活用を進めている。外部設計書をもとに、高精度なプログラム設計書やCOBOLコードを自動生成するほか、単体テストケースの網羅的な作成や、ブラックボックス観点を取り入れたテストケースの補強を行っている。</p>
<p>また、JCBが連携する500を超える提携先ごとに異なるインターフェース仕様や、業界固有の規制要件に対応したテストデータを生成AIで自動作成する取り組みも進めている。これにより、従来は大きな負担となっていたテスト工程の効率化と品質確保を両立させる狙いだ。</p>
<h2>設計〜テスト工程で約20%の効率化</h2>
<p>こうした取り組みの成果として、すでに一部のシステムでは、設計からテストまでの工程において約20%の開発効率化を達成したという。JCBと日本IBMは、この成果を踏まえ、生成AIを活用した開発手法を今後のシステム更改や他の開発案件にも順次拡大していく方針だ。</p>
<h2>要件定義やコードレビューへの展開も視野</h2>
<p>今後は、自然言語による要件定義の支援や、コードレビューへの生成AI活用など、より上流工程・高度工程への適用も検討する。両社は、AIを前提とした開発スタイルを通じて、基幹システムの持続的な進化と新たな価値創出につなげていくとしている。</p>
<p>JCBは、日本発唯一の国際カードブランドとしてグローバルに決済ネットワークを展開しており、安定性と拡張性を両立するシステム基盤の強化が重要な課題となっている。日本IBMは、コンサルティングからシステム構築、運用までを一貫して支援する立場から、今回のパートナーシップを通じて金融分野における生成AI活用をさらに加速させる考えだ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>競争優位性の鍵は「全社導入」にあり。JTPが解き明かす、生成AI活用の“3つの壁”を乗り越える「Third AI」という最適解</title>
      <link>https://ledge.ai/articles/jtp-interview</link>
      <description><![CDATA[<p>生成AIが、もはや一部の先進的なツールではなく、ビジネスの競争力を左右する必須インフラとなった現代。多くの企業がその導入を急ぐ一方で、「全社的な活用」という非常に高い壁に直面している。この課題の根源は、生成AIを戦術的な「ツール」として配布しようとする、根本的なアプローチの誤りにある。真の競争優位性は、AIを組織全体に統合された戦略的な「ケイパビリティ（組織能力）」へと昇華させた時にこそ生まれるのだ。</p>
<p>この戦略的転換を阻むのが、コスト、セキュリティ、そして定着化という、3つの壁だ。ユーザー数課金は利用者を限定し、機密情報の取り扱いは導入を停滞させ、多忙な従業員に新たなツールを根付かせるのは容易ではない。</p>
<p>本記事では、これらの課題を解決するために、単なるツールではなく、優れた「戦略」として設計されたJTP株式会社の「Third AI 生成AIソリューション」について、同社のソリューション事業本部 副本部長 執行役員であり、本ソリューションのプロダクトオーナーを務める中川隆男氏へのインタビューに基づき、その核心に迫る。</p>
<h2>なぜ「一部の専門家」ではなく「全社員」による生成AI活用が必要なのか</h2>
<p>個々の業務効率化に留まらず、なぜ「全社員」によるAI活用が企業の将来を左右するほど重要と考えられるのか。その戦略的意義は、単なる生産性向上を超えた、企業文化そのものの変革にある。</p>
<h3><strong>競争力の源泉としてのAI活用</strong></h3>
<p>「もはや、全社員が生成AIを使えるようにならないと、企業としての競争力を失いかねません」。中川氏は、こう断言する。この言葉が示すのは、現在のAIが電気やインターネット、スマートフォンに匹敵するレベルの技術であるという事実だ。かつてインターネットを一部門のツールとしてしか捉えず、全社的なビジネスプロセスへの統合に失敗した企業が置き去りにされたように、AIを一部の専門チームに限定する企業は、今後同様の運命を辿る可能性が高い。
目指すべきは、AIが組織の隅々にまで浸透し、誰もが当たり前にその恩恵を受ける企業文化の醸成だ。</p>
<h3><strong>開発現場の実例が示すインパクト</strong></h3>
<p>そのインパクトは、すでに技術の最前線で現実のものとなっている。例えば、システム開発の現場では、生成AIで組まれたソースコードが多く動いているということは、もはや当たり前のことだ。AIを活用する企業とそうでない企業とでは、開発の「スピード」と「コスト（人件費・工数）」において、もはや比較にならないほどの差が生まれていることの意味に直結する。もちろんこれは一例で、こうした変革は、あらゆる職種に及ぶ可能性を秘めている。
全社員がこの新たな力を手にすることが、組織全体の生産性を底上げし、ひいては企業競争力そのものを再定義する。しかし、その理想的な未来への道のりには、多くのアプローチが共通して直面する障壁が存在する。</p>
<h2>生成AIの全社導入を阻む「3つの巨大な壁」</h2>
<p>生成AIの全社展開という壮大な目標を掲げたものの、多くの企業が具体的な障壁の前で足踏みしている。これらの壁は独立した問題ではなく、AIを「ツール」として捉えるアプローチが生み出す、相互に関連した症状である。これらの構造を正確に理解することこそ、適切なソリューションを選択するための不可欠な第一歩だ。</p>
<h3><strong>1. コストの壁：利用者を縛る「ユーザー数課金」</strong></h3>
<p>最も直接的で、かつ根本的な問題がコストだ。多くの生成AIサービスが採用する「ユーザー数課金モデル」は、社員一人ひとりの利用に対して費用が発生するため、全社展開を躊躇させる最大の要因となる。「ユーザー数課金では、どうしても一部のユーザーしか使わないという結果になりがちです。これでは全社的な生産性向上には繋がりません」と中川氏は指摘する。利用者を絞らざるを得ない価格体系が、結果的に「全社員活用」という本来の目的を阻害してしまっているのだ。</p>
<h3><strong>2. セキュリティの壁：機密情報と最新技術のジレンマ</strong></h3>
<p>次に立ちはだかるのが、堅牢さが求められるエンタープライズならではのセキュリティの壁だ。特に、金融機関や大手製造業の研究開発部門では、「まだ公開されていない技術情報や、顧客の機密データをAIにアップロードしてよいのか」という懸念が導入の大きなブレーキとなっている。
さらに、この問題は最新技術へのアクセスというジレンマと深く結びついている。「最新世代の高性能なAIモデルは、まず海外リージョンで提供されることがほとんどです。しかし、日本の多くの企業はデータを国外に送ることに強い懸念を持っています」。最高の性能を求めるならば海外リージョンを使わざるを得ず、しかし国内のセキュリティポリシーがそれを許さない。この板挟みが、多くの企業のAI戦略を停滞させている。</p>
<h3><strong>3. 定着化の壁：MAU 6〜7割の限界とインターフェースの問題</strong></h3>
<p>たとえコストとセキュリティの壁を乗り越えてツールを導入できたとしても、最後の壁である「定着化」が待ち受ける。中川氏によると、熱心に利用促進活動を行っている企業でさえ、月間アクティブユーザー（MAU）は「6〜7割で頭打ちになる」のが実情だという。
その一因は、インターフェースにある。「チャット画面という形式は、一部のユーザーにとっては依然として心理的なハードルが高いのです」。日常的に使っている業務アプリケーションから離れ、わざわざ別のツールを立ち上げてプロンプトを考えるという行為が、利用の習慣化を妨げる。AIが日常業務の中に自然に溶け込まない限り、利用率が100%に近づくことはない。</p>
<h2>“3つの壁”を打ち破る「Third AI」の戦略的アプローチ</h2>
<p>本インタビューの核心はここにある。JTPの「Third AI」は、前述した3つの壁を乗り越えるために、極めて戦略的に設計されたソリューションだ。そのアプローチは単なる機能提供に留まらない。企業のAI活用を根底から変革する、思想に基づいている。
その思想の中心にあるのが、「生成AIの民主化」を実現するという明確なミッションだ。技術的に高度なソリューションであると同時に、「誰でも使える」「全員に開かれている」ことを前提に設計されている点が、Third AIの大きな特徴である。</p>
<h3><strong>「環境課金」が全社導入の本当のボトルネックを解消する</strong></h3>
<p>「Third AI」が採用するのは、ユーザー数課金ではなく「環境課金」モデルだ。これは、利用する社員の数に依存せず、構築されたAI環境そのものに対して課金する方式である。この違いは極めて重要だ。この価格体系の背景には、「全社員の利用を阻む“課金の壁”を外す」という明確な思想がある。
戦略的な観点から見れば、この価格モデルはAI導入のROI計算を根本的に変える。企業は利用人数の増減を気にすることなく、全社員にAI活用の門戸を開くことができる。これは、コストを理由に利用者を限定せざるを得なかった企業にとって、真の全社展開を可能にする戦略的な一手と言えるだろう。</p>
<h3><strong>最高レベルの「セキュリティ」と「先進性」は両立できる</strong></h3>
<h4><strong>堅牢なセキュリティ基盤</strong></h4>
<p>「Third AI」は一般的なSaaSとは異なり、顧客が契約するMicrosoft Azure環境内に直接インストールされる。これにより、ソリューションは外部サービスではなく「自社のアプリケーション」として扱えるようになる。データが自社の管理する環境の外に出ることがないため、金融情報や未公開技術といった機密性の高い情報も、安心してAIに活用させることが可能になる。すでに大手自動車会社や金融機関など、セキュリティ要件が極めて厳しい136社への導入実績があるといい、その堅牢性と信頼性が認められていることの一つの証拠だ。</p>
<h4><strong>最新技術への迅速な追随</strong></h4>
<p>堅牢なセキュリティを確保しつつも、技術の先進性を犠牲にしないのがJTPの強みだ。「新しいモデルがリリースされた際は、その日のうちに利用可能にするべく動いている」という開発スピードをポリシーとしている。中川氏は「古いモデルをチューニングして性能を上げるよりも、新しいモデルに置き換える方が、性能向上率は断然大きい」と話す。セキュリティや統合の遅れから最新モデルの採用が遅れる企業は、単に後れを取るだけでなく、根本的に非効率な改善曲線の上で戦うことになるのだ。</p>
<h4><strong>全社展開を成功に導くエンタープライズ向け統制機能</strong></h4>
<p>全社員が利用するプラットフォームには、自由度と同時に厳格な管理機能が求められる。「Third AI」は、その両立を実現するエンタープライズグレードの統制機能を備えている。</p>
<ul>
<li><strong>詳細な権限管理</strong></li>
</ul>
<p>管理者は、ユーザー単位、あるいはMicrosoft 365のグループ単位で、利用できるAIモデルを細かく制御できる。例えば、「研究開発部門には高性能な最新モデルを割り当て、一般社員には標準モデルを使わせる」といった戦略的な運用が可能だ。このきめ細やかな管理機能は単なる利便性向上に留まらない。それは、先に述べた企業の中心的ジレンマ、すなわち「コストの壁」を解決するために全社アクセスを提供しつつ、「セキュリティの壁」に対応するために予算とリスクの統制を維持するという課題を解決するメカニズムそのものである。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/JTP_05d3172f80/JTP_05d3172f80.png" alt="管理画面①&#39;.png" /></p>
<ul>
<li><strong>利用状況の可視化</strong></li>
</ul>
<p>部門ごとの利用率やチャット回数などを一覧できるダッシュボード機能も提供される。これにより、「どの部署で活用が進んでいて、どこが遅れているのか」が一目瞭然となる。データに基づいた利用促進活動の計画や、経営層への効果報告が容易になり、全社的なAI活用のPDCAサイクルを回す上で不可欠な機能だ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/JTP_ab3e121fd0/JTP_ab3e121fd0.png" alt="管理画面②.png" /></p>
<p>「Third AI」は単なるAIチャットツールではない。それは、企業のAI活用を組織レベルで成功へと導くための、強力な統制・管理基盤なのである。</p>
<h2>「生成AIツール」から「自律型AIエージェント」へ</h2>
<p>ツールの導入はゴールではなく、スタート地点に過ぎない。JTPは、顧客がAI活用の初期段階から高度な段階へとスムーズに移行できるよう、意図的に設計されたオンボーディング手法を用意している。</p>
<h3>AI活用の4ステップ：計算された成熟への道筋</h3>
<p>中川氏が提示するAI活用のロードマップは、組織全体のAIリテラシーを段階的に引き上げるための、巧みなシナリオとなっている。このシーケンスは、単純な対話から始め、徐々にビジネスの文脈と複雑性を加えていくことで、組織がテクノロジーと共に成熟することを保証する。</p>
<ol>
<li><strong>まずは使ってみる</strong>：生成AIの基本機能に慣れる段階。全社員がAIとの対話に慣れ、その能力を体感する。</li>
<li><strong>社内データを活用する</strong>：RAG技術等で社内ナレッジを参照させ、AIを自社の文脈を理解する専門家へ進化させる。</li>
<li><strong>業務システムと連携する</strong>：API連携により、既存システム内にAI機能を組み込み、日常業務のワークフローの一部とする。</li>
<li><strong>AIエージェント化する</strong>：定型業務を自律的に処理する「AIエージェント」を構築し、AIが能動的に業務を遂行する未来を目指す。中川氏が提示するAI活用のロードマップは、組織全体のAIリテラシーを段階的に引き上げるための、巧みなシナリオとなっている。このシーケンスは、単純な対話から始め、徐々にビジネスの文脈と複雑性を加えていくことで、組織がテクノロジーと共に成熟することを保証する。</li>
</ol>
<p>ステップ3で「業務システムと連携」させることによって、社員の日常的な業務フローの中にAIが自然と溶け込む「ハブ」となる。</p>
<h3><strong>「利用率100%」を実現するハブ構想</strong></h3>
<p>この「ハブ」構想こそ、JTPが「定着化の壁」に対して提示する決定的な答えだ。MAUが6〜7割で頭打ちになる問題は、ユーザーの問題ではなく、インターフェースの問題である可能性が大きい。「Third AI」は、AIを独立した目的地（チャット画面）から、既存のワークフローに埋め込まれたユーティリティへと変革する。これにより、導入の障壁となる摩擦そのものを解消するのだ。
目指すのは、社員が普段使っているツールの中で、ごく自然にAIのサポートを受けられる世界だ。AIがインフラとしてあらゆるシステムに浸透することで、「意識せずにAIを使える」状態を作り出し、社員のAI活用を定着化させようとしている。</p>
<h2>AIエージェント時代の到来を見据えた多層的アプローチ</h2>
<p>AI活用の次なるフロンティアとして期待される「AIエージェント」。しかし、多くの日本企業にとって、その導入は依然として手探りの段階にある。一方でJTPは、すでにAIエージェントの本格導入を見据える企業とともに、検討から実装まで一貫した支援を行っている。単なるツール導入ではなく、AIエージェントを通じて組織が描く未来の業務像やビジネスモデルを、具体的な成果へと繋げることを目指している。</p>
<p>JTPは、まず「どの業務から変えるのか」「どのような価値を生み出すのか」を共に描き出し、全体像を設計するところから伴走する。単一のやり方を押し付けるのではなく、現場の成熟度や業務特性などを踏まえ、「今どこから着手するべきか」「将来どこまで高度化できるか」という道筋を共に描くことを重視している。</p>
<p>さらにThird AIだけにとらわれず、必要に応じてその分野に特化した企業とも協業し、ソリューションの幅と深みを戦略的に拡張している。そうすることで、「AIエージェントが前提の新しい業務像」を机上の構想にとどめず、現場で機能する姿への具現化に繋げていく。</p>
<h2>「Third AI」は、生成AIの全社展開を成功に導くための有力な選択肢</h2>
<p>「Third AI 生成AIソリューション」は、単なる生産性向上ツールではない。それは、生成AIを一部の武器から全社の力へと変え、持続的なビジネス変革を実現するための戦略的プラットフォームなのである。</p>
<p>:::button
<a href="https://ai.jtp.co.jp/products/genai-solution/">「Third AI 生成AIソリューション」に関する詳しい情報やお問い合わせはこちら</a>{target=_blank}
:::</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMエージェントでSNSの「バズ」を再現──投稿人気を高精度に予測する新手法「PopSim」</title>
      <link>https://ledge.ai/articles/llm_agent_sns_popularity_simulation_popsim</link>
      <description><![CDATA[<p>中国科学院情報工程研究所などの研究チームは2025年12月2日、大規模言語モデル（LLM）を用いたマルチエージェント・シミュレーションによって、SNS投稿の人気度を高精度に予測できるとする研究成果を<a href="https://arxiv.org/abs/2512.02533v1">発表</a>した。研究チームは、ソーシャルメディア上の情報拡散を仮想的に再現する新しい人気予測手法「PopSim」を提案し、既存の最先端手法を上回る性能を示したという。</p>
<h2>静的モデルの限界、動的シミュレーションへ</h2>
<p>SNS投稿の人気予測（Social Media Popularity Prediction, SMPP）は、推薦システムや広告、トレンド分析などで重要な役割を果たしてきた。従来手法の多くは、過去データから特徴量を抽出し、静的なモデルで将来の人気度を推定する「帰納的アプローチ」を採用してきた。</p>
<p><strong>■ 従来の静的な人気予測モデル（上）と、LLMエージェントによる動的シミュレーションを用いたPopSim（下）の比較。PopSimは投稿の拡散過程そのものを再現する点が特徴</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_164610177c/x1_164610177c.png" alt="x1.png" /></p>
<p>しかし研究チームは、投稿の拡散や評価はユーザー同士の相互作用によって時間的に変化する動的なプロセスであり、静的モデルではその本質を捉えきれないと指摘する。PopSimはこの課題に対し、LLMを搭載した多数の仮想エージェントがSNS空間で相互作用する「シミュレーション型アプローチ」を採用したという。</p>
<h2>LLMエージェントが作る「仮想SNS」</h2>
<p>PopSimでは、最大1000体規模のLLMベース・エージェントを用いて、SNSユーザーの行動を模倣する。各エージェントは、プロフィール、記憶、行動モジュールを持ち、投稿、リポスト、返信、いいね、沈黙といった行動を選択する。</p>
<p><strong>■ PopSimの全体構成。LLMベースのエージェントがSNS空間をシミュレーションし、その結果を統合して人気度を予測する二段階構成を採用している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_9_1d92aaac22/x2_9_1d92aaac22.png" alt="x2 (9).png" /></p>
<p>特徴的なのは「社会平均場（Social Mean Field）」と呼ばれる仕組みだ。
エージェント全体の状態を、</p>
<ul>
<li>投稿に対する言語的反応を要約する「テキスト平均場」</li>
<li>投稿への評価や関心度を数値化する「数値平均場」</li>
</ul>
<p>という2つのチャネルで表現し、個々のエージェントがそれを参照しながら意思決定を行う。これにより、個人と集団の相互作用を効率的にモデル化し、大規模シミュレーションを可能にした。</p>
<h2>実データで誤差を平均8.82％削減</h2>
<p>研究チームは、ICIPおよびSMPDという2つの実世界SNSデータセットを用いてPopSimを評価した。その結果、平均絶対誤差（MAE）や平均二乗誤差（MSE）、順位相関（SRC）といった主要指標で、既存の特徴量ベース手法や検索拡張型手法を一貫して上回る性能を示した。</p>
<p>特にSMPDデータセットでは、最先端モデルと比べて予測誤差を平均8.82％削減したとしている。単純にLLMに人気度を直接予測させる手法と比べても、大幅な改善が確認された。</p>
<h2>精度だけでなく効率面でも改善</h2>
<p>PopSimは計算効率の面でも成果を示している。すべてのエージェント同士が直接相互作用する従来型シミュレーションと比べ、社会平均場を用いることでシミュレーション全体の実行時間を約83％削減できたという。</p>
<p>また、エージェント数やシミュレーション回数を増やすことで精度が向上する一方、一定規模を超えると改善効果が頭打ちになることも示され、現実的な運用規模についての知見も提示された。</p>
<h2>「予測」から「再現」へ</h2>
<p>研究チームは、PopSimを単なる予測モデルではなく、SNS上での情報拡散や世論形成を理解するための基盤技術と位置づけている。LLMの進化に伴い、より現実に近い社会シミュレーションが可能になることで、SNS分析や社会科学研究への応用が広がる可能性があるとしている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI検索を汚染する「LLM電話番号ポイズニング」──Aurascape、偽コールセンター誘導の新手法を確認</title>
      <link>https://ledge.ai/articles/llm_phone_number_poisoning_aurascape_fake_call_center</link>
      <description><![CDATA[<p>AIチャットボットやAI検索が参照する公開情報を悪用し、利用者を偽のコールセンターへ誘導する新たなサイバー攻撃キャンペーンが確認されたと、サイバーセキュリティ企業が明らかにした。</p>
<p>米国時間2025年12月8日、サイバーセキュリティ企業Aurascapeの研究部門であるAura Labsは、<a href="https://aurascape.ai/llm-search-poisoning-fake-support-numbers/">調査ブログ</a>でこの手法を「LLM Phone-Number Poisoning（LLM電話番号ポイズニング）」と名付け、AI時代特有の詐欺リスクだと警告している。</p>
<p>Aura Labsによると、この攻撃はAIモデルそのものを侵害するものではない。AIが検索や回答生成の際に参照する公開ウェブ情報の層を意図的に汚染し、AIに誤った電話番号を「正規のサポート番号」として出力させる点が特徴だという。</p>
<h2>公開情報を狙う「LLM電話番号ポイズニング」</h2>
<p>LLM電話番号ポイズニングでは、攻撃者が政府機関や大学、企業関連サイトなど、一見すると信頼性が高いドメイン上に、偽のサポート電話番号を含むコンテンツを配置する。これらのページやPDFは、生成AIやAI検索が拾いやすい構造で作られており、いわゆるGEO（Generative Engine Optimization：生成エンジン最適化）やAEO（Answer Engine Optimization：回答エンジン最適化）を意識した設計がなされているという。</p>
<p>その結果、AIチャットボットやAI検索は、こうした偽情報を複数の情報源から統合し、「もっともらしい公式情報」として利用者に提示してしまう。Aura Labsは、この現象を「検索ポイズニングがAIの回答レイヤーにまで拡張された例」だとしている。</p>
<h2>偽の航空会社サポート番号を案内する事例も</h2>
<p>Aura Labsは調査の中で、実際にAI検索や生成AIが航空会社の公式サポート番号として、誤った電話番号を提示する事例を複数確認したとしている。例えば、航空会社名と予約や問い合わせ用の電話番号を検索した場合、AIが公開情報をもとに生成した回答の中に、正規のものと見分けがつきにくい番号が含まれるケースがあったという。</p>
<p>下の画像は、Google検索におけるAI Overviewの表示例だ。航空会社の予約方法として複数の電話番号が提示されており、AIが「公式情報」として整理している様子が分かる。Aura Labsは、このような表示の背後で、公開ウェブ上に混入した偽情報がAIに取り込まれ、結果として偽のサポート番号が案内されるリスクが生じていると指摘している。</p>
<p><strong>Google検索のAI Overviewに表示された航空会社の予約電話番号の例</strong> ：Aura Labsは、公開情報の汚染によって、AIが偽のサポート番号を公式情報として提示する事例を確認していると指摘
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Google_AI_Blog_Image_3_24272c21ee/Google_AI_Blog_Image_3_24272c21ee.png" alt="Google-AI-Blog-Image-3.png" /></p>
<p>こうした挙動は、複数のAI検索・生成AIサービスで確認されており、特定の企業やサービスに限った問題ではないとされる。Aura Labsは、電話番号が一致している点から、組織的なキャンペーンとして実行されている可能性が高いと指摘している。</p>
<h2>ユーザーが直面する詐欺リスク</h2>
<p>偽の電話番号に連絡した利用者は、予約変更や返金手続きを装った詐欺に誘導される恐れがある。具体的には、クレジットカード情報や個人情報の詐取、金銭の送金要求、さらにはリモート操作ツールの導入を求められるといった被害につながる可能性がある。</p>
<p>Aura Labsは、AIが「信頼できる案内役」として認識されつつある現状において、こうした電話番号汚染攻撃の影響は従来の検索スパムよりも深刻になりうると警告している。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、音声分離AI「SAM Audio」公開──テキスト・映像・時間指定で任意の音を切り出し</title>
      <link>https://ledge.ai/articles/meta_sam_audio_release</link>
      <description><![CDATA[<p>米Metaは2025年12月16日、複雑な音声データから特定の音を分離できる音声分離AIモデル「SAM Audio」を<a href="https://about.fb.com/news/2025/12/our-new-sam-audio-model-transforms-audio-editing/">発表</a>した。テキスト、映像、時間スパンという3種類のプロンプトを用いて音を切り出せる点が特徴で、同社は音声分野における初の統合型（unified）音声分離モデルとして位置付けている。</p>
<p>SAM Audioは、Metaが展開してきた「Segment Anything」モデル群の最新例となる。動画や音声に含まれる複数の音が混在した状態から、ユーザーが指定した対象音のみを抽出できるよう設計されており、音声編集や動画制作の工程を大きく変える可能性があるとしている。</p>
<p>Metaは具体例として、バンド演奏を撮影した動画からギターやボーカルだけを分離するケースや、屋外で撮影した映像から交通騒音を除去するケース、ポッドキャスト全体から犬の鳴き声を取り除くといった使い方を挙げている。専門的な音響知識を必要とせず、直感的な操作で音声分離が行える点を強調する。</p>
<p>@<a href="https://www.youtube.com/watch?v=gPj_cQL_wvg">YouTube</a></p>
<h2>3種類のプロンプトで音声分離を実現</h2>
<p>SAM Audioは、以下の3種類のプロンプト方式に対応する。</p>
<ul>
<li><strong>テキストプロンプト：</strong> 「dog barking（犬の鳴き声）」や「singing voice（歌声）」といった自然言語を入力することで、該当する音を抽出できる</li>
<li><strong>ビジュアルプロンプト：</strong> 動画上の人物や物体をクリックすることで、その対象が発している音を分離する</li>
<li><strong>スパン（時間）プロンプト：</strong> 対象音が含まれる時間区間を指定し、同種の音を音声全体から抽出する。Metaはこの方式を「業界初」としている。</li>
</ul>
<p><strong>スパンプロンプト：音声波形上で鳥の鳴き声が含まれる区間を指定すると、その特徴を手がかりに、音声全体から同種の音を検出・分離する。音の名称を言語で指定する必要はなく、「この時間に鳴っている音」を示すだけでよい</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/samaudio_spanprompting_760d424baa/samaudio_spanprompting_760d424baa.jpg" alt="samaudio spanprompting.jpg" /></p>
<p>これらのプロンプトは単独でも、組み合わせても使用可能で、ユーザーは目的に応じて柔軟に音声分離の条件を指定できる。</p>
<h2>断片化していた音声編集を統合モデルでカバー</h2>
<p>これまでの音声分離や音声編集は、用途ごとに特化した単機能ツールが中心だった。MetaはSAM Audioについて、人が自然に音を捉え、指定する感覚に近い形で操作できる点を特徴とし、従来の断片化した音声編集環境を統合的に扱えるモデルだと説明している。</p>
<p><a href="https://ai.meta.com/research/publications/sam-audio-segment-anything-in-audio/">研究論文</a>では、多様な実世界の音環境を想定した評価において高い性能を示したとしており、音声分離における汎用的な基盤モデルを目指す取り組みとして位置付けられている。</p>
<h2>音楽・映像から研究、アクセシビリティまで</h2>
<p>Metaは、SAM Audioの活用分野として、音楽制作、ポッドキャスト、テレビや映画制作、動画編集、科学研究、アクセシビリティ支援などを挙げている。同社はすでにSAM Audioを次世代のクリエイティブメディアツールの開発に活用しているという。</p>
<p>SAM Audioは、Metaの「Segment Anything Playground」で試用できる。ユーザーは用意された音声・動画素材を選択するほか、自身のデータをアップロードしてモデルの挙動を確認できる。あわせて、研究・開発用途向けにモデルのダウンロード提供も開始している。</p>
<p>Metaは、画像分野で広く使われてきた「Segment Anything」の考え方を音声分野に拡張することで、音声編集の在り方を変える可能性があるとし、SAM Audioを「オールラウンドな音声分離モデル」と位置付けている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スマホ単体でLLMをファインチューニング──C++製OSS「MobileFineTuner」、メモリ・電力制約を越える最適化</title>
      <link>https://ledge.ai/articles/mobilefinetuner_llm_finetuning_on_mobile_phones</link>
      <description><![CDATA[<p>スマートフォン上で大規模言語モデル（LLM）のファインチューニングをエンドツーエンドで実行できる統合フレームワークが提案された。</p>
<p>Duke Kunshan University（中国・崑山）およびThe University of Hong Kongの研究チームは、一般的なスマートフォンを対象にLLMを直接ファインチューニング可能にするオープンソースフレームワーク「MobileFineTuner」を開発したと報告した。</p>
<p>研究成果は2025年12月9日に論文「MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones」としてarXivで<a href="https://arxiv.org/abs/2512.08211">公開</a>。コードは、商用可能なApache-2.0ライセンスでGitHub上に公開された。</p>
<p>論文では、GPT-2、Gemma 3、Qwen 2.5といったLLMを対象に、Androidスマートフォン上でのファインチューニングに関する実証結果が示されている（ただし、端末のメモリ条件によって実行できなかった一部のモデルやタスクについては、論文中では“–”として示されている）。</p>
<h2>公開データ枯渇と「スマホ上の私的データ」</h2>
<p>研究チームは、LLM開発を支えてきた高品質な公開データが、2026〜2032年に枯渇する可能性が指摘されている点を背景として挙げる一方で、個人のメッセージ履歴、メモ、アプリ操作ログといった価値の高い私的データの多くはスマートフォン上に存在するが、クラウド送信による学習はプライバシーや規制面で課題が大きいとした。</p>
<p>このギャップを埋める手段として、データを端末外に出さずに学習する「オンデバイス・ファインチューニング」が注目されてきたものの、既存研究の多くはシミュレーション、IoTボード、PC環境に留まり、「一般的なスマートフォン」を実装対象にした枠組みが不足していたと指摘している。</p>
<h2>Python非依存のC++実装という設計判断</h2>
<p>MobileFineTunerの最大の特徴は、フレームワーク全体をC++で実装し、Pythonランタイムに依存しない点にある。
論文では、PyTorchやHugging Face Transformersなどの既存フレームワークがPython前提であり、Androidを含むモバイルOSでは直接利用できないことが、実装上の最大の障壁だったと説明されている。</p>
<p><strong>■ MobileFineTunerの全体構成：</strong> C++ベースのオンモバイル・ファインチューニング基盤の上に、Full-FT/PEFT、評価機構、メモリ・エネルギー最適化が統合されている
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/overview2_f098ba40dd/overview2_f098ba40dd.png" alt="overview2.png" /></p>
<p>MobileFineTunerは、以下の3点を設計原則として掲げる。</p>
<ul>
<li><strong>効率性：</strong> 自動微分やバックプロパゲーションを含む学習処理をC++でネイティブ実装</li>
<li><strong>拡張性：</strong> Full-FT（全パラメータ更新）とPEFT（LoRA）の双方に対応</li>
<li><strong>実用性：</strong> 高水準APIを備え、モバイル上で完結する学習を可能にする</li>
</ul>
<p>これにより、Python仮想環境やVM（例：Termux）に依存せず、モバイルOS上で直接動作する学習基盤として、スマートフォン単体でLLMをファインチューニングできる構成を実現したとしている。</p>
<h2>メモリと電力制約に対応するシステム最適化</h2>
<p>論文では、モバイル端末特有の制約としてRAM容量とバッテリー消費を明確に課題として位置付けている。
一般に、FP16学習では「10億パラメータあたり約16GBのRAM」が必要とされる一方、2025年時点のスマートフォンのRAMは4〜16GBに留まると指摘する。</p>
<p><strong>■ スマートフォンの限られたRAM（4–16GB）に対し、学習時に必要なレイヤのみを「アクティブレイヤ」として保持し、他のパラメータはストレージ側に退避する設計</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/memory_parameters_76e1f8a522/memory_parameters_76e1f8a522.png" alt="memory_parameters.png" /></p>
<p>これに対し、MobileFineTunerは以下の最適化を統合的に実装している。</p>
<ul>
<li><strong>ZeRO着想のパラメータシャーディング：</strong> 学習に必要なパラメータのみをRAMに保持し、非アクティブ部分はストレージへ退避する仕組みを採用</li>
<li><strong>Gradient Accumulation：</strong> マイクロバッチに分割して勾配を蓄積することで、メモリ使用量を抑えつつ学習の安定性を維持</li>
<li><strong>エネルギー認識型スケジューリング：</strong> バッテリー残量を監視し、閾値を下回ると計算頻度を動的に抑制する仕組みを導入</li>
</ul>
<h2>Pixel実機での検証とPyTorchとの比較</h2>
<p>評価では、Google Pixel 8／7 Pro／8 Proといった市販Androidスマートフォンを用い、GPT-2（124M/355M）、Qwen2.5-0.5B、Gemma3（270M/1B）を対象に検証が行われた。</p>
<p>PEFT（LoRA）による検証では、WikiText-2およびMMLUタスクにおいて、PyTorch（サーバー実行）とほぼ同等の損失・PPL・精度が得られたと報告されている。論文は、性能優位性を主張するものではなく、「モバイル上での学習結果が標準的な学習挙動と整合している」点を検証の主眼としている。</p>
<h2>公開形態と今後の焦点</h2>
<p>MobileFineTunerは、論文とともにオープンソースソフトウェアとして公開されており、Android 10以降の端末で動作するとされている。著者らは今後、異種ハードウェア対応や、フェデレーテッド／協調学習との統合を検討するとしている。</p>
<p>研究は、オンデバイスLLM学習を「概念」ではなく実装と実機検証で示した点に特徴があり、スマートフォンを前提としたLLM活用の設計空間を広げるものとして位置付けられる。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、次世代都市構想「光の街」始動──IOWNを都市に実装し、本社を2031年に日比谷へ移転</title>
      <link>https://ledge.ai/articles/ntt_iown_hikari_city_hibiya_hq_move_2031</link>
      <description><![CDATA[<p>NTT株式会社、NTTアーバンソリューションズ株式会社、NTT都市開発株式会社は2025年12月8日、次世代情報通信基盤「IOWN」を都市空間に実装し、街がテクノロジーとともに進化し続ける「光の街 powered by IOWN」構想を開始すると<a href="https://group.ntt/jp/newsrelease/2025/12/08/251208a.html">発表</a>した。本構想の第一弾は、2031年10月末に竣工予定の「NTT日比谷タワー」を中心に展開され、NTT本社も同タワーへの移転を予定している。</p>
<p>1961年に旧日本電信電話公社が本社を構えた日比谷の地に再び拠点を置くことで、NTTグループが蓄積してきた技術力を結集し、新たな価値創出と超・低消費電力化を実現することを目指すとしている。</p>
<h2>社会課題の深刻化とIOWNの役割</h2>
<p>日本では少子高齢化による人手不足、地球温暖化、自然災害の頻発に加え、AI・ロボティクスの普及による電力消費の増大が課題となっている。NTTは、膨大なデータを大容量・低遅延・低消費電力で処理できるIOWNを社会基盤として都市に実装することで、災害予測、インフラ制御、企業業務の効率化など、多領域での課題解決を進めるという。</p>
<h2>新しいビジネス・イノベーション</h2>
<p>IOWNが実装されるNTT日比谷タワーでは、世界中の企業とリアルタイムで協働できる環境を整備する。
通信とデータ処理を統合した基盤を活用することで、臨場感のあるコミュニケーションや高度な遠隔業務が可能になる。</p>
<p>また、NTTは業務支援の高度化に向けて、NTT版LLM「tsuzumi 2」や、大規模AI連携技術「AIコンステレーション」をIOWNと組み合わせることで情報検索や資料作成支援、国際的なコラボレーションなど、企業活動を支える多様なアプリケーションの展開を想定している。
将来的には、会議で生まれたアイデアをモデル化したり、必要な情報を即座に提示するなど、働く環境の高度化を支える技術として発展させる方針だ。</p>
<p>将来的な空間・時間を問わないビジネスシーンイメージ
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251208ab_3cda72f446/251208ab_3cda72f446.jpg" alt="251208ab.jpg" /></p>
<h2>新たなライフスタイル・エンターテインメント</h2>
<p>日比谷タワー低層部に整備される大規模アトリウム「（仮称）Cross Gate」では、壁面・天井一体型の大型LEDビジョンを活用し、世界各地とリアルタイムでつながるイベント空間を形成する。</p>
<p>商業施設との連動イベントや多拠点同時発表会、ライブビューイングなど、多様な活用が可能。将来的には音響XR技術なども組み合わせ、より深い没入体験を提供する。</p>
<p>将来的な（仮称）Cross Gateでのエンターテイメントイメージ（左図：バーチャルアクアリウム、右図：他会場と融合したバスケットボール観戦）
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/251208ac_72eb58dead/251208ac_72eb58dead.jpg" alt="251208ac.jpg" /></p>
<h2>超・低消費電力化によるサステナビリティ</h2>
<p>都市全体の持続可能性に向け、NTTは以下の取り組みを明示している。</p>
<ul>
<li>オフィス部分で「ZEB Ready」を実現（従来比50％以上の省エネ）</li>
<li>光電融合デバイスによる消費電力削減</li>
<li>IOWN×AIの予測制御「Just Enough Energy」で10〜20％のCO₂削減</li>
<li>将来は光量子コンピュータや水素エネルギーの活用も検討</li>
</ul>
<h2>今後の展開</h2>
<p>内幸町一丁目街区は、官民連携や研究機関との共創が可能な次世代スマートシティへと整備が進む。NTT日比谷タワーで得られた知見は、周辺エリア、国内、さらには海外へと段階的に展開される予定だ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、ChatGPT向けアプリ提出を解禁──エコシステム拡張と収益化も視野に</title>
      <link>https://ledge.ai/articles/openai_chatgpt_app_submission_app_directory</link>
      <description><![CDATA[<p>OpenAIは米国時間2025年12月17日、開発者がChatGPT向けアプリを提出できるようになったと<a href="https://openai.com/ja-JP/index/developers-can-now-submit-apps-to-chatgpt/">発表</a>した。提出されたアプリは審査を経て公開され、ChatGPT内に新設される「アプリディレクトリ（App Directory、画面左の『アプリ』メニュー）」を通じて、ユーザーが見つけて利用できるようになる。</p>
<p>ChatGPTはこれまで対話型AIとして進化を重ねてきたが、今回の取り組みにより、会話を起点に外部の機能やアクションを呼び出す「アプリ」を組み込める仕組みが本格的に整備される。</p>
<h2>DevDayで示された構想が具体化</h2>
<p>OpenAIは今年初めに開催した年次開発者イベント「DevDay」で、ChatGPT向けアプリの構想を明らかにしていた。今回、アプリ提出ガイドラインに基づく正式な提出受付が始まり、開発者はChatGPTへのアプリの審査・公開申請を行えるようになった。</p>
<p>ChatGPTアプリは、新たなコンテキストやアクションを会話に取り込むことで、ChatGPTの体験を拡張する。OpenAIは具体例として、食料品の注文、アウトラインからのスライド作成、住まい探しなど、会話から直接アクションにつながる利用シーンを挙げている。</p>
<h2>「アプリ」一覧を通じた発見と利用</h2>
<p>OpenAIはあわせて、ChatGPT内にアプリの一覧画面としてアプリディレクトリを導入する。ユーザーは、ChatGPT画面左の「アプリ」メニューから、注目のアプリを閲覧したり、公開されているアプリを検索したりできる。</p>
<p>アプリディレクトリは、ChatGPTのツールメニューからもアクセス可能で、専用ページ（chatgpt.com/apps）から直接利用することもできる。開発者は、他のプラットフォームからディープリンクを用いて、自身のアプリのディレクトリページへユーザーを直接誘導することも可能だ。</p>
<p>ユーザーがアプリに接続すると、会話中にアプリ名を「@」で指定したり、ツールメニューから選択したりすることでアプリが起動する。OpenAIはさらに、会話の文脈やアプリの利用状況、ユーザーの好みといったシグナルを用いて、関連性の高いアプリを会話内に表示する仕組みの試験も進めているという。</p>
<h2>収益化も視野に入れたアプリ展開</h2>
<p>現在の初期段階では、開発者は ChatGPT アプリから自社の Web サイトやネイティブアプリへ誘導し、物理的な商品の購入や決済を完了できる。</p>
<p>さらに同社は、デジタル商品を含む追加の収益化オプションについても、今後検討を進めていくとしている。開発者やユーザーの利用状況から得られる知見を踏まえながら、ChatGPTアプリを通じてユーザーにリーチし、価値提供と収益化を両立させる方法を広げていく考えだ。</p>
<h2>開発者向け公式リソースも提供</h2>
<p>OpenAIは、アプリ提出受付の開始にあわせて、開発者向けの公式リソースも公開した。現在ベータ版として提供されている「Apps SDK」を利用することで、開発者はコンテキストやアクションをChatGPTに直接取り込み、チャットネイティブな体験を構築できる。</p>
<p>あわせて、優れたChatGPTアプリを設計するためのベストプラクティス、チャット向けインターフェースを想定したオープンソースのUIライブラリ、ステップバイステップ形式のクイックスタートガイドなども提供されている。OpenAIは、DevDay以降に得られた知見をもとに、開発者がユーザーに支持される高品質なアプリを構築できるよう支援するとしている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/17 [WED]OpenAI、新モデル「GPT Image 1.5」搭載の「ChatGPT Images」を公開──GoogleのNano Banana Proに対抗</title>
      <link>https://ledge.ai/articles/openai_chatgpt_images_gpt_image_1_5_release</link>
      <description><![CDATA[<p>OpenAIは2025年12月17日、新しい画像生成モデル「GPT Image 1.5」を搭載した新バージョンの「ChatGPT Images」をリリースしたことを<a href="https://openai.com/index/new-chatgpt-images-is-here/">発表</a>した。新モデルは、ゼロからの画像生成だけでなく、既存画像の編集においてもユーザーの意図をより忠実に反映するよう設計されており、OpenAIはこれを同社の“最も高性能な汎用画像生成モデル”と位置づけている。</p>
<p>公式ブログによると、GPT Image 1.5は「Precise edits that preserve what matters（重要な要素を保ったまま、正確な編集を行う）」ことを重視して開発された。画像の一部を修正する際にも、照明や構図、人物の外見といった重要な視覚的要素を維持しつつ、指示された変更点のみを反映できるという。</p>
<p>@<a href="https://www.youtube.com/watch?v=DPBtd57p5Mg">YouTube</a></p>
<h2>意図に沿った編集を、細部まで</h2>
<p>GPT Image 1.5は、テキスト入力から新たな画像を生成する従来型の使い方に加え、既存の画像をアップロードして編集する用途にも対応する。OpenAIによると、被写体の一部を変更したり、要素を追加・削除したりする際にも、元の画像の文脈や視覚的な整合性を保ったまま編集できるという。</p>
<p>特に、編集時にありがちな意図のずれや不自然な合成を抑え、ユーザーが指示した内容を反映しやすくした点が、今回のアップデートの特徴とされている。</p>
<p><strong>元の素材</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/chatgpt_images_example_1_input_2_side_10deaf7fff/chatgpt_images_example_1_input_2_side_10deaf7fff.jpg" alt="chatgpt-images-example-1-input-2-side.jpg" />
<strong>プロンプト：2人の男性と犬を、子供の誕生日パーティーで退屈そうにしている2000年代のフィルムカメラ風の写真に合成します</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/chatgpt_images_example_1_output_1_9a9c4bee33/chatgpt_images_example_1_output_1_9a9c4bee33.webp" alt="chatgpt-images-example-1-output-1.webp" />
<strong>プロンプト：背景に、物を投げたり叫んだりするカオスな子供たちを追加します。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/chatgpt_images_example_1_output_2_c4825ffe56/chatgpt_images_example_1_output_2_c4825ffe56.webp" alt="chatgpt-images-example-1-output-2.webp" />
<strong>プロンプト：左側の男性を手描きのレトロアニメスタイルに変更し、犬をぬいぐるみスタイルに変更し、右側の男性と背景の風景はそのままにします。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/new_save_8e5602dc1a/new_save_8e5602dc1a.webp" alt="new-save.webp" />
<strong>プロンプト：全員に、こんな感じのOpenAI セーターを着せてみましょう。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Screenshot_2025_12_12_at_10_23_01a_AM_514132aad4/Screenshot_2025_12_12_at_10_23_01a_AM_514132aad4.webp" alt="Screenshot_2025-12-12_at_10.23.01â__AM.webp" />
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/MIX_1_ea42e6aaef/MIX_1_ea42e6aaef.webp" alt="MIX-1.webp" /></p>
<h2>ChatGPT内に「Images」専用の制作空間を追加</h2>
<p>今回のアップデートにあわせて、ChatGPT内には画像生成専用の「Images」体験が導入された。ユーザーはテキストで指示するだけでなく、プリセットのスタイルやトレンドプロンプトを選択することで、簡単に画像生成や編集を試すことができる。</p>
<p>OpenAIは、この専用スペースによって、アイデア探索や試行錯誤をより直感的かつ高速に行えるようになるとしている。画像生成速度は最大で従来比4倍に向上しており、生成中であっても次の画像を作成できるため、待ち時間を減らしながら創作を進められる。</p>
<h2>API提供も開始</h2>
<p>GPT Image 1.5は、ChatGPT内の機能としてだけでなく、APIとしても提供される。これにより、開発者は自社のアプリケーションやサービスに画像生成・編集機能を組み込むことが可能になる。OpenAIは、クリエイティブ用途にとどまらず、業務やプロダクト開発での活用も想定している。</p>
<p>OpenAIは今回のリリースを通じて、テキストと画像を横断するマルチモーダル体験を強化し、ChatGPTを中心とした生成AIの活用領域をさらに広げていく考えだ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>楽天、7000億パラメータの日本語LLM「Rakuten AI 3.0」発表──GENIAC支援で開発、国内最大規模</title>
      <link>https://ledge.ai/articles/rakuten_ai_3_0_japanese_llm_700b_geniac</link>
      <description><![CDATA[<p>楽天グループは2025年12月18日、日本語に特化した大規模言語モデル（LLM）「Rakuten AI 3.0」を<a href="https://corp.rakuten.co.jp/news/press/2025/1218_01.html">発表</a>した。同社によると、同モデルは約7000億パラメータ規模で、日本語LLMとして国内最大規模に位置付けられる。経済産業省および新エネルギー・産業技術総合開発機構（NEDO）が推進する生成AI開発支援プロジェクト<a href="https://ledge.ai/articles/geniac_third_round_rakuten_nri_selected">「GENIAC（Generative AI Accelerator Challenge）」の支援</a>を受けて開発された。</p>
<p>Rakuten AI 3.0は、Mixture of Experts（MoE）アーキテクチャを採用する。総パラメータ数は約7000億に達する一方、推論時には入力内容に応じて一部の専門モデルのみを動作させる仕組みとすることで、計算資源の効率化と運用コストの低減を図ったとしている。</p>
<p>同社によると、Rakuten AI 3.0は日本語の文脈理解や表現の自然さを重視して設計され、楽天が保有するデータや高品質な日本語・バイリンガルデータを用いて学習および調整が行われた。日本語ベンチマークの一つである日本語版MT-Benchでは8.88のスコアを記録したとしている。</p>
<p><strong>■ 日本語特化モデルとのベンチマーク比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rakuten_ai_3_0_82bda693ce/rakuten_ai_3_0_82bda693ce.jpg" alt="rakuten ai 3-0.jpg" /></p>
<p>また、社内検証では、同規模クラスのモデルと比較して最大90％のコスト削減効果が確認されたという。研究用途にとどまらず、実サービスへの適用を前提としたモデルである点を特徴としている。</p>
<p><strong>■ 楽天AIシリーズにおける位置付け</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rakuten_ai_3_0_1_41fbde6837/rakuten_ai_3_0_1_41fbde6837.jpg" alt="rakuten ai 3-0-1.jpg" /></p>
<p>Rakuten AI 3.0は、楽天の生成AI基盤「Rakuten AI Gateway」に統合され、APIを通じて利用可能となる予定だ。さらに、同社が展開する「Rakuten AI」エージェントプラットフォームを介し、楽天エコシステム内の各種サービスへの順次導入を進めるとしている。</p>
<p>開発は、GENIACの枠組みに基づく支援の下で行われた。GENIACは、日本国内における生成AIの基盤技術強化と社会実装を目的に、計算資源の提供や研究開発支援を行う国家プロジェクトである。</p>
<p>楽天グループは、Rakuten AI 3.0について、2026年春を目標にオープンウェイトモデルとして公開する計画も示している。日本語に特化した大規模モデルをオープンに提供することで、国内の生成AI開発や利活用の裾野拡大につなげたい考えだ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>半導体設計にAIエージェント導入へ──ラピダス、設計企業向けツール群「Raads」の提供を発表</title>
      <link>https://ledge.ai/articles/rapidus_ai_agent_semiconductor_design_raads</link>
      <description><![CDATA[<p>ラピダスは2025年12月17日、半導体設計において自律的に作業を行う人工知能（AI）エージェントを中核とする設計支援ツール群「Raads」を、半導体設計企業向けに提供すると<a href="https://www.rapidus.inc/news_topics/news-info/rapidus-unveils-new-ai-design-tools-for-advanced-semiconductor-manufacturing/">発表</a>した。従来の設計支援AIの枠を超え、設計そのものを担うAIエージェントの導入を目指す。</p>
<p>Raadsはこれまで構想してきた「Rapidus AI-Assisted Design Solution」を発展させたもので、今後は「Rapidus AI-Agentic Design Solution」へと進化させていくと同社はいう。設計者を補助するだけでなく、最先端半導体デバイス設計におけるAIエージェントとして機能することを想定。既存のEDAツールと併用することで、設計期間の50％短縮、設計コストの30％削減を可能にするとしている。</p>
<p>Raadsは複数のAIツールで構成され、PDK（Process Design Kit）やリファレンスフローとあわせて顧客に提供される。主なツールとして、設計仕様を入力するとラピダスの2nm製造プロセスに最適化されたRTL（Register Transfer Level）設計データを生成する「Raads Generator」や、RTLデバッグおよび物理設計・配置配線の最適化を行い、PPA（Power、Performance、Area）を短期間で予測する「Raads Predictor」を用意する。</p>
<p>設計者は、デザインアイデアや希望する仕様をRaads GeneratorでRTLソースコードとして出力し、SDC（Synopsys Design Constraints）とともにRaads Predictorに入力することで、ラピダスで製造されるシリコンのPPAを事前に予測できるという。</p>
<p>このほか、設計者のQAやアシスタンスを行う「Raads Navigator」「Raads Indicator」、ML（機械学習）やAIを活用した階層レイアウト設計ツール「Raads Manager」、PPA最適化のためのパラメータ探索を行う「Raads Optimizer」などを、今後順次リリースする計画だ。</p>
<p>ラピダスは、2nmプロセス対応のPDK整備を進めるとともに、製造基盤の構築と設計環境の整備を並行して進めている。Raadsはこうした取り組みと連動し、顧客が最先端半導体の設計を開始できる環境を支えるツール群として位置付けられている。提供開始は2026年度からを予定している。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI時代の就活を見直す──ロート製薬、新卒採用で書類選考を廃止し「対話起点」へ</title>
      <link>https://ledge.ai/articles/rohto_entry_meet_recruiting_ai_era</link>
      <description><![CDATA[<p>ロート製薬は2025年12月15日、2027年4月入社の大学生・大学院生向け新卒採用から、エントリーシートによる書類選考を廃止すると<a href="https://www.rohto.co.jp/news/release/2025/1215_01">発表</a>した。</p>
<p>人事担当者との15分間の対話を採用プロセスの第一ステップとする「Entry Meet（エントリーミート）採用」を新たに導入し、全国8拠点で実施する。</p>
<p>同社は、新卒採用の初期段階において書類選考やAI面接が一般化する中で、学生一人ひとりの個性や価値観を十分に捉えきれないまま選考が進んでしまう点を課題として認識していた。生成AIの普及によりエントリーシートの内容が均質化する傾向が強まっていることも、制度見直しの背景にあるという。</p>
<p>ロート製薬は、応募の手軽さが高まる一方で、企業は効率的な選考を迫られ、学生側も多数の企業に応募せざるを得ない状況に置かれていると指摘する。短期間で多くの選考に臨む構造は、企業理解が不十分なまま選考が進む要因となり、入社後のミスマッチにつながる可能性があるとの考えを示した。</p>
<p>こうした課題意識を踏まえ、同社は求職者と企業が「共に働く未来」を具体的に想像できるかどうかを採用において最も重視するとし、書類やAI面接による一方向の評価に偏らず、直接対話することを採用の入口に据える判断を行った。</p>
<p>「Entry Meet採用」は、就職活動が“合格するための対策”に偏り、受験のようになっている現状への危機感から生まれた取り組みだという。採用担当者は、通過しやすいとされるエントリーシートの型だけでは本質的な個性を捉えきれず、学生一人ひとりの可能性を正しく判断できているのか疑問を感じていたと説明する。採用を「未来を共につくる仲間探し」と位置づけ、限られた時間でも直接会い、対話を通じて価値観を確かめ合うことを重視する姿勢を示した。</p>
<p>制度の概要として、応募開始は2025年12月15日。応募者は採用マイページから必要書類を提出したうえで、Entry Meetの枠を予約する。Entry Meetは人事担当者との15分間の対話形式で、私服での参加を推奨する。開催期間は2026年1月16日から2月8日までで、札幌、仙台、東京、名古屋、金沢、大阪、広島、福岡の全国8拠点で実施する。原則として対面で行うが、海外大学在籍など物理的に参加が難しい場合にはオンライン参加も検討するとしている。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Steamに「100％AI制作」をうたうゲーム登場──コードから音楽まで“全工程AI”と開示</title>
      <link>https://ledge.ai/articles/steam_100_percent_ai_generated_game_codex_mortis</link>
      <description><![CDATA[<p>ゲーム開発における生成AI活用が広がる中、制作工程のすべてをAIで生成したと申告するゲームが、PCゲーム配信プラットフォーム「Steam」に登場した。</p>
<p>対象となるのは、ローグライト系アクションゲーム「CODEX MORTIS」。Steam上で公開されている体験版（Demo）は2025年12月9日付で<a href="https://store.steampowered.com/app/4095390/CODEX_MORTIS_Demo/">配信</a>が始まっており、ストアページの「AI Generated Content Disclosure（AI生成コンテンツの開示）」欄には、コード、アート、サウンド、音楽、テキストのすべてがAI生成であると記載されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=E5Oxs8lPT8s">YouTube</a></p>
<h2>Steam上に現れた“全工程AI”という記載</h2>
<p>「CODEX MORTIS」の体験版および本編のSteamストアページでは、いずれもAI生成コンテンツに関する開示が行われている。
体験版の開示欄には「All code is AI vibe codes, also arts, sounds, music, texts」と記されており、本編ページでも、ゲーム全体がAIによって生成されたことが示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/100_Vibe_Coded_Playable_Game_4fb83b3185/100_Vibe_Coded_Playable_Game_4fb83b3185.jpg" alt="100%VibeCodedPlayableGame.jpg" /></p>
<p>開発元はGROLAF、パブリッシャーはCRUNCHFESTと表示されており、本編の発売時期については、現時点では「未定」とされている。</p>
<p>これらの記載は、第三者による検証結果ではなく、開発側がSteam上で申告した内容である。一方で、コードから音楽に至るまで「全工程AI」と明示している点は、Steam上でも目立つ表現となっている。</p>
<h2>Steamは何を開示させているのか</h2>
<p>Steamを運営するValveは、開発者向け公式ドキュメント「Steamworks」において、ゲーム公開前に提出する「Content Survey（コンテンツ調査）」の中で、生成AIの利用有無や内容を申告する仕組みを設けている。</p>
<p>この調査では、</p>
<ul>
<li>開発段階で生成されたコンテンツ（Pre-Generated AI）</li>
<li>実行中に生成されるコンテンツ（Live-Generated AI）</li>
</ul>
<p>といった区分を含め、生成AIがどの工程でどのように使われているかを説明することが求められる。
その回答内容に基づき、Steamストア上では「AI Generated Content Disclosure」として、AI利用に関する情報が表示される。</p>
<p>「CODEX MORTIS」は、この枠組みの下で、制作工程全体をAI生成とする内容を申告したタイトルの一つとなる。</p>
<h2>“全工程AI”は例外か、兆しか</h2>
<p>ゲーム業界では近年、コンセプトアート制作やコード補助、テキスト生成、テスト工程など、さまざまな場面で生成AIの活用が進んでいる。一方で、コード、ビジュアル、音楽までを含めて“すべてAI生成”と明示するケースは、依然として多くはない。</p>
<p>今回の事例は、作品の完成度や評価とは切り離して、SteamのAI開示制度の下で「全工程AI」という申告が公に確認できる形で示された点に特徴がある。</p>
<p>生成AIをめぐっては、これまでSteamは取り扱いに慎重な姿勢を見せる一方、Epic Games Storeは比較的早い段階から生成AIの活用を前提としたスタンスを示してきた。
そうした中で、Steamが生成AIの利用内容を明示的に開示させる制度を整え、その枠組みの中で「全工程AI」を申告するタイトルが登場したことは、同プラットフォームにおける運用の一つの転換点として捉えることもできる。</p>
<p>今回の事例は、生成AI作品を一律に排除するのではなく、開示と申告を前提に取り扱うという、Steam側の現在地を示すものとも言えそうだ。</p>
]]></description>
      <pubDate>Thu, 11 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>リコー、「Gemma 3 27B」基盤の日本語LLMを開発──gpt-oss-20b同等性能を達成しつつ、PCサーバで動くオンプレ向けモデルとして企業提供を開始</title>
      <link>https://ledge.ai/articles/ricoh_gemma3_27b_japanese_llm_onprem_release</link>
      <description><![CDATA[<p>リコーは2025年12月8日、Google のオープンモデル「Gemma 3 27B」を基盤に、日本語向けに最適化した大規模言語モデル（LLM）を開発したと<a href="https://jp.ricoh.com/release/2025/1208_1">発表</a>した。同モデルは企業のオンプレミス環境での利用を想定しており、PCサーバ上で動作可能な規模に抑えつつ、日本語ベンチマークで OpenAI の「gpt-oss-20b」と同等スコアを記録したという。</p>
<h2>モデルマージと「Chat Vector」で性能を強化</h2>
<p>リコーは今回、独自のモデルマージ技術を活用し、ベースモデルである Gemma 3 27B に対して複数の「Chat Vector」を統合した。Chat Vectorは、約1万5,000件の指示チューニングデータから抽出した“指示追従能力”を表すベクトルで、これを組み合わせることで追加学習を行わずに対話性能を高める仕組みとなっている。</p>
<p>同社によると、非推論モデルでありながら初期応答性（TTFT）が短く、文書作成などの業務利用に適した特性を持つという。</p>
<p>@<a href="https://www.youtube.com/watch?v=mKftRMFEZYg">YouTube</a></p>
<h2>ベンチマークで「gpt-oss-20b」と同等水準</h2>
<p>評価には「Japanese MT-Bench」と「ELYZA-tasks-100」を使用。Google「gemma-3-27b-it」や Alibaba Cloud「Qwen3-32B」、OpenAI「gpt-oss-20b」などと比較し、リコーのモデルは平均スコアで OpenAI の gpt-oss-20bに近い水準を示した。</p>
<p>MT-Benchはコーディング、抽出、数学、推論、ライティングなど8分野の質問応答を、ELYZA-tasks-100は要約・意図汲み取り・複雑計算など100種類のタスクを評価対象とする。スコアはそれぞれ MT-Benchが10点満点、ELYZAが5点満点で、リコーは比較のため2倍換算した平均値で評価した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/LLM_cfe88d4fc3/LLM_cfe88d4fc3.jpg" alt="ベンチマークテストリコーLLM.jpg" /></p>
<h2>PCサーバで動作可能な27Bモデル、オンプレ向けに最適化</h2>
<p>モデル規模は270億パラメータと比較的コンパクトで、GPUリソースを大量に必要とする大規模モデルとは異なり、PCサーバなど既存のオンプレ環境で運用できる点が特徴となる。</p>
<p>リコーは同モデルを「低コストで導入できる日本語プライベートLLM」と位置づけており、データ主権やセキュリティ要件の高い企業での利用を想定している。</p>
<h2>PRIMERGYへプリインストール、Difyとともに提供</h2>
<p>2025年12月下旬から、エフサステクノロジーズの「Private AI Platform on PRIMERGY（Very Smallモデル）」に量子化済みモデルをプリインストールした形で提供を開始する。生成AIアプリをノーコードで構築できる「Dify」も組み込まれ、リコージャパンが環境構築済みの形で企業へ導入支援を行う。</p>
<p>Difyを利用すれば、FAQ対応、ナレッジ検索、文書要約などの業務アプリケーションを、専門知識なしに構築できるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1208_1_60d9384d72/1208_1_60d9384d72.webp" alt="1208_1.webp" /></p>
<p>リコーは2021年から自然言語処理を活用した文書分析サービスを提供し、2022年以降は独自LLM開発を本格化。700億パラメータの大規模モデル、指示追従性を高めたInstructモデル、モデルマージによる高速開発手法など、LLM関連の取り組みを継続してきた。</p>
<p>今回のGemma 3 27Bベースモデルは、その延長線上で「オンプレミスで利用できる高性能日本語LLM」というニーズを反映したものになる。</p>
]]></description>
      <pubDate>Wed, 10 Dec 2025 07:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>