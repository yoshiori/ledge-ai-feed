<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>車限定だった「Geminiナビ」が徒歩・自転車にも拡大──Google マップで利用可能に</title>
      <link>https://ledge.ai/articles/google_maps_gemini_navigation_walking_cycling</link>
      <description><![CDATA[<p>地図アプリ「Google マップ」のナビゲーション中に利用できるAIアシスタント「Gemini」について、これまで自動車の運転時に限定していた対応を拡大し、徒歩および自転車でのナビゲーション中でも利用可能にした。同社が公式ブログで<a href="https://blog.google/products-and-platforms/products/maps/gemini-navigation-biking-walking/">発表</a>した。機能はGemini提供地域において、AndroidおよびiOS向けに順次提供される。</p>
<h2>自動車ナビ限定から、徒歩・自転車へ拡大</h2>
<p>Geminiは、Google マップのナビゲーション中に音声で呼び出し、目的地までの案内を続けながら各種操作や質問に対応するAIアシスタントとして提供されてきた。従来は自動車でのナビゲーション時に限られていたが、今回のアップデートにより、徒歩ナビおよび自転車ナビでも同様の体験が可能となった。</p>
<h2>ナビ中に使える主な機能</h2>
<p>ナビゲーション中、ユーザーは音声による自然言語でGeminiに指示を出すことができる。たとえば、</p>
<ul>
<li>到着予定時刻（ETA）の確認</li>
<li>ルート周辺の飲食店や施設の検索</li>
<li>簡単なメッセージ送信</li>
</ul>
<p>などを、ナビを中断せずに行える。Googleは、移動中に画面操作を最小限に抑える設計である点を強調している。
徒歩・自転車利用での意味合い</p>
<p>徒歩での移動中には、周辺情報を把握しながら目的地まで案内を受けられる点が特徴となる。また自転車での利用では、走行中に画面へ触れることなく音声で操作できるため、ハンズフリーによる利便性の向上が想定されている。</p>
<h2>提供条件と対応環境</h2>
<p>この機能は、Geminiが提供されている地域で利用可能となる。対応端末はAndroidおよびiOSで、最新版のGoogle マップが必要となる。提供は段階的に行われるため、利用可能になる時期はユーザーや地域によって異なる。</p>
<h2>導入の背景</h2>
<p>Googleは、ナビゲーション中の音声アシスタントを従来のGoogle アシスタントからGeminiへと順次移行してきた。今回の対応拡大は、自動車以外の移動手段にもAIナビ体験を広げる取り組みの一環と位置づけられる。</p>
]]></description>
      <pubDate>Mon, 02 Feb 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/1/31 [SAT]AI研究の主要国際会議「NeurIPS 2025」採択論文でハルシネーション多数──GPTZero、「vibe citing（雰囲気引用）」を中心概念として定義し分析を公開</title>
      <link>https://ledge.ai/articles/neurips_2025_hallucinated_citations_gptzero</link>
      <description><![CDATA[<p>AI生成コンテンツの検出を手がけるGPTZeroは2026年1月21日、AI研究の主要国際会議NeurIPS 2025の採択論文を分析した結果、51本の論文にまたがる計100件の「ハルシネーション（幻覚引用）」を確認したと<a href="https://gptzero.me/news/neurips/">発表</a>{target=”_blank”}した。対象は、NeurIPS 2025で採択された論文のうち4,841本で、いずれも既に採択され、会議で発表済みの論文だとしている。</p>
<h2>採択論文4,841本を分析、51本で「確認済み」100件</h2>
<p>GPTZeroによると、今回確認された「幻覚引用」とは、実在しない、または事実と一致しない参考文献が、もっともらしい書誌情報として記載されている状態を指す。具体的には、実在論文に似たタイトルや著者名を組み合わせたもの、存在しないDOIやURL、別論文を指すarXiv IDなどが含まれるという。
同社は、専用ツール「Hallucination Check」でオンライン照合できない引用を抽出したうえで、人手による確認を経て“幻覚”と判断した例のみを集計したとしている。</p>
<h2>「vibe citing（雰囲気引用）」と定義、誤検出の可能性にも言及</h2>
<p>GPTZeroは、生成AIが実在文献を下敷きにしながら、著者名・タイトル・掲載先・年次などを混在させて作る引用を「vibe citing（雰囲気引用）」と呼び、今回の分析の中心概念として定義した。
一方で、同社は「照合不能＝即ハルシネーションではない」とも説明しており、未公開資料やアーカイブ文献などがオンラインで見つからない場合もあるとして、最終判断には人の確認が必要だと注意を促している。</p>
<h2>投稿数急増で査読負荷が拡大、公式統計も</h2>
<p>NeurIPS運営側の公式発表によると、NeurIPS 2025の有効投稿数は21,575本、採択数は5,290本、採択率は24.52％だった。投稿数は近年大きく増加しており、査読体制への負荷が高まっている状況が示されている。</p>
<p>GPTZeroは、今回の結果について、特定の著者や査読者を批判するものではなく、投稿規模の拡大と生成AIの普及が、従来の査読プロセスに新たな課題を突きつけていると説明している。</p>
<h2>LLM利用ポリシーでは、問題があれば措置の可能性も</h2>
<p>NeurIPSは、論文作成における大規模言語モデル（LLM）の利用について<a href="https://neurips.cc/Conferences/2025/LLM">公式ポリシー</a>{target=”_blank”}を設けており、内容の正確性は著者が責任を負うと明記している。科学的整合性に重大な問題が認められた場合、受理後であっても調査や措置の対象となり得るとしている。</p>
<p>GPTZeroは、引用確認を含むチェック工程を、著者・査読者・編集・運営の各段階で支援するツールの活用が有効だとし、今後も学術出版プロセスの透明性向上を目指すとしている。</p>
]]></description>
      <pubDate>Sat, 31 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4oが再び退場へ──OpenAI、ChatGPTで旧モデル整理　2月13日に提供終了、利用の大半はGPT-5.2に移行</title>
      <link>https://ledge.ai/articles/gpt-4o_retirement_chatgpt_feb_13</link>
      <description><![CDATA[<p>OpenAIは2026年1月29日、ChatGPTで提供している「GPT-4o」「GPT-4.1」「GPT-4.1 mini」「OpenAI o4-mini」の4モデルを、2026年2月13日をもって提供終了（retire）すると<a href="https://openai.com/index/retiring-gpt-4o-and-older-models/">発表</a>した。同日には、すでに発表されている「GPT-5（InstantおよびThinking）」のChatGPTでの提供終了も実施される。なお、APIについては現時点で変更はないとしている。ChatGPT上で利用可能な旧世代モデルを整理し、より新しいモデルにリソースを集中させる狙いだ。</p>
<h2>2月13日にChatGPTから4モデルを除外</h2>
<p>提供終了の対象となるのは、以下の4モデルだ。</p>
<ul>
<li>GPT-4o</li>
<li>GPT-4.1</li>
<li>GPT-4.1 mini</li>
<li>OpenAI o4-mini</li>
</ul>
<p>これらのモデルは2月13日以降、ChatGPTのモデル選択肢から削除され、同サービス上では利用できなくなる。一方で同社は、APIについては「現時点では変更はない」と明記している。</p>
<h2>GPT-4oは一度引退後に復活、再び退場へ</h2>
<p>OpenAIは今回の告知の中で、GPT-4oについて特別に背景を説明している。</p>
<p>GPT-4oは、過去に一度ChatGPTから非推奨（deprecated）となった後、GPT-5のリリース時にアクセスが復活した経緯がある。復活の背景には、PlusおよびProユーザーの一部から寄せられたフィードバックがあった。具体的には、創造的なアイデア出しなどの用途で移行に時間が必要だったことや、GPT-4oの「会話のスタイルや温かみ」を評価する声があったとしている。</p>
<p><strong>「GPT-5切替で “4oロス” 広がる──ChatGPT界隈を席巻した「#keep4oムーブ」と期間限定 “里帰りモード”」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Chat_GPT_Image_2025_8_12_18_58_22_d73354f1a7/Chat_GPT_Image_2025_8_12_18_58_22_d73354f1a7.jpg" alt="ChatGPT Image 2025年8月12日 18_58_22.jpg" /></p>
<h2>利用の大半はGPT-5.2に移行、GPT-4o選択は0.1％</h2>
<p>OpenAIは、今回あらためてGPT-4oを提供終了とする理由について、「必要な改善がすでに整った」ことと、「利用状況の変化」を挙げた。</p>
<p>同社によると、現在のChatGPT利用の大半はすでにGPT-5.2に移行しており、日常的にGPT-4oを選択しているユーザーは全体の0.1％にとどまっているという。この状況を踏まえ、GPT-4oの役割は事実上、新世代モデルに引き継がれたと判断した。</p>
<h2>GPT-5.1／5.2で人格や創造性を強化</h2>
<p>OpenAIは、GPT-4oに寄せられたフィードバックが、GPT-5.1およびGPT-5.2の改良に直接反映されたと説明している。</p>
<p>新世代モデルでは、人格や創造性の改善に加え、ChatGPTの応答スタイルを調整できる仕組みを拡充。ベースとなるスタイルやトーンの選択に加え、温かみや熱量といった要素をユーザーが調整できるようになっている。</p>
<h2>過剰な拒否や説教的応答の是正にも言及</h2>
<p>OpenAIは今後の方向性として、ChatGPTの人格や創造性のさらなる改善に加え、「不要な拒否」や「過度に慎重、あるいは説教的な応答」への対処を進めていく方針も示した。これらについては、近くアップデートを予定しているという。</p>
<p>また、18歳以上の成人ユーザー向けに、適切な安全策の範囲内で選択肢と自由度を拡張したChatGPT体験を目指す考えも示している。この取り組みの一環として、OpenAIは18歳未満と推定される利用者を対象に、年齢に応じた体験を提供するための年齢推定（age prediction）を、多くの市場で展開していることにも触れた。</p>
<h2>「苦渋の判断」としつつ改善に集中</h2>
<p>OpenAIは、GPT-4oの提供終了について「一部のユーザーにとっては不満や不便を感じる決定であることは理解している」としつつ、「モデルの引退は決して容易ではないが、より良いモデルの改善に集中するために必要な判断だ」と説明している。</p>
]]></description>
      <pubDate>Fri, 30 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、月額1,200円のAI有料プラン「Google AI Plus」日本展開　Geminiなどの利用枠を拡張</title>
      <link>https://ledge.ai/articles/google_ai_plus_launch_japan_1200yen</link>
      <description><![CDATA[<p>Googleは2026年1月28日、AI機能の利用上限を拡大できる有料サブスクリプションプラン「Google AI Plus」を日本で提供開始したことを<a href="https://blog.google/intl/ja-jp/company-news/technology/google-ai-plus/">発表</a>した。月額料金は1,200円。Geminiをはじめとする同社の生成AI機能を、無料プランよりも広い枠で利用できる。</p>
<p>Google AI Plusは、Google Oneを通じて提供される個人向けAIプランの一つで、生成AIを日常的に活用するユーザーを主な対象とする。新規登録者向けには、最初の2カ月間を月額600円とする半額キャンペーンも用意されている。</p>
<p>同プランでは、Geminiアプリで高性能モデルである「Gemini 3 Pro」や「Nano Banana Pro」を利用できるほか、AIを活用した映像制作ツール「Flow」、リサーチや執筆を支援する「NotebookLM」など、複数のAI機能が含まれる。GmailやGoogleドキュメント、スプレッドシートといったGoogleの各種サービスに統合されたGemini機能についても、利用枠が拡張される。</p>
<p>また、Google AI Plusには200GBのクラウドストレージが付帯し、Google Drive、Gmail、Google Photosで共通利用が可能だ。ストレージやAI特典は、最大5人までの家族メンバーと共有できる。既存のGoogle One プレミアム（2TB）ユーザーについては、数日以内にGoogle AI Plus相当のAI特典が利用可能になるとしている。</p>
<p><strong>GoogleのAIサブスクリプション3プランの比較。AI Plusは月額1,200円で提供される入門プラン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae.jpg" alt="JP_aiplus_comparison.width-1000.format-webp.jpg" /></p>
<p>一方で、Googleは同プランについて、Google Workspaceのビジネスおよび教育機関向けアカウントでは利用できないとしている。</p>
<p>Googleは、個人向けに段階的なAIサブスクリプションを用意しており、Google AI Plusはその中でも入門・中核的な位置づけとなる。今後は、より高い利用上限や機能を備えた上位プランと併せて、生成AIの利用拡大を図る。</p>
]]></description>
      <pubDate>Wed, 28 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「AIは5層のケーキ」NVIDIAのフアンCEO、ダボス会議で語ったエネルギーからアプリまでのAI構造</title>
      <link>https://ledge.ai/articles/ai_five_layer_cake_jensen_huang_davos_wef</link>
      <description><![CDATA[<p>NVIDIAのCEOであるジェンスン・フアン氏は、スイス・ダボスで開催された世界経済フォーラム（WEF）年次総会のメインステージに登壇し、AIを<a href="https://blogs.nvidia.com/blog/davos-wef-blackrock-ceo-larry-fink-jensen-huang/">「5層のケーキ」にたとえて説明</a>した。AIを単一の技術としてではなく、エネルギーからアプリケーションに至るまで、複数の層が積み重なって初めて成立する産業基盤として捉える考え方を示した。</p>
<p>この発言は、世界経済フォーラム年次総会（通称ダボス会議）の公式セッション「Conversation with Jensen Huang, President and CEO of NVIDIA」で2026年1月21日（現地時間）に行われたもので、対談相手は米資産運用大手ブラックロックのCEO、ラリー・フィンク氏だった。</p>
<h2>ダボス会議メインステージで示された「5層」の構造</h2>
<p>フアン氏は対談の中で、「AIは5層のケーキのようなものだ」と述べ、次のような層構造を示した。</p>
<ul>
<li><strong>第1層 エネルギー：</strong> AIを動かす前提となる電力供給の層。大規模なAI計算には膨大な電力が必要であり、電力インフラそのものがAI時代の基盤になるとした。</li>
<li><strong>第2層 チップとコンピューティング・インフラ：</strong> GPUなどの半導体や計算基盤の層。AIの性能やスケールを左右する中核で、計算能力の拡張が上位層を支える。</li>
<li><strong>第3層 クラウドおよびデータセンター：</strong> 計算資源を実際に運用・提供するためのシステム全体の層。フアン氏は、ここまで含めて初めてAIの「工場」が成立すると説明した。</li>
<li><strong>第4層 AIモデル：</strong> 大規模言語モデル（LLM）などの基盤モデルが該当する層。下位層の計算資源と密接に結びつきながら進化するとした。</li>
<li><strong>第5層 アプリケーション：</strong> 企業や個人が実際に利用するサービスや業務システムの層。医療、製造、金融など、産業ごとの具体的な活用はこの層で実現される。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e.jpg" alt="Gemini_Generated_Image_mf83p4mf83p4mf83.jpg" /></p>
<h2>「どれか一つ欠けても成立しない」</h2>
<p>フアン氏は、これら5つの層は独立して存在するものではなく、どれか一つが欠けてもAIは社会的・産業的な価値を生み出せないと強調した。特に、モデルやアプリケーションへの注目が集まりがちな一方で、エネルギーや計算インフラといった下位層への投資が不可欠であるとの認識を示した。</p>
<p>WEFも<a href="https://www.weforum.org/stories/2026/01/nvidia-ceo-jensen-huang-on-the-future-of-ai/">公式ストーリー記事</a>で、フアン氏の発言を「AIが次の大規模インフラ構築になる」という文脈で紹介しており、AIを電力網や通信網と同様の基盤産業として捉える視点が、ダボス会議という国際経済・政策の場で共有された形となった。</p>
<p>@<a href="https://www.youtube.com/watch?v=hoDYYCyxMuE&amp;t=160s">YouTube</a></p>
]]></description>
      <pubDate>Mon, 26 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、Acrobatに生成AIを活用した3つの新機能「プレゼン生成」「ポッドキャスト生成」「自然言語PDF編集」──Acrobat Studioで提供開始（英語版）</title>
      <link>https://ledge.ai/articles/adobe_acrobat_studio_ai_presentation_podcast_pdf_edit</link>
      <description><![CDATA[<p>Adobeは2026年1月21日（米国時間）、PDFとコンテンツ制作を統合する「Adobe Acrobat Studio」において、生成AIを活用した3つの新機能の提供を<a href="https://blog.adobe.com/jp/publish/2026/01/26/dc-work-smarter-acrobat-turn-docs-presentations-podcasts-edit-pdfs-ai">開始</a>した。新たに追加されたのは、「プレゼンテーションを生成」「ポッドキャストを生成」「自然言語によるPDF編集」の各機能で、文書を起点にした情報活用とアウトプット作成を効率化する。これらの機能は、現時点では英語版で利用可能としている。</p>
<h2>文書からスライドを自動作成する「プレゼンテーション生成」</h2>
<p>新機能の「プレゼンテーションを生成」は、PDFや関連資料をもとに、AIが内容を整理し、プレゼンテーション用のアウトラインを自動作成するものだ。ユーザーは生成前にアウトラインを確認し、長さやトーンを調整したうえでスライド化できる。</p>
<p>入力データには、Acrobat内の「PDF スペース」に追加した文書ファイルやリンクを利用でき、財務報告書、製品仕様書、競合分析資料、Webページなど複数の情報源をまとめて扱える。生成されたスライドは、Adobe Expressと連携し、テンプレートやデザインライブラリを活用しながら、画像の差し替えや動画の追加、フォント変更などの編集が可能だ。これにより、デザインの専門知識がなくても、短時間で体裁の整ったプレゼン資料を作成できるとしている。</p>
<h2>長文資料を音声で要約する「ポッドキャスト生成」</h2>
<p>「ポッドキャストを生成」は、文書内容をAIが要約し、音声コンテンツとして出力する機能だ。PDF スペースに追加したメモ、文字起こし、数百ページ規模のレポートなどを対象に、AIアシスタントへ要約を依頼すると、ポッドキャスト形式の音声が生成される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c.jpg" alt="media_18964bee91bcdcb676c009037bc19e7eba3f8275d.jpg" /></p>
<p>会議資料の事前把握や移動中の情報収集、学習用コンテンツの音声化などを想定しており、読む時間が確保しづらい場面でも、文書の要点を把握できる手段として位置づけられている。</p>
<h2>チャットで操作できる「自然言語によるPDF編集」</h2>
<p>3つ目の新機能である「自然言語によるPDF編集」では、チャット形式のAIインターフェースを通じて、PDFの編集操作を行える。ユーザーは自然言語で指示を入力するだけで、ページやテキスト、コメント、画像の削除、電子署名の追加、パスワード設定などの基本的な編集作業を実行できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02.jpg" alt="media_106fc491d70ca3f2de8116afcbc18a917ceafb64b.jpg" /></p>
<p>あわせてヘルプ機能も強化されており、操作方法の案内やトラブルシューティングをチャット形式で受けられるようになった。従来のメニュー操作に不慣れなユーザーでも、直感的にPDF編集が可能になるとしている。</p>
<h2>「PDF スペース」を軸にした共同作業を強化</h2>
<p>これらの新機能は、Acrobat Studioに統合された共有ワークスペース「PDF スペース」を中心に提供される。PDF スペースでは、ファイルの整理やインサイト抽出に加え、招待したメンバーが資料を追加したり、メモやコメントを残したりできる。生成AI機能と組み合わせることで、個人作業だけでなく、チームでの資料準備やレビューの効率化を狙う。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが高次元幾何学の難問に挑む──中国研究チーム、接吻数問題で複数次元の記録更新</title>
      <link>https://ledge.ai/articles/ai_kissing_number_problem_game_theoretic_rl</link>
      <description><![CDATA[<p>中国の北京大学や上海科学智能研究院などの研究グループが2026年1月26日、AIを用いて、高次元幾何学の難問として知られる「接吻数問題」に取り組み、複数の次元で既存の下界を更新する成果を報告した。研究成果は論文「<a href="https://arxiv.org/abs/2511.13391">Finding Kissing Numbers with Game-theoretic Reinforcement Learning</a>」として発表された。</p>
<p>接吻数問題は、同じ大きさの球が1つの球の周囲に互いに重ならないよう最大でいくつ接触できるかを問う問題で、1694年にアイザック・ニュートンらが議論して以来、長年にわたり研究が続けられてきた。次元が高くなるにつれて幾何構造が複雑化し、解析や探索が極めて困難になることが知られている。</p>
<h2>球の配置を「行列」として扱うAI手法</h2>
<p>研究チームは、接吻数問題をGram行列（内積行列）の補完問題として定式化し、ゲーム理論と強化学習を組み合わせたAIシステム「PackingStar」を開発した。従来のように高次元空間上の座標を直接最適化するのではなく、球同士の内積関係のみを行列として扱うことで、数値的不安定性を抑えつつ大規模な並列探索を可能にしたとしている。</p>
<p>PackingStarでは、2つのAIエージェントが協調的に動作する。一方のエージェントが行列を拡張して配置候補を追加し、もう一方が全体構造を考慮して不適切な要素を削除・修正する。この「追加」と「修正」を繰り返すことで、より大きな配置、すなわちより高い接吻数に対応する構造を探索する仕組みだ。</p>
<p><strong>【図：PackingStarの3段階（シミュレーション→行列初期化→2プレイヤー行列補完ゲーム）を示した模式図】</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_1_12e03bdc99/x2_1_12e03bdc99.png" alt="x2 (1).png" /></p>
<h2>25〜31次元で既存の下界を更新</h2>
<p>論文によると、PackingStarは25次元から31次元までのすべての次元で、これまでに知られていた最良の下界を上回る接吻配置を発見した。特に25次元では、得られた配置が高次元格子として知られるLeech格子の部分構造と対応する明確な幾何パターンを示しており、最適構造である可能性を示唆しているという。ただし、厳密な数学的証明は現時点では示されていない。</p>
<p>研究チームは、2011年や2016年に提案されていた構成テンプレートを超える配置が得られたとし、高次元における探索能力の拡張を成果として位置づけている。</p>
<p><strong>【図：次元ごとの接吻数と、本研究による更新点を示したグラフ】</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_76eb8d2f20/x1_76eb8d2f20.png" alt="x1.png" /></p>
<h2>13次元で「合理構造」を刷新</h2>
<p>また13次元では、1971年以来更新されていなかった「合理構造」と呼ばれる構成を刷新し、接吻数1146の配置を発見した。合理構造とは、球同士の内積がすべて有理数で表される配置を指す。現在知られている13次元での最高記録は非合理構造による1154だが、合理構造は厳密な解析が可能である点から、理論的価値が高いとされる。</p>
<p>論文では、今回の成果が高次元幾何学や球面符号、情報理論分野での研究に資する可能性にも言及している。</p>
<h2>一般化接吻数でも新記録</h2>
<p>さらに、球同士の角度制約を変更した「一般化接吻数」においても成果を報告した。12次元（内積制約1/4）、14次元および17次元（内積制約1/3）で既存記録を更新し、数千件規模の新たな配置を発見したとしている。</p>
<h2>AIによる数学探索の新たな事例に</h2>
<p>研究チームは、PackingStarが既存の構造を単に最適化するのではなく、新しい幾何構造を体系的に発見できる点を特徴として挙げている。一方で、得られた配置が真に最適であることを示す証明は今後の課題とした。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>技術の思春期に入ったAI──Anthropic CEOダリオ・アモデイ氏、国家安全保障・経済・民主主義へのリスクに警鐘</title>
      <link>https://ledge.ai/articles/ai_technology_adolescence_amodei_democracy_risk</link>
      <description><![CDATA[<p>AI開発企業AnthropicのCEOである ダリオ・アモデイ 氏は2026年1月27日、強力なAIが社会にもたらすリスクについて論じた長文エッセイ「The Adolescence of Technology（技術の思春期）」を<a href="https://www.darioamodei.com/essay/the-adolescence-of-technology">公開</a>した。同氏は、AIが急速に能力を高める一方で、制度や社会の成熟が追いついていない「危険な過渡期」にあると指摘し、国家安全保障、経済、民主主義の3領域で深刻な影響が生じうると警告している。</p>
<h2>「技術の思春期」とは──能力が先行する危うい段階</h2>
<p>アモデイ氏は現在のAIを、人間の成長過程になぞらえて「技術の思春期（Adolescence）」にあると表現する。この段階では、技術的な能力が急速に拡大する一方で、それを安全かつ安定的に運用するためのガバナンスや社会制度が十分に整っていない。</p>
<p>強い影響力を持ち始めながらも、判断力や自制が成熟していない――同氏は、こうした「能力の増大」と「未成熟さ」が同居する状態こそが、現在のAIを最も不安定で危険な存在にしていると論じている。</p>
<h2>国家安全保障：AIが不安定化させる軍事・サイバー空間</h2>
<p>国家安全保障の領域では、AIの高度化が軍事、諜報、サイバー分野に新たな不安定要因をもたらす可能性があると指摘した。
サイバー攻撃や情報操作の高度化により、従来の抑止や防御の枠組みが機能しにくくなる恐れがあるという。</p>
<p>また、国家間の技術競争が激化する中で、安全対策や慎重な検証が後回しにされる構造的リスクにも言及しており、AIは一度広く普及すると制御が難しくなる点を強調している。</p>
<h2>経済：生産性向上の裏で進む急激な再編</h2>
<p>経済面では、AIが生産性を大きく押し上げる可能性を認めつつ、その恩恵が均等に分配されないリスクを挙げた。雇用構造の急変や、特定の企業や国家への権力集中が進めば、社会的な不安定化につながりかねないとしている。</p>
<p>技術進歩のスピードに制度的・社会的な調整が追いつかない場合、短期間で大きな歪みが生じる可能性があるとし、経済的影響を過小評価すべきではないとの認識を示した。</p>
<h2>民主主義：情報環境の脆弱化と「共通の現実」の喪失</h2>
<p>民主主義への影響について、アモデイ氏は特に強い懸念を示している。AIによる情報生成・拡散能力の向上は、世論操作や偽情報の高度化を招き、民主主義が前提としてきた「共通の現実」や情報の信頼性を損なう恐れがあるという。</p>
<p>同氏は、こうした情報環境の変化が、有権者の判断基盤そのものを弱体化させる可能性がある点を、深刻なリスクとして位置づけている。</p>
<h2>米ミネソタ州での出来事が浮き彫りにした「国内の民主主義」</h2>
<p>アモデイ氏は、このエッセイが主にAIと将来を論じたものであるとしつつも、公開時点で米ミネソタ州をめぐって起きている出来事に触れ、民主主義的価値と権利を国内で守る重要性が一層切実になっていると述べている。</p>
<p>同州では連邦当局の強制執行をめぐる死亡事件などをきっかけに、権利や法の在り方を巡る議論と抗議が広がっており、アモデイ氏はこうした現実の緊張が、エッセイで論じた「民主主義の脆弱性」を現実の問題として浮き彫りにしていると示唆した。</p>
<p>なお、ミネソタ州での出来事をめぐっては、Reutersが、OpenAIの サム・アルトマン CEOが従業員向けの内部メッセージで、移民当局ICEの対応を「行き過ぎ」と批判したと報じている。</p>
<h2>前作「Machines of Loving Grace」との関係</h2>
<p>アモデイ氏は今回のエッセイを、約1年前に発表した「<a href="https://www.darioamodei.com/essay/machines-of-loving-grace">Machines of Loving Grace</a>」（強力なAIを正しく活用できた場合に何が実現できるかを論じたエッセイ）の“対”に位置づけている。</p>
<p>前作では、AIがもたらしうる可能性や理想像に焦点が当てられていたのに対し、今回のエッセイでは、その裏側にあるリスクや、社会が備えるべき課題が正面から論じられている。</p>
<h2>「止める」か「進める」かではなく、どう向き合うか</h2>
<p>アモデイ氏は、AI開発を止めるべきだと主張しているわけではない。一方で、無条件に加速させる姿勢にも警鐘を鳴らしている。必要なのは、ガバナンス、制度設計、国際的な協調を含め、社会全体でAIと向き合う枠組みを整えることだとし、「技術の思春期」にある今の判断が、将来の安定性を大きく左右すると結論づけている。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AmazonがOpenAI出資を検討、最大500億ドル（約7.6兆円）規模と報道　今ラウンドでの資金調達は1000億ドル超も</title>
      <link>https://ledge.ai/articles/amazon_openai_investment_50b_funding_100b_reported</link>
      <description><![CDATA[<p>AmazonがOpenAIに対し、最大500億ドル（約7兆6000億円）規模の出資を検討していると、<a href="https://www.reuters.com/business/retail-consumer/amazon-talks-invest-up-50-billion-openai-wsj-reports-2026-01-29/">Reuters</a>や<a href="https://www.cnbc.com/2026/01/29/amazon-openai-investment-jassy-altman.html">CNBC</a>など複数の米メディアが2026年1月29日に報じた。協議は進行中で、最終的な出資額や条件は流動的だとしている。</p>
<h2>最大500億ドル規模、交渉はなお初期段階</h2>
<p>関係者の話として伝えられているところによると、AmazonはOpenAIに数百億ドル規模の投資を協議しており、その金額は最大500億ドルに達する可能性がある。ただし、協議はまだ初期段階にあり、最終的な条件や金額は確定していないとされる。Amazonはコメントを控え、OpenAIも現時点で公式な見解を示していない。</p>
<h2>条件書は数週間以内に署名の可能性も</h2>
<p>報道では、関係者によると条件書（term sheet）が数週間以内に署名される可能性があるとも伝えられている。今回の資金調達は、Amazonのほか、MicrosoftやNVIDIAといった戦略投資家を先行させ、その後に他の投資家が参加する2段階構成となる可能性があるという。</p>
<h2>OpenAI、最大1000億ドル調達・評価額8300億ドルの可能性</h2>
<p>OpenAIは今回のラウンドで、最大1000億ドルの資金調達を目指しているとされ、評価額は約8300億ドルに達する可能性がある。報道では、SoftBankや中東の政府系ファンドなども投資家候補として名前が挙がっている。</p>
<p>交渉には、AmazonのCEOであるAndy Jassy氏と、OpenAIのCEOのSam Altman氏が直接関与しているとされる。米紙<a href="https://www.wsj.com/tech/ai/amazon-in-talks-to-invest-up-to-50-billion-in-openai-43191ba0">The Wall Street Journal</a>は、この協議について先行して報じていた。</p>
<p>Amazonは、OpenAIの競合であるAnthropicにもこれまでに巨額投資を行ってきた。今回の動きについては、大手テック企業が複数のAI企業に同時に投資する構図が鮮明になりつつあるとの見方も出ている。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、Claudeで外部業務ツール連携を拡充　SlackやAsana、Figmaなどを会話内で操作可能に</title>
      <link>https://ledge.ai/articles/anthropic_claude_interactive_tools_slack_asana_figma</link>
      <description><![CDATA[<p>米AI企業の Anthropic は2026年1月26日、同社のAIサービス Claude において、外部業務ツールを会話内でインタラクティブに利用できる機能を拡充したと<a href="https://claude.com/blog/interactive-tools-in-claude">発表</a>した。今回のアップデートにより、Slack、Asana、Figma、Canva、Box などのツールを、Claudeのチャット画面内で直接操作できるようになる。</p>
<h2>会話の流れでツールを操作、画面切り替え不要に</h2>
<p>対応したツールでは、単なる情報参照にとどまらず、各サービスの操作をClaudeの会話の流れの中で行える。</p>
<p>例えばSlackではメッセージの下書きや送信、Asanaではタスクやプロジェクトの更新、FigmaやCanvaではデザインや資料の作成・確認といった作業を、別タブに移動することなく進められるという。</p>
<p>これにより、複数の業務ツールを行き来しながら作業する従来のワークフローを簡略化し、AIとの対話を起点に業務を進める形を想定している。</p>
<p>@<a href="https://www.youtube.com/watch?v=bluAmTHoEow">YouTube</a></p>
<h2>Model Context Protocol（MCP Apps）を活用</h2>
<p>こうしたインタラクティブな連携は、Anthropicが推進するオープン標準プロトコル「Model Context Protocol（MCP）」の拡張仕様である「MCP Apps」によって実現されている。
MCP Appsは、外部ツール側が提供するインターフェースをAIクライアント上で扱えるようにする仕組みで、Claudeはこの仕様に対応することで、外部サービスの操作画面を会話の文脈に沿って表示・利用できるようになった。</p>
<p>Anthropicは、MCPを通じてClaudeと業務ツールの接続性を高め、開発者や企業が独自のツールを統合できる環境整備も進めている。</p>
<h2>対象プランと今後の展開</h2>
<p>今回のインタラクティブツール連携は、Claudeの有料プラン（Pro、Team、Enterpriseなど）を中心に提供される。対応ツールは今後も拡大予定としており、Claudeを業務のハブとして活用するユースケースを広げていく方針だ。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国AIテック、オープンソース推論モデルを相次ぎ公開──Alibabaが「Qwen3-Max-Thinking」、Moonshot AIは「Kimi K2.5」発表</title>
      <link>https://ledge.ai/articles/china_ai_open_source_reasoning_models_qwen3_max_thinking_kimi_k2_5</link>
      <description><![CDATA[<p>中国のAIテック企業が、推論能力を前面に打ち出したオープンソース大規模言語モデル（LLM）を相次いで公開している。</p>
<p>Alibabaは2026年1月26日、同社の「Qwen」シリーズにフラッグシップ推論モデル「<a href="https://qwen.ai/blog?id=qwen3-max-thinking">Qwen3-Max-Thinking</a>」を追加した。続く27日には、中国のAIスタートアップであるMoonshot AIが、生成AIサービス「Kimi」の新モデルとして「<a href="https://www.kimi.com/blog/kimi-k2-5.html">Kimi K2.5</a>」を発表した。</p>
<h2>Alibaba、推論特化のオープンソースLLM「Qwen3-Max-Thinking」を公開</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Qwen3_Max_Thinking_a4f4c3f239/Qwen3_Max_Thinking_a4f4c3f239.jpg" alt="Qwen3-Max-Thinking.jpg" /></p>
<p>Alibaba傘下のQwen開発チームは2026年1月26日、同社が開発する大規模言語モデル「Qwen」シリーズの新モデルとして、「Qwen3-Max-Thinking」を<a href="https://qwen.ai/blog?id=qwen3-max-thinking">発表</a>した。公開した。</p>
<p>同モデルは、モデル規模の拡大と大規模な強化学習を組み合わせることで、知識量、複雑な推論能力、指示追従性、人間の嗜好との整合性、エージェント機能など複数の側面で性能を高めたとしている。</p>
<p>Qwenチームによると、19の既存ベンチマークにおいて、GPT-5.2-ThinkingやClaude Opus 4.5、Gemini 3 Proと同等水準の性能を示したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/score_c57592148d/score_c57592148d.jpg" alt="score.jpg" />
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/qwen3_max_bench_a596df956e/qwen3_max_bench_a596df956e.jpg" alt="qwen3 max bench.jpg" /></p>
<p>また、必要に応じて検索やコード実行を自律的に呼び出す適応的なツール利用機能を備え、Qwen Chat上で利用可能としている。推論時に追加計算を割り当てるテスト時スケーリング手法も導入し、複数の推論系ベンチマークで性能向上を確認したとしている。</p>
<p>Qwen3-Max-Thinkingは、Qwen ChatおよびAPIを通じて提供されており、オープンソースモデルとして公開されている。</p>
<h2>Moonshot AI、オープンソース推論モデル「Kimi K2.5」発表</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Kimiai_704db61aa9/Kimiai_704db61aa9.jpg" alt="Kimiai.jpg" /></p>
<p>Moonshot AIは2026年1月27日、同社が提供する生成AIサービス「Kimi」の新たな基盤モデルとして、「Kimi K2.5」を<a href="https://www.kimi.com/blog/kimi-k2-5.html">発表</a>した。</p>
<p>同社はKimi K2.5を、視覚理解と推論、エージェント機能を統合した「オープンソースのVisual Agentic Intelligence」と位置づけている。</p>
<p>同社の公式Xアカウントによると、Kimi K2.5はエージェント関連ベンチマークにおいて、HLE（full set）で50.2%、BrowseCompで74.9%のスコアを記録したという。また、視覚理解やコード生成に関する評価では、MMMU Proで78.5%、VideoMMMUで86.6%、SWE-bench Verifiedで76.8%を示し、オープンソースモデルとして最高水準の性能だとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f.jpg" alt="G_pUaPlaoAAa9as.jpg" /></p>
<p>Kimi K2.5の特徴として、最大100のサブエージェントを自律的に生成・統括する「Agent Swarm」機能を挙げている。複数のエージェントが並列に最大1,500回のツール呼び出しを行うことで、単一エージェント構成と比べて処理速度が最大4.5倍向上するとしている。Agent Swarmは現在ベータ版として提供されている。</p>
<p>Kimi K2.5は、KimiのWeb版およびアプリで利用可能で、チャットモードとエージェントモードをサポートする。APIも提供されており、同社は本番環境でのソフトウェア開発用途として、開発者向けツール「Kimi Code」との併用を推奨している。モデルの重みとコードはHugging Face上で公開されている。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本発ヒューマノイド「cinnamon 1」初公開　ドーナッツロボティクス、無言で操作できる特許技術も発表</title>
      <link>https://ledge.ai/articles/donut_robotics_cinnamon1_humanoid_silent_gesture</link>
      <description><![CDATA[<p>ヒューマノイド開発に取り組むスタートアップ、ドーナッツロボティクスは2026年1月21日、日本ブランドのヒューマノイド『cinnamon 1（シナモン ワン）』を<a href="https://prtimes.jp/main/html/rd/p/000000041.000057944.html">発表</a>した。二足歩行が可能な量産型ヒューマノイドとして、同社は2026年内の市場投入を目指す。</p>
<h2>二足歩行の量産ヒューマノイド、年内投入を目標に</h2>
<p>「cinnamon 1」は、同社が保有する特許技術を搭載した二足歩行のヒューマノイドロボットだ。現時点では海外企業から提供された機体をベースに、独自開発のAIを搭載している。将来的には、機体も含めた国産ヒューマノイドの実現を目指すとしている。</p>
<p>AIには、視覚情報・言語理解・行動を統合する「Vision-Language-Action（VLA）」の概念を取り入れる予定で、人の指示を理解し、自律的に行動するロボットの開発を進める。</p>
<h2>声を出さずに指示できる「サイレント ジェスチャー コントロール」</h2>
<p>同社はあわせて、手振りや指の動きだけでロボットに指示を伝える特許技術「サイレント ジェスチャー コントロール」を発表した。音声を使わずに操作できる点が特徴で、同社はこの技術を搭載したヒューマノイドとして「世界初」としている。</p>
<p>騒音の大きい工場や建設現場、声を出しにくい家庭環境などでの利用を想定しており、難聴者が多い環境でも使いやすい技術として位置づけている。</p>
<h2>工場・建設現場での作業代替を想定</h2>
<p>ドーナッツロボティクスは、2026年内に工場内や建設現場での作業代替を進める計画を示している。2025年10月には、建築関連事業を手がける株式会社エムビーエスと資本業務提携を発表しており、建設業界での活用を見据える。</p>
<p>また、VLA開発を支える国内データセンターの設立構想にも言及しており、ヒューマノイド開発を軸にしたAI基盤づくりを進める方針だ。</p>
<p>YouTube動画を引用する場合　　　
@<a href="https://www.youtube.com/watch?v=1vBI0GYjAKM">YouTube</a></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI活用の“壁”を突破する鍵はエッジにあり──デル・テクノロジーズが描く「分散型エージェントとハイブリッドAI」の未来</title>
      <link>https://ledge.ai/articles/edgetechplus20251121</link>
      <description><![CDATA[<p>生成AIはすでに私たちの生活に浸透しつつある一方で、ビジネスの現場では「スキル不足」「セキュリティ」「データのサイロ化」などが障壁となり、本格活用に踏み切れない企業も少なくない。</p>
<p>11月21日にパシフィコ横浜で開催された展示会「EdgeTech+」では、AI Elite(AIエリート)としてアジア太平洋地域のAI戦略を担う増月氏が登壇し、ビジネスにおけるAI活用の突破口は「クラウド」から「エッジ」への発想転換にあると語った。</p>
<p>本記事では、識別型AIと生成AIを組み合わせたハイブリッドコンピューティングモデルや分散型エージェント、さらに「Dell AI Factory with NVIDIA」、および、「Dell NativeEdge」によるエッジAI戦略について、同氏の講演内容をもとにひもといていく。</p>
<p>::: box
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_b53adeff8b/2_b53adeff8b.jpg" alt="2.jpg" />
デル・テクノロジーズ株式会社
インフラストラクチャー・ソリューションズSE統括本部
AIプラットフォーム・ソリューションズ
シニア システム エンジニア | AI Elite
CTO Ambassador
増月 孝信 氏</p>
<p>国内大手電機メーカの研究所にてAI研究職を経て、外資ITベンダーにてOS、ミドルウエア、データセンタなど幅広い分野で技術職, 技術マーケティングおよび製品企画を経験。過去に Java, OpenSolaris, OpenStack などOSSコミュニティーの幹事として貢献。2011年デル株式会社(現デル・テクノロジーズ株式会社)へ入社。
現在はAIソリューションのビジネス開発を担当。2023年にCTO Ambassadorを拝命。
:::</p>
<h2>AI活用は進みつつあるがビジネスでは課題も多い</h2>
<p>増月氏はデル・テクノロジーズでAI Eliteとして活躍する人物だ。AI Eliteはその名の通りデル・テクノロジーズのAIスペシャリストから選出認定された役職で、全世界でも20名弱しかいない。AI Eliteは同社のAIに関するビジネスに深く関わっており、増月氏もアジア・パシフィック地域におけるAI戦略を担当しているという。</p>
<p>そんなデル・テクノロジーズが近年注力するのが「エッジAI」である。これはクラウドではなく、PCのような端末で動作するAIのこと。クラウド型のAIとは対極的な特徴を持っており、今後需要がさらに高まることが予想されている。</p>
<p>本講演の主題ともいえるエッジAIについて語る前に、増月氏はまずAI活用の現状について説明を行った。</p>
<p>調査によると、現在「何らかの形で生活の中で生成AIを使用している」人は80％に達しており、さらに「仕事に使ったことがある」人も63％に上っている。すでにAIは人々の生活に溶け込んでいると言えるのだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_4bee902b23/3_4bee902b23.png" alt="3.png" /></p>
<p>一方で、ビジネスの現場でのAI活用については課題も見えてきたと増月氏は話す。</p>
<p>「一番の課題はAIのスキルです。調査によると組織の41％が従業員の専門知識やスキルがAIの導入に課題であると回答しています」</p>
<p>そしてもう一つの大きな課題がAIにおけるセキュリティの問題だ。アンケートでは組織の73％が「データのプライバシーとセキュリティが生成AIを使用する際に懸念されるリスク」と回答している。</p>
<p>「外部からのサイバー攻撃もAIによって高度化しており、社内にAIを導入するしないとは関係ないところでのAIリスクも考えられます」</p>
<p>さらに増月氏は「データそのものがAI活用の課題になっている」とも指摘する。</p>
<p>「皆さん、AIのモデルや分析プラットフォームなどは非常に考えているのですが、そもそもデータが整っていないと成果はまったく上がりません。データにもっと投資して、うまく使える状態にしなければならないのです」</p>
<h2>レイテンシーやセキュリティ面でエッジAIの重要度は高い</h2>
<p>データに関する課題としてよく語られるのがサイロ化の問題だ。コーポレートシステムにおけるデータウェアハウスやトランザクションデータ、事業や部門に蓄積された製品や顧客のデータ、さらに支社や関連会社に存在する様々なビジネスデータ――こうしたデータが分断されていてはAIによる成果も期待できない。</p>
<p>またサイロ化という点で何よりも「置いてきぼりになっている」のが、まさに「エッジ」のデータだと増月氏は述べる。</p>
<p>「実際のデータが生成される場所というのは、クラウドやデータセンターの中ではなく、エッジなのです。たとえば皆さんが持っている携帯電話、あるいは製造や医療などの現場で発生するデータの方が、クラウドやデータセンターのデータよりも重要度が高い場合もあります」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4_10389fe9ec/4_10389fe9ec.jpg" alt="4.jpg" /></p>
<p>だからこそ、デル・テクノロジーズは今「エッジAI」に着目しているというわけだ。</p>
<p>エッジAIには他にも様々なメリットがある。</p>
<p>たとえばローカル処理を行うことによるレイテンシーの短縮だ。仮に製造現場で生成された画像データを処理するのにいちいちクラウドやデータセンターに送信していては遅延が発生し、意思決定に遅れにつながる恐れがある。また何らかの問題でネットワークが機能しなくなると、処理自体が行えなくなってしまう。</p>
<p>またセキュリティについてもメリットは大きい。エッジAIなら重要な機密情報をクラウドに送信することなく端末内で処理できるわけだから、情報漏洩にもつながりにくいのだ。</p>
<p>こうしたメリットの大きさからエッジAI活用も少しずつ進みつつあるが、現状はまだ多くの企業がクラウド型の生成AI活用に目が向いている状態だ。</p>
<p>調査によると「エッジにAIを完全、または部分的に実装した」と回答しているのはITの意思決定者の29％に留まっている。増月氏はこの現状に対し、「これからもっとエッジAIにフォーカスしていく必要がある」と述べた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/5_cb622891a1/5_cb622891a1.png" alt="5.png" /></p>
<h2>エッジAIの課題を分散型エージェントが解決する</h2>
<p>製造現場などではすでにエッジAIが導入されており、業務で活用が進んでいる。ただし、それはあくまでも「画像データを分析して製品の不良を見つける」といった「識別型AI」であり、昨今トレンドとなっている生成AIではない。というのも生成AIを動作させるには膨大なリソースが必要であり、現状のエッジの性能では難しいからだ。これが、LLMを用いた多くのサービスがクラウド型で提供されている大きな理由でもある。</p>
<p>また各AIを組み合わせるなど、何らかの処理を自動で行うことも識別型AIでは難しい。AI同士を連携して業務を進めるには、現状ではまだ人間が介在する必要がある。</p>
<p>こうした課題を解決しうるのが「エージェント」の存在だ。</p>
<p>「単一ではなく分散型でエージェントを運用することで、従来の識別型AIの処理を自動化するなどのユースケースを生み出せるのではないかと考えています」</p>
<p>ただしエージェントが勝手に意思決定し、アクションをとるところまで自動化するのはリスクも伴う。そこで増月氏が提案するのが「ヒューマン・イン・ザ・ループ」だ。これはエージェントによるワークフローの中に人間が介入し、条件付きでワークフローを自動化する考え方。最初は人による関与を多くしてエージェントを監視するが、次第にエージェントが学習し、人間の介在を少なくするというアプローチである。</p>
<p>この他にも、従来型のエッジAIとエージェント型AIには様々な違いがある。</p>
<p>たとえば管理・オーケストレーションについては、従来型エッジAIが中央集約型のコントロールプレーンで一元管理するのに対し、エージェント型AIは分散・自律型で、各ノードやエージェントがそれぞれ状態管理・意思決定を実施する。</p>
<p>ユーザーインターフェースについては、従来型エッジAIはダッシュボードやコマンドラインが中心で、複雑な操作や習熟が必要となる。ダッシュボードの多重化による負担も増えがちだ。一方、エージェント型AIは自然言語インターフェースでユーザーが対話的に指示・確認できるため、直感的かつ低学習コストで操作が可能だ。当然、ダッシュボードの負担も軽減できる。</p>
<p>「エージェント型AIにより、今までの専門知識を持った人しか扱えなかった世界から、もう少しフレキシビリティの高い環境を作ることができるのではないかと考えています」</p>
<p>複数のエージェントがネットワーク全体で動作しユーザーの意図を理解して、特定のタスクを効果的に実行する。そんな「分散型エージェント」のワークフローはどのように構築できるのか。増月氏は次のように一例を示した。</p>
<p>「まず人が命令するのは自然言語です。コマンドを叩きたり、ダッシュボードで操作したりするのではなく、自然言語で命令を入力します。するとAPIを介在してエージェントが検出され、ワークフローマネージャーで実際のステップを構築していきます。メモリーストアはエージェント間のステートを共有する仕組みで、これにより精度の高い結果を生むことができます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/6_9ee6548d1d/6_9ee6548d1d.png" alt="6.png" /></p>
<h2>「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルとは</h2>
<p>続いて増月氏が解説するのが「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルだ。</p>
<p>識別型AIは前述したようにデータをもとに分類や予測を行うAIのこと。たとえばスマートフォンの顔認証もその一つ。あらかじめ「自分の顔の特徴」というデータを学習させることで、カメラに映っている人物が持ち主であると“識別”させているわけだ。この識別型AIは生成AIがブームになる前から世の中のあらゆる場所で活用されている。</p>
<p>同じAIであっても、この識別型AIと生成AIの違いを理解することは重要だ。。昨今は生成AIのインパクトがことさら強調されがちだが、何かのエラー判定を行うような場合など、分野によっては識別型AIの方がはるかに高い精度を出せる場面も多い。また比較的少ないリソースで動作するのも識別型AIのメリットだ。</p>
<p>一方で生成AIはコンテキストの認識や汎用化において識別型AIを寄せ付けないほどの強みを持っている。両者の特徴は異なり、うまく両方のメリットを組み合わせることが今後は重要になってくるのだ。</p>
<p>「低レイテンシーやリアルタイム性が要求されるケースでは、できるだけワークロードをデータが生成されるエッジに持ってくる必要があります。ただ難しい処理になるとエッジよりもある程度コンピューティングリソースのある環境が必要になるため、クラウド活用が重要になってきます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_68105acef1/7_68105acef1.jpg" alt="7.jpg" /></p>
<p>では具体的にどのようなアーキテクチャを構築すべきなのか。増月氏が一例として示すのが、ハイブリッド分散型AI推論システムだ。</p>
<p>製造ラインの例では、エッジサイドで識別型AIが製品の合否判定を行い、不良品が検出された場合は比較的小さなリソースで稼働する生成AI VLM（ビジュアル言語モデル）を使って異常を分析する。一方で、複雑な処理はデータセンター側のLLMと連携し、分散型のLFMを使ってネットワークトラフィックを削減するわけだ。</p>
<p>このアーキテクチャにより、デジタルツインでのシミュレーションも可能になるほか、ロボットや自動運転、スマートシティなどのフィジカルAIの実現にもつながると増月氏は語った。</p>
<h2>「Dell AI Factory with NVIDIA」と「Dell NativeEdge」――デル・テクノロジーズが進めるAI戦略</h2>
<p>こうした発想に基づき、デル・テクノロジーズが進めるAI戦略が「Dell AI Factory」である。</p>
<p>柱となるのは「AI in/AI on/AI for/AI with」という4つの考え方だ。PCやストレージといった製品の中にAI機能を組み込み（AI in）、ハードウェアやコンピュート環境の上でAIを実装する（AI on）。さらにデル・テクノロジーズ一社ではなく、グローバルでパートナー企業と協力し（AI with）、デル社内でのAI活用で培ったノウハウを提供していく（AI for）とのことだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/8_10f5e922bc/8_10f5e922bc.png" alt="8.png" /></p>
<p>デル・テクノロジーズの強みについて増月氏は、ユースケース定義、データパイプライン設計、エッジからスーパーコンピュータまで網羅する幅広いインフラ提供、シリコンベンダーやソフトウェアベンダーとの多様なパートナーリング、サービスデリバリーまでエンド・トゥ・エンドで提供できる点にあると述べた。</p>
<p>Dell AI Factoryにおいてチャレンジとなるのが、エッジのワークロードをどのようにオーケストレートするのかという点だ。そのための仕組みが「Dell NativeEdge Platform」である。</p>
<p>「識別型AIや生成AIなどのワークロードを展開するのに、わざわざITの管理者が現場に行くことなくオーケストレートする仕組みです。現場に行かなくてもリモートで運用ができる“ゼロタッチ”により、AIだけでなくいろいろな環境とインテグレートすることができます」</p>
<p>デル・テクノロジーズのAI Factoryは、特にNVIDIAと強いリレーションを持っている。GPUやソフトウェアスタック、ネットワーキングなどをすべてインテグレートする仕組みがあり、エッジサイドではGB10を搭載した超小型スーパーコンピュータSparkも提供可能とのことだ。</p>
<p>講演ではHugging Face上のLLMポータルからモデルを選択し、ブループリントを生成、NativeEdgeを通じてエッジデバイスに展開するデモも行われた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9_535c14c78e/9_535c14c78e.jpg" alt="9.jpg" /></p>
<p>デル・テクノロジーズが考えるハイブリッドモデルは、NativeEdgeとDell AI Factoryを連携させ、一元管理する仕組みだ。これはクラウドベンダーではできないことであり、同時にエッジのみにフォーカスしているベンダーにも難しい取り組みである。まさにデル・テクノロジーズだからこそ可能な提案と言える。</p>
<p>増月氏は最後にエージェント間のコミュニケーションの重要性について触れ、パートナーリングのエコシステムをさらに加速させる必要があると呼びかけて講演を締めくくった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/10_f010c9bc0b/10_f010c9bc0b.png" alt="10.png" /></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Genspark、日本市場に本格参入──音声操作と自律ワークフローを備えた「AI Workspace 2.0」発表</title>
      <link>https://ledge.ai/articles/genspark_ai_workspace_2_japan_launch</link>
      <description><![CDATA[<p>米AIスタートアップの Genspark は2026年1月28日、日本市場での法人展開を本格化すると<a href="https://prtimes.jp/main/html/rd/p/000000002.000176655.html">発表</a>した。あわせて、音声入力アプリ「Speakly」やAI受信トレイのワークフローなどを含む「AI Workspace 2.0」を公開した。</p>
<h2>日本市場を重要拠点に位置づけ</h2>
<p>Gensparkは、日本市場を米国やアジアの主要市場と並ぶ重要拠点の一つと位置づけ、業務利用を前提としたAIワークスペースの提供を本格化する。日本語環境での業務利用を想定し、法人向けの導入を進める方針だ。</p>
<h2>業務全体を担う「AI Workspace 2.0」</h2>
<p>「Genspark AI Workspace 2.0」は、情報収集、情報処理、成果物作成までを単一の環境で担う業務特化型AIワークスペースとして設計されている。ユーザーの指示をもとに、AIがタスクを分解し、複数の工程を自律的に実行する点が特徴だ。</p>
<p><strong>Genspark AI Workspace 2.0は、情報収集・処理・成果物作成までを単一環境で担う業務向けAIワークスペースとして設計されている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub2_86e094679d/sub2_86e094679d.png" alt="sub2.png" /></p>
<h2>音声入力とカスタムワークフローを新搭載</h2>
<p>新バージョンでは、音声入力による操作に対応した。キーボード操作を介さず、話しかけるだけで指示を出せるため、業務のスピード向上が期待される。
また、ユーザー自身が業務内容に応じたカスタムワークフローを構築できる機能も追加された。定型業務や複数ステップにまたがる処理をAIに任せることで、業務の自動化を進められる。</p>
<h2>メール処理を自動化する「AI受信トレイ」</h2>
<p>AI Workspace 2.0には、メール処理を自動化する「AI受信トレイ」も搭載されている。受信箱のトリアージや転送、優先順位付けなどを自律的に処理する仕組みとしている。</p>
<h2>複数AIモデルを統合、モデル選択は不要</h2>
<p>Gensparkは、ChatGPTやGemini、Claudeなど複数の大規模言語モデルを内部で活用している。ユーザーは個別のモデルを意識する必要はなく、タスク内容に応じて最適なモデルが裏側で使い分けられる仕組みだ。
同社は、ChatGPTやGemini、Claudeなどを含む70以上のAIモデルを統合し、指示をタスクに分解したうえで最適なモデルを選定すると説明している。</p>
<p><strong>Gensparkは、複数のAIモデル、ツール、データを組み合わせる独自のエージェントエンジンによって業務実行を行う</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_c8285ce386/sub1_c8285ce386.png" alt="sub1.png" /></p>
<p>こうしたGenspark AI Workspace 2.0の動作イメージについて、同社は以下の公式デモ動画で紹介している。</p>
<p>@<a href="https://www.youtube.com/watch?v=KtOZNvFhV8c">YouTube</a></p>
<h2>日本企業での導入も進展</h2>
<p>Gensparkは、日本国内において広告、IT、製造、金融など複数業界の企業で導入が進んでいると説明する。今後は、日本市場向けの機能拡張や導入支援を通じて、業務現場でのAI活用をさらに広げていく考えだ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub3_2ec073c221/sub3_2ec073c221.png" alt="sub3.png" /></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>100万文字DNAを一度に解析──Google DeepMind、11種のゲノム過程を統合予測するAI「AlphaGenome」</title>
      <link>https://ledge.ai/articles/google_deepmind_alphagenome_nature_1mb_genome_prediction</link>
      <description><![CDATA[<p>Google DeepMindの研究チームは、最大100万塩基（約100万文字）に及ぶDNA配列を一度に解析し、遺伝子発現やスプライシングなど11種類の主要なゲノムプロセスを高精度で予測できるAIモデル「AlphaGenome」を開発した。研究成果は<a href="https://www.nature.com/articles/s41586-025-10014-0">Nature</a>に2026年1月28日付で掲載され、研究コミュニティ向けにソースコードとモデルの重みも公開されている。</p>
<p>Nature掲載とともに「DNA配列の理解と遺伝的変化の分子レベルでの影響予測を支援するモデル」として紹介している。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/deepmind_x_67d9e3d161/deepmind_x_67d9e3d161.jpg" alt="deepmind x.jpg" /></p>
<h2>最大100万塩基を「文脈」として扱い、11のプロセスを同時予測</h2>
<p>従来のゲノム解析AIにおける入力配列長は、数万〜数十万塩基程度が限界とされていた。AlphaGenomeはこの制約を大幅に拡張し、最大100万塩基（1M bp）という長大なDNA配列を単一の入力として処理することを可能にした。</p>
<p>特筆すべきは、単一のモデルアーキテクチャでありながら、多岐にわたる予測タスクをこなす点だ。遺伝子発現（RNA-seq、CAGE、PRO-cap等）やスプライシングに加え、クロマチンアクセシビリティ、ヒストン修飾、転写因子結合、さらには3次元的なクロマチン接触パターンに至るまで、計11種類の主要なゲノムプロセスを同時に、かつ高精度で予測できるよう設計されている。</p>
<h2>既存SOTAと同等以上、長距離相互作用の解析で強み</h2>
<p>Nature論文によれば、AlphaGenomeは遺伝子発現量やスプライシング予測といった主要タスクにおいて、既存の最先端（SOTA）モデルと同等、あるいは一部でそれらを上回る性能を示した。</p>
<p>とりわけ優位性が示されたのは、DNA配列上で遠く離れた領域同士が影響し合う「長距離調節」の解析だ。最大100万塩基という広い受容野（コンテキスト）を前提とすることで、従来の短い入力長では捉えきれなかったエンハンサーとプロモーター間の相互作用など、遠隔制御に関わる情報を扱える設計となっている。</p>
<h2>「非コード領域」の変異影響を多角的に評価</h2>
<p>ヒトゲノムの大部分を占めながら、その機能解釈が難しいとされてきた「非コード領域（non-coding region）」。AlphaGenomeは、この領域に生じた単一塩基変異が、細胞内の分子プロセスにどのような影響を及ぼすかを、多面的に予測・スコアリングできる。</p>
<p>具体的には、ある変異が遺伝子発現、スプライシング、クロマチン状態といった複数の層に同時に与える変化を評価可能だ。論文では、臨床的に関連する既知の変異を対象に、複数の分子過程をまたいだ予測が既存の実験知見と整合する例も示されている。</p>
<h2>1次元の配列から3次元クロマチン接触パターンを予測</h2>
<p>AlphaGenomeの特徴の一つとして、1次元のDNA配列情報のみから、Hi-C実験などで観測される「3次元クロマチン接触パターン（コンタクトマップ）」を予測できる点が挙げられる。</p>
<p>遺伝子の発現調節は、DNAが核内でどのように折り畳まれているかという立体構造と密接に関係している。配列情報から空間的な接触傾向を推定できるこの機能は、ゲノム制御機構の理解に資する可能性がある。</p>
<h2>Nature掲載に合わせ、コードと重みを研究者向けに公開</h2>
<p>Google DeepMindは本研究成果の発表と同時に、GitHubを通じてAlphaGenomeのソースコードおよび学習済みモデルの重みを公開した。利用は非商用の研究用途に限定されている。</p>
<p>これにより、世界中の研究者が再現実験や手法検証を行えるほか、独自データを用いた解析や予測パイプラインの拡張が可能となる。研究チームは、論文掲載とオープンな公開を通じて、ゲノム研究コミュニティでの幅広い活用を促している。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“プロンプトで歩ける世界”が現実に──Google、世界生成AIの実験プロトタイプ「Project Genie」米国提供　Google DeepMindの世界モデル「Genie 3」を搭載</title>
      <link>https://ledge.ai/articles/google_project_genie_interactive_virtual_world_us_release</link>
      <description><![CDATA[<p>Googleは2026年1月29日（現地時間）、テキストや画像から対話型の仮想世界を生成・探索できる実験的なプロトタイプ「Project Genie」を<a href="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/">公開</a>した。まずは米国の「Google AI Ultra」ユーザーを対象に提供する。</p>
<h2>テキストや画像から対話型の仮想世界を生成</h2>
<p>Project Genieは、ユーザーが自然言語の指示や画像を入力すると、AIが仮想空間を生成し、その中を移動・操作しながら探索できる点が特徴だ。生成された世界は静的な3Dモデルではなく、視点移動や操作に応じて周囲の環境がリアルタイムに構築される。</p>
<p>同プロトタイプでは、体験は三つの中核機能で構成されている。テキストや生成・アップロードした画像を用いて環境を作成する「World sketching」、生成された世界の中を歩行や飛行、乗り物での移動などを通じて体験する「World exploration」、既存の世界を基に新たな解釈を加える「World remixing」だ。
作成前には世界の見た目をプレビューし、視点を一人称・三人称から選択することもできる。</p>
<p>@<a href="https://youtu.be/YxkGdX4WIBE">YouTube</a></p>
<h2>世界モデル「Genie 3」を中核に据えた構成</h2>
<p>技術面では、Google DeepMindが開発した世界モデル「Genie 3」を中核に据える。ユーザーの行動に応じて進行方向の環境を生成する仕組みを採用し、物理挙動や相互作用を含む動的な世界をシミュレーションする。プロトタイプはGenie 3に加え、画像生成モデル「Nano Banana Pro」や対話型AI「Gemini」を組み合わせたWebアプリとして提供されている。</p>
<h2>米国のGoogle AI Ultraユーザー向けに限定提供</h2>
<p>Project GenieはGoogle Labsにおける実験的研究プロトタイプとして提供される。現時点では米国在住の18歳以上で、「Google AI Ultra」に加入しているユーザーに限定されている。生成した世界や探索の様子は動画としてダウンロードすることも可能だ。</p>
<p>Googleは、現段階では生成結果が必ずしも現実世界の物理や入力内容に完全に一致しない場合があるほか、操作時の遅延や生成時間が最大60秒に制限されている点など、いくつかの制約があるとしている。一部のGenie 3の機能も本プロトタイプには含まれていない。今後はユーザーからのフィードバックを基に改良を進め、提供地域を段階的に拡大していく方針だ。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、ピクサー出身監督と制作した短編アニメをサンダンス映画祭でプレビュー上映へ──AIを制作工程に組み込む新たな表現手法を提示</title>
      <link>https://ledge.ai/articles/google_sundance_ai_animation_workflow</link>
      <description><![CDATA[<p>Googleは2026年1月26日（現地時間）、同社が制作した短編アニメ映画を、米国で開催されるサンダンス映画祭のプログラム「Sundance Institute Story Forum」でプレビュー上映すると<a href="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/dear-upstairs-neighbors">発表</a>した。作品は、Google DeepMindの研究チームと、ピクサー出身の監督が協働して制作したもので、AIをアニメーション制作工程に組み込む新たな表現手法を示す事例として紹介される。</p>
<p>なお、Sundance Film Festivalは、インディペンデント映画を中心に、新しい表現手法や制作アプローチを積極的に紹介してきた国際的な映画祭として知られている。上映作品だけでなく、物語の作り方や制作プロセスを議論する場も設けられており、映画表現の変化をいち早く取り上げる場として注目されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=eCk5VFKKz08">YouTube</a></p>
<h2>ピクサー出身監督とGoogle DeepMindが共同制作</h2>
<p>今回プレビュー上映される短編アニメは、ピクサー出身の監督 Connie He 氏と、Google DeepMindの研究者・エンジニアが共同で制作した。同作は、研究成果のデモンストレーションではなく、完成した短編アニメ作品として制作された点が特徴だ。Googleは、AI研究の成果を実際のクリエイティブ制作に適用する試みとして位置づけている。</p>
<h2>AIを“主役”にしない制作ワークフロー</h2>
<p>制作では、Google DeepMindが開発する画像生成モデル「Imagen」や動画生成モデル「Veo」などが用いられた。ただし、テキストプロンプトのみを入力して映像を生成する一般的な生成AIの使い方は採られていない。</p>
<p><strong>Imagenをファインチューニングして生成された主人公「Ada」のビジュアル例。単一のプロンプト生成ではなく、制作者の素材や意図を反映させながら表現の幅を広げたとしている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/WM_Ada_T2_I_1080p_max_1080x1080_format_webp_abc27ecd3f/WM_Ada_T2_I_1080p_max_1080x1080_format_webp_abc27ecd3f.webp" alt="WM_AdaT2I_1080p.max-1080x1080.format-webp.webp" /></p>
<p>Googleによると、制作工程ではまずアーティストが手描きのスケッチや絵コンテ、ラフアニメーションを作成し、それらのビジュアル素材をもとにAIモデルを調整・活用する手法が取られたという。Veoは既存のアニメーションや映像素材を入力として受け取り、動きや質感を保ったまま表現を拡張する用途で使われ、Imagenはキャラクターや背景のビジュアル表現を補完する役割を担ったとしている。</p>
<p>このように、AIは制作工程の各段階で補助的に組み込まれており、物語構成や演出、最終的な表現の判断は人間の制作者が担う設計となっている。Googleは、AIを「自動生成の主体」ではなく、アーティストの意図を反映するための制作ツールとして位置づけている。</p>
<h2>「Story Forum」でのプレビュー上映という位置づけ</h2>
<p>上映が行われる「Sundance Institute Story Forum」は、完成作品の優劣を競うコンペティションではなく、物語表現や制作手法、創作プロセスそのものを共有・議論することを目的としたプログラムだ。</p>
<p>今回の短編アニメも、AIを活用した新しい制作工程の事例として紹介され、制作の背景や手法についての説明とあわせて上映される予定となっている。</p>
<h2>AI研究成果を創作の現場へ</h2>
<p>Googleは同作品について、AI研究の成果を実験段階にとどめず、映画やアニメーションといった創作の現場でどのように活用できるかを示す試みだとしている。表現の幅を広げることや、制作工程の選択肢を増やすことを目的としており、現時点で商用配信や一般公開の予定については明らかにしていない。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、推論向けAIアクセラレータ「Maia 200」発表──GPT-5.2を含む最新モデルを支える基盤に</title>
      <link>https://ledge.ai/articles/microsoft_maia_200_inference_ai_accelerator</link>
      <description><![CDATA[<p>Microsoftは米国時間2026年1月26日、AI推論に特化した自社設計のカスタムアクセラレータ「Maia 200」を<a href="https://blogs.microsoft.com/blog/2026/01/26/maia-200-the-ai-accelerator-built-for-inference/">発表</a>した。大規模言語モデル（LLM）などの推論処理を想定した設計で、同社はクラウドサービス「Azure」におけるAI基盤を支える中核技術の一つと位置づけている。</p>
<p>Maia 200は、学習用途ではなく推論ワークロードに最適化したアクセラレータとして設計された。Microsoftによると、トークン生成を中心とする推論処理において、スループットや電力効率、システム全体でのスケーラビリティを重視しているという。製造にはTSMCの3ナノメートルプロセスを採用し、FP8およびFP4演算に対応したテンソル演算機構を備える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Maia200chip_960x540_c584507414/Maia200chip_960x540_c584507414.png" alt="Maia200chip-960x540.png" /></p>
<p>メモリ構成ではHBM3eを採用し、大容量かつ高帯域のメモリアクセスを可能にした。Microsoftは、Maia 200が従来世代と比べて性能あたりのコスト効率を向上させたと説明しているが、具体的な比較対象や条件については明らかにしていない。</p>
<p>同社は、Maia 200をAzureのデータセンターに段階的に導入する方針を示している。Azure AI FoundryやMicrosoft 365 CopilotといったAIサービスの基盤として活用されるほか、OpenAIの最新モデルであるGPT-5.2を含む複数のAIモデルを支えるインフラとして位置づけられている。</p>
<p>@<a href="https://www.youtube.com/watch?v=bGecvPR2QWo">YouTube</a>
Microsoftはこれまで、GPUを中心とした外部ベンダー製アクセラレータを活用してきたが、AI利用の急拡大を背景に、自社設計シリコンの開発を進めてきた。Maia 200は、その流れの中で推論処理に特化した最新世代のアクセラレータとなる。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、GPT-5.2搭載の研究執筆AI「Prism」を無料で公開──人数制限なしの共同作業ワークスペース</title>
      <link>https://ledge.ai/articles/openai_prism_gpt5_2_research_writing_workspace</link>
      <description><![CDATA[<p>OpenAIは2026年1月27日、科学研究向けのAI執筆・共同作業ワークスペース「Prism」を<a href="https://openai.com/index/introducing-prism/">発表</a>した。GPT-5.2を中核に据えたAIネイティブ設計を採用し、論文執筆や修正、共同編集といった研究の日常業務を単一のクラウド環境に統合する。Prismは無料で利用でき、ChatGPTアカウントを持つユーザーであれば、人数制限なく共同作業を行える。</p>
<h2>研究執筆に残る分断を解消</h2>
<p>OpenAIは、AIは数学や生物学などの分野で研究の加速に寄与し始めている一方、論文執筆や推敲、数式管理、参考文献整理、共同編集といった日常業務は、依然として複数のツールに分断されたままだと述べる。研究者はエディタ、PDF、数式コンパイラ、文献管理ツール、チャットを行き来する必要があり、文脈の断絶が作業効率を下げてきた。Prismは、こうした断片化を解消する最初の取り組みとして位置付けられている。</p>
<h2>GPT-5.2を統合したAIネイティブ環境</h2>
<p>Prismは、OpenAIの最新モデルであるGPT-5.2を研究執筆のワークフローに直接組み込んだ点が特徴だ。数式や参考文献、論文全体の構造を文脈として理解したうえで、AIがドラフト作成や修正、推敲を支援する。研究者は、執筆環境の外にあるチャットツールを行き来することなく、同一のプロジェクト内でAIと対話しながら作業を進められる。</p>
<p><strong>OpenAIが公開したPrismの紹介動画。論文執筆とAI支援が同一ワークスペース内でどのように統合されているかを示している。</strong></p>
<p>@<a href="https://www.youtube.com/watch?v=xnInEsaaj9c">YouTube</a></p>
<h2>クラウド型・専門記法対応のワークスペース</h2>
<p>Prismは、学術論文で広く使われる数式や専門記法に対応したクラウドベースの執筆環境として設計されている。OpenAIが取得したクラウドLaTeX基盤「Crixet」を発展させたもので、既存の成熟した執筆・共同編集機能を土台に、AIを自然に統合したという。数式や図表、引用関係を横断的に理解しながら編集できる点を強みとする。</p>
<h2>研究チームでの共同作業を前提に設計</h2>
<p>科学研究は本質的に共同作業で進められる。Prismは、プロジェクト数や共同編集者数に制限を設けず、研究チーム全体での利用を前提に設計されている。クラウド型のため、ローカル環境の構築や専門ソフトのインストールは不要で、編集内容はリアルタイムに反映される。これにより、版管理や手動での統合作業にかかる負担を減らし、研究内容そのものに集中できるとしている。</p>
<h2>無料提供と今後の展開</h2>
<p>Prismは無料で利用でき、ChatGPTの個人アカウントを持つユーザーであれば、すぐに執筆や共同作業を開始できる。購読契約や席数の制限は設けられていない。OpenAIは今後、ChatGPT Business、Enterprise、Education向けにも提供を予定しており、より高度なAI機能については有料プランで順次展開するとしている。</p>
<p>OpenAIは、2025年にAIがソフトウェア開発の在り方を大きく変えたのに続き、2026年には科学研究でも同様の変化が起きると見ている。Prismは、研究者の日常業務に伴う摩擦を減らすことで、科学の進展を加速させるための第一歩と位置付けられている。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>パナソニック、仮想タレント制作のAI modelに出資──大企業CVCが並ぶプレシリーズBで資金調達</title>
      <link>https://ledge.ai/articles/panasonic_virtual_talent_ai_model_investment</link>
      <description><![CDATA[<p>パナソニックは2026年1月23日、SBIインベストメントと共同で運営するコーポレートベンチャーキャピタル（CVC）を通じ、AIを活用して仮想タレントなどを制作するスタートアップのAI modelに出資したと<a href="https://news.panasonic.com/jp/press/jn260123-1">発表</a>した。AI modelは同日、プレシリーズBラウンドの<a href="https://prtimes.jp/main/html/rd/p/000000046.000097252.html">資金調達を実施</a>したことを明らかにしている。</p>
<p>パナソニックの出資は、同社とSBIインベストメントが共同で設立したCVCファンド「PC‐SBI投資事業有限責任組合（通称：パナソニックくらしビジョナリーファンド）」を通じて行われた。出資額は非公表としている。</p>
<p>AI modelの発表によると、今回の資金調達には、SBIインベストメントのほか、キヤノンマーケティングジャパンがグローバル・ブレインと共同で設立したCVCファンド「Canon Marketing Japan MIRAI Fund」、三菱UFJキャピタルなどが参加した。このほか、複数の事業会社や地域系ベンチャーキャピタルも引受先として名を連ねている。</p>
<p>AI modelは、AIを用いた仮想タレントやデジタルヒューマンの制作を手がけるスタートアップで、エンターテインメントやブランド活用などを想定したAIモデルの開発を進めている。今回の資金調達を通じ、事業拡大や技術開発を進めるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_31d793e5a3/sub1_31d793e5a3.jpg" alt="sub1.jpg" /></p>
<p>パナソニックは、SBIインベストメントと共同でCVCを運営し、くらしやコンテンツ、デジタル領域を含む成長分野への投資を進めてきた。今回のAI modelへの出資も、そうした投資活動の一環として位置づけられる。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>データ連携の雄、セゾンテクノロジーが見据えるAI活用の未来図 ― 石田誠司常務が語る「データインテグレーター」の真価</title>
      <link>https://ledge.ai/articles/saison_ishida_interview2026</link>
      <description><![CDATA[<p>生成AIの登場がビジネスの風景を塗り替えつつある現在、多くの企業がその活用に乗り出す一方で、根源的な課題に直面している。それは、AIの知性を育む「データ」の分断と混乱である。ファイル転送の分野で20年以上国内トップシェアを誇る「HULFT」や、データ連携プラットフォーム（iPaaS）「HULFT Square」を擁するセゾンテクノロジーは、この課題を真正面から捉え、自らを「データインテグレーター」へと再定義し、戦略転換を宣言している。本稿では、同社の取締役 常務執行役員 営業本部長である石田誠司氏へのインタビューを通じ、企業のAI活用が直面するリアルな課題と、同社が描くデータ連携が拓く未来について話を聞いた。</p>
<h2>再定義「データインテグレーター」</h2>
<p>デジタルトランスフォーメーション（DX）という言葉が一般化して久しいが、多くのIT企業にとって、その本質を自社の事業モデルにどう落とし込むかは依然として重い課題だ。特に、従来のシステムインテグレーション事業は利益率の低下圧力に晒され、クラウドとSaaSの爆発的な普及は「データのサイロ化」という新たな分断を生み出した。</p>
<p><strong>自社を「データインテグレーター」と称されていますが、その狙いは何でしょうか？</strong></p>
<p><strong>石田氏:</strong> 当社は50年以上の歴史の中で、お客様の要望通りにシステムを構築する、いわゆる従来のシステムインテグレーションの事業と、「HULFT」に代表されるプロダクト事業の二軸で成長してきました。しかし、数年前から、市場の変化を見据え、当社の最大の強みであるファイル連携やデータ連携の領域に事業を大きくシフトさせる戦略転換を図りました。これにより、従来の受託開発事業で培った技術を活かしつつ、高付加価値なデータインテグレーション事業へと集中しています。「データインテグレーター」という呼称は、SIerと対比する形で、「我々はデータを中心にインテグレーションを行う企業である」という決意を込めて名乗り始めました。</p>
<p><strong>「データインテグレーター」という新たなポジショニングに対する、市場や顧客からの反応はいかがですか？</strong></p>
<p><strong>石田氏:</strong> ちょうど「DX」という言葉が一般に流通し始めた2018年から2019年頃に、我々はデータ連携ビジネスを本格化させました。当時から大手企業数百社のお客様にデータ連携基盤を納めてきた実績がありましたが、近年になってようやく「DXの成功には、その基盤となるデータ連携が不可欠である」という考え方が、お客様の間で共通言語になってきたと感じています。この手応えは、経営層だけでなく、現場の社員も強く感じているところです。我々が見据えていた世界観が、ようやく市場に浸透し始めたという実感がありますね。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_3861fa3e2b/3_3861fa3e2b.png" alt="3.png" /></p>
<h2>データ連携市場を勝ち抜く、セゾンテクノロジーならではの競争優位性</h2>
<p><strong>国内外の競合と比較した際の、貴社の競争優位点は何でしょうか？</strong></p>
<p><strong>石田氏:</strong> 我々の競争優位性は、大きく3つの点に集約されると考えています。これらの強みが個別に存在するのではなく、三位一体で機能している点が重要です。</p>
<p><strong>1. 12,000社以上の強固な顧客基盤</strong>
長年にわたり提供してきた「HULFT」は、現在12,000社を超えるお客様にご利用いただいています。この強固な顧客基盤と、そこで培われた信頼関係こそが、我々の最大の資産であり、競争優位性の源泉です。この信頼をベースに、データ連携という新たな価値提案へと繋げることができています。</p>
<p><strong>2. 実装まで手掛ける実行力</strong>
我々は単なるパッケージベンダーではありません。「データインテグレーター」として、お客様の要件を深く理解し、実際のインプリメンテーション（実装）まで手掛ける専門部隊を擁しています。また、様々なユースケースに対応するためのデータ連携テンプレートも豊富に保有しており、迅速な価値提供が可能です。これは、製品を提供するだけのベンダーにはない決定的な強みです。</p>
<p><strong>3. 北米トレンドを取り込む開発体制</strong>
当社は海外にも開発拠点を構えており、特に先進的なトレンドが生まれる北米の動向を常に製品開発にフィードバックしています。いわば「タイムマシン経営」のような形で、世界の最先端技術やユースケースを取り込み、製品を進化させ続けることができるのです。</p>
<p>これら3つの強みの相乗効果こそが、我々の戦略の核心です。圧倒的な顧客基盤が高度なソリューションを提案する信頼の入り口となり、実装チームがその提案を現実のものに変え、そして北米からのフィードバックがそのソリューションを常に最先端に保ち続けるのです。</p>
<h2>「データはあるが、使えない」企業の根深い課題を解決する</h2>
<p>多くの企業がデータ活用の重要性を認識し、巨額の投資を行っているにもかかわらず、その成果を十分に得られていない。その根源には、部門間の壁によってデータが分断される「サイロ化」や、存在はするものの活用方法が分からず放置された「休眠データ」といった根深い問題がある。企業はまさに、価値の源泉であるはずのデータという宝の山を前に、それを掘り起こす術を持てずに立ち尽くしているのである。</p>
<p><strong>昨今の企業におけるデータ活用のトレンドと、企業が陥りがちな課題をどのように捉えていますか？</strong></p>
<p><strong>石田氏:</strong> 企業が抱えるデータ活用の課題は、その規模によって少し様相が異なります。大手企業では、むしろ組織が強固であるために「部門間の壁」がデータ連携を阻害しています。製造部門と販売部門がそれぞれ独自のSaaSやクラウドを導入し、結果として「野良クラウド」「野良SaaS」が乱立してしまっているのです。 一方で、中堅・中小企業のお客様からは「うちは活用できるデータがない」というお話をよく聞きます。しかし、実際にはそんなことはありません。例えば、社員間のチャットツールでのやり取りやプロジェクトの報告書など、非構造化データの中には、個々の社員が何を志向しているかといった貴重な情報が眠っています。</p>
<p>さらに、両者に共通する課題として、「データはあるが、触れられない」という問題があります。メインフレーム上に存在するレガシーデータや、部門ごとにバラバラに管理されて統一されていないマスターデータなどがその典型です。こうした課題を解決する上で、AIは非常に有効な手段となり得ます。例えば、AIに商品説明や成分表を読み込ませることで、異なるコードで管理されていたマスターデータを「これは同じ製品だ」と瞬時に紐付けることも可能になるのです。</p>
<h2>「RAGの沼」を越え、データを真の洞察へ</h2>
<p>データ活用の課題は、生成AIの登場によって新たな局面を迎えている。特に社内データを参照して回答を生成するRAG（検索拡張生成）技術は、企業データ活用のゲームチェンジャーとして大きな期待を集めている。しかし、その回答精度は元となるデータの質に大きく依存するため、多くの企業が「期待した答えが返ってこない」という「RAGの沼」にはまり、AI投資のROIを見出せずにいる。この沼は、多くのAIプロジェクトが実証実験（PoC）段階で頓挫する「死の谷」であり、ここを乗り越えることこそが価値創出の鍵となる。</p>
<p><strong>多くの企業が直面する「RAGの沼」に対し、どのようなアプローチで支援していますか？</strong></p>
<p><strong>石田氏:</strong> まさにそこが我々の価値を発揮できる領域です。RAGの精度を上げるためには、AIがデータを読み込む前の「前処理」が決定的に重要になります。当社では、この前処理を効率化するため「HULFT Square」向けの「AI前処理テンプレートシリーズ」を提供しています。このテンプレートを使えば、PDF形式のマニュアルや画像データといったAIがそのままでは理解しにくい非構造化データを、タグなどのノイズ除去やQ&amp;A形式のCSVファイル変換など、AIが最も理解しやすい形式に自動で加工や整形することができます。実際に、あるPDFデータをそのまま読み込ませた場合、ある生成AIモデルでの正解率が50%だったのに対し、当社のテンプレートで前処理を施したデータでは90%まで劇的に向上しました。一度、自力でRAGを試してうまくいかなかった経験をお持ちのお客様ほど、この前処理の重要性をご理解いただけ、我々のアプローチが非常に響くようです。</p>
<p><strong>データとAIを連携させることで、企業活動そのものはどのように変わるのでしょうか？</strong></p>
<p><strong>石田氏:</strong> 一例として、人材活用（タレントマネジメント）の領域で劇的な変化が起きています。従来、プロジェクトへの人員アサインは、マネージャーの経験や勘、あるいはスキルシートといった限られた情報に頼らざるを得ず、そこには必ず個人のバイアスがかかっていました。しかしAIは、そうしたバイアスとは無縁です。例えば、社員が任意で受講したeラーニングの履歴や、チャットツールでの「会計の知識を深めたい」といった何気ない発言まで、多角的なデータを統合的に分析します。その結果、「英語はできないが、海外プロジェクトへの参加意欲が誰よりも高い」といった、人間のマネージャーでは見過ごしがちだった潜在的な意欲を汲み取り、最適人材としてアサインするといったことも可能になるでしょう。これは、社員のモチベーションを最大限に引き出す、従来とは全く異なるアサインメントの形であり、データとAIの連携がもたらす変革のほんの一例に過ぎません。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_729af42f23/2_729af42f23.png" alt="2.png" /></p>
<h2>自律的なAIエージェントの活用とガバナンスという新たな挑戦</h2>
<p>AIの進化は、RPAに代表されるような定型業務の自動化から、自ら状況を判断し、タスクを遂行する「AIエージェント」へとその主戦場を移している。AIエージェントは、人間の手を介さずに業務を完結させることで飛躍的な生産性向上をもたらすと期待される一方、管理・統制が取れなくなる「野良エージェント」が企業システム内で無秩序に活動し、セキュリティやコンプライアンス上の深刻なリスクとなる二面性を持つ。このパラダイムシフトは、企業に「いかにしてAIの力を解き放ち、同時にそのリスクを統制するか」という新たな問いを突きつけている。</p>
<p><strong>AIエージェントの進化をどう見ていますか？また、その中で貴社はどのような役割を果たしますか？</strong></p>
<p><strong>石田氏:</strong> AIエージェントには、RPAの延長線上にある業務自動化タイプのものと、より高度なインテリジェンスを持って自律的に判断するものの2種類があると考えており、我々は特に後者の進化に注目しています。例えば、コールセンターでお客様の感情を分析し、怒っているようであれば対応をエスカレーションするといった活用は、インテリジェントなエージェントならではの動きです。 そして、こうしたAIエージェントの活用が本格化する中で、我々が果たすべき最も重要な役割は「ガバナンス」の提供です。企業の様々なシステムやデータ、そしてAIエージェントが、我々のiPaaSである「HULFT Square」をハブとして連携するアーキテクチャを構築します。これにより、どのエージェントが、いつ、どのデータにアクセスし、どのような処理を行ったかをすべて可視化し、追跡することが可能になります。このハブを通過しないエージェントは「野良エージェント」として明確に判別できるため、企業はセキュリティと統制を担保しながら、AIエージェントの活用を推進できるのです。これが我々の描くビジョンです。</p>
<h2>「AI Foundation構想」が拓く、オープンなAIエコシステムの未来</h2>
<p>これまでの議論は、一つの壮大な構想へと収斂していく。それが、セゾンテクノロジーが掲げる「AI Foundation構想」である。これは、単なる製品開発ロードマップではない。同社が持つ競争優位性を最大限に活かし、AIエージェントのガバナンスという喫緊の課題に応え、そして経営層のマインドセット変革を後押しするための、オープンなAIエコシステムを社会に実装しようとする野心的な試みだ。</p>
<p><strong>貴社が掲げる「AI Foundation構想」とは、具体的にどのようなものでしょうか？</strong></p>
<p><strong>石田氏:</strong> 「AI Foundation構想」とは、当社のiPaaS「HULFT Square」を中核とした、オープンなAIエコシステムを構築する構想です。このプラットフォーム上には、これまで述べてきたRAGに読み込むデータを事前加工するAI前処理テンプレートや、AIエージェント同士が連携するためのA2A（Agent-to-Agent）プロトコルなどを取り揃えていきます。重要なのは、これを我々だけで開発するのではなく、パートナー企業が持つ優れた技術やエージェントも自由に組み込めるオープンな設計にしている点です。将来的には、このエコシステムを通じて、企業間をまたいでAIエージェント同士が自律的に連携する世界を見据えています。例えば、あるメーカーで製品のリコールが発生した際に、その情報がメーカーのAIエージェントから販売店のERPを管理するAIエージェントへ自動で伝達され、出荷停止や在庫確認が即座に行われる、といった世界が実現可能になります。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Foundation_bbc64166ee/AI_Foundation_bbc64166ee.png" alt="AI Foundation.png" /></p>
<p><strong>2026年以降のAI市場、特に「国産」という文脈でどのような未来を描いていますか？</strong></p>
<p><strong>石田氏:</strong> 2026年は、AIエージェントの活用が本格化する年になると予測しています。その際、海外の大手ベンダーは、自社の製品群で固めたクローズドな「密結合」のエコシステムを構築してくるでしょう。それに対し、我々は様々なシステムやサービスを繋ぐオープンな「疎結合」のハブとなることを目指します。 また、「国産」という点も重要です。現在、多くの日本企業が高価な海外製ソリューションに依存しており、それがコストを圧迫しています。我々は、そうした高価なシステムから必要な機能だけを切り出す「オフロード」の受け皿となりたい。他の優れた国産ベンダーと連携し、安価で使いやすく、日本の商習慣に合ったソリューションを提供することで、日本企業全体のAI競争力を高めていく。それこそが、国産データインテグレーターとしての我々の使命だと考えています。</p>
<p>エンタープライズAIの戦場は、もはや最高のアルゴリズムを持つ者が制するのではない。そのアルゴリズムを動かす、混沌としたデータの流れを制する者が勝者となる。セゾンテクノロジーは、システムや部門、さらには企業の壁を越えてデータを「つなぐ」という長年磨き上げてきた技術を武器に、日本企業のデータ駆動型経営を根幹から支える中核的存在へと飛躍しようとしている。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>SpaceX、AI向け「宇宙データセンター」構想をFCC提出──太陽光を直接使う“軌道上AIインフラ”、衛星100万基規模</title>
      <link>https://ledge.ai/articles/spacex_fcc_orbital_ai_data_center_1m_satellites</link>
      <description><![CDATA[<p>SpaceXが、AI向け計算基盤の新たな構想を打ち出した。<a href="https://www.reuters.com/business/aerospace-defense/spacex-seeks-fcc-nod-solar-powered-satellite-data-centers-ai-2026-01-31/">Reuters</a>によると、SpaceXは2026年1月30日、米連邦通信委員会（FCC）に対し、将来的に最大100万基規模へ拡大する衛星コンステレーション計画を申請した。これらの衛星は、従来の通信用途にとどまらず、「軌道上データセンター」としてAIの計算・データ処理を担う構想が盛り込まれているという。</p>
<h2>地上の電力制約を回避する「宇宙」という選択肢</h2>
<p>Reutersによれば、今回申請された低軌道（LEO）衛星群は、衛星同士をネットワークで接続し、高度な計算機能を担うことを想定している。宇宙空間でほぼ連続的に得られる太陽光を直接電力源として活用することで、地上データセンターが直面する電力供給の制約を回避できる可能性があると報じている。</p>
<h2>FCCの審査と「Starlink Gen2」の判断例</h2>
<p>FCCへの申請手続き上、こうした構想を含む衛星システムも通信衛星として扱われ、周波数利用の適格性などが審査対象となる。FCCは2026年1月9日、SpaceXが申請していた次世代通信衛星「Starlink Gen2」を正式に承認しており、公式文書（<a href="https://docs.fcc.gov/public/attachments/DA-26-36A1.pdf">DA-26-36A1</a>）では、大規模な低軌道衛星コンステレーションであっても、既存の通信枠組みに基づき審査・判断が行われることが示されている。</p>
<p>今回の申請は、提出時点で承認されたものではなく、今後FCCによる審査を経て判断される。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>フィールズ賞のテレンス・タオ氏、「GPT-5.2 Proが数学の未解決問題をほぼ自律的に解き切った」と評価──エルデシュ問題#728で示されたAIの新たな到達点</title>
      <link>https://ledge.ai/articles/ai_autonomous_solution_erdos_problem_728</link>
      <description><![CDATA[<p>AIが数学の未解決問題を「ほぼ自律的に解き切った」と、数学者が評価した。著名な数学者であるテレンス・タオ氏が2026年1月8日、分散型SNS「Mathstodon」への投稿で、エルデシュ問題の一つである #728 が、AIツールによって「more or less autonomously（ほぼ自律的に）」解かれたと<a href="https://mathstodon.xyz/@tao/115855840223258103">述べた</a>。</p>
<p>この成果についてタオ氏は「私たちの知る限り、既存の文献では再現されていない」としたうえで、近年のAIツールの能力向上を示す「節目（milestone）」だと位置づけた。</p>
<h2>エルデシュ問題とは</h2>
<p>エルデシュ問題は、20世紀を代表する数学者ポール・エルデシュが提起した数多くの問題をもとに整理された、数学の未解決問題群を指す。現在も多くの問題が未解決のまま残されており、世界中の数学者が長年にわたって取り組んできた。</p>
<p>今回タオ氏が言及した エルデシュ問題#728 は、その中の一つで、問題の内容や背景はエルデシュ問題の<a href="https://www.erdosproblems.com/728">公式サイト</a>で公開されている。</p>
<p>未解決問題は、数学界において特別な位置づけを持つ。解決に至れば理論的に重要な意味を持つだけでなく、長年の研究の蓄積を塗り替える可能性があるためだ。</p>
<p><strong>■ ポール・エルデシュ（左）と、当時10歳のテレンス・タオ。1985年撮影。</strong> エルデシュ問題は、エルデシュ自身が提起した未解決問題群に由来する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Paul_Erdos_with_Terence_Tao_952867730e/Paul_Erdos_with_Terence_Tao_952867730e.jpg" alt="Paul_Erdos_with_Terence_Tao.jpg" /></p>
<h2>GPT-5.2 Proと人間の役割分担</h2>
<p>証明には、OpenAIの大規模言語モデル GPT-5.2 Pro が用いられた。人間側は、計算環境の整備や初期試行へのフィードバック、結果の検証、形式的な証明への整理といった役割を担ったとされる。</p>
<p>AIが完全に単独で問題を解決したわけではないものの、思考の主導権がどこにあったのかが、今回の評価における重要なポイントとなった。</p>
<p><strong>■ 「ほぼ自律的に」解いた、という表現</strong>
従来、AIは数学分野において計算の高速化や文献探索、発想の補助といった役割を担ってきた。一方で今回のケースでは、問題の解釈から解法の構築、証明に至るまでの過程をAIが主導したと評価された。</p>
<p>タオ氏によれば、AIは初期の試行に対する一定のフィードバックを受けた後、問題の趣旨に沿った形で解決に到達したという。この点が、「ほぼ自律的」という表現につながった。</p>
<h2>「解決以上に興味深い点」</h2>
<p>タオ氏は今回の投稿で、解決結果そのものに加え、「それ以上に興味深い点がある」とも述べている。投稿では、</p>
<p>「より興味深いのは、解法の説明（exposition）を迅速に書き、書き直し、再構成するAI主導の能力が現れつつある点だ」
と指摘し、証明文書の作成や改稿をめぐるAIの能力向上に言及した。</p>
<p><strong>■ テレンス・タオ氏がMathstodonに投稿したエルデシュ問題#728に関する発言。AIが「ほぼ自律的に」問題を解いたと評価している。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/terencetao_mathstodon_b05b8af4d5/terencetao_mathstodon_b05b8af4d5.jpg" alt="terencetao mathstodon.jpg" /></p>
<p>従来、数学論文の執筆や大幅な改稿には多大な時間と労力が必要だったが、AIによる文章生成と形式証明ツールを組み合わせることで、説明文を用途や読者に応じて柔軟に作り直すことが可能になりつつあるという。</p>
<h2>他のAI解決事例との位置づけ</h2>
<p><strong>■ エルデシュ問題を巡るAI活用事例を整理した公式Wikiの一部。#728は、AIによる解決後に類似文献が確認されたケースとして位置づけられている。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/github_erdos_problem_058007f757/github_erdos_problem_058007f757.jpg" alt="github erdos problem.jpg" /></p>
<p>タオ氏自身も、AIによるエルデシュ問題の解決例の多くでは、後に類似の結果が既存文献で確認されてきたと説明している。#728についても、問題文の再構成が比較的最近まで行われていなかったことが、先行研究が見当たらなかった理由の一つだとされている。</p>
<h2>数学とAIの関係に生じた変化</h2>
<p>今回の発言は、AIが数学者の役割を代替したことを示すものではない。一方で、未解決問題を対象とした成果について、数学者がAIの関与を明示的に評価し、その能力の到達点を具体的に言及した点は確認できる事実である。エルデシュ問題#728をめぐる今回の事例は、AIの活用がどの段階まで進んでいるのかを示す一例として位置づけられ、今後、同様の評価が他の問題や分野でも示されるかどうかが注目される。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>共通テスト2026、ChatGPT最新モデルが9科目満点──LifePrompt検証、精度の先で浮かぶ“弱点の質”</title>
      <link>https://ledge.ai/articles/common_test_2026_chatgpt_full_marks_9_subjects_lifeprompt_analysis</link>
      <description><![CDATA[<p>AIベンチャーのライフプロンプトは2026年1月20日、大学入学共通テスト（2026年度）の問題を複数の最新生成AIに解かせた検証結果を公式noteで<a href="https://note.com/lifeprompt/n/nb87edfb2e7ca">公開</a>した。OpenAIのGPT-5.2 Thinkingが、受験させた科目のうち9科目で満点を獲得したという。</p>
<p>同社は同一条件下で、Gemini 3 Pro、Claude Opus4.5 にも同テストを受験させ、得点だけでなく解答に要した時間や誤答の傾向まで比較した。ライフプロンプトが「AI vs 共通テスト」の年次検証を行うのは2023年からで、今回が4年目となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9.webp" alt="1768868571-lsp4EjCy6DWLX1rB8AcThYZb.webp" /></p>
<h2>共通テストを「そのまま解かせる」ための検証方法</h2>
<p>今回の検証では、人為的なコピペミスや恣意性を排除するため、共通テスト専用の自動受験システムを構築し、API経由で試験を実施した。</p>
<p>具体的には、共通テストの問題PDFをシステムに投入し、全ページを画像化すると同時にテキスト解析を行う。問題構造を自動判定したうえで大問ごとに分割し、各AIモデルにAPI経由で出題。AIが出力した自由記述の回答を、別のAIプロセスでマークシート形式に変換し、自動採点する仕組みだ。</p>
<p>例外措置として、英語リスニングは試験センターが公開している読み上げスクリプト（台本）をテキスト入力で使用した。また、国語の縦書き文章については、外部ツールで文字起こししたテキストを用いている。</p>
<p>今回比較したモデルは以下の3種だ。</p>
<ul>
<li>ChatGPT系列：GPT-5.2 Thinking</li>
<li>Gemini 3 Pro</li>
<li>Claude Opus 4.5</li>
</ul>
<h2>満点9科目、得点はGPT、速度はGeminiとClaude</h2>
<p>検証の結果、文系・理系いずれの合計点でもGPT-5.2 Thinkingが最も高得点を記録し、満点科目は9科目に達した。Gemini 3 ProとClaude Opus4.5 も900点台前半の高得点で続いた。</p>
<p>一方、解答に要した時間では明確な差が出た。GeminiとClaudeは約1時間40分前後で全科目を解き終えたのに対し、GPT-5.2 Thinkingは約5時間30分を要した。ライフプロンプトは、GPTが深い推論と検算を繰り返す「熟考型」であることが、高得点と引き換えに時間がかかった理由だとしている。</p>
<p>同社は、昨年の検証でAIが東京大学の合格水準に到達したと報告しており、今年は「合格できるかどうか」ではなく、「満点を取れるか」「どれだけ速く解けるか」といった次の段階に焦点を移したと位置付けている。</p>
<h2>なぜAIは間違えたのか──誤答に共通するパターン</h2>
<p>これほど高得点を記録したAIだが、3モデルすべてが共通して誤答した問題も存在した。ライフプロンプトは、誤答の傾向から現在の生成AIに残る課題が見えるとしている。</p>
<p>一つは図表やイラストの読み取りだ。英語リスニングの「バスの乗り方」を問う問題では、音声スクリプトの内容は正確に理解できていたものの、選択肢として示されたバスのイラスト（矢印の向き）を正しく判定できず、全モデルが誤答した。</p>
<p>次に挙げられるのが、国語（小説）の心情理解である。主人公が現状を正当化しようとしつつも割り切れない思いを抱える場面で、正解は「現状への妥協」を示す選択肢だったが、AIはいずれも「過去の過ちへの反省」を選んだ。ライフプロンプトは、一般論的な道徳観に引き寄せられ、人間特有の曖昧な感情を読み違えたと分析している。</p>
<p>さらに、地理などの視覚情報も弱点として浮かび上がった。色の濃淡で分布を示した地図問題では、ヒートマップの微妙な違いを識別できず、全モデルが誤答した。</p>
<h2>それでも差は出た──Geminiだけが正解した問題</h2>
<p>一方で、すべての問題で同じ結果になったわけではない。地理の別問題では、Gemini 3 Proのみが地図上の地形（アンデス山脈）と気候グラフを正しく結びつけ、唯一正解したケースもあった。</p>
<p>ライフプロンプトは、GPT-5.2 ThinkingやClaudeが画像を「文字情報の集合」として処理しようとする傾向があるのに対し、Geminiは画像を視覚情報として捉える能力が強く、地図やグラフの相関関係を直感的に把握できたと説明している。</p>
<h2>「AI入試挑戦」を巡る論点の変化</h2>
<p>同社はこれまで、毎年のように生成AIが入試に挑戦する検証を取り上げてきた。2024年頃は、共通テストでどのモデルが最も高得点を取るのか、人間の合格水準にどこまで迫ったのかが主な関心事だった。</p>
<p>2025年には、共通テストに加えて東大二次試験なども対象とした検証が登場し、「難関大学に通用する水準かどうか」が焦点となった。そして2026年の今回、論点はさらに一段階進み、満点科目の数、解答速度、誤答の質へと移っている。</p>
<p>AIが「解けるかどうか」ではなく、「どこで、なぜ落とすのか」が具体的に示される段階に入ったことを、今回の検証は示している。</p>
<p>共通テストで9科目満点という結果は、生成AIの推論能力が標準化試験レベルでは極めて高い水準に到達したことを示す。一方で、図表の読み取りや感情理解といった領域では、人間とは異なるつまずき方をすることも明らかになった。</p>
<p>今後も同社は同様の検証を続けるとしており、AIが入試問題を通じてどのように進化していくのかは、引き続き注目される。</p>
]]></description>
      <pubDate>Thu, 22 Jan 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>