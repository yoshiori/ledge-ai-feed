<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>【AI歴史年表】AIはダートマス会議から数えて2026年で70周年！起源から生成AI革命までのAI全史を振り返る</title>
      <link>https://ledge.ai/articles/70year_history_of_ai_from_the_dartmouth_conference</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>2026年は、人工知能（AI）研究が正式に始動した歴史的な瞬間、1956年のダートマス会議から70周年という記念すべき節目を迎える。この70年間、AIは期待と幻滅の波を乗り越え、ついに人類の創造性を拡張する「生成AI」の時代へと到達した。この壮大な進化の軌跡を、各時代のエポックメイキングな出来事とともに紹介する。</p>
<h2>1. AIの誕生、最初の挫折と基礎構築 (1956–1979)</h2>
<p>人工知能（AI）は、1956年のダートマス会議でJ.マッカーシーらによって正式に分野として確立された。このダートマス会議で若手の中心となったJ.マッカーシー、M.ミンスキー、A.ニューウェルの3人はいずれも1927年生まれ、30歳を少し過ぎたところだ。ダートマス会議後、この3人はそれぞれスタンフォード大学、MIT、カーネギーメロン大学で活動し、AI研究の世界的な拠点が形成されていく。</p>
<p>初期の成功として、1958年にはF.ローゼンブラットが脳を模倣した初の学習可能モデルであるパーセプトロンを発表し、1966年にはJ.ワイゼンバウムが初の対話型システムであるELIZAを開発した。また、NNの学習においては、1967年に甘利俊一が確率的勾配降下法という後のディープラーニングの基礎となる最適化手法を発表するなど、技術的な基盤も築かれ始めていた。</p>
<p>しかし、この楽観的なブームは短期間で終焉を迎える。1969年、M.ミンスキーらがパーセプトロンの限界証明を行い、単層NNでは複雑な問題が解けないことを示唆した結果、AI研究への資金が大幅に削減され、最初の「冬の時代」が到来した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_70_AI_2ddf249970/01_70_AI_2ddf249970.jpg" alt="表01_70AI.jpg" /></p>
<p>この停滞期においても、後のAIの土台となる研究は継続された。日本では、1972年に甘利俊一が脳の記憶を模倣した連想記憶モデルを発表し、1979年には福島邦彦が、後の畳み込みニューラルネットワーク（CNN）の原型となるネオコグニトロンという階層型のNNモデルを開発した。この時期の日本の研究者の貢献は、AIの次の飛躍に向けた重要な種を蒔いたと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>2. AI研究の転換期における三つの潮流 (1980–1996)</h2>
<p>1980年代から1990年代前半にかけて、AI研究は、1970年代の停滞期を脱するため、異なる哲学に基づいた三つの潮流が並立した。</p>
<p>まず、記号主義（知識ベース）AIの流れを極限まで推し進めようとする試みがあった。その代表が1984年にD.レナートによって開始されたCycプロジェクトである。このプロジェクトは、人間が持つ膨大な常識をすべて手作業で知識ベースに構築し、究極のエキスパートシステムを実現することを目指した。これは、記号主義AIの可能性を探る壮大な挑戦であったが、同時に知識を形式化し獲得することの難しさを浮き彫りにした。</p>
<p>次に、長らく停滞していたニューラルネットワーク（NN）研究が息を吹き返した。この復活は、1982年にJ.ホップフィールドが、甘利俊一の先行研究と同系統の連想記憶モデルを、統計物理学の手法を用いて再発見したことに端を発する。これにより、NNが「記憶」のメカニズムを持つことが示唆された。決定的なブレイクスルーとなったのは、1986年にG.ヒントンらが多層NNを効率的に学習させる誤差逆伝播法（Backpropagation）を普及させたことである。この手法の登場は、NNが単層の限界を乗り越え、複雑なパターン認識を扱えるようになる第2次NNブームを牽引した。</p>
<p>そして第三の潮流として、従来の複雑な推論中心のAIに異を唱える行動ベースAIが登場した。1991年、iRobotの創業者でもあるR.ブルックスは、包摂アーキテクチャという新しい考え方を提唱し、その具体例として小型六本足ロボットのGenghisを開発した。これは、中央の知識ベースを持たず、環境からのセンサー情報に基づいて直接行動することで、現実世界でのタスク実行を重視するアプローチである。この研究は、AI研究の主流を、抽象的な推論から知覚と行動の統合へとシフトさせるきっかけとなり、その後のロボット工学に大きな影響を与えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/02_70_AI_204dc3e658/02_70_AI_204dc3e658.jpg" alt="表02_70AI.jpg" /></p>
<p>このように、1980年代から90年代前半は、知識ベースの限界と挑戦、NNの劇的な復活、そして現実世界指向の新しいパラダイムの誕生という、複数の試行錯誤を通じて、後のAI発展の基礎が築かれた重要な転換期であったと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>3. データと計算力によるAIの夜明け～ディープラーニングの衝撃 (1997–2016)</h2>
<p>1990年代後半から2010年代にかけてのAI研究は、インターネットの普及によるデータの爆発的な増加と、計算機能力の飛躍的な向上という二つの外部要因に強く支えられた。この時期、AIは「知識ベース」から「データ駆動」へとパラダイムを完全に転換し、特定のタスクで人間の能力を超える成果を上げ始めた。</p>
<p>まず、AIは特定の知的ゲームにおいて、人間を凌駕する能力を示した。1997年には、IBMのDeep Blueがチェスの世界チャンピオン、ガルリ・カスパロフに勝利し、「探索と計算」に特化したAIの能力を世界に示した。この頃、インターネットの本格的な普及は、AI研究の間接的な基盤を構築していた。Web上の膨大な情報（ビッグデータ）を分析するデータマイニングや統計的手法が発展し、AI研究も経験的なデータから知識を抽出する方向に傾倒していった。</p>
<p>AIに真のブレイクスルーをもたらしたのは、ニューラルネットワーク（NN）の進化であった。2006年、G.ヒントンらがディープラーニングを提唱し、多層NNを効率的に学習させる手法（深層化）に成功した。これは、増大するインターネット上のビッグデータを扱うために、極めて重要な進歩であった。この技術の有効性は、様々な分野で証明され始めた。2011年には、IBMのWatsonが、膨大な非構造化データ（書籍、記事など）から答えを導き出す能力により、米国の人気クイズ番組『ジェパディ！』で歴代チャンピオンに勝利した。そして2012年、ヒントンらが開発したAlexNetが、大規模な画像認識コンテスト（ILSVRC 2012）で圧倒的な性能を見せつけ、ディープラーニングが画像認識の主流技術となることを決定づけた。</p>
<p>この時期のAI研究の集大成となったのが、Google DeepMindによるAlphaGoの成功である。2016年、AlphaGoは、人間の直感と深い洞察力が求められる囲碁において、世界トップ棋士であるイ・セドル九段に勝利した。この勝利は、チェスのような「探索」だけでなく、「直感的な判断」が必要とされる領域でもAIが人間を超越したことを意味し、ディープラーニングと強化学習を組み合わせたAIが、人類の「知性の最後の砦」の一つを突破した歴史的な瞬間であった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/03_70_AI_00677c2be5/03_70_AI_00677c2be5.jpg" alt="表03_70AI.jpg" /></p>
<p>この1997年から2016年にかけて、AIはインターネットによって供給されるデータと、高性能なGPUによって可能になった計算力を武器に、ディープラーニングという核技術を獲得し、次の「生成AI」時代への道筋を明確に作ったのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>4. 生成AI革命の勃発 (2017–2022)</h2>
<p>2017年から2022年の期間は、AI研究史上最も劇的な変革期であり、技術的なブレイクスルーと、それによる生成AI革命の勃発が特徴である。</p>
<p>この変革の起点は、2017年にGoogleが発表したTransformerモデルにあった。このモデルは、入力データ内の重要度を把握する「注意機構（Attention）」を採用し、計算を並列処理できるようになったため、大規模で深いネットワークの学習を可能にし、大規模言語モデル（LLM）の時代の扉を開いた。</p>
<p>このアーキテクチャを基盤に、2018年にOpenAIがGenerative Pre-trained Transformer（GPT）を開発し、LLMの基礎を築いた。さらに2020年には、モデルを大きくするほど性能が向上するというスケーリング則が確立され、LLMの巨大化戦略が主流となった。また、同年には拡散モデルが実用化され、高精度な画像生成AIの道も開かれた。</p>
<p>そして2022年、AIは一気に社会へ浸透した。LLMの推論能力を飛躍的に高める思考の連鎖（CoT）などの手法が開発される一方、Midjourneyなどの対話型画像生成AIが普及した。極めつけは、同年後半にOpenAIからリリースされたChatGPTである。人間と遜色ない自然な対話能力を持つChatGPTは、リリース後わずか約2か月で月間アクティブユーザー数1億人を突破し、生成AIブームを世界中に巻き起こした。</p>
<p>一方で、技術の急速な発展に伴い、AIの倫理と安全性に関する議論も本格化した。2017年にはアシロマ会議が開かれ、AIの安全な開発と利用に向けた「アシロマAI 23原則」が策定されたことも、この時期の重要な出来事である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/04_70_AI_28c3fdc49a/04_70_AI_28c3fdc49a.jpg" alt="表04_70AI.jpg" /></p>
<p>この5年間で、AIは「認識」から「創造」の領域へと能力を拡張し、人類の生活を一変させる新たなステージへと進んだのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>5. 70周年の展望：AIと人類の未来 (2023年～)</h2>
<h3>5-1. 2023～2025年におけるAIと人類の状況</h3>
<p>2023年から2025年は、生成AI（Generative AI）技術が社会全体に急速に浸透した「AIの実用化元年」とも呼ぶべき変革期であった。特に大規模言語モデル（LLM）の進化により、AIは単なる自動化ツールから、人間の協働者や代行者へとその役割を急速に拡大した時期である。</p>
<p>日常生活においては、AIはスマートフォンや家電に深く組み込まれ、ルーティン作業の自動化、情報検索の高度化、そして個別化された健康管理の提供を通じて、人々の生活効率を向上させた。教育分野では、AIチューターや個別学習プログラムの利用が一般化し、生徒一人ひとりの進捗に合わせたカスタマイズ教育が主流となった一方で、教師は教材作成や評価の負担が軽減され、より対話的な指導に注力できるようになった。エンターテイメント領域では、AIによる画像、音楽、動画の生成が爆発的に増加し、コンテンツ制作の民主化が進んだ。また、AIを活用したパーソナライズされたゲーム体験や、没入型のMR/VRコンテンツも普及した。</p>
<p>ビジネスにおいては、AI導入が業務効率を大幅に向上させ、産業構造の再編を促した。ここでは利用形態に明確な対比が見られた。一つは、コーディングや文書作成などの専門作業において人間の作業を支援・加速するコパイロット型AIであり、これは人間の意思決定が最終的に介在する協調的な形態である。もう一つは、人間からの指示を基に複数のタスクを自律的に計画・実行し、ビジネスプロセスや顧客対応を代行・自動化するAIエージェントの進化である。この対比は、業務におけるAIの自律性の度合いを示す重要な指標となった。</p>
<p>政治においては、AIによる情報分析と政策立案支援が進み、行政の効率化が図られた。しかし同時に、AIが生成するディープフェイクや誤情報が選挙や世論形成に与える影響が重大な社会問題となり、各国でAIの倫理的利用と規制に関する議論が加速した。この時期、人類はAIの利便性を享受しつつも、その倫理性、安全性、社会への影響に対する向き合い方を確立する過渡期にあるのが現状である。</p>
<h3>5-2. 未来のAI：相乗効果と応用のグランドビジョン</h3>
<p>未来のAI技術 (AI_future) の進化は、現在の技術の単なる延長ではない。それは、基礎技術の「積」による指数関数的な相乗効果と、応用領域の「和」による社会的な価値の最大化によって実現されるビジョンである。
Ledge.aiでは、このビジョンを、以下のように定式化して考えている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_formula_ff6d7ead4c/ai70th_formula_ff6d7ead4c.png" alt="ai70th_formula.png" /></p>
<h3>■SYNERGY（相乗効果：積の力）による性能の飛躍</h3>
<p>現在のAI技術 (AI_current) は、四つの主要な基礎技術が掛け合わされる（積Π）ことで、その性能を劇的に高める。これらの技術は、それぞれがAIの抱える限界を突破する鍵となる。</p>
<ul>
<li><strong>量子コンピューター (Quantum) :</strong> AIの処理速度と複雑な問題解決能力に演算能力のブレイクスルーをもたらし、現行のスーパーコンピューターでは不可能な領域の学習と計算を可能にする。</li>
<li><strong>Web3 技術 (Web3):</strong> ブロックチェーンや分散型台帳技術により、AIが扱うデータと意思決定プロセスに透明性と信頼性を与え、分散化された環境での安全なAI連携を実現する。</li>
<li><strong>核融合エネルギー (Fusion):</strong> ほぼ無限かつクリーンなエネルギー源を提供することで、大規模な計算資源の制約を完全に緩和し、膨大なデータを用いた学習（超大規模モデル）を経済的かつ環境負荷なく実行可能にする。</li>
<li><strong>データインフラ (DataInfra):</strong> 5G/6Gや次世代ストレージ技術が実現する高速・大容量データ処理基盤が、AIのリアルタイムな学習と推論を支える。</li>
</ul>
<p>これらの技術が個別に進化するのではなく、相互に作用し合う（積）ことで、AIはこれまでにないレベルの知性を獲得する。</p>
<h3>■APPLICATION（応用価値：和の力）による社会実装</h3>
<p>性能が飛躍的に向上したAIは、様々な応用領域へ展開され、その価値を社会へ還元する。これらの応用領域は、AIの価値を社会的効用として積み重ねていく（和Σ）役割を担う。</p>
<ul>
<li><strong>Robotics (ロボティクス):</strong> 高度な知性を持つAIが、物理的な世界で活動するロボットと統合され、自動化・遠隔操作・協調作業を飛躍的に進化させる。</li>
<li><strong>MR (複合現実):</strong> AIがMR環境を分析・最適化し、人間とAIが直感的かつシームレスに連携する新たなインターフェースと作業空間を提供する。</li>
<li><strong>Autonomous Driving (自動運転):</strong> 複雑で予測不可能な環境においても、AIがリアルタイムに安全な判断を下し、交通システム全体を最適化することで社会インフラを革新する。</li>
<li><strong>Social Engineering (社会システムへの適用):</strong> 都市計画、医療、教育などの大規模な社会システムにAIが組み込まれ、データの分析と最適化を通じて社会全体の効率と公平性を向上させる。</li>
</ul>
<p>結論として、未来のAIは、基礎技術の「積」によって知性の限界を超え、応用領域の「和」を通じて私たちの生活、産業、そして社会構造そのものを根本から変革するグランドビジョンである。</p>
<p>金融分野でのいわゆる”AIバブル”は、早晩弾ける可能性がある。しかし、AI技術は着実な進歩が予想される。このようなグランドビジョンのもと、人類とAIの未来を創造していただければ幸いである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>富士通、NVIDIA技術で「マルチAIエージェント基盤」公開　機密ワークフローの自動化を狙う</title>
      <link>https://ledge.ai/articles/fujitsu_nvidia_multi_ai_agent_framework</link>
      <description><![CDATA[<p>富士通は2025年12月24日、米NVIDIAとの協業の成果として、Physical AI（物理AI）とAIエージェントをシームレスに連携させる技術「Fujitsu Kozuchi Physical AI 1.0」を開発したと<a href="https://global.fujitsu/ja-jp/pr/news/2025/12/24-02">発表</a>した。あわせて、機密性の高い業務ワークフローをセキュアに自動化するため、NVIDIA技術を活用したマルチAIエージェントフレームワークをはじめとするPhysical AI関連技術を公開した。</p>
<p>同社によると、今回の技術は、2025年10月3日に発表した富士通とNVIDIAの協業における最初の成果に位置付けられる。NVIDIAのソフトウェアスタックと富士通の技術を統合することで、Physical AIとAIエージェントの連携を可能にした点が特徴だという。</p>
<h2>NVIDIA NIMと統合し、保守性とセキュリティを確保</h2>
<p>AIエージェントの適用はこれまで、企業業務の一部にとどまり、部署間や企業間にまたがる複雑な業務ワークフローへの展開は進んでいなかった。富士通はその要因として、機密情報を含む業務データの安全な処理や、ワークフロー全体の保守性の確保が課題になっている点を挙げる。</p>
<p>こうした課題に対応するため、同社はバージョン管理やアップデート機能を備えたNVIDIAの「NIM（NVIDIA NIMマイクロサービス）」と自社技術を統合し、「Fujitsu Kozuchi Physical AI 1.0」を開発した。これにより、AIエージェントが業務ワークフローに含まれる機密情報をセキュアに処理しながら、自動化を進められるとしている。</p>
<h2>マルチAIエージェントフレームワークを提供</h2>
<p>本技術のコア機能として公開されたマルチAIエージェントフレームワークは、ビジュアルな設計インターフェースを用いて業務ワークフローを構築できる点が特徴だ。富士通の「Fujitsu Composite AI」により、同社のAIプラットフォーム「Fujitsu Kozuchi」に搭載されたNIM対応のコア技術や、特化型LLM「Takane」を自動的に組み合わせることで、保守性の高い業務ワークフローを短期間で構築できるという。</p>
<p>また、セキュアエージェントゲートウェイを通じて、企業の機密情報やプライバシー情報を保護しながら、複数のAIエージェントを安全に連携させることが可能だとしている。</p>
<h2>調達業務向けに3種類の特化型AIエージェントを搭載</h2>
<p>第一弾のユースケースとして、富士通は自社LLM「Takane」をベースにした「Fujitsu Kozuchi AI Agent」を搭載した。企業の購買部門における調達業務の自動化・効率化を支援するため、以下の3種類の特化型AIエージェントを開発したという。</p>
<ul>
<li>帳票理解に特化したAIエージェント：複雑な帳票構造を理解し、高精度で構造化データに変換する。</li>
<li>購買規約解析に特化したAIエージェント：購買規約を解析し、適合チェック用のプロンプトを生成する。</li>
<li>適合チェックに特化したAIエージェント：構造化された帳票データとチェック用プロンプトを用いて、規約適合性を自動で判定する。</li>
</ul>
<p>適合チェック後の見積依頼は、セキュアエージェントゲートウェイを介して機密情報の有無を確認した上で、社外の発注先へ送信される仕組みだ。</p>
<h2>社内実証で業務工数50％削減を確認</h2>
<p>富士通は自社の購買部門で実証実験を行い、これら3種類の特化型AIエージェントを活用することで、発注確認業務の工数を約50％削減できることを確認したという。さらに、NIMに対応することで推論速度が約50％向上する見込みで、一日当たり数百件に及ぶ社内規約適合チェック業務の高速化につながるとしている。</p>
<h2>2025年度中に自律進化型AIエージェントへ発展</h2>
<p>今後について富士通は、ソブリン領域を視野に入れ、NVIDIAと協力して本技術を発展させ、2025年度中に顧客環境においてAIが自律的に学習・進化するAIエージェント技術へと進化させる方針を示した。さらに、AIエージェントが物理的なロボットを介して現実世界に直接作用するPhysical AI領域へと順次拡張し、複数のロボットが高度に協調する社会の実現を目指すとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/31 [WED]Google、研究開発の2025年総括を公開　AIは「ツールからユーティリティへ」──8分野のブレークスルーを整理</title>
      <link>https://ledge.ai/articles/google_research_2025_ai_research_breakthroughs_review</link>
      <description><![CDATA[<p>Googleは2025年12月23日、同社の研究開発分野における1年間の進展をまとめた年次レビュー記事を公式ブログで<a href="https://blog.google/technology/ai/2025-research-breakthroughs/#ai-products">公開</a>した。記事は、Google ResearchおよびAI担当シニアフェローの Jeff Dean 氏、Demis Hassabis 氏（Google DeepMind CEO）、研究・技術・社会担当シニアヴァイスプレジデントの James Manyika 氏が連名で解説している。</p>
<p>記事では、2025年を「AIが単なるツールから、実際の仕事を任せられるユーティリティへと移行した年」と位置づけ、基盤モデル、プロダクト、科学研究、計算基盤、社会課題、安全性、そして産官学連携に至るまで、8つの領域にわたる研究開発のブレークスルーを整理している。</p>
<h2>AIは「考え、行動し、探索する」フェーズへ</h2>
<p>レビューの冒頭でGoogleは、2024年がマルチモーダルAIの基盤を整えた年だったのに対し、2025年はAIが人間と並んで「考え、行動し、世界を探索する」段階に入った年だったと総括した。AIだけでなく量子コンピューティングの分野でも、実用化を見据えた進展があったと位置づけている。</p>
<h2>世界トップ級モデルの進展：Gemini 3世代の登場</h2>
<p>2025年の研究成果の中核をなすのが、基盤モデル「Gemini」シリーズの進化だ。Googleは3月に「Gemini 2.5」を、11月に「Gemini 3」を、さらに12月には高速・高効率モデル「Gemini 3 Flash」を相次いで投入した。</p>
<p>Gemini 3 Proは、推論能力とマルチモーダル理解を強化した最上位モデルとして設計され、複数の難関ベンチマークで高い性能を示したとされる。続くGemini 3 Flashは、Pro級の推論能力を維持しながら、低遅延・高効率・低コストを実現したモデルとして位置づけられている。Googleはこれを「次世代のFlashモデルが、前世代のProモデルを上回る」という流れの延長線上にあるものと説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_flash_final_benchmark_table_light_25_12_17_final_582c2ec55d/gemini_3_flash_final_benchmark_table_light_25_12_17_final_582c2ec55d.gif" alt="gemini-3-flash_final_benchmark-table_light_25-12-17_final.gif" /></p>
<h2>オープンモデル「Gemma」も拡張</h2>
<p>クローズドモデルだけでなく、公開・軽量モデルである「Gemma」ファミリーも2025年に大きく進化した。マルチモーダル対応、コンテキストウィンドウの拡張、多言語性能の強化、効率性と性能の向上が進められ、単一のGPUやTPUで実行可能なモデルとしての実用性が高められたという。</p>
<h2>AIエージェントがプロダクトと開発現場へ浸透</h2>
<p>Googleは2025年を、AIが「支援ツール」から「協働するエージェント」へと進化した年とも位置づけている。ソフトウェア開発分野では、コーディングを補助する段階を超え、開発者と並んで作業を進めるエージェント型システムを導入。AI開発基盤「Google Antigravity」は、その象徴的な取り組みとされている。</p>
<p>こうした技術は、Pixel 10のAI機能強化や検索のAI Mode、Geminiアプリ、NotebookLMの「Deep Research」機能など、コンシューマー向けプロダクトにも広く展開された。</p>
<p>@<a href="https://youtu.be/6QeVnO709r0">YouTube</a></p>
<h2>生成メディアとGoogle Labsの実験</h2>
<p>生成AIを活用したクリエイティブ分野も、2025年に大きく前進した。画像生成・編集を担う「Nano Banana」シリーズ、動画生成モデル「Veo 3.1」、画像モデル「Imagen 4」、制作ツール「Flow」や「Music AI Sandbox」などが相次いで更新された。</p>
<p>またGoogle Labsでは、ブランド向け生成AI「Pomelli」、UI設計を自動化する「Stitch」、非同期型コーディングエージェント「Jules」、3Dビデオ通信基盤「Google Beam」など、実験的な取り組みが公開され、ユーザーからのフィードバックを基に改良が進められている。</p>
<h2>科学と数学：AIが研究パートナーに</h2>
<p>科学研究の分野では、AIが研究者を支援する「パートナー」としての役割を強めた。特にたんぱく質構造予測AI「AlphaFold」は公開から5周年を迎え、世界190以上の国・地域で300万人を超える研究者に利用されているという。</p>
<p>そのほか、理論計算機科学を支援する「AlphaEvolve」、医療・ゲノミクス分野での解析AI、研究仮説の生成を支援する「AI co-scientist」などが紹介されている。Geminiの高度な推論機能「Deep Think」は、国際的な数学・プログラミング競技で金メダル相当の成果を達成したとも言及された。</p>
<h2>量子・TPU・ロボティクスと「物理世界」への展開</h2>
<p>計算基盤と物理世界への応用も、2025年の重要なテーマだ。量子コンピューティングでは、実用化を見据えたアルゴリズム「Quantum Echoes」が紹介され、関連研究に携わったGoogleの研究者がノーベル物理学賞を受賞したことにも触れている。</p>
<p>AIインフラでは、推論時代に最適化した新TPU「Ironwood」を発表。設計にはAIを用いたチップ設計手法「AlphaChip」が活用され、エネルギー効率や環境影響の測定にも取り組んだとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Ironwood_superpod_width_1000_format_webp_7a1859d68c/Ironwood_superpod_width_1000_format_webp_7a1859d68c.webp" alt="Ironwood_superpod.width-1000.format-webp.webp" /></p>
<p>さらに、ロボティクス分野では「Gemini Robotics」や「Gemini Robotics 1.5」、汎用的な世界モデルとして「Genie 3」を発表し、AIエージェントを物理・仮想の両世界に展開する構想を示した。</p>
<p>@<a href="https://www.youtube.com/watch?v=PDKhUknuQDg">YouTube</a></p>
<h2>気候・医療・教育など社会課題への適用</h2>
<p>Googleは、AIを用いた科学的進展が社会課題の解決に直結し始めている点も強調した。洪水予測システムは、150カ国以上・20億人超をカバーする規模に拡大。高速・高精度な気象予測モデル「WeatherNext 2」や、地理空間AI「Google Earth AI」、山火事早期検知システム「FireSat」などが紹介されている。</p>
<p>医療分野では、診断から治療までを支援するAI、教育分野では「LearnLM」やGeminiを活用した学習支援、翻訳機能の高度化などが進められた。</p>
<p>@<a href="https://blog.google/technology/ai/2025-research-breakthroughs/#safety-responsibility">YouTube</a></p>
<h2>産官学連携でフロンティアを前進</h2>
<p>レビューの終盤では、フロンティアAIの発展には社会全体での連携が不可欠だと強調されている。Googleは、複数のAI研究機関と連携して「Agentic AI Foundation（AAIF）」の形成を支援したほか、Model Context Protocol（MCP）をGoogleの各種サービスに対応させた。</p>
<p>また、米エネルギー省および国立研究所との共同研究、大学や教育機関との連携、映像制作者や音楽家との協働など、多方面でのパートナーシップが紹介されている。</p>
<p>Googleはこの年次レビューを通じ、2025年を「研究成果を現実のプロダクトや社会的価値へと転換した年」と総括した。2026年に向けては、安全性と責任を重視しながら、AIと科学のフロンティアをさらに押し広げていく姿勢を示している。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>多様なプロンプトでも最終的に「灯台」「大聖堂」へ？──画像生成AIで700件の“自律ループ”が12類型に収束する可能性</title>
      <link>https://ledge.ai/articles/image_generation_ai_autonomous_loop_converges_12_styles</link>
      <description><![CDATA[<p>画像生成AIは、多様で自由な表現を生み出せる技術として注目されている。しかし、AI同士が自律的に生成と評価を繰り返す環境では、その多様性が徐々に失われ、最終的に似通った表現へ収束する可能性が示された。</p>
<p>スウェーデンの研究者らは、画像生成AIと画像説明AIを組み合わせた「自律ループ」を用いた大規模な実験を行い、生成結果が最終的にわずか12種類の視覚スタイル（モチーフ）に集約される傾向を確認した。研究成果は、Cell Pressの学術誌『Patterns』に<a href="https://www.cell.com/patterns/pdf/S2666-3899%2825%2900299-5.pdf">掲載</a>された。</p>
<h2>画像生成と説明を繰り返す「自律ループ」を構築</h2>
<p>研究チームが用いたのは、テキストから画像を生成する拡散モデルと、生成された画像を自然言語で説明する視覚言語モデルを組み合わせた閉ループ構成だ。具体的には、テキストプロンプトから画像を生成し、その画像を別のAIが説明文に変換し、その説明文を次の生成プロンプトとして再び画像を生成する、という工程を自律的に繰り返す。</p>
<p>この「テキスト→画像→テキスト→画像…」という循環は、人間の介入を介さずにAI同士だけで進行する点が特徴で、研究ではこれを“自律ループ”と呼んでいる。</p>
<h2>初期プロンプトは意図的に多様化</h2>
<p>実験では、初期条件の偏りを避けるため、埋め込み空間上で互いに離れた位置に配置されるよう設計された100種類の初期プロンプトを用意した。それぞれのプロンプトは1文30語以下に制限され、内容的にも視覚的にも多様性を確保するよう設計されている。</p>
<p>この初期プロンプトを起点に、温度パラメータを変えながら最大100ステップの自律ループを実行し、合計700件の生成軌跡が分析対象となった。</p>
<h2>反復の末に見られた「意味の漂流」と収束</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Figure_2_Example_trajector_75356cd0d4/Figure_2_Example_trajector_75356cd0d4.jpg" alt="Figure 2_Example trajector.jpg" />
画像生成と説明をAI同士で繰り返すと、内容は初期プロンプトから離れ、豪奢な室内空間など“無難な構図”へと漂流していく（論文Figure 2より）</p>
<p>分析の結果、すべての条件において、生成内容は初期プロンプトから急速に乖離していく傾向が確認された。この現象について研究チームは、反復生成の過程で意味や構図が変質していく「意味ドリフト（semantic drift）」が生じていると説明している。</p>
<p>さらに反復を続けると、生成結果は次第に安定し、特定の視覚的特徴を持つ状態へと収束していった。最終段階のプロンプト表現をクラスタリングしたところ、700件すべてを統合すると、最適なクラスタ数は12に集約されることが示された。</p>
<h2>最終的に現れた12の視覚モチーフ</h2>
<p>論文によると、収束先として現れた12のモチーフには、以下のような特徴的な題材が含まれている。</p>
<p>・海辺に立つ灯台
・ゴシック様式の大聖堂や荘厳な宗教建築の内部
・宮殿のような豪奢な室内空間
・夜景を伴う都市風景
・牧歌的な村や田園の情景
・劇的な照明で演出された自然や動物
・家庭的な食卓や生活空間　など</p>
<p>これらはいずれも、商業画像やストックフォトで頻繁に見られる、視覚的に「無難」で魅力的な構図である点が共通している。</p>
<p>研究チームはこの現象を、刺激の少ない音楽が繰り返される「エレベーターミュージック」になぞらえ、「visual elevator music（視覚的エレベーターミュージック）」と表現している。</p>
<h2>モデル構成を変えても同様の傾向</h2>
<p>研究では、使用するモデルの組み合わせを変えた追加検証も行われた。
複数の画像生成モデルと複数の画像説明モデルを組み合わせた実験でも、程度の差こそあれ、最終的には似た視覚モチーフへの収束が観察されたという。</p>
<p>統計分析の結果、意味ドリフトへの影響は画像生成モデルよりも、画像を言語化する側のモデルが大きいことも示されている。</p>
<h2>自律的なAI運用への示唆</h2>
<p>研究チームは、本研究の結果が示すのは「画像生成AIの創造性の限界」ではなく、「AI同士が閉じた環境で反復的に生成を行う運用形態のリスク」だと指摘する。</p>
<p>人間の介入がない自律ループでは、意図せず表現が画一化していく可能性があり、今後、エージェント型AIや自律的コンテンツ生成システムを設計する際には、多様性を維持する仕組みが重要になるとしている。</p>
<p>研究で用いられた生成プロセスや分析コード、プロンプト設計の方法は、オープンサイエンス基盤を通じて公開されている。
研究チームは、同様の現象が他のモデル構成や生成タスクでも起きるかどうか、今後の検証を呼びかけている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「知能爆発」へ“10年以内”の現実味──オックスフォード大の哲学者マッカスキル（MacAskill）氏らの警告、AIが「数年で1世紀分」の技術進歩を起こし得る</title>
      <link>https://ledge.ai/articles/intelligence_explosion_10_years_warning</link>
      <description><![CDATA[<p>オックスフォード大学の哲学者Will MacAskill氏とFin Moorhouse氏は2025年3月に公開した論文「<a href="https://arxiv.org/abs/2506.14863">Preparing for the Intelligence Explosion（知能爆発への備え）</a>」で、人間よりはるかに賢いAIが今後10年以内に登場する「十分に現実的な可能性（serious chance）」があると指摘した。</p>
<p>AIが研究開発そのものを加速した場合、技術進歩が「数年で1世紀分（a century in a decade）」に相当する速度で進む可能性がある一方、その過程では社会にとって不可逆で重大な意思決定が短期間に連続して発生し得るとして、今から多面的な準備（AGI Preparedness）を進める必要があると論じている。</p>
<h2>研究努力の主役が人間からAIへ移りつつある</h2>
<p>論文は、近年の生成AIと計算資源の拡大により、研究努力（research effort）の成長率が人間の認知的研究努力を大きく上回り始めている点に注目する。AIは単なる作業補助にとどまらず、仮説生成、実験設計、コード作成、評価といった研究工程そのものを担い始めており、研究の“量”と“速度”が同時に拡張される局面が到来しつつあるという。</p>
<p><strong>■ AIによる研究努力は年率で急拡大し、人間の認知的研究努力の成長率を大きく上回り始めている。論文は、この非対称な成長が技術進歩の時間軸を大幅に圧縮し得ると指摘する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Human_vs_AI_research_wide_2985231073/Human_vs_AI_research_wide_2985231073.jpg" alt="Human_vs_AI_research_wide.jpg" /></p>
<h2>「研究をするAI」が技術進歩を自己加速させる可能性</h2>
<p>MacAskill氏らが想定する鍵は、AIが研究を行う主体になることによるフィードバックループだ。研究を自動化・加速するAIが、より高性能なAIの設計や評価に寄与すれば、ソフトウェア中心の自己増幅的な進歩が生じる可能性がある。論文は、こうした条件がそろった場合、物理的制約（人員や時間）に縛られない形で研究能力が拡張され、進歩速度が非連続に跳ね上がり得ると述べる。</p>
<p><strong>■ 推論用計算資源の拡大と推論効率の改善が重なれば、同時に稼働するAI（AI population）が急増し、研究・開発に投入される総知能が飛躍的に拡大する可能性がある</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_population_wide_2_a387a34cd7/AI_population_wide_2_a387a34cd7.jpg" alt="AI_population_wide_2.jpg" /></p>
<h2>最大級の学習規模がもたらす非連続な性能向上</h2>
<p>論文はまた、最大規模の学習（training run）のスケーリングにも言及する。今後、電力やコストなどの制約に直面するまでの間、学習規模の拡大が性能の段差的向上をもたらす局面があり得るとする。これに研究自動化が重なれば、技術的ブレークスルーが短期間に集中する可能性がある。</p>
<p><strong>■ 過去のモデルと比較した最大規模の学習実行の拡大イメージ。論文は、一定期間は学習規模の拡張余地が残っていると指摘する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/scaling_the_biggest_training_run_21a215692d/scaling_the_biggest_training_run_21a215692d.jpg" alt="scaling the biggest training run.jpg" /></p>
<h2>「アラインメントだけ」では不十分という問題提起</h2>
<p>MacAskill氏らは、AIが人間の意図に沿って振る舞うかというアラインメント問題の重要性を認めつつも、それだけに備えを限定することは不十分だと指摘する。理由の一つは、不可逆な意思決定が、完全に整合した超高度AIが確立する前に訪れる可能性があるためだ。</p>
<p>論文が例示する「grand challenges」には、次のような領域が含まれる。</p>
<ul>
<li>新型の破壊的技術や兵器の出現</li>
<li>AIによる権力集中や権威主義的統治の強化</li>
<li>宇宙資源など新たなフロンティアをめぐる競争</li>
<li>道徳的配慮の対象となり得るデジタル存在の扱い</li>
</ul>
<p>これらは一度決定されると後戻りが難しく、「将来のより賢いAIに判断を委ねればよい」という対応が取れない局面が生じ得るとされる。</p>
<h2>論文が示す「今からの備え」</h2>
<p>こうした前提から、論文はAGI Preparednessとして、技術・制度・社会を横断する準備の必要性を挙げる。具体的には、</p>
<ul>
<li>極端な権力集中を防ぐためのインフラや統治構造の設計</li>
<li>政府や公共部門が高度AIを適切に活用できる体制整備</li>
<li>集合意思決定を支援するAIツールの開発と運用</li>
<li>新領域（宇宙資源、デジタル存在など）に関する制度設計</li>
</ul>
<p>といった論点を、アラインメント研究と並行して進める必要があると整理している。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>基盤モデルとの融合はロボットに何をもたらすのか——現在地と未来への展望</title>
      <link>https://ledge.ai/articles/interview_Kawaharazuka</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>人工知能の知性が宿る抽象的なデータ空間と、ロボットが動く物理的な現実世界。これまで別々の進化を遂げてきた二つの領域が今、急速に融合しようとしている。人間のように思考し、対話し、そして行動するロボット——そんなSFの世界が、いよいよ現実のものになるのではないかという期待が、社会全体を包み込んでいる。</p>
<p>しかし、この技術的変革の波の中で、何が現実で、何がまだ遠い夢なのだろうか。本記事では、ロボティクスとAI研究の第一線で活躍する河原塚健人氏を水先案内人として迎え、その鋭い洞察を紐解いていく。</p>
<h2>ロボットの「知能」革命：基盤モデルはいかにしてロボットを変えたか</h2>
<p>基盤モデルの登場は、単にロボットの性能を向上させただけではない。それはロボットの「知能」の構造そのものに、これまでの開発とは一線を画す根本的な変化をもたらした。この革命の本質を理解するために、まずはロボットが行動に至るまでのプロセスを見ていこう。</p>
<p>ロボットの行動は、大きく分けて以下の3つの段階で構成されている。</p>
<ul>
<li><strong>認識：</strong> センサーを通じて周囲の状況を理解する。</li>
<li><strong>計画：</strong> 認識した状況に基づき、次に何をすべきかを決める。</li>
<li><strong>制御：</strong> 計画に従って、モーターなどを動かし、身体を具体的に動かす。</li>
</ul>
<p>このプロセスの中で、基盤モデルは特に「認識」と「計画」の能力を飛躍的に進化させた。その最大の原動力となったのが、「言語」を扱えるようになったことだ。</p>
<p>従来、ロボットに「ドアが開いている」と認識させるには、深度センサーで取得した三次元の点群データを解析し、目の前にドアの形状が存在するかどうかをプログラムで判断させるなど、人間が地道にルールを記述する必要があった。</p>
<p>しかし、基盤モデルはインターネット上の膨大なテキストと画像のデータを学習することで、人間のような曖昧で高度な状況認識能力を獲得した。「ドアが半開きになっている」といった微妙な状態や、「玉ねぎがあめ色に炒まってきた」といった、感覚的で言語的な表現を理解できるようになったのだ。これは、ルールベースの手法では到底到達できなかった領域であり、まさしくパラダイムシフトと呼ぶにふさわしい。</p>
<p>ただ「制御」については、依然として基盤モデルが苦手とする領域だ。その理由は、後述する「なぜバク転は簡単で、ジャガイモの皮むきは難しいのか」という、一見パラドックスにも思えるような事実からも紐解ける「タスクの複雑性と相互作用」にある。ジャガイモの皮むきのようなタスクは、不揃いな対象物、力の加減、予測不可能な変形といった、環境との絶え間ない相互作用とフィードバックが必要となる。この現実世界との複雑なインタラクションこそが、「制御」の精度を上げるにあたって技術的なボトルネックとなっているのだ。</p>
<h2>特化型ロボットと汎用型ロボット</h2>
<p>現在のロボット開発は二つの大きな潮流に分かれている。一つは「特定のタスク」を完璧にこなす特化型ロボット。もう一つは、人間のように「何でもこなす」ことを目指す汎用ロボットだ。現在のLLMによる「認識・計画」の進化は特化型ロボットの性能を飛躍的に向上させたが、人間のようになんでもこなせる真の汎用性の実現は、複雑な制御という壁により、依然として道の途中にある。</p>
<h3><strong>特化型タスク：完成は「時間の問題」</strong></h3>
<p>特定の作業に限定すれば、ロボット技術は驚異的な進歩を遂げている。河原塚氏は、強化学習や模倣学習といった技術と基盤モデルが組み合わさることで、「特定のタスクはほとんど何でもできるようになった」と評価する。</p>
<ul>
<li><strong>歩行・走行（ロコモーション）：</strong> 現代の四足歩行ロボットは、どんな悪路でも転ばず、高い壁を乗り越え、さらにはバク転さえもこなす。これは強化学習によって、あらゆる状況に対応できる頑健な制御能力を獲得した成果だ。</li>
<li><strong>操作（マニピュレーション）：</strong> かつては非常に困難とされた「服をたたむ」といった複雑な作業も、人間がお手本を見せる模倣学習によって実現可能になった。ロボットはスポンジのようにデータを吸収し、教えられたタスクを高い精度で再現できる。</li>
</ul>
<p>河原塚氏は、これらの特化型タスクの完成はもはや「時間の問題」であると考えているという。特定の作業を人間に代わって行うロボットは、着実に社会実装へと向かっている。</p>
<h3><strong>汎用型タスク：「まだ全然解けていない」壮大な挑戦</strong></h3>
<p>一方で、人間のようにあらゆるタスクに対応できる汎用ロボットへの道のりは遥かに険しい。この領域について、河原塚氏は「まだ全然解けていない」と率直に評価する。発表される華々しいデモンストレーションも、「まだまだ大きく課題は残っている、というのが正直なところです」との見方を示す。</p>
<p>その課題の本質は、現在のVLA（Vision-Language-Action）モデルの限界にある。これらのモデルは、膨大な学習データに含まれるタスクやそれに類似したタスクを再現することには長けている。しかし、完全に未知の状況への対応は難しい。</p>
<p>「ハサミを一度も使ったことがないロボットに『ハサミを使え』と言っても、絶対に使えるようにはならない」。現在の汎用ロボットは、あくまで学習データの範囲内で動いているに過ぎず、真の汎用性には程遠い。
では、この汎用性を実現するために、現代のロボットに決定的に欠けているものは一体何なのだろうか。</p>
<h2>現代のロボットに欠けている「人間らしさ」とは</h2>
<p>汎用ロボットの実現を阻む壁は、単なるデータ量や計算能力の問題ではない。その根源には、より本質的な「学習能力」の欠如があると河原塚氏は指摘する。人間が当たり前のように持つ、しかし現代のAIにはない「人間らしさ」とも言える2つの能力が、その鍵を握っている。</p>
<h3><strong>欠落要素1：動的に適応する能力</strong></h3>
<p>現在の基盤モデルは、いわば「完成品」として提供される静的な存在だ。膨大なデータを一度学習したら、その後は一切進化しない。デプロイされた後に未知の状況に遭遇し、タスクに失敗しても、そこから学ぶことはできない。「できなかったら、できないまま」なのだ。</p>
<p>これに対し、人間は絶えず世界と相互作用しながら学び続ける。未知の状況に遭遇すれば、「とりあえずやってみて、失敗から学び、その知識を次に活かす」。この「動的な適応性」こそが、人間と現在のAIを分かつ決定的な違いだ。河原塚氏はこの動的な学習能力こそが、汎用ロボットが獲得すべき最も重要な力であると強調する。</p>
<h3><strong>欠落要素2：自ら学ぶ好奇心</strong></h3>
<p>また、ただ未知の状況に対応するだけでは不十分だ。真の汎用性には、ロボット自身が能動的に学習しようとする姿勢が求められる。つまり、「自分に何ができないか」を自己認識し、それを克服するために積極的に情報を集めに行く、いわば「好奇心」のような存在が必要だ。</p>
<p>これは専門的には「アクティブラーニング」と呼ばれるアプローチに近い。指示されたタスクをこなすだけでなく、自らの知識の空白を埋めようと世界を探求する力。この内発的な動機がなければ、無限に広がる現実世界の複雑さに対応することは不可能だろう。</p>
<p>このような人間とロボットの根本的な能力の違いは、我々が直感的に感じる「タスクの難しさ」にも、大きな隔たりを生んでいる。</p>
<h2>なぜバク転は簡単で、ジャガイモの皮むきは難しいのか</h2>
<p>この汎用性への挑戦の困難さを理解するには、まず我々人間が持つ「難しさ」の物差しを一旦脇に置く必要がある。河原塚氏が指摘するように、ロボットの世界では、我々の直感とは真逆の物理法則が支配しているのだ。この現象は「モラベックのパラドックス」として知られており、ロボット技術の現状を正しく把握する上で極めて重要な視点となる。</p>
<h3><strong>バク転＝人間には至難、ロボットには「めちゃくちゃ簡単」</strong></h3>
<p>ほとんどの人間にとって、バク転は習得困難な技のように感じられる。しかし、ロボットの視点から見ると、これは「めちゃくちゃ簡単な」なタイプに分類されるのだという。</p>
<p>その理由は、物理モデル化の容易さにある。ロボットが空中にいる間の身体の動きは、物理法則に従う「剛体の回転運動」に過ぎず、非常に正確にモデル化できる。そのため、「モデル予測制御」という手法を用いて、目標とする着地点から逆算し、手足の動きを精密にコントロールすることが可能なのだ。環境との相互作用が限定的であるため、計算上の問題として解きやすいのである。</p>
<h3><strong>料理＝人間には容易、ロボットには「とんでもなく難しい」</strong></h3>
<p>対照的に、人間が日常的に行う料理、例えば「ジャガイモの皮をむく」といった作業は、ロボットにとっては「とんでもなく難しい」のだそうだ。</p>
<p>その理由は、前述したように環境との複雑で予測不能な相互作用にある。ロボットは、自分自身の身体（関節の角度やモーターの硬さなど）については完璧なモデルを持っている。しかし、外部環境については、ほぼ知識を持ち合わせていない。ジャガイモが硬いか柔らかいか、ツルツル滑るか否かは、実際に触ってみるまで分からない。皮むき器という道具をどう握り、どれくらいの力で、どの角度で当てればよいのか。これらの無数の変数は、事前にモデル化することが困難なのだ。</p>
<p>バク転よりもジャガイモの皮むきが難しいというこの現実こそが、ロボット開発における最も根源的な制約——すなわち『環境との相互作用』を浮き彫りにする。そしてこの制約こそが、来るべき汎用ロボットの『形』を必然的に規定していくことになる。</p>
<h2>ヒューマノイドという必然：なぜ未来のロボットは「人間型」になるのか</h2>
<p>SF映画に登場するようなヒューマノイド（人間型）ロボット。それは単なる創作上の産物や、人々の目を引くためのプロモーション戦略なのだろうかとも思いがちだが、そうではない。汎用ロボットが人間型になるのは、現代のAI開発が直面する課題から導き出される、極めて論理的で必然的な帰結なのだ。その理由は、大きく3つある。</p>
<h3><strong>1. 圧倒的なデータ不足の問題</strong></h3>
<p>ロボットの知能、特にVLAモデルを学習させるには、膨大な量の「行動データ」が必要となる。しかし、ロボット自身が生み出したデータは、世界にほとんど存在しない。この絶望的なデータ不足を解決する最も現実的な方法が、インターネットの動画共有サイトなどに無限に存在する「人間の動画データ」の活用だ。人間が何かを操作したり、歩き回ったりする映像は、ロボットにとって最高の教科書となりうる。この人間のデータを最大限に活用するためには、ロボットの身体構造が人間に近い方が、学習の転移が圧倒的に容易になる。</p>
<h3><strong>2. 人間中心に設計された環境の問題</strong></h3>
<p>我々が暮らす世界のあらゆるものは、人間の身体に合わせて設計されている。階段の段差、ドアノブの高さ、ハサミやドライバーといった道具の形状。これら全てが、人間の身体を前提としている。この人間中心の環境で効率的に活動するためには、ロボットもまた人間と同じ身体構造を持つことが最も合理的なのである。車輪型ロボットが階段を上れないように、環境がハードウェアの形状を規定するのだ。</p>
<h3><strong>3. 基盤モデルそのものが持つ人間中心性</strong></h3>
<p>基盤モデルの知能もまた、人間中心に構築されている。LLMが扱う「右手」「左足」といった言語は、人間の身体性を前提とした概念だ。画像認識モデルが学習するデータも、その大半は人間の視点から撮影されたものである。「アリの視点」で撮影された画像データはほとんど存在しない。基盤モデルの性能を最大限に引き出すためには、モデルが学習した世界観の前提（＝人間の身体）に近いハードウェア、すなわち人間型ロボットが不可欠となる。</p>
<p>つまり、未来のロボットが人間型になるのは、我々の模倣から学ぶ『ソフトウェア』、我々が作った世界で動く『ハードウェア』、そして我々の知性を拡張した『AI』という、三重の制約が導き出す必然なのである。
ただし、この「人間型への収斂」は、あくまで人間社会で活動する汎用ロボットに限った話である点には注意が必要だ。河原塚氏が指摘するように、人間が必ずしも最適ではない「災害救助」のような過酷な環境ではキャタピラ型が優れていたり、特定の製造ラインでは多関節アームが合理的であったりと、タスクに応じて最適なロボットの形態は多様であり続けるだろう。</p>
<h2>研究室からリビングへ：社会実装への険しく不確かな道のり</h2>
<p>技術的なブレークスルーが達成されたとしても、ロボットが研究室から我々のリビングへとやってくるまでには、ビジネスモデル、コスト、そして社会受容性という、分厚く現実的な壁がいくつも立ちはだかっている。最近では、家庭用のヒューマノイド型ロボットの展開もリリースが発表されるなど、一般家庭にヒューマノイド型ロボットが徐々に入り込み始めている。たとえまだ求めるレベルに至っていなかったとしても、先行事例として実際の家庭環境に入ることで、研究開発に「圧倒的に不足している実世界のデータ」を収集できる可能性がある。それが次のブレークスルーの起爆剤になるかもしれないのだ。</p>
<p>この議論は、日本のロボット開発が置かれた状況にも繋がる。ハードウェア開発で世界に遅れをとっている日本だからこそ、「とにかく作って試してみるべきだ」と河原塚氏は提言する。研究開発の「火を絶やさない」こと。それこそが、深刻な人手不足という社会課題を抱える日本にとって、未来を切り拓くための極めて重要な戦略となる。</p>
<p>未来がどうなるか誰にも予測できないからこそ、多様な可能性を探求し続ける。その姿勢こそが、ロボット研究分野全体に、そしてこれからの社会を考える我々一人ひとりに求められているのかもしれない。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIの過去・現在・未来を貫く知の探求：甘利俊一博士に聞く、理論の力と”意識・ひらめき”の謎</title>
      <link>https://ledge.ai/articles/interview_prof_amari</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>シリコンバレーが生成AIの熱狂に沸き、大規模言語モデル（LLM）が世界の風景を一変させようとする今、その喧騒から遠く離れた日本の大学や研究機関の一室で、数十年にわたり静かに紡がれてきた理論の系譜がある。この革命的なテクノロジーの根幹をなす学習原理が、実は半世紀以上も前に一人の日本人研究者の手によって築かれていたという事実は、一般にはあまり知られていない。
　その人物こそ、数理工学者であり、情報科学の世界的権威である甘利俊一博士だ。彼の探求は、今日のAIを支えるアルゴリズムの原型に留まらない。情報や統計が織りなす世界を「幾何学」として捉えるという新しい学問分野「情報幾何学」を創出し、さらにはAIの最終目標ともいえる「意識」や「ひらめき」といった、人間の知性の最も深遠な謎にまで及ぶ。
　本記事は、甘利博士への独占インタビューを基に、AI研究の黎明期から現代LLMが抱える課題、そして知性の未来までを縦断する、壮大な知の旅路である。それは、AIという鏡を通して、私たち自身の知性の本質を再発見するプロセスに他ならない。</p>
<p>※インタビューは2025年10月30日に東京都文京区本郷で行われた。</p>
<h2>1. ニューラルネットワークの黎明期：時代に先駆けた原理の発見</h2>
<p>現代AIの中核、深層学習。その膨大なネットワークがデータを学習し賢くなるための基本原理が、驚くべきことに1970年前後、甘利先生によってすでに考案されていた。それは、AIの歴史における「創世記」であり、その後の研究の潮流を決定づける歴史的な一歩であった。</p>
<p>甘利先生が1967年に提示した「確率的勾配降下法」は、今日のAIが学習を行う際の最も基本的な考え方そのものである。現在広く知られる「バックプロパゲーション（誤差逆伝播法）」との関係について、甘利氏はこう語る。</p>
<p>\u003E甘利先生
「基本は確率的勾配降下法なんです。それを具体的に、例えば（ニューラルネットワークの）層がいっぱいあったらどう計算したらいいか、というのをやったのがバックプロパゲーション。計算法としては面白いけれど、原理的には私のやつでほぼ完成しているんです。」**</p>
<p>つまり、甘利先生が確立したのが「誤差を減らす方向にパラメータを少しずつ調整する」という基本原理であり、バックプロパゲーションはその原理を多層構造のネットワークで効率的に計算するための具体的な手法だ。</p>
<p>さらに先生の先見性は、1972年の「連想記憶モデル」にも表れている。これは、10年後に物理学者ジョン・ホップフィールドが発表し一世を風靡した「ホップフィールド・モデル」と本質的に同じものだった。だが甘利先生のモデルはさらに先を見据え、静的な連想だけでなく時系列の記憶、例えば「百人一首で上の句を言えば下の句が出てくる」といった動的な連想の仕組みまでをも内包していた。これは現代のAIが扱うシーケンシャルデータの処理を予見するものであった。</p>
<p>当時、AI研究は二つの潮流に分かれていた。マービン・ミンスキーらが主導し、知性を記号と論理の操作と捉える <strong>「記号・論理」</strong> 派と、フランク・ローゼンブラットらが提唱し、脳の神経回路網を模倣する <strong>「神経回路網」</strong> 派だ。両者の対立と成果の停滞は、AIの「冬の時代」を招きつつあった。</p>
<p>この停滞を打ち破ったのが、甘利先生の発想の転換だった。当時の研究者はニューロンを「0か1かで動作するデジタルな論理素子」と見ていた。これでは、重みを少し変えても出力は突然反転するまで変化せず、どこを修正すればよいか分からない。甘利先生はこれを覆し、ニューロンを「連続的に変化するアナログな素子」として捉え直した。先生の言葉は、このブレークスルーの本質を鮮やかに描き出す。</p>
<p>\u003E甘利先生
「途中の重みをちょっと変えると、最後の答えもちょっと変わる。全部アナログの世界だから連続なんです。それならば、微分を使えばいい。全体の（誤差）関数をこのパラメータ（重み）で微分したもの、それが勾配です。勾配に従ってエラーが減る方向に少しずつ動かしていけば、良くなるはずではないか。」</p>
<p>この「アナログ」という視点こそが、微分（勾配）を用いて学習を進めるという、現代AIの根幹をなす手法を可能にした核心であった。この革新は、電気や機械といった個別の分野に囚われず、「数理」という普遍的な視点で現象を横断的に捉える、甘利先生の学問的背景「数理工学」の精神から生まれた。そして、まさにこの同じ精神が、全く新しい学問分野の創設へと繋がっていく。</p>
<h2>2. 情報幾何学の誕生：世界を捉える新たな「幾何」</h2>
<p>甘利先生の独創性を最も象徴するのが、先生自身が創始した**「情報幾何学」** だ。これは単なる数学理論ではない。確率分布やニューラルネットワークといった、形のない「情報」の世界に「幾何学」という形と構造を与え、その内部を探索するための地図とコンパスを提供するという、画期的な試みであった。</p>
<p>その着想は、大学院時代に遡る。あるセミナーで出会ったカルバックの著書『統計と情報』が全ての始まりだった。2つの確率分布の違いを示す「カルバック・ライブラー・ダイバージェンス」という概念に触れた甘利先生は、この「違い」を2点間の「距離」と捉え、確率分布の集合体そのものを一つの「空間」として研究しようと考えた。</p>
<p>情報幾何学の核心は、「確率分布のなす空間は、ユークリッド空間のように平坦ではなく、歪んだ『曲がった空間』である」という洞察にある。これはアインシュタインの一般相対性理論とのアナロジーで理解できる。相対性理論では、質量が周囲の時空を曲げ、その歪みが重力となる。同様に、情報幾何学では、情報の構造そのものが空間を曲げると考えるのだ。この「曲がった情報空間」の性質を解き明かす鍵は、以下のポイントにある。</p>
<ul>
<li><strong>フィッシャー情報行列</strong>   非常に近い2つの確率分布間の「カルバック・ライブラー・ダイバージェンス」を計算すると、1次の項は打ち消し合い、2次の項だけが残る。この2次の項こそが「フィッシャー情報行列」であり、曲がった空間の「計量（物差し）」、すなわちリーマン計量の役割を果たす。この物差しによって初めて、情報空間における最短の学習経路を正しく測ることができるのだ。</li>
<li><strong>負の定曲率空間</strong> 　甘利先生が試しに、最も基本的な正規分布のなす空間の形を計算したところ、驚くべき結果が得られた。それは「至るところで一定の負の曲率を持つ、非常に美しい空間」だった。先生自身の身振りで説明するように、それは「ある方向には下に曲がり、別の方向には上に曲がっている」ような、複雑だが極めて規則的な構造をしていた。</li>
<li><strong>美しさへの確信</strong> 　当時、この計算結果が具体的に何を意味するのかは分からなかった。しかし甘利先生は「綺麗なものには意味がある」と直感した。この数学的な美しさへの確信が、具体的な応用が見えない時代から、このテーマを長年温め続ける原動力となった。 　 　この一見抽象的な幾何学の理論が、数十年後、現代の深層学習が抱える根源的な問題を解き明かす鍵となる可能性を秘めていることが、今まさに明らかになろうとしている。</li>
</ul>
<h2>3. 情報幾何学から現代AIへ：深層学習の謎に迫る</h2>
<p>情報幾何学は、なぜ今、LLMをはじめとする最先端AIの理論的解明に不可欠なのか。それは、現代の深層学習が「なぜこれほどうまく機能するのか」という根本的な問いに、誰も明確な答えを出せていないからだ。この理論なき技術の先行という現状は、印象的な成果を生む一方で、脆く非効率な技術基盤を生み出している。甘利先生の理論は、そのブラックボックスの深淵に光を当てる可能性を秘めているのだ。</p>
<p>甘利先生の分析によれば、深層学習が探索する「パラメータ空間」（ニューラルネットワークの膨大な重みの組み合わせが作る空間）は、我々が直感するような素直な空間ではない。先生が探求し始めた優美な多様体とは異なり、それは遥かに凶暴で複雑な領域なのだ。</p>
<p>\u003E甘利先生
「パラメータがこの値と全然違う値とで、ほとんど同じ動作をする。違う点が実はくっついて近くに来てしまう…そこが1点に縮んで『特異点』になるんです。そして、そういう特異点がものすごくたくさん、網の目のようになっている。」</p>
<p>この「特異点が網の目のように存在する」空間では、通常の微分幾何学は役に立たない。甘利先生は、この構造を解明するためには、特異点を扱う「代数幾何学」のような、より高度な数学が必要だと指摘する。情報が持つ地理的性質という彼の根本的な直観は正しかったが、その地形は標準的な幾何学では踏破できないほど複雑だったのだ。</p>
<p>\u003E甘利先生
「現在のLLMは「技術が理論を先行している」状態にある。理論的な解明が急務なのは、真の理解が得られれば、その先に広がる未来が大きいからです。理論で物事が分かってくれば、今のトランスフォーマーとは違う、もっとパラメータが少なくて済むものができるのではないか。そうでなければ、もう電力がもたない。」</p>
<p>AIの理論的解明は、計算効率の問題に留まらない。それは、人間の知性の根源とは何か、という究極の問い、すなわち「意識」や「ひらめき」の問題へと私たちを導いていく。</p>
<h2>4. 計算の先にあるもの：『意識』と『ひらめき』への探求</h2>
<p>AIの能力が人間を凌駕しつつある現代、私たちは根源的な問いに直面している。「意識」や「ひらめき」といった人間性の核が、AIに宿る日は来るのだろうか。</p>
<p>まず甘利先生は「意識」を明確に定義する。それは情報の統合だけではない。一部の研究者が提唱するように、情報の統合量（Φ）そのものが意識であり「単純なシステムにも低いレベルの意識がある」という考え方に対し、甘利先生は異を唱える。彼にとって意識とは、「自分が今やろうとしていることを自覚し、実行する前にその計画を吟味できる機能」である。脳が素早く見つけ出した行動計画をすぐ実行せず、一度立ち止まり、自らの答えを客観的に評価する。この自己言及的な評価ループこそが意識なのだ。</p>
<p>そして、「意識」と「ひらめき」は明確に区別されるべき、より高次の機能だと続ける。</p>
<p>\u003E甘利先生
「”ひらめき”とは、長期間の無意識下での思考の末に訪れる、既存の枠組みを超えた飛躍です。それは、全く新しい概念体系そのものを”発明”する創造的な行為だ。ケプラーが惑星運動の法則（楕円軌道）を<strong>発見</strong> したのに対し、ニュートンは「なぜそうなるのか」を説明するために「力・質量・加速度」という全く新しい概念体系（力学）を<strong>発明</strong> した。これこそが”ひらめき”の真髄です。」</p>
<p>この文脈で考えると、現在のLLMの限界は明らかだ。LLMは膨大なデータに基づく「統計的推論」には長けているが、厳密な「論理的推論」は苦手だ。そして何よりも、訓練データの概念的枠組みの中でしか動作できないため、原理的に「ひらめき」の機能を持っていない。</p>
<p>では、AI研究の未来の役割とは何か。それは人間の代替ではない。むしろ、AIは「人間の知性とは何か」を理解するための強力なツール（鏡）になるという。</p>
<p>\u003E甘利先生
「（LLMに）すごいことができるという事実を、逆に人間の方にフィードバックして、では人間はどうやっているのかを考える。その両方の交流が、これからはもっと進んでいくのではないでしょうか。」</p>
<p>AIという異質な知性との対話を通じて、私たちは自らの知性のメカニズムを解き明かすヒントを得るかもしれない。その探求は、純粋な科学的興味に留まらず、私たちの社会の未来を方向づける喫緊の課題なのである。</p>
<h2>5. 未来への警鐘：AIと『人間の家畜化』</h2>
<p>AIがもたらす恩恵の裏側で、甘利先生は人類の未来に対する深刻な懸念を抱いている。それは、技術の進化を手放しで礼賛する風潮に一石を投じる、思慮深い警鐘だ。先生が最も危惧するのは「人間の家畜化」である。AIがあまりに有能になることで人々が自ら考えることをやめ、あらゆる判断をAIに委ねるようになる。その結果、人類全体の思考力が低下していくのではないか、と。</p>
<p>\u003E甘利先生
「一番まずいのは、もうAIの言いなりになって、自分で物を考えないことです。AIが強力になればなるほど、自分で考える苦しみというものが薄れて、『AIに聞いてみよう』となる。それでは、人類の文明が滅びていくのではないか。人間が、AIの家畜になってしまうのではないか。」</p>
<p>この懸念は、教育、ビジネス、さらには民主主義や自由といった、近代社会が築き上げてきた価値観そのものを揺るがしかねない。甘利先生の究極のメッセージは、単なるAIの利用法に関する警告ではない。それは、物事が「なぜ」機能するのかを問うことをやめ、「ただ」機能するという事実に満足してしまう世界への警鐘なのだ。</p>
<p>AIを思考停止の道具にするのではなく、自らの知性を拡張し、人間とは何かを深く見つめ直すためのパートナーとして使いこなす。AIに答えを求める前にまず自分で考え、AIの答えを鵜呑みにせず吟味し、そしてまた自分で考える。その知的な格闘の中にこそ、人間とAIが共進化する未来がある。</p>
<p>半世紀以上にわたり知の最前線を走り続けてきた巨人は、インタビューの最後に「まあでも、好きだからやってきたんですね」と語った。複雑な数式や深遠な概念について語るその姿は、驚くほど楽しそうで、純粋な知的好奇心に満ち溢れていた。技術の奔流に身を任せるのではなく、自らの知性を研ぎ澄ませ、未来を思索し続けること。その探究心こそが、AIという巨大な問いに私たちが向き合うべき姿勢であることを、甘利先生の言葉は静かに、しかし力強く示している。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>量子コンピュータとAIの「リアルな現在地」から「SF的未来」へ：第一人者・大関真之教授に聞く</title>
      <link>https://ledge.ai/articles/interview_prof_ohzeki</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>空前の生成AIブームが世界を席巻する中、技術界の視線は次なる地平へと注がれている。その筆頭に挙げられるのが「量子コンピュータ」だ。メディアではその驚異的な計算能力が頻繁に報じられ、AIの進化を加速させる究極の鍵として、大きな期待が寄せられている。しかし、その輝かしい未来像と研究の最前線にある現実との間には、無視できない大きな隔たりが存在する。</p>
<p>この複雑な状況の真実を探るべく、量子コンピュータ研究の第一人者であり、東北大学・東京科学大学で教鞭をとる大関真之教授に話を伺った。量子アニーリング方式の研究で知られる大関教授だが、あまり知られていない事実がある。<strong>「ちなみに僕は最初はゲート（方式）なんですけどね。みんな知らないんですけど…アニーリングをやれって上司から命令されたからやるしかなかっただけなんです」</strong> と彼は明かす。この実務から生まれた両方式への深い知見は、分野全体を俯瞰する、他に類を見ない冷静かつ鋭い視点を与えている。</p>
<p>本記事は、単なる技術礼賛ではない。専門家の視点から、量子コンピュータが直面する「不都合な真実」、AIとの融合における「致命的な課題」、そしてそれらを超えた先に見える「SF的な未来」の可能性まで、客観的かつ深く掘り下げていく。</p>
<p>※インタビューは2025年11月5日にオンラインで行われた。</p>
<h2>1. 幻想を打ち砕く：量子コンピュータの「リアルな現在地」</h2>
<p>現在のメディア報道や世間の期待と、研究現場における量子コンピュータの実際の性能との間には、大きなギャップが存在する。まずその幻想を打ち砕き、専門家が見る「リアルな現在地」を明らかにすることから始めたい。大関教授の言葉は、この分野に漂う熱狂に冷や水を浴びせるかもしれないが、真の可能性を理解するためには不可欠な第一歩である。</p>
<h3>1.1. ゲート方式の厳しい現実：「ノイズだらけで使い物にならない」</h3>
<p>現在、量子コンピュータの主流として開発が進められている「ゲート方式」。しかし、大関教授はその現状を <strong>「ただの乱数生成器の域を超えない」</strong> と厳しく評価する。</p>
<p>メディアでは量子ビット数が飛躍的に増加しているというニュースが頻繁に流れるが、教授は <strong>「実際には積極的な利用にはかなりハードルがある」</strong> と一蹴する。問題の本質は、計算過程で発生するノイズ（エラー）にある。量子ビットを増やしても、それに伴ってエラーが積み重なり、最終的な計算結果は信頼できないものになってしまうのだ。</p>
<p>ユーザビリティも絶望的だ。これは学術的なツールに限った話ではない。大関教授は、ある企業の有料商用サービスにアクセスしようとした際の経験を語る。「<strong>数日とかジョブ待ち</strong> 状態」。研究開発のツールとしてすら実用レベルに達していないのが実情だ。ニュースで語られる華々しい成果と、研究者が直面する現実は、残念ながら大きく乖離している。念の為補足すると、その企業がまだ量子コンピュータを大量に並べて多くのジョブを捌ける状態にないのだから仕方のないことではある。</p>
<h3>1.2. アニーリング方式の可能性と限界</h3>
<p>ゲート方式とは異なるアプローチをとる「量子アニーリング方式」は、実用面で一定の評価を得ている。大関教授も <strong>「ジョブ遅延が全くない」「普通にAPIを叩くとちゃんと答えは返ってくる」</strong> と、その安定性を認める。これは量子アニーリングマシンについては早期に開発が進み、周りのシステムや多数のマシンでカバーをしていることによる。</p>
<p>しかし、これもまた「組合せ最適化問題」を劇的に速く解く銀の弾丸ではない。大関教授は、「何も考えずに実行して、<strong>組合せ最適化問題を早く解くなんていうのは基本ないですね</strong> 」と断言する。これらの問題は「NP困難」という性質を持ち、本質的に <strong>「どんな手段を使っても指数関数的に時間がかかる」</strong> からだ。量子アニーリングを使ったとしても、この原理を覆すことはできない。</p>
<p>それでも、教授はこの方式に悲観的なわけではない。CPUがクロック周波数を上げることで高速化してきたように、量子アニーリングマシンを動かすQPU（Quantum Processing Unit）の「1ステップ」そのものが質的に向上することで、性能が向上する”伸びしろ”に期待を寄せている。<strong>「技術としてはまだまだ伸びしろはあるだろうな」</strong> と、その可能性を冷静に見据えているのだ。</p>
<p>ここまでで明らかになったのは、量子コンピュータのハードウェアが依然として発展途上であり、ソフトウェアや応用を語る以前に、ノイズや計算原理といった根本的な課題を抱えているという事実である。この厳しい現実を踏まえた上で、次にAI分野で特に期待の高い「量子機械学習」の議論へと進みたい。</p>
<h2>2. 量子機械学習（QML）の落とし穴：見過ごされてきた2つの致命的課題</h2>
<p>ハードウェアが手強い物理的挑戦に直面しているとすれば、ソフトウェア、特に大きな期待を集める「量子機械学習（QML）」の分野は、それ自体が存亡に関わる危機に瀕している。大関教授によれば、この分野は歴史の繰り返しというべき隘路にはまり込み、実用化を阻む2つの致命的な課題から抜け出せずにいるという。</p>
<h3>2.1. 課題1：勾配消失問題という「歴史の再演」</h3>
<p>QMLが直面する一つ目の大きな壁は、古典的なディープラーニングがかつて乗り越えた「勾配消失問題」の再来だ。ディープラーニングの黎明期、ニューラルネットワークの層を深くすると学習が進まなくなるという問題に直面した。層を重ねるごとに勾配情報が失われることが原因だったが、「ReLU」という活性化関数の登場で劇的に改善された歴史がある。驚くべきことに、量子回路でも全く同じことが起きている。</p>
<p>量子回路における非線形変換は、本質的に三角関数（sinやcos）の組み合わせで表現される。これらの関数の微分値は1以下であるため、回路が複雑になる（層が深くなる）と、勾配情報は指数関数的にゼロに収束してしまう。これは <strong>「Barren Plateau（不毛な台地）」</strong> 問題として知られている。</p>
<p>さらに深刻なのは、古典的なニューラルネットワークと違い、<strong>「自分で勝手にその非線形変換部分を変えられない」</strong> ことだ。量子力学の原理に縛られるため、ReLUのような都合の良い解決策を自由に設計できない。いわば <strong>「量子回路を使うっていう縛りプレイ」</strong> の中で、歴史的な課題と再び向き合わなければならないのだ。</p>
<h3>2.2. 課題2：「くっそ遅い」データ入力のボトルネック</h3>
<p>理論的な課題以上に、より現実的で致命的なのがデータ入力のボトルネックだ。現代の機械学習は、大量のデータを高速に処理することを大前提としている。しかし、QMLの現実はその真逆にある。大関教授は、その遅さを「くっそ遅い」と一言で表現する。</p>
<p>データを一つ処理するたびに、QPUに情報を書き込み、その応答を待つというプロセスを繰り返さなければならない。
<strong>「データ数1個分に対してパラメータの変更があるので量子回路を調整して再入力する必要がある。計算時間よりもそのボトルネックが大きい」</strong>
これは、ミニバッチ学習どころか、1つのデータで勾配を1回計算するのに途方もない時間がかかることを意味する。ビッグデータを扱う現代の機械学習の手法とは、全く相容れないのが現状だ。</p>
<p>これらの課題により、QMLの研究は <strong>「大きくは進化していない」</strong> と大関教授は指摘する。しかし、この行き詰まりは、視点を変えることで新たなパラダイムへの扉を開くきっかけにもなる。</p>
<h2>3. 新たなパラダイム：「次世代GPU」としての量子コンピュータ</h2>
<p>これまでの厳しい指摘から一転し、大関教授は量子コンピュータの新たな捉え方を提示する。それは、単なる「万能で高速な計算機」という幻想から脱却し、その本質を見極めることで見えてくる未来像だ。この視点の転換は、将来のコンピューティングアーキテクチャに大きなインパクトを与える可能性を秘めている。
　この結論は、行き詰まりの中から生まれた「原点回帰」の思考から導かれた。教授は、最も根源的な問いを自らに投げかけたという。<strong>「そもそも、量子コンピュータとは何をするマシンなんだろう？」</strong></p>
<ul>
<li>
<p><strong>本質の再定義</strong>　その答えは、量子力学の基礎方程式である「シュレーディンガー方程式」のシミュレーションにある。数学的に言えば、それは <strong>「巨大な行列とベクトルの掛け算を実行するマシン」</strong> に他ならない。</p>
</li>
<li>
<p><strong>GPUとの対応関係</strong>　この本質は、現代のAIを支えるGPUの役割と驚くほど酷似している。GPUもまた、その中核機能は膨大な線形代数演算（行列計算）の実行だ。ここから、<strong>「将来的にはGPUとちょうど対応する置き換えが行われる部分は結構あるんじゃないか」</strong> という未来像が導き出される。量子コンピュータは、特定のタスクに特化した「次世代のGPU」、あるいはGPUと相補的に機能する新しいプロセッサになり得るのだ。</p>
</li>
<li>
<p><strong>最大のメリット省電力性</strong>　なぜGPUの代替が必要なのか？その答えこそ、このパラダイムにおける量子コンピュータの最大の武器、すなわち圧倒的な電力効率にある。<strong>「QPUベースの量子コンピューターはやっぱり省電力性に優れているっていうことが最大のメリットですよね」</strong> と大関教授は強調する。AIモデルの巨大化に伴い、その消費電力が社会的な課題となりつつある今、同じ線形代数演算を根本的に異なる原理で、より効率的に実行できるアーキテクチャは、「あれば便利なもの」から「必要不可欠なもの」へと変わる可能性がある。</p>
</li>
<li>
<p><strong>未来のアプリケーション</strong>　この視点に立つと、有望な応用分野も見えてくる。特に、金融市場の株価変動のように、時間と共に変化し、<strong>「非局所的な相関」</strong> を持つシステムのシミュレーションに威力を発揮する可能性がある。<strong>「今までの常識的な力学だと近くのものしか変化しないんですが、（量子力学では）全然違う場所のところに『俺はこんな状況なんだけど、あなたはどんな状況？』という関係を扱うことが重要になる」</strong> と教授は説明する。一見無関係に見える遠くの事象が連動する複雑なダイナミクスを捉える能力は、従来のモデルでは不可能だった予測を可能にするかもしれない。</p>
</li>
</ul>
<p>量子コンピュータを「何でもできる魔法の箱」ではなく、特定のタスクに特化した「新しいアーキテクチャのプロセッサ」として捉え直すこと。この視点こそが、現実的な応用への道を切り拓く鍵となるのかもしれない。そしてこの思索は、さらに根源的な問いへと繋がっていく。</p>
<h2>4. SF的未来への展望：量子が拓く「真のAI」への道筋</h2>
<p>ここからは、より長期的で思索的なテーマへと足を踏み入れる。現在のLLM（大規模言語モデル）が持つ本質的な限界と、その先にある「意識」や「自己」を持つAIの実現に、量子コンピュータはどう関わるのか。大関教授と共に、根源的な問いを探求する。</p>
<h3>4.1. LLMに「足りないピース」と量子の役割</h3>
<p>現在のLLMは、人間が一生かかっても触れられないほどの膨大なデータを学習し、驚くほど人間らしい対話を行う。しかし、多くの人が直感的に「何かが足りない」と感じているのも事実だ。その正体は何なのか。</p>
<p>大関教授は、問題はデータ量ではなく「モデルが悪い」ことにあると指摘する。<strong>「人間の思考の結果として表出した言語や画像を確率分布で表現したのが生成モデルですが、その先、到達できない何かがあるはずなんです」</strong> 。現在のAIモデル（アーキテクチャ）では表現しきれない、何か根本的な構造が存在するのではないか、という問いだ。</p>
<p>ここで、量子の役割が浮上する。Googleが「量子超越性」を実証した際に見せたのは、あるタスク、すなわち特殊な確率分布からのサンプリングが <strong>「量子コンピュータだと簡単にできるけど、スーパーコンピュータだと（事実上不可能なくらい）大変」</strong> という事実だった。</p>
<p>もし、人間の思考や意識、あるいは共感といった複雑な現象が、現在のAIモデルでは近似できない「特殊な確率分布」によって支配されているとしたらどうだろうか。その「足りないピース」を表現する能力を、量子コンピュータだけが持っているのかもしれない。大関教授は、このSF的な可能性について <strong>「もちろんその可能性は否定するものではないですよね」</strong> と、開かれた姿勢を見せる。</p>
<h3>4.2. なぜ巨大テックは投資するのか：「アポロ計画」に見る本質</h3>
<p>実用化にはまだ30年かかるとも言われる量子コンピュータに、なぜGoogleやNVIDIAのような巨大テック企業は巨額の投資を続けるのか。その答えを、大関教授は「アポロ計画」とのアナロジーで鮮やかに解説する。
<strong>「『月に行くことに何の意味があるんだ』という話で。だけど月に行くためにロケットを開発し、ロケット燃料を開発し、宇宙服を開発して…。目標の周りでいろんなチャレンジが進むんですよね。」</strong></p>
<p>「月に行く」という壮大で、それ自体は直接的な利益を生まないかもしれない目標が、ロケット素材、生命維持技術、燃料技術といった数多くの副次的な技術革新を生み、産業全体を押し上げた。</p>
<p>同様に、「量子コンピュータを作る」という挑戦的な目標が、超電導技術、極低温冷却技術、材料科学、精密測定技術といった、幅広い周辺分野全体の進歩を牽引する、健全な研究開発のドライバーとなっているのだ。巨大テック企業の投資は、単一の成果だけでなく、この技術的波及効果全体に向けられている。それは、未来のコンピューティングの覇権をかけた、壮大な布石なのである。</p>
<h2>5. 未来を創るために：研究者の信念とビジネスパーソンへの提言</h2>
<p>インタビューの最後に、我々は技術論を超え、未来を創り出す当事者としての大関教授個人の研究哲学と、これからの時代を生きるビジネスパーソンへのメッセージを伺った。</p>
<h3>5.1. 今ある技術で価値を創出する</h3>
<p>大関教授の研究者としての姿勢は、一つの哲学に貫かれている。それは <strong>「今あるもので、多少しょぼくても価値を創造する」</strong> という信念だ。</p>
<p>その象徴的なエピソードが、東日本大震災の際の取り組みだ。当時、まだ黎明期にあった量子アニーリングマシンを使い、津波からの避難経路を最適化する問題に取り組んだ。多くの研究者がマシンのベンチマークテストに終始する中、不完全な技術であっても社会課題の解決に繋げようとするその姿勢は、理論だけでなく実践を重んじる研究者としての矜持を示している。
<strong>「今あるもので多少しょぼくても価値を創造するっていうのを率先してやるっていうのが、昔も変わらないし、これからも続けてやっていこうかなっていうのは思いますね。」</strong></p>
<h3>5.2. 10年先を見据える思考法</h3>
<p>最後に、大関教授から、未来を見据えるビジネスパーソンへ力強いアドバイスが送られた。</p>
<p><strong>「生成AIとかLLMとか、今の時代はもうある意味あらゆるものがやればできる、やればできそうというか、調べたりやってみたりすればあらかた分かるように、できるようになった。だけどこの先のことは創り続ける必要があるわけですから、自分たちがそのリードに立つとか、先駆者になるためには、もう少し先のこと（10年、20年先）を想像しよう、創造しようと考えるようにするといいのかなと思いますね。」</strong></p>
<p>現在のトレンドを追いかけるだけでは、真の先行者にはなれない。誰も答えを知らない、不確実で困難な未来の領域にこそ、次の時代の勝機がある。厳しい現実を直視しつつも、その先にある壮大な可能性を信じて考え続けること。それが、不確実な未来を切り拓くための唯一の方法なのかもしれない。</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/1/5 [MON]生成AIは「実装フェーズ」へ──ディープラーニング協会・松尾豊理事長が年頭所感で示した2026年のAI論点</title>
      <link>https://ledge.ai/articles/jdla_new_year_message_2026</link>
      <description><![CDATA[<p>2026年1月5日、日本ディープラーニング協会（JDLA）は年始にあたり、理事長で東京大学大学院工学系研究科教授の 松尾豊氏による<a href="https://www.jdla.org/news/260105001/">年頭所感</a>を公表した。生成AIの社会実装が急速に進む中、同所感では2025年の技術的動向を振り返るとともに、2026年に向けたAI活用、人材育成、制度整備の方向性が整理されている。</p>
<p>年頭所感では、2025年を「生成AIが研究や実証の段階を越え、実践的な活用フェーズに入った年」と位置づけた。企業活動や教育、行政など、幅広い分野で生成AIの導入が進みつつあり、特定用途にとどまらない汎用的な技術基盤としての役割が強まっているという。</p>
<p>生成AIはもはや一部の先進的な現場だけの技術ではなく、社会全体を支えるインフラに近い存在になりつつあるとの認識が示された。</p>
<h2>AIエージェントとフィジカルAIの進展</h2>
<p>技術面では、AIエージェントが業務プロセスに組み込まれ始めている点や、実世界と連動するフィジカルAIの進展に言及した。モデル性能の向上に加え、AIが人の業務や現場環境とどのように結びつくかという「使われ方」の変化が顕在化していると整理している。</p>
<p>あわせて、大規模投資やインフラ整備の動きにも触れ、データセンター整備などを含む産業基盤の強化が進んでいる現状を示した。</p>
<h2>生成AIを巡る制度と国際環境の変化</h2>
<p>生成AIの普及に伴い、著作権や倫理などの社会的課題が顕在化している点にも触れられている。海外では新興AI企業の台頭や市場環境の変化が見られ、国際競争が激化しているとした。</p>
<p>国内ではAI関連法制の整備が進み、イノベーションの促進とリスク対応の両立を図る枠組みが整いつつあることが紹介されている。</p>
<h2>AI人材育成と資格制度の役割</h2>
<p>人材面では、JDLAが実施するG検定やE資格といった資格制度に言及した。これらを通じてAIに関わる基礎的・専門的知識を持つ人材の裾野が広がっており、高専DCONなどの実践的な教育施策も含め、人材育成基盤が拡充しているとした。</p>
<p>AI技術の社会実装を支えるためには、技術者だけでなく、AIを理解し活用できる多様な人材の育成が不可欠であるとの認識が示されている。</p>
<h2>2026年に向けて</h2>
<p>年頭所感の締めくくりでは、2026年に向けて「学びと信頼の循環」をさらに広げていく方針が示された。AIと共に成長できる社会の実現を目指し、引き続き産業界・教育機関・行政との連携を進めていくとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、汎用AIエージェント開発企業「Manus」を買収──Meta AIへの統合を表明</title>
      <link>https://ledge.ai/articles/meta_manus_ai_agent</link>
      <description><![CDATA[<p>米Metaは2025年12月29日、汎用AIエージェントを手がける「Manus」を買収したと<a href="https://www.facebook.com/business/news/manus-joins-meta-accelerating-ai-innovation-for-businesses">発表</a>した。Manusは市場調査やコーディング、データ分析など複雑な業務を自律的に実行できる汎用AIエージェントを開発しており、今後はManusのサービスを継続して運営・販売しながら、Metaの製品群へ統合される。</p>
<p>Manusは単一用途に特化したAIではなく、複数の業務を横断的に担う「自律型・汎用AIエージェント」として設計されている。Metaは、こうした汎用AIエージェントを自社の消費者向けおよび企業向けプロダクトに展開することで、AI活用の幅を広げる方針だ。</p>
<h2>市場調査からコーディングまで担う汎用AIエージェント</h2>
<p>ManusのAIエージェントは、市場調査やソフトウェア開発、データ分析といった業務を、人の介在を最小限にして実行できるとされる。Metaは今回の発表で、このManusを数十億人規模に届けることを目標に掲げており、同社の幅広いサービス群への展開を進める。</p>
<h2>147兆トークン処理、8,000万超の仮想コンピュータ生成</h2>
<p>Metaによれば、Manusはすでに世界中の個人ユーザーや企業で利用されている。これまでに累計で147兆トークン以上を処理し、8,000万以上の仮想コンピュータを生成したという。2025年初頭には初のGeneral AI Agentを公開しており、日常業務を支援するAIとして利用が広がってきた。</p>
<p>Metaは、こうした実績を踏まえ、Manusの提供を今後さらに多くの企業向けにスケールさせる考えを示した。</p>
<h2>Meta AIを含む製品群へ統合</h2>
<p>今回の参画により、Manusを開発してきた人材と技術はMetaのチームに加わる。Metaは、消費者向けおよび企業向けの各プロダクト、ならびにMeta AIを含むサービス群において、汎用AIエージェントとしてのManusを活用した機能提供を進めるとしている。</p>
<p>なお、買収金額や契約条件の詳細については公表されていない。Manusのサービスは引き続き提供され、既存のユーザーや顧客への影響はないとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/23 [TUE]AI研究の最高峰「NeurIPS 2025」でアリババQwenチームら、最優秀論文賞を受賞―—Transformerの根幹「Attention」を見直す「Gated Attention」を提案</title>
      <link>https://ledge.ai/articles/neurips_2025_best_paper_gated_attention</link>
      <description><![CDATA[<p>2025年12月、AIと機械学習分野で世界最高峰の国際学会として知られるNeurIPS 2025において、大規模言語モデル（LLM）の基盤技術であるTransformerの「Attention」メカニズムを改良する研究が、最優秀論文賞（Best Paper Award）を<a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/120216">受賞</a>した。</p>
<p>受賞した論文は「Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free」。アリババグループのQwenチームを中心に、複数の大学・研究機関が参加した共同研究で、Attentionの計算結果の扱い方を見直すことで、学習の安定性や長文処理性能の改善を示した。</p>
<h2>LLMの中核を担う「Attention」</h2>
<p>Transformerモデルは、入力された文章の中で「どの単語が、どの単語と強く関係しているか」を計算するAttention機構によって、高い表現力を実現している。現在のLLMの多くはこの仕組みを前提としており、Attentionの挙動はモデル全体の性能に大きな影響を与える。</p>
<p>一方で、従来のAttentionには、特定のトークンに注意が過度に集中する現象や、長文条件での性能低下、学習の不安定さといった課題が指摘されてきた。</p>
<h2>Attentionの「結果」に着目した改良</h2>
<p>研究が注目したのは、Attentionの計算方法そのものではなく、「Attentionが出力した結果をどのように次の層へ渡しているか」という点だ。</p>
<p>研究チームは、Scaled Dot-Product Attention（SDPA）の出力直後に、ヘッドごとに独立したシグモイド型の「ゲート」を挿入する手法を提案した。このゲートは、Attentionによって集められた情報を入力ごとに取捨選択する役割を果たす。</p>
<h2>実験で確認された効果</h2>
<p>論文では、数十億〜百億規模のパラメータを持つDenseモデルや、混合専門家（MoE）モデルを用いた大規模な実験が行われた。その結果、以下の点が報告されている。</p>
<ul>
<li>学習中に発生しやすい損失の急上昇（ロス・スパイク）が抑制され、学習が安定した</li>
<li>Attention出力に非線形性が加わることで、表現力が向上した</li>
<li>入力に応じたスパースな情報選択が可能になった</li>
<li>文頭トークンなどに注意が集中する「Attention Sink」現象が大きく緩和された</li>
<li>長文条件のベンチマークにおいて、性能低下が抑えられた</li>
</ul>
<p>計算コストの増加は小さく、既存のTransformer構成に比較的容易に組み込める点も示されている。</p>
<h2>長文処理と大規模モデルへの示唆</h2>
<p>Attention Sinkの抑制により、コンテキスト長を拡張した条件ほど効果が顕在化することも報告された。長文を扱うタスクや、今後さらに大型化が進むLLMにとって、Attentionの出力制御が重要な設計要素になり得ることを示している。</p>
<h2>実装と今後の展開</h2>
<p>論文によれば、提案手法はアリババが開発するQwen系列の次世代モデルにも採用されているという。研究チームは関連コードやモデルの公開も進めており、今後のLLM設計への影響が注目される。</p>
<p>Transformerという既存の枠組みを前提に、Attentionの「使い方」を丁寧に検証し直した本研究は、LLMの基盤技術をめぐる議論に新たな視点を提供するものとして、NeurIPS 2025の最優秀論文に選ばれた。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、GroqのAI推論技術を非独占ライセンス──創業者ら主要人材も合流</title>
      <link>https://ledge.ai/articles/nvidia_groq_ai_inference_non_exclusive_license</link>
      <description><![CDATA[<p>米半導体大手の NVIDIA は、AIアクセラレータを開発する米企業 Groq が保有するAI推論技術について、非独占ライセンス契約を締結した。Groqが2025年12月24日に<a href="https://groq.com/newsroom/groq-and-nvidia-enter-non-exclusive-inference-technology-licensing-agreement-to-accelerate-ai-inference-at-global-scale">発表</a>した。</p>
<p>この契約により、NVIDIAはGroqの推論関連技術を活用できる。契約は非独占であり、Groqは引き続き他社に対しても同技術を提供できるという。</p>
<h2>推論技術を対象とした非独占ライセンス契約</h2>
<p>発表によると、今回の合意はAIモデルの学習ではなく、実運用時の処理を担う「推論（inference）」に関する技術を対象としている。Groqはこれまで、推論処理に特化したアーキテクチャとソフトウェアスタックを強みとしてきた。非独占契約である点から、NVIDIAによる買収や資本参加ではなく、あくまで技術ライセンスという位置づけとなる。</p>
<h2>創業者ら主要人材がNVIDIAに参加</h2>
<p>契約の一環として、Groqの創業者であるJonathan Ross氏、社長のSunny Madra氏ら主要メンバーがNVIDIAに加わることも明らかにされた。両氏は今後、ライセンスされた推論技術の開発およびグローバル展開に関与するという。</p>
<p>一方でGroqは独立した企業として存続する。新たな経営体制の下で、同社のクラウドサービス「GroqCloud」など既存事業は継続される見通しだ。</p>
<h2>推論特化を強みとするGroqの立ち位置</h2>
<p>Groqは、AI推論処理に最適化したアクセラレータとソフトウェアを開発する企業として知られる。大規模言語モデル（LLM）などの推論を低レイテンシかつ高いスループットで実行することを主眼に設計されており、学習用途を主戦場とするGPUとは異なる思想を掲げてきた。</p>
<p>今回の契約により、Groqの推論技術がNVIDIAのエコシステムに組み込まれる形となる。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「Head of Preparedness（準備責任者）」を高額報酬で再募集──アルトマンCEOが「ストレスフル」と明言、超知能研究の先に来る“運用の責任”</title>
      <link>https://ledge.ai/articles/openai_altman_head_of_preparedness_recruitment</link>
      <description><![CDATA[<p>OpenAIのCEOであるサム・アルトマン氏は2025年12月27日（現地時間）、X（旧Twitter）で新たな役職「Head of Preparedness（準備責任者）」の<a href="https://x.com/sama/status/2004939524216910323">募集を告知</a>した。</p>
<p>年俸は55万5000ドル（約8000万円）に加え、株式報酬を含む高額条件が提示されている。同氏はこの仕事について「ストレスフルで、すぐに深みに飛び込むことになる」と表現し、役割の重要性と負荷の大きさを強調した。超知能をめぐる長期研究や組織再編を経て、OpenAIはいま、AIの制御を「研究」から「運用責任」として引き受ける段階に入っている。</p>
<p><strong>OpenAIのアルトマンCEOがX（旧Twitter）で告知した「Head of Preparedness」の募集投稿</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/openai_head_of_preparedness_2b4ba75a08/openai_head_of_preparedness_2b4ba75a08.jpg" alt="openai head of preparedness.jpg" /></p>
<h2>OpenAIが募集する「Head of Preparedness」とは</h2>
<p>同職は、OpenAIのSafety Systemsチームに属する中核ポジションだ。フロンティアAIの能力向上に伴い発生し得る深刻なリスクに備えるための枠組み「Preparedness Framework」の技術戦略と実行を統括する。能力評価、脅威モデルの構築、緩和策の設計を一体として管理し、その結果を製品のリリース判断やポリシー、安全ケースに直接反映させる責任を担う。</p>
<p>研究成果を積み上げる役割というよりも、評価結果をもとに実運用上の判断に関与する「責任職」として位置づけられている点が特徴だ。</p>
<h2>アルトマン氏が示した「いま直面している課題」</h2>
<p>アルトマン氏はXへの投稿で、AIモデルの性能が急速に向上し、多くの価値を生み出している一方で、「現実の課題」が現れ始めていると述べた。具体例として挙げたのが、2025年に見られたメンタルヘルスへの影響の「予兆」や、モデルがコンピュータセキュリティ分野で高度化し、重大な脆弱性を見つけ始めている点だ。</p>
<p>同氏は、OpenAIには能力向上を測定するための強固な基盤があるとしたうえで、今後は「その能力がどのように悪用され得るのか」「どのようにその影響を抑制できるのか」を、より精緻に理解し、測定する必要がある段階に入ったと説明した。前例の少ない領域であり、見た目には妥当そうな対策にもエッジケースが存在する、とも指摘している。</p>
<h2>Preparedness Frameworkが担う役割</h2>
<p>Preparedness Frameworkは、フロンティアAIの能力がもたらし得る壊滅的リスクを追跡・評価し、事前に備えるための枠組みだ。サイバーセキュリティや生物分野など、複数の高リスク領域を横断的に扱う。</p>
<p>能力評価、脅威モデル、緩和策の設計を切り離すのではなく、一連のプロセスとして接続し、実際の製品開発やリリース判断に耐えうる形で運用することを目的としている。Head of Preparednessは、この枠組み全体を技術面・運用面の双方から統括する立場となる。</p>
<h2>長期視点で描かれた「超知能制御」への挑戦</h2>
<p>OpenAIは2023年、人間を超える知能、いわゆる超知能をどのように制御するかを正面から掲げた長期研究「<a href="https://ledge.ai/articles/openai_surveillance_team">Superalignment</a>」を立ち上げた。共同創業者でChief Scientistを務めていたイリヤ・サツケバー氏と、アライメント研究者のヤン・ライケ氏が共同で率い、計算資源の20％を投じる構想として発表された。</p>
<p>Superalignmentは、将来的な超知能の出現を見据えた研究主導の安全アプローチとして注目を集めていた。</p>
<h2>研究体制に影を落としたガバナンスの混乱</h2>
<p>しかし2023年11月、OpenAIはサム・アルトマン氏の一時解任と復帰という深刻なガバナンス危機を経験する。この過程で、サツケバー氏は取締役会側の中心人物の一人として報じられ、後に自身の関与を悔やむ趣旨を表明した。</p>
<p>2024年にはサツケバー氏がOpenAIを退社し、ライケ氏も退社を表明。ライケ氏は、安全が製品開発より後回しにされていると公に批判した。こうした動きを経て、Superalignmentは事実上、他の研究活動に統合される形となった。</p>
<h2>運用の現場へと移った安全の重心</h2>
<p>一方でOpenAIは、長期研究とは別の軸として、フロンティアモデルの能力上昇に伴う現実的なリスクを運用で管理する取り組みを進めてきた。その中核に位置づけられているのが<a href="https://ledge.ai/articles/openai_preparedness">Preparedness</a>だ。</p>
<p>評価や判断に外部の視点を取り入れるため、専門家によるSafety Advisory Groupを設置するなど、運用面での安全体制を重ねて整備してきた。Preparednessは、将来像を描く研究というよりも、日々のリリース判断と直結する実務的な安全運用の枠組みとして位置づけられている。</p>
<h2>報酬水準が示す役割の性格</h2>
<p>Head of Preparednessが担うのは、成果が目に見えにくい一方で、判断を誤った場合の社会的影響が極めて大きい役割だ。成功とは問題が起きないことであり、失敗のコストは高い。</p>
<p>年俸55万5000ドルという報酬水準は、希少な専門性というよりも、こうした責任と判断の重さを反映したものと受け取れる。</p>
<p>アルトマン氏が「ストレスフル」と明言した背景には、この役職が前例の少ない領域での判断を継続的に求められる点がある。サイバー防御と攻撃抑止のバランス、生物学的能力の慎重な公開、さらには自己改善するシステムの安全性など、高い不確実性の中で判断を下し続けなければならない。</p>
<p>OpenAI自身が、その重さを隠さずに示した募集だと言える。</p>
<h2>研究から運用へ──Preparednessが示す現在地</h2>
<p>今回の募集は、OpenAIがPreparedness Frameworkの運用を担う責任者を正式に置き、フロンティアモデルの能力評価やリスク管理を製品開発プロセスに組み込んでいく体制を継続する方針を示すものだ。
Safety Systemsチームの中核ポジションとして、評価結果をもとにした判断や調整を担う役割、Head of Preparednessの重要性が改めて示された形となる。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【2025年のAIトレンドを振り返る】その②：企業の生成AI活用と、国家・自治体・教育機関の対応</title>
      <link>https://ledge.ai/articles/reflecting_on_ai_trends_for2025-2</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>企業の生成AI活用</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_9f96c29932/AI_9f96c29932.png" alt="企業の生成AI活用.png" /></p>
<p>企業の生成AI活用は、単なる実験段階から、全社的な戦略的義務化および意思決定層へのAIの組み込みへと大きく移行した。</p>
<p>この年の最も顕著な動きの一つは、大手企業による生成AI利用の徹底だ。例えば、LINEヤフーは、全社員1.1万人に対して生成AIの利用を義務化するという革新的な方針を打ち出した。これは、「まずはAIに聞く」という新しい働き方を定着させることを目的としており、同社はこれにより3年以内に生産性を2倍にすることを目指している。
　AIは現場の効率化だけでなく、経営判断の領域にも深く浸透している。キリンは、AI役員「CoreMate」を経営戦略会議に常設した。この「CoreMate」は10年分のデータを活用することで、企業における意思決定の高速化を図る役割を担う。</p>
<p>また、特定業務に特化した自律型AIエージェントの導入が進み、金融業界の効率化に貢献している。三菱UFJ銀行は、200超の業務スキルを持つ自律型AIエージェントを導入し、これはSalesforceの「Agentforce for Financial Services」を日本で初めて採用した事例となった。広島銀行も営業準備プロセスに生成AIを導入し、「無意識に使える」業務フローを目指すことで、面談時間を7割削減する見込みだ。</p>
<p>さらに、業界特有のデジタルトランスフォーメーション（DX）も加速しており、例えば住宅業界では、リブワークとカナダのAI企業が連携し、AIが住宅設計を「数秒で自動生成」する住宅DXに本格的に着手した。</p>
<p>このようなAI活用の進展に伴い、企業は人材戦略の再構築にも注力している。三菱商事は、2027年度からAI資格を管理職昇格の必須要件として全社に適用する方針を決定した。このような企業のニーズに応えるため、OpenAIも、2026年にもAIスキル認定と求人プラットフォームを導入する予定であり、AI時代に対応する人材育成と採用のインフラが急速に整備されつつある。</p>
<p>総じて、2025年は生成AIが、現場の生産性向上から経営戦略、そして人材登用に至るまで、企業活動の根幹を成す要素として位置づけられた年であったと言える。AIの活用は、単なるツール利用の枠を超え、企業の構造や文化を変革する動きとして展開された。</p>
<h2>国家、自治体、教育機関の対応</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_cff5f69e07/_cff5f69e07.png" alt="国家、自治体、教育機関の対応.png" /></p>
<p>AI基盤の構築競争、行政効率化のための大規模な導入、そしてガバナンスへの斬新な応用という三つの主要な側面で対応を加速させていることが確認できる。</p>
<p>まず、国家レベルでは、AIインフラの主導権を確保するための巨額な投資競争が展開されている。アメリカでは2025年1月、OpenAIやソフトバンクなどが参画する「Stargateプロジェクト」が発表され、総額約77兆円が投じられ、世界最大規模のAI基盤が米国で構築される計画だ。これに対抗するように、欧州連合（EU）もAIの主導権を確立するため、「AIギガファクトリー」の建設を発表した。この施設では、大規模モデルの訓練を可能にするために10万個のAIチップが使用される予定だ。</p>
<p>日本の政府機関においても、AIの実装と国産化に向けた具体的な動きが進んでいる。経済産業省とNEDOは、生成AI開発支援プロジェクト「GENIAC」の第3期において、楽天や野村総研を含む新規13件を採択し、生成AIの国産化を加速させている。また、行政内部でのAI活用も大きく進展しており、デジタル庁が導入した生成AI環境「源内」の3か月間の実績によると、職員の8割が利用し、1人あたりの平均利用回数は70回に上るなど、業務への定着が示されている。政治の領域でも、AIエンジニアの安野たかひろ氏が「永田町にエンジニアチームを！」を掲げた新党『チームみらい』を結党し、“デジタル民主主義”の実装計画を提唱するなど、AI技術者が政策形成に直接関わる動きが見られた。</p>
<p>さらに、自治体レベルの課題解決や国家ガバナンスの向上においてAIが利用されている。国際的には、アルバニアが汚職撲滅の対策として、賄賂や脅迫が効かないとされるAI「ディエラ」を公共入札担当の大臣に任命するという事例が注目された。国内の地域社会では、上智大学の深澤研究室が、19地域におけるクマ被害の遭遇リスクをAIで可視化する予測マップを開発し、1kmメッシュで危険度を5段階表示することで、地域住民や自治体によるリスク管理への貢献が期待されている。</p>
<p>教育機関もまた、AI活用に積極的です。米国では、カリフォルニア州立大学が米国最大規模となる「ChatGPT Edu」の全学展開を発表し、約50万人の学生と職員にAIを導入した。また、筑波大学とMicrosoftによる研究では、AIが媒介となる新しい「自己省察」の学びのあり方についても報告されており、教育研究の分野でもAIが深く関与し始めている。</p>
<p>このように2025年は、各国政府がAIインフラへの莫大な投資を続け、日本でも国産化支援と行政への浸透が進むとともに、教育機関での大規模導入や、汚職対策、地域のリスク管理といった多様な公共サービスへAIが応用される、実装とガバナンスのフェーズに突入した年であると言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【2025年のAIトレンドを振り返る】その③：アート・エンタメ・消費者領域での浸透と、半導体の活況</title>
      <link>https://ledge.ai/articles/reflecting_on_ai_trends_for2025-3</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>アート、エンタメ、消費者領域での浸透</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_d2b0e3c917/_d2b0e3c917.png" alt="アート、エンタメ、消費者領域での浸透.png" /></p>
<p>2025年は、AIがアート、エンターテイメント、消費者領域に深く浸透した結果、歴史的な創造的成果が生まれた一方で、倫理的・法的な規制強化と伝統的な業界からの危機感が顕在化した年である。</p>
<h3>■創造性の拡張と高まる実績</h3>
<p>音楽分野では、AI技術が過去の遺産を蘇らせる革新的な力を見せつけた。ビートルズの最後の新曲「Now And Then」がグラミー賞を受賞し、これはAI編集楽曲として初の快挙となった。この楽曲は、AI技術の活用によってジョン・レノン氏の声がよみがえらされ完成したものである。また、文学界においても、芥川賞作家である九段理江氏が生成AIと共作した短編『影の雨』の制作に用いられたプロンプト全文が公開され、人間とAIの協業プロセスに対する関心が高まった。大規模アートの領域では、落合陽一氏がプロデュースした「null²」（大阪・関西万博発）の移設のためのクラウドファンディングが、開始後わずか23時間で1億円を達成し、AIを活用したアート作品の商業的な成功を示す事例となった。</p>
<h3>■消費者による浸透と新たな課題</h3>
<p>消費者レベルでのAIツールの普及は急速に進み、特にChatGPTの新画像生成機能の人気により、「ジブリ風画像」が大量に発生した。この画像生成ブームは、「GPUが溶けるほどの負荷」が発生するほどの人気を博したが、同時に著作権問題とシステム負荷の増大という課題を浮き彫りにした。</p>
<h3>■倫理的・法的規制と創造性の危機</h3>
<p>AIコンテンツの爆発的な増加は、業界に倫理的なガイドラインと法的規制を促した。技術提供企業側では、Stability AIが2025年7月31日から利用規約を改定し、Stable Diffusion、API、OSSを含む全サービスにおいてAIポルノ生成を全面禁止する措置を取り、性的コンテンツを遮断した。また、著作権侵害に対する取り締まりも本格化した。生成AI画像に関して、著作権が成立すると判断された事例が発生し、無断複製を行った27歳男性が千葉県警によって書類送致されるという、全国初の摘発事例が確認された。
　エンターテイメント産業の中心地であるハリウッドでは、AIの浸透が雇用と創造性への危機感を引き起こした。アカデミー賞は、生成AIの使用に関する初の指針を明文化し、審査においては「人間の創造性」を重視する姿勢を示したが、AIの使用自体はノミネートの可能性に対して「プラスにもマイナスにもならない」としている。一方、世界初のAI女優「ティリー・ノーウッド」の登場はハリウッドに衝撃を与え、SAG-AFTRA（米俳優組合）や著名俳優らは「創造性の危機」を警告する事態となった。</p>
<p>このように2025年のアート・エンタメ・消費者領域におけるAIのトレンドは、過去の遺産を最新技術で再構築する進歩と、人間の創造的労働および著作権保護の必要性を巡る、複雑な議論が並行して進んだ特徴を持つ。</p>
<h2>半導体の活況</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_a149ae0711/_a149ae0711.png" alt="半導体の活況.png" /></p>
<p>主要テクノロジー企業による内製化の動き、既存大手による次世代技術の発表、および製造・冷却技術の劇的な進歩という三つの側面から進展している状況である。</p>
<p>まず、ハイパースケーラーやAI開発企業が、特定用途に特化した自社チップの開発を加速させている。Googleは、推論に特化したTPU（テンソル処理ユニット）である「Ironwood」を発表し、AIインフラの進化を示した。同様に、MetaはNVIDIAへの依存を低減させることを目的として、AIトレーニング向けに自社製チップの試験的な導入を進めている。さらに、OpenAIも自社AIチップの量産を目指しており、2026年からの量産に向けてBroadcomと協業する方針が報じられた。</p>
<p>市場をリードするNVIDIAも革新を止めず、次世代アーキテクチャとソフトウェアの強化を続けている。2025年3月に、次世代GPUアーキテクチャとして「Blackwell Ultra」「Vera Rubin」「Rubin Ultra」といった革新的な製品群を続々と発表した。同時に、推論AI用のライブラリである「NVIDIA Dynamo」を発表しており、これはDeepSeek-R1を30倍に高速化することを可能にする。この分野での競争は激しく、HuaweiのAIチップ「Ascend 910C」が、DeepSeekのテスト結果においてNVIDIAのフラッグシップモデル「H100」の60%の推論性能を達成したことも報告されている。</p>
<p>また、この半導体の活況は、単なるチップの設計競争に留まらず、その製造技術とインフラ技術の革新にも支えられている。TSMCは、2028年の量産を目指し、次世代半導体製造技術「A14」を発表した。これは、現在の2nmプロセス「N2」から1.4nmへと移行するものであり、さらなる性能向上と省電力化を実現する見込みである。</p>
<p>インフラ面では、MicrosoftがAIチップの冷却効率を高めるために「マイクロ流体」を導入した。これはシリコンに直接液体を流すことで、冷却効率を3倍に向上させる技術であり、2025年9月に発表された。</p>
<p>これらの動向から、2025年は、高性能AIチップの需要拡大と、特定企業への依存を脱却するための内製化戦略が交錯し、チップの設計、製造、および運用インフラの全てにおいて技術革新が起こる、競争が加速した時期であると捉えることができる。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【2025年のAIトレンドを振り返る】その④：生成だけではないAI関連の進化と、AIを取り巻く広義のリスク</title>
      <link>https://ledge.ai/articles/reflecting_on_ai_trends_for2025-4</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>生成だけではないAI関連の進化</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_3e3f5e6751/AI_3e3f5e6751.png" alt="生成だけではないAI関連の進化.png" /></p>
<p>2025年におけるAIの進化は、単にコンテンツを生成する能力を超え、計算基盤の革新、物理的な知能（ロボティクス）の高度化、そしてAIの理論的解釈と実社会への実装基盤の整備という三つの軸で顕著な進展を見せている。</p>
<p>まず、計算能力の限界を押し広げる次世代コンピューティング分野では、量子コンピュータが飛躍的に進化している。Amazonは、シュレーディンガーの思考実験にちなんだ「猫量子ビット」を活用する新型量子チップ「Ocelot」を発表し、これによりエラー訂正コストを90%削減する見込みである。同様に、Microsoftも世界初方式の量子プロセッサ「Majorana 1」を発表しており、これは1台で全世界の従来型コンピュータの計算能力を合わせたものを凌駕するポテンシャルを持つとされる。また、スーパーコンピューティングの領域でも、理化学研究所（理研）がNVIDIAと共同で「富岳」後継機の開発を進めており、次世代機はAIとシミュレーションの融合を目指すことが発表されている。</p>
<p>次に、現実世界における複雑なタスク実行を可能にするロボティクス向けの基盤モデルが充実している。Googleは、ロボット操作向けAI基盤モデル「Gemini Robotics 1.5」を公開した。このモデルは、行動を実行する前に思考し、複雑なタスクを処理する能力を備えている。さらにNVIDIAは、汎用的なロボット向けAI基盤モデル「Isaac GR00T N1」と、物理エンジン「Newton」を発表しており、このIsaacは「速い思考と遅い思考」というデュアルモデルの思考を採用している点が特徴である。
　
　そして、AIの根源的な理解と実社会での応用基盤の強化も進んでいる。学術面では、京都大学などの研究チームが、「理論がないAI/LLM」に対し、情報幾何学の観点から新たな解釈の可能性を提示した。これは、「曲がった」ニューラルネットワークが引き起こす爆発的記憶や高次相互作用の数理に突破口を開くものとされている。一方、社会実装の面では、トヨタが「Woven City」のPhase 1を9月25日に正式開業した。ロケット企業を含む12社が参画するこの“実証都市”は、AIやモビリティ技術を現実世界で応用し検証するための重要なプラットフォームとなる。</p>
<h2>AIを取り巻く広義のリスク</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_7f88974b36/AI_7f88974b36.png" alt="AIを取り巻く広義のリスク.png" /></p>
<p>2025年におけるAIを取り巻く広義のリスクは、技術の急速な社会浸透に伴い、法的責任、社会的安全性、経済構造、そして技術的な信頼性といった多岐にわたる領域で顕在化している。</p>
<p>特に法的・倫理的な側面では、生成AIの責任問題が具体的に追及される事例が増加している。たとえば、Anthropicは著作権侵害訴訟に関して15億ドルの和解を成立させ、約50万点の作品に対して1作品あたり3,000ドルを分配することで決着した。また、生成AI画像に著作権が成立すると判断され、無断複製を行ったとして千葉県警が27歳男を書類送致する全国初の摘発事例も発生した。さらに、AIが生成した「架空の判例」を裁判所に提出した弁護士に対し、米インディアナ州連邦地裁が1万5,000ドルの制裁金を科すという事態も生じており、これはAIの利用において「実際の知性」が不可欠であることを示唆している。</p>
<p>社会的・安全保障上のリスクも深刻である。OpenAIは、16歳の自殺訴訟を受けたことに対応するため、数日のうちにChatGPTにペアレンタルコントロールを導入する動きを見せた。また、大規模言語モデル（LLM）の悪用に関する摘発も進んでおり、Anthropicは100超の偽ペルソナを利用し複数の政治キャンペーンに関与した影響力請負ネットワークを摘発した。セキュリティ面では、Google Threat Intelligence Groupのレポートにより、「実行中に書き換える」AIマルウェアが初めて確認されたという新たな脅威が報告されている。</p>
<p>経済および企業統治の領域でも、AIが直接的なリスク要因となっている。米国の10月の人員削減（15万人超）において、「AI」がその理由の第2位に挙げられており、AIの導入が雇用市場を直撃している実態が明らかになっている。さらに、AIベンチャーのオルツに対し、売上の7割が水増しされた可能性のある粉飾決算疑惑をめぐり、証券取引等監視委員会（SESC）による強制調査が入った。</p>
<p>技術モデル自体の信頼性低下も重要なリスク要因である。米研究チームは、LLMがSNSの「ジャンク投稿」によって学習され続けることで、推論力や安全性が劣化するという「Brain Rot（脳腐敗）仮説」を提唱しており、これはAIの基盤となるデータの質の低下がモデルの性能と信頼性を損なう可能性を指摘している。</p>
<p>これらの事例から、2025年のAIを取り巻くリスクは、単なる技術的欠陥ではなく、法規制の不備、社会的な悪用、経済的な混乱、そしてAIモデル自体の持続可能性に関わる広範な課題として捉えられているのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スマートニュースとUUUMが業務提携　YouTube動画を生成AIで解析し「動画を読む」ニュース体験へ</title>
      <link>https://ledge.ai/articles/smartnews_uuum_video_reading_ai_partnership</link>
      <description><![CDATA[<p>スマートニュースとUUUMは2025年12月24日、業務提携に向けた基本合意を締結したことを<a href="https://about.smartnews.com/ja/news/2524.html">発表</a>した。UUUM所属クリエイターのYouTube動画を生成AIで解析し、テキスト記事としてSmartNewsアプリ上で配信する。動画を「視聴」するのではなく、「読む」形で届けることで、新しいニュース体験の提供を目指す。あわせて、広告領域での協業についても検討を進める。</p>
<h2>動画視聴のハードルと、発見されにくさという課題</h2>
<p>近年、ニュースやスポーツ、趣味、生活情報など幅広い分野で動画コンテンツが急増している。一方で、サムネイルや概要欄だけでは内容や魅力が伝わりにくく、視聴には一定の時間を要することから、ユーザーにとって再生までの心理的・時間的ハードルが高いという課題が指摘されてきた。クリエイター側にとっても、初めて触れるユーザーに動画を視聴してもらう導線は限られており、魅力ある動画でも発見されにくい状況が続いていた。</p>
<p>SmartNewsはこれまで、テキスト主体のニュース記事にとどまらず、グラフィックを用いた記事やニュース動画など、多様な形式のコンテンツを展開してきた。直近では、KADOKAWAとの提携による漫画紹介コンテンツの配信や、生成AIを活用した「スマニューAIまとめ」の提供など、AI技術を活かしたプロダクト刷新とコンテンツ拡充を進めている。今回のUUUMとの取り組みは、こうした方針をクリエイターが制作する動画領域へと広げるものとなる。</p>
<p>今回の基本合意に基づき、SmartNewsはUUUM所属クリエイターのYouTube動画を生成AIで解析し、内容や見どころを短時間で把握できるテキスト記事としてSmartNewsアプリ上で配信する。動画を視聴しなくても要点を理解できるほか、記事内から該当シーンを短尺で確認できるなど、隙間時間でも楽しめる体験を提供する。コンテンツはSmartNewsのトップ画面や関連チャンネルからアクセス可能で、日常のニュース閲覧の流れの中で自然に動画に触れられる導線を整える。</p>
<h2>「記事として読む」ことで生まれる、新しい動画との出会い</h2>
<p>先行展開として、釣りやゴルフといった趣味領域の動画を対象に、AIによる記事化を順次開始する。「釣りよかでしょう。」や「UUUM GOLF-ウーム ゴルフ-」など、UUUM所属の人気クリエイターによる動画を、内容が一目で分かる記事として紹介することで、ユーザーがこれまで接点のなかった動画にも自然に出会える機会を創出する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Smart_News_UUUM_02_ca55da062a/Smart_News_UUUM_02_ca55da062a.png" alt="SmartNews_UUUM_02.png" /></p>
<p>先行テストでは、動画紹介記事がチャンネル内の他の記事と同等以上の閲読数を獲得し、記事から元動画の視聴へ進む動きも確認された。動画を「読む」という新たな入り口が、視聴のハードルを下げ、クリエイターとの接点拡大につながる可能性を示している。SmartNewsは今回の取り組みを通じて、より多様な動画の魅力に気軽に触れられるニュース体験の提供を進めていくとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>SOMPO、3万人の仕事を「AI前提」に再設計──国内グループでAIエージェント導入</title>
      <link>https://ledge.ai/articles/sompo_ai_agent_work_redesign</link>
      <description><![CDATA[<p>2025年12月26日、SOMPOホールディングスは2026年1月から、国内グループ会社の社員約3万人を対象に、AIエージェントの助言を前提とした働き方へ移行することを<a href="https://www.sompo-hd.com/-/media/hd/files/news/2025/20251226_1.pdf">発表</a>した。社内業務を「AI前提」で再設計し、業務効率化と生産性向上に加え、ビジネスモデル変革を強力に推進する狙いだ。</p>
<p>導入する「SOMPO AIエージェント」は、SOMPOホールディングス本体および中核事業会社である損保ジャパンを含む国内グループ会社で活用される。対象は約3万人に上り、単一の企業グループとしては国内最大級の規模となる。</p>
<p>SOMPOグループは2016年にSOMPO Digital Labを設立して以降、DXとAI活用を進めてきた。グループ専用の汎用型生成AIを展開してきたほか、各事業領域で業務特化型生成AIの実装も進めている。生成AI技術の進化を背景に、同社はこれらの取り組みを次の成長段階につなげる構えだ。</p>
<p>今回のAIエージェント導入は、個別業務の効率化にとどまらず、業務プロセス全体をAI前提で再構築する取り組みとして位置づけられる。オペレーション全体の変革を視野に入れている点が特徴となる。</p>
<p><strong>SOMPOグループにおけるAI活用の進化ロードマップ。今回のAIエージェント導入は、オペレーション全体の変革を目指す「AI 2.0」に位置づけられる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sompo_c4be8a4303/sompo_c4be8a4303.jpg" alt="sompo.jpg" /></p>
<p>「SOMPO AIエージェント」は、社内文書の検索・要約、デスクトップリサーチ、会議の議事録作成支援、データ分析補助などを担う。保険事業を中心とした業務知見や業務プロセスを反映し、業務に特化した形で活用される。</p>
<p>2026年1月からは実証実験を開始する。Google Cloudの企業向けAIエージェント基盤「Gemini Enterprise」を主に採用し、業務プロセスの自動化や高度化の効果を検証する。あわせて、Microsoftの「Copilot Studio」についても一部で検証を進める予定だ。</p>
<p>人材面では、管理職以上を対象に「SOMPO AIエージェントリーダーシップ研修」を必須化する。AIを前提とした業務設計を担う人材育成を進める。</p>
<p>同社は今後、AIエージェント活用の効果を定量的に検証し、創出された時間を顧客への付加価値提供や新規事業創出に振り向けることで、ビジネスモデル変革を加速させるとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/1/1 [THU]AGIは来ない、バブルは続かない──スタンフォード大 HAI研究所が示す2026年のAI、過剰期待の時代は終わり、評価フェーズへ</title>
      <link>https://ledge.ai/articles/stanford_hai_ai_2026_evaluation_phase</link>
      <description><![CDATA[<p>巨額投資と急速な技術進展が続いてきたAI分野は、2026年に転機を迎える可能性がある。Stanford Human-Centered AI Institute（HAI）は2025年12月15日（米国時間）、同研究所に所属する研究者らの予測をまとめた記事を<a href="https://hai.stanford.edu/news/stanford-ai-experts-predict-what-will-happen-in-2026">発表</a>し、AIをめぐる議論は「できるかどうか」から「どの程度役に立つのか」を問う評価フェーズへ移行するとの見方を示した。</p>
<p>同記事では、計算機科学、医学、法学、経済学など複数分野の研究者が共通して、過剰な期待や宣伝が先行してきたAI開発のあり方に転換点が訪れていると指摘している。</p>
<h2>AGIは2026年にも実現しない、AI主権が主要テーマに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/James20_Fall202022_aefa4ec674/James20_Fall202022_aefa4ec674.webp" alt="James20Fall202022.webp" /></p>
<p>HAI共同ディレクターで計算機科学教授のJames Landay氏は、2026年に汎用人工知能（AGI）が実現することはないと明言した。その上で、各国が自国のデータや計算資源を管理する「AI主権（AI Sovereignty）」への関心が急速に高まると予測している。</p>
<p>AI主権の形は一様ではなく、自国で大規模言語モデル（LLM）を構築するケースもあれば、他国が開発したモデルを自国内のGPU上で運用し、データを国外に出さない方式も含まれる。HAIでは、こうした複数の主権モデルを整理・分析する研究にも取り組んでいるという。</p>
<p>一方で、世界各地で進む大規模データセンター投資については、投機的な側面も指摘されている。Landay氏は、AI関連投資が無制限に拡大し続けるわけではなく、バブル的な様相が意識される局面に入るとの見解を示した。</p>
<h2>生産性向上は限定的、失敗するAIプロジェクトが増加</h2>
<p>2026年には、AIがもたらす生産性向上について、より冷静な評価が広がるとみられている。プログラミング支援やコールセンター業務など一部の領域では効果が確認される一方、多くのAI導入プロジェクトは期待した成果を上げられない可能性があると指摘された。</p>
<p>その結果、企業や組織は「AIをどこに適用すべきか」という選別を迫られ、成功確率の高い用途に資源を集中させる動きが強まるとみられる。</p>
<h2>巨大モデルの限界と、高品質データ重視への転換</h2>
<p>HAIの研究者らは、モデルの巨大化が必ずしも性能向上につながらなくなりつつある点にも言及している。データの量的枯渇や品質低下が課題となる中、より小規模でも高品質なデータセットを用いたモデル開発への関心が高まると予測されている。</p>
<p>この流れは、計算資源や環境負荷への懸念とも結びつき、AI開発の効率性を重視する方向性を後押しする可能性がある。</p>
<h2>医療・科学分野で進む「ブラックボックス」の解体</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/russ_altman_1_be03daceca/russ_altman_1_be03daceca.webp" alt="russ_altman_1.webp" /></p>
<p>科学・医療分野では、AIモデルの予測精度だけでなく、なぜその結論に至ったのかを説明できることが強く求められるようになる。HAI上級フェローのRuss Altman氏は、高性能なニューラルネットワーク内部を解析し、重要な特徴や判断根拠を明らかにする研究が進展すると見ている。</p>
<p>医療分野では、自己教師あり学習の進展により、大規模かつ高品質な医療データを用いた基盤モデルが登場し、診断精度の向上や希少疾患への応用が広がる可能性も示された。</p>
<h2>法務、経済分野でも「測るAI」へ</h2>
<p>法務分野では、「文章を書けるか」ではなく、正確性やリスク、業務効率への寄与といった具体的な成果を評価する指標が重視される見通しだ。複数文書を横断して推論する高度なタスクに対応するAIの評価手法も整備されつつある。</p>
<p>また、経済分野では、AIが雇用や生産性に与える影響を職種・タスク単位で可視化する「AI経済ダッシュボード」が登場し、政策立案や企業経営に活用される可能性があるとされている。</p>
<h2>人間中心のAI設計が問われる段階へ</h2>
<p>HAIの研究者らは、AIが人間の思考力や判断力、長期的な成長に与える影響にも目を向ける必要があると指摘する。短期的な利便性や満足度ではなく、人間の能力をどのように補完し、育てるのかを前提とした設計思想が、今後のAI開発で重要になると結論づけている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>倒木リスクをAIで見抜く──三井住友建設、樹木管理向け「tree AI」基本システムを開発完了</title>
      <link>https://ledge.ai/articles/tree_ai_fall_risk_detection_smc</link>
      <description><![CDATA[<p>三井住友建設は2025年12月17日、AI（人工知能）の画像解析技術を活用し、樹木の倒木や落枝の危険性を自動で判定する樹木リスク評価システム「tree AI」の基本システム開発を完了したと<a href="https://www.smcon.co.jp/topics/2025/12171300/">発表</a>した。樹木管理における初期リスク評価をAIで支援し、管理業務の効率化と事故防止への貢献を目指す。</p>
<h2>AIが樹木の状態を解析し、倒木・落枝リスクを自動判定</h2>
<p>「tree AI」は、樹木を撮影した画像をAIが解析し、倒木や落枝の恐れがある危険木を自動で判定する仕組みだ。専門知識を必要とせず、樹木1本あたり数分で評価できるため、多数の樹木を短時間で点検できる点を特徴とする。</p>
<p><strong>■ AIによるリスク評価例（樹皮の欠損を検知したケース、三井住友建設資料より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251217_02_841de28d49/20251217_02_841de28d49.png" alt="20251217_02.png" /></p>
<h2>評価結果をデジタル台帳で一元管理、現場作業を効率化</h2>
<p>評価結果は、地図データと連携したデジタル管理台帳（開発中）に自動で反映され、樹木の位置情報や診断内容を一元的に管理できる。スマートフォンやタブレットなど、インターネットに接続された端末から利用可能とすることで、現地での点検作業や管理業務の負担軽減につなげる。</p>
<p><strong>■ AIを活用した樹木リスク評価と管理の流れ（三井住友建設資料より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20241111_02_239ce5262c/20241111_02_239ce5262c.png" alt="20241111_02.png" /></p>
<h2>自治体での実証を通じ、事業化と機能拡張を目指す</h2>
<p>同社によると、現在は全国の複数自治体で本システムを用いた実証実験を進めており、実運用に向けた検証を行っている。実証を通じて得られたデータはAIの学習に活用され、診断精度の向上が図られているという。</p>
<p>今回完成した基本システムでは、「樹勢」「樹皮の状態」「キノコ」の3項目を評価対象としている。今後は「開口空洞」や「枯枝」などの評価項目を追加し、機能強化を進める方針だ。事業化に向けては、2026年度にデジタル管理台帳の先行販売を開始し、2027年度にAIリスク評価システムを含めた製品提供を目指すとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「大きいほど脳に近い」？──Meta研究、脳活動との対応がスケールと文脈長で強まると報告</title>
      <link>https://ledge.ai/articles/xllm_brain_alignment_scaling_and_context_meta_study</link>
      <description><![CDATA[<p>Metaの研究チームは、人間が物語を聞いている最中の脳活動と大規模言語モデル（LLM）の内部表現を比較した結果、モデルの規模や入力文脈の長さに応じて、脳の言語処理と対応する計算構造が現れるとする研究成果を<a href="https://arxiv.org/abs/2512.01591">発表</a>した。論文「Scaling and context steer LLMs along the same computational path as the human brain」は、2025年12月にarXivで公開されている。</p>
<h2>脳活動とモデル内部表現をどう対応づけたのか</h2>
<p>研究では、被験者3人が約10時間にわたってオーディオブックを聴取する際の脳活動を「脳磁図（MEG）」を用いて計測した。
取得した脳信号は、単語の出現タイミングに同期させて解析され、言語刺激に対する時間分解能の高い反応として整理された。</p>
<p>一方、同じテキストを22種類の言語モデルに入力し、各層の内部表現を抽出。脳信号からモデル内部表現を予測する線形写像を学習し、その予測精度をもとに、どのモデル層が、脳のどの時間帯の反応と対応するかを評価した。</p>
<p><strong>図：脳活動とLLM内部表現の対応付け手法の概要</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/method_figure_tmax_923f1bc517/method_figure_tmax_923f1bc517.png" alt="method_figure_tmax.png" /></p>
<h2>層の深さと脳反応の時間順序に見られた対応関係</h2>
<p>解析の結果、多くのモデルにおいて、浅い層ほど脳の早い反応と、深い層ほど遅い反応と対応する傾向が確認されたという。これは、言語処理における計算の進行順序が、LLMと人間の脳で部分的に一致している可能性を示すものとされる。</p>
<p>研究では、この層の深さと脳反応のピーク時間との対応を「temporal alignment（時間的整合）」と呼び、単なる相関ではなく、計算の段階構造が揃っているかどうかを捉える指標として位置づけている。</p>
<h2>モデル構造の違いが示した共通点と相違点</h2>
<p>こうした時間的整合は、Transformer系モデルだけでなく、状態空間モデル（Mamba）や再帰型モデル（RecurrentGemma）でも観測された。</p>
<p>一方で、BERTやRoBERTa、wav2vec 2.0といった双方向モデルでは、脳活動との対応自体は一定程度見られるものの、計算の時間順序に関する整合は弱く、統計的に有意ではないケースが多かったという。</p>
<p>研究チームは、モデルが「未来の単語も参照できる」双方向構造を持つことが、時間順序の対応を弱める可能性を指摘している。</p>
<h2>モデル規模の拡大で現れた“対応の立ち上がり”</h2>
<p>モデルサイズの影響については、パラメータ数のみを段階的に変化させたPythiaモデル群を用いて検証された。その結果、最小規模の14Mパラメータモデルでは時間的整合は有意に確認されなかった一方、12Bパラメータモデルでは非常に強い整合が示された。</p>
<p>この対応の強まりは、モデルサイズの増加に対して対数的に進み、一定規模を超えると伸びが緩やかになる傾向も見られたという。</p>
<h2>文脈情報が計算対応に与える影響</h2>
<p>研究では、入力する文脈の長さも重要な要因として検証された。Llama-3.2（3B）を用いた実験では、文脈をほとんど与えない条件では時間的整合は弱く、文脈長を1000語程度まで拡張すると、脳活動との対応が大きく強まった。</p>
<p>この効果はMambaモデルでも同様に確認されており、文脈情報の蓄積が、脳に近い計算順序を形成する要因になっている可能性が示唆されている。</p>
<h2>単語予測の容易さだけでは説明できない点</h2>
<p>研究チームは、こうした対応が単に「次の単語を予測しやすいかどうか」によって生じている可能性も検討した。その結果、予測可能性の高低で単語を分けても、時間的整合の傾向は維持されており、単純な次トークン予測の難易度だけでは説明できないと結論づけている。</p>
<h2>研究が示唆することと、残された課題</h2>
<p>研究は、LLMのスケールや文脈処理能力の拡張が、人間の脳における言語処理の計算構造と対応する方向へ作用する可能性を示した。一方で、被験者数が限られている点や、MEGの空間分解能の制約、感覚入力を伴わないテキストモデル中心の分析である点など、今後の検証課題も挙げられている。</p>
<p>研究チームは、今後さらに多様なモデルや条件での比較を通じて、言語モデルと人間の認知過程の関係を精査していくとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>