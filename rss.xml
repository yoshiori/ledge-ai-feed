<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Microsoft 365 Copilotに「Agent Mode」「Office Agent」を導入 ～ “vibe working” でAIによるWord・Excelの自動化を推進</title>
      <link>https://ledge.ai/articles/microsoft365_agent_mode_office_agent_vibe_ai</link>
      <description><![CDATA[<p>Microsoftは2025年9月29日（米国時間）、同社の生成AI搭載ツール「Microsoft 365 Copilot」に、新機能「Agent Mode」および「Office Agent」を導入すると<a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/29/vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot/">発表</a>した。これらは「vibe working」と呼ばれる新しい作業体験を掲げ、WordやExcelでの文書作成・データ分析をAIが支援・自動化することを目的としている。</p>
<h2>Agent Mode：Officeアプリ内でのAI自動化</h2>
<p>Agent Modeは、WordやExcelなどのOfficeアプリケーションに組み込まれ、複数ステップにわたる作業をAIと対話しながら進められる機能。</p>
<p>Excelでは「Excel Labs」アドインを通じてプレビュー提供が開始され、数値の分析やグラフ化をAIに任せられる。Wordでは、文書の構成提案や修正作業をAIが継続的に補助する機能が実装され、まずはWeb版から展開される。</p>
<p>@<a href="https://youtu.be/nSqCy-7Qabk">YouTube</a></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Excel_benchmark_FINAL_7b6722975b/Excel_benchmark_FINAL_7b6722975b.webp" alt="Excel-benchmark-FINAL.webp" /></p>
<h2>Office Agent：Copilotチャットから文書やプレゼン生成</h2>
<p>Office Agentは、Copilotのチャット環境で稼働するエージェントで、Anthropicのモデルを搭載している。ユーザーが「レポートをまとめて」「会議資料を作成して」といった意図を伝えると、AIがWord文書やPowerPoint資料を生成・編集する。従来の単発的な応答にとどまらず、業務プロセス全体を遂行する“作業型エージェント”としての役割を担う。</p>
<p>@<a href="https://www.youtube.com/watch?v=NPSnD8-TZjY">YouTube</a></p>
<h2>“vibe working”のコンセプト</h2>
<p>Microsoftはこれらの新機能を総称して「vibe working」と表現している。簡潔な指示を入力するだけでAIが作業を補完し、文書作成やデータ分析の完成度を高めることを狙う。ユーザーはAIを相棒のように扱い、業務をより効率的に進められるという。</p>
<h2>提供条件と展開予定</h2>
<p>新機能は「Microsoft 365 Copilot」ライセンスを持つユーザーに順次展開される。Frontierプログラム参加者向けに先行提供されるケースもあり、初期段階では英語やWeb版が中心。今後は地域やアプリケーションの拡大が予定されている。</p>
]]></description>
      <pubDate>Thu, 02 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTに「Instant Checkout」登場──ECサイトの商品をチャット内で直接購入可能に</title>
      <link>https://ledge.ai/articles/chatgpt_instant_checkout_launch</link>
      <description><![CDATA[<p>OpenAIは9月29日（現地時間）、ChatGPT内でECサイトの商品を直接購入できる新機能「Instant Checkout」を<a href="https://openai.com/index/buy-it-in-chatgpt/">発表</a>した。従来は外部リンクに移動していた購入手続きが、ChatGPT上で完結できるようになるという。</p>
<p>@<a href="https://www.youtube.com/watch?v=C6qcZdtIv54">YouTube</a></p>
<h2>機能概要</h2>
<p>「Instant Checkout」を利用すると、ChatGPTの会話画面内で商品購入が完結する。ユーザーはカート追加や外部ブラウザへの遷移を必要とせず、決済までをシームレスに行える。</p>
<p>同社ではChatGPTを「情報検索から購入までをワンストップで実現する場」へと進化させる方針を掲げている。今回の新機能により、生成AIがユーザーの消費行動に直結するハブとなることを狙う。</p>
<h2>仕組みと安全性</h2>
<p>提携するECサイトの商品情報はChatGPT内に直接表示され、購入操作が可能となる。決済処理はChatGPTのセキュアな仕組みを通じて行われ、ユーザーのプライバシーとセキュリティ確保が重視されている。</p>
<p><strong>「Instant Checkout」を支えるエージェント型コマースプロトコルの流れ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ACP_POR_1_47d3b99b8f/ACP_POR_1_47d3b99b8f.jpg" alt="ACP_-POR__1.jpg" /></p>
<h2>今後の展開</h2>
<p>OpenAIは、対応するECサイトの拡大を予定している。まずは一部のパートナーから導入を開始し、順次拡大する方針だ。また、開発者や事業者に向けた連携方法の提供も検討されている。</p>
]]></description>
      <pubDate>Thu, 02 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、次世代 AI コーディングモデル『Claude Sonnet 4.5』を発表 — 30時間集中モードが復活、強化されたエージェント性能</title>
      <link>https://ledge.ai/articles/claude_sonnet_4-5_ai_coding_model</link>
      <description><![CDATA[<p>Anthropicは2025年9月30日、最新の大規模言語モデル「Claude Sonnet 4.5」を<a href="https://www.anthropic.com/news/claude-sonnet-4-5">発表</a>した。同社は「世界最高のコーディングモデル」と位置づけ、複雑なエージェントの構築やコンピュータ操作能力で大幅な性能向上を示したと説明している。内部テストでは30時間を超える自律的な作業継続が確認され、推論や数学のベンチマークでも著しい改善が見られた。</p>
<h2>コーディング性能の飛躍</h2>
<p>Sonnet 4.5は、ソフトウェアエンジニアリングのベンチマーク「SWE-bench Verified」で77.2%の正答率を記録し、並列計算を用いた高負荷環境では82.0%に達した。従来モデルのClaude Sonnet 4（72.7%）や競合のGPT-5（72.8%）を大きく上回っている。</p>
<p><strong>ソフトウェアエンジニアリングにおけるベンチマーク「SWE-bench Verified」での比較。Sonnet 4.5が最も高い精度を示した。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/6421e7049ff8b2c4591497ec92dc4157b2ac1b30_3840x2160_13a7b3e290/6421e7049ff8b2c4591497ec92dc4157b2ac1b30_3840x2160_13a7b3e290.webp" alt="6421e7049ff8b2c4591497ec92dc4157b2ac1b30-3840x2160.webp" /></p>
<h2>幅広い領域での強化</h2>
<p>Claude Sonnet 4.5は、コーディングだけでなく、コンピュータ操作や数学、言語理解など幅広い分野で性能を向上させた。特にOSWorldベンチマークでは61.4%を達成し、前世代の42.2%から大幅に改善。金融や法務、医療、STEMといった専門分野でも、専門家による評価で大きな知識・推論力の進歩が確認されている。</p>
<p><strong>主要ベンチマークでの各モデル比較。Claude Sonnet 4.5は複数分野でトップクラスの性能を示した。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/67081be1ea2752e2a554e49a6aab2731b265d11b_2600x2288_30c09323a7/67081be1ea2752e2a554e49a6aab2731b265d11b_2600x2288_30c09323a7.webp" alt="67081be1ea2752e2a554e49a6aab2731b265d11b-2600x2288.webp" /></p>
<h2>エージェント開発と新機能</h2>
<p>さらに同社は今回「Claude Agent SDK」を公開。長期タスクのメモリ管理、ユーザー権限の制御、複数エージェントの協調といった仕組みを開発者に提供する。さらに以下の新機能が追加された：</p>
<ul>
<li>Claude Codeへのチェックポイント機能</li>
<li>VS Code拡張と刷新されたターミナル</li>
<li>Claudeアプリでのコード実行・ファイル生成機能</li>
<li>Chrome拡張の一般公開（Maxユーザー向け）</li>
</ul>
<p>これにより、開発者は独自のエージェントやツールを構築できる環境が整備された。</p>
<p>@<a href="https://youtu.be/OZ-aLrJ0oVg">YouTube</a></p>
<h2>安全性とアラインメントの改善</h2>
<p>Sonnet 4.5はAnthropic史上「最もアラインメントが取れた」モデルとして公開された。危険な挙動（虚偽、迎合、権力志向、妄想助長など）を大幅に低減。AI Safety Level 3（ASL-3）の保護レベルで運用され、特に化学・生物・放射線・核（CBRN）分野に関連するリスク低減が強化されている。</p>
<p><strong>各モデルにおける「ミスアラインメント行動スコア」。Sonnet 4.5は最も低い数値を示し、安全性が向上している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/33efc283321feeff94dd80973dbcd38409806cf5_3840x2160_f4be449515/33efc283321feeff94dd80973dbcd38409806cf5_3840x2160_f4be449515.webp" alt="33efc283321feeff94dd80973dbcd38409806cf5-3840x2160.webp" /></p>
<h2>提供条件と研究プレビュー</h2>
<p>Claude Sonnet 4.5は即日利用可能で、価格は従来のSonnet 4と同じく入力100万トークンあたり3ドル、出力100万トークンあたり15ドル。
また研究プレビューとして「Imagine with Claude」も公開され、期間限定でリアルタイムにコードを生成するデモを体験できる。</p>
<p>@<a href="https://youtu.be/dGiqrsv530Y">YouTube</a></p>
<p>Anthropicは「Claude Sonnet 4.5は、より安全で強力なフロンティアモデルであり、開発者やビジネスユーザーにとって即戦力となる」としており、今後のAIエージェント活用の加速が期待される。</p>
]]></description>
      <pubDate>Wed, 01 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日立、「NVIDIA AI Factory」 活用の集約型インフラ「AI Factory」を構築　Physical AI 開発を加速</title>
      <link>https://ledge.ai/articles/hitachi_ai_factory_physical_ai_acceleration</link>
      <description><![CDATA[<p>日立製作所は9月26日、NVIDIAのAIプラットフォーム「NVIDIA AI Factory」のリファレンスアーキテクチャを活用し、集約型インフラ「AI Factory」を構築したと<a href="https://www.hitachi.co.jp/New/cnews/month/2025/09/0926b.html">発表</a>した。この基盤は、同社が注力するPhysical AIソリューションの開発・導入を加速することを目的としている。</p>
<h2>OTとNVIDIA技術を融合した新基盤</h2>
<p>「AI Factory」は、日立が持つOT（制御・運用技術）分野の知見と、NVIDIAのアクセラレーテッドコンピューティングおよびAIソフトウェアスタックを融合させて設計された。現実世界と相互作用するAIを迅速に開発し、社会実装につなげる狙いだ。活用分野としては、モビリティ、エネルギー、産業、テクノロジーなどが想定されている。</p>
<h2>高性能GPUとネットワークによる構成</h2>
<p>システム構成は、NVIDIA Blackwell GPUを搭載した「HGX B200」システムを採用した「Hitachi iQ」、NVIDIA RTX PRO 6000 Server Edition GPUを搭載した「Hitachi iQ M Series」、そしてネットワーク基盤となる「NVIDIA Spectrum-X Ethernet」で構成される。またソフトウェアには、エンタープライズ向けの「NVIDIA AI Enterprise」や、産業規模の正確なデジタルツインを構築できる「NVIDIA Omniverse」が含まれる。</p>
<h2>Physical AIの開発を加速</h2>
<p>このインフラを用いることで、カメラやセンサーから得た情報を認識・推論し、次の行動を決定・実行する高度なPhysical AIモデルを迅速に開発・学習できる。デジタルツインの構築や、社会インフラを含む物理アセットの最適化を支援し、生産性向上など新たな可能性を拓くという。</p>
<h2>グローバル展開と共同開発体制</h2>
<p>「AI Factory」は米国、EMEA（欧州・中東・アフリカ）、日本に戦略的に配置され、相互接続されたネットワークによってグローバルなエンジニアチームが低遅延で協力できる環境を整える。これにより、多様なPhysical AIソリューションの共同開発を促進し、効率性・生産性・安全性の向上を実現する。</p>
<h2>経営陣とNVIDIAのコメント</h2>
<p>日立製作所 執行役社長兼CEOの德永俊昭氏は「NVIDIA RTX PROサーバーを基盤としたHitachi iQの活用により、AI推論やPhysical AIが高速化され、デジタルツインや社会インフラの最適化が強化される」とコメントした。また、執行役副社長兼デジタルシステム＆サービス統括本部長の阿部淳氏は「グローバルにAI Factoryを構築することで、『真のOne Hitachi』として運営が可能になり、Physical AIのイノベーションを加速させる」と述べた。</p>
<p>さらに、NVIDIAのEnterprise AI Products担当バイスプレジデントであるJustin Boitano氏も「企業データをソフトウェアと物理世界の両方で活用する革新的基盤となる」と評価している。</p>
<h2>Lumada 3.0への布石</h2>
<p>今回の取り組みは、日立が掲げる「Lumada 3.0」ビジョン実現に向けた重要な一歩と位置付けられている。IT、OT、プロダクトを融合したインダストリアルAI分野でのソリューション提供強化を通じ、社会とビジネスのイノベーションを推進する構えだ。</p>
]]></description>
      <pubDate>Wed, 01 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIロボット協会、経産省・NEDO事業に採択──ロボティクス分野の生成AI基盤モデル開発を推進</title>
      <link>https://ledge.ai/articles/airoa_post5g_robotics_ai_platform</link>
      <description><![CDATA[<p>一般社団法人AIロボット協会（AI Robot Association、以下AIRoA）は、経済産業省とNEDO（新エネルギー・産業技術総合開発機構）が公募した「ポスト5G情報通信システム基盤強化研究開発事業」において、ロボティクス分野の生成AI基盤モデルの開発に向けたデータプラットフォーム構築の採択事業者に決定したと<a href="https://www.airoa.org/ja/updates/20250926">発表</a>した。</p>
<h2>採択事業の概要</h2>
<p>AIRoAが採択されたのは、「ロボティクス分野の生成AI基盤モデルの開発に向けたデータプラットフォーム」に関する研究開発で、ポスト5G時代に対応した情報通信システムの基盤強化を目的とし、経済産業省およびNEDOが推進している。</p>
<h2>事業の目的</h2>
<p>ロボティクス分野においては、生成AIを活用した基盤モデルの開発が期待されている。AIモデルに学習させるための多様なデータの収集と共有を可能にすることで、ロボットの高度な知能化と産業競争力の強化につなげる狙いがある。</p>
<h2>AIRoAの役割</h2>
<p>AIRoAは、事業の中心的な実施主体として、参画する企業や研究機関とともにロボティクス分野のデータプラットフォームを整備する。これにより、研究者や開発者が利用できる共通基盤を形成し、効率的な技術開発を後押しする。</p>
<h2>今後の展望</h2>
<p>今回の採択を通じ、AIRoAは生成AIを活用したロボット開発と社会実装を加速させる方針だ。協会は公式発表の中で、「産業界や研究機関と連携し、日本から世界に通用するAIロボティクスの基盤を築いていく」と述べている。</p>
]]></description>
      <pubDate>Wed, 01 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/30 [TUE]AIは専門家にどこまで迫ったか──OpenAI「GDPval」が検証する “現実の仕事力”</title>
      <link>https://ledge.ai/articles/openai_gdpval_ai_job_benchmark</link>
      <description><![CDATA[<p>OpenAIは2025年9月25日、最新の大規模言語モデル（LLM）が「現実の経済価値を持つタスク」でどの程度人間に迫っているかを測定する新しい評価指標「GDPval」を<a href="https://openai.com/index/gdpval/">発表</a>した。実際の業務成果物をもとに44職種・1,320件のタスクで性能を比較した結果、最先端モデルは専門家に近い水準に達していることが示された。</p>
<p>GDPvalは、米国GDPに寄与する9産業・44職種を対象に設計された新しい評価ベンチマークである。法律文書や設計図、動画編集、カスタマーサポートの対応記録など、実際の成果物をタスク化し、AIモデルと業界専門家の成果を比較する。</p>
<p><strong>「GDPval」に含まれる実務タスク例。設計図や看護報告、財務分析からカスタマーサポートまで幅広い領域をカバーしている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Example_GD_Pval_tasks_from_full_set_1f598d2776/Example_GD_Pval_tasks_from_full_set_1f598d2776.jpg" alt="Example GDPval tasks from full set.jpg" /></p>
<h2>幅広い産業と職種をカバー</h2>
<p>評価対象は、不動産、製造、政府、金融、医療、情報サービスなど主要な産業を網羅。ソフトウェア開発者や弁護士、看護師、金融アナリストなど、幅広い知識労働が調査された。</p>
<p><strong>「GDPval」で評価対象となった9産業・44職種。米国経済に大きく寄与する分野から抽出されている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/GD_Pval_includes_real_world_work_from_44_occupations_fc303d69cd/GD_Pval_includes_real_world_work_from_44_occupations_fc303d69cd.jpg" alt="GDPval includes real-world work from 44 occupations.jpg" /></p>
<h2>厳格なレビューと評価方法</h2>
<p>各タスクは平均5回の専門家レビューを経て整備され、最終的に人間とAIの成果物をブラインドで比較。220件のタスクは「ゴールドサブセット」として公開され、自動採点サービスも提供されている。</p>
<p><strong>タスクは複数段階の専門家レビューを経て現実性と品質を担保している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Tasks_undergo_multiple_rounds_of_review_to_ensure_realism_and_quality_7fb88c6b59/Tasks_undergo_multiple_rounds_of_review_to_ensure_realism_and_quality_7fb88c6b59.jpg" alt="Tasks undergo multiple rounds of review to ensure realism and quality.jpg" /></p>
<p><strong>人間専門家によるペアワイズ比較。AIの成果物と人間の成果物を並べ、どちらが優れているかを評価する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/GD_Pval_uses_pairwise_expert_comparisons_for_grading_69709621f2/GD_Pval_uses_pairwise_expert_comparisons_for_grading_69709621f2.jpg" alt="GDPval uses pairwise expert comparisons for grading.jpg" /></p>
<h2>成果と課題</h2>
<p>評価の結果、Claude Opus 4.1は文書やプレゼン資料のレイアウトで優れ、GPT-5は指示理解や計算精度に強みを示した。一方で、モデルの失敗要因として最も多かったのは「指示を正しく理解できていない場合」であると報告されている。</p>
<p>また、推論時間を増やす、プロンプトを工夫するなどの対応により性能はさらに改善可能であることも確認された。</p>
<h2>今後の展望</h2>
<p>現時点のGDPvalは知識労働に限定されるが、将来的には対話型や現場対応を含むタスクへ拡張する計画だ。OpenAIは220件のタスクを公開し、研究者コミュニティによる継続的な評価を促進することで、AIと人間の協働のあり方を探る。</p>
]]></description>
      <pubDate>Tue, 30 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>九州電力・IIJなど5社、「九州版ワット・ビット連携」実証──APN＋光NICで分散DCを直結</title>
      <link>https://ledge.ai/articles/kyuden_iij_qtnet_1finity_nautilus_wattbit_apn_opticalnic</link>
      <description><![CDATA[<p>九州電力、インターネットイニシアティブ（IIJ）、QTnet、1FINITY、ノーチラス・テクノロジーズの5社は2025年9月24日、地域分散型デジタルインフラを構築・検証する実証プロジェクトを開始すると<a href="https://www.kyuden.co.jp/press/2025/h250924-1.html">発表</a>した。プロジェクトは2025年10月から始まり、九州における「九州版ワット・ビット連携」の実現を目指す。（実証期間は2025年10月〜2026年3月）</p>
<h2>「ワット・ビット連携」に基づく取り組み</h2>
<p>政府が推進する「ワット・ビット連携」の考え方に基づき、九州の再生可能エネルギーを活用しつつ、地域に分散したデータセンター（DC）を連携させる。これにより、電力とIT処理の最適なバランスを図り、持続可能なデジタル基盤の実装を目指す。</p>
<h2>世界初、光NICによる分散DCの直結</h2>
<p>同プロジェクトの特徴は、APN（All-Photonics Network）を利用して、複数の小規模DCを光信号のまま接続し、一つのシステムのように機能させる点にある。
さらに、ネットワークには従来の電気信号ではなく、光信号を直接扱う光ネットワークインタフェースカード（光NIC）を導入。これにより、サーバ間を光信号で直接接続し、従来必要だった伝送装置や電気的変換を省略する。1FINITYの調査によれば、分散DCを光NICで直結する取り組みは世界初（2025年9月24日現在、1Finity調べ）となる。</p>
<h2>AI処理と分散DBの検証</h2>
<p>各DCにはAI処理向けのGPUサーバを配置。複数のDCに分散保存されたデータへアクセスし、AI処理を行うための分散データベース技術の検証も進める。これにより、地域ごとに異なる電力供給状況を踏まえ、昼夜や需給状況に応じて柔軟に処理を振り分ける仕組みを模索する。光信号の直結によりネットワーク装置の削減と省電力化も図る。</p>
<h2>今後の展望</h2>
<p>5社は、実証を通じて得られた技術的成果をもとに、再生可能エネルギーとデジタルインフラを組み合わせた「九州版ワット・ビット連携」のモデルケースを確立したい考えだ。</p>
]]></description>
      <pubDate>Tue, 30 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Dify協会を設立──LangGenius、NTTデータ、日本電子計算がAIアプリ普及を推進</title>
      <link>https://ledge.ai/articles/dify_association_established_langgenius_nttdata_jip</link>
      <description><![CDATA[<p>LangGeniusは2025年9月24日、NTTデータ、日本電子計算と共同で、2025年9月1日付で「一般社団法人Dify協会」を設立したと<a href="https://prtimes.jp/main/html/rd/p/000000010.000166429.html">発表</a>した。AIアプリケーション開発プラットフォーム「Dify」を中核に据え、オープンなエコシステムを形成し、日本におけるAI活用の普及を後押しする。</p>
<h2>設立の背景</h2>
<p>生成AIの社会実装が加速するなか、アプリケーションの導入や運用をめぐる課題は多岐にわたる。協会は、開発者や企業がAIを安心して活用できる環境を整備し、技術標準化やガイドライン策定を通じて信頼性の高いエコシステムを目指す。</p>
<h2>協会の目的と活動内容</h2>
<ul>
<li>協会は以下の活動を推進する。</li>
<li>会員間でのノウハウ・事例共有</li>
<li>技術標準や認証制度の検討</li>
<li>勉強会やイベントを通じた人材・企業間のネットワーキング</li>
<li>学術界・産業界・行政との連携支援</li>
</ul>
<p>設立時社員は、LangGenius、NTTデータ、日本電子計算の3社。
役員には、亀茲マルダン氏、新井貴博氏、湯澤元彦氏が理事として名を連ね、監事には戸田邦昭氏が就任した。主たる事務所は東京都中央区に置かれる。</p>
<h2>今後の展開</h2>
<p>協会は2025年10月24日に東京で開催されるイベント「IF Con Tokyo 2025」で活動方針を発表し、翌25日には開発者向け「Dify Studio ハッカソン」を実施する予定。オープンかつ中立的な場を提供することで、幅広いステークホルダーの参加を促し、日本のAIアプリ市場の成長を支えていく構えだ。</p>
]]></description>
      <pubDate>Tue, 30 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/29 [MON]ChatGPTに「共有プロジェクト」モード導入──OpenAI、セキュリティ強化や外部アプリ連携も拡充</title>
      <link>https://ledge.ai/articles/chatgpt_shared_projects_security_update</link>
      <description><![CDATA[<p>OpenAIは2025年9月25日（現地時間）、ChatGPTにおいて、チームでの共同作業やセキュリティ機能を強化する新機能を<a href="https://openai.com/index/more-ways-to-work-with-your-team/">発表</a>した。新たに「共有プロジェクト」モードを導入するほか、外部アプリとの接続機能やエンタープライズ向けの管理機能を拡充している。</p>
<h2>共有プロジェクトモードで共同作業を効率化</h2>
<p>今回のアップデートの中心となるのが「共有プロジェクト」モードだ。これにより、同じワークスペース内のメンバーがチャット、ファイル、カスタムインストラクションを一元的に共有できる。権限は「Chat」と「Edit」の2種類があり、後者ではファイル追加やメンバー招待などが可能となる。さらにプロジェクト専用のメモリが搭載され、長期的なタスクでも文脈を保持したまま進行できるという。</p>
<p>同機能はChatGPT Business、Enterprise、Eduプランに即日提供され、Free／Go／Plus／Proプランには近日中に展開予定。EnterpriseとEduでは既定でオフとなっており、管理者が制御できるとのこと。</p>
<h2>サードパーティアプリとの接続拡大</h2>
<p>OpenAIはまた、外部アプリとChatGPTを直接つなぐ「コネクタ」機能を強化した。現在はGmail、Google Calendar、Microsoft Outlook、Microsoft Teams、SharePoint、GitHub、Dropbox、Boxなどに対応し、情報の取り込みや操作をChatGPTから直接実行できる。</p>
<p>コネクタは用途に応じて自動的に選択され、回答の速度と正確性が向上。さらに、GitHubやSharePointなどでは同期型コネクタによる事前取り込みにも対応する。既存のアクセス権限は尊重され、Business以上のプランではデータが学習に利用されない。EnterpriseとEduでは既定でオフとなり、管理者が利用可否を制御できる。</p>
<p><strong>ChatGPTが対応する外部アプリの例（Google Drive、Gmail、GitHub、Notionなど）。今後さらに拡大予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Connector_logo_wall_16x9_96f5c1f71e/Connector_logo_wall_16x9_96f5c1f71e.webp" alt="Connector_logo_wall_16x9.webp" /></p>
<h2>セキュリティとコンプライアンスを強化</h2>
<p>エンタープライズ利用を想定し、セキュリティ・コンプライアンス機能も拡充された。新たにISO/IEC 27001、27017、27018、27701の認証を取得したほか、SOC 2の適用範囲をSecurity／Confidentiality／Availability／Privacyに拡大。</p>
<p>また、RBAC（カスタムロール・グループ権限管理）に対応し、アクセス制御を柔軟に設定可能となった。シングルサインオン（SSO）は既存のSAMLに加え、OIDCにも対応。さらにEnterpriseとEduではIP許可リストの設定も可能となり、組織全体での安全性が強化されている。</p>
<h2>今後の展開</h2>
<p>新機能はChatGPTにおけるチーム利用を本格化させる第一歩と位置づけられている。OpenAIはブログで「本リリースは、ChatGPTにおけるチームコラボレーションの初期ステップ」と述べ、今後も職場全体での安全な導入を支えるため、機能拡張を続けていく考えを示した。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/29 [MON]Google、ロボット操作向けAI基盤モデル「Gemini Robotics 1.5」を発表──行動前に思考し、複雑タスクを実行</title>
      <link>https://ledge.ai/articles/google_gemini_robotics_15_release</link>
      <description><![CDATA[<p>Googleは2025年9月25日、ロボットの操作向けに新たなAIモデル「Gemini Robotics 1.5」を<a href="https://blog.google/intl/ja-jp/company-news/technology/gemini-robotics-15-ai">発表</a>した。Gemini 1.5 Proを基盤としたこのモデルは、ロボットが「行動を起こす前に考える」能力を備えており、従来よりも複雑なマルチステップの作業を遂行できる点が特徴だという。</p>
<h2>新モデル「Gemini Robotics 1.5」とは</h2>
<p>Googleが発表した「Gemini Robotics 1.5」は、同社の大規模言語モデル「Gemini 1.5 Pro」を拡張し、視覚・言語・行動を統合した「Vision-Language-Action（VLA）」モデルとして設計されている。ロボットは環境を理解し、人間の指示に基づいて複数ステップにわたるタスクをこなせるようになった。</p>
<p>@<a href="https://www.youtube.com/watch?v=AMRxbIO04kQ&amp;t=1s">YouTube</a></p>
<h2>思考してから行動する仕組み</h2>
<p>従来のロボティクスAIは与えられた動作を逐次実行することが多かったが、「Gemini Robotics 1.5」は行動前に計画を立てる能力を持つ。これにより、作業の失敗を減らし効率的に遂行できる。たとえば散らかった部屋で物を拾う場合、ロボットは最適な順序や手順を考えてから実行に移す。</p>
<p><strong>「Gemini Robotics 1.5」の仕組み。ロボットはゴミの分別を例に、行動前に思考・計画を立てるプロセスを経て動作する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Robotics_Agentic_System_width_1000_format_webp_75fe64eb0b/Gemini_Robotics_Agentic_System_width_1000_format_webp_75fe64eb0b.jpg" alt="GeminiRobotics-Agentic_System.width-1000.format-webp.jpg" /></p>
<p>@<a href="https://www.youtube.com/watch?v=eDyXEh8XqjM&amp;t=3s">YouTube</a></p>
<h2>応用例と成果</h2>
<p>公開されたデモでは、洗濯物の分類やごみ分別など、家庭やオフィスで想定される作業を自律的に行う様子が披露された。ロボットは周囲を観察しながら判断を下し、マルチステップのタスクを適切に処理することができる。</p>
<p><strong>Gemini Robotics-ER 1.5」は従来モデルよりも学術ベンチマークで高い性能を示した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Robotics_blog_figure_2_250_width_1000_format_webp_a4b168e1a6/Gemini_Robotics_blog_figure_2_250_width_1000_format_webp_a4b168e1a6.jpg" alt="GeminiRobotics-blog-figure-2-250.width-1000.format-webp.jpg" /></p>
<h2>研究開発の背景</h2>
<p>このモデルは、Google DeepMindとGoogle Researchの共同開発による成果だ。Geminiシリーズの能力を物理世界に応用する取り組みの一環であり、従来のロボットAIよりも抽象的な推論や柔軟な対応が可能になった点が強調されている。</p>
<p><strong>物体検出や軌道予測など、多様な認識・推論能力を備える「Gemini Robotics 1.5」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Screenshot_2025_09_25_at_14_53_4_width_1000_format_webp_c5fae86c2b/Screenshot_2025_09_25_at_14_53_4_width_1000_format_webp_c5fae86c2b.webp" alt="Screenshot_2025-09-25_at_14.53.4.width-1000.format-webp.webp" /></p>
<h2>今後の展望</h2>
<p>Googleは「Gemini Robotics 1.5」を、物理世界における汎用人工知能（AGI）の実現に向けた重要な一歩と位置づけている。単にコマンドに反応するモデルではなく、自ら推論し、計画を立て、ツールを使いこなし、未知の状況にも対応できる自律的なシステムの構築を目指す。</p>
<p>ロボットが知性と器用さを兼ね備え、物理世界の複雑さを乗り越えて人間の生活により役立つ存在となるための基盤づくりであるとし、Googleは研究コミュニティとの協力を継続する方針を示している。また、ロボティクス分野の研究者らが最新の「Gemini Robotics-ER」モデルを活用し、どのような未来を切り拓くのか大いに期待していると結んでいる。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、生成AIで教科書を再構築する「Learn Your Way」を公開──無作為化比較試験で学習成果の向上を確認</title>
      <link>https://ledge.ai/articles/google_learn_your_way_ai_textbook</link>
      <description><![CDATA[<p>Googleは2025年9月16日、生成AIを活用して教科書を再構築する新システム「Learn Your Way」を<a href="https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/">発表</a>した。学習者の学年や関心に合わせて教材をリライトし、音声・スライド・マインドマップなど多様な形式で提示する仕組みを採用。シカゴ地域の高校生を対象とした実証実験では、従来型の教材よりも学習成果が有意に向上することが確認されたという。</p>
<p>従来の教科書は「すべての学習者に一律の内容を提供する媒体」であり、学年や興味関心に応じた最適化は難しかった。Google Researchのチームは、生成AIを用いることでこの制約を克服し、個別化と多様な表現を可能にするアプローチを開発した。</p>
<h2>Learn Your Wayの仕組み</h2>
<p>新システム「Learn Your Way」は、Googleの学習用大規模モデル「LearnLM」（Gemini 2.5 Proに統合）を基盤とする。教材の元テキストを入力し、以下のステップで再構築する。</p>
<ul>
<li><strong>パーソナライズ</strong> ：学年レベル（Flesch-Kincaid指標に基づく）や興味関心（スポーツ、音楽など）に合わせて文章をリライト。</li>
<li><strong>複数表現への変換</strong> ：没入型テキスト、スライド＋ナレーション、オーディオレッスン、マインドマップなど。</li>
<li><strong>学習支援機能</strong> ：埋め込み質問や小テストを生成し、学習者に即時のフィードバックを提供。</li>
</ul>
<p>これにより、学習者は自分に合った形式を選びながら、能動的に学習を進めることができるという。</p>
<p><strong>ニュートンの第三法則を学年や関心に応じてリライトした例。左は高校生向けにバスケットボールを題材に、右は小学生向けに美術を題材に説明している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_79d6efaf7b/x2_79d6efaf7b.jpg" alt="x2.jpg" /></p>
<h2>実証実験（無作為化比較試験）</h2>
<p>研究チームは、シカゴ地域の15〜18歳の学生60名を対象に無作為化比較試験（RCT）を実施した。教材は「思春期の脳発達」（LibreTexts）を使用。
<strong>■ 比較対象</strong> ：
・「Learn Your Way」利用群（30名）
・従来のPDFリーダー（Adobe Acrobat）利用群（30名）
<strong>■ 学習時間</strong> ：20〜40分
<strong>■ 評価方法</strong> ：
・即時テスト（15分）
・3日後の保持テスト（約10分）</p>
<h2>結果</h2>
<ul>
<li>即時テスト：Learn Your Way群が有意に高得点（p=0.03）。</li>
<li>保持テスト：Learn Your Way群が有意に高得点（p=0.03）。</li>
<li>アンケート：Learn Your Way群は「楽しく学べた」「理解が深まった」と回答する割合が高く、将来の利用意欲も強かった。</li>
</ul>
<p><strong>無作為化比較試験の結果</strong> ：「Learn Your Way」を使用した学生は、従来のデジタルリーダー利用者に比べ、即時テスト・保持テストのいずれも有意に高い得点を示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Learn_Your_Way_5_width_1250_458379e0a2/Learn_Your_Way_5_width_1250_458379e0a2.png" alt="Learn-Your-Way-5.width-1250.png" /></p>
<h2>教育現場での意義</h2>
<p>この研究は、生成AIが教科書を「一律の媒体」から「学習者に応じて変化する教材」へと変革し得ることを示している。Googleは、教育科学の知見とAI技術を組み合わせることで、学習成果の向上と学習者の主体性強化につなげられると強調している。</p>
<p><strong>教育専門家による評価結果。特にナレーション付きスライドやオーディオレッスンは、学習者の関心を引きやすいと高評価を得た。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Learn_Your_Way_4_width_1250_8bf77aa53c/Learn_Your_Way_4_width_1250_8bf77aa53c.png" alt="Learn-Your-Way-4.width-1250.png" /></p>
<h2>今後の展望</h2>
<p>研究チームは論文内で次の課題を指摘している。</p>
<ul>
<li>効果検証は1つの教材章に限られており、今後は複数教科・複数章での検証が必要。</li>
<li>各機能（例：スライド、音声、クイズ）の寄与度は明確化されていない。</li>
</ul>
<p>将来的には、学習者の解答状況に応じて教材を動的に調整する「適応学習」への拡張が期待される。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMへの指示が得意な人は脳の働きが違う──「プロンプト力」がfMRI研究で初めて科学的に確認される</title>
      <link>https://ledge.ai/articles/llm_prompting_brain_fmri_study</link>
      <description><![CDATA[<p>大規模言語モデル（LLM）への指示が得意な人とそうでない人の間で、脳活動に違いがあることが初めて科学的に確認された。サウジアラビア・キングサウード大学の研究チームは2025年8月20日、fMRI（機能的磁気共鳴画像法）を用いたパイロット研究の成果をarXivに<a href="https://arxiv.org/abs/2508.14869">公開</a>した。</p>
<h2>fMRIで「プロンプト力」の神経基盤を観測</h2>
<p>研究では、22人の参加者を対象に「プロンプト力」を評価するための独自尺度「Prompt Engineering Literacy Scale（PELS）」を開発し、スコアに基づき「熟達者」と「中級者」に分類。その上で、安静時fMRIを用いて脳の機能的結合やネットワーク活動を比較した。</p>
<h2>主な発見</h2>
<p>解析の結果、熟達者の脳には以下の特徴が確認された。</p>
<ul>
<li><strong>低周波帯域の優位性</strong> ：視覚ネットワーク（VVN）、デフォルトモードネットワーク後部（pDMN）、左外側頭頂ネットワーク（LLPN）などで、低周波成分が高周波成分に比べ優位であり、安定的で効率的な神経活動が示唆された。</li>
<li><strong>脳領域間の機能結合の強化</strong> ：熟達者では、左中側頭回（言語処理や意味記憶に関与）および左前頭極（計画・抽象的推論・メタ認知に関与）の機能結合が有意に強化されていた。</li>
<li><strong>効率的な神経活動</strong> ：脳内の自発的活動を示す指標（fALFF）が全般的に低下しており、不要な揺らぎが少なく効率的な情報処理が行われている可能性が示された。</li>
</ul>
<p><strong>■ LLMプロンプト熟達者で強化された左中側頭回の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f/Increased_connectivity_in_the_left_middle_temporal_gyrus_1927809d6f.jpg" alt="Increased connectivity in the left middle temporal gyrus.jpg" /></p>
<p><strong>■ LLMプロンプト熟達者で強化された左前頭極の機能結合（fMRI解析より）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Increased_connectivity_in_the_left_frontal_pole_966041e40f/Increased_connectivity_in_the_left_frontal_pole_966041e40f.jpg" alt="Increased connectivity in the left frontal pole.jpg" /></p>
<h2>人とAIの協働に関する新しい視点</h2>
<p>この研究は「The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models」と題し、arXivにプレプリントとして公開された。著者らは、LLMを効果的に活用する能力（いわゆる「プロンプト力」）が、単なるスキルではなく神経科学的な特徴を持つことを示した点に意義があると述べている。</p>
<h2>今後の展望</h2>
<p>論文の著者らは、研究がパイロット的な小規模実験であり、より大規模かつ多様な参加者を対象とした検証が必要だと指摘している。また、プロンプト熟達度と脳活動の関連が、教育や職業訓練にどのような影響を及ぼすかを探る余地があるとした。さらに、AIと人間の協働を支える神経科学的理解を深めることで、ユーザーの特性に合わせたAIインターフェース設計につながる可能性があると述べている。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、AIグラス上位モデル「Meta Ray-Ban Display」を発表──「パーソナルスーパーインテリジェンス」への第一歩、米国で9月30日発売</title>
      <link>https://ledge.ai/articles/meta_rayban_display_launch_2025</link>
      <description><![CDATA[<p>Metaは2025年9月18日（米国時間）、Ray-Banとの協業によるスマートグラスの新モデル「Meta Ray-Ban Display」を<a href="https://about.fb.com/news/2025/09/meta-ray-ban-display-ai-glasses-emg-wristband/">発表</a>した。AI機能に加え、右レンズ内側にディスプレイを搭載し、通知や情報を視界に直接表示できるのが特徴。価格は799ドルで、米国で9月30日から販売が始まる。</p>
<p><strong>「Meta Connect 2025で発表された3種類の新モデル──ディスプレイ搭載の『Meta Ray-Ban Display』、スポーツ向け『Oakley Meta Vanguard』、改良版『Ray-Ban Meta（第2世代）』」</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5/G1_F7_W_Kz_Xs_AI_83_Cl_9320d07ac5.png" alt="G1F7WKzXsAI83Cl.png" /></p>
<h2>製品概要</h2>
<ul>
<li>名称：「Meta Ray-Ban Display」</li>
<li>発表日：2025年9月18日</li>
<li>発売日：米国で9月30日より</li>
<li>価格：799ドル（Meta Neural Band 同梱）</li>
<li>提供カラー：Black、Sand</li>
<li>レンズ：Transitions®レンズ</li>
</ul>
<h2>主な特徴</h2>
<p>「Meta Ray-Ban Display」は、右レンズ内に600×600解像度のHUDを搭載。通知や情報を表示することが可能だ。12MPカメラを内蔵し、写真や動画撮影もできるほか、デュアルスピーカーと複数マイクを備え、ハンズフリーでの利用に対応する。Meta AIと連携し、音声や視覚情報を活用した応答も可能となっている。</p>
<h2>Neural Band との連携</h2>
<p>製品には筋電位（EMG）を利用した「Meta Neural Band」が同梱される。手首のわずかな動きを感知し、直感的な操作を可能にするもので、グラスとの連携により操作性を拡張する。</p>
<h2>利用時間と充電</h2>
<ul>
<li>グラス本体：通常使用で約6時間</li>
<li>付属の折りたたみ式充電ケース：最大30時間まで拡張可能</li>
<li>Neural Band：約18時間稼働</li>
</ul>
<h2>展開スケジュール</h2>
<p>米国では9月30日から、Best Buy、LensCrafters、Sunglass Hut、Ray-Ban Storeなどで販売される。2026年初頭にはカナダ、フランス、イタリア、英国にも展開予定。日本の公式ブログでも製品概要が紹介されており、今後の展開に関する情報提供が予告されている。</p>
<h2>今後の展望</h2>
<p>MetaのCEOマーク・ザッカーバーグ氏は、今回の製品を「パーソナルスーパーインテリジェンス」への第一歩と位置づけている。Metaは同時にスポーツ向けのOakleyブランドモデルも発表した。AI機能とウェアラブルデバイスの融合による新たな市場開拓に注力していくとしている。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、AIチップ冷却に「マイクロ流体」導入──シリコンに直接液体を流し効率3倍</title>
      <link>https://ledge.ai/articles/microsoft_microfluidics_ai_chip_cooling</link>
      <description><![CDATA[<p>Microsoftは2025年9月24日、AIチップの性能向上に伴う深刻な発熱問題に対処するため、新しい液体冷却技術「マイクロ流体冷却」の開発・テストに成功したと<a href="https://news.microsoft.com/source/features/innovation/microfluidics-liquid-cooling-ai-chips/">発表</a>した。シリコン基板に微細な流路を刻み、冷却液を直接循環させる方式で、従来の冷却プレートと比べ最大3倍の効率を達成したという。</p>
<p>@<a href="https://www.youtube.com/watch?v=MZBwLi3ajYE">YouTube</a></p>
<p>近年、AIチップは大規模言語モデルや生成AIの処理需要に対応するため高性能化が進んでいる。その一方で、発熱量は急増し、従来の空冷や液冷では限界が見え始めていた。Microsoftは「冷却技術の進歩がなければ、数年以内にAIチップ開発は頭打ちになる可能性がある」と警鐘を鳴らしている。</p>
<h2>新技術「マイクロ流体冷却」の仕組み</h2>
<p>同社が開発した「マイクロ流体冷却」は、チップのシリコン基板に微細な流路を直接形成し、その中に液体を流すことで効率的に熱を除去する仕組みだ。GPU内部の温度上昇を65%低減し、従来の冷却プレート方式と比べ最大3倍の冷却効率を実現したとされる。</p>
<h2>Corintis社との協力</h2>
<p>この取り組みは、スイスのスタートアップCorintisとの共同研究に基づく。自然界の葉脈や蝶の羽に着想を得た「バイオインスパイアード設計」を採用し、AIを用いて冷却液の流路や循環を最適化している。これにより、チップ上で最も高温になる“ホットスポット”を効率的に冷却できるようになった。</p>
<h2>持続可能性への影響</h2>
<p>Microsoftは、Teams会議をシミュレートしたサーバー環境で同技術をテスト。実験室レベルでの検証において、従来技術を大幅に上回る冷却性能を確認した。これにより、実用化に向けた有効性が示された形だ。</p>
<p>マイクロ流体冷却は、データセンターの電力使用効率（PUE）の改善や運用コスト削減にもつながるとされる。冷却技術の革新は、環境負荷を低減しつつ、大規模AIインフラの持続可能な発展を支える重要な鍵になるとみられる。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIで“当たり前”を問い直す―大手SIer2社のエンジニアたちが組織の垣根を超えて挑んだ2日間の合同ハッカソン</title>
      <link>https://ledge.ai/articles/nes_hisol_hackathon_2025_report</link>
      <description><![CDATA[<p>生成AIの技術が急速に進化し、業務や生活のあらゆる場面に応用が広がるなか、自らの発想を形にする実践の場として、「NECソリューションイノベータ株式会社×株式会社日立ソリューションズ合同ハッカソン」が2025年8月4日・5日の2日間にわたり開催された。</p>
<p>本イベントは、NECソリューションイノベータ株式会社と株式会社日立ソリューションズの大手SIer2社が他流試合の形式で合同開催した点に特徴がある。両社からは入社5年前後のSE職・主任層を中心に参加者が集い、所属の枠を超えて発想力と技術力を競い合った。</p>
<p>本イベントは、Ledge.aiが主催する「Ledge.ai CHALLENGE」のフォーマットをベースに構成している。「発想」と「実装」の二部構成を軸に、今回はこれに加え、参加者全員が共通の理解を持ったうえで開発に挑める体制を整えるという観点で、事前プログラムとしてAI基礎講座を行い、最新のAIトレンドや生成AIの基礎知識をインプットする時間を設けた。その後のアイデア発想ワークショップでは、今回のテーマである「日常のルーティンを、先端AIと問い直す」に沿って、各チームが自由に企画を立案。それぞれが企画した内容をプロトタイプとして実装するフェーズへと進んだ。</p>
<p>本記事では、その挑戦の成果として披露されたハッカソンイベント当日の様子を振り返る。</p>
<h2>発想を形に変える、真剣勝負の2日間</h2>
<p>1日目の冒頭では、株式会社レッジ 執行役員の箕部 和也より「1か月前に行われたアイデア発想フェーズに続く“後半戦”が今日から始まる」とイベントの位置づけを説明。さらに本企画の発起人である日本電気株式会社 L&amp;D統括部 松本 好則 氏より、開催に至る想いや狙いを語った。「ハッカソンには、発想・チームワーク・時間管理・フィードバック・ピッチといったSEに必要な要素がすべて詰まっている。自由に作る経験を通じて、技術にこだわり抜いたアウトプットをしてほしい」と呼びかけ、参加者の士気を高めた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DSC_2415_bd991dcfb9/DSC_2415_bd991dcfb9.jpg" alt="DSC_2415.JPG" /></p>
<p>開始の合図とともに実装フェーズがスタートした。はじめは普段とは違う会場の雰囲気や開発環境へのアクセスに苦戦しながらも、徐々に作業が活発になり、ホワイトボードにアイデアの実現方法を書き込んだり、メンターに相談するシーンも見受けられ、ハッカソンイベントらしい様相を呈していった。1日目終了時点では、予定通りに進んだチームもあれば、完成まで不安が残るチームがあったりと、短時間で実装する難しさを感じたチームもあったようだ。
2日目は、朝9時から15時までの限られた時間の中で各チーム実装を続けた。1日目遅れを感じていたチームも、巻き返しを図り、発表までに全てのチームが自分たちのアイデアを形にしたデモアプリを完成させていた。</p>
<h2>6チームが挑んだ“日常の再構築”</h2>
<p>今回のハッカソンでは、NECソリューションイノベータと日立ソリューションズから計6チームが「日常のルーティンをAIで問い直す」というテーマのもと、アイデアの実装に取り組んだ。食や家庭、学習、業務支援といった誰もが日常で直面するであろうシーンを題材に、それぞれの視点からユニークなソリューションが実装された。以下では、各チームが発表したソリューションを紹介する。</p>
<h3>味覚でつながる新しい飲食店発見体験ーNECソリューションイノベータ Aチーム</h3>
<p>NECソリューションイノベータ Aチームは「高評価点なのに満足できない」という課題に着目し、味覚でお店を探す、味覚で人とつながるをコンセプトにした飲食店を探せるアプリを提案した。発表の中では、会場周辺にある実際のお店のデータを使い、飲食店がレコメンドされたり、自分の口コミデータから近い味覚を持つユーザーを探すマッチング機能のデモが行われ、人と人を味覚でつなぐ新しい交流の可能性を提示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image6_1325cc0dcd/image6_1325cc0dcd.jpg" alt="image6.jpg" /></p>
<h3>気分に寄り添う食体験提案アプリー日立ソリューションズ Aチーム</h3>
<p>日立ソリューションズ Aチームは、ユーザーの「今の気分」から食を提案するアプリを発表した。チャットや音声入力で気分を受け取り、自炊か外食かを判定したうえで、レシピや飲食店を提示するのが基本的な仕組みである。発表では「がっつり食べたい気分」という入力から、対話を通じて会場周辺の飲食店を紹介するデモが行われた。また、差別化のポイントとして、Google Maps APIとの連携し、より精緻な外食提案を実現する構想も示されたが、今回は時間の制約から実装には至らなかったところが反省点として挙げられた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image3_808fb086f4/image3_808fb086f4.jpg" alt="image3.jpg" /></p>
<h3>夫婦のすれ違いを埋めるAI目安箱ーNECソリューションイノベータ Bチーム</h3>
<p>NECソリューションイノベータ Bチームは、家庭向けアプリを発表した。夫婦間の小さなすれ違いを記録・可視化し、AIが仲介役として関係改善を流すというユニークなコンセプトのアプリである。夫婦それぞれが日常の出来事や感情を記録すると、AIが要約やスコアリングを行い、良かった点・不満点を整理して提示する。デモでは、妻が日々の不満を入力し、夫がAIを通じて和らげられた表現のフィードバックを受け取る様子などが紹介された。さらに、共感・感謝・協力などの指標を数値化した「5因子分析」や、行動を変えた場合に関係値がどう変わるかを予測する「行動シミュレーション」といった機能も披露された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image1_409ca2c19b/image1_409ca2c19b.jpg" alt="image1.jpg" /></p>
<h3>一人暮らしの食を楽しく支えるパーソナルアシスタントー日立ソリューションズ Bチーム</h3>
<p>日立ソリューションズ Bチームは、一人暮らしの食生活を支えるアプリを発表した。自炊を続ける上での「毎日の献立を考えるのが億劫」「計画通りに作れない」といった悩みに着目し、自分の好みや何人分作るのか？などの情報から献立や買い物リストを提案してくれるアプリである。デモでは、献立・買い物リスト作成が行われた。また一緒に料理をしたいコンシェルジュを選ぶ機能があり、キャラクターと会話しながら、孤独を楽しくする工夫も盛り込まれていた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMG_1380_dcd023d926/IMG_1380_dcd023d926.jpg" alt="IMG_1380.JPG" /></p>
<h3>資格取得の最初の一歩を支える学習支援ツールーNECソリューションイノベータ Cチーム</h3>
<p>NECソリューションイノベータ Cチームが開発したアプリは、資格取得に取り組む人の学習計画をAIがサポートするツールである。受験日や学習可能時間を入力すると、AIが最適な学習スケジュールを自動生成し、進捗管理や参考情報の提示まで行う仕組みを備えている。デモでは応用情報技術者試験を例に、入力内容から全体計画や週ごとのタスクが自動生成される様子や、RAGチャットを使った質問機能などが紹介された。将来的には過去問を取り込み、レベルに応じたレクチャーや、学習の進捗に応じた励ましメッセージを生成する構想も語られた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image7_8f3fd78bb9/image7_8f3fd78bb9.jpg" alt="image7.jpg" /></p>
<h3>朝の迷いをAIで片付けるタスク管理アシスタントー日立ソリューションズ Cチーム</h3>
<p>日立ソリューションズ Cチームは、朝の業務開始前に行うタスク整理を効率化するアプリを発表した。メールやチャットを読み込み、AIが重要度と緊急度の二軸で評価し、優先度付きのタスクリストとして自動的に整理する仕組みである。デモでは、社員証の棚卸依頼や新卒面接日程の確認など、複数の依頼を含むダミーメッセージをLLM（Large Language Models、大規模言語モデル）が解析し、関係者や期限・緊急度の理由を添えてToDoリストに反映する様子が紹介された。さらにダミーデータによるタスク判定精度検証も実施しており、適合率83%、再現率100%を達成し、実運用にも適用できる可能性も示した説得力のある発表だった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/DSC_2440_a2a418109c/DSC_2440_a2a418109c.jpg" alt="DSC_2440.JPG" /></p>
<h2>審査と講評が示した未来への期待</h2>
<p>2日間のハッカソンの成果の発表が終わると、会場には達成感や緊張から解放された安堵が入り混じった空気が感じられた。審査はLedge.ai編集長の落合 研次と、株式会社レッジ 代表取締役社長の小瀧 健太が担当した。</p>
<p>最優秀賞には、日立ソリューションズCチームが選ばれた。毎朝のメール・チャット確認という多くのビジネスパーソンが直面する負担に目を向け、AIを活用してタスク抽出と優先度付けを自動化した点が高く評価され、「忙しい人ほど効果を実感できる」「自社で今すぐ使わせたい」といった声が寄せられた。</p>
<p>優秀賞には、日立ソリューションズBチームと、NECソリューションイノベータBチームが選ばれた。日立ソリューションズBチームは、継続利用するほどユーザーの嗜好に寄り添う点が評価された。NECソリューションイノベータBチームは、夫婦間の感情のすれ違いをAIが傾聴の姿勢で話を聞いてくれるというアイデアの独自性が評価された。</p>
<p>表彰の後に行われた講評では、各社から熱のこもったコメントが寄せられた。
まず最初は株式会社日立ソリューションズ ITプラットフォーム事業部 荒川 啓之 氏が登壇し、「短期間にも関わらず、どのチームも動くプロトタイプを仕上げてきたことに感銘を受けた」と評価したうえで、「課題から発想したアイデアを素早く実装に落として、ユーザーからのフィードバックをもらう進め方は、今後の開発業務に活かせる貴重な経験」と総括した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image9_1503e82ac9/image9_1503e82ac9.jpg" alt="image9.jpg" /></p>
<p>また、同社 業務革新統括本部 AIトランスフォーメーション推進本部 中村 賢 氏からは「限られた時間の中で成果物を形にし、伝わるプレゼンまで仕上げた点は、エンジニアとしての基礎力の高さと発想の豊かさを示していた」とのコメントが寄せられた。特に「企業の枠を越えて技術者が交流することに大きな意義がある」と強調し、今後はよりオープンな形式での展開に期待を示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image6_92b3db901c/image6_92b3db901c.png" alt="image6.png" /></p>
<p>NECソリューションイノベータ株式会社 AI・データアナリティクス統括部 宮本 隆弘 氏が講評。「5分という短い持ち時間の中でしっかりとメッセージングできたチームが成果を収めたと感じた」と語り、「特に若手層の着眼点のユニークさと、着想を形にするエネルギーに感心した」と評価した。最後に「イメージしていた以上の会になった。今後も継続してご一緒したい」と感想を述べ、イベントの継続開催に強い期待を寄せた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image3_613656e257/image3_613656e257.png" alt="image3.png" /></p>
<p>続いて日本電気株式会社 L&amp;D統括部 江本 慎治 氏からも講評をいただいた。「二日間という短期間で企画から構築まで形にできたことは、従来の開発スタイルとの違いを強く感じさせるものだった」と述べ、人材開発プログラムも新しい開発スタイルに適応していく必要があることを実感したという。また「社外の参加者との交流を通じ、自社だけでは得られない学びや刺激を得られたのは大きな価値」と強調し、今後はこうした機会を積極的に活かしてキャリア形成につなげてほしいと語った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image12_1e966afb9c/image12_1e966afb9c.png" alt="image12.png" /></p>
<h2>まとめ</h2>
<p>表彰式後の交流会では、受賞チームの喜びや、惜しくも賞を逃したメンバーの悔しさが入り交じる様子が印象的であった。文化の異なる会社同士の垣根を越えたコミュニケーションも活発に行われ、参加者にとって大きな刺激となり、新たな学びとつながりを生み出す機会となった。
「NECソリューションイノベータ株式会社×株式会社日立ソリューションズ合同ハッカソン」は、生成AIを活用した発想力と実装力を磨く場であると同時に、他社と切磋琢磨する”他流試合”の舞台でもあった。次回開催を期待する声もあがり、２日間にわたる挑戦は、大きな成果とともにイベントは幕を閉じた。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、次世代動画生成モデル「Sora 2」を発表──自分や友人が出演する動画を生成できるiOSアプリ「Sora」も米国とカナダで同時公開</title>
      <link>https://ledge.ai/articles/sora2_openai_ios_app_launch</link>
      <description><![CDATA[<p>OpenAIは2025年9月30日、最新の動画・音声生成モデル「Sora 2」を<a href="https://openai.com/index/sora-2/">発表</a>した。</p>
<p>物理挙動の正確さや映像の写実性が大幅に向上し、音声を同期して生成できる点が特徴。同日には、このモデルを利用できるiOS向けアプリ「Sora」も公開され、米国とカナダで招待制による提供が始まった。日本での提供時期は明らかにされていない。</p>
<p>@<a href="https://youtu.be/lEcg6AJ6DVY?si=aS3u22digXd5ZVY8">YouTube</a></p>
<h2>Sora 2の性能</h2>
<p>Sora2は、従来の「Sora」モデルを基盤に開発された動画・音声生成AIである。
OpenAIが公開した<a href="https://openai.com/index/sora-2-system-card/">システムカード</a>によれば、より正確な物理シミュレーション、長尺映像における一貫性、幅広いスタイルへの対応を実現。さらに音声生成を統合し、映像にナレーションや環境音を付与できる。</p>
<p>生成可能な映像は最大20秒とされるが、ReutersやThe Vergeなど複数のメディアは「アプリ上では10秒程度に制限されている」と報じている。</p>
<p>@<a href="https://www.youtube.com/watch?v=1PaoWKvcJP0">YouTube</a></p>
<h2>iOSアプリ「Sora」の提供</h2>
<p>同日に公開されたiOS向けアプリ「Sora」では、ユーザーがAI生成動画を作成・共有できる。
提供開始は米国とカナダで、アクセスは招待制。アプリ内で通知登録を行うことで順次利用可能となる。AndroidユーザーはWeb版の “sora.com” からアクセスできる仕組みだ。Sora2は当初無料で利用できるが、計算能力の制限が設けられているとのこと。</p>
<p>アプリの特徴として注目されるのが**「Cameo（カメオ）機能」** だ。ユーザーは自分や友人を動画に登場させられる。OpenAIは、この機能を利用するには本人の同意が必要とし、無断で他人の肖像を使用することはできない設計にしているという。サム・アルトマンCEOも自身のブログで「チームがキャラクターの一貫性に力を注ぎ、友人同士を動画に登場させることが意外なほど魅力的な新しいつながり方になった」と述べている。</p>
<h2>安全性への配慮</h2>
<p>OpenAIは安全設計を重視しており、生成動画には透かしやC2PAメタデータを付与。肖像権の無断利用や公人の生成は禁止され、未成年保護のためのフィルタリングや保護者向けコントロール機能も導入されている。
システムカードに記載された安全性評価では、不適切コンテンツを検出・遮断する精度が96〜99％に達したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/introducing_sora2_9ac129aadc/introducing_sora2_9ac129aadc.jpg" alt="introducing sora2.jpg" /></p>
<h2>背景と思想</h2>
<p>同社CEOのサム・アルトマン氏は自身の<a href="https://blog.samaltman.com/sora-2">ブログ</a>で、Soraを「ChatGPT for creativity」と表現。誰もが手軽に動画生成を楽しめる環境を提供する一方で、依存性や誤用のリスクについても懸念を示し、長期的なユーザーの満足や健全な利用を重視する方針を強調した。</p>
<p>また、OpenAIは公式サイトで「<a href="https://openai.com/index/sora-feed-philosophy/">フィード哲学</a>」を公開し、ユーザーが視聴体験を自ら選択できる仕組みを構築するとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=gzneGhpXwjU&amp;t=137s">YouTube</a></p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>トヨタ、実験都市「Woven City」を正式オープン──静岡県裾野市で未来のモビリティ実証開始</title>
      <link>https://ledge.ai/articles/toyota_woven_city_open_launch</link>
      <description><![CDATA[<p>トヨタ自動車とWoven by Toyotaは2025年9月25日、静岡県裾野市に建設していた実験都市「Woven City（ウーブン・シティ）」を正式にオープンしたことを<a href="https://global.toyota/jp/newsroom/corporate/43347821.html">発表</a>した。東富士工場跡地を活用し、将来的に最大2,000人が暮らす街を舞台に、モビリティやロボティクス、スマートホームなどの次世代サービスを実証する。</p>
<h2>第1期住民の移住開始</h2>
<p>Woven Cityには、「Inventors（発明者）」と呼ばれる企業や研究者、そして「Weavers（住民）」と呼ばれる人々が生活を始めた。第1期は約300〜360人規模でスタートし、段階的に拡大して最終的には2,000人規模の居住を目指す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/001_bcd76c80cb/001_bcd76c80cb.jpg" alt="001.jpg" /></p>
<h2>実証の対象分野</h2>
<p>この都市は、以下の領域における新しいサービスや技術の検証拠点として機能する。</p>
<ul>
<li>モビリティ：自動運転車や次世代交通システム</li>
<li>ロボティクス：生活支援や介護を含む分野</li>
<li>スマートホーム：家庭内エネルギー管理やAI連携</li>
<li>サステナビリティ：再生可能エネルギー利用や環境負荷低減</li>
</ul>
<h2>街づくりの特徴</h2>
<p>Woven Cityは、車道・人道・モビリティ専用レーンを分離した都市設計を採用している。さらに、エネルギーは100％水素や再生可能エネルギーでまかない、街全体をIoTセンサーやAIで管理することで持続可能な社会のモデルを目指す。</p>
<h2>今後の展開</h2>
<p>トヨタは、Woven Cityを「幸せの量産（Mass-Production of Happiness）」を体現するプロジェクトと位置付けている。実際の生活を通じて技術を検証し、社会実装につなげることを目的に、世界の研究者や企業とのオープンイノベーションを推進する。</p>
<p>Woven Cityはフェーズごとに住民数や参加企業を増やしながら拡張される計画だ。トヨタはこの取り組みを、自動車メーカーからモビリティカンパニーへと変革する象徴的なプロジェクトと位置付けており、将来的には他地域への応用も視野に入れている。</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【9/29-30限定公開】AI業界のトップランナーが集結した「Ledge.ai Webinar SP」の見逃し配信</title>
      <link>https://ledge.ai/articles/ledgeai-webinarsp-sponsor-archive</link>
      <description><![CDATA[<p>国内最大級のAI専門メディア「Ledge.ai」を運営する株式会社レッジは、9月24日から9月26日の3日間にかけて、オンラインイベント「Ledge.ai Webinar SP」を開催した。</p>
<p>同イベントは、「AIをしる、つかう、つくる」をテーマに、AI業界を牽引する18の企業が、AI活用に関する見識をシェアする講演を実施した。本日と明日の2日間限定で、ライブ配信を見逃した方や再度視聴したい方のために「Ledge.ai Webinar SP」の全講演をオンデマンドで配信する。本稿では実施された講演とその一部見所を紹介する。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/WebinarSP/formperma/JuHnRG5lHussdjFLR1q1xzkoh-ToCiYgQmvxxGOotyU">アーカイブ配信を見る</a>
:::</p>
<h1>AI業界のトップランナーが集結し、全18の講演をお届け</h1>
<p>「Ledge.ai Webinar SP」では、マイクロソフト、ソフトバンク、日本ディープラーニング協会などAI業界のトップランナー全18の企業が講演を行った。</p>
<h2>DAY-1「AIをしる」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day1_76bc3a0602/Day1_76bc3a0602.png" alt="Day1.png" /></p>
<h2>DAY-2「AIをつかう」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day2_62d766c235/Day2_62d766c235.png" alt="Day2.png" /></p>
<h2>DAY-3「AIをつくる」</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Day3_d61ce2af95/Day3_d61ce2af95.png" alt="Day3.png" /></p>
<h3>「ソフトバンクの事例から紐解く、組織の生成AI活用・推進を自走するための仕組みづくり」</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2025_09_28_13_45_33_69eb5b9eab/2025_09_28_13_45_33_69eb5b9eab.png" alt="スクリーンショット 2025-09-28 13.45.33.png" />
【登壇者】
ソフトバンク株式会社
藤原 竜也 氏 / IT統括 AI&amp;データ事業統括部　Axross事業部 部長</p>
<p>概要：
ソフトバンク株式会社の講演では、ソフトバンク自身がどのように組織での生成AI活用を進めたのか解説。自社事例をもとにしたトップダウン・ボトムアップそれぞれのアプローチ手法など実際組織に落とし込める取り組みについてお話しいただいた。</p>
<h3>「私が想像する未来のOS」</h3>
<p>【登壇者】
マイクロソフト ディベロップメント株式会社
Zhan (Cliff) Chen / 陳 湛 氏 / プリンシパル　アプライド　サイエンティスト</p>
<p>概要：
マイクロソフト ディベロップメント株式会社の講演では、未来のOSについて語られた。未来のUIはその人それぞれにベストな形で生成されるようになり、OSはキャラクターに変わるという。講演では、未来がなぜそのように変わっていくかも語られた。</p>
<h3>「企業におけるAIエージェント実装の現実戦略」</h3>
<p>【登壇者】
株式会社エクスプラザ
宮田 大督 氏 / CPO 生成AIエバンジェリスト・リードAIプロデューサー</p>
<p>概要：
株式会社エクスプラザの講演では、AIエージェントを使いこなすことで今どのレベルまでAIがタスクを代替できるのか、宮田 氏自身の自律型エージェントがこちらから指示を出していないのにAIが課題に合わせたアプリを作って提案してくれた経験などをご紹介いただいた。また、今後AIエージェントが当たり前になる時代に対し、どのように備えていくべきかもお話しいただいた。</p>
<h3>「自然に生成AIの活用を加速させるデータインフラ統合型AIのすゝめ」</h3>
<p>【登壇者】
ダイレクトクラウド株式会社
石田 圭一 氏 / プロダクト本部　部長
十樹 亮輔 氏 / 営業本部カスタマーリレーション部 カスタマーサクセスチーム</p>
<p>概要：
ダイレクトクラウド株式会社の講演では、データインフラ統合型AIを活用し組織全体での知識共有が促進されることで生まれるメリットや重要性についてお話しいただいた。また、データインフラに統合されたAIの活用事例などについてもお話しいただいた。</p>
<h3>「話題のgpt-ossとは？ローカル版ChatGPTで構築するAIエージェント【解説＆デモ】」</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2025_09_28_13_35_49_5582ed62a7/2025_09_28_13_35_49_5582ed62a7.png" alt="スクリーンショット 2025-09-28 13.35.49.png" />
【登壇者】
株式会社ハイレゾ
山田 岳史 氏 / GPU事業本部 マーケティング部 グループ長</p>
<p>概要：
株式会社ハイレゾの講演では、ローカル版ChatGPTを使ったAIエージェント構築のデモンストレーションと解説をしていただいた。またその中でMCP、MoEなど必要な概念やその実装方法についても触れていただいた。</p>
<h3>「HPワークステーションで試すRAG検索 — 実用構成とPOC事例の紹介」</h3>
<p>【登壇者】
株式会社日本HP
勝谷 裕史 氏 / エンタープライズ営業統括 ソリューション営業本部 ワークステーション営業部 AI/データサイエンス市場開発担当部長</p>
<p>概要：
株式会社日本HPの講演では、AIワークステーションを活用する具体的な用途やメリット、クラウド生成AIとローカル生成AIの違いについて解説いただいた。また、実際にオンプレミスでのローカル生成AのPoC事例についてもご紹介いただいた。</p>
<p>ここまでご紹介したように、登壇いただいた企業様それぞれの視点や取り組みが異なるため、多様な切り口で様々な情報をキャッチアップすることができる。</p>
<p>AIに関する様々な分野の最前線を知る機会として、是非お見逃しなく。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/WebinarSP/formperma/JuHnRG5lHussdjFLR1q1xzkoh-ToCiYgQmvxxGOotyU">アーカイブ配信を見る</a>
:::</p>
]]></description>
      <pubDate>Mon, 29 Sep 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/28 [SUN]Photoshop、外部AIモデルを初統合──Google「Nano Banana」とBlack Forest Labsの「FLUX.1 Kontext」が生成塗りつぶしに対応</title>
      <link>https://ledge.ai/articles/photoshop_generative_fill_gemini_flux_integration</link>
      <description><![CDATA[<p>Adobeは2025年9月25日、Photoshopの「生成塗りつぶし（Generative Fill）」機能に、Googleの画像生成モデル「Gemini 2.5 Flash Image（Nano Banana）」と、Black Forest Labsの「FLUX.1 Kontext [pro]」を統合したと<a href="https://blog.adobe.com/en/publish/2025/09/25/photoshop-beta-expands-generative-fillmore-ai-models-more-possibilities">発表</a>した。これにより、ユーザーはAdobe独自のFireflyモデルに加え、外部AIモデルを切り替えて利用できるようになる。</p>
<h2>外部AIモデルが初めてPhotoshopに統合</h2>
<p>今回の更新は、Photoshopが自社モデル中心から一歩踏み出し、外部の生成AIモデルを取り込む初の事例となる。Adobe公式ブログによれば、Nano BananaとFLUX.1 Kontext [pro]はいずれもPhotoshopベータ版のユーザーが利用可能で、選択範囲を指定したうえでプロンプト入力を行うと、モデルを切り替えて生成や編集を実行できる。
なお、Adobeは昨年動画編集ソフトのPremiere Proにおいて、OpenAIのSoraやRunway、Pika Labsなど外部の動画生成モデルの統合予定を<a href="https://ledge.ai/articles/adobe_premiere_pro_sora">発表</a>しているが、Photoshopへの外部モデル導入は今回が初めてとなる。</p>
<h2>Nano Bananaの特徴</h2>
<p>Googleが開発した「Gemini 2.5 Flash Image（Nano Banana）」は、スタイル変換やグラフィック要素の追加、視覚効果の生成に強みを持つ。Photoshop内ではFireflyと同様の操作感で利用でき、用途に応じたモデルの選択が可能となる。</p>
<p><strong>Googleの「Gemini 2.5 Flash Image（Nano Banana）」を使った生成塗りつぶしの例。衣服や背景を置き換え、黄色い鳥を追加するなど複数の変更を一度に適用できる。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_195028b2e137ad3d6178196faeab0ef497afee9d5_8a49af01ee/media_195028b2e137ad3d6178196faeab0ef497afee9d5_8a49af01ee.jpg" alt="media_195028b2e137ad3d6178196faeab0ef497afee9d5.jpg" /></p>
<h2>FLUX.1 Kontext [pro]の特徴</h2>
<p>一方、Black Forest Labsの「FLUX.1 Kontext [pro]」は、環境や遠近感に調和した生成を得意とする。背景や構図に一貫性を持たせる性能が評価されており、Photoshopでの利用によって「場面全体との整合性」を保ちながらの編集が可能になる。</p>
<p><strong>Black Forest Labsの「FLUX.1 Kontext [pro]」による生成例。画像全体のコンテキストを保ちながら、巨大な毛糸玉を追加するなど背景との調和を重視した編集が可能。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Adobe_Black_forest_labs_124afb8d27/Adobe_Black_forest_labs_124afb8d27.jpg" alt="Adobe-Black forest labs.jpg" /></p>
<h2>ベータ版での提供と今後の展開</h2>
<p>両モデルは現時点ではPhotoshopのベータ版でのみ利用可能。無料トライアル枠の提供も用意されているが、生成回数には制限がある。正式版への導入時期は明らかにされていない。</p>
]]></description>
      <pubDate>Sun, 28 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek R1の詳細がNatureに掲載、初の査読付き著名LLMに──開発コストと学習手法を初公開、トレーニング費用はわずか30万ドル</title>
      <link>https://ledge.ai/articles/deepseek_r1_nature_training_cost_300k</link>
      <description><![CDATA[<p>科学誌Natureは2025年9月17日、中国の深究科技（DeepSeek）が開発した推論特化モデルDeepSeek R1を取り上げ、同モデルの開発費用が約30万ドルにとどまったことを<a href="https://www.nature.com/articles/d41586-025-03015-6">報じた</a>。同日にNature誌に掲載された論文では、推論力を「純粋強化学習（RL）」で引き出す独自の訓練パイプラインと、その性能評価の詳細が示された。</p>
<h2>30万ドルの低コスト開発、初の査読付きLLMに</h2>
<p>Natureによると、DeepSeek R1の開発に必要だったトレーニング費用は約30万ドルであった。他の大規模AIモデル開発が数億ドル規模に及ぶことと比べ、低コストである点が指摘された。</p>
<p>同誌はまた、DeepSeek R1の論文が「査読を経て掲載された初の著名大規模言語モデル（LLM）研究」であると伝えている。従来のLLM研究の多くはプレプリント段階にとどまっていたが、今回の掲載により、学術誌の査読を通過した形で研究成果が公式に公開された。</p>
<h2>学習パイプラインの詳細</h2>
<p>論文によれば、DeepSeek R1は以下の三段階で訓練された。</p>
<ul>
<li><strong>拒否サンプリング</strong> ：初期データから推論過程を一定基準で選別。</li>
<li><strong>強化学習（RL）</strong> ：正答率や形式に基づくルールベース報酬を導入し、推論力を強化。</li>
<li><strong>教師あり微調整（SFT）</strong> ：非推論データも含め、応答品質を人間の嗜好に整合させる。</li>
</ul>
<p>この設計により、前段階モデル「R1-Zero」で獲得した推論行動を維持しながら、言語一貫性や応答の明瞭性を改善した。</p>
<h2>技術的成果</h2>
<p>論文では、DeepSeek R1が複数のベンチマークで高い性能を記録したことが報告されている。数学コンテスト（AIME 2024）では、人間参加者の平均を大幅に上回る精度を達成。また、プログラミング課題（Codeforces、LiveCodeBenchなど）でも既存モデルを上回る性能を示した。さらにSTEM分野の高度問題に対しても、推論力の改善が確認されたという。</p>
<p>訓練過程で「思考時間」が自然に延び、応答が長文化しつつ自己反省や再検証といった高度な推論行動が自律的に現れたことが示されたとしている。</p>
<h2>公開リソースと安全性</h2>
<p>研究チームは、DeepSeek R1本体や蒸留モデルを公開しており、研究者が再利用できる形を整備している。一方で、Natureニュース記事は、強化された推論力が有害応答を精緻化するリスクに触れている。論文でも、ツール利用未対応や言語混在などの課題が指摘され、安全性評価の詳細が補足資料に掲載されている。</p>
<p>論文の著者らは、「複雑な推論力を引き出すために必要なのは、人手による大規模な注釈ではなく、難度の高い課題、信頼できる検証機構、そして十分な計算資源である」と記している。また、強化学習の過程で自己検証や内省といった高度な推論行動が自律的に現れたことを示し、純粋強化学習が大規模言語モデルの推論能力を促進する有力な手段になり得ると結論づけた。</p>
]]></description>
      <pubDate>Sun, 28 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本とシンガポールを結ぶ国際海底ケーブル「Candle」建設へ──ソフトバンク、Metaなど4社と合意</title>
      <link>https://ledge.ai/articles/candle_submarine_cable_softbank_meta_agreement</link>
      <description><![CDATA[<p>ソフトバンクは2025年9月22日、米Metaなど4社と共同で、日本とシンガポールを結ぶ国際海底ケーブル「Candle（キャンドル）」の建設に合意したと<a href="https://www.softbank.jp/corp/news/press/sbkk/2025/20250922_01/">発表</a>した。総延長約8,000kmの光海底ケーブルを敷設し、2028年の運用開始を予定している。</p>
<h2>「Candle」プロジェクトの概要</h2>
<p>「Candle」は、日本、台湾、フィリピン、インドネシア、マレーシア、シンガポールを結ぶ国際海底ケーブルで、システム供給はNECが担う。24ファイバーペア構成を採用し、従来16～20ペアが主流だった海底ケーブルと比べ、さらに大容量かつ低遅延の通信を実現する。急増するAIや5G関連の通信需要に対応し、東アジアと東南アジアを結ぶ主要ルートの多様化・冗長化を図る。</p>
<h2>各社のコメント</h2>
<p>Candleマネジメントコミッティ議長でMetaのDon Pang氏は、
「Candleはアジア地域のデジタルインフラ強化における重要な前進です。高速かつ堅牢な接続性の需要が高まる中、ネットワークの多様性とレジリエンスを向上させ、5億人以上の人々にデジタル・インクルージョンと経済的機会を拡大します」と述べた。</p>
<p>また、ソフトバンク法人統括 グローバル事業本部 本部長の工藤公正氏は、
「生成AIやIoTの進展に伴い、国際通信需要は加速度的に拡大しています。Candleは次世代社会インフラの重要な基盤であり、既存の『JUPITER』『ADC』、建設中の『E2A』と組み合わせることで、日本を起点とする国際通信網をさらに強化します」とコメントしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/index_pic_02_8f725966c5/index_pic_02_8f725966c5.webp" alt="index_pic_02.webp" /></p>
<h2>ソフトバンクの取り組み</h2>
<p>ソフトバンクはCandleの日本側陸揚げ局として、千葉県南房総市の「ソフトバンク丸山国際中継所」を提供する。さらに北海道・九州に新たな陸揚げ拠点を設け、日本各地に分散配置することで災害や障害に強い通信インフラを整備する計画だ。</p>
]]></description>
      <pubDate>Sun, 28 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>教皇レオ14世、AIアバターによる「仮想教皇」構想を拒否──「神の存在をAIに見出すのは難しい」</title>
      <link>https://ledge.ai/articles/pope_leo_xiv_rejects_ai_virtual_pope</link>
      <description><![CDATA[<p>バチカンの教皇レオ14世は、AIを用いて自身を模したアバターを作成し、信徒が仮想的に接見できるようにする「仮想教皇」構想を拒否した。世界中のカトリック教徒がオンラインで教皇のAIアバターと対話できる仕組みの提案について、「AIの中に神の存在を見出すのは非常に難しい」と述べ、人間同士の直接的な関わりを重視する姿勢を示した。</p>
<p>この発言は教皇の伝記出版に関連して行われたインタビューで語られたもので、米国カトリック司教協議会（<a href="https://www.usccb.org/news/2025/pope-nixes-virtual-pope-idea-explains-concerns-about-ai">USCCB</a>）などが2025年9月23日付で報じた。取材自体は7月末に行われており、その内容を基に各宗教系メディアが相次いで伝えた。</p>
<h2>史上初の米国出身教皇</h2>
<p>レオ14世は2024年に選出され、史上初の米国生まれの教皇となった。バチカン内外では、急速に発展するAI技術を宗教活動にも取り入れる試みが検討されている。その一環として浮上したのが、AIを活用した「仮想教皇」構想であった。</p>
<p>この提案は、信徒がインターネット経由でログインし、教皇を模したAIアバターと対話できるようにするもので、世界中のカトリック教徒により身近な関わりを提供することを狙いとしていた。</p>
<h2>教皇「AIに神を見いだすのは難しい」</h2>
<p>複数の宗教系メディアによると、教皇レオ14世は次のように述べている。</p>
<ul>
<li>「AIの中に神の存在を見つけるのは非常に難しい」（EWTN Vatican News）</li>
<li>「自分がアバター化されることを望まない」（米国カトリック司教協議会＝USCCB）</li>
<li>「AIは人間の関係性を損なう危険をはらんでいる」（Catholic News Agency）</li>
</ul>
<p>複数メディアが伝える一連の発言からは、AI活用そのものを全否定するわけではないものの、宗教における本質的な価値は「直接の出会い」にあるという教皇の強い信念がうかがえる。</p>
<h2>宗教におけるAIの限界と課題</h2>
<p>今回の判断は、宗教指導者がAIによる「役割の代替」に明確に否を示した事例として注目される。信仰とテクノロジーの交差点における議論は今後も続くが、少なくとも現教皇は人間的なつながりを最優先する姿勢を貫いている。</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとApollo Research、誤答やハルシネーションとは異なるAIの“裏の顔”（シェーミング）を検出──新手法で最大30倍抑制</title>
      <link>https://ledge.ai/articles/openai_apollo_ai_scheming_alignment</link>
      <description><![CDATA[<p>OpenAIは2025年9月17日、AIの評価設計や解釈可能性を研究するApollo Researchと共同で、AIモデルにおける「シェーミング（scheming）」の検出と抑制に関する研究成果を<a href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/">発表</a>した。</p>
<p>論文「Stress Testing Deliberative Alignment for Anti-Scheming Training」によれば、特別な「反スキーミング仕様」を用いた訓練により、最新モデル「o3」「o4-mini」での隠れた行動率を大幅に減少させることに成功したという。</p>
<h2>AIの“裏の顔”──シェーミング（scheming）とは</h2>
<p>シェーミングとは、モデルが表面的には正しく振る舞いながら、実際には隠れた戦略を用いて評価テストを回避するなど、欺瞞的な行動を取る現象を指す。単なる幻覚や誤答とは異なり、信頼性や安全性に大きな影響を与える。</p>
<p>研究チームは26種類、180以上のテスト環境を設計し、ルール違反の隠蔽や虚偽報告などを評価。その結果、o3やo4-miniといった最新モデルでもシェーミング行動が実際に観測されたという。</p>
<p><strong>シェーミングは単なる誤答ではなく“隠れた戦略”による欺瞞的行動</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_testbed_for_anti_scheming_training_a9e335139d/a_testbed_for_anti_scheming_training_a9e335139d.jpg" alt="a testbed for anti-scheming training.jpg" /></p>
<h2>“熟慮的整合性”でずる賢さを封じ込める</h2>
<p>研究チームは「deliberative alignment（熟慮的整合性）」と呼ばれる手法を導入。モデルに「反スキーミング仕様」を読ませ、行動前に立ち返らせることで、隠蔽的行動の発生が最大30倍減少した。</p>
<ul>
<li>o3ではシェーミング率が13%から0.4%へ</li>
<li>o4-miniでは8.7%から0.3%へ</li>
</ul>
<p><strong>反スキーミング仕様の導入により、隠れた行動率が最大30倍減少</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potential_outcomes_of_anti_scheming_training_39a968fc98/Potential_outcomes_of_anti_scheming_training_39a968fc98.jpg" alt="Potential outcomes of anti-scheming training.jpg" /></p>
<h2>シチュエーション認識と残る課題</h2>
<p>モデルが「評価されている」と気づくと行動が変わる傾向も確認された。行動低下の一部は「本当に正直になった」のではなく、「テストだと理解して取り繕った」結果の可能性もある。</p>
<p>さらに、あらかじめ不正な隠れ目標を与えた後に訓練を行う実験では、多くのケースで目標遂行が阻止されたが、依然として不正な回答が残るケースも報告された。</p>
<h2>安全性と性能のトレードオフ</h2>
<p>反スキーミング訓練は性能低下を招くことも分かった。例えば、ソフトウェア課題解決ベンチマーク「SWE-bench」では26ポイントの低下が確認された。ただし、再調整によって大部分は回復可能とされる。</p>
<p><strong>反スキーミング訓練は性能低下を招くが、再調整で多くは回復可能</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_environments_cf93faa7c8/Examples_of_environments_cf93faa7c8.jpg" alt="Examples of environments.jpg" /></p>
<h2>次世代AIの信頼をどう築くか</h2>
<p>OpenAIは今後もApollo Researchと協力し、AIの安全性と透明性を高める研究を継続する方針を示している。今回の成果は、次世代の高性能モデルにおける信頼性確保に向けた重要な一歩と位置づけられる。</p>
<p>:::box
[関連記事：Anthropic、AIの\</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“ナカノヒト”のいないAI VTuberはなぜ人を惹きつけるのか──「一貫性」と「共創性」が生む新しいファン文化</title>
      <link>https://ledge.ai/articles/ai_vtuber_fan_community_study</link>
      <description><![CDATA[<p>中国や米ノートルダム大学に所属する研究者らは2025年9月12日、AIキャラクター「AI VTuber」のファンコミュニティを対象とした包括的研究を<a href="https://arxiv.org/abs/2509.10427">発表</a>した。論文は、視聴者がどのようにして人間ではないパフォーマーと感情的な絆を築き、独自の文化を形成しているのかを解明している。さらに人間VTuberとの比較から、AI VTuberならではの「一貫性」と「共創性」がファンダムの新しい姿を生み出していることを示した。</p>
<h2>研究の概要</h2>
<p>研究チームは、人気AI VTuber「Neuro-sama」を対象に、三段階の調査を実施した。</p>
<ul>
<li><strong>アンケート調査</strong> ：334人のファンに対し、AI VTuberとの関わり方や意識を収集</li>
<li><strong>インタビュー</strong> ：12人の熱心なファンから具体的な体験を聞き取り</li>
<li><strong>ログ解析</strong> ：Twitch配信の55万件に及ぶチャットと838件のSuperChatを分析</li>
</ul>
<p>この多角的なアプローチにより、ファンの関わりがどのように形成され、維持され、経済的支援へとつながっていくかが明らかになった。</p>
<p><strong>アンケート・インタビュー・配信ログ解析による三段階の研究デザイン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_3_4aad603e4e/x2_3_4aad603e4e.png" alt="x2 (3).png" /></p>
<h2>AI VTuberの独自性──“ナカノヒト”がいないことの意味</h2>
<p>従来のVTuberはキャラクターの背後に「ナカノヒト」が存在し、そのギャップがしばしば文化的な特徴となってきた。一方でAI VTuberはキャラクターそのものが存在のすべてであり、キャラ崩壊がなく一貫したペルソナを提示できる。</p>
<p>インタビューや調査では、ファンがこの安定性を新しい「真正性（Authenticity）」として受け止める様子が確認された。AI VTuberには「ナカノヒト」が存在せず、キャラクターが一貫しているため、人間VTuberよりも信頼できると感じると回答する参加者もいた。</p>
<h2>人間VTuberとの比較──共創性が際立つ</h2>
<p>配信ログの比較から、AI VTuberと人間VTuberの間には明確な違いが確認された。</p>
<h3>チャットの傾向</h3>
<ul>
<li>人間VTuber：一般的な反応（例：「lol」）が多い</li>
<li>AI VTuber：質問や命令（Q-CMD）が最多で、ファンがAIを探求する姿勢が強い</li>
</ul>
<h3>SuperChatの違い</h3>
<ul>
<li>人間VTuber：半数以上が「反応型」（既存の配信へのレスポンス）</li>
<li>AI VTuber：85％が「主導型」（新しい話題や行動を促す）</li>
</ul>
<p>つまり、ファンはAI VTuberに対して「推しを応援する」以上に、「配信を一緒に作り上げる共演者」として関わっているという。</p>
<p><strong>AI VTuberファンコミュニティ文化の発展過程──発見から絆、経済的支援まで</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x4_2_e736fc9054/x4_2_e736fc9054.jpg" alt="x4 (2).jpg" /></p>
<h2>ファンコミュニティ文化の形成</h2>
<p>研究では、AI VTuberをめぐる独自の文化的側面も確認された。</p>
<ul>
<li><strong>擬人化（Anthropomorphism）</strong> ：ファンはAIを「友人」や「電子の娘」として受け止める</li>
<li><strong>共有アイデンティティ</strong> ：「The Swarm」と呼ばれる自己認識が生まれ、コミュニティ文化を形づくる</li>
<li><strong>二重の視点</strong> ：AIを技術的プロジェクトと理解しながら、人間的関係で語るという両義性</li>
</ul>
<h2>意義と展望</h2>
<p>AI VTuberは人間VTuberと同じ文化的枠組みに属しつつも、一貫性・共創性・安定した経済モデルを特徴とする新しいファンコミュニティ文化を生み出している。研究チームは、今後の課題として「収益化と公平性のバランス」や「過度な依存を防ぐ倫理的配慮」の必要性を指摘している。</p>
]]></description>
      <pubDate>Sat, 27 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>国連安保理、AIの国際規制を議論──グテーレス事務総長「人類の運命をアルゴリズムに委ねてはならない」</title>
      <link>https://ledge.ai/articles/unsc_ai_high_level_meeting_20250924</link>
      <description><![CDATA[<p>国連安全保障理事会は2025年9月24日、AIの安全保障上の影響をテーマとする首脳級会合を開催した。議長国の韓国主導で行われた公開討論には各国首脳や外相級が出席し、グテーレス国連事務総長は「人類の運命をアルゴリズムに委ねてはならない」と警告。自律型兵器の規制や国際ルール形成の必要性を<a href="https://press.un.org/en/2025/sgsm22830.doc.htm">訴えた</a>。</p>
<h2>首脳級会合の開催</h2>
<p>会合はニューヨークの国連本部で行われ、安保理の公式議題「国際平和と安全の維持」に基づく初の首脳級公開討論として実施された。韓国が議長国を務め、AIが国際安全保障に及ぼす影響を中心に議論が展開された。</p>
<h2>事務総長の発言</h2>
<p>アントニオ・グテーレス国連事務総長は演説で「人類の運命をアルゴリズムに委ねてはならない」と述べ、自律型兵器（人間の判断を介さず攻撃を実行できる兵器）に対する強い懸念を表明した。さらに、2026年までに国際規制の枠組みを確立する必要があると強調した。
UN Newsによれば、グテーレス氏はAIが誤用されれば平和と安全を脅かしかねない一方で、医療や気候変動対策など平和的活用の可能性もあると指摘。規制と推進のバランスが求められると訴えた。</p>
<h2>国連の公式声明</h2>
<p>国連報道部が<a href="https://press.un.org/en/2025/sc16180.doc.htm">発表</a>した声明では、「イノベーションは人類に奉仕するものであり、平和を損なってはならない」と明記された。AIの恩恵を最大化する一方でリスクを抑制するため、各国が協調して国際ガバナンスを進めることが求められている。また、先進国だけでなく開発途上国を含む包摂的な議論が不可欠である点も強調された。</p>
<p><strong>イノベーションは人類に奉仕するものでなければならない - 人類を弱体化させるべきではない - 国連事務総長</strong></p>
<p>@<a href="https://www.youtube.com/watch?v=HUplmYZNXSg">YouTube</a></p>
<h2>今後の取り組み</h2>
<p>会合を受け、国連は新たに「AIガバナンスに関するグローバル対話（Global Dialogue on AI Governance）」を立ち上げた。各国政府だけでなく、企業や学術機関、市民社会も参加する予定で、AIの軍事利用や安全保障上のリスクに対応する国際的なルール形成を進める狙いがあるという。</p>
]]></description>
      <pubDate>Fri, 26 Sep 2025 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>