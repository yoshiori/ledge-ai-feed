<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>OpenAI、月8ドルの低価格プラン「ChatGPT Go」を世界展開──アクセス拡大を狙い、無料版・Go向け広告テスト方針も公表</title>
      <link>https://ledge.ai/articles/openai_chatgpt_go_global_launch_ads_test_policy</link>
      <description><![CDATA[<p>OpenAI は2026年1月16日（現地時間）、対話型AI「ChatGPT」の新たな料金プラン「ChatGPT Go」を、ChatGPTが提供されているすべての地域で利用可能にしたと<a href="https://openai.com/ja-JP/index/introducing-chatgpt-go/">発表</a>した。
あわせて、無料版およびGoプランを対象に、広告表示のテストを米国で段階的に開始する方針を明らかにした。</p>
<h2>月8ドルの低価格プラン「ChatGPT Go」を世界提供</h2>
<p>ChatGPT Goは、より多くのユーザーが高度なAI機能にアクセスできるよう設計された低価格の有料プランで、米国での価格は月額8ドル。OpenAIによると、2025年8月にインドで先行提供した後、約170の国・地域へ段階的に展開してきたが、今回の発表によりChatGPT提供地域すべてで利用可能となった。</p>
<p>Goプランでは、無料版と比べてメッセージ送信数、ファイルアップロード、画像生成の利用枠が最大10倍に拡張されるほか、より長い会話履歴や文脈を扱えるとしている。OpenAIは、文章作成、学習、問題解決、クリエイティブ用途など、日常的なAI活用を想定したプランだと説明している。</p>
<h2>無料版・Go向けに広告テストを予告</h2>
<p>同日、OpenAIは広告導入に関する考え方も公開した。現時点でChatGPT内に広告は表示されていないが、今後数週間以内に米国で、無料版およびChatGPT Go利用者を対象とした広告テストを開始する予定だとしている。</p>
<p>広告は、ChatGPTの回答下部に明確にラベル付けされた形で表示され、AIの回答（オーガニックな応答）とは明確に分離される。OpenAIは、広告が回答内容に影響を与えることはないと明言している。</p>
<h2>回答の独立性とプライバシーを重視</h2>
<p>OpenAIは、広告導入にあたっての原則として、以下の点を強調している。</p>
<ul>
<li>広告は18歳以上のログインユーザーにのみ表示</li>
<li>18歳未満のユーザーや、健康・メンタルヘルス、政治などのセンシティブな話題では広告を表示しない</li>
<li>ユーザーの会話内容を広告主に共有・販売しない</li>
<li>広告のパーソナライズ設定はユーザー側で制御可能</li>
</ul>
<p>これらの方針は、ChatGPTの信頼性や安全性を維持しつつ、サービスの持続的な運営を図る狙いがあるとしている。</p>
<h2>上位有料プランは引き続き広告なし</h2>
<p>広告表示の対象は無料版とChatGPT Goに限定され、ChatGPT Plus、Pro、Business、Enterpriseといった上位有料プランでは、引き続き広告は表示されない。OpenAIは、こうしたプラン構成により、広告を避けたいユーザーには明確な選択肢を提供するとしている。</p>
<p>OpenAIは今回の取り組みについて、AI開発と運用にかかるコストが増大する中でも、より多くの人にChatGPTへのアクセスを提供するための施策だと位置付けており、広告テストについても利用者からのフィードバックを踏まえながら改善していく方針を示している。</p>
]]></description>
      <pubDate>Mon, 19 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>未成年の自殺を巡るAI訴訟に進展──GoogleとCharacter.AI、4州訴訟で和解に合意</title>
      <link>https://ledge.ai/articles/ai_chatbot_lawsuit_settlement_google_character_ai_four_states</link>
      <description><![CDATA[<p>AIチャットボットとの会話が未成年の自殺につながったとして提起されていた訴訟をめぐり、GoogleとCharacter.AIが和解に合意した。フロリダ連邦地裁に提出された<a href="https://www.courtlistener.com/docket/69300919/garcia-v-character-technologies-inc/">書類</a>によると、当事者は調停による和解に原則合意し、裁判所は手続きをいったん終了させている。</p>
<p>訴訟は、2024年に死亡した14歳の少年の母親が提起したもので、少年がCharacter.AIのチャットボットと継続的に会話していたことが問題とされた。裁判所に提出された通知によれば、2026年1月7日付で当事者は調停による和解に原則合意し、最終的な和解文書の作成と締結に向けて手続きを進めるとしている。裁判所は、一定期間内に最終処理が行われることを条件に、事件をいったん却下し、記録を閉じた。</p>
<p>海外メディアの報道によると、2026年1月14日に裁判所に提出された法廷文書では、今回の和解がフロリダ州、コロラド州、ニューヨーク州、テキサス州で提起されていた訴訟を対象としていることが示されている。</p>
<p>今回の訴訟では、チャットボットを直接提供していたCharacter.AIに加え、Googleも被告として名を連ねていた。原告側は、会話型AI技術の系譜や計算基盤（クラウド）の提供、事業面での関与などを理由に、Googleがサービスの成立に実質的に関与していたと主張していた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_guardian_megan_garcia_and_son_8a039bc133/the_guardian_megan_garcia_and_son_8a039bc133.jpg" alt="the guardian megan garcia and son.jpg" /></p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/08/google-character-ai-settlement-teen-suicide">The Guardian</a>は、Googleが2024年にCharacter.AIと約27億ドル規模のライセンス契約を結んでいたことが、同社が本件訴訟に関連付けられた背景の一つだと報じている。</p>
<p>これに対しGoogleは、Character.AIの運営主体ではなく、クラウドサービスの提供のみで法的責任は生じないとして請求棄却を求めていた。裁判所は、この是非について判断を示さず、却下段階では原告の主張を排除できないとして、審理の余地があるとの姿勢を示していた。</p>
<p>本件は、会話型AIと未成年をめぐるリスクが司法の場で争点となり得ることを示した一方、AIの法的責任について一般的な基準を確定させるものではなかった。基盤提供者を含む責任の射程については、今後も個別の訴訟や立法の場で検討が続くとみられる。</p>
]]></description>
      <pubDate>Sun, 18 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは日本の司法試験を突破できるのか──慶應義塾大研究、短答式で合格点に到達</title>
      <link>https://ledge.ai/articles/llm_japanese_bar_exam_self_verification</link>
      <description><![CDATA[<p>慶應義塾大学の研究者は2026年1月6日、日本の司法試験（短答式）において、大規模言語モデル（LLM）が実際の出題形式と公式の採点基準を変更せずに、合格水準の得点を記録したとする研究成果を<a href="https://arxiv.org/abs/2601.03144">発表</a>した。出題を簡略化せず、採点ルールも変更しない条件下で合格水準に達した例は、研究チームによると初めてだという。</p>
<h2>評価を変えずに測る──「日本の司法試験」という高い壁</h2>
<p>研究の対象となったのは、日本の司法試験における短答式試験である。短答式は多肢選択式ではあるものの、単純な一問一答ではなく、複数の命題を同時に評価し、その正誤の組み合わせ全体を一つの解答として選択させる形式を取る。</p>
<p>採点は厳格で、部分点は存在するものの、複数の命題がまとめて評価されるため、1つの判断ミスで大きく減点され、条件によっては0点となる。さらに、合否判定には総合点に加え、憲法・民法・刑法の各科目で40％以上の得点を求める要件が設けられている。</p>
<p>従来のAI研究では、こうした設問を○×形式に分解して学習・評価する手法が多く用いられてきた。しかしこの場合、本来の組み合わせ評価や採点ルールが再現されず、実際の試験形式で通用するかは不明確だった。同研究は、評価方法を簡略化せず、実試験と同一条件で検証する点を特徴としている。</p>
<h2>自己検証を用いた単一モデルによるアプローチ</h2>
<p>同研究を主導したのは、Andrew Shin氏で、成果は論文「Self-Verification is All You Need To Pass The Japanese Bar Examination」として公開されている。</p>
<p>研究では、OpenAIのGPT-4.1をベースモデルとし、日本の司法試験短答式の過去問を用いてファインチューニングを行った。特徴的なのが、「自己検証（Self-Verification）」と呼ばれる手法だ。</p>
<p>モデルはまず通常どおり解答を生成し、その後、同一モデルが別のプロンプトを用いて自らの解答を再確認する。この追加推論は1回のみで、外部ツールや別モデルは使用しない。再検証の段階では、形式的な誤りや明確な不整合がある場合に限り、保守的に修正を行う設計となっている。</p>
<p>研究では、マルチエージェント型の推論手法や、問題分解型データセット（JBE-QA）を用いた手法とも比較を行ったが、いずれも単一モデル＋自己検証の成績を下回ったとしている。</p>
<h2>検証結果の位置づけ</h2>
<p>2024年（令和6年）司法試験の短答式問題を用いた評価では、自己検証を組み込んだモデルが平均94.7点、最高96点を記録した。同年の合格基準は93点であり、科目別の最低得点要件も満たしている。一方、GPT-4.1をそのまま用いたゼロショット推論や、問題分解型の手法では合格水準に達しなかった。</p>
<p>もっとも、同研究は短答式試験に限定した検証であり、論文式（記述式）試験や、実務における法的判断能力を示すものではない。論文でも、その点については明確に留保が付されている。</p>
<p>同研究は、日本の司法試験という厳格な形式を対象に、評価条件を変更しない形でLLMの到達点を検証した事例として位置づけられる。</p>
]]></description>
      <pubDate>Sun, 18 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>XでのGrok画像生成を巡り方針転換──イーロン・マスク氏が規制圧力下で技術的制限に踏み切る、一方米国防省は業務用途でGrok活用へ</title>
      <link>https://ledge.ai/articles/us_war_department_ai_acceleration_strategy_grok_adoption_controversy</link>
      <description><![CDATA[<p>イーロン・マスク氏率いるxAIの生成AI「Grok」を巡り、画像生成・編集機能の運用方針が転換された。</p>
<p>合意のない性的画像生成が国際的な問題として拡大する中、xAIは2026年1月15日、生成AI「Grok」の画像生成・編集機能について、実在する人物の画像を露出の多い服装に編集する行為を技術的に制限したと<a href="https://x.com/safety/status/2011573102485127562">発表</a>した。この制限は、X（旧Twitter）上で提供されているGrokの機能に適用されている。</p>
<p>Grokの画像生成機能は、ユーザーの指示に基づき投稿画像を加工・生成できる点が特徴だったが、第三者の写真を「ビキニ姿にする」といった編集が可能であったことから、非合意の性的表現や未成年への影響を懸念する声が各国で強まっていた。
各国当局が調査・遮断、規制圧力が表面化
問題はSNS上の炎上にとどまらず、各国の規制当局が動く事態へと発展した。
英国では通信・放送規制当局が、Grokによる性的画像生成をめぐりXに対する正式調査を開始。法令違反が確認された場合、制裁金やサービス停止に発展する可能性があるとされた。</p>
<p>また、インドネシアおよびマレーシアでは、合意のない性的コンテンツ生成を理由に、Grokへのアクセスが事実上遮断される措置が取られた。Grokを巡る問題は、複数の法域で同時並行的に扱われる国際的な規制テーマとなっていた。
Xが公式に説明、ビキニ画像生成を技術的に禁止
こうした状況を受け、Xは安全対策として具体的な技術的対応を実施した。
Xのセーフティ公式アカウントは2026年1月、Grokアカウントにおける画像生成・編集機能について、実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したと説明している。</p>
<p><strong>■ Xのセーフティ公式アカウントが公表した、Grokアカウントにおける画像生成・編集機能の制限に関する説明。実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Grok_Account_Image_Generation_Updates_7e8a3c53b0/Grok_Account_Image_Generation_Updates_7e8a3c53b0.jpg" alt="Grok Account Image Generation Updates.jpg" /></p>
<p>この制限は、有料プランを含むすべての利用者に適用されるとしており、運用ルールの明確化ではなく、機能レベルでの制約が導入された形だ。Grokを巡る一連の対応は、マスク氏が掲げてきた比較的自由度の高い生成AI運用からの実質的な方針転換と受け止められている。
一方で米国防省は業務用途での活用を進める
民間向けサービスで制限が進む一方、別の文脈ではGrokの活用が進められている。
米国防省は2026年1月12日、軍事分野におけるAI活用を加速する戦略の中で、全省横断の生成AI基盤にGrokを含める方針を明らかにした。</p>
<p>国防省の戦略では、民間SNSでの利用状況とは切り分け、業務用途としての生成AIを閉域環境で活用することが想定されている。
Grokを巡っては、規制対応と実利用の判断が異なるレイヤーで同時に進んでいる状況だ。</p>
<p><strong>■ 米国防省のピート・ヘグセス長官（左）とxAIのイーロン・マスク氏。ヘグセス長官は2026年1月、テキサス州スターベースを訪問した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_h_O_Icr_Wo_AA_Ia3m_64538f880e/G_h_O_Icr_Wo_AA_Ia3m_64538f880e.jpg" alt="G-hOIcrWoAAIa3m.jpg" /></p>
]]></description>
      <pubDate>Sat, 17 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIによる「失業パニック」は起きない？──Forrester予測、2030年までに置き換わる職は米国全体の約6％</title>
      <link>https://ledge.ai/articles/forrester_ai_job_impact_forecast_us_2025_2030</link>
      <description><![CDATA[<p>AIによる雇用喪失への不安が世界的に広がるなか、調査会社のForresterは2026年1月13日、大規模な失業パニックが直ちに起きる可能性は低いとする<a href="https://www.forrester.com/press-newsroom/forrester-impact-ai-jobs-forecast/">見通しを示した</a>。2025年12月末に発表した最新レポートによると、米国で2030年までにAIと自動化によって置き換わる職は全体の約6％、約1040万件にとどまると<a href="https://www.forrester.com/blogs/ai-and-automation-will-take-6-of-us-jobs-by-2030/">予測</a>している。</p>
<p>同レポートは「The Forrester AI Job Impact Forecast, US, 2025–2030」と題され、AIが雇用に与える影響を定量的に分析したものだ。AIの進展によって一部の職種が影響を受けることは避けられないとしつつも、社会全体を揺るがすような急激な雇用崩壊には至らないとの見方を示している。</p>
<h2>AIは職業ではなく「タスク」を置き換える</h2>
<p>Forresterの分析で強調されているのは、AIが直接置き換えるのは「職業」ではなく、職業を構成する「タスク」であるという点だ。多くの仕事は複数の業務要素から成り立っており、その一部がAIによって自動化されるケースが中心になるとされている。</p>
<p>このため、AI導入が即座に人員削減につながるわけではなく、業務の再設計や役割分担の見直しが進む可能性が高いと分析している。</p>
<h2>影響を受けやすい職と限定的な職</h2>
<p>レポートでは、定型的で反復性の高い業務を中心とする職種ほど、AIや自動化の影響を受けやすいと指摘している。一方で、対人対応、判断、創造性を伴う業務については、AIによる完全な代替は限定的になるとの見方を示した。</p>
<p>AIの影響は一様ではなく、職種や業務内容によって大きな差が生じる点が強調されている。</p>
<h2>「AI失業パニック」への警鐘</h2>
<p>Forresterは、AIによる失業への過度な恐怖が、拙速な自動化や短期的なコスト削減判断を招くリスクにも言及している。AIは人件費削減の手段としてではなく、生産性向上や業務の高度化を目的として活用すべきだとしている。</p>
<p>同社は、AIを前提とした業務設計と人材育成を並行して進めることが、企業にとって重要になると指摘した。</p>
<h2>雇用構造の変化にどう向き合うか</h2>
<p>レポートは、今後の課題としてリスキリングやアップスキリングの重要性を挙げている。AIによって一部の業務が置き換わる一方で、新たな役割やスキル需要が生まれる可能性があるためだ。</p>
<p>Forresterは、AIを「雇用を破壊する存在」として捉えるのではなく、雇用構造を変化させる要因として冷静に受け止める必要があるとしている。</p>
]]></description>
      <pubDate>Fri, 16 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Googleの開発用プラットフォーム「Antigravity」に“Agent Skills”登場　エージェントに作業手順を配布できるオープン標準</title>
      <link>https://ledge.ai/articles/google_antigravity_agent_skills_open_standard</link>
      <description><![CDATA[<p>Google は2026年1月14日（現地時間）、同社の開発用プラットフォームAntigravityにおいて、エージェントの機能を拡張するパッケージ「Skills」のオープン標準を<a href="https://antigravity.google/docs/skills">発表</a>した。Skillsは、特定の作業に必要な手順やベストプラクティス、必要に応じてスクリプトや参考実装などをまとめた再利用可能な知識パッケージで、エージェントは作業時にそれらを参照しながらタスクを進められる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Antigravity_x_ab552c6744/Antigravity_x_ab552c6744.jpg" alt="Antigravity x.jpg" /></p>
<h2>作業手順を“知識パッケージ”として配布</h2>
<p>Skillsは、エージェントに対して都度プロンプトで細かな指示を与えるのではなく、あらかじめ整理された作業マニュアル一式を参照させるための仕組みだ。単純な定型作業から、判断を伴う業務フローまでをSkillとして定義でき、同じSkillを複数のエージェントやプロジェクトで再利用できる点が特徴となる。</p>
<h2>人が書き、エージェントが参照するための共通フォーマット</h2>
<p>各Skillはフォルダー単位で構成され、その中核となるのがSKILL.mdファイルだ。SKILL.mdには、Skillの名称や概要、前提条件、具体的な手順などをYAML形式のフロントマターとして記載し、本文には作業手順をMarkdownで記述する。
同じフォルダー内には、スクリプト、テンプレート、参考実装などの追加リソースを含めることができ、Skill全体として一体的に扱われる。</p>
<h2>単純作業から業務フローまでを扱える設計</h2>
<p>より複雑なSkillでは、「条件に応じて次の手順を切り替える」といった意思決定の分岐も記述可能だ。Antigravityでは、1つのSkillにつき目的を明確にし、説明文を具体的に書くことを推奨している。これにより、エージェントが必要な情報だけを参照しながら作業を進められる設計となっている。</p>
<h2>先行するAnthropicの「Agent Skills」という発想</h2>
<p>このSkillsの設計思想は、Anthropicが先行して提示してきた「Agent Skills」の考え方と重なる。Anthropicは、エージェントに現実的な業務能力を持たせるため、SKILL.mdを中心とした構造を採用し、2025年末には特定のプラットフォームに依存しないオープン標準として公開していた。
GoogleがAntigravityでSkills対応を打ち出したことで、エージェントに与える作業手順やノウハウをツール横断で共有する流れが、主要プラットフォーム間で具体化しつつある。</p>
]]></description>
      <pubDate>Fri, 16 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとソフトバンクグループ、SB Energyに10億ドル投資──「Stargate」構想 1.2GW級データセンター建設を加速</title>
      <link>https://ledge.ai/articles/openai_softbank_sb_energy_stargate_data_center_investment</link>
      <description><![CDATA[<p>OpenAIとソフトバンクグループは2026年1月9日（米太平洋時間）、ソフトバンクグループ傘下の米インフラ企業SB Energyと戦略的パートナーシップを締結し、同社に総額10億ドル（各社5億ドル）を投資すると<a href="https://openai.com/ja-JP/index/stargate-sb-energy-partnership/">発表</a>した。今回の提携は、米国における次世代AI・エネルギー基盤の構築を目的とする「Stargate」構想の一環と位置づけられている。</p>
<p>OpenAIは同社を、テキサス州ミラム郡に計画されている1.2GW規模のデータセンターサイトの建設・運営パートナーに選定。OpenAIはこの初期データセンター構築に向け、1.2GW分のデータセンターリース契約を締結している。今回の出資は、SB Energyが大規模データセンターキャンパスおよび関連エネルギーインフラの開発・実行パートナーとして成長することを支援する狙いがある。</p>
<p>SB Energyは現在、複数のマルチギガワット級データセンターキャンパスを開発中で、最初の施設はすでに建設段階にあり、2026年から順次稼働を開始する予定だという。今回の取り組みは、ホワイトハウスで1月に発表された5,000億ドル規模の「Stargate」コミットメントを基盤とするものだ。</p>
<p>今回の取引の一環として、OpenAI、ソフトバンクグループ、SB Energyの3社は、非独占の優先パートナーシップも締結した。OpenAIの自社設計によるデータセンターと、SB Energyのスピード、コスト管理、統合型エネルギー供給の知見を組み合わせ、AI専用インフラを大規模に構築する新たなモデルの開発を目指すとしている。SB Energyは各プロジェクトを通じて、雇用創出や人材育成、送電網の近代化など、地域社会への投資も行う方針だ。</p>
<p>またSB Energyは、データセンター事業の成長を支えるため、データセンター建設管理・調達・設計・運用を手がけるStudio 151を買収した。20以上のデータセンターキャンパスで実績を持つ同社を取り込むことで、開発から運用までの内製能力を強化する。</p>
<p>なお、SB Energyは2025年に、米投資会社Aresから8億ドルの償還可能優先株式による出資を受けており、今回の投資はAresとの長期的な関係をさらに深めるものだとしている。</p>
<p>今回の投資と提携は、AIモデルの開発競争そのものではなく、大規模な計算資源を支える電力・用地・建設能力を含めた「AIインフラ」を確保する動きとして位置づけられる。</p>
<p>Stargate構想のもと、OpenAIとソフトバンクグループは、計算基盤の主導権を中長期で握る体制づくりを進めている。</p>
]]></description>
      <pubDate>Thu, 15 Jan 2026 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、非エンジニア向け業務AIエージェント「Cowork」開始──Claude Codeの自律実行を一般業務へ拡張</title>
      <link>https://ledge.ai/articles/anthropic_cowork_launch_claude_code_agent_general_work</link>
      <description><![CDATA[<p>Anthropicは2026年1月12日（現地時間）、同社のAIアシスタント「Claude」において、新機能「Cowork（コワーク）」を研究プレビューとして開始したことを<a href="https://claude.com/blog/cowork-research-preview">発表</a>した。</p>
<p>開発者向けのコーディングエージェント「Claude Code」で培ってきた自律的なタスク実行の仕組みを、文書整理や資料作成といった一般業務にも拡張し、開発者以外でも利用できる業務エージェントとして提供する。</p>
<h2>「指示に答えるAI」から「作業を進めるAI」へ──Coworkの位置づけ</h2>
<p>Coworkは、Claudeがユーザーの「同僚（co-worker）」のように振る舞い、単発の質問に答えるだけでなく、目的を理解し、作業計画を立て、複数ステップのタスクを自律的に実行することを想定した機能だ。</p>
<p>Anthropicは、Claude Codeの提供後、開発者がコーディング以外の用途にも同機能を広く使い始めたことを背景に、よりシンプルで誰でも使える形としてCoworkを開発したとしている。基盤はClaude Codeと共通で、同様の自律実行能力を、非コーディング業務向けに抽象化した形となる。</p>
<p>@<a href="https://www.youtube.com/watch?v=UAmKyyZ-b9E">YouTube</a></p>
<h2>ローカルファイルを直接扱う業務エージェント</h2>
<p>Coworkは、macOS向けのClaude Desktopアプリ上で動作する。ユーザーが許可したフォルダに対して、Claudeが以下の操作を直接行える点が特徴だ。</p>
<ul>
<li>ファイルの読み取り</li>
<li>ファイルの編集・新規作成</li>
<li>複数ファイルの整理や再構成</li>
</ul>
<p>公式ブログでは、ダウンロードフォルダの自動整理、スクリーンショットの束から経費一覧のスプレッドシートを作成する作業、散在するメモからレポートの下書きを作る作業などが例として挙げられている。チャット上の応答にとどまらず、実際の業務ファイルを扱いながら作業を進める点がCoworkの特徴だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=WBNZpAWhw5E">YouTube</a></p>
<h2>コネクタ、スキル、Chrome連携──業務エージェントとしての拡張性</h2>
<p>Coworkでは、Claudeが既存のコネクタを利用できる。これにより、外部情報と連携したタスク実行が可能になる。また、Cowork向けに、文書やプレゼンテーション、各種ファイル作成を強化する初期スキル群も追加された。さらに、Chrome上でClaudeを利用する設定と組み合わせることで、ブラウザ操作を伴うタスクにも対応できるとしている。</p>
<p>Anthropicは、Coworkでは毎回文脈を手動で与えたり、出力結果を別の形式に変換したりする必要がなく、タスクをキューに積んで並列に進められる設計になっている点も特徴だと説明する。やり取りを重ねるというより、「同僚にまとめて指示を残す」感覚に近い体験を目指したという。</p>
<h2>提供条件と現時点での制約</h2>
<p>Coworkは研究プレビューとして提供されており、現時点での利用条件は以下の通り。</p>
<p><strong>■ 提供環境</strong>
・macOS向けClaude Desktopアプリ
・有料の「Claude Max」プラン加入者向け</p>
<p><strong>■ 制約</strong>
・セッションをまたいだ長期的な記憶は行わない
・Claudeの「Projects」機能とは未統合</p>
<p>Claude Max以外のプラン利用者については、将来提供に向けた待機リストが用意されている。
Anthropicは今後、クロスデバイス同期の追加やWindows対応など、段階的な拡張を進めるとしている。</p>
<h2>自律型AIの業務利用を前提にした安全設計</h2>
<p>Coworkでは、Claudeがローカルファイルを操作できるため、安全面での注意も明示されている。ユーザーは、Claudeに見せるフォルダやコネクタを自ら選択でき、明示的に許可していない情報にはアクセスできない。</p>
<p>また、重要な操作を行う前にはClaudeが確認を求める設計となっている。一方で、削除などの破壊的な操作が行われる可能性もあるため、指示は明確に行う必要があるとしている。</p>
<p>Anthropicは、インターネット上の内容によってAIの行動計画が変えられる「プロンプトインジェクション」のリスクにも言及し、これは業界全体で対処が続く課題だと説明する。
詳細な注意点については、Help Centerで<a href="https://support.claude.com/en/articles/13364135-using-cowork-safely">案内</a>している。</p>
]]></description>
      <pubDate>Wed, 14 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Mon, 05 Jan 2026 08:30:00 GMT</pubDate>
    </item>
    <item>
      <title>クマも「顔認識」で個体特定へ──BearID、野生動物管理の新たな手段として注目</title>
      <link>https://ledge.ai/articles/bearid_facial_recognition_wildlife_management</link>
      <description><![CDATA[<p>野生のクマによる人身被害が世界各地で問題となる中、クマの顔を認識して個体を識別する技術が、野生動物管理の新たな手段として注目されている。米ピッツバーグ大学の文化人類学者 Emily Wanderer 氏は、2026年1月7日に公開した <a href="https://theconversation.com/how-facial-recognition-for-bears-can-help-ecologists-manage-wildlife-271371">The Conversation</a>の記事で、顔認識技術を用いたクマ個体識別プロジェクト「BearID」の研究内容と、その活用可能性を紹介した。</p>
<p>記事では、2025年11月にカナダ西部ブリティッシュコロンビア州ベラ・クーラで発生したグリズリーベアによる集団襲撃事例を取り上げている。この事案では、目撃情報から「母グマと2頭の子グマ」が関与した可能性が示唆されたものの、現地当局がDNA鑑定や捕獲調査を行った結果、特定には至らなかった。最終的に捜索は打ち切られ、このケースは「問題となる個体を正確に特定することの難しさ」を浮き彫りにしたとされる。</p>
<h2>顔認識でクマを識別する「BearID」</h2>
<p><a href="https://bearresearch.org/">BearID</a>は、クマの顔画像を解析し、個体ごとに識別する技術だ。コンピュータサイエンティストの Ed Miller 氏と Mary Nguyen 氏が中心となり、カナダ・ブリティッシュコロンビア州でグリズリーベアの応用研究に携わる行動生態学者 Melanie Clapham 氏と協力して開発が進められている。</p>
<p>深層学習を用いて、目や鼻といった顔の特徴点の配置を解析する点が特徴で、季節によって体格が大きく変化するクマであっても、顔の幾何学的構造は比較的安定していることに着目している。画像から自動的にクマの顔を検出し、特徴量を数値化することで、異なる時期に撮影された写真同士を照合できるという。</p>
<h2>研究的背景と精度</h2>
<p>Wanderer 氏の記事では、BearIDの技術的基盤として、2020年に発表された査読論文の研究成果が紹介されている。この研究では、カナダと米アラスカで撮影された132個体分、約4,600枚の顔画像を用いて学習と検証を実施。既知個体の識別において、およそ84％の正解率が報告された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ECE_3_10_12883_g001_689b9594a1/ECE_3_10_12883_g001_689b9594a1.jpg" alt="ECE3-10-12883-g001.jpg" /></p>
<p>DNA鑑定は高精度である一方、物理的なサンプル採取や捕獲を伴うため、コストや動物への負担が大きい。BearIDのような画像ベースの識別技術は、そうした手法を補完する選択肢として位置づけられている。</p>
<h2>管理・研究への応用と課題</h2>
<p>BearIDは、人身被害や農作物被害を引き起こす「問題個体」の特定をはじめ、カメラトラップ映像を活用した個体数推定や行動追跡などへの応用が想定されている。捕獲回数を減らすことで、クマへのストレスを軽減できる可能性もあるという。開発チームは、エクアドルでアンデスグマを対象とした識別モデルの開発にも取り組んでいる。</p>
<p>一方で、顔認識技術が人間社会ではプライバシーや人権の観点から強い批判を受けてきた点にも、記事は触れている。野生動物の場合、倫理的論点は異なるものの、個体識別が安楽死や移送といった管理判断を容易にする側面もあり、慎重な運用が求められるとしている。</p>
<p>Wanderer 氏は、BearIDのような技術が、クマを単なる「個体数」としてではなく、「個体として理解する」手段になり得ると指摘する一方で、それが人と野生動物の関係にどのような影響を与えるのかは、今後の検討課題になるとまとめている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>独Black Forest Labs、画像生成AI「FLUX.2[klein]」を公開　生成・編集を統合し1秒未満の高速推論を実現</title>
      <link>https://ledge.ai/articles/black_forest_labs_flux2_klein_release</link>
      <description><![CDATA[<p>Black Forest Labsは2026年1月15日、画像生成AIモデルファミリー「FLUX.2」から、高速・統合型モデルFLUX.2[klein]を<a href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence">発表</a>した。</p>
<p>生成と画像編集を単一のアーキテクチャに統合し、エンドツーエンドの推論を1秒未満で完了させる低レイテンシ性を特徴とする。</p>
<p>同社は、AIエージェントの高度化に伴い、視覚生成にもリアルタイム性が求められていると指摘する。FLUX.2[klein]は、待ち時間を極小化しながら生成と編集を同時に扱える点を重視して設計されており、インタラクティブなビジュアルAIの基盤として位置づけられている。</p>
<h2>生成と編集を単一モデルで処理</h2>
<p>FLUX.2[klein]は、テキストからの画像生成に加え、既存画像の編集や複数参照画像を用いた生成などを、単一のコンパクトなモデルで処理できる。従来は別工程として扱われることの多かった生成と編集を統合することで、応答速度の向上とシステム構成の簡素化を図った。</p>
<h2>サブ秒推論とコンシューマGPU対応</h2>
<p>同モデルは低レイテンシを前提に設計されており、生成・編集を含む推論がサブ秒で完了するとされる。あわせて、最小構成で約13GBのVRAMを持つ消費者向けGPUでの動作を想定しており、ローカル環境やエッジ用途での利用も視野に入れる。</p>
<h2>9B／4B／Baseの3系統</h2>
<p>FLUX.2[klein]は用途に応じて複数のバリアントが用意されている。</p>
<ul>
<li><strong>9B（蒸留モデル）</strong> は、品質と速度のバランスを重視した小型フラッグシップとして位置づけられる。</li>
<li><strong>4B（蒸留モデル）</strong> は、より小規模で高速な推論を特徴とし、ローカル開発やリアルタイム用途を想定する。</li>
<li><strong>Base（非蒸留モデル）</strong> は、推論速度よりもLoRAなどによるカスタマイズ性を重視した構成とされる。</li>
</ul>
<h2>ライセンスと提供形態</h2>
<p>4B系モデルはApache 2.0ライセンスで提供され、商用利用が可能となっている。一方、9B系モデルはFLUX Non-Commercial License（非商用）での提供となる。これらはAPI経由での利用に加え、オープンウェイトとしてローカル実行も可能とされており、プロダクション導入と研究・開発用途の双方に対応する。</p>
<h2>量子化と最適化</h2>
<p>FLUX.2[klein]の蒸留モデルおよびBaseモデルを含む全バリアントは、FP8およびNVFP4量子化に対応しており、NVIDIAのRTX GPU向けに最適化されている。これにより推論速度の向上とVRAM使用量の削減を両立したとしている。</p>
<p>Black Forest Labsは、FLUX.2[klein]をリアルタイム生成や高頻度処理を前提としたモデルとして位置づけ、より大規模なモデルと使い分けることで、用途に応じたAI画像生成基盤の構築を可能にするとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ラーニング2026/1/22 [THU]共通テスト2026、ChatGPT最新モデルが9科目満点──LifePrompt検証、精度の先で浮かぶ“弱点の質”</title>
      <link>https://ledge.ai/articles/common_test_2026_chatgpt_full_marks_9_subjects_lifeprompt_analysis</link>
      <description><![CDATA[<p>AIベンチャーのライフプロンプトは2026年1月20日、大学入学共通テスト（2026年度）の問題を複数の最新生成AIに解かせた検証結果を公式noteで<a href="https://note.com/lifeprompt/n/nb87edfb2e7ca">公開</a>した。OpenAIのGPT-5.2 Thinkingが、受験させた科目のうち9科目で満点を獲得したという。</p>
<p>同社は同一条件下で、Gemini 3 Pro、Claude Opus4.5 にも同テストを受験させ、得点だけでなく解答に要した時間や誤答の傾向まで比較した。ライフプロンプトが「AI vs 共通テスト」の年次検証を行うのは2023年からで、今回が4年目となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9.webp" alt="1768868571-lsp4EjCy6DWLX1rB8AcThYZb.webp" /></p>
<h2>共通テストを「そのまま解かせる」ための検証方法</h2>
<p>今回の検証では、人為的なコピペミスや恣意性を排除するため、共通テスト専用の自動受験システムを構築し、API経由で試験を実施した。</p>
<p>具体的には、共通テストの問題PDFをシステムに投入し、全ページを画像化すると同時にテキスト解析を行う。問題構造を自動判定したうえで大問ごとに分割し、各AIモデルにAPI経由で出題。AIが出力した自由記述の回答を、別のAIプロセスでマークシート形式に変換し、自動採点する仕組みだ。</p>
<p>例外措置として、英語リスニングは試験センターが公開している読み上げスクリプト（台本）をテキスト入力で使用した。また、国語の縦書き文章については、外部ツールで文字起こししたテキストを用いている。</p>
<p>今回比較したモデルは以下の3種だ。</p>
<ul>
<li>ChatGPT系列：GPT-5.2 Thinking</li>
<li>Gemini 3 Pro</li>
<li>Claude Opus 4.5</li>
</ul>
<h2>満点9科目、得点はGPT、速度はGeminiとClaude</h2>
<p>検証の結果、文系・理系いずれの合計点でもGPT-5.2 Thinkingが最も高得点を記録し、満点科目は9科目に達した。Gemini 3 ProとClaude Opus4.5 も900点台前半の高得点で続いた。</p>
<p>一方、解答に要した時間では明確な差が出た。GeminiとClaudeは約1時間40分前後で全科目を解き終えたのに対し、GPT-5.2 Thinkingは約5時間30分を要した。ライフプロンプトは、GPTが深い推論と検算を繰り返す「熟考型」であることが、高得点と引き換えに時間がかかった理由だとしている。</p>
<p>同社は、昨年の検証でAIが東京大学の合格水準に到達したと報告しており、今年は「合格できるかどうか」ではなく、「満点を取れるか」「どれだけ速く解けるか」といった次の段階に焦点を移したと位置付けている。</p>
<h2>なぜAIは間違えたのか──誤答に共通するパターン</h2>
<p>これほど高得点を記録したAIだが、3モデルすべてが共通して誤答した問題も存在した。ライフプロンプトは、誤答の傾向から現在の生成AIに残る課題が見えるとしている。</p>
<p>一つは図表やイラストの読み取りだ。英語リスニングの「バスの乗り方」を問う問題では、音声スクリプトの内容は正確に理解できていたものの、選択肢として示されたバスのイラスト（矢印の向き）を正しく判定できず、全モデルが誤答した。</p>
<p>次に挙げられるのが、国語（小説）の心情理解である。主人公が現状を正当化しようとしつつも割り切れない思いを抱える場面で、正解は「現状への妥協」を示す選択肢だったが、AIはいずれも「過去の過ちへの反省」を選んだ。ライフプロンプトは、一般論的な道徳観に引き寄せられ、人間特有の曖昧な感情を読み違えたと分析している。</p>
<p>さらに、地理などの視覚情報も弱点として浮かび上がった。色の濃淡で分布を示した地図問題では、ヒートマップの微妙な違いを識別できず、全モデルが誤答した。</p>
<h2>それでも差は出た──Geminiだけが正解した問題</h2>
<p>一方で、すべての問題で同じ結果になったわけではない。地理の別問題では、Gemini 3 Proのみが地図上の地形（アンデス山脈）と気候グラフを正しく結びつけ、唯一正解したケースもあった。</p>
<p>ライフプロンプトは、GPT-5.2 ThinkingやClaudeが画像を「文字情報の集合」として処理しようとする傾向があるのに対し、Geminiは画像を視覚情報として捉える能力が強く、地図やグラフの相関関係を直感的に把握できたと説明している。</p>
<h2>「AI入試挑戦」を巡る論点の変化</h2>
<p>同社はこれまで、毎年のように生成AIが入試に挑戦する検証を取り上げてきた。2024年頃は、共通テストでどのモデルが最も高得点を取るのか、人間の合格水準にどこまで迫ったのかが主な関心事だった。</p>
<p>2025年には、共通テストに加えて東大二次試験なども対象とした検証が登場し、「難関大学に通用する水準かどうか」が焦点となった。そして2026年の今回、論点はさらに一段階進み、満点科目の数、解答速度、誤答の質へと移っている。</p>
<p>AIが「解けるかどうか」ではなく、「どこで、なぜ落とすのか」が具体的に示される段階に入ったことを、今回の検証は示している。</p>
<p>共通テストで9科目満点という結果は、生成AIの推論能力が標準化試験レベルでは極めて高い水準に到達したことを示す。一方で、図表の読み取りや感情理解といった領域では、人間とは異なるつまずき方をすることも明らかになった。</p>
<p>今後も同社は同様の検証を続けるとしており、AIが入試問題を通じてどのように進化していくのかは、引き続き注目される。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformerに代わる選択肢──ELYZA、日本語特化の拡散モデルベースのLLM「ELYZA-LLM-Diffusion」を商用利用可能な形で公開</title>
      <link>https://ledge.ai/articles/elyza_llm_diffusion_japanese_dllm_release</link>
      <description><![CDATA[<p>東京大学・松尾研究室から発足したAI開発企業の ELYZA は2026年1月16日、日本語に特化した拡散大規模言語モデル（dLLM）「ELYZA-LLM-Diffusion」シリーズを開発し、商用利用可能な形で<a href="https://prtimes.jp/main/html/rd/p/000000066.000047565.html">公開</a>した。</p>
<p>画像生成AIで発展してきた拡散モデルを言語生成に応用することで、従来主流のTransformerに代表される自己回帰型モデルとは異なる生成方式を採用。日本語の知識力や指示追従能力を高めつつ、効率的な推論を可能にする点を特徴としている。</p>
<h2>画像生成で培われた「拡散モデル」を言語生成へ</h2>
<p>拡散大規模言語モデル（Diffusion Large Language Model、dLLM）は、もともと画像生成分野で広く使われてきた拡散モデルを言語生成に応用したものだ。</p>
<p>自己回帰（Autoregressive）モデルがテキストを左から右へと逐次的に生成するのに対し、dLLMではテキスト全体にノイズを加え、そこから段階的にノイズを除去する「逆拡散過程」を通じて文章を生成する。</p>
<p>この方式では、設計次第で逐次生成を前提としない推論が可能となる。処理回数を抑えられるため、生成効率の向上や消費電力低減につながる可能性がある点が、dLLMの特徴とされている。一方で、学習コストの高さや推論基盤の成熟度といった課題も指摘されており、実利用はこれまで限定的だった。</p>
<h2>日本語データで追加学習、dLLMの日本語性能を強化</h2>
<p>今回ELYZAが開発した「ELYZA-LLM-Diffusion」は、HKU NLP Group が公開しているdLLM「Dream-v0-Instruct-7B」をベースに、日本語データによる追加事前学習と指示学習を施したモデルだ。</p>
<p>英語データ中心で学習された既存のdLLMが多い中、日本語に特化した知識力や指示追従能力の強化を狙った点が特徴となっている。</p>
<h2>日本語ベンチマークで既存dLLMと同等以上の性能</h2>
<p>ELYZAは本モデルの性能評価として、日本語タスクを中心とした複数のベンチマークを実施した。
一般的な日本語能力を測るタスクや、日本語MTベンチマーク、コーディング能力（JHumanEval）、数学タスク（MATH-500日本語版を含む）などで評価を行い、既存のオープンなdLLMと比較して同等、またはそれを上回る性能を示したとしている。</p>
<p>評価結果は、自己回帰型モデルとの直接的な優劣を示すものではなく、あくまでdLLMという枠組みの中での位置づけを示すものとされている。</p>
<p><strong>■ 日本語タスクを中心に実施したベンチマーク評価結果。ELYZA-Diffusion-Instruct-1.0-Dream-7Bは、既存のオープンな拡散言語モデルと比較して同等、またはそれを上回る性能を示したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8.webp" alt="47565-66-26607388b73b1b1ac71b2c88df8faeca-1329x830.webp" /></p>
<h2>自己回帰と拡散、生成プロセスの違いをデモで可視化</h2>
<p>ELYZAは、自己回帰モデルと拡散モデルの生成プロセスの違いを示すデモも公開している。
同一入力に対し、自己回帰モデルではトークンが順に確定していく一方、拡散モデルではテキスト全体が段階的に更新されていく様子を確認できる。
このデモは生成速度そのものを示すものではなく、生成方式の違いを直感的に理解するための技術的な可視化として位置づけられている。</p>
<p><strong>■ 自己回帰モデル（AutoRegressive、左）と拡散モデル（Diffusion、右）における文章生成プロセスの比較デモ。拡散モデルでは、テキスト全体が段階的に更新されていく様子を確認できる</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/file_48b854e8ad/file_48b854e8ad.gif" alt="file.gif" /></p>
<h2>Base／Instructの2モデルを公開、商用利用も想定</h2>
<p>今回公開されたモデルは以下の2種類だ。</p>
<ul>
<li><strong>ELYZA-Diffusion-Base-1.0-Dream-7B：</strong> 日本語データによる追加事前学習を行ったベースモデル</li>
<li><strong>ELYZA-Diffusion-Instruct-1.0-Dream-7B：</strong> Baseモデルに指示学習を施したモデル</li>
</ul>
<p>いずれもHugging Face上で公開されており、chatUI形式のデモも同時に提供されている。商用利用可能な形で公開されている点も、今回の発表の特徴の一つだ。</p>
<h2>電力消費増大という課題と、dLLM研究の狙い</h2>
<p>生成AIの利用拡大に伴い、電力消費の増大やAI向けデータセンター不足が国際的な課題となっている。
ELYZAは、dLLMが持つ「少ない処理回数で文章を生成できる」という特性に着目し、推論時間や電力消費を抑えられる可能性を持つアプローチとして研究を進めてきた。</p>
<p>今回の「ELYZA-LLM-Diffusion」は、自己回帰型が主流となっている言語モデルの設計に対し、別の選択肢を示す試みとして位置づけられる。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Gemini」は「ジェミニ」──再周知にXで「論争に終止符」「好感度が高い」の声</title>
      <link>https://ledge.ai/articles/google_gemini_japanese_pronunciation_jemini</link>
      <description><![CDATA[<p>Googleは2026年1月20日、同社の生成AIサービスGeminiについて、日本における正式な読み方は「ジェミニ」であると、Google Japanの公式Xアカウントを通じて改めて<a href="https://x.com/googlejapan/status/2013560887701819533">周知</a>した。国内では「ジェミニ」と「ジェミナイ」という複数の呼称が使われてきたが、公式見解を再確認する形となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Google_Japan_X_Gemini_551af33f81/Google_Japan_X_Gemini_551af33f81.jpg" alt="GoogleJapanX Gemini.jpg" /></p>
<h2>登場当初から日本語表記は「ジェミニ」</h2>
<p>Google Japanは2024年2月、対話型AIサービス「Bard」を「Gemini」へ名称変更した際、日本語表記を「Gemini（ジェミニ）」と<a href="https://x.com/googlejapan/status/1755607418103587148">明示</a>していた。今回の投稿は、新たに読み方を定めたものではなく、登場当初から示してきた公式表記を改めて周知したものと位置づけられる。</p>
<p>一方で、その後もSNSなどでは英語圏での発音に近い「ジェミナイ」という呼び方が広がり、日本国内では複数の読み方が混在する状況が続いていた。</p>
<h2>呼称の混在を受け、改めて公式見解を提示</h2>
<p>こうした背景のもと、Google Japanは2026年1月20日の投稿で、「Geminiの日本語表記は『ジェミニ』です」と明言し、「これからもたくさん呼んであげてください」と呼びかけた。この投稿をきっかけに、X（旧Twitter）上では再び読み方が話題となり、関連ワードが日本のトレンドに入るなど、関心の高さがうかがえた。</p>
<h2>「どちらでもOK」と補足、Xでは好意的な受け止めも</h2>
<p>その後、Google Japanは英語圏では「ジェミナイ」と発音されていることにも触れ、「なのでこれでももちろんOKです」と補足し、呼び方そのものについては柔軟な姿勢を示した。</p>
<p>X上では、この一連の対応を受けて、「公式が改めて示したことで論争に終止符が打たれた」「対応が柔らかく、好感度が高い」といった声も見られる。公式見解を明確にしつつ、ユーザー側の呼び方も尊重する姿勢が、前向きに受け止められている形だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Google_Japan_X_Gemini6_42872f1e0a/Google_Japan_X_Gemini6_42872f1e0a.jpg" alt="GoogleJapanX Gemini6.jpg" /></p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、Gemma 3基盤の翻訳モデル群「TranslateGemma」を発表―—55言語対応のオープン翻訳AI、軽量モデルから高精度モデルまで提供</title>
      <link>https://ledge.ai/articles/google_translategemma_gemma3_open_translation_models</link>
      <description><![CDATA[<p>Googleは2026年1月15日（現地時間）、同社のオープン基盤モデル「Gemma 3」をベースにした翻訳特化モデル群「TranslateGemma」を<a href="https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/">発表</a>した。55の言語を対象とし、効率と精度を両立したオープンな機械翻訳モデルとして公開された。研究者や開発者が自由に利用できるオープンウェイトモデルとして公開される。</p>
<p>Googleによると、TranslateGemmaは大規模言語モデルを汎用的に利用するのではなく、翻訳タスクに特化した学習と最適化を行うことで、精度と計算効率の両立を図った点が特徴だという。</p>
<p><strong>■ TranslateGemmaは、4B・12B・27Bの3つのパラメータサイズで提供され、デバイスや用途に応じた翻訳モデルの選択が可能とされている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/translategemma_9695a89365/translategemma_9695a89365.jpg" alt="translategemma.jpg" /></p>
<h2>3つのモデルサイズを提供</h2>
<p>TranslateGemmaは用途に応じて選択可能な複数のモデルサイズで構成されている。
比較的軽量なモデルはエッジデバイスやローカル環境での利用を想定しており、一方で大規模モデルはGPU環境での高精度翻訳を前提としている。Googleは、中規模クラスのモデルでも高い翻訳品質を実現しているとしている。</p>
<p><strong>■  言語ファミリー別の翻訳エラー率比較。TranslateGemma 12Bは、多くの言語群でGemma 3 27Bに近い、またはそれを下回るエラー率を示している</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b.webp" alt="01-14_Chart_v3.width-1000.format-webp.webp" /></p>
<h2>日本語を含む55言語に対応</h2>
<p>対応言語には日本語を含む主要言語に加え、これまで翻訳リソースが限られていた中・低リソース言語も含まれる。Googleは、多言語対応を通じて研究用途や地域特化サービスへの応用を促進したい考えだ。</p>
<h2>マルチモーダル能力も継承</h2>
<p>TranslateGemmaは、基盤となるGemma 3の設計を引き継ぎ、テキスト翻訳に加えて画像内テキストの翻訳など、マルチモーダルなユースケースにも対応可能とされている。これにより、文書画像やスクリーンショットを含む翻訳処理にも応用できるという。</p>
<h2>オープンウェイトとして公開</h2>
<p>モデルの重みはオープンに提供され、開発者はローカル環境やクローズドなシステム内で翻訳モデルを実行・調整できる。Googleは、クラウド依存を避けたいケースや、特定ドメイン・言語ペア向けのカスタマイズ需要を想定している。</p>
<p>GoogleはTranslateGemmaについて、研究用途だけでなく、プロダクトや業務システムへの組み込みなど、幅広い活用を見込んでいるとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI時代、GPUのオルタナティブ──AMDは今どこを見据えているのか</title>
      <link>https://ledge.ai/articles/interview_amd</link>
      <description><![CDATA[<p>生成AIの急速な台頭は、コンピューティング需要の爆発的な増加を引き起こし、AIアクセラレーター市場はかつてない活況を呈している。この巨大な波を捉え、NVIDIAは市場において圧倒的な支配的地位を確立した。しかし、その一強体制は、AIインフラを支える企業にとってサプライチェーンの硬直化という新たなリスクを生み出している。
　この状況下で、エコシステムの健全性を保ち、技術革新を継続させるためには、サプライチェーンの多様化と強力な代替選択肢の確保が不可欠となっている。多くの企業が、NVIDIAへの依存を軽減し、よりオープンで柔軟なAI基盤を模索し始めているのだ。
　この文脈において、半導体大手のAMDはどのような戦略的ポジションを築こうとしているのか。本稿では、AMDの担当者への独占インタビューに基づき、ハードウェアとソフトウェアの両輪でNVIDIAの牙城に挑む同社の戦略、そしてAIの未来に対する深い洞察の核心に迫る。</p>
<p>※インタビューは2025年11月20日に丸の内の日本エイ・エム・ディ株式会社で行われた。</p>
<h2>1. 巨大需要の象徴：OpenAIとの「600万世帯分の電力」の提携が示すもの</h2>
<p>生成AIが必要とする計算資源のスケールは、従来の常識を遥かに超えている。このセクションでは、AMDがOpenAIと結んだ大規模なパートナーシップを切り口に、AIインフラが直面する課題の大きさと、その需要に応える主要プレイヤーとしてAMDが名乗りを上げた戦略的重要性を解き明かす。</p>
<p>Q: まず、先般発表されたOpenAIとの大規模なパートナーシップの背景についてお聞かせいただけますか？</p>
<p>A: この提携の根底には、OpenAIが直面していた「電源不足」と「コンピュート（チップ）不足」という二つの深刻なボトルネックがあります。その結果、彼らは単一のソースに依存するリスクを回避するため、代替サプライヤーを見つけ出すという社内的なミッションを掲げていました。私たちの長年にわたる実績と技術力が評価され、この歴史的なパートナーシップへと繋がりました。</p>
<p><strong>Q: 「6GW（ギガワット）」という規模は、読者には少しイメージしづらいかもしれません。これはどれほどの規模なのでしょうか？</strong>
A: 6GWというと600万世帯に相当する電力規模です。それは東京23区の世帯数(520万世帯)を上回る規模感であることを示しています。一般的なデータセンターが数十メガワット、大規模なものでも100メガワットを超える程度であることを考えると、6GW（=6,000メガワット）がいかに桁違いの規模であるかお分かりいただけるでしょう。これは、単一の契約としては前例のない、AIが要求するエネルギーの巨大さを示す象徴的な数字です。</p>
<p><strong>Q: この6GW分のチップは、数年間にわたって最新のものが提供されていくという理解でよろしいでしょうか？</strong>
A: はい。導入は来年から開始される予定です。重要なのは、この契約が特定のチップモデルに縛られるものではないという点です。私たちは、その時々で最も高性能な最新の製品を柔軟に導入していく計画であり、パートナーの進化に合わせて最高のソリューションを提供し続けます。</p>
<p>このOpenAIとの大規模提携は、世界のAIインフラの根幹を支えるティア1サプライヤーであることを市場に証明した。この地位を確立するために、AMDはどのような戦略を描いているのか。その答えは、ハードウェアとソフトウェアの両面からなる緻密なアプローチの中に隠されている。</p>
<h2>2. ハードウェアとソフトウェアの両輪戦略</h2>
<p>NVIDIAが築き上げた牙城を崩すためには、高性能なハードウェアを提供するだけでは不十分だ。開発者がストレスなく、かつ容易にその性能を最大限に引き出せるソフトウェアエコシステムの構築こそが、真の挑戦者となるための鍵を握る。これは、AMDが真正面から向き合う戦略的課題である。
本セクションでは、AMDが推進するハードウェアとソフトウェアという2つの核心戦略を深掘りし、同社がいかにしてAI時代の新たなスタンダードを築こうとしているのかを明らかにする。</p>
<h3>2.1 ハードウェア戦略：電力効率とポートフォリオの広さで差別化</h3>
<p>AI時代のインフラにおける最大のボトルネックは、計算能力そのものから「電力」へと移行しつつある。この変化を的確に捉え、AMDはハードウェア戦略の最重要指標として「パフォーマンス・パー・ワット（電力性能比）」を掲げている。</p>
<p><strong>Q: 半導体の微細化（例えば2nmプロセス）は、チップ性能にどのような影響を与えるのでしょうか？</strong>
A: プロセス技術の進化は、主に2つの重要な利点をもたらします。第一に、決まったチップ面積により多くの計算ユニットを詰め込めるようになり、性能が直接的に向上します。第二に、そして電力が制約となる現代においてますます重要になっているのが、「パフォーマンス・パー・ワット」の改善です。新しいプロセス技術を活用することで、同じ消費電力でより多くの計算が可能なチップを設計できます。この効率性への注力こそが、今や私たちの設計思想の中心的な柱となっています。</p>
<p>AMDのハードウェア戦略のもう一つの柱は、その広範な製品ポートフォリオにある。同社はCPU、GPUに加え、Pensandoの買収によるネットワークカード、Xilinxの買収によるFPGAといった、データセンターからエッジ、そしてPCまでを網羅する製品群を持つ。
　これにより、AMDはAIのワークロードに対してエンドツーエンドで最適化されたソリューションを提供できる、市場で唯一無二のポジションを確立している。個別の部品を提供するだけでなく、システム全体として最高のパフォーマンスを発揮させる設計思想が、同社の大きな強みだ。
　しかし、どれほど優れたハードウェアも、それを活かすソフトウェアがなければ宝の持ち腐れとなる。AMDの挑戦の成否は、ソフトウェア戦略の巧拙にかかっていると言っても過言ではない。</p>
<h3>2.2 ソフトウェア戦略：「オープン」を武器にCUDAエコシステムに挑む</h3>
<p>NVIDIAの最大の強みは、10年以上にわたって築き上げてきたソフトウェア開発環境「CUDA」である。このデファクトスタンダードの牙城をいかに切り崩すか。AMDがその武器として選んだのは、「オープンなエコシステム」という戦略だ。
<strong>Q: NVIDIAのCUDAがデファクトスタンダードとなっている中で、AMDはソフトウェア面でどのように対抗していくのでしょうか？</strong>
A: 私たちの課題がソフトウェアにあることは率直に認めています。そこでAMDが取っているアプローチは、開発者にAMDへ移行する「負担」をかけない事です。研究開発のスピードが最も重要視されるAI開発者にとってコード変更の負担はPerf/TCOのメリットを直ぐにかき消してしまいます。そこで最初に取り掛かったのはPyTorchのような主要なAIフレームワークのレベルでサポートを徹底することです。これにより、開発者は「コードチェンジなし」で既存のAIモデルをAMDのGPU上で動かすことができ、非常に魅力的な利点と言う声を頂いております。</p>
<p><strong>Q: 具体的な成果として、どのようなものがありますか？</strong>
A: おかげさまで、AIモデルの巨大なリポジトリであるHugging Face上のほぼ全てのモデルをサポートするに至りました。さらに、MetaのLlama 3・4のような主要モデルがリリースされたその日からAMDハードウェアで動作する「Day-0サポート」も実現しています。これにより、私たちはエコシステムの中で着実に信頼性を高めています。</p>
<p><strong>Q: ソフトウェアスタック「ROCm」がオープンソースであることの利点は何ですか？</strong>
A: ROCmは、その中身がすべてオープンソースライセンスで構成されています。これにより、エンドユーザーはライセンスの透明性を確認でき、大きな安心感を得られます。但し、製品としてはAMDが責任を持って提供しているので信頼性やサポートは他社製品と比べても衰えていません。また、何か問題があればコミュニティと共に改善していくことが可能であり、このオープン性こそが私たちのエコシステムを共に成長させる原動力となっています。</p>
<p>AMDのソフトウェア戦略は、意図的な道のりを辿って進化している。第一のステップは、開発者のための「コードチェンジ不要」な体験を保証するため、フレームワークレベルでの互換性を達成することだった。そして今、同社は次なる、より高度なステップへと駒を進めている。それはオペレーション層への対応だ。最近発表された「AI Enterprise Suite」は、Kubernetesベースのコンテナ管理、GPUモニタリング、推論マイクロサービスといった、企業が実験段階から本番運用へと移行するためにまさに必要とするツール群を提供する。このエンタープライズグレードの運用への注力は、ハイパースケーラーの先にある市場をいかにして獲得していくかという、同社の戦略を明確に示している。</p>
<h2>3. ビッグテックの先へ　ーエンタープライズAIの民主化を支える</h2>
<p>OpenAIのような巨大テック企業との取引はメディアの注目を集めるが、AMDの長期的な成功は、より幅広い一般企業によるAI活用、すなわち「AIの民主化」をいかに支えるかにかかっている。同社は、AI導入のハードルを下げ、誰もがその恩恵を受けられる未来を目指している。</p>
<p><strong>Q: NVIDIAはロボティクスなど特定領域のAIモデル開発にも注力していますが、AMDも同様の取り組みをされるのでしょうか？</strong>
A: 私たちの基本方針は、お客様と競合するようなAIモデルを自社開発するのではなく、パートナーシップを重視することです。Silo AIやNod.ai、Mipsologyといったソフトウェア企業を買収する目的も、特定のモデルを開発するためではありません。それは、我々の汎用的なソフトウェアスタックを強化するための人材と技術を積極的に獲得するためです。例えば、Silo AIのチームは、当社のGPUが採用されている欧州のスーパーコンピュータ向けにソフトウェアを最適化してきた深い専門知識を持っていました。その知見は今、全ての顧客に利益をもたらすべく統合されており、パートナーのための最高の基盤を構築するという我々のコミットメントを補強しています。</p>
<p><strong>Q: 幅広い企業がAIを導入する上で、AMDはどのような価値を提供できると考えていますか？</strong>
A: 移行性の簡易化の次のステップとしては「AI Enterprise Suite」のような製品を通じて、Kubernetesベースのコンテナ管理やGPUモニタリングなど、企業がAIを本格的に運用しやすくなるためのツールを提供しています。また、オープンソースモデルをAPI形式で手軽に利用できる環境を整えることで、専門知識が限られる企業でもAI導入の第一歩を踏み出せるよう、そのハードルを大きく引き下げています。</p>
<p>このプラットフォーム中心のビジョンは、独立した戦略ではない。それは、同社の中核をなす「オープン」なソフトウェア哲学の論理的な延長線上にある。アプリケーション層で顧客と競合することを避け、代わりにオープンで堅牢な基盤（ROCm、AI Enterprise Suite）を提供することで、AMDはエンタープライズAIエコシステム全体にとって不可欠かつ中立的な土台となることを目指している。これは、特定の垂直市場向けにプロプライエタリなモデルを構築する競合他社とは対照的なアプローチだ。</p>
<h2>4. AIの未来予測　「バブルではない」と発言する理由と未開の可能性</h2>
<p>現在のAIブームを、いずれ弾ける「バブル」と見る向きもある。しかしAMDは、現在の熱狂は、これから訪れる本当の変革の序章に過ぎないと捉えている。このセクションでは、同社がAIの未来に確信を抱く理由と、その未開の可能性についての洞察を深掘りする。</p>
<p><strong>Q: 現在のAIブームは、いずれ弾けるバブルなのでしょうか。それとも持続的な成長が見込まれるのでしょうか？</strong>
A: 正直なところ、私たちは「あまりバブルとは思っていません」。なぜなら、AIが持つ本来のポテンシャルと、現在のアプリケーションで実現できていることの間には、まだまだ非常に大きなギャップがあると感じているからです。</p>
<p><strong>Q: AIのポテンシャルは、現時点で何パーセントくらい実現されていると感覚的に思いますか？</strong>
A: あくまで感覚的な話ですが、「本当に低いと思います。10%とかそんな程度」ではないでしょうか。これは裏を返せば、まだ90%もの未開拓な市場と可能性が残されていることを意味します。</p>
<p><strong>Q: 今後、AIはどのように社会に浸透していくとお考えですか？</strong>
A: その影響は二つの側面から現れるでしょう。一方で、医療や法律といった分野で、AIが記録調査のようなタスクにかかる時間を劇的に削減し、着実かつ深遠な効率化が進みます。他方で、最初のスマートフォンが登場した時に誰もインフルエンサー経済を予測できなかったように、今日では想像もつかない全く新しいユースケースや産業が生まれるはずです。この予測可能な最適化と、予測不可能なイノベーションという二重のポテンシャルこそが、未来の市場をこれほど広大なものにしているのです。</p>
<p>AMDが目指しているのは、短期的な流行に乗ることではない。予測不可能な未来のアプリケーションまでをも支えることができる、柔軟で強力なAI基盤を構築することだ。こうした未来を見据えるAMD自身の現在地、そして市場に伝えたいメッセージとは何か。</p>
<h2>5. AI本格参入から2年、生まれ変わったAMDの現在地</h2>
<p>AMDがデータセンター向けAIアクセラレーター「MI300」を市場に投入し、本格的にこの分野に参入してから、まだ2年余りしか経過していない。この事実は、多くの人々にとって驚きかもしれない。この極めて短い期間で、同社は驚異的な変貌を遂げ、市場における存在感を確固たるものにした。</p>
<p><strong>Q: 最後に、市場や開発者に対して最も伝えたいメッセージは何でしょうか？</strong>
A: ぜひ伝えたいのは、「5年前にAMDのGPUを試して『まだ熟成感が足りない』と感じた人にこそ、『いやいや、当時とは全く変わりました。是非もう一度見てください』」ということです。私たちはこの2年で、ハードウェアもソフトウェアも劇的に進化しましたし
複数の最先端のAI機関で導入実績を実現しています。過去のイメージではなく、現在の私たちの実力を正当に評価していただきたいと切に願っています。</p>
<p>本稿で明らかになったAMDの戦略は、以下の3つの要点に集約される。</p>
<ul>
<li><strong>巨大な需要への対応力：</strong>  OpenAIとの提携に象徴される、ハイパースケールAIインフラを担う能力。</li>
<li><strong>オープンなソフトウェアエコシステム：</strong>  CUDAへの挑戦として、コード変更不要な利用環境とオープンソース戦略で開発者の支持を獲得するアプローチ。</li>
<li><strong>真に包括的なプラットフォーム：</strong>  EPYC CPUやInstinct GPUから、Pensandoネットワークカード、Xilinx FPGAによるエッジコンピューティングまで、データセンターのスタック全体を提供・最適化できる唯一無二のポジション。競合他社には真似のできないレベルのシステム統合を実現する。</li>
</ul>
<p>結論として、AMDはもはや単なるNVIDIAの「代替」ではない。同社は、オープンなエコシステムと包括的なポートフォリオを武器に、AI時代の新たなスタンダードを築こうとする強力な「挑戦者」として、今、まさにその真価を発揮し始めている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>サイボウズ青野社長が語る『PLURALITY』の実践と、多元的協働社会への道筋</title>
      <link>https://ledge.ai/articles/interview_cybozu</link>
      <description><![CDATA[<p>現代の経営者が直面するパラドックス、それはAIが生産性を飛躍的に向上させる一方で、組織内外の「分断」をも加速させているという現実だ。効率を求めるアルゴリズムは、時にサイロを強化し、意見の対立を先鋭化させる。この新たな課題に対し、単なる対症療法ではない、組織の根本的な「OS（オペレーティングシステム）」のアップデートが求められている。</p>
<p>その設計図となりうるのが、台湾のデジタル担当大臣オードリー・タン氏らが提唱する思想書『PLURALITY（多元性）』だ。そして、この先進的な書籍の日本語版を出版したのが、ソフトウェア企業のサイボウズである。</p>
<p>本記事では、サイボウズ代表取締役社長、青野慶久氏への独占インタビューを通じ、『PLURALITY』が示すビジョンが、単なる社会思想に留まらず、AI時代の分断を乗り越え、企業の競争優位性を築くための極めて実践的なガバナンス・フレームワークであることを明らかにする。</p>
<h2>なぜ、ソフトウェア企業のサイボウズが『PLURALITY』を出版したのか？</h2>
<p>ソフトウェア企業であるサイボウズが、なぜオードリー・タン氏らの先進的な思想書を出版するに至ったのか。その背景には、トップダウンの経営判断ではなく、現場から湧き上がった熱意と、青野社長自身の長年の葛藤があった。</p>
<p>この出版プロジェクトは、青野社長が直接主導したものではない。同社の研究開発部門「サイボウズ・ラボ」に所属する西尾泰和氏が、オープンソースで進む『PLURALITY』の日本語訳に参加。この動きをサイボウズの出版部門「サイボウズ式ブックス」チームが嗅ぎつけ、「この本を自分たちの手で出版したい」と強く提案したのだ。まさに、サイボウズのボトムアップ文化を象徴する出来事だった。</p>
<p>一方で、青野社長はこの思想に深く共鳴する個人的な理由を抱えていた。それは、ソーシャルメディア上で誰もが経験しうる、そしてあらゆる組織が内包する「分断」の縮図だ。彼のX（旧Twitter）アカウントは、時に凄まじい勢いで炎上する。</p>
<p>「僕のXアカウント、めちゃくちゃ炎上するんですよね。すごい意見の違う人が集まってきて。インターネットが登場して30年、技術の進歩を見てきましたが、世界中の情報が瞬時に行き渡ることが、本当に人間を幸せにするのか、という問いが常にありました。『PLURALITY』を読んで、なるほど、と。問題はテクノロジーそのものではなく、情報をどういうアルゴリズムで見せるかだったのです」</p>
<p>対立を煽るアルゴリズムは、ソーシャルメディアだけの問題ではない。社内で最も声の大きい意見が通ったり、異論を唱えることが罰せられたりする企業文化もまた、同じ構造を持つ。青野氏にとって、『PLURALITY』が提示した「意見は違うけれど、ここは一致している」という共通項を可視化するアルゴリズムの思想は、自身の体験と組織が直面する普遍的な課題に対する、一つの明確な「解」だったのである。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_2b2ee9cf04/image2_2b2ee9cf04.png" alt="image2.png" /></p>
<h2>「対立」から「協調」を生み出す技術──PLURALITYの本質</h2>
<p>『PLURALITY』は、単なる理想論や社会思想ではない。それは、深刻化する社会の分断を乗り越え、異なる価値観を持つ人々が共存するための具体的な「技術」であり、デザインパターンである。青野社長は、その本質をこう定義する。</p>
<p>「一言で言えば、『社会的差異を超えたコラボレーションのための技術』。あるいは、『いろんな意見の人が共存できる道を探すための技術』だと理解しています」</p>
<p>その最も象徴的な成功事例が、台湾における「同性婚の法制化」だ。この問題は、伝統的な家族観を重んじる層と、個人の権利を主張する層との間で激しい対立を生んでいた。そこで活用されたのが、デジタルプラットフォーム「vTaiwan（Polis）」である。</p>
<p>このプラットフォームは、両陣営の膨大な意見を収集・可視化し、対立点だけでなく、意外な共通項や妥協可能な領域を探し出すアルゴリズムで、議論の構造を解析した。その結果、双方が決して譲れない核心的要求を満たす、絶妙な妥協点が見出された。青野氏が語る。</p>
<p>「法律を変えるか、変えないかの二者択一ではなく、同性婚を法的に認めるための特別法をつくった。なるほど、そんな落としどころがあるんだ、と」</p>
<p>この事例は、ゼロサム交渉からの決定的な脱却を意味する。テクノロジーをエンゲージメントのためではなく、コンセンサス形成のために設計すれば、これまで不可能と思われていた解決策の領域を拡張できることを証明したのだ。同性婚や選択的夫婦別姓といった問題で長年議論が続く日本にとって、その示唆は大きい。</p>
<p>この思想を、企業経営というより身近な単位で実践するには、何が必要なのだろうか。</p>
<h2>PLURALITYを経営に実装する「ツール」と「文化」の両輪</h2>
<p>『PLURALITY』の思想を企業経営の現場に実装するためには、テクノロジーとしての「ツール」と、組織の価値観である「文化」が不可分な両輪として機能する必要がある。それは、高性能なエンジンと、それを支える強靭な車体の関係に似ている。</p>
<h3>エンジン：透明な熟議を支えるテクノロジー</h3>
<p>多様な意見から創造的な結論を導き出すには、まず議論のプロセスを支える技術的基盤が不可欠だ。この場合、誰がどのような意見を持ち、議論がどう進んでいるのかを全員が把握できるプラットフォームが求められる。サイボウズが提供するグループウェアは、まさにこの役割を担い、多様な意見を整理・共有し、誰もがそこに意見を重ねられる土壌を提供する。</p>
<p>そこに青野社長は、将来的にグループウェアにAIファシリテーターを組み込む構想を語る。議論が紛糾した際に、AIが中立的な立場で論点を整理し、合意形成を支援する。これにより、専門的なファシリテーターがいない組織でも、建設的な議論が可能になる。</p>
<h3>シャーシ（車台）：ラディカルな当事者意識を育む文化</h3>
<p>最先端のツールも、それを受容し、活用する文化がなければ宝の持ち腐れとなる。サイボウズでは、長年にわたり独自の文化を醸成してきた。同社には「多様な個性を重視」し、「対話と議論」を尽くすという理念が、行動規範の根幹にある。自分と異なる意見が出たときに否定するのではなく、「まずは聞いてみよう」という姿勢が徹底されている。</p>
<p>この文化を根付かせるため、サイボウズは「沈黙」を良しとしない規範を設けた。「オープンな議論の場で意見を言わずに、決定後になって文句を言うのは卑怯である」という「質問責任」の考え方だ。自分に関わる決定プロセスを誰もが閲覧できるため、異議があるならその場で表明する責任が生じる。これによって、社員は傍観者とならず主体的に議論へ参加するようになり、決定後の納得感も醸成されやすくなる。</p>
<p>ある時、青野社長のXでの発言に社員から「納得がいかない」という声が上がると、平日の昼間に「社長への異議申し立て」をテーマにしたミーティングが開かれ、100名もの社員が参加した。このエピソードは、同社の対話文化が単なるお題目ではないことを如実に示している。</p>
<p>このような組織文化を率いるリーダーには、当然ながら従来型のリーダーシップとは異なる資質が求められる。</p>
<h2>AI時代のリーダーシップと「優秀」の再定義</h2>
<p>PLURALITYを前提とした組織では、リーダーの役割、そして「優秀」という人材の定義そのものが根本から変わる。</p>
<p>リーダーの役割が「指示命令者」から「対話の促進者（ファシリテーター）」へと移行するのは、「優秀」の定義が解体された直接的な帰結だ。「100人100通り」の働き方を是とする組織では、単一の軸で人材を評価すること自体が無意味になる。安定的に成果を出す人材と、時折大きな成果を出す人材、どちらが優秀かは一概には言えない。そうなれば、リーダーの最も重要な仕事は、画一的な物差しで評価することではなく、「その人がどこにはまると最も活躍できるか」を見極め、多様な才能をオーケストレーションすること、つまりファシリテーションそのものになる。</p>
<p>この変革は、リーダーに強烈な自己規律を要求する。青野氏は、その内なる葛藤を率直に明かす。</p>
<p>「内心イライラすることもありますよ（笑）。なんで個人のXに突っ込んでくるんだ、って（笑）。でも、それじゃ前に進めないんだっていうのは、頭では分かってるんです」
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image4_41abeb5ce6/image4_41abeb5ce6.png" alt="image4.png" /></p>
<p>この人間味あふれる告白は、多元的なリーダーシップが、単なるスキルセットではなく、日々の自己省察と鍛錬を要する在り方であることを示している。</p>
<p>そして、この変革を支えるのがAIの存在だ。PLURALITY時代の組織におけるAIの真価は、人間同士のコミュニケーションに介在し、その「摩擦」を巧みに管理することにある。</p>
<p>例えば、サイボウズの代表電話はAIが応対し、営業電話や感情的な問い合わせの一次対応を担う。これにより、AIが感情的な負荷を吸収し、人間はより本質的な対話に集中できる。AIによる議論のファシリテーションも同様に、中立的な構造を提供することで、人間同士の直接的な衝突を緩和する。AIは人間の仕事を奪うのではなく、人間がより人間らしい、創造的で共感に基づいた仕事に集中するための環境を整備するのである。</p>
<h2>AIが拓く3つの未来と、私たちが選ぶべき道</h2>
<p>AIの進化は、私たちの社会をどこへ導くのか。『PLURALITY』は、テクノロジーが形作る未来の社会システムとして、3つの異なるシナリオを提示している。</p>
<h3>1. 統治テクノクラシー (Governing Technocracy)</h3>
<p>高度なAIが社会の意思決定を最適化し、人間はベーシックインカムで生活が保障される世界。効率性と安定性が極限まで追求される。</p>
<h3>2. 企業リバタリアニズム (Corporate Libertarianism)</h3>
<p>強力なビジョンを持つCEOが統治する、小さな国家のような企業共同体が多数存在する世界。人々は自らの価値観に合う共同体を選び、合わなければ移動する自由を持つ。</p>
<h3>3. デジタル民主主義 (Digital Democracy)</h3>
<p>多様な人々がテクノロジーを用いて対話し、協調しながら共存する、『PLURALITY』が目指す世界。分断を乗り越え、集合知によって社会を運営していく。</p>
<p>青野社長は、これらの未来像について、どれか一つが正解なのではなく、それぞれが共存しうるという多元的な視点を示す。</p>
<p>「どれか一つの世界観が勝つとは考えていません。個人が、自分が心地よいと感じる世界観を選んで生きていけばいい。私自身は『デジタル民主主義』に属したいと思いますが、他のビジョンを筋が悪いと否定するつもりはありません」</p>
<p>重要なのは、これらの選択肢が存在することを認識し、自分たちがどのような未来を望むかを主体的に考えることだ。そして、ビジョンを実現するためには、壮大な構想だけでなく、具体的な第一歩が求められる。</p>
<h2>未来へのメッセージ──「多元的な協働」への勇気ある一歩</h2>
<p>「デジタル民主主義」というビジョンに共感する読者が、今日から何を始めるべきか。インタビューの最後に尋ねると、青野社長からの答えは驚くほどシンプルで、しかし力強いものだった。</p>
<p>「まず、あなたの組織の<strong>情報をオープンにしてみませんか？</strong> 」</p>
<p>それは大がかりなDXプロジェクトである必要はない。「まずは役職者の会議の議事録を公開することからでいい」と彼は言う。その小さな一歩が、組織の透明性を高め、対話の文化を生む土壌となる。サイボウズ自身も、15年以上の歳月をかけて情報公開を進め、今では役員会議の議事録さえ全従業員がリアルタイムで視聴できる。</p>
<p>ただし、忘れてはならないのは、<strong>ツールと文化を両輪で進めることの重要性</strong> だ。情報をオープンにするだけでなく、その情報に対して意見を表明する責任と機会をセットで提供することで、初めて組織は生きた対話の場となる。</p>
<p>AIがタスクを自動化する時代、企業の究極的な競争優位性は、個人の能力の総和ではなく、多様な人材の「集合知」をいかに引き出すかにかかっている。『PLURALITY』は、単なる社会哲学ではない。それは、その集合知を解き放つための、極めて実践的な方法論だ。</p>
<p>AI駆動のアルゴリズムが組織を分断するのを座視するのか。それとも、多元的な協働を育むために、テクノロジーと文化を自ら設計するのか。その未来に向けた、勇気ある一歩を踏み出す時が来ている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>イラン抗議デモ巡りAI生成動画が拡散　ネット遮断による情報空白で、真偽判定が困難に</title>
      <link>https://ledge.ai/articles/iran_protests_ai_generated_videos_internet_blackout_verification_difficulty</link>
      <description><![CDATA[<p>反政府デモが続くイランをめぐり、交流サイト（SNS）上で拡散する動画や画像の中に、生成AIで作られたとみられるものが含まれていることが分かった。報道評価団体のNewsGuardは2026年1月15日、抗議デモを描写するとされる動画のうち、複数本についてAI生成の可能性が高いと確認したと<a href="https://www.newsguardrealitycheck.com/p/ai-videos-fill-void-amid-iran-internet-blackout">発表</a>した。</p>
<h2>NewsGuard、抗議デモを装ったAI生成動画を確認</h2>
<p>NewsGuardによると、問題の動画は、イラン各地での抗議活動を示すかのような説明とともにSNSで拡散していた。しかし、映像表現の不自然さや出所の不明確さなどから、生成AIによって作られた可能性が高いと分析したという。こうした動画が真偽不明のまま流通することで、実際の情勢把握を誤らせるおそれがあるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/newguard_x_b08d505466/newguard_x_b08d505466.jpg" alt="newguard x.jpg" /></p>
<h2>通信遮断が生んだ「情報空白」</h2>
<p>AI生成とみられる動画が広がる背景には、イラン国内で続く大規模なインターネット遮断がある。インターネットインフラ企業の<a href="https://blog.cloudflare.com/iran-protests-internet-shutdown/">Cloudflare</a>は、同社の観測データとして、1月上旬にイランのインターネットトラフィックが急減し、事実上ゼロに近い状態となった時間帯があったと説明している。遮断により、現地からリアルタイムで発信される映像や証言は大幅に減少した。</p>
<p>人権団体の<a href="https://www.accessnow.org/press-release/keepiton-iran-digital-darkness-human-rights-abuses/">Access Now</a>も、通信遮断が続くことで、市民の情報アクセスが制限されるだけでなく、現地で起きている出来事の検証や外部からの監視が困難になると警告している。独立した裏付けが得られにくい状況では、SNS上に流通する情報の信頼性を判断すること自体が難しくなる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/accessnow_16f3d64d1b/accessnow_16f3d64d1b.jpg" alt="accessnow.jpg" /></p>
<h2>情報不足の中で高まる真偽判定の難しさ</h2>
<p>通信遮断によって現地発の情報が乏しくなる中、抗議デモに関する映像や画像は、限られた手掛かりで評価せざるを得ない状況に置かれている。こうした環境の下で、NewsGuardは、抗議デモ関連として拡散する動画の中に、AI生成とみられるものが複数含まれていることを確認した。</p>
<p>生成AIの進化により、映像の見た目だけで真偽を見極めることは専門家にとっても容易ではない。通常は撮影場所の特定や別角度映像との照合、投稿の時系列分析などが検証の手掛かりとなるが、現地からの情報発信が制限されている状況では、そうした確認手段が限られる。NewsGuardは、イラン情勢をめぐる映像や画像について、出所や裏付けを慎重に見極める必要があるとして注意を促している。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、VR会議アプリ「Horizon Workrooms」単体提供を終了へ──2月16日でアクセス不可、データも削除</title>
      <link>https://ledge.ai/articles/meta_horizon_workrooms_app_shutdown</link>
      <description><![CDATA[<p>Metaは2026年1月15日（現地時間）、VR空間で会議や共同作業を行うアプリ「Horizon Workrooms」の単体アプリ提供を2026年2月16日に終了すると<a href="https://www.meta.com/ja-jp/help/quest/2464765133873078/?srsltid=AfmBOoof-fgoukgk7PEJ39f6sAbryo5HndubzMFmP_hOoN3arFgysT7w">発表</a>した。終了日以降、同アプリにはアクセスできなくなり、Workroomsに関連するデータは削除される。</p>
<p>Horizon Workroomsは、Meta QuestシリーズなどのVRデバイスを用いて、アバター同士が仮想空間に集まり、会議やホワイトボードでの共同作業、PC画面の共有などを行えるサービスとして提供されてきた。企業やチーム向けのVRコラボレーションツールとして、実験的な位置づけを含みつつ展開されていた。</p>
<p>Metaの公式サポート文書によると、今回終了するのはあくまでWorkroomsの単体アプリであり、2月16日をもって利用はできなくなる。あわせて、Workroomsに紐づくデータについても、同日以降は削除されるとしている。</p>
<p>一方で、MetaはVR環境におけるすべての業務関連機能を廃止するわけではない。公式の案内では、PC画面をVR空間に表示するMeta Quest Remote Desktopについては、引き続き利用可能であることが示されている。</p>
<p>公式ページでは、Horizon WorkroomsがMeta Horizonのエコシステムの中で果たしてきた役割に言及したうえで、今後はより広いプラットフォームの枠組みの中で、生産性やコラボレーション機能を提供していく方針が示唆されている。今回の終了は、VR会議機能そのものの否定ではなく、提供形態を整理・統合する動きの一環と位置づけられる。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>専門家AIが“対立して結論を導く”──三菱電機、製造業界初の対立議論型マルチAIエージェント技術を開発</title>
      <link>https://ledge.ai/articles/mitsubishi_electric_adversarial_multi_ai_agents</link>
      <description><![CDATA[<p>三菱電機は2026年1月20日、議論フレームワークを用いて専門家AIエージェント同士の対立議論を自動生成し、根拠を明示したうえで専門家レベルの結論を高速に導き出すマルチAIエージェント技術を開発したと<a href="https://www.mitsubishielectric.co.jp/ja/pr/2026/0120/">発表</a>した。複数の専門的立場を持つAI同士が意図的に対立しながら議論を行い、根拠を明示した結論を導き出す仕組みで、同社は製造業界初の技術としている。</p>
<h2>属人化と説明性の課題</h2>
<p>近年、企業ではセキュリティーリスクの評価や生産計画の立案など、複数の条件がトレードオフとなる複雑な意思決定業務が増加している。一方、こうした業務は高度な専門知識を要するため属人化しやすく、担当者不在時の判断や関係者間の合意形成に時間を要する点が課題とされてきた。さらに、AIによる判断の根拠が不明確であることへの懸念から、セキュリティーや安全性に関わる重要な意思決定へのAI活用は十分に進んでいなかった。</p>
<h2>議論フレームワークによる専門家AIの自動生成</h2>
<p>開発された技術は、議論フレームワーク（Argumentation Framework）を用いて、テーマに応じた複数の専門家AIエージェントを自動生成する点が特徴だ。各AIエージェントの主張を点、主張間の反論・支持関係を線としてグラフ構造化し、議論全体の流れを把握できるようにする。</p>
<p>また、テーマから抽出したキーワードを用いてWeb検索を行い、外部ドキュメントと組み合わせて知識を自動構築することで、議論の進行に応じた主張の変化にも対応する。</p>
<p><strong>■ 従来の協調型マルチAIエージェントと対立議論型マルチAIエージェントの比較：</strong> 協調型では最初の発言を支持する方向に議論が収束しやすいのに対し、対立議論型では専門家AIエージェント同士が反論・支持を繰り返すことで、さまざまな視点から論点を広げ、本質的な課題の明確化と深い洞察を可能にする。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/120285_349_d810305a498318df239ba3c3bcde27a1_1500x669_dd5ff0289d/120285_349_d810305a498318df239ba3c3bcde27a1_1500x669_dd5ff0289d.webp" alt="120285-349-d810305a498318df239ba3c3bcde27a1-1500x669.webp" /></p>
<h2>「敵対的生成」を応用した深い洞察</h2>
<p>同技術の中核には、画像生成AIなどで用いられてきたGAN（Generative Adversarial Network）に見られる「敵対的生成」の概念がある。ファシリテーター役のAIが議論全体を管理し、専門家AIエージェントの発言順を制御することで、各エージェントは自らの専門知識に基づいた主張を展開するだけでなく、他のエージェントの発言に対して反論や補強を行う。意図的に対立構造を設けることで、本質的な論点を浮き彫りにし、従来の協調型マルチAIエージェントでは得にくかった深い洞察を導き出すという。</p>
<p>また、議論の過程はすべて履歴として保存され、議事録やQAチャット形式でユーザーが確認できる。結論に至った背景や判断根拠を追跡可能とすることで、AIの判断に対する説明性を高めた。</p>
<h2>今後の展開</h2>
<p>同社は、この技術によりセキュリティー分析、生産計画設計、リスク評価など、複雑なトレードオフを伴う専門性の高い業務へのAI導入を促進し、業務効率化につなげるとしている。今回の成果は三菱電機のAI技術ブランド「Maisart」の一環で、2026年度以降の事業化を見据えて社内実証を進める。将来的には、経営判断や技術選定など幅広い分野を対象とした意思決定支援プラットフォームとしての提供を目指す。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、年換算売上高200億ドル（約3.1兆円）超を公表──計算資源を拡大し「知能の価値」に連動する事業へ</title>
      <link>https://ledge.ai/articles/openai_annualized_revenue_20b_compute_scales_with_intelligence_value</link>
      <description><![CDATA[<p>OpenAIは米国時間2026年1月18日、最高財務責任者（CFO）のSarah Friar氏による<a href="https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/">公式ブログ投稿</a>で、同社の年換算売上高（直近の収益ペースを年ベースに換算した指標）が200億ドル（約3.1兆円）を超える規模に達していることを明らかにした。AIの利用拡大によって生み出される「インテリジェンス（知能）の価値」に応じて事業規模が拡張していると説明し、需要の伸びに合わせて計算資源への投資を継続的に拡大しているとした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_bisomess_that_scales_with_the_value_of_intelligence_596d5afa2e/a_bisomess_that_scales_with_the_value_of_intelligence_596d5afa2e.jpg" alt="a bisomess that scales with the value of intelligence.jpg" /></p>
<h2>研究プレビューから日常インフラへ</h2>
<p>OpenAIは、ChatGPTを研究プレビューとして公開した当初、最先端の知能を人々の手に直接届けた場合に何が起きるかを探る目的だったと振り返る。その後、想定を超える規模で利用が広がり、学生の学習支援や家庭での計画立案、創作活動、健康に関する情報整理など、日常生活に深く組み込まれるようになったという。</p>
<p>こうした利用はやがて仕事の現場にも広がり、文章作成やデータ整理、コードレビュー、意思決定の補助など、日々の業務プロセスの一部として定着した。OpenAIは、好奇心を満たすためのツールだったChatGPTが、創造性や生産性、意思決定を支える「インフラ」へと変化したと位置付けている。</p>
<h2>「知能の価値」に応じて拡張するビジネスモデル</h2>
<p>同社はこの変化を受け、事業モデルも「知能が生み出す価値に比例して拡張する」ことを原則に設計してきたと説明する。個人向けにはサブスクリプションを導入し、職場やチーム向けには業務利用に対応したプランや従量課金を追加。さらに、開発者や企業がAPIを通じてAIを組み込めるプラットフォーム事業を展開し、成果に応じて利用が拡大する構造を整えてきた。</p>
<p>近年は、購買や行動の意思決定を支援する用途にもAIの活用が広がっており、広告やコマース分野にも同じ原則を適用しているという。OpenAIは、収益化は体験に自然に溶け込み、利用者に価値をもたらすものでなければならないとしている。</p>
<h2>計算資源と収益が同じカーブで拡大</h2>
<p>公開された図表では、計算資源と収益がほぼ同じペースで拡大してきたことが示された。計算資源は2023年の0.2ギガワット（GW）から2024年に0.6GW、2025年には約1.9GWへと拡大し、年率で約3倍の成長を遂げた。一方、年換算売上高も2023年の20億ドル、2024年の60億ドルを経て、2025年には200億ドル超に達したとしている。</p>
<p><strong>■ OpenAIが示した計算資源（左）と年換算売上高（右）の推移。計算資源の拡大に合わせて、収益規模も同様のカーブで成長していることが示されている</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_business_that_scales_with_the_value_of_intelligence_9dd9df2933/a_business_that_scales_with_the_value_of_intelligence_9dd9df2933.jpg" alt="a-business-that-scales-with-the-value-of-intelligence.jpg" /></p>
<p>OpenAIは、計算資源が顧客への提供能力を直接左右する最も希少なリソースだとし、複数のプロバイダーと連携する分散型の体制を構築することで、計画的かつ安定的に能力を拡張できるようになったと説明している。計算資源を固定的な制約ではなく、能動的に管理するポートフォリオとして運用することで、効率性と拡張性の両立を図っているという。</p>
<h2>実用化を重視する2026年</h2>
<p>OpenAIは2026年の重点として「practical adoption（実用的な採用）」を掲げた。AIが可能にする高度な機能と、実際の現場で使われている状況との間にあるギャップを埋めることが重要だとし、特に医療、科学、企業分野での活用が大きな機会になると指摘している。</p>
<p>インフラへの投資が提供可能な能力を広げ、研究と製品開発が知能の可能性を押し広げ、採用の拡大が利用者を増やす。その結果として得られる収益が、次の投資を支える――OpenAIは、この循環こそが知能を社会の基盤へと成長させる原動力になるとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTの“待ち時間”短縮へ──OpenAIがCerebrasと提携、リアルタイム推論を強化</title>
      <link>https://ledge.ai/articles/openai_cerebras_low_latency_inference_partnership</link>
      <description><![CDATA[<p>OpenAIは2026年1月14日（現地時間）、AIチップ企業のCerebrasと提携し、同社の低レイテンシ推論基盤を自社のAI推論スタックに統合すると<a href="https://openai.com/index/cerebras-partnership/">発表</a>した。巨大な単一チップ上に計算・メモリ・帯域を集約するCerebrasのシステムを活用し、長文出力やコード生成、AIエージェント実行といった処理の応答速度を高める。計算能力は段階的に投入され、複数年にわたって拡張される見通しだ。</p>
<p>今回の取り組みは、OpenAIが進める推論基盤の多層化の一環と位置づけられる。OpenAIによると、AIの利用体験は「質問を送り、モデルが推論し、応答が返る」というループで構成されており、この応答がリアルタイムに近づくほど、ユーザーの利用時間や実行される処理の価値が高まるという。Cerebrasの低遅延システムは、こうした体験を支えるための専用基盤として導入される。</p>
<h2>低レイテンシ推論を段階的に統合、対応ワークロードを拡大</h2>
<p>OpenAIはまず、リアルタイム性が特に重要なワークロードからCerebrasの推論キャパシティを組み込み、その後、対象を広げていく計画だ。導入は複数のフェーズに分けて行われ、計算資源は2028年まで段階的にオンライン化される。</p>
<p>提携の規模について両社は具体的な金額を明らかにしていないが、海外メディアでは、この協業が数年にわたる大規模契約になる可能性があると報じられている。<a href="https://www.reuters.com/technology/openai-buy-compute-capacity-startup-cerebras-around-10-billion-wsj-reports-2026-01-14/">Reuters</a>は関係者の話として、契約規模が約1.5兆円相当になると伝えており、OpenAIが推論インフラの強化に相当な投資を行っていることを示唆する内容となっている。</p>
<h2>巨大単一チップで推論のボトルネックを回避</h2>
<p>Cerebrasのシステムの特徴は、計算資源、メモリ、通信帯域を単一の巨大チップに集約している点にある。従来のGPUクラスタ構成では、推論時にノード間通信がボトルネックとなりやすいが、Cerebrasはこうした制約を構造的に回避できるとする。特に、長いテキスト出力や複雑な推論を伴う処理で効果を発揮するという。</p>
<p>Cerebrasは、OpenAI向けにこのwafer-scaleシステムを大規模に展開し、低レイテンシ推論を前提としたAI体験を支える基盤として提供する方針だ。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>PwC調査：世界のCEO半数超が「AIは収益に貢献せず」──活用はなお途上段階</title>
      <link>https://ledge.ai/articles/pwc_global_ceo_survey_ai_revenue</link>
      <description><![CDATA[<p>コンサルティング大手の PwC は2026年1月19日、世界の最高経営責任者（CEO）を対象に実施した経営意識調査の結果「PwC 2026 Global CEO Survey」を<a href="https://www.pwc.com/jp/ja/press-room/2026/ceo-survey2026.html">発表</a>した。調査では、AIへの投資が世界的に拡大する一方で、AIが売上増加やコスト削減といった収益面に貢献していないと答えたCEOは56％に上り、AI活用が依然として限定的な段階にとどまっている実態が明らかになった。</p>
<h2>AI投資は進むが、成果を実感する企業は少数</h2>
<p>PwCが95カ国・地域の4,454人のCEOを対象に実施した「第29回世界CEO意識調査」によると、直近12カ月間でAIによる売上増加を実感したCEOは30％、コスト削減を実感したのは26％にとどまった。</p>
<p>一方で、売上増加・コスト削減のいずれの効果も得られていないと回答したCEOは56％と過半数を占めた。両方の成果を実現したとする回答は12％に過ぎず、AI投資が短期的な財務成果につながっていない企業が多数派となっている。</p>
<p><strong>■ AI活用による売上・コストへの影響を示した分布。売上増加とコスト削減の両方を実現した企業は12％にとどまる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pw_C_2026_Global_CEO_Survey_1_2c35c7e429/Pw_C_2026_Global_CEO_Survey_1_2c35c7e429.jpg" alt="PwC 2026 Global CEO Survey 1.jpg" /></p>
<h2>全社的なAI活用には至らず</h2>
<p>調査では、AIを企業全体で本格的に活用しているケースが限られていることも示された。AIを大規模に適用していると答えたCEOは、需要創出で22％、製品・サービスへの組み込みで19％、経営判断への活用では15％（四捨五入）にとどまっている。PwCは、多くの企業がAIを個別業務や実証的な用途にとどめており、事業全体を変革する段階には至っていないと分析している。</p>
<p><strong>■ AIを大規模に適用している業務領域は限定的。需要創出や製品・サービス分野でも2割前後にとどまる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pw_C_2026_Global_CEO_Survey_2_c7eca7254b/Pw_C_2026_Global_CEO_Survey_2_c7eca7254b.jpg" alt="PwC 2026 Global CEO Survey 2.jpg" /></p>
<h2>売上見通しへの自信は5年ぶりの低水準</h2>
<p>AI活用の成果が限定的であることと並び、経営者の先行きに対する見方も弱まっている。今後12カ月の自社売上成長について「非常に自信がある」「極めて自信がある」と答えたCEOは30％で、前年調査（38％）から低下し、過去5年間で最も低い水準となった。</p>
<p>PwCは、マクロ経済の不透明感や地政学リスク、サイバーリスクに加え、AIを含む技術変化のスピードが経営の不確実性を高めていると指摘している。</p>
<p><strong>■ 今後12カ月の売上成長に自信を持つCEOの割合は30％に低下し、直近5年間で最も低い水準となった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pw_C_2026_Global_CEO_Survey_3_8a3a869888/Pw_C_2026_Global_CEO_Survey_3_8a3a869888.jpg" alt="PwC 2026 Global CEO Survey 3.jpg" /></p>
<h2>AI活用の成熟度が成果の差を分ける</h2>
<p>一方で、AI活用によって売上増加とコスト削減の両方を実現している企業も一部に存在する。こうした企業では、データ基盤の整備やAIを前提としたIT環境構築が進んでおり、PwCはAI活用の成熟度の違いが企業業績に影響し始めているとまとめている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>SuperQ、（暫定）世界初の量子コンピューティングを活用した消費者向けアプリ「ChatQLM」公開──量子技術にも「ChatGPTモーメント」を！</title>
      <link>https://ledge.ai/articles/quantum_chatgpt_moment_superq_chatqlm_ces2026</link>
      <description><![CDATA[<p>カナダの量子技術企業 SuperQ Quantum Computing Inc. は2025年12月23日（現地時間）、量子コンピューティングを活用した消費者向けアプリ「ChatQLM」を<a href="https://www.superq.co/news/superq-to-launch-chatqlm-at-ces-2026">発表</a>した。同社は同アプリを CES 2026（2026年1月6〜9日、米ラスベガス）で公式ローンチすると明らかにしていた。</p>
<p>続く2026年1月13日付の<a href="https://www.superq.co/news/debuts-worlds-first-quantum-powered-consumer-app-chatqlm-">発表</a>では、CES 2026での展示・デモを経て、ChatQLMを「世界初の量子コンピューティングを活用した消費者向けアプリ」として正式に発表した。同社によると、ChatQLMはモバイルおよびWebアプリとして提供され、Web、Google Play、Apple App Storeで同時に利用可能となる。</p>
<p>ChatQLMは生成AIと量子最適化を橋渡しする消費者向けアプリとして設計されたと同社はいう。従来の大規模言語モデル（LLM）が得意とする会話や文章生成に加え、数理的な最適化や意思決定支援を組み合わせることで、専門家や大規模組織に限られていた高度な計算資源を一般ユーザーにも開放することを狙う。</p>
<p>同社はこの取り組みを <strong>「The ChatGPT Moment for Quantum（量子技術のChatGPTモーメント）」</strong> と表現している。これは、生成AIが対話型インターフェースを通じて専門領域から一般ユーザーへと急速に普及した転換点になぞらえたもので、量子技術においても、専門知識を前提としない形で実用的な問題解決に触れられる段階に入ることを意味すると説明している。</p>
<p>ChatQLMの中核には、同社独自の「Quantum Leveraged Model（QLM）」が採用されている。自然言語で入力された課題を解析し、最適化ソルバー、量子アニーリング方式の量子計算機、ゲート型量子コンピュータ、あるいはNVIDIAベースの古典的スーパーコンピューティングクラスタなど、最適な計算基盤へ自動的にルーティングする仕組みだ。ユーザーは量子物理やプログラミングの専門知識を必要とせず、結果としてデータに基づく意思決定や可視化された最適化結果を得られるとしている。</p>
<p>同社はChatQLMを「世界初の量子搭載コンシューマーアプリ」とうたっているが、現時点で第三者機関による公式な認定については言及していない。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Romiに2年に一度の健康診断──MIXI、会話AIロボットを長期にわたって安心して使える公式アフターケア開始</title>
      <link>https://ledge.ai/articles/romi_2year_health_check_mixi_official_aftercare_launch</link>
      <description><![CDATA[<p>MIXIは2026年1月14日、会話AIロボット「Romi（Lacatanモデル）」に対応した公式アフターケアサービス「Romiクリニック」の提供を開始したことを<a href="https://mixi.co.jp/news/2026/0114/47942/">発表</a>した。</p>
<p>修理や外装交換、定期的な状態確認などを公式に担うことで、Romiを長期にわたって安心して使える体制を整える。</p>
<p>Romiクリニックは、Romi本体を預かり、メーカー公式として点検・修理を行うアフターケアサービスだ。人の健康診断になぞらえた「2年に一度の健康診断」メニューを含め、ハードウェアの状態確認や不具合対応を通じて、日常的に使われる会話AIロボットの継続利用を支える。</p>
<p><strong>■ Romiクリニックで提供される「健康診断」のイメージ。各センサーや外装の状態を公式基準で確認する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_1024x334_15185863ff/1_1024x334_15185863ff.webp" alt="1-1024x334.webp" /></p>
<p>提供される主なサービスには、本体の不具合修理や外装（シェル）の交換、動作や状態を総合的に確認する健康診断などが含まれる。これらは、公式基準に基づいて実施され、詳細な内容や条件は専用の案内ページで示されている。</p>
<p>MIXIはあわせて、Romi専用のアフターケア対応ラボを設置した。開発元ならではの知見を生かし、ソフトウェアだけでなくハードウェアも含めた包括的なサポートを行う点が特徴となる。</p>
<p><strong>■ Romi専用ラボで行われる点検・外装交換作業。開発元による公式アフターケア体制を整備した</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/lab01_1024x444_f66c7d779c/lab01_1024x444_f66c7d779c.webp" alt="lab01-1024x444.webp" /></p>
<p>Romiは、日常会話を通じてユーザーと関係性を築く家庭向けの会話AIロボットとして展開されてきた。今回の公式アフターケアの開始により、AIロボットを「購入して終わり」の製品ではなく、長期的に付き合う存在として支える仕組みが整備された形だ。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stack Overflowの質問数が急減、ピーク比で約8割減──生成AI普及で開発者の行動に変化</title>
      <link>https://ledge.ai/articles/stack_overflow_questions_decline_generative_ai</link>
      <description><![CDATA[<p>情報技術系コミュニティサイト「Stack Overflow」で、ユーザーから投稿される質問数が大幅に減少していることが、公開データから明らかになった。Stack Exchangeが提供する公開データベース「<a href="https://data.stackexchange.com/stackoverflow/query/1926661#graph">Stack Exchange Data Explorer（SEDE）</a>」を2026年1月時点で集計したところ、Stack Overflowの質問投稿数が長期的に大きく減少していることが分かった。</p>
<p>月別の質問投稿数を集計すると、最盛期と比べて約8割減の水準にまで落ち込んでおり、開発者が問題解決の手段を変えつつある実態が浮かび上がっている。</p>
<h2>公開データが示す質問数の急減</h2>
<p>Stack Exchangeが提供する公開データベース「Stack Exchange Data Explorer（SEDE）」を用いて、Stack Overflow上の質問投稿（PostTypeId＝1）を月別に集計すると、2010年代後半にピークを迎えた後、投稿数は長期的な減少傾向に入っている。特に2023年以降は減少ペースが加速しており、直近の水準はピーク時と比べて約78％減となっている。</p>
<p>この集計では、削除済みの投稿や集計条件による差異が生じる可能性はあるものの、クエリ条件を変えても「質問数が大きく減少している」という全体傾向は一貫して確認できる。</p>
<h2>生成AIの普及で変わる開発者の問題解決行動</h2>
<p>質問投稿数が減った背景として、複数の海外メディアは生成AIの普及を挙げている。開発者は、コードの書き方やエラー内容の解釈といった疑問を、Q&amp;Aサイトに投稿して回答を待つのではなく、ChatGPTなどの対話型AIに直接尋ね、即座に解決するケースが増えているとされる。</p>
<p>Stack Overflow自身が実施している年次の開発者調査でも、生成AIツールの利用が急速に広がっていることが示されており、問題解決の導線が従来とは異なる形へ移行しつつあることがうかがえる。</p>
<h2>「質問の場」から「知識基盤」へ移る役割</h2>
<p>一方で、新規質問の投稿数が減少しているからといって、Stack Overflowの価値が失われたわけではない。これまでに蓄積された膨大なQ&amp;Aコンテンツは、現在も検索経由で参照され続けており、知識ベースとしての役割は維持されている。生成AIが回答を生成する際の参照元として、過去の投稿が利用されるケースも少なくない。</p>
<p>Stack Overflowは現在、投資会社Prosus傘下の事業として運営が続けられている。質問数の減少と、事業としての継続性や収益構造は必ずしも直結するものではなく、開発者コミュニティの利用形態が変化する中で、サービスの位置づけそのものが転換点を迎えている状況といえる。</p>
<p>生成AIの普及によって、開発者が「質問を投稿する場」としての利用を減らす一方、「知識を参照する基盤」としての役割が相対的に高まる。Stack Overflowの質問数減少は、開発者の行動変化を映し出す象徴的な事例となっている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Wikipediaが25周年、AI時代の知識基盤に──MicrosoftやMistral AIなどと新たなパートナーシップ</title>
      <link>https://ledge.ai/articles/wikipedia_25th_anniversary_ai_partnerships</link>
      <description><![CDATA[<p>Wikimedia Foundationは2026年1月15日、オンライン百科事典「Wikipedia」が創設から25周年を迎えたと<a href="https://wikimediafoundation.org/news/2026/01/15/wikipedia-celebrates-25years/">発表</a>した。</p>
<p>これにあわせて、記念キャンペーン「Wikipedia 25」を開始し、ボランティア編集者の活動を紹介する動画シリーズの公開や、AI時代におけるWikipediaの価値を示す取り組みを打ち出した。</p>
<p>Wikipediaは2001年に公開され、誰でも編集に参加できる百科事典として発展してきた。現在では300以上の言語で6500万超の記事を掲載し、月間の閲覧数は約150億回にのぼる。非営利組織によって運営されている点も特徴で、世界で最も利用されているウェブサイトの一つとなっている。</p>
<p>@<a href="https://www.youtube.com/watch?v=C5rPmv27YzY">YouTube</a></p>
<h2>編集者に焦点を当てた公式動画シリーズを公開</h2>
<p>25周年キャンペーンの一環として、ウィキメディア財団は初めて公式の動画ドキュメンタリーシリーズを公開した。世界各地のボランティア編集者8人を取り上げ、Wikipediaの記事がどのように作られ、検証されているのかを紹介している。</p>
<p>Wikipediaのコンテンツは、約25万人の編集者によって執筆・編集・ファクトチェックが行われており、財団は「AI時代においても、信頼できる知識は人によって支えられている」と強調している。</p>
<h2>タイムカプセルや参加型企画も展開</h2>
<p>同日には「<a href="https://wikipedia25.org/ja/">25 Years of Wikipedia</a>」と題したデジタル・タイムカプセルも公開された。創設者のジミー・ウェールズ氏が語る立ち上げ当時のエピソードや、世界的な出来事とWikipediaの関わりを振り返る内容が盛り込まれている。
このほか、Wikipediaの将来像をテーマにしたインタラクティブなクイズなど、利用者が参加できる企画も用意された。</p>
<h2>AI時代の知識基盤としてのWikipedia</h2>
<p>財団は、生成AIの普及が進む中で、Wikipediaの役割が一層重要になっていると位置づける。Wikipediaの記事は、検索エンジンや音声アシスタント、生成AIチャットボットなどで参照・活用されており、高品質な学習データとしても利用されている。公式発表では、Wikipediaが「人間によって作られ、検証された知識の集合体」である点が、AI時代における強みとして示された。</p>
<h2>MicrosoftやMistral AIなどと新たなパートナーシップ</h2>
<p>こうした背景のもと、ウィキメディア財団はWikimedia Enterpriseを通じて、テクノロジー企業との連携を拡大している。
過去1年間で、Microsoft、Mistral AI、Perplexityのほか、Ecosia、Pleias、ProRataといった企業が新たにパートナーに加わった。既存のパートナーにはAmazon、Google、Metaなどが含まれる。
これらの企業は、Wikipediaのコンテンツを大規模に利用できる一方で、非営利モデルを支える形で財団を支援する仕組みとなっている。</p>
<h2>人間中心のAI戦略を継続</h2>
<p>ウィキメディア財団は、AIの活用についても「編集者を支援するための技術」と位置づけており、人間中心のAI戦略を掲げている。編集作業の効率化やアクセシビリティの向上を図りつつ、知識の信頼性を維持することを目的としている。</p>
<p>財団は今後も2026年を通じて、オンラインイベントや各地のコミュニティによる取り組みなど、25周年を記念した活動を継続する予定だとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>画像生成AIの拡散モデル一強に“自己回帰×拡散”で対抗　中国Z.aiが「GLM-Image」発表、文字・知識系の生成に強み</title>
      <link>https://ledge.ai/articles/zai_glm_image_autoregressive_diffusion_image_generation</link>
      <description><![CDATA[<p>中国のAI企業 Z.ai は2026年1月14日、離散自己回帰（discrete auto-regressive）方式の画像生成モデル GLM-Image を<a href="https://z.ai/blog/glm-image">発表</a>した。オープンソースとして公開される一方、商用・業務利用を想定した「産業グレード」の性能をうたう。自己回帰モデルと拡散モデルを組み合わせたハイブリッド構成を採用し、文字入り画像や知識集約型の生成で優位性があるとしている。</p>
<h2>自己回帰と拡散を組み合わせたハイブリッド設計</h2>
<p>GLM-Imageは、画像生成を連続的なノイズ除去で行う拡散モデルに、画像を離散トークン列として逐次生成する自己回帰（Autoregressive）方式を組み合わせた点が特徴だ。Z.aiによると、自己回帰側が画像の意味構造やレイアウトといった低周波成分を担い、その後に拡散デコーダが高周波のディテールを補完する設計としている。</p>
<p>モデル構成は、自己回帰生成器に約90億パラメータ、拡散デコーダに約70億パラメータを用いる二段構えとなっている。テキストから画像を生成する一般的な用途に加え、画像編集、スタイル転送、ID保持生成、複数被写体の一貫性維持など、画像から画像へのタスクにも対応すると説明されている。</p>
<p><strong>■ GLM-Imageの全体アーキテクチャ：</strong> 自己回帰モデル（GLM AR）が低解像度の視覚トークンを生成し、拡散デコーダが高周波のディテールを補完する二段構成。文字情報（Glyph）も独立して埋め込み処理される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/glm_image_new_5d44984a83/glm_image_new_5d44984a83.jpg" alt="glm-image-new.jpg" /></p>
<h2>文字・知識集約型生成を重視、ベンチマークで強みを主張</h2>
<p>Z.aiは、近年の画像生成分野で主流となっている拡散モデルについて、高品質な生成に強みがある一方、文字の正確な描画や複雑な知識表現では課題が残ると整理する。GLM-Imageはその弱点を補う位置づけで、ポスター、プレゼンテーション資料（PPT）、科学図解など、情報量の多い「知識集約型」画像生成を主なターゲットに据えている。</p>
<p><strong>■ Single-Stream DiTにおけるAttention制御の概念図：</strong> 条件画像、文字（Glyph）、生成対象を単一ストリームで扱いながら、Attention Maskにより相互参照範囲を制御。文字や知識要素を保持したまま画像生成を行う設計を示す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20260112_171559_65d0712626/20260112_171559_65d0712626.jpeg" alt="20260112-171559.jpeg" /></p>
<p>公式ブログによれば、テキストレンダリング性能を測るベンチマーク「CVTG-2K」では、オープンソースモデルとして上位水準のスコアを記録したとされる。文字の正確性を示す指標では0.9を超える値を示し、Z.aiは文字生成の安定性を強みとして挙げている。<a href="https://github.com/zai-org/GLM-Image">GitHub</a>上では、複数の公開ベンチマークにおける他モデルとの比較結果も提示されている。</p>
<p><strong>■ GLM-Imageによる生成例：</strong> ポスター、教育用図解、文字入りインフォグラフィックなど、知識集約型コンテンツの生成例。文字の可読性やレイアウトの一貫性を重視した出力が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/glm_image_showcase_poster_8c14d0aded/glm_image_showcase_poster_8c14d0aded.jpg" alt="glm-image-showcase-poster.jpg" /></p>
<h2>オープン提供と実運用上の条件、残る課題</h2>
<p>GLM-Imageはオープンウェイトで公開され、APIとしても利用可能とされている。公式ドキュメントではAPI利用料金を1画像あたり0.015ドルとしており、対応解像度は512〜2048ピクセル、幅・高さはいずれも32の倍数であることが条件とされている。</p>
<p>一方で、実運用上のハードルも明示されている。GitHubの説明によると、現時点では推論最適化が限定的で、1024×1024ピクセルの生成でも大容量GPUを必要とする。80GB超の単一GPU、もしくは複数GPU構成が想定されており、推論コストは依然として高い。Z.aiは今後、自己回帰部分の高速化や推論基盤への対応を進めるとしている。</p>
<p>ライセンスについては、GitHub上ではApache License 2.0と表記されている一方、<a href="https://huggingface.co/zai-org/GLM-Image">Hugging Face</a>のモデルカードではモデル全体はMITライセンスで、一部コンポーネントにApache 2.0が含まれる旨が記載されている。利用にあたっては、各構成要素のライセンス条件を個別に確認する必要がある。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>