<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>OpenAI、月8ドルの低価格プラン「ChatGPT Go」を世界展開──アクセス拡大を狙い、無料版・Go向け広告テスト方針も公表</title>
      <link>https://ledge.ai/articles/openai_chatgpt_go_global_launch_ads_test_policy</link>
      <description><![CDATA[<p>OpenAI は2026年1月16日（現地時間）、対話型AI「ChatGPT」の新たな料金プラン「ChatGPT Go」を、ChatGPTが提供されているすべての地域で利用可能にしたと<a href="https://openai.com/ja-JP/index/introducing-chatgpt-go/">発表</a>した。
あわせて、無料版およびGoプランを対象に、広告表示のテストを米国で段階的に開始する方針を明らかにした。</p>
<h2>月8ドルの低価格プラン「ChatGPT Go」を世界提供</h2>
<p>ChatGPT Goは、より多くのユーザーが高度なAI機能にアクセスできるよう設計された低価格の有料プランで、米国での価格は月額8ドル。OpenAIによると、2025年8月にインドで先行提供した後、約170の国・地域へ段階的に展開してきたが、今回の発表によりChatGPT提供地域すべてで利用可能となった。</p>
<p>Goプランでは、無料版と比べてメッセージ送信数、ファイルアップロード、画像生成の利用枠が最大10倍に拡張されるほか、より長い会話履歴や文脈を扱えるとしている。OpenAIは、文章作成、学習、問題解決、クリエイティブ用途など、日常的なAI活用を想定したプランだと説明している。</p>
<h2>無料版・Go向けに広告テストを予告</h2>
<p>同日、OpenAIは広告導入に関する考え方も公開した。現時点でChatGPT内に広告は表示されていないが、今後数週間以内に米国で、無料版およびChatGPT Go利用者を対象とした広告テストを開始する予定だとしている。</p>
<p>広告は、ChatGPTの回答下部に明確にラベル付けされた形で表示され、AIの回答（オーガニックな応答）とは明確に分離される。OpenAIは、広告が回答内容に影響を与えることはないと明言している。</p>
<h2>回答の独立性とプライバシーを重視</h2>
<p>OpenAIは、広告導入にあたっての原則として、以下の点を強調している。</p>
<ul>
<li>広告は18歳以上のログインユーザーにのみ表示</li>
<li>18歳未満のユーザーや、健康・メンタルヘルス、政治などのセンシティブな話題では広告を表示しない</li>
<li>ユーザーの会話内容を広告主に共有・販売しない</li>
<li>広告のパーソナライズ設定はユーザー側で制御可能</li>
</ul>
<p>これらの方針は、ChatGPTの信頼性や安全性を維持しつつ、サービスの持続的な運営を図る狙いがあるとしている。</p>
<h2>上位有料プランは引き続き広告なし</h2>
<p>広告表示の対象は無料版とChatGPT Goに限定され、ChatGPT Plus、Pro、Business、Enterpriseといった上位有料プランでは、引き続き広告は表示されない。OpenAIは、こうしたプラン構成により、広告を避けたいユーザーには明確な選択肢を提供するとしている。</p>
<p>OpenAIは今回の取り組みについて、AI開発と運用にかかるコストが増大する中でも、より多くの人にChatGPTへのアクセスを提供するための施策だと位置付けており、広告テストについても利用者からのフィードバックを踏まえながら改善していく方針を示している。</p>
]]></description>
      <pubDate>Mon, 19 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは日本の司法試験を突破できるのか──慶應義塾大研究、短答式で合格点に到達</title>
      <link>https://ledge.ai/articles/llm_japanese_bar_exam_self_verification</link>
      <description><![CDATA[<p>慶應義塾大学の研究者は2026年1月6日、日本の司法試験（短答式）において、大規模言語モデル（LLM）が実際の出題形式と公式の採点基準を変更せずに、合格水準の得点を記録したとする研究成果を<a href="https://arxiv.org/abs/2601.03144">発表</a>した。出題を簡略化せず、採点ルールも変更しない条件下で合格水準に達した例は、研究チームによると初めてだという。</p>
<h2>評価を変えずに測る──「日本の司法試験」という高い壁</h2>
<p>研究の対象となったのは、日本の司法試験における短答式試験である。短答式は多肢選択式ではあるものの、単純な一問一答ではなく、複数の命題を同時に評価し、その正誤の組み合わせ全体を一つの解答として選択させる形式を取る。</p>
<p>採点は厳格で、部分点は存在するものの、複数の命題がまとめて評価されるため、1つの判断ミスで大きく減点され、条件によっては0点となる。さらに、合否判定には総合点に加え、憲法・民法・刑法の各科目で40％以上の得点を求める要件が設けられている。</p>
<p>従来のAI研究では、こうした設問を○×形式に分解して学習・評価する手法が多く用いられてきた。しかしこの場合、本来の組み合わせ評価や採点ルールが再現されず、実際の試験形式で通用するかは不明確だった。同研究は、評価方法を簡略化せず、実試験と同一条件で検証する点を特徴としている。</p>
<h2>自己検証を用いた単一モデルによるアプローチ</h2>
<p>同研究を主導したのは、Andrew Shin氏で、成果は論文「Self-Verification is All You Need To Pass The Japanese Bar Examination」として公開されている。</p>
<p>研究では、OpenAIのGPT-4.1をベースモデルとし、日本の司法試験短答式の過去問を用いてファインチューニングを行った。特徴的なのが、「自己検証（Self-Verification）」と呼ばれる手法だ。</p>
<p>モデルはまず通常どおり解答を生成し、その後、同一モデルが別のプロンプトを用いて自らの解答を再確認する。この追加推論は1回のみで、外部ツールや別モデルは使用しない。再検証の段階では、形式的な誤りや明確な不整合がある場合に限り、保守的に修正を行う設計となっている。</p>
<p>研究では、マルチエージェント型の推論手法や、問題分解型データセット（JBE-QA）を用いた手法とも比較を行ったが、いずれも単一モデル＋自己検証の成績を下回ったとしている。</p>
<h2>検証結果の位置づけ</h2>
<p>2024年（令和6年）司法試験の短答式問題を用いた評価では、自己検証を組み込んだモデルが平均94.7点、最高96点を記録した。同年の合格基準は93点であり、科目別の最低得点要件も満たしている。一方、GPT-4.1をそのまま用いたゼロショット推論や、問題分解型の手法では合格水準に達しなかった。</p>
<p>もっとも、同研究は短答式試験に限定した検証であり、論文式（記述式）試験や、実務における法的判断能力を示すものではない。論文でも、その点については明確に留保が付されている。</p>
<p>同研究は、日本の司法試験という厳格な形式を対象に、評価条件を変更しない形でLLMの到達点を検証した事例として位置づけられる。</p>
]]></description>
      <pubDate>Sun, 18 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>XでのGrok画像生成を巡り方針転換──イーロン・マスク氏が規制圧力下で技術的制限に踏み切る、一方米国防省は業務用途でGrok活用へ</title>
      <link>https://ledge.ai/articles/us_war_department_ai_acceleration_strategy_grok_adoption_controversy</link>
      <description><![CDATA[<p>イーロン・マスク氏率いるxAIの生成AI「Grok」を巡り、画像生成・編集機能の運用方針が転換された。</p>
<p>合意のない性的画像生成が国際的な問題として拡大する中、xAIは2026年1月15日、生成AI「Grok」の画像生成・編集機能について、実在する人物の画像を露出の多い服装に編集する行為を技術的に制限したと<a href="https://x.com/safety/status/2011573102485127562">発表</a>した。この制限は、X（旧Twitter）上で提供されているGrokの機能に適用されている。</p>
<p>Grokの画像生成機能は、ユーザーの指示に基づき投稿画像を加工・生成できる点が特徴だったが、第三者の写真を「ビキニ姿にする」といった編集が可能であったことから、非合意の性的表現や未成年への影響を懸念する声が各国で強まっていた。
各国当局が調査・遮断、規制圧力が表面化
問題はSNS上の炎上にとどまらず、各国の規制当局が動く事態へと発展した。
英国では通信・放送規制当局が、Grokによる性的画像生成をめぐりXに対する正式調査を開始。法令違反が確認された場合、制裁金やサービス停止に発展する可能性があるとされた。</p>
<p>また、インドネシアおよびマレーシアでは、合意のない性的コンテンツ生成を理由に、Grokへのアクセスが事実上遮断される措置が取られた。Grokを巡る問題は、複数の法域で同時並行的に扱われる国際的な規制テーマとなっていた。
Xが公式に説明、ビキニ画像生成を技術的に禁止
こうした状況を受け、Xは安全対策として具体的な技術的対応を実施した。
Xのセーフティ公式アカウントは2026年1月、Grokアカウントにおける画像生成・編集機能について、実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したと説明している。</p>
<p><strong>■ Xのセーフティ公式アカウントが公表した、Grokアカウントにおける画像生成・編集機能の制限に関する説明。実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Grok_Account_Image_Generation_Updates_7e8a3c53b0/Grok_Account_Image_Generation_Updates_7e8a3c53b0.jpg" alt="Grok Account Image Generation Updates.jpg" /></p>
<p>この制限は、有料プランを含むすべての利用者に適用されるとしており、運用ルールの明確化ではなく、機能レベルでの制約が導入された形だ。Grokを巡る一連の対応は、マスク氏が掲げてきた比較的自由度の高い生成AI運用からの実質的な方針転換と受け止められている。
一方で米国防省は業務用途での活用を進める
民間向けサービスで制限が進む一方、別の文脈ではGrokの活用が進められている。
米国防省は2026年1月12日、軍事分野におけるAI活用を加速する戦略の中で、全省横断の生成AI基盤にGrokを含める方針を明らかにした。</p>
<p>国防省の戦略では、民間SNSでの利用状況とは切り分け、業務用途としての生成AIを閉域環境で活用することが想定されている。
Grokを巡っては、規制対応と実利用の判断が異なるレイヤーで同時に進んでいる状況だ。</p>
<p><strong>■ 米国防省のピート・ヘグセス長官（左）とxAIのイーロン・マスク氏。ヘグセス長官は2026年1月、テキサス州スターベースを訪問した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_h_O_Icr_Wo_AA_Ia3m_64538f880e/G_h_O_Icr_Wo_AA_Ia3m_64538f880e.jpg" alt="G-hOIcrWoAAIa3m.jpg" /></p>
]]></description>
      <pubDate>Sat, 17 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIによる「失業パニック」は起きない？──Forrester予測、2030年までに置き換わる職は米国全体の約6％</title>
      <link>https://ledge.ai/articles/forrester_ai_job_impact_forecast_us_2025_2030</link>
      <description><![CDATA[<p>AIによる雇用喪失への不安が世界的に広がるなか、調査会社のForresterは2026年1月13日、大規模な失業パニックが直ちに起きる可能性は低いとする<a href="https://www.forrester.com/press-newsroom/forrester-impact-ai-jobs-forecast/">見通しを示した</a>。2025年12月末に発表した最新レポートによると、米国で2030年までにAIと自動化によって置き換わる職は全体の約6％、約1040万件にとどまると<a href="https://www.forrester.com/blogs/ai-and-automation-will-take-6-of-us-jobs-by-2030/">予測</a>している。</p>
<p>同レポートは「The Forrester AI Job Impact Forecast, US, 2025–2030」と題され、AIが雇用に与える影響を定量的に分析したものだ。AIの進展によって一部の職種が影響を受けることは避けられないとしつつも、社会全体を揺るがすような急激な雇用崩壊には至らないとの見方を示している。</p>
<h2>AIは職業ではなく「タスク」を置き換える</h2>
<p>Forresterの分析で強調されているのは、AIが直接置き換えるのは「職業」ではなく、職業を構成する「タスク」であるという点だ。多くの仕事は複数の業務要素から成り立っており、その一部がAIによって自動化されるケースが中心になるとされている。</p>
<p>このため、AI導入が即座に人員削減につながるわけではなく、業務の再設計や役割分担の見直しが進む可能性が高いと分析している。</p>
<h2>影響を受けやすい職と限定的な職</h2>
<p>レポートでは、定型的で反復性の高い業務を中心とする職種ほど、AIや自動化の影響を受けやすいと指摘している。一方で、対人対応、判断、創造性を伴う業務については、AIによる完全な代替は限定的になるとの見方を示した。</p>
<p>AIの影響は一様ではなく、職種や業務内容によって大きな差が生じる点が強調されている。</p>
<h2>「AI失業パニック」への警鐘</h2>
<p>Forresterは、AIによる失業への過度な恐怖が、拙速な自動化や短期的なコスト削減判断を招くリスクにも言及している。AIは人件費削減の手段としてではなく、生産性向上や業務の高度化を目的として活用すべきだとしている。</p>
<p>同社は、AIを前提とした業務設計と人材育成を並行して進めることが、企業にとって重要になると指摘した。</p>
<h2>雇用構造の変化にどう向き合うか</h2>
<p>レポートは、今後の課題としてリスキリングやアップスキリングの重要性を挙げている。AIによって一部の業務が置き換わる一方で、新たな役割やスキル需要が生まれる可能性があるためだ。</p>
<p>Forresterは、AIを「雇用を破壊する存在」として捉えるのではなく、雇用構造を変化させる要因として冷静に受け止める必要があるとしている。</p>
]]></description>
      <pubDate>Fri, 16 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Googleの開発用プラットフォーム「Antigravity」に“Agent Skills”登場　エージェントに作業手順を配布できるオープン標準</title>
      <link>https://ledge.ai/articles/google_antigravity_agent_skills_open_standard</link>
      <description><![CDATA[<p>Google は2026年1月14日（現地時間）、同社の開発用プラットフォームAntigravityにおいて、エージェントの機能を拡張するパッケージ「Skills」のオープン標準を<a href="https://antigravity.google/docs/skills">発表</a>した。Skillsは、特定の作業に必要な手順やベストプラクティス、必要に応じてスクリプトや参考実装などをまとめた再利用可能な知識パッケージで、エージェントは作業時にそれらを参照しながらタスクを進められる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Antigravity_x_ab552c6744/Antigravity_x_ab552c6744.jpg" alt="Antigravity x.jpg" /></p>
<h2>作業手順を“知識パッケージ”として配布</h2>
<p>Skillsは、エージェントに対して都度プロンプトで細かな指示を与えるのではなく、あらかじめ整理された作業マニュアル一式を参照させるための仕組みだ。単純な定型作業から、判断を伴う業務フローまでをSkillとして定義でき、同じSkillを複数のエージェントやプロジェクトで再利用できる点が特徴となる。</p>
<h2>人が書き、エージェントが参照するための共通フォーマット</h2>
<p>各Skillはフォルダー単位で構成され、その中核となるのがSKILL.mdファイルだ。SKILL.mdには、Skillの名称や概要、前提条件、具体的な手順などをYAML形式のフロントマターとして記載し、本文には作業手順をMarkdownで記述する。
同じフォルダー内には、スクリプト、テンプレート、参考実装などの追加リソースを含めることができ、Skill全体として一体的に扱われる。</p>
<h2>単純作業から業務フローまでを扱える設計</h2>
<p>より複雑なSkillでは、「条件に応じて次の手順を切り替える」といった意思決定の分岐も記述可能だ。Antigravityでは、1つのSkillにつき目的を明確にし、説明文を具体的に書くことを推奨している。これにより、エージェントが必要な情報だけを参照しながら作業を進められる設計となっている。</p>
<h2>先行するAnthropicの「Agent Skills」という発想</h2>
<p>このSkillsの設計思想は、Anthropicが先行して提示してきた「Agent Skills」の考え方と重なる。Anthropicは、エージェントに現実的な業務能力を持たせるため、SKILL.mdを中心とした構造を採用し、2025年末には特定のプラットフォームに依存しないオープン標準として公開していた。
GoogleがAntigravityでSkills対応を打ち出したことで、エージェントに与える作業手順やノウハウをツール横断で共有する流れが、主要プラットフォーム間で具体化しつつある。</p>
]]></description>
      <pubDate>Fri, 16 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとソフトバンクグループ、SB Energyに10億ドル投資──「Stargate」構想 1.2GW級データセンター建設を加速</title>
      <link>https://ledge.ai/articles/openai_softbank_sb_energy_stargate_data_center_investment</link>
      <description><![CDATA[<p>OpenAIとソフトバンクグループは2026年1月9日（米太平洋時間）、ソフトバンクグループ傘下の米インフラ企業SB Energyと戦略的パートナーシップを締結し、同社に総額10億ドル（各社5億ドル）を投資すると<a href="https://openai.com/ja-JP/index/stargate-sb-energy-partnership/">発表</a>した。今回の提携は、米国における次世代AI・エネルギー基盤の構築を目的とする「Stargate」構想の一環と位置づけられている。</p>
<p>OpenAIは同社を、テキサス州ミラム郡に計画されている1.2GW規模のデータセンターサイトの建設・運営パートナーに選定。OpenAIはこの初期データセンター構築に向け、1.2GW分のデータセンターリース契約を締結している。今回の出資は、SB Energyが大規模データセンターキャンパスおよび関連エネルギーインフラの開発・実行パートナーとして成長することを支援する狙いがある。</p>
<p>SB Energyは現在、複数のマルチギガワット級データセンターキャンパスを開発中で、最初の施設はすでに建設段階にあり、2026年から順次稼働を開始する予定だという。今回の取り組みは、ホワイトハウスで1月に発表された5,000億ドル規模の「Stargate」コミットメントを基盤とするものだ。</p>
<p>今回の取引の一環として、OpenAI、ソフトバンクグループ、SB Energyの3社は、非独占の優先パートナーシップも締結した。OpenAIの自社設計によるデータセンターと、SB Energyのスピード、コスト管理、統合型エネルギー供給の知見を組み合わせ、AI専用インフラを大規模に構築する新たなモデルの開発を目指すとしている。SB Energyは各プロジェクトを通じて、雇用創出や人材育成、送電網の近代化など、地域社会への投資も行う方針だ。</p>
<p>またSB Energyは、データセンター事業の成長を支えるため、データセンター建設管理・調達・設計・運用を手がけるStudio 151を買収した。20以上のデータセンターキャンパスで実績を持つ同社を取り込むことで、開発から運用までの内製能力を強化する。</p>
<p>なお、SB Energyは2025年に、米投資会社Aresから8億ドルの償還可能優先株式による出資を受けており、今回の投資はAresとの長期的な関係をさらに深めるものだとしている。</p>
<p>今回の投資と提携は、AIモデルの開発競争そのものではなく、大規模な計算資源を支える電力・用地・建設能力を含めた「AIインフラ」を確保する動きとして位置づけられる。</p>
<p>Stargate構想のもと、OpenAIとソフトバンクグループは、計算基盤の主導権を中長期で握る体制づくりを進めている。</p>
]]></description>
      <pubDate>Thu, 15 Jan 2026 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、非エンジニア向け業務AIエージェント「Cowork」開始──Claude Codeの自律実行を一般業務へ拡張</title>
      <link>https://ledge.ai/articles/anthropic_cowork_launch_claude_code_agent_general_work</link>
      <description><![CDATA[<p>Anthropicは2026年1月12日（現地時間）、同社のAIアシスタント「Claude」において、新機能「Cowork（コワーク）」を研究プレビューとして開始したことを<a href="https://claude.com/blog/cowork-research-preview">発表</a>した。</p>
<p>開発者向けのコーディングエージェント「Claude Code」で培ってきた自律的なタスク実行の仕組みを、文書整理や資料作成といった一般業務にも拡張し、開発者以外でも利用できる業務エージェントとして提供する。</p>
<h2>「指示に答えるAI」から「作業を進めるAI」へ──Coworkの位置づけ</h2>
<p>Coworkは、Claudeがユーザーの「同僚（co-worker）」のように振る舞い、単発の質問に答えるだけでなく、目的を理解し、作業計画を立て、複数ステップのタスクを自律的に実行することを想定した機能だ。</p>
<p>Anthropicは、Claude Codeの提供後、開発者がコーディング以外の用途にも同機能を広く使い始めたことを背景に、よりシンプルで誰でも使える形としてCoworkを開発したとしている。基盤はClaude Codeと共通で、同様の自律実行能力を、非コーディング業務向けに抽象化した形となる。</p>
<p>@<a href="https://www.youtube.com/watch?v=UAmKyyZ-b9E">YouTube</a></p>
<h2>ローカルファイルを直接扱う業務エージェント</h2>
<p>Coworkは、macOS向けのClaude Desktopアプリ上で動作する。ユーザーが許可したフォルダに対して、Claudeが以下の操作を直接行える点が特徴だ。</p>
<ul>
<li>ファイルの読み取り</li>
<li>ファイルの編集・新規作成</li>
<li>複数ファイルの整理や再構成</li>
</ul>
<p>公式ブログでは、ダウンロードフォルダの自動整理、スクリーンショットの束から経費一覧のスプレッドシートを作成する作業、散在するメモからレポートの下書きを作る作業などが例として挙げられている。チャット上の応答にとどまらず、実際の業務ファイルを扱いながら作業を進める点がCoworkの特徴だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=WBNZpAWhw5E">YouTube</a></p>
<h2>コネクタ、スキル、Chrome連携──業務エージェントとしての拡張性</h2>
<p>Coworkでは、Claudeが既存のコネクタを利用できる。これにより、外部情報と連携したタスク実行が可能になる。また、Cowork向けに、文書やプレゼンテーション、各種ファイル作成を強化する初期スキル群も追加された。さらに、Chrome上でClaudeを利用する設定と組み合わせることで、ブラウザ操作を伴うタスクにも対応できるとしている。</p>
<p>Anthropicは、Coworkでは毎回文脈を手動で与えたり、出力結果を別の形式に変換したりする必要がなく、タスクをキューに積んで並列に進められる設計になっている点も特徴だと説明する。やり取りを重ねるというより、「同僚にまとめて指示を残す」感覚に近い体験を目指したという。</p>
<h2>提供条件と現時点での制約</h2>
<p>Coworkは研究プレビューとして提供されており、現時点での利用条件は以下の通り。</p>
<p><strong>■ 提供環境</strong>
・macOS向けClaude Desktopアプリ
・有料の「Claude Max」プラン加入者向け</p>
<p><strong>■ 制約</strong>
・セッションをまたいだ長期的な記憶は行わない
・Claudeの「Projects」機能とは未統合</p>
<p>Claude Max以外のプラン利用者については、将来提供に向けた待機リストが用意されている。
Anthropicは今後、クロスデバイス同期の追加やWindows対応など、段階的な拡張を進めるとしている。</p>
<h2>自律型AIの業務利用を前提にした安全設計</h2>
<p>Coworkでは、Claudeがローカルファイルを操作できるため、安全面での注意も明示されている。ユーザーは、Claudeに見せるフォルダやコネクタを自ら選択でき、明示的に許可していない情報にはアクセスできない。</p>
<p>また、重要な操作を行う前にはClaudeが確認を求める設計となっている。一方で、削除などの破壊的な操作が行われる可能性もあるため、指示は明確に行う必要があるとしている。</p>
<p>Anthropicは、インターネット上の内容によってAIの行動計画が変えられる「プロンプトインジェクション」のリスクにも言及し、これは業界全体で対処が続く課題だと説明する。
詳細な注意点については、Help Centerで<a href="https://support.claude.com/en/articles/13364135-using-cowork-safely">案内</a>している。</p>
]]></description>
      <pubDate>Wed, 14 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>核融合炉「SPARC」の開発をAIデジタルツインで加速―—Commonwealth Fusion Systems、NVIDIA・シーメンスと連携</title>
      <link>https://ledge.ai/articles/cfs_sparc_ai_digital_twin_nvidia_siemens</link>
      <description><![CDATA[<p>核融合スタートアップの Commonwealth Fusion Systems（CFS） は2026年1月6日、NVIDIA および Siemens と提携し、実証用核融合炉 SPARC の設計・開発をAI主導で加速するデジタルツインを構築すると<a href="https://cfs.energy/news-and-media/commonwealth-fusion-systems-accelerates-commercial-fusion-with-siemens-and-nvidia-leveraging-ai-powered-digital-twins">発表</a>した。AIとシミュレーションを中核に据え、従来は物理試験に大きく依存していた核融合炉開発のプロセスを仮想空間上で統合・高速化する。</p>
<h2>AIと産業ソフトウェアを統合したデジタルツイン</h2>
<p>CFSが構築するデジタルツインは、NVIDIAのAIおよび物理シミュレーションライブラリと、Siemensの設計・製造向けソフトウェア群を統合したものとなる。</p>
<p>SiemensのNXやTeamcenterを中心とする設計・PLM（製品ライフサイクル管理）ツールで作成されたデータを、NVIDIAのシミュレーション基盤と連携させることで、SPARCの構造・磁場・熱挙動などを一体的に再現する。</p>
<p>@<a href="https://www.youtube.com/watch?v=4PItOlY6_xE">YouTube</a></p>
<p>この環境では部品単位から炉全体までを単一の仮想モデルで扱うことが可能となり、設計変更や検証を仮想空間上で迅速に繰り返せるという。</p>
<h2>「動く炉」を再現するデジタルモデル</h2>
<p>今回のデジタルツインは、静的な3D設計モデルではなく、実際の運転を想定した動的モデルとして構築される。
電磁場、熱、構造応力といった複数の物理現象を同時に扱い、将来的には実機から得られるデータを反映させることで、仮想モデルと現実の炉の状態を同期させる設計とされている。これにより、実際に装置を製作・試験する前の段階で、設計上の課題や挙動を検証できるようになる。</p>
<h2>高磁場・小型化を支えるAI活用</h2>
<p>SPARCは、高温超電導（HTS）磁石を用いることで、従来よりも小型ながら高磁場を実現する設計を採用している。
CFSはすでに、SPARC向けの初号磁石を完成させ、出荷したことを明らかにしている。この磁石は「空母を持ち上げられるほどの磁力を持つ」と説明されており、高磁場化に伴う構造応力や熱管理が技術的な焦点となっている。</p>
<p>こうした複雑な物理挙動を事前に解析・検証するため、AIとシミュレーションを組み合わせたデジタルツインが設計プロセスの前提となっている。</p>
<h2>実機開発と仮想検証を並行</h2>
<p>CFSは、磁石の製造・据え付けと並行して、デジタルツイン上で炉全体の挙動解析を進める体制を構築している。
物理的な試作・試験と、仮想空間での検証を同時に進めることで、開発工程全体の効率化を図る狙いだ。</p>
<p>デジタルツインは、建設段階にとどまらず、将来的な運転や保守、最適化にも活用されることが想定されている。</p>
<h2>2027年稼働を見据えた基盤整備</h2>
<p>SPARCは、核融合反応による正味エネルギー獲得を目指す実証炉として開発が進められており、2027年の稼働が計画されている。
今回のNVIDIAおよびSiemensとの連携は、設計から運転までをデータとAIに基づいて進める開発基盤を整備する取り組みとして位置付けられる。</p>
]]></description>
      <pubDate>Mon, 12 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Mon, 05 Jan 2026 08:30:00 GMT</pubDate>
    </item>
    <item>
      <title>未成年の自殺を巡るAI訴訟に進展──GoogleとCharacter.AI、4州訴訟で和解に合意</title>
      <link>https://ledge.ai/articles/ai_chatbot_lawsuit_settlement_google_character_ai_four_states</link>
      <description><![CDATA[<p>AIチャットボットとの会話が未成年の自殺につながったとして提起されていた訴訟をめぐり、GoogleとCharacter.AIが和解に合意した。フロリダ連邦地裁に提出された<a href="https://www.courtlistener.com/docket/69300919/garcia-v-character-technologies-inc/">書類</a>によると、当事者は調停による和解に原則合意し、裁判所は手続きをいったん終了させている。</p>
<p>訴訟は、2024年に死亡した14歳の少年の母親が提起したもので、少年がCharacter.AIのチャットボットと継続的に会話していたことが問題とされた。裁判所に提出された通知によれば、2026年1月7日付で当事者は調停による和解に原則合意し、最終的な和解文書の作成と締結に向けて手続きを進めるとしている。裁判所は、一定期間内に最終処理が行われることを条件に、事件をいったん却下し、記録を閉じた。</p>
<p>海外メディアの報道によると、2026年1月14日に裁判所に提出された法廷文書では、今回の和解がフロリダ州、コロラド州、ニューヨーク州、テキサス州で提起されていた訴訟を対象としていることが示されている。</p>
<p>今回の訴訟では、チャットボットを直接提供していたCharacter.AIに加え、Googleも被告として名を連ねていた。原告側は、会話型AI技術の系譜や計算基盤（クラウド）の提供、事業面での関与などを理由に、Googleがサービスの成立に実質的に関与していたと主張していた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_guardian_megan_garcia_and_son_8a039bc133/the_guardian_megan_garcia_and_son_8a039bc133.jpg" alt="the guardian megan garcia and son.jpg" /></p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/08/google-character-ai-settlement-teen-suicide">The Guardian</a>は、Googleが2024年にCharacter.AIと約27億ドル規模のライセンス契約を結んでいたことが、同社が本件訴訟に関連付けられた背景の一つだと報じている。</p>
<p>これに対しGoogleは、Character.AIの運営主体ではなく、クラウドサービスの提供のみで法的責任は生じないとして請求棄却を求めていた。裁判所は、この是非について判断を示さず、却下段階では原告の主張を排除できないとして、審理の余地があるとの姿勢を示していた。</p>
<p>本件は、会話型AIと未成年をめぐるリスクが司法の場で争点となり得ることを示した一方、AIの法的責任について一般的な基準を確定させるものではなかった。基盤提供者を含む責任の射程については、今後も個別の訴訟や立法の場で検討が続くとみられる。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>独Black Forest Labs、画像生成AI「FLUX.2[klein]」を公開　生成・編集を統合し1秒未満の高速推論を実現</title>
      <link>https://ledge.ai/articles/black_forest_labs_flux2_klein_release</link>
      <description><![CDATA[<p>Black Forest Labsは2026年1月15日、画像生成AIモデルファミリー「FLUX.2」から、高速・統合型モデルFLUX.2[klein]を<a href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence">発表</a>した。</p>
<p>生成と画像編集を単一のアーキテクチャに統合し、エンドツーエンドの推論を1秒未満で完了させる低レイテンシ性を特徴とする。</p>
<p>同社は、AIエージェントの高度化に伴い、視覚生成にもリアルタイム性が求められていると指摘する。FLUX.2[klein]は、待ち時間を極小化しながら生成と編集を同時に扱える点を重視して設計されており、インタラクティブなビジュアルAIの基盤として位置づけられている。</p>
<h2>生成と編集を単一モデルで処理</h2>
<p>FLUX.2[klein]は、テキストからの画像生成に加え、既存画像の編集や複数参照画像を用いた生成などを、単一のコンパクトなモデルで処理できる。従来は別工程として扱われることの多かった生成と編集を統合することで、応答速度の向上とシステム構成の簡素化を図った。</p>
<h2>サブ秒推論とコンシューマGPU対応</h2>
<p>同モデルは低レイテンシを前提に設計されており、生成・編集を含む推論がサブ秒で完了するとされる。あわせて、最小構成で約13GBのVRAMを持つ消費者向けGPUでの動作を想定しており、ローカル環境やエッジ用途での利用も視野に入れる。</p>
<h2>9B／4B／Baseの3系統</h2>
<p>FLUX.2[klein]は用途に応じて複数のバリアントが用意されている。</p>
<ul>
<li><strong>9B（蒸留モデル）</strong> は、品質と速度のバランスを重視した小型フラッグシップとして位置づけられる。</li>
<li><strong>4B（蒸留モデル）</strong> は、より小規模で高速な推論を特徴とし、ローカル開発やリアルタイム用途を想定する。</li>
<li><strong>Base（非蒸留モデル）</strong> は、推論速度よりもLoRAなどによるカスタマイズ性を重視した構成とされる。</li>
</ul>
<h2>ライセンスと提供形態</h2>
<p>4B系モデルはApache 2.0ライセンスで提供され、商用利用が可能となっている。一方、9B系モデルはFLUX Non-Commercial License（非商用）での提供となる。これらはAPI経由での利用に加え、オープンウェイトとしてローカル実行も可能とされており、プロダクション導入と研究・開発用途の双方に対応する。</p>
<h2>量子化と最適化</h2>
<p>FLUX.2[klein]の蒸留モデルおよびBaseモデルを含む全バリアントは、FP8およびNVFP4量子化に対応しており、NVIDIAのRTX GPU向けに最適化されている。これにより推論速度の向上とVRAM使用量の削減を両立したとしている。</p>
<p>Black Forest Labsは、FLUX.2[klein]をリアルタイム生成や高頻度処理を前提としたモデルとして位置づけ、より大規模なモデルと使い分けることで、用途に応じたAI画像生成基盤の構築を可能にするとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、Gemma 3基盤の翻訳モデル群「TranslateGemma」を発表―—55言語対応のオープン翻訳AI、軽量モデルから高精度モデルまで提供</title>
      <link>https://ledge.ai/articles/google_translategemma_gemma3_open_translation_models</link>
      <description><![CDATA[<p>Googleは2026年1月15日（現地時間）、同社のオープン基盤モデル「Gemma 3」をベースにした翻訳特化モデル群「TranslateGemma」を<a href="https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/">発表</a>した。55の言語を対象とし、効率と精度を両立したオープンな機械翻訳モデルとして公開された。研究者や開発者が自由に利用できるオープンウェイトモデルとして公開される。</p>
<p>Googleによると、TranslateGemmaは大規模言語モデルを汎用的に利用するのではなく、翻訳タスクに特化した学習と最適化を行うことで、精度と計算効率の両立を図った点が特徴だという。</p>
<p><strong>■ TranslateGemmaは、4B・12B・27Bの3つのパラメータサイズで提供され、デバイスや用途に応じた翻訳モデルの選択が可能とされている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/translategemma_9695a89365/translategemma_9695a89365.jpg" alt="translategemma.jpg" /></p>
<h2>3つのモデルサイズを提供</h2>
<p>TranslateGemmaは用途に応じて選択可能な複数のモデルサイズで構成されている。
比較的軽量なモデルはエッジデバイスやローカル環境での利用を想定しており、一方で大規模モデルはGPU環境での高精度翻訳を前提としている。Googleは、中規模クラスのモデルでも高い翻訳品質を実現しているとしている。</p>
<p><strong>■  言語ファミリー別の翻訳エラー率比較。TranslateGemma 12Bは、多くの言語群でGemma 3 27Bに近い、またはそれを下回るエラー率を示している</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b.webp" alt="01-14_Chart_v3.width-1000.format-webp.webp" /></p>
<h2>日本語を含む55言語に対応</h2>
<p>対応言語には日本語を含む主要言語に加え、これまで翻訳リソースが限られていた中・低リソース言語も含まれる。Googleは、多言語対応を通じて研究用途や地域特化サービスへの応用を促進したい考えだ。</p>
<h2>マルチモーダル能力も継承</h2>
<p>TranslateGemmaは、基盤となるGemma 3の設計を引き継ぎ、テキスト翻訳に加えて画像内テキストの翻訳など、マルチモーダルなユースケースにも対応可能とされている。これにより、文書画像やスクリーンショットを含む翻訳処理にも応用できるという。</p>
<h2>オープンウェイトとして公開</h2>
<p>モデルの重みはオープンに提供され、開発者はローカル環境やクローズドなシステム内で翻訳モデルを実行・調整できる。Googleは、クラウド依存を避けたいケースや、特定ドメイン・言語ペア向けのカスタマイズ需要を想定している。</p>
<p>GoogleはTranslateGemmaについて、研究用途だけでなく、プロダクトや業務システムへの組み込みなど、幅広い活用を見込んでいるとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI時代、GPUのオルタナティブ──AMDは今どこを見据えているのか</title>
      <link>https://ledge.ai/articles/interview_amd</link>
      <description><![CDATA[<p>生成AIの急速な台頭は、コンピューティング需要の爆発的な増加を引き起こし、AIアクセラレーター市場はかつてない活況を呈している。この巨大な波を捉え、NVIDIAは市場において圧倒的な支配的地位を確立した。しかし、その一強体制は、AIインフラを支える企業にとってサプライチェーンの硬直化という新たなリスクを生み出している。
　この状況下で、エコシステムの健全性を保ち、技術革新を継続させるためには、サプライチェーンの多様化と強力な代替選択肢の確保が不可欠となっている。多くの企業が、NVIDIAへの依存を軽減し、よりオープンで柔軟なAI基盤を模索し始めているのだ。
　この文脈において、半導体大手のAMDはどのような戦略的ポジションを築こうとしているのか。本稿では、AMDの担当者への独占インタビューに基づき、ハードウェアとソフトウェアの両輪でNVIDIAの牙城に挑む同社の戦略、そしてAIの未来に対する深い洞察の核心に迫る。</p>
<p>※インタビューは2025年11月20日に丸の内の日本エイ・エム・ディ株式会社で行われた。</p>
<h2>1. 巨大需要の象徴：OpenAIとの「600万世帯分の電力」の提携が示すもの</h2>
<p>生成AIが必要とする計算資源のスケールは、従来の常識を遥かに超えている。このセクションでは、AMDがOpenAIと結んだ大規模なパートナーシップを切り口に、AIインフラが直面する課題の大きさと、その需要に応える主要プレイヤーとしてAMDが名乗りを上げた戦略的重要性を解き明かす。</p>
<p>Q: まず、先般発表されたOpenAIとの大規模なパートナーシップの背景についてお聞かせいただけますか？</p>
<p>A: この提携の根底には、OpenAIが直面していた「電源不足」と「コンピュート（チップ）不足」という二つの深刻なボトルネックがあります。その結果、彼らは単一のソースに依存するリスクを回避するため、代替サプライヤーを見つけ出すという社内的なミッションを掲げていました。私たちの長年にわたる実績と技術力が評価され、この歴史的なパートナーシップへと繋がりました。</p>
<p><strong>Q: 「6GW（ギガワット）」という規模は、読者には少しイメージしづらいかもしれません。これはどれほどの規模なのでしょうか？</strong>
A: 6GWというと600万世帯に相当する電力規模です。それは東京23区の世帯数(520万世帯)を上回る規模感であることを示しています。一般的なデータセンターが数十メガワット、大規模なものでも100メガワットを超える程度であることを考えると、6GW（=6,000メガワット）がいかに桁違いの規模であるかお分かりいただけるでしょう。これは、単一の契約としては前例のない、AIが要求するエネルギーの巨大さを示す象徴的な数字です。</p>
<p><strong>Q: この6GW分のチップは、数年間にわたって最新のものが提供されていくという理解でよろしいでしょうか？</strong>
A: はい。導入は来年から開始される予定です。重要なのは、この契約が特定のチップモデルに縛られるものではないという点です。私たちは、その時々で最も高性能な最新の製品を柔軟に導入していく計画であり、パートナーの進化に合わせて最高のソリューションを提供し続けます。</p>
<p>このOpenAIとの大規模提携は、世界のAIインフラの根幹を支えるティア1サプライヤーであることを市場に証明した。この地位を確立するために、AMDはどのような戦略を描いているのか。その答えは、ハードウェアとソフトウェアの両面からなる緻密なアプローチの中に隠されている。</p>
<h2>2. ハードウェアとソフトウェアの両輪戦略</h2>
<p>NVIDIAが築き上げた牙城を崩すためには、高性能なハードウェアを提供するだけでは不十分だ。開発者がストレスなく、かつ容易にその性能を最大限に引き出せるソフトウェアエコシステムの構築こそが、真の挑戦者となるための鍵を握る。これは、AMDが真正面から向き合う戦略的課題である。
本セクションでは、AMDが推進するハードウェアとソフトウェアという2つの核心戦略を深掘りし、同社がいかにしてAI時代の新たなスタンダードを築こうとしているのかを明らかにする。</p>
<h3>2.1 ハードウェア戦略：電力効率とポートフォリオの広さで差別化</h3>
<p>AI時代のインフラにおける最大のボトルネックは、計算能力そのものから「電力」へと移行しつつある。この変化を的確に捉え、AMDはハードウェア戦略の最重要指標として「パフォーマンス・パー・ワット（電力性能比）」を掲げている。</p>
<p><strong>Q: 半導体の微細化（例えば2nmプロセス）は、チップ性能にどのような影響を与えるのでしょうか？</strong>
A: プロセス技術の進化は、主に2つの重要な利点をもたらします。第一に、決まったチップ面積により多くの計算ユニットを詰め込めるようになり、性能が直接的に向上します。第二に、そして電力が制約となる現代においてますます重要になっているのが、「パフォーマンス・パー・ワット」の改善です。新しいプロセス技術を活用することで、同じ消費電力でより多くの計算が可能なチップを設計できます。この効率性への注力こそが、今や私たちの設計思想の中心的な柱となっています。</p>
<p>AMDのハードウェア戦略のもう一つの柱は、その広範な製品ポートフォリオにある。同社はCPU、GPUに加え、Pensandoの買収によるネットワークカード、Xilinxの買収によるFPGAといった、データセンターからエッジ、そしてPCまでを網羅する製品群を持つ。
　これにより、AMDはAIのワークロードに対してエンドツーエンドで最適化されたソリューションを提供できる、市場で唯一無二のポジションを確立している。個別の部品を提供するだけでなく、システム全体として最高のパフォーマンスを発揮させる設計思想が、同社の大きな強みだ。
　しかし、どれほど優れたハードウェアも、それを活かすソフトウェアがなければ宝の持ち腐れとなる。AMDの挑戦の成否は、ソフトウェア戦略の巧拙にかかっていると言っても過言ではない。</p>
<h3>2.2 ソフトウェア戦略：「オープン」を武器にCUDAエコシステムに挑む</h3>
<p>NVIDIAの最大の強みは、10年以上にわたって築き上げてきたソフトウェア開発環境「CUDA」である。このデファクトスタンダードの牙城をいかに切り崩すか。AMDがその武器として選んだのは、「オープンなエコシステム」という戦略だ。
<strong>Q: NVIDIAのCUDAがデファクトスタンダードとなっている中で、AMDはソフトウェア面でどのように対抗していくのでしょうか？</strong>
A: 私たちの課題がソフトウェアにあることは率直に認めています。そこでAMDが取っているアプローチは、開発者にAMDへ移行する「負担」をかけない事です。研究開発のスピードが最も重要視されるAI開発者にとってコード変更の負担はPerf/TCOのメリットを直ぐにかき消してしまいます。そこで最初に取り掛かったのはPyTorchのような主要なAIフレームワークのレベルでサポートを徹底することです。これにより、開発者は「コードチェンジなし」で既存のAIモデルをAMDのGPU上で動かすことができ、非常に魅力的な利点と言う声を頂いております。</p>
<p><strong>Q: 具体的な成果として、どのようなものがありますか？</strong>
A: おかげさまで、AIモデルの巨大なリポジトリであるHugging Face上のほぼ全てのモデルをサポートするに至りました。さらに、MetaのLlama 3・4のような主要モデルがリリースされたその日からAMDハードウェアで動作する「Day-0サポート」も実現しています。これにより、私たちはエコシステムの中で着実に信頼性を高めています。</p>
<p><strong>Q: ソフトウェアスタック「ROCm」がオープンソースであることの利点は何ですか？</strong>
A: ROCmは、その中身がすべてオープンソースライセンスで構成されています。これにより、エンドユーザーはライセンスの透明性を確認でき、大きな安心感を得られます。但し、製品としてはAMDが責任を持って提供しているので信頼性やサポートは他社製品と比べても衰えていません。また、何か問題があればコミュニティと共に改善していくことが可能であり、このオープン性こそが私たちのエコシステムを共に成長させる原動力となっています。</p>
<p>AMDのソフトウェア戦略は、意図的な道のりを辿って進化している。第一のステップは、開発者のための「コードチェンジ不要」な体験を保証するため、フレームワークレベルでの互換性を達成することだった。そして今、同社は次なる、より高度なステップへと駒を進めている。それはオペレーション層への対応だ。最近発表された「AI Enterprise Suite」は、Kubernetesベースのコンテナ管理、GPUモニタリング、推論マイクロサービスといった、企業が実験段階から本番運用へと移行するためにまさに必要とするツール群を提供する。このエンタープライズグレードの運用への注力は、ハイパースケーラーの先にある市場をいかにして獲得していくかという、同社の戦略を明確に示している。</p>
<h2>3. ビッグテックの先へ　ーエンタープライズAIの民主化を支える</h2>
<p>OpenAIのような巨大テック企業との取引はメディアの注目を集めるが、AMDの長期的な成功は、より幅広い一般企業によるAI活用、すなわち「AIの民主化」をいかに支えるかにかかっている。同社は、AI導入のハードルを下げ、誰もがその恩恵を受けられる未来を目指している。</p>
<p><strong>Q: NVIDIAはロボティクスなど特定領域のAIモデル開発にも注力していますが、AMDも同様の取り組みをされるのでしょうか？</strong>
A: 私たちの基本方針は、お客様と競合するようなAIモデルを自社開発するのではなく、パートナーシップを重視することです。Silo AIやNod.ai、Mipsologyといったソフトウェア企業を買収する目的も、特定のモデルを開発するためではありません。それは、我々の汎用的なソフトウェアスタックを強化するための人材と技術を積極的に獲得するためです。例えば、Silo AIのチームは、当社のGPUが採用されている欧州のスーパーコンピュータ向けにソフトウェアを最適化してきた深い専門知識を持っていました。その知見は今、全ての顧客に利益をもたらすべく統合されており、パートナーのための最高の基盤を構築するという我々のコミットメントを補強しています。</p>
<p><strong>Q: 幅広い企業がAIを導入する上で、AMDはどのような価値を提供できると考えていますか？</strong>
A: 移行性の簡易化の次のステップとしては「AI Enterprise Suite」のような製品を通じて、Kubernetesベースのコンテナ管理やGPUモニタリングなど、企業がAIを本格的に運用しやすくなるためのツールを提供しています。また、オープンソースモデルをAPI形式で手軽に利用できる環境を整えることで、専門知識が限られる企業でもAI導入の第一歩を踏み出せるよう、そのハードルを大きく引き下げています。</p>
<p>このプラットフォーム中心のビジョンは、独立した戦略ではない。それは、同社の中核をなす「オープン」なソフトウェア哲学の論理的な延長線上にある。アプリケーション層で顧客と競合することを避け、代わりにオープンで堅牢な基盤（ROCm、AI Enterprise Suite）を提供することで、AMDはエンタープライズAIエコシステム全体にとって不可欠かつ中立的な土台となることを目指している。これは、特定の垂直市場向けにプロプライエタリなモデルを構築する競合他社とは対照的なアプローチだ。</p>
<h2>4. AIの未来予測　「バブルではない」と発言する理由と未開の可能性</h2>
<p>現在のAIブームを、いずれ弾ける「バブル」と見る向きもある。しかしAMDは、現在の熱狂は、これから訪れる本当の変革の序章に過ぎないと捉えている。このセクションでは、同社がAIの未来に確信を抱く理由と、その未開の可能性についての洞察を深掘りする。</p>
<p><strong>Q: 現在のAIブームは、いずれ弾けるバブルなのでしょうか。それとも持続的な成長が見込まれるのでしょうか？</strong>
A: 正直なところ、私たちは「あまりバブルとは思っていません」。なぜなら、AIが持つ本来のポテンシャルと、現在のアプリケーションで実現できていることの間には、まだまだ非常に大きなギャップがあると感じているからです。</p>
<p><strong>Q: AIのポテンシャルは、現時点で何パーセントくらい実現されていると感覚的に思いますか？</strong>
A: あくまで感覚的な話ですが、「本当に低いと思います。10%とかそんな程度」ではないでしょうか。これは裏を返せば、まだ90%もの未開拓な市場と可能性が残されていることを意味します。</p>
<p><strong>Q: 今後、AIはどのように社会に浸透していくとお考えですか？</strong>
A: その影響は二つの側面から現れるでしょう。一方で、医療や法律といった分野で、AIが記録調査のようなタスクにかかる時間を劇的に削減し、着実かつ深遠な効率化が進みます。他方で、最初のスマートフォンが登場した時に誰もインフルエンサー経済を予測できなかったように、今日では想像もつかない全く新しいユースケースや産業が生まれるはずです。この予測可能な最適化と、予測不可能なイノベーションという二重のポテンシャルこそが、未来の市場をこれほど広大なものにしているのです。</p>
<p>AMDが目指しているのは、短期的な流行に乗ることではない。予測不可能な未来のアプリケーションまでをも支えることができる、柔軟で強力なAI基盤を構築することだ。こうした未来を見据えるAMD自身の現在地、そして市場に伝えたいメッセージとは何か。</p>
<h2>5. AI本格参入から2年、生まれ変わったAMDの現在地</h2>
<p>AMDがデータセンター向けAIアクセラレーター「MI300」を市場に投入し、本格的にこの分野に参入してから、まだ2年余りしか経過していない。この事実は、多くの人々にとって驚きかもしれない。この極めて短い期間で、同社は驚異的な変貌を遂げ、市場における存在感を確固たるものにした。</p>
<p><strong>Q: 最後に、市場や開発者に対して最も伝えたいメッセージは何でしょうか？</strong>
A: ぜひ伝えたいのは、「5年前にAMDのGPUを試して『まだ熟成感が足りない』と感じた人にこそ、『いやいや、当時とは全く変わりました。是非もう一度見てください』」ということです。私たちはこの2年で、ハードウェアもソフトウェアも劇的に進化しましたし
複数の最先端のAI機関で導入実績を実現しています。過去のイメージではなく、現在の私たちの実力を正当に評価していただきたいと切に願っています。</p>
<p>本稿で明らかになったAMDの戦略は、以下の3つの要点に集約される。</p>
<ul>
<li><strong>巨大な需要への対応力：</strong>  OpenAIとの提携に象徴される、ハイパースケールAIインフラを担う能力。</li>
<li><strong>オープンなソフトウェアエコシステム：</strong>  CUDAへの挑戦として、コード変更不要な利用環境とオープンソース戦略で開発者の支持を獲得するアプローチ。</li>
<li><strong>真に包括的なプラットフォーム：</strong>  EPYC CPUやInstinct GPUから、Pensandoネットワークカード、Xilinx FPGAによるエッジコンピューティングまで、データセンターのスタック全体を提供・最適化できる唯一無二のポジション。競合他社には真似のできないレベルのシステム統合を実現する。</li>
</ul>
<p>結論として、AMDはもはや単なるNVIDIAの「代替」ではない。同社は、オープンなエコシステムと包括的なポートフォリオを武器に、AI時代の新たなスタンダードを築こうとする強力な「挑戦者」として、今、まさにその真価を発揮し始めている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>イラン抗議デモ巡りAI生成動画が拡散　ネット遮断による情報空白で、真偽判定が困難に</title>
      <link>https://ledge.ai/articles/iran_protests_ai_generated_videos_internet_blackout_verification_difficulty</link>
      <description><![CDATA[<p>反政府デモが続くイランをめぐり、交流サイト（SNS）上で拡散する動画や画像の中に、生成AIで作られたとみられるものが含まれていることが分かった。報道評価団体のNewsGuardは2026年1月15日、抗議デモを描写するとされる動画のうち、複数本についてAI生成の可能性が高いと確認したと<a href="https://www.newsguardrealitycheck.com/p/ai-videos-fill-void-amid-iran-internet-blackout">発表</a>した。</p>
<h2>NewsGuard、抗議デモを装ったAI生成動画を確認</h2>
<p>NewsGuardによると、問題の動画は、イラン各地での抗議活動を示すかのような説明とともにSNSで拡散していた。しかし、映像表現の不自然さや出所の不明確さなどから、生成AIによって作られた可能性が高いと分析したという。こうした動画が真偽不明のまま流通することで、実際の情勢把握を誤らせるおそれがあるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/newguard_x_b08d505466/newguard_x_b08d505466.jpg" alt="newguard x.jpg" /></p>
<h2>通信遮断が生んだ「情報空白」</h2>
<p>AI生成とみられる動画が広がる背景には、イラン国内で続く大規模なインターネット遮断がある。インターネットインフラ企業の<a href="https://blog.cloudflare.com/iran-protests-internet-shutdown/">Cloudflare</a>は、同社の観測データとして、1月上旬にイランのインターネットトラフィックが急減し、事実上ゼロに近い状態となった時間帯があったと説明している。遮断により、現地からリアルタイムで発信される映像や証言は大幅に減少した。</p>
<p>人権団体の<a href="https://www.accessnow.org/press-release/keepiton-iran-digital-darkness-human-rights-abuses/">Access Now</a>も、通信遮断が続くことで、市民の情報アクセスが制限されるだけでなく、現地で起きている出来事の検証や外部からの監視が困難になると警告している。独立した裏付けが得られにくい状況では、SNS上に流通する情報の信頼性を判断すること自体が難しくなる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/accessnow_16f3d64d1b/accessnow_16f3d64d1b.jpg" alt="accessnow.jpg" /></p>
<h2>情報不足の中で高まる真偽判定の難しさ</h2>
<p>通信遮断によって現地発の情報が乏しくなる中、抗議デモに関する映像や画像は、限られた手掛かりで評価せざるを得ない状況に置かれている。こうした環境の下で、NewsGuardは、抗議デモ関連として拡散する動画の中に、AI生成とみられるものが複数含まれていることを確認した。</p>
<p>生成AIの進化により、映像の見た目だけで真偽を見極めることは専門家にとっても容易ではない。通常は撮影場所の特定や別角度映像との照合、投稿の時系列分析などが検証の手掛かりとなるが、現地からの情報発信が制限されている状況では、そうした確認手段が限られる。NewsGuardは、イラン情勢をめぐる映像や画像について、出所や裏付けを慎重に見極める必要があるとして注意を促している。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本・ASEAN、「信頼できるAI」推進で共同声明──デジタル大臣会合で協力深化</title>
      <link>https://ledge.ai/articles/japan_asean_trustworthy_ai_joint_statement_2026</link>
      <description><![CDATA[<p>総務省は2026年1月15日、日本とASEAN（東南アジア諸国連合）が、安全・安心で信頼できるAIの推進に向けた共同声明を採択したことを<a href="https://www.soumu.go.jp/menu_news/s-news/01tsushin09_02000190.html">発表</a>した。ベトナムで開催された第5回 日ASEANデジタル大臣会合で合意したもので、日本とASEANがAI分野に関する大臣共同声明を発出するのは初めてとなる。</p>
<p>会合ではあわせて、今後1年間の協力方針をまとめた「日ASEANデジタルワークプラン2026」も承認された。</p>
<h2>日ASEANデジタル大臣会合で共同声明を採択</h2>
<p>ベトナムで開催された日ASEANデジタル大臣会合には、日本から総務大臣である林芳正氏が出席した。会合は、日本とASEAN各国のICT所管大臣が一堂に会し、デジタル分野における協力方針を決定する唯一の閣僚級会合と位置づけられている。</p>
<p>今回の会合では、ホスト国であるベトナムの閣僚とともに林総務大臣が共同議長を務め、
日ASEANデジタルワークプラン2026
安全、安心で、信頼できるAIの推進に関する日ASEANデジタル大臣共同声明</p>
<p>の2つが正式に承認・採択された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/asean_japan_statement_7be3e05969/asean_japan_statement_7be3e05969.jpg" alt="asean japan statement.jpg" /></p>
<h2>「信頼できるAI」を軸に協力を深化</h2>
<p>採択された共同声明は、AIの開発・導入・利用の各段階において、安全性・信頼性・安心感を確保することを基本方針としている。日ASEAN間でAI協力を深化させることで、各国のAIエコシステムの発展とともに、グローバルなAIエコシステムの構築に貢献する考えを示した。</p>
<p>AIをめぐっては国際的な開発競争が激化する一方、安全性やガバナンスをどう確保するかが共通課題となっている。今回の声明は、そうした状況を踏まえ、日ASEANが協調して取り組む姿勢を明確にしたものといえる。</p>
<h2>ガバナンスから人材育成まで、声明が示した協力分野</h2>
<p>共同声明では、信頼できるAIの推進に向け、幅広い協力分野が整理された。</p>
<p>ガバナンス面では、広島AIプロセスの国際行動規範を踏まえ、AIシステムの安全性・セキュリティ・信頼性の強化を進めるとした。各国の制度整備に向けた協力や、ガバナンスの相互運用性を高めるための連携も盛り込まれている。</p>
<p>開発・インフラ分野では、各国の文化や価値観、言語を尊重したAIモデルの開発協力や、AI関連インフラ整備での連携を明記した。また、ASEANにおけるAI安全性ベンチマークや評価手法の取組を担うWG-AI（AIガバナンス作業部会）との連携強化、ASEAN AI安全ネットワークに関する協力も掲げられている。</p>
<p>人材育成・能力構築では、AI分野の能力構築や技術移転、若手AI開発者の育成に向けた協力を通じ、各国におけるローカルなAIエコシステムの構築と発展に貢献するとした。</p>
<p>さらに、AIソリューションの共創として、各国のAI活用事例を共有し、社会課題の解決に資するAIの利活用を進める方針を示した。プライバシーやデータガバナンス、知的財産の尊重、偽情報や情報操作への対応など、包摂的で信頼できるAIの推進も盛り込まれている。</p>
<h2>ワークプラン2026で示された具体的な協力施策</h2>
<p>日ASEANデジタルワークプラン2026は、今後1年間の協力・連携施策を整理したものだ。AI分野では、各国における大規模言語モデル（LLM）の開発や人材育成に関する協力、ASEANのAIエコシステム構築に向けた取組が位置づけられている。</p>
<p>このほか、サイバーセキュリティ分野における能力構築支援の拡充や、オープンRANの普及促進を通じたデジタルインフラ整備など、AI以外の分野についても協力を進める方針が示された。</p>
<h2>日本とASEAN、AI協力を実装フェーズへ</h2>
<p>今回の共同声明とワークプランの承認により、日ASEANのAI協力は理念共有の段階から、具体的な取組を進める実装フェーズへと移行することになる。各国の状況やAIエコシステムを尊重しつつ、地域全体として安全・安心で信頼できるAIの活用を広げていく。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、VR会議アプリ「Horizon Workrooms」単体提供を終了へ──2月16日でアクセス不可、データも削除</title>
      <link>https://ledge.ai/articles/meta_horizon_workrooms_app_shutdown</link>
      <description><![CDATA[<p>Metaは2026年1月15日（現地時間）、VR空間で会議や共同作業を行うアプリ「Horizon Workrooms」の単体アプリ提供を2026年2月16日に終了すると<a href="https://www.meta.com/ja-jp/help/quest/2464765133873078/?srsltid=AfmBOoof-fgoukgk7PEJ39f6sAbryo5HndubzMFmP_hOoN3arFgysT7w">発表</a>した。終了日以降、同アプリにはアクセスできなくなり、Workroomsに関連するデータは削除される。</p>
<p>Horizon Workroomsは、Meta QuestシリーズなどのVRデバイスを用いて、アバター同士が仮想空間に集まり、会議やホワイトボードでの共同作業、PC画面の共有などを行えるサービスとして提供されてきた。企業やチーム向けのVRコラボレーションツールとして、実験的な位置づけを含みつつ展開されていた。</p>
<p>Metaの公式サポート文書によると、今回終了するのはあくまでWorkroomsの単体アプリであり、2月16日をもって利用はできなくなる。あわせて、Workroomsに紐づくデータについても、同日以降は削除されるとしている。</p>
<p>一方で、MetaはVR環境におけるすべての業務関連機能を廃止するわけではない。公式の案内では、PC画面をVR空間に表示するMeta Quest Remote Desktopについては、引き続き利用可能であることが示されている。</p>
<p>公式ページでは、Horizon WorkroomsがMeta Horizonのエコシステムの中で果たしてきた役割に言及したうえで、今後はより広いプラットフォームの枠組みの中で、生産性やコラボレーション機能を提供していく方針が示唆されている。今回の終了は、VR会議機能そのものの否定ではなく、提供形態を整理・統合する動きの一環と位置づけられる。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、年換算売上高200億ドル（約3.1兆円）超を公表──計算資源を拡大し「知能の価値」に連動する事業へ</title>
      <link>https://ledge.ai/articles/openai_annualized_revenue_20b_compute_scales_with_intelligence_value</link>
      <description><![CDATA[<p>OpenAIは米国時間2026年1月18日、最高財務責任者（CFO）のSarah Friar氏による<a href="https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/">公式ブログ投稿</a>で、同社の年換算売上高（直近の収益ペースを年ベースに換算した指標）が200億ドル（約3.1兆円）を超える規模に達していることを明らかにした。AIの利用拡大によって生み出される「インテリジェンス（知能）の価値」に応じて事業規模が拡張していると説明し、需要の伸びに合わせて計算資源への投資を継続的に拡大しているとした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_bisomess_that_scales_with_the_value_of_intelligence_596d5afa2e/a_bisomess_that_scales_with_the_value_of_intelligence_596d5afa2e.jpg" alt="a bisomess that scales with the value of intelligence.jpg" /></p>
<h2>研究プレビューから日常インフラへ</h2>
<p>OpenAIは、ChatGPTを研究プレビューとして公開した当初、最先端の知能を人々の手に直接届けた場合に何が起きるかを探る目的だったと振り返る。その後、想定を超える規模で利用が広がり、学生の学習支援や家庭での計画立案、創作活動、健康に関する情報整理など、日常生活に深く組み込まれるようになったという。</p>
<p>こうした利用はやがて仕事の現場にも広がり、文章作成やデータ整理、コードレビュー、意思決定の補助など、日々の業務プロセスの一部として定着した。OpenAIは、好奇心を満たすためのツールだったChatGPTが、創造性や生産性、意思決定を支える「インフラ」へと変化したと位置付けている。</p>
<h2>「知能の価値」に応じて拡張するビジネスモデル</h2>
<p>同社はこの変化を受け、事業モデルも「知能が生み出す価値に比例して拡張する」ことを原則に設計してきたと説明する。個人向けにはサブスクリプションを導入し、職場やチーム向けには業務利用に対応したプランや従量課金を追加。さらに、開発者や企業がAPIを通じてAIを組み込めるプラットフォーム事業を展開し、成果に応じて利用が拡大する構造を整えてきた。</p>
<p>近年は、購買や行動の意思決定を支援する用途にもAIの活用が広がっており、広告やコマース分野にも同じ原則を適用しているという。OpenAIは、収益化は体験に自然に溶け込み、利用者に価値をもたらすものでなければならないとしている。</p>
<h2>計算資源と収益が同じカーブで拡大</h2>
<p>公開された図表では、計算資源と収益がほぼ同じペースで拡大してきたことが示された。計算資源は2023年の0.2ギガワット（GW）から2024年に0.6GW、2025年には約1.9GWへと拡大し、年率で約3倍の成長を遂げた。一方、年換算売上高も2023年の20億ドル、2024年の60億ドルを経て、2025年には200億ドル超に達したとしている。</p>
<p><strong>■ OpenAIが示した計算資源（左）と年換算売上高（右）の推移。計算資源の拡大に合わせて、収益規模も同様のカーブで成長していることが示されている</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/a_business_that_scales_with_the_value_of_intelligence_9dd9df2933/a_business_that_scales_with_the_value_of_intelligence_9dd9df2933.jpg" alt="a-business-that-scales-with-the-value-of-intelligence.jpg" /></p>
<p>OpenAIは、計算資源が顧客への提供能力を直接左右する最も希少なリソースだとし、複数のプロバイダーと連携する分散型の体制を構築することで、計画的かつ安定的に能力を拡張できるようになったと説明している。計算資源を固定的な制約ではなく、能動的に管理するポートフォリオとして運用することで、効率性と拡張性の両立を図っているという。</p>
<h2>実用化を重視する2026年</h2>
<p>OpenAIは2026年の重点として「practical adoption（実用的な採用）」を掲げた。AIが可能にする高度な機能と、実際の現場で使われている状況との間にあるギャップを埋めることが重要だとし、特に医療、科学、企業分野での活用が大きな機会になると指摘している。</p>
<p>インフラへの投資が提供可能な能力を広げ、研究と製品開発が知能の可能性を押し広げ、採用の拡大が利用者を増やす。その結果として得られる収益が、次の投資を支える――OpenAIは、この循環こそが知能を社会の基盤へと成長させる原動力になるとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTの“待ち時間”短縮へ──OpenAIがCerebrasと提携、リアルタイム推論を強化</title>
      <link>https://ledge.ai/articles/openai_cerebras_low_latency_inference_partnership</link>
      <description><![CDATA[<p>OpenAIは2026年1月14日（現地時間）、AIチップ企業のCerebrasと提携し、同社の低レイテンシ推論基盤を自社のAI推論スタックに統合すると<a href="https://openai.com/index/cerebras-partnership/">発表</a>した。巨大な単一チップ上に計算・メモリ・帯域を集約するCerebrasのシステムを活用し、長文出力やコード生成、AIエージェント実行といった処理の応答速度を高める。計算能力は段階的に投入され、複数年にわたって拡張される見通しだ。</p>
<p>今回の取り組みは、OpenAIが進める推論基盤の多層化の一環と位置づけられる。OpenAIによると、AIの利用体験は「質問を送り、モデルが推論し、応答が返る」というループで構成されており、この応答がリアルタイムに近づくほど、ユーザーの利用時間や実行される処理の価値が高まるという。Cerebrasの低遅延システムは、こうした体験を支えるための専用基盤として導入される。</p>
<h2>低レイテンシ推論を段階的に統合、対応ワークロードを拡大</h2>
<p>OpenAIはまず、リアルタイム性が特に重要なワークロードからCerebrasの推論キャパシティを組み込み、その後、対象を広げていく計画だ。導入は複数のフェーズに分けて行われ、計算資源は2028年まで段階的にオンライン化される。</p>
<p>提携の規模について両社は具体的な金額を明らかにしていないが、海外メディアでは、この協業が数年にわたる大規模契約になる可能性があると報じられている。<a href="https://www.reuters.com/technology/openai-buy-compute-capacity-startup-cerebras-around-10-billion-wsj-reports-2026-01-14/">Reuters</a>は関係者の話として、契約規模が約1.5兆円相当になると伝えており、OpenAIが推論インフラの強化に相当な投資を行っていることを示唆する内容となっている。</p>
<h2>巨大単一チップで推論のボトルネックを回避</h2>
<p>Cerebrasのシステムの特徴は、計算資源、メモリ、通信帯域を単一の巨大チップに集約している点にある。従来のGPUクラスタ構成では、推論時にノード間通信がボトルネックとなりやすいが、Cerebrasはこうした制約を構造的に回避できるとする。特に、長いテキスト出力や複雑な推論を伴う処理で効果を発揮するという。</p>
<p>Cerebrasは、OpenAI向けにこのwafer-scaleシステムを大規模に展開し、低レイテンシ推論を前提としたAI体験を支える基盤として提供する方針だ。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ロボット開発の“データ不足”をどう埋める？Pantographが数千台規模の「幼稚園」構想を提示</title>
      <link>https://ledge.ai/articles/pantograph_robot_preschool_data_collection</link>
      <description><![CDATA[<p>米ロボティクス企業のPantographは2026年1月、ロボット開発における深刻な「データ不足」の課題に対する新たなアプローチとして、「ロボットのための幼稚園（preschool for robots）」と名付けた構想を公式<a href="https://pantograph.com/blog/building-a-preschool-for-robots.html">ブログ</a>で明らかにした。探索・失敗・継続的な改善を通じて、ロボット自身が現実世界で学習データを収集する環境を構築するという。</p>
<h2>実世界のデータが不足するロボティクス領域</h2>
<p>Pantographによると、近年急速に進歩した深層学習分野の多くは、言語モデルや画像生成のように、インターネット規模の豊富なデータを利用できた領域に集中している。一方、ロボティクスでは同等の大規模データセットが存在せず、学習に必要なデータを一から作り出す必要があるという。</p>
<p>特に、動画だけでは推定が難しい素材の物性――質感、粘性、密度、曲げたときの感触、物同士を擦り合わせた際の挙動など――は、実際に触れて試すことでしか得られない情報だと説明している。</p>
<h2>「ロボットの幼稚園」で探索をスケール</h2>
<p>同社が提示した解決策が、「ロボットのための幼稚園」構想だ。初期フェーズでは、数千台規模の小型で低コストなロボットを用意し、実世界で自由に探索させる。ロボットは物を掴む、投げる、擦る、積み上げるといった行動を繰り返しながら、周囲の環境についての内部表現を徐々に構築していく。</p>
<p>Pantographは、このように多様で大規模な実世界データを蓄積することで、未知のタスクにも対応できる汎用的なモデルの学習につなげる狙いだとしている。また、ロボットは外界だけでなく、自身のハードウェア特性や癖についても学習し、人が操作するよりもロボット自身に適した制御モデルを獲得できるとする。</p>
<h2>幼稚園フェーズに最適化した小型ロボット</h2>
<p>構想とあわせて、同社は「ロボットの幼稚園」を前提に設計した自社ハードウェアの早期プレビューも公開した。小型で低重心の設計とすることで、製造コストを抑え、量産や交換を容易にするほか、学習初期の失敗による破損リスクを低減する狙いがある。</p>
<p>実世界での探索では耐久性が重要になるとして、Pantographはハードウェアを自社設計し、部品レベルでの検証を重ねてきたという。これまでに、重要部品について1万時間を超える社内のストレス試験・耐久試験データを蓄積しているとしている。</p>
<p>移動機構には車輪ではなくクローラ（履帯）を採用し、安定性や走破性、モーター効率を重視した。製造面では、打ち抜き加工やレーザーカット、板金曲げといった2次元加工を活用する「オリガミ」的設計により、材料効率と量産性を高めている。</p>
<h2>強度・器用さ・工具使用のデモを公開</h2>
<p>公開されたデモでは、小型ながらも一定の強度と操作性を備える点が示された。ロボットのアームは、伸ばした状態でそれぞれ約1キログラムの連続ペイロードに対応し、より重い物体を動かす例も紹介されている。</p>
<p>また、結束バンドの接続やUSBケーブルの挿入、木製ブロックを用いた構造物の組み立てといった細かな操作や、ハサミや電動ドライバー、ラベルライターなど、人間向けに設計された工具を扱う様子も示された。これらのデモデータは、シンプルなテレオペレーション環境を用いて収集されたものだとしている。</p>
<p><strong>■ シンプルな遠隔操作のセットアップ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/teleop_image_2156096eb1/teleop_image_2156096eb1.jpeg" alt="teleop_image.jpeg" /></p>
<h2>数千台規模への拡大と未踏の研究課題</h2>
<p>Pantographは今後、数カ月以内にロボットの台数を数千台規模へと拡大し、信頼性や製造性、能力の向上に向けた反復的な改良を進める計画だ。あわせて、ロボットを継続的に稼働させながらデータ収集を行う体制を構築するとしている。</p>
<p>研究面では、どのようなタスク分布が適切か、事前学習をどう組み込むか、学習したモデルをどのように制御・誘導するかなど、多くの未解決課題が残されているとし、これらはまだ大規模に検証されたことのない領域だと位置付けている。</p>
<p>同社は、こうした取り組みを通じて、人間の作業能力や創造性を拡張する汎用ロボットの実現を目指すとしており、現在エンジニアや研究者の採用も進めている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>SuperQ、（暫定）世界初の量子コンピューティングを活用した消費者向けアプリ「ChatQLM」公開──量子技術にも「ChatGPTモーメント」を！</title>
      <link>https://ledge.ai/articles/quantum_chatgpt_moment_superq_chatqlm_ces2026</link>
      <description><![CDATA[<p>カナダの量子技術企業 SuperQ Quantum Computing Inc. は2025年12月23日（現地時間）、量子コンピューティングを活用した消費者向けアプリ「ChatQLM」を<a href="https://www.superq.co/news/superq-to-launch-chatqlm-at-ces-2026">発表</a>した。同社は同アプリを CES 2026（2026年1月6〜9日、米ラスベガス）で公式ローンチすると明らかにしていた。</p>
<p>続く2026年1月13日付の<a href="https://www.superq.co/news/debuts-worlds-first-quantum-powered-consumer-app-chatqlm-">発表</a>では、CES 2026での展示・デモを経て、ChatQLMを「世界初の量子コンピューティングを活用した消費者向けアプリ」として正式に発表した。同社によると、ChatQLMはモバイルおよびWebアプリとして提供され、Web、Google Play、Apple App Storeで同時に利用可能となる。</p>
<p>ChatQLMは生成AIと量子最適化を橋渡しする消費者向けアプリとして設計されたと同社はいう。従来の大規模言語モデル（LLM）が得意とする会話や文章生成に加え、数理的な最適化や意思決定支援を組み合わせることで、専門家や大規模組織に限られていた高度な計算資源を一般ユーザーにも開放することを狙う。</p>
<p>同社はこの取り組みを <strong>「The ChatGPT Moment for Quantum（量子技術のChatGPTモーメント）」</strong> と表現している。これは、生成AIが対話型インターフェースを通じて専門領域から一般ユーザーへと急速に普及した転換点になぞらえたもので、量子技術においても、専門知識を前提としない形で実用的な問題解決に触れられる段階に入ることを意味すると説明している。</p>
<p>ChatQLMの中核には、同社独自の「Quantum Leveraged Model（QLM）」が採用されている。自然言語で入力された課題を解析し、最適化ソルバー、量子アニーリング方式の量子計算機、ゲート型量子コンピュータ、あるいはNVIDIAベースの古典的スーパーコンピューティングクラスタなど、最適な計算基盤へ自動的にルーティングする仕組みだ。ユーザーは量子物理やプログラミングの専門知識を必要とせず、結果としてデータに基づく意思決定や可視化された最適化結果を得られるとしている。</p>
<p>同社はChatQLMを「世界初の量子搭載コンシューマーアプリ」とうたっているが、現時点で第三者機関による公式な認定については言及していない。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Romiに2年に一度の健康診断──MIXI、会話AIロボットを長期にわたって安心して使える公式アフターケア開始</title>
      <link>https://ledge.ai/articles/romi_2year_health_check_mixi_official_aftercare_launch</link>
      <description><![CDATA[<p>MIXIは2026年1月14日、会話AIロボット「Romi（Lacatanモデル）」に対応した公式アフターケアサービス「Romiクリニック」の提供を開始したことを<a href="https://mixi.co.jp/news/2026/0114/47942/">発表</a>した。</p>
<p>修理や外装交換、定期的な状態確認などを公式に担うことで、Romiを長期にわたって安心して使える体制を整える。</p>
<p>Romiクリニックは、Romi本体を預かり、メーカー公式として点検・修理を行うアフターケアサービスだ。人の健康診断になぞらえた「2年に一度の健康診断」メニューを含め、ハードウェアの状態確認や不具合対応を通じて、日常的に使われる会話AIロボットの継続利用を支える。</p>
<p><strong>■ Romiクリニックで提供される「健康診断」のイメージ。各センサーや外装の状態を公式基準で確認する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_1024x334_15185863ff/1_1024x334_15185863ff.webp" alt="1-1024x334.webp" /></p>
<p>提供される主なサービスには、本体の不具合修理や外装（シェル）の交換、動作や状態を総合的に確認する健康診断などが含まれる。これらは、公式基準に基づいて実施され、詳細な内容や条件は専用の案内ページで示されている。</p>
<p>MIXIはあわせて、Romi専用のアフターケア対応ラボを設置した。開発元ならではの知見を生かし、ソフトウェアだけでなくハードウェアも含めた包括的なサポートを行う点が特徴となる。</p>
<p><strong>■ Romi専用ラボで行われる点検・外装交換作業。開発元による公式アフターケア体制を整備した</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/lab01_1024x444_f66c7d779c/lab01_1024x444_f66c7d779c.webp" alt="lab01-1024x444.webp" /></p>
<p>Romiは、日常会話を通じてユーザーと関係性を築く家庭向けの会話AIロボットとして展開されてきた。今回の公式アフターケアの開始により、AIロボットを「購入して終わり」の製品ではなく、長期的に付き合う存在として支える仕組みが整備された形だ。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stack Overflowの質問数が急減、ピーク比で約8割減──生成AI普及で開発者の行動に変化</title>
      <link>https://ledge.ai/articles/stack_overflow_questions_decline_generative_ai</link>
      <description><![CDATA[<p>情報技術系コミュニティサイト「Stack Overflow」で、ユーザーから投稿される質問数が大幅に減少していることが、公開データから明らかになった。Stack Exchangeが提供する公開データベース「<a href="https://data.stackexchange.com/stackoverflow/query/1926661#graph">Stack Exchange Data Explorer（SEDE）</a>」を2026年1月時点で集計したところ、Stack Overflowの質問投稿数が長期的に大きく減少していることが分かった。</p>
<p>月別の質問投稿数を集計すると、最盛期と比べて約8割減の水準にまで落ち込んでおり、開発者が問題解決の手段を変えつつある実態が浮かび上がっている。</p>
<h2>公開データが示す質問数の急減</h2>
<p>Stack Exchangeが提供する公開データベース「Stack Exchange Data Explorer（SEDE）」を用いて、Stack Overflow上の質問投稿（PostTypeId＝1）を月別に集計すると、2010年代後半にピークを迎えた後、投稿数は長期的な減少傾向に入っている。特に2023年以降は減少ペースが加速しており、直近の水準はピーク時と比べて約78％減となっている。</p>
<p>この集計では、削除済みの投稿や集計条件による差異が生じる可能性はあるものの、クエリ条件を変えても「質問数が大きく減少している」という全体傾向は一貫して確認できる。</p>
<h2>生成AIの普及で変わる開発者の問題解決行動</h2>
<p>質問投稿数が減った背景として、複数の海外メディアは生成AIの普及を挙げている。開発者は、コードの書き方やエラー内容の解釈といった疑問を、Q&amp;Aサイトに投稿して回答を待つのではなく、ChatGPTなどの対話型AIに直接尋ね、即座に解決するケースが増えているとされる。</p>
<p>Stack Overflow自身が実施している年次の開発者調査でも、生成AIツールの利用が急速に広がっていることが示されており、問題解決の導線が従来とは異なる形へ移行しつつあることがうかがえる。</p>
<h2>「質問の場」から「知識基盤」へ移る役割</h2>
<p>一方で、新規質問の投稿数が減少しているからといって、Stack Overflowの価値が失われたわけではない。これまでに蓄積された膨大なQ&amp;Aコンテンツは、現在も検索経由で参照され続けており、知識ベースとしての役割は維持されている。生成AIが回答を生成する際の参照元として、過去の投稿が利用されるケースも少なくない。</p>
<p>Stack Overflowは現在、投資会社Prosus傘下の事業として運営が続けられている。質問数の減少と、事業としての継続性や収益構造は必ずしも直結するものではなく、開発者コミュニティの利用形態が変化する中で、サービスの位置づけそのものが転換点を迎えている状況といえる。</p>
<p>生成AIの普及によって、開発者が「質問を投稿する場」としての利用を減らす一方、「知識を参照する基盤」としての役割が相対的に高まる。Stack Overflowの質問数減少は、開発者の行動変化を映し出す象徴的な事例となっている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Wikipediaが25周年、AI時代の知識基盤に──MicrosoftやMistral AIなどと新たなパートナーシップ</title>
      <link>https://ledge.ai/articles/wikipedia_25th_anniversary_ai_partnerships</link>
      <description><![CDATA[<p>Wikimedia Foundationは2026年1月15日、オンライン百科事典「Wikipedia」が創設から25周年を迎えたと<a href="https://wikimediafoundation.org/news/2026/01/15/wikipedia-celebrates-25years/">発表</a>した。</p>
<p>これにあわせて、記念キャンペーン「Wikipedia 25」を開始し、ボランティア編集者の活動を紹介する動画シリーズの公開や、AI時代におけるWikipediaの価値を示す取り組みを打ち出した。</p>
<p>Wikipediaは2001年に公開され、誰でも編集に参加できる百科事典として発展してきた。現在では300以上の言語で6500万超の記事を掲載し、月間の閲覧数は約150億回にのぼる。非営利組織によって運営されている点も特徴で、世界で最も利用されているウェブサイトの一つとなっている。</p>
<p>@<a href="https://www.youtube.com/watch?v=C5rPmv27YzY">YouTube</a></p>
<h2>編集者に焦点を当てた公式動画シリーズを公開</h2>
<p>25周年キャンペーンの一環として、ウィキメディア財団は初めて公式の動画ドキュメンタリーシリーズを公開した。世界各地のボランティア編集者8人を取り上げ、Wikipediaの記事がどのように作られ、検証されているのかを紹介している。</p>
<p>Wikipediaのコンテンツは、約25万人の編集者によって執筆・編集・ファクトチェックが行われており、財団は「AI時代においても、信頼できる知識は人によって支えられている」と強調している。</p>
<h2>タイムカプセルや参加型企画も展開</h2>
<p>同日には「<a href="https://wikipedia25.org/ja/">25 Years of Wikipedia</a>」と題したデジタル・タイムカプセルも公開された。創設者のジミー・ウェールズ氏が語る立ち上げ当時のエピソードや、世界的な出来事とWikipediaの関わりを振り返る内容が盛り込まれている。
このほか、Wikipediaの将来像をテーマにしたインタラクティブなクイズなど、利用者が参加できる企画も用意された。</p>
<h2>AI時代の知識基盤としてのWikipedia</h2>
<p>財団は、生成AIの普及が進む中で、Wikipediaの役割が一層重要になっていると位置づける。Wikipediaの記事は、検索エンジンや音声アシスタント、生成AIチャットボットなどで参照・活用されており、高品質な学習データとしても利用されている。公式発表では、Wikipediaが「人間によって作られ、検証された知識の集合体」である点が、AI時代における強みとして示された。</p>
<h2>MicrosoftやMistral AIなどと新たなパートナーシップ</h2>
<p>こうした背景のもと、ウィキメディア財団はWikimedia Enterpriseを通じて、テクノロジー企業との連携を拡大している。
過去1年間で、Microsoft、Mistral AI、Perplexityのほか、Ecosia、Pleias、ProRataといった企業が新たにパートナーに加わった。既存のパートナーにはAmazon、Google、Metaなどが含まれる。
これらの企業は、Wikipediaのコンテンツを大規模に利用できる一方で、非営利モデルを支える形で財団を支援する仕組みとなっている。</p>
<h2>人間中心のAI戦略を継続</h2>
<p>ウィキメディア財団は、AIの活用についても「編集者を支援するための技術」と位置づけており、人間中心のAI戦略を掲げている。編集作業の効率化やアクセシビリティの向上を図りつつ、知識の信頼性を維持することを目的としている。</p>
<p>財団は今後も2026年を通じて、オンラインイベントや各地のコミュニティによる取り組みなど、25周年を記念した活動を継続する予定だとしている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>画像生成AIの拡散モデル一強に“自己回帰×拡散”で対抗　中国Z.aiが「GLM-Image」発表、文字・知識系の生成に強み</title>
      <link>https://ledge.ai/articles/zai_glm_image_autoregressive_diffusion_image_generation</link>
      <description><![CDATA[<p>中国のAI企業 Z.ai は2026年1月14日、離散自己回帰（discrete auto-regressive）方式の画像生成モデル GLM-Image を<a href="https://z.ai/blog/glm-image">発表</a>した。オープンソースとして公開される一方、商用・業務利用を想定した「産業グレード」の性能をうたう。自己回帰モデルと拡散モデルを組み合わせたハイブリッド構成を採用し、文字入り画像や知識集約型の生成で優位性があるとしている。</p>
<h2>自己回帰と拡散を組み合わせたハイブリッド設計</h2>
<p>GLM-Imageは、画像生成を連続的なノイズ除去で行う拡散モデルに、画像を離散トークン列として逐次生成する自己回帰（Autoregressive）方式を組み合わせた点が特徴だ。Z.aiによると、自己回帰側が画像の意味構造やレイアウトといった低周波成分を担い、その後に拡散デコーダが高周波のディテールを補完する設計としている。</p>
<p>モデル構成は、自己回帰生成器に約90億パラメータ、拡散デコーダに約70億パラメータを用いる二段構えとなっている。テキストから画像を生成する一般的な用途に加え、画像編集、スタイル転送、ID保持生成、複数被写体の一貫性維持など、画像から画像へのタスクにも対応すると説明されている。</p>
<p><strong>■ GLM-Imageの全体アーキテクチャ：</strong> 自己回帰モデル（GLM AR）が低解像度の視覚トークンを生成し、拡散デコーダが高周波のディテールを補完する二段構成。文字情報（Glyph）も独立して埋め込み処理される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/glm_image_new_5d44984a83/glm_image_new_5d44984a83.jpg" alt="glm-image-new.jpg" /></p>
<h2>文字・知識集約型生成を重視、ベンチマークで強みを主張</h2>
<p>Z.aiは、近年の画像生成分野で主流となっている拡散モデルについて、高品質な生成に強みがある一方、文字の正確な描画や複雑な知識表現では課題が残ると整理する。GLM-Imageはその弱点を補う位置づけで、ポスター、プレゼンテーション資料（PPT）、科学図解など、情報量の多い「知識集約型」画像生成を主なターゲットに据えている。</p>
<p><strong>■ Single-Stream DiTにおけるAttention制御の概念図：</strong> 条件画像、文字（Glyph）、生成対象を単一ストリームで扱いながら、Attention Maskにより相互参照範囲を制御。文字や知識要素を保持したまま画像生成を行う設計を示す。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20260112_171559_65d0712626/20260112_171559_65d0712626.jpeg" alt="20260112-171559.jpeg" /></p>
<p>公式ブログによれば、テキストレンダリング性能を測るベンチマーク「CVTG-2K」では、オープンソースモデルとして上位水準のスコアを記録したとされる。文字の正確性を示す指標では0.9を超える値を示し、Z.aiは文字生成の安定性を強みとして挙げている。<a href="https://github.com/zai-org/GLM-Image">GitHub</a>上では、複数の公開ベンチマークにおける他モデルとの比較結果も提示されている。</p>
<p><strong>■ GLM-Imageによる生成例：</strong> ポスター、教育用図解、文字入りインフォグラフィックなど、知識集約型コンテンツの生成例。文字の可読性やレイアウトの一貫性を重視した出力が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/glm_image_showcase_poster_8c14d0aded/glm_image_showcase_poster_8c14d0aded.jpg" alt="glm-image-showcase-poster.jpg" /></p>
<h2>オープン提供と実運用上の条件、残る課題</h2>
<p>GLM-Imageはオープンウェイトで公開され、APIとしても利用可能とされている。公式ドキュメントではAPI利用料金を1画像あたり0.015ドルとしており、対応解像度は512〜2048ピクセル、幅・高さはいずれも32の倍数であることが条件とされている。</p>
<p>一方で、実運用上のハードルも明示されている。GitHubの説明によると、現時点では推論最適化が限定的で、1024×1024ピクセルの生成でも大容量GPUを必要とする。80GB超の単一GPU、もしくは複数GPU構成が想定されており、推論コストは依然として高い。Z.aiは今後、自己回帰部分の高速化や推論基盤への対応を進めるとしている。</p>
<p>ライセンスについては、GitHub上ではApache License 2.0と表記されている一方、<a href="https://huggingface.co/zai-org/GLM-Image">Hugging Face</a>のモデルカードではモデル全体はMITライセンスで、一部コンポーネントにApache 2.0が含まれる旨が記載されている。利用にあたっては、各構成要素のライセンス条件を個別に確認する必要がある。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>