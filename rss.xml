<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>「AI 2027」予測を“後ろ倒し”──元OpenAI研究者ココタジロ氏ら、超人的AIの到来見通しを更新</title>
      <link>https://ledge.ai/articles/ai_2027_timeline_revision_kokotajlo</link>
      <description><![CDATA[<p>元OpenAIのAI研究者であるDaniel Kokotajlo氏らは2025年12月31日、AIの急速な進展とその潜在的リスクを描いた将来予測シナリオ「AI 2027」に関連する予測を見直し、AIが人間を明確に上回る能力を獲得する時期についての見通しを、従来より後ろ倒しにしたと<a href="https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update">発表</a>した。</p>
<p>この見直しは、同氏らが運営するAI Futures Projectが2025年12月末に公開した最新の予測モデルによるものだ。公式の説明によると、新モデルでは、AIが人間並み、あるいはそれ以上の能力でコーディングや研究開発を自動化する段階に到達するまでのタイムラインを、従来の想定より数年単位で長く見積もっているという。</p>
<h2>予測シナリオ「AI 2027」が提示してきたもの</h2>
<p>「<a href="https://ai-2027.com/">AI 2027</a>」は2025年に公開されたシナリオで、AIの能力向上が加速した場合に、2020年代後半にも人間を超える汎用的な知能が出現する可能性と、それに伴う社会的・安全保障上のリスクを描いたものだ。物語形式のシナリオとともに、能力向上のマイルストーンやタイムライン予測を示し、AI安全性やガバナンスをめぐる議論の中で広く参照されてきた。</p>
<p>同シナリオは、特定の年を断定するものではなく、複数の前提条件に基づく予測モデルを用いて将来像を提示している点が特徴とされている。</p>
<h2>最新モデルで示されたタイムラインの修正</h2>
<p>今回公開された最新モデルでは、AIが「完全なコーディング自動化」に至るまでの期間について、旧モデル（AI 2027で用いられた予測）よりも慎重な見積もりが採用された。AI Futures Projectはその理由として、完全自動化に至る前段階でのAIによる研究開発（R&amp;D）加速の効果を、現実的な制約を踏まえて再評価した点を挙げている。</p>
<p><strong>AI Futures Projectが公開した最新の予測モデル画面。AI 2027で用いられた従来モデルを更新し、AI研究開発の自動化や計算資源の前提を再評価している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f2bf7c4b_33b1_4411_acb4_ffe5c2178fa0_1600x906_7bde2dd933/f2bf7c4b_33b1_4411_acb4_ffe5c2178fa0_1600x906_7bde2dd933.png" alt="f2bf7c4b-33b1-4411-acb4-ffe5c2178fa0_1600x906.png" /></p>
<p>研究開発の自動化が進めばAIの進化は複利的に加速する可能性がある一方、その速度や実用化の範囲については不確実性が大きいとし、前回の想定を修正した形だ。</p>
<h2>当事者による位置づけと説明</h2>
<p>ココタジロ氏は<a href="https://x.com/DKokotajlo/status/2006257807721652588">自身のX投稿</a>でも、「AI 2027のシナリオよりも進展はやや遅い可能性が高い」と言及している。あわせて、当初から予測には幅があり、今回の更新は新たなデータや前提条件を反映した結果だと説明している。</p>
<p><strong>AI Futures Modelに基づく1つの想定トラジェクトリー。完全なコーディング自動化（AC）、超人的AI研究者（SAR）、人工超知能（ASI）に至る時期を示している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G9dm_El_Oa_YA_Ettaj_2dbcf7c8fd/G9dm_El_Oa_YA_Ettaj_2dbcf7c8fd.jpg" alt="G9dmElOaYAEttaj.jpg" /></p>
<h2>更新を前提とした予測モデルという位置づけ</h2>
<p>AI Futures Projectは、今回公開した最新モデルについて、現時点の技術動向や前提条件を反映したものであり、今後の研究開発の進展や実証結果に応じて見直しを行うとしている。AI 2027で提示された予測も、こうした更新の一部として位置づけられており、同プロジェクトは引き続き、モデルの前提や結果を公開しながら予測を更新していく方針を示している。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>未成年の自殺を巡るAI訴訟に進展──GoogleとCharacter.AI、4州訴訟で和解に合意</title>
      <link>https://ledge.ai/articles/ai_chatbot_lawsuit_settlement_google_character_ai_four_states</link>
      <description><![CDATA[<p>AIチャットボットとの会話が未成年の自殺につながったとして提起されていた訴訟をめぐり、GoogleとCharacter.AIが和解に合意した。フロリダ連邦地裁に提出された<a href="https://www.courtlistener.com/docket/69300919/garcia-v-character-technologies-inc/">書類</a>によると、当事者は調停による和解に原則合意し、裁判所は手続きをいったん終了させている。</p>
<p>訴訟は、2024年に死亡した14歳の少年の母親が提起したもので、少年がCharacter.AIのチャットボットと継続的に会話していたことが問題とされた。裁判所に提出された通知によれば、2026年1月7日付で当事者は調停による和解に原則合意し、最終的な和解文書の作成と締結に向けて手続きを進めるとしている。裁判所は、一定期間内に最終処理が行われることを条件に、事件をいったん却下し、記録を閉じた。</p>
<p>海外メディアの報道によると、2026年1月14日に裁判所に提出された法廷文書では、今回の和解がフロリダ州、コロラド州、ニューヨーク州、テキサス州で提起されていた訴訟を対象としていることが示されている。</p>
<p>今回の訴訟では、チャットボットを直接提供していたCharacter.AIに加え、Googleも被告として名を連ねていた。原告側は、会話型AI技術の系譜や計算基盤（クラウド）の提供、事業面での関与などを理由に、Googleがサービスの成立に実質的に関与していたと主張していた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_guardian_megan_garcia_and_son_8a039bc133/the_guardian_megan_garcia_and_son_8a039bc133.jpg" alt="the guardian megan garcia and son.jpg" /></p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/08/google-character-ai-settlement-teen-suicide">The Guardian</a>は、Googleが2024年にCharacter.AIと約27億ドル規模のライセンス契約を結んでいたことが、同社が本件訴訟に関連付けられた背景の一つだと報じている。</p>
<p>これに対しGoogleは、Character.AIの運営主体ではなく、クラウドサービスの提供のみで法的責任は生じないとして請求棄却を求めていた。裁判所は、この是非について判断を示さず、却下段階では原告の主張を排除できないとして、審理の余地があるとの姿勢を示していた。</p>
<p>本件は、会話型AIと未成年をめぐるリスクが司法の場で争点となり得ることを示した一方、AIの法的責任について一般的な基準を確定させるものではなかった。基盤提供者を含む責任の射程については、今後も個別の訴訟や立法の場で検討が続くとみられる。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>現在の生成AI勢力図はどこからどのように生まれたのか？──Google起点の系譜を可視化した「AI Mafia」</title>
      <link>https://ledge.ai/articles/ai_mafia_google_ai_talent_network</link>
      <description><![CDATA[<p>生成AIを牽引する研究者や起業家たちは、どこから生まれ、どのようにつながってきたのか。
個人開発者のDipak Wani氏が公開したインタラクティブ可視化「<a href="https://dipakwani.com/ai-mafia/">AI Mafia</a>」は、Googleを起点とするAI人材の系譜をネットワーク図として可視化した試みとして注目を集めている。</p>
<p>「AI Mafia」は、人物、企業、研究組織などをノードとして配置し、それらの関係性を線で結んだインタラクティブなネットワーク図だ。閲覧者はノードを操作することで、特定の研究者がどの組織に所属し、どの企業や研究と結びついてきたのかを辿ることができる。生成AI分野を形作ってきた人材の流れを、構造として俯瞰できる点が特徴となっている。</p>
<h2>Googleに集結したAI人材──2010年代前半の「集中」</h2>
<p>この可視化の背景にあるのが、米国の人気ビジネス系ポッドキャスト「Acquired」が2025年秋に公開したエピソード「<a href="https://www.youtube.com/watch?v=lCEB7xHer5U">Google: The AI Company</a>」で整理されたAI史だ。同エピソードでは、現在の生成AI革命を担う人材の多くが、2010年代前半に一度Googleへ集結していたことが語られている。</p>
<p>@<a href="https://https://www.youtube.com/watch?v=lCEB7xHer5U">YouTube</a></p>
<p>2012年のImageNetコンペティションで勝利し、深層学習の転換点を作ったジェフ・ヒントン教授と、その教え子であるアレックス・クリジェフスキー、イリヤ・サツケヴァーらは、スタートアップ「DNN Research」を通じてGoogleに加わった。ほぼ同時期に、デミス・ハサビスらが創業したDeepMindも2014年にGoogleに買収され、優秀な研究者集団がGoogle傘下に入った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/hinton_dnn_hassabis_deepmind_723429abc4/hinton_dnn_hassabis_deepmind_723429abc4.jpg" alt="hinton dnn hassabis deepmind.jpg" /></p>
<p>さらに、アンドリュー・ン氏やジェフ・ディーン氏らを中心に、Google内部では「Google Brain」が立ち上げられた。Acquiredではこの時期を、かつてIBMがコンピュータ時代初期にプログラマーを一手に集めていた状況になぞらえ、AI分野の人材と計算資源がGoogleに強く集中していた段階として位置づけている。</p>
<h2>OpenAIの設立と最初の人材流出</h2>
<p>こうした集中構造に変化をもたらしたのが、2015年前後のOpenAI設立だ。イーロン・マスク氏やサム・アルトマン氏らは、GoogleがAI研究と計算資源を事実上独占している状況に危機感を示し、対抗的な研究組織としてOpenAIを立ち上げた。
多くの研究者がGoogleに留まる中で、最初に大きな動きを見せたのがイリヤ・サツケヴァー氏だった。同氏はGoogleを離れ、OpenAIの創業メンバーとして参加し、後に同社の技術的中核を担う存在となった。この動きは、AI人材がGoogleから外部へ流出し始めた象徴的な出来事とされている。</p>
<h2>Transformer論文が加速させた分岐</h2>
<p>人材流動を決定的に加速させたのが、2017年にGoogleの研究者らが発表した論文「Attention Is All You Need」、いわゆるTransformer論文だ。現在の生成AIの基盤となるこの技術はGoogle内部で生まれたが、製品化には慎重な姿勢が取られた。</p>
<p>その結果、論文の共著者たちは数年以内に相次いでGoogleを退職し、スタートアップを創業したり、競合企業へ移籍したりしていった。主要著者の一人であるノーム・シャジール氏は、社内でのチャットボット公開が認められなかったことを背景に退職し、Character.AIを創業した例として知られる。</p>
<p><strong>Transformer論文著者たちのその後</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/after_transformer_6288345452/after_transformer_6288345452.jpg" alt="after transformer.jpg" /></p>
<h2>現在の生成AI勢力図へとつながる人材の流れ</h2>
<p>現在の生成AI業界を代表する企業の多くは、こうした流れの延長線上にある。OpenAIはサツケヴァー氏ら元Google研究者が技術基盤を築き、AnthropicはOpenAIからスピンアウトしたダリオ・アモデイ氏（元Google Brain）らによって設立された。DeepMindの共同創業者であるムスタファ・スレイマン氏はInflection AIを経て、現在はMicrosoftのAI部門を率いている。</p>
<p>Dipak Wani氏の「AI Mafia」は、これらの人材の集中と分岐の歴史を、一枚のインタラクティブな図として可視化したものだ。2025年10月下旬に<a href="https://news.ycombinator.com/item?id=45715819">Hacker News</a>上で作者本人によって公開され、年末から年始にかけてテック系コミュニティで共有が広がった。研究成果の優劣を示すものではないが、生成AI時代のエコシステムがどのような人材の流れによって形作られてきたのかを理解する手がかりとして参照されている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、Claudeを医療・ライフサイエンス向けに拡張──診療支援から臨床試験までAI活用を本格化</title>
      <link>https://ledge.ai/articles/anthropic_claude_healthcare_life_sciences_expansion</link>
      <description><![CDATA[<p>米AI企業の Anthropic は2026年1月12日（現地時間）、同社の生成AI「Claude」において、医療およびライフサイエンス分野向けの機能拡張を<a href="https://www.anthropic.com/news/healthcare-life-sciences">発表</a>した。医療機関や保険者、研究者、個人利用者を対象に、医療データの要約・解釈から臨床試験、規制業務までを支援する専用機能を提供する。</p>
<h2>「Claude for Healthcare」を新設、医療業務向けAIを明確に区分</h2>
<p>同社は医療分野向けの専用機能群として「Claude for Healthcare」を導入した。これは、医療提供者、保険者、消費者が医療用途でClaudeを利用することを想定したプロダクトで、HIPAA（米医療保険の携行性と責任に関する法律）への対応を前提として設計されている。</p>
<p>想定される活用例としては、診療記録や検査結果の要約・解釈、医療文書の作成支援、保険請求や事前承認（prior authorization）といった事務手続きの効率化などが挙げられている。汎用的なチャット利用とは区別し、医療業務に特化したAIとして提供する点を明確にした。</p>
<h2>医療データ連携を拡充、CMSやPubMedなどに対応</h2>
<p>医療・行政データへの対応も拡充された。Claudeは新たに、米国の医療制度や診療報酬に関連するデータベースであるCMS Coverage DatabaseやICD-10、医療機関・医師情報を扱うNPI Registryといったデータソースに接続可能となった。</p>
<p>また、医学・生命科学分野の文献データベースであるPubMedへのコネクタも追加されている。これに加え、FHIR（Fast Healthcare Interoperability Resources）を用いた開発支援や、事前承認業務に対応するAgent Skillsも拡張され、臨床現場だけでなく医療事務や制度対応を含めた業務全体を視野に入れた設計となっている。</p>
<h2>個人向けにも健康データ接続を提供、学習利用は行わず</h2>
<p>個人利用者向けには、米国のClaude ProおよびMax加入者を対象に、健康データをClaudeに接続できる機能をベータ版として提供する。HealthExやFunctionを介した医療記録の接続に加え、Apple HealthやAndroid Health Connectとの連携にも対応する。</p>
<p>Anthropicは、こうした個人の健康データについて、AIモデルの学習には使用しない方針を明示している。医療・健康情報という機微性の高いデータを扱うにあたり、利用範囲とデータ取り扱いを限定する姿勢を強調した形だ。</p>
<h2>ライフサイエンス分野も強化、臨床試験・規制業務を支援</h2>
<p>ライフサイエンス分野向けには、「Claude for Life Sciences」の機能強化も行われた。新たにClinicalTrials.govやMedidata、bioRxivおよびmedRxivといった研究・臨床試験関連のデータソースとの連携が追加されている。</p>
<p>これにより、臨床試験の設計や進捗管理、研究文献の整理、規制当局向け文書の作成支援など、研究開発から規制対応までの幅広い業務をAIで支援することが可能になるとしている。</p>
<h2>医療・生命科学分野での実運用を見据えた展開</h2>
<p>Anthropicは今回の発表について、規制や安全性が強く求められる医療および生命科学分野において、生成AIを実運用に耐える形で導入するための取り組みだとしている。医療向けに用途を明確化し、データ連携や取り扱い方針を整理した上で提供を進めることで、医療現場や研究現場での活用拡大を狙う。</p>
<p>@<a href="https://www.youtube.com/watch?v=UXyVMGAFLAs&amp;t=1s">YouTube</a></p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/14 [WED]Anthropic、非エンジニア向け業務AIエージェント「Cowork」開始──Claude Codeの自律実行を一般業務へ拡張</title>
      <link>https://ledge.ai/articles/anthropic_cowork_launch_claude_code_agent_general_work</link>
      <description><![CDATA[<p>Anthropicは2026年1月12日（現地時間）、同社のAIアシスタント「Claude」において、新機能「Cowork（コワーク）」を研究プレビューとして開始したことを<a href="https://claude.com/blog/cowork-research-preview">発表</a>した。</p>
<p>開発者向けのコーディングエージェント「Claude Code」で培ってきた自律的なタスク実行の仕組みを、文書整理や資料作成といった一般業務にも拡張し、開発者以外でも利用できる業務エージェントとして提供する。</p>
<h2>「指示に答えるAI」から「作業を進めるAI」へ──Coworkの位置づけ</h2>
<p>Coworkは、Claudeがユーザーの「同僚（co-worker）」のように振る舞い、単発の質問に答えるだけでなく、目的を理解し、作業計画を立て、複数ステップのタスクを自律的に実行することを想定した機能だ。</p>
<p>Anthropicは、Claude Codeの提供後、開発者がコーディング以外の用途にも同機能を広く使い始めたことを背景に、よりシンプルで誰でも使える形としてCoworkを開発したとしている。基盤はClaude Codeと共通で、同様の自律実行能力を、非コーディング業務向けに抽象化した形となる。</p>
<p>@<a href="https://www.youtube.com/watch?v=UAmKyyZ-b9E">YouTube</a></p>
<h2>ローカルファイルを直接扱う業務エージェント</h2>
<p>Coworkは、macOS向けのClaude Desktopアプリ上で動作する。ユーザーが許可したフォルダに対して、Claudeが以下の操作を直接行える点が特徴だ。</p>
<ul>
<li>ファイルの読み取り</li>
<li>ファイルの編集・新規作成</li>
<li>複数ファイルの整理や再構成</li>
</ul>
<p>公式ブログでは、ダウンロードフォルダの自動整理、スクリーンショットの束から経費一覧のスプレッドシートを作成する作業、散在するメモからレポートの下書きを作る作業などが例として挙げられている。チャット上の応答にとどまらず、実際の業務ファイルを扱いながら作業を進める点がCoworkの特徴だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=WBNZpAWhw5E">YouTube</a></p>
<h2>コネクタ、スキル、Chrome連携──業務エージェントとしての拡張性</h2>
<p>Coworkでは、Claudeが既存のコネクタを利用できる。これにより、外部情報と連携したタスク実行が可能になる。また、Cowork向けに、文書やプレゼンテーション、各種ファイル作成を強化する初期スキル群も追加された。さらに、Chrome上でClaudeを利用する設定と組み合わせることで、ブラウザ操作を伴うタスクにも対応できるとしている。</p>
<p>Anthropicは、Coworkでは毎回文脈を手動で与えたり、出力結果を別の形式に変換したりする必要がなく、タスクをキューに積んで並列に進められる設計になっている点も特徴だと説明する。やり取りを重ねるというより、「同僚にまとめて指示を残す」感覚に近い体験を目指したという。</p>
<h2>提供条件と現時点での制約</h2>
<p>Coworkは研究プレビューとして提供されており、現時点での利用条件は以下の通り。</p>
<p><strong>■ 提供環境</strong>
・macOS向けClaude Desktopアプリ
・有料の「Claude Max」プラン加入者向け</p>
<p><strong>■ 制約</strong>
・セッションをまたいだ長期的な記憶は行わない
・Claudeの「Projects」機能とは未統合</p>
<p>Claude Max以外のプラン利用者については、将来提供に向けた待機リストが用意されている。
Anthropicは今後、クロスデバイス同期の追加やWindows対応など、段階的な拡張を進めるとしている。</p>
<h2>自律型AIの業務利用を前提にした安全設計</h2>
<p>Coworkでは、Claudeがローカルファイルを操作できるため、安全面での注意も明示されている。ユーザーは、Claudeに見せるフォルダやコネクタを自ら選択でき、明示的に許可していない情報にはアクセスできない。</p>
<p>また、重要な操作を行う前にはClaudeが確認を求める設計となっている。一方で、削除などの破壊的な操作が行われる可能性もあるため、指示は明確に行う必要があるとしている。</p>
<p>Anthropicは、インターネット上の内容によってAIの行動計画が変えられる「プロンプトインジェクション」のリスクにも言及し、これは業界全体で対処が続く課題だと説明する。
詳細な注意点については、Help Centerで<a href="https://support.claude.com/en/articles/13364135-using-cowork-safely">案内</a>している。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Apple、次世代AI基盤にGemini採用──SiriなどApple Intelligenceで活用へ</title>
      <link>https://ledge.ai/articles/apple_nextgen_ai_platform_gemini_adoption</link>
      <description><![CDATA[<p>Apple と Google は2026年1月12日（米国時間）、Apple の次世代基盤 AI「Apple Foundation Models」に、Google の生成 AI モデル Gemini とクラウド技術を採用すると<a href="https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/">発表</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/google_apple_x_b32876998f/google_apple_x_b32876998f.jpg" alt="google apple x.jpg" /></p>
<p>声明によると、この協業は複数年にわたる取り組みで、Siri を含む Apple Intelligence 関連機能の基盤として活用される。今回の発表は、Google が公式ブログ上で Apple との Joint Statement として公開したもの。Apple Foundation Models は、Apple が自社製品やサービスに組み込む AI 機能の基盤となるモデル群で、今後の Apple Intelligence の中核を担う位置づけとされている。</p>
<h2>Apple Foundation Models の基盤に Gemini と Google Cloud</h2>
<p>Apple は次世代の Foundation Models において、Gemini のモデル群と Google のクラウド基盤を採用する。Gemini は Google が開発する大規模言語モデルで、テキスト理解や生成をはじめ、幅広い AI タスクに対応する点が特徴とされる。</p>
<p>Apple はこの技術を、Apple Foundation Models の一部として統合し、Apple Intelligence を構成する各種機能の基盤として利用する。具体的なモデル構成や技術的な役割分担については、今回の声明では詳細は明らかにされていない。</p>
<h2>Siri を含む Apple Intelligence 機能で活用へ</h2>
<p>両社は、Gemini を採用した Apple Foundation Models が、Siri を含む Apple Intelligence 関連機能で活用されるとしている。これにより、Gemini とクラウド技術を基盤とする次世代 Foundation Models が、Siri などの Apple Intelligence 機能を支える設計になることが示されている。</p>
<h2>プライバシーは Apple の基準を維持</h2>
<p>プライバシーに関しては、共同声明の中で、ユーザーデータの取り扱いは Apple のプライバシー基準に基づいて行われる方針が示されている。Apple は、ユーザーのプライバシー保護を重視した形で AI 機能を提供するとしている。</p>
<h2>AI 基盤を巡る競争の中で進む協業</h2>
<p>Apple と Google は、モバイル OS や AI 分野で競合関係にある一方、検索やクラウド分野では協業関係も持つ。今回の発表は、AI 基盤技術を巡る競争が激化する中で、両社がそれぞれの技術的強みを活用する形で合意に至ったことを示すものとなった。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>独Black Forest Labs、画像生成AI「FLUX.2[klein]」を公開　生成・編集を統合し1秒未満の高速推論を実現</title>
      <link>https://ledge.ai/articles/black_forest_labs_flux2_klein_release</link>
      <description><![CDATA[<p>Black Forest Labsは2026年1月15日、画像生成AIモデルファミリー「FLUX.2」から、高速・統合型モデルFLUX.2[klein]を<a href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence">発表</a>した。</p>
<p>生成と画像編集を単一のアーキテクチャに統合し、エンドツーエンドの推論を1秒未満で完了させる低レイテンシ性を特徴とする。</p>
<p>同社は、AIエージェントの高度化に伴い、視覚生成にもリアルタイム性が求められていると指摘する。FLUX.2[klein]は、待ち時間を極小化しながら生成と編集を同時に扱える点を重視して設計されており、インタラクティブなビジュアルAIの基盤として位置づけられている。</p>
<h2>生成と編集を単一モデルで処理</h2>
<p>FLUX.2[klein]は、テキストからの画像生成に加え、既存画像の編集や複数参照画像を用いた生成などを、単一のコンパクトなモデルで処理できる。従来は別工程として扱われることの多かった生成と編集を統合することで、応答速度の向上とシステム構成の簡素化を図った。</p>
<h2>サブ秒推論とコンシューマGPU対応</h2>
<p>同モデルは低レイテンシを前提に設計されており、生成・編集を含む推論がサブ秒で完了するとされる。あわせて、最小構成で約13GBのVRAMを持つ消費者向けGPUでの動作を想定しており、ローカル環境やエッジ用途での利用も視野に入れる。</p>
<h2>9B／4B／Baseの3系統</h2>
<p>FLUX.2[klein]は用途に応じて複数のバリアントが用意されている。</p>
<ul>
<li><strong>9B（蒸留モデル）</strong> は、品質と速度のバランスを重視した小型フラッグシップとして位置づけられる。</li>
<li><strong>4B（蒸留モデル）</strong> は、より小規模で高速な推論を特徴とし、ローカル開発やリアルタイム用途を想定する。</li>
<li><strong>Base（非蒸留モデル）</strong> は、推論速度よりもLoRAなどによるカスタマイズ性を重視した構成とされる。</li>
</ul>
<h2>ライセンスと提供形態</h2>
<p>4B系モデルはApache 2.0ライセンスで提供され、商用利用が可能となっている。一方、9B系モデルはFLUX Non-Commercial License（非商用）での提供となる。これらはAPI経由での利用に加え、オープンウェイトとしてローカル実行も可能とされており、プロダクション導入と研究・開発用途の双方に対応する。</p>
<h2>量子化と最適化</h2>
<p>FLUX.2[klein]の蒸留モデルおよびBaseモデルを含む全バリアントは、FP8およびNVFP4量子化に対応しており、NVIDIAのRTX GPU向けに最適化されている。これにより推論速度の向上とVRAM使用量の削減を両立したとしている。</p>
<p>Black Forest Labsは、FLUX.2[klein]をリアルタイム生成や高頻度処理を前提としたモデルとして位置づけ、より大規模なモデルと使い分けることで、用途に応じたAI画像生成基盤の構築を可能にするとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>AIは主役から基盤へ──CES 2026で示された「実装段階」に入ったテクノロジーの姿</title>
      <link>https://ledge.ai/articles/ces2026_ai_design_embedded_devices</link>
      <description><![CDATA[<p>世界最大級のテクノロジー見本市「CES 2026」は、2026年1月6日から9日まで、米国ネバダ州ラスベガスで<a href="https://www.ces.tech/press-releases/ces-2026-the-future-is-here">開催された</a>。主催するConsumer Technology Association（CTA）は、今回のCESを「The Future Is Here（未来はすでにここにある）」と位置づけ、先端技術が構想や実験段階を越え、現実の製品やサービスとして展開されるフェーズに入ったことを強調した。
展示会場では、AIが単独の主役として語られるのではなく、PC、デジタルヘルス、モビリティ、日用品など幅広い分野に組み込まれ、生活や仕事のあり方を具体的に変える基盤技術として提示された。</p>
<p>CES 2026で示されたのは、AIが主役として語られるフェーズを越え、製品や体験の設計思想そのものに組み込まれていく段階に入った姿だった。編集部では、こうした移り変わりを象徴するようなデバイスをいくつかピックアップした。いずれも「AI搭載」を強調するより、計算や推論が製品の内部に溶け込み、使い方そのものを形づくっている点が共通している。これらの製品を通じて、CES 2026で示された“実装段階”の姿を見ていく。</p>
<h2>キーボード一体型AI PC：HP EliteBoard G1a</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/v2_2026_hpeliteboardg1anextgenaipc_hpeliteboard_primary_826008a117/v2_2026_hpeliteboardg1anextgenaipc_hpeliteboard_primary_826008a117.webp" alt="v2_2026_hpeliteboardg1anextgenaipc-hpeliteboard_primary.webp" /></p>
<p>HPは、キーボード一体型のAI PC「EliteBoard G1a」を<a href="https://www.ces.tech/ces-innovation-awards/2026/hp-eliteboard-g1a-next-gen-ai-pc/">発表</a>した。外観はフルサイズキーボードに近いが、内部にCPUに加えてNPUを含む演算基盤を搭載し、外付けディスプレイと接続して使用する構成となっている。本製品はローカルでのAI処理を前提に設計されており、クラウドに依存せず、生成AIや要約、分析といったAIタスクを端末側で実行する用途を想定している。画面を本体から切り離すことで、AI処理を担う計算ユニットを机上に集約する設計思想が示された。
本製品はCES Innovation Awards 2026にも選出されている。</p>
<p><strong>PC → 生活空間AIへの転換</strong>
PC領域でのローカルAI処理を前提とした設計が示された一方で、CES 2026では、AIがディスプレイや入力装置の枠を越え、生活空間そのものに組み込まれる例も複数見られた。</p>
<h2>AIコンパニオン：Lepro Ami</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Lepro_Ami_70cd5a7695/Lepro_Ami_70cd5a7695.jpg" alt="Lepro_Ami.jpg" /></p>
<p>Leproは、デスクトップ型AIコンパニオン「Lepro Ami」を<a href="https://www.newswire.ca/news-releases/lepro-unveils-lepro-ami-at-ces-2026-a-desktop-ai-companion-that-feels-in-the-room--847670849.html">公開</a>した。公式説明によると、Amiは音声入力や周囲の環境情報をAIが解釈し、利用者との対話や反応を行うことを目的としたデバイスである。画面操作を中心とする従来のAIとは異なり、空間内での存在感や応答性を重視した設計が特徴とされる。AI処理の一部はローカルで行う構成が示されており、プライバシーへの配慮も設計要素として挙げられている。日常空間に常駐するAIの形を提示するデバイスとして位置づけられている。</p>
<p><strong>空間AI → 個人データ／ライフログ</strong>
空間に常駐するAIに加え、CES 2026では、個人の行動や状態を継続的に捉えるAIを想定したデバイスも提示された。AIを“使う”存在ではなく、“常にそばにある前提”で設計する動きが浮かび上がる。</p>
<h2>AIライフログ・ペンダント：Motorola Project Maxwell</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Maxwell_Photo_7_1536x1024_36f46681ba/Maxwell_Photo_7_1536x1024_36f46681ba.jpg" alt="Maxwell-Photo-7-1536x1024.jpg" /></p>
<p>Motorolaは、AIライフログデバイス「Project Maxwell」を研究プロジェクトとして<a href="https://motorolanews.com/motorola-unveils-new-flagship-devices-and-ai-powered-innovation-at-lenovo-tech-world-2026/">紹介</a>している。ペンダント型デバイスとして構想されており、利用者が見聞きしている情報をAIが理解・整理することを目的とする。公式リリースでは、視覚や音声といった日常環境データをAIが解析し、個人に合わせた体験や支援につなげる構想が示されている。AIは常時稼働するアシスタントとして振る舞うことを想定しており、Motorola 312 Labsによる実験的な取り組みの一環として位置づけられている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_EPFK_2a_MAA_Vy_Iy_216a72ad1f/G_EPFK_2a_MAA_Vy_Iy_216a72ad1f.jpg" alt="G-EPFK2aMAAVyIy.jpg" /></p>
<p><strong>ライフログ → デジタルヘルス</strong>
こうした流れは、デジタルヘルス分野でも顕著だった。CES 2026では、ウェアラブルや医療機器に限らず、日常的な動作や映像を起点に健康状態を把握しようとするアプローチが広がりを見せた。</p>
<h2>ミラー型デバイス：NuraLogix「Longevity Mirror」</h2>
<p>デジタルヘルス技術企業NuraLogixは、ミラー型デバイス「Longevity Mirror」を<a href="https://www.linkedin.com/posts/nuralogix-corporation_ai-longevity-healthtech-activity-7414349139225788416-Ne-N">公開</a>した。製品では、30秒のセルフィービデオをAIが解析し、血流変化などの映像情報から健康関連指標を推定する。同社によると、AIは映像データをもとに「Longevity Index（LIX）」を算出し、心血管疾患リスクや代謝の健康、精神的ストレスなど5つの生理学的領域を統合的に評価するという。ウェアラブルや物理センサーを用いず、カメラ映像とAI解析のみで健康状態の把握を試みる点が特徴とされている。</p>
<p>@<a href="https://www.youtube.com/watch?v=dDem2hR4_1E">YouTube</a></p>
<p>CES 2026には、約14万8,000人が来場し、4,100社以上（うち約1,200社がスタートアップ）が出展した。CTAのGary Shapiro氏は、CESを「世界で最も強力なイノベーションの実証の場」と位置づけ、技術がビジネスや政策、社会と結びつく場であると説明している。また、Kinsey Fabrizio氏は、AIをはじめとする技術がビジョンから実用段階へと移行している点を強調した。
AIが話題の中心となった過去数年を経て、2026年はAIを含む先端技術が、実体あるプロダクトや産業の中で役割を担い始めた段階を示すCESとなった。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>核融合炉「SPARC」の開発をAIデジタルツインで加速―—Commonwealth Fusion Systems、NVIDIA・シーメンスと連携</title>
      <link>https://ledge.ai/articles/cfs_sparc_ai_digital_twin_nvidia_siemens</link>
      <description><![CDATA[<p>核融合スタートアップの Commonwealth Fusion Systems（CFS） は2026年1月6日、NVIDIA および Siemens と提携し、実証用核融合炉 SPARC の設計・開発をAI主導で加速するデジタルツインを構築すると<a href="https://cfs.energy/news-and-media/commonwealth-fusion-systems-accelerates-commercial-fusion-with-siemens-and-nvidia-leveraging-ai-powered-digital-twins">発表</a>した。AIとシミュレーションを中核に据え、従来は物理試験に大きく依存していた核融合炉開発のプロセスを仮想空間上で統合・高速化する。</p>
<h2>AIと産業ソフトウェアを統合したデジタルツイン</h2>
<p>CFSが構築するデジタルツインは、NVIDIAのAIおよび物理シミュレーションライブラリと、Siemensの設計・製造向けソフトウェア群を統合したものとなる。</p>
<p>SiemensのNXやTeamcenterを中心とする設計・PLM（製品ライフサイクル管理）ツールで作成されたデータを、NVIDIAのシミュレーション基盤と連携させることで、SPARCの構造・磁場・熱挙動などを一体的に再現する。</p>
<p>@<a href="https://www.youtube.com/watch?v=4PItOlY6_xE">YouTube</a></p>
<p>この環境では部品単位から炉全体までを単一の仮想モデルで扱うことが可能となり、設計変更や検証を仮想空間上で迅速に繰り返せるという。</p>
<h2>「動く炉」を再現するデジタルモデル</h2>
<p>今回のデジタルツインは、静的な3D設計モデルではなく、実際の運転を想定した動的モデルとして構築される。
電磁場、熱、構造応力といった複数の物理現象を同時に扱い、将来的には実機から得られるデータを反映させることで、仮想モデルと現実の炉の状態を同期させる設計とされている。これにより、実際に装置を製作・試験する前の段階で、設計上の課題や挙動を検証できるようになる。</p>
<h2>高磁場・小型化を支えるAI活用</h2>
<p>SPARCは、高温超電導（HTS）磁石を用いることで、従来よりも小型ながら高磁場を実現する設計を採用している。
CFSはすでに、SPARC向けの初号磁石を完成させ、出荷したことを明らかにしている。この磁石は「空母を持ち上げられるほどの磁力を持つ」と説明されており、高磁場化に伴う構造応力や熱管理が技術的な焦点となっている。</p>
<p>こうした複雑な物理挙動を事前に解析・検証するため、AIとシミュレーションを組み合わせたデジタルツインが設計プロセスの前提となっている。</p>
<h2>実機開発と仮想検証を並行</h2>
<p>CFSは、磁石の製造・据え付けと並行して、デジタルツイン上で炉全体の挙動解析を進める体制を構築している。
物理的な試作・試験と、仮想空間での検証を同時に進めることで、開発工程全体の効率化を図る狙いだ。</p>
<p>デジタルツインは、建設段階にとどまらず、将来的な運転や保守、最適化にも活用されることが想定されている。</p>
<h2>2027年稼働を見据えた基盤整備</h2>
<p>SPARCは、核融合反応による正味エネルギー獲得を目指す実証炉として開発が進められており、2027年の稼働が計画されている。
今回のNVIDIAおよびSiemensとの連携は、設計から運転までをデータとAIに基づいて進める開発基盤を整備する取り組みとして位置付けられる。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ファミマ、防犯カメラ×AIで売場を「点数化」　首都圏で新システム「AI売場スコアリング」の実証開始、AI発注やロボットとの連携も視野に</title>
      <link>https://ledge.ai/articles/familymart_ai_camera_salesfloor_scoring</link>
      <description><![CDATA[<p>ファミリーマートは2026年01月13日、店舗に設置している防犯カメラの映像を活用し、人工知能（AI）で売場の状態を点数化する新たな店舗運営支援システム「AI売場スコアリング」の実証実験を開始することを<a href="https://www.family.co.jp/company/news_releases/2026/20260113_02.html">発表</a>した。2026年1月中旬から首都圏の一部店舗で導入し、業務効率化や品揃えの最適化につなげる。</p>
<p>同システムは、防犯カメラで撮影した売場映像をAIで画像解析し、売場の状態を数値（スコア）として可視化する仕組みだ。これにより、従来は経験や目視に頼りがちだった売場評価を、客観的なデータに基づいて行えるようにする。</p>
<h2>決まった時間に売場を撮影、画像を蓄積</h2>
<p>実証では、あらかじめ設定した時間に売場を撮影し、画像データを蓄積する。例えば「おむすび売場」を毎日同じ時間帯に撮影することで、曜日や時間帯ごとの売場の違いを比較できるようにする。蓄積された画像をもとに、売場のボリュームを点数化し、定点観測が可能なレポートを作成する。</p>
<h2>曜日・日・時間帯別にスコアリング</h2>
<p>AIによるスコアリングは、曜日別、日別、時間帯別の3つの軸で行う。売場画像と点数を組み合わせることで、どの時間帯や曜日に売場の課題が生じやすいかを把握しやすくする狙いだ。作成された定点観測レポートは、店長やスーパーバイザー（SV）が売場を客観的に評価するための資料として活用される。</p>
<h2>SV巡回や店長不在時の売場把握に活用</h2>
<p>SVは巡回時に、売場画像とスコアを確認しながら店長と課題を共有し、発注や売場づくりの改善につなげる。また、店長が不在の間も売場の状況を画像で把握できるため、実態に即した発注が可能になり、発注精度の向上が期待されるとしている。</p>
<h2>ロボットやAI発注との連携も視野</h2>
<p>同社は将来的に、多機能型床清掃ロボット「ポム」にカメラを搭載し、本システムに活用する構想も示している。さらに、既存のAI発注システムや、人型AIアシスタント「レイチェル」と連携させ、売場分析や発注提案の自動化を進める方針だ。対象売場も順次拡大し、店舗運営全体の効率化を図る。</p>
<p>なお同社は、本取り組みの目的において、個人情報が含まれる売場画像は利用しないとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/16 [FRI]AIによる「失業パニック」は起きない？──Forrester予測、2030年までに置き換わる職は米国全体の約6％</title>
      <link>https://ledge.ai/articles/forrester_ai_job_impact_forecast_us_2025_2030</link>
      <description><![CDATA[<p>AIによる雇用喪失への不安が世界的に広がるなか、調査会社のForresterは2026年1月13日、大規模な失業パニックが直ちに起きる可能性は低いとする<a href="https://www.forrester.com/press-newsroom/forrester-impact-ai-jobs-forecast/">見通しを示した</a>。2025年12月末に発表した最新レポートによると、米国で2030年までにAIと自動化によって置き換わる職は全体の約6％、約1040万件にとどまると<a href="https://www.forrester.com/blogs/ai-and-automation-will-take-6-of-us-jobs-by-2030/">予測</a>している。</p>
<p>同レポートは「The Forrester AI Job Impact Forecast, US, 2025–2030」と題され、AIが雇用に与える影響を定量的に分析したものだ。AIの進展によって一部の職種が影響を受けることは避けられないとしつつも、社会全体を揺るがすような急激な雇用崩壊には至らないとの見方を示している。</p>
<h2>AIは職業ではなく「タスク」を置き換える</h2>
<p>Forresterの分析で強調されているのは、AIが直接置き換えるのは「職業」ではなく、職業を構成する「タスク」であるという点だ。多くの仕事は複数の業務要素から成り立っており、その一部がAIによって自動化されるケースが中心になるとされている。</p>
<p>このため、AI導入が即座に人員削減につながるわけではなく、業務の再設計や役割分担の見直しが進む可能性が高いと分析している。</p>
<h2>影響を受けやすい職と限定的な職</h2>
<p>レポートでは、定型的で反復性の高い業務を中心とする職種ほど、AIや自動化の影響を受けやすいと指摘している。一方で、対人対応、判断、創造性を伴う業務については、AIによる完全な代替は限定的になるとの見方を示した。</p>
<p>AIの影響は一様ではなく、職種や業務内容によって大きな差が生じる点が強調されている。</p>
<h2>「AI失業パニック」への警鐘</h2>
<p>Forresterは、AIによる失業への過度な恐怖が、拙速な自動化や短期的なコスト削減判断を招くリスクにも言及している。AIは人件費削減の手段としてではなく、生産性向上や業務の高度化を目的として活用すべきだとしている。</p>
<p>同社は、AIを前提とした業務設計と人材育成を並行して進めることが、企業にとって重要になると指摘した。</p>
<h2>雇用構造の変化にどう向き合うか</h2>
<p>レポートは、今後の課題としてリスキリングやアップスキリングの重要性を挙げている。AIによって一部の業務が置き換わる一方で、新たな役割やスキル需要が生まれる可能性があるためだ。</p>
<p>Forresterは、AIを「雇用を破壊する存在」として捉えるのではなく、雇用構造を変化させる要因として冷静に受け止める必要があるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>エンジニアリング2026/1/16 [FRI]Googleの開発用プラットフォーム「Antigravity」に“Agent Skills”登場　エージェントに作業手順を配布できるオープン標準</title>
      <link>https://ledge.ai/articles/google_antigravity_agent_skills_open_standard</link>
      <description><![CDATA[<p>Google は2026年1月14日（現地時間）、同社の開発用プラットフォームAntigravityにおいて、エージェントの機能を拡張するパッケージ「Skills」のオープン標準を<a href="https://antigravity.google/docs/skills">発表</a>した。Skillsは、特定の作業に必要な手順やベストプラクティス、必要に応じてスクリプトや参考実装などをまとめた再利用可能な知識パッケージで、エージェントは作業時にそれらを参照しながらタスクを進められる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Antigravity_x_ab552c6744/Antigravity_x_ab552c6744.jpg" alt="Antigravity x.jpg" /></p>
<h2>作業手順を“知識パッケージ”として配布</h2>
<p>Skillsは、エージェントに対して都度プロンプトで細かな指示を与えるのではなく、あらかじめ整理された作業マニュアル一式を参照させるための仕組みだ。単純な定型作業から、判断を伴う業務フローまでをSkillとして定義でき、同じSkillを複数のエージェントやプロジェクトで再利用できる点が特徴となる。</p>
<h2>人が書き、エージェントが参照するための共通フォーマット</h2>
<p>各Skillはフォルダー単位で構成され、その中核となるのがSKILL.mdファイルだ。SKILL.mdには、Skillの名称や概要、前提条件、具体的な手順などをYAML形式のフロントマターとして記載し、本文には作業手順をMarkdownで記述する。
同じフォルダー内には、スクリプト、テンプレート、参考実装などの追加リソースを含めることができ、Skill全体として一体的に扱われる。</p>
<h2>単純作業から業務フローまでを扱える設計</h2>
<p>より複雑なSkillでは、「条件に応じて次の手順を切り替える」といった意思決定の分岐も記述可能だ。Antigravityでは、1つのSkillにつき目的を明確にし、説明文を具体的に書くことを推奨している。これにより、エージェントが必要な情報だけを参照しながら作業を進められる設計となっている。</p>
<h2>先行するAnthropicの「Agent Skills」という発想</h2>
<p>このSkillsの設計思想は、Anthropicが先行して提示してきた「Agent Skills」の考え方と重なる。Anthropicは、エージェントに現実的な業務能力を持たせるため、SKILL.mdを中心とした構造を採用し、2025年末には特定のプラットフォームに依存しないオープン標準として公開していた。
GoogleがAntigravityでSkills対応を打ち出したことで、エージェントに与える作業手順やノウハウをツール横断で共有する流れが、主要プラットフォーム間で具体化しつつある。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIエージェント時代の購買基盤「Universal Commerce Protocol（UCP）」を発表──NRF 2026でエージェンティックコマース構想を提示</title>
      <link>https://ledge.ai/articles/google_nrf2026_universal_commerce_protocol_ucp_agentic_commerce</link>
      <description><![CDATA[<p>Googleは2026年1月11日（現地時間）、全米小売業協会（NRF）が主催する年次イベントNRF 2026において、AIエージェントが購買プロセスを担う「エージェンティックコマース（agentic commerce）」時代に向けた取り組みを<a href="https://blog.google/company-news/inside-google/message-ceo/nrf-2026-remarks/">発表</a>した。</p>
<p>同社は、AIエージェントと小売事業者、決済事業者、プラットフォームを横断的につなぐオープン標準として<a href="https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/">「Universal Commerce Protocol（UCP）」</a>を公開し、検索や広告、コマース体験を再編する構想を示した。</p>
<h2>AIが商品探索から購入までを担う「エージェンティックコマース」</h2>
<p>Googleが示すエージェンティックコマースは、利用者が検索や比較を行い購入を決定する従来のEC体験とは異なり、AIエージェントが利用者の意図を理解し、商品探索、条件比較、購入判断、決済までを代行することを前提とする。
NRF 2026での発言において、Googleはこうした購買体験の変化を、小売業界における次の大きな転換点として位置づけた。</p>
<h2>中核となるオープン標準「Universal Commerce Protocol」</h2>
<p>UCPは、AIエージェント時代の商取引を支える共通基盤として設計されたオープンプロトコルだ。
AIエージェント、EC事業者、決済サービス、プラットフォームが個別に連携する従来型の構成ではなく、共通の仕様を介して相互運用できることを目的としている。</p>
<p><strong>■ Universal Commerce Protocol（UCP）の構成概要</strong> ：消費者向けAIサーフェス（検索やGemini）と、小売・決済などの業務バックエンドを、共通プロトコルで接続する。商品探索、カート、チェックアウト、注文といった機能をモジュール化し、AIエージェント時代の商取引を支える。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/UCP_Diagram_Detailed_1_original_9904d1d1ab/UCP_Diagram_Detailed_1_original_9904d1d1ab.png" alt="UCP_Diagram_Detailed_1.original.png" /></p>
<p>Googleによると、UCPは既存のモデル連携プロトコルやエージェント間通信の考え方とも親和性を持ち、オープンソースとして公開される。これにより、小売事業者やプラットフォームは、特定のAIやサービスに依存せず、エージェンティックコマースへの対応を進めることが可能になるという。</p>
<h2>検索とGeminiでの直接購入体験を支える基盤に</h2>
<p>UCPは、Google検索のAI Modeや、生成AI「Gemini」を通じた新しい購買体験の基盤としても活用される。</p>
<p><strong>■ Google検索から購入完了までのエージェンティックコマース体験例</strong> : AIエージェントとの対話を通じて商品を確認し、そのままチェックアウトまで完結する。UCPは、こうした検索起点の直接購入体験を支える基盤として機能する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/triptych_alt_original_aa3f1e380e/triptych_alt_original_aa3f1e380e.jpg" alt="triptych-alt.original.jpg" /></p>
<p>利用者はAIエージェントとの対話を通じて商品を比較・検討し、そのまま購入まで進むことが可能になる設計だ。Googleは、こうした体験を自社サービスに閉じたものではなく、業界全体に開かれた形で展開する姿勢を強調している。</p>
<h2>小売事業者向けのAIツール群もあわせて提供</h2>
<p>GoogleはUCPと並行して、小売事業者向けのAIツールも発表した。検索上でブランドと対話できる「Business Agent」をはじめ、AIエージェントが商品情報や条件を正確に理解するためのデータ拡張、Google AdsやCommerce製品との連携機能などが含まれる。</p>
<p>これらの機能は、まず米国の一部小売事業者から段階的に提供される予定としている。</p>
<h2>検索・広告・ECを横断する再設計</h2>
<p>今回の発表は、単一の新製品や機能にとどまらず、検索、広告、コマースをAIエージェント前提で再設計するGoogleの方向性を示すものとなった。</p>
<p>Googleは、UCPを軸としたオープンなエコシステムを通じて、AIが購買の主体となる時代における小売体験の基盤づくりを進めるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Google、Gemma 3基盤の翻訳モデル群「TranslateGemma」を発表―—55言語対応のオープン翻訳AI、軽量モデルから高精度モデルまで提供</title>
      <link>https://ledge.ai/articles/google_translategemma_gemma3_open_translation_models</link>
      <description><![CDATA[<p>Googleは2026年1月15日（現地時間）、同社のオープン基盤モデル「Gemma 3」をベースにした翻訳特化モデル群「TranslateGemma」を<a href="https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/">発表</a>した。55の言語を対象とし、効率と精度を両立したオープンな機械翻訳モデルとして公開された。研究者や開発者が自由に利用できるオープンウェイトモデルとして公開される。</p>
<p>Googleによると、TranslateGemmaは大規模言語モデルを汎用的に利用するのではなく、翻訳タスクに特化した学習と最適化を行うことで、精度と計算効率の両立を図った点が特徴だという。</p>
<p><strong>■ TranslateGemmaは、4B・12B・27Bの3つのパラメータサイズで提供され、デバイスや用途に応じた翻訳モデルの選択が可能とされている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/translategemma_9695a89365/translategemma_9695a89365.jpg" alt="translategemma.jpg" /></p>
<h2>3つのモデルサイズを提供</h2>
<p>TranslateGemmaは用途に応じて選択可能な複数のモデルサイズで構成されている。
比較的軽量なモデルはエッジデバイスやローカル環境での利用を想定しており、一方で大規模モデルはGPU環境での高精度翻訳を前提としている。Googleは、中規模クラスのモデルでも高い翻訳品質を実現しているとしている。</p>
<p><strong>■  言語ファミリー別の翻訳エラー率比較。TranslateGemma 12Bは、多くの言語群でGemma 3 27Bに近い、またはそれを下回るエラー率を示している</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b/01_14_Chart_v3_width_1000_format_webp_ca763b5b1b.webp" alt="01-14_Chart_v3.width-1000.format-webp.webp" /></p>
<h2>日本語を含む55言語に対応</h2>
<p>対応言語には日本語を含む主要言語に加え、これまで翻訳リソースが限られていた中・低リソース言語も含まれる。Googleは、多言語対応を通じて研究用途や地域特化サービスへの応用を促進したい考えだ。</p>
<h2>マルチモーダル能力も継承</h2>
<p>TranslateGemmaは、基盤となるGemma 3の設計を引き継ぎ、テキスト翻訳に加えて画像内テキストの翻訳など、マルチモーダルなユースケースにも対応可能とされている。これにより、文書画像やスクリーンショットを含む翻訳処理にも応用できるという。</p>
<h2>オープンウェイトとして公開</h2>
<p>モデルの重みはオープンに提供され、開発者はローカル環境やクローズドなシステム内で翻訳モデルを実行・調整できる。Googleは、クラウド依存を避けたいケースや、特定ドメイン・言語ペア向けのカスタマイズ需要を想定している。</p>
<p>GoogleはTranslateGemmaについて、研究用途だけでなく、プロダクトや業務システムへの組み込みなど、幅広い活用を見込んでいるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Google検索の「AIによる概要」、健康関連クエリで一部非表示に―—英ガーディアン調査で判明</title>
      <link>https://ledge.ai/articles/guardian_google_ai_overviews_health_queries_hidden</link>
      <description><![CDATA[<p>Google検索に表示される「AIによる概要（AI Overviews）」が、健康・医療関連の検索クエリにおいて誤解を招く情報を提供していたことが、2026年1月26日の<a href="https://www.theguardian.com/technology/2026/jan/11/google-ai-overviews-health-guardian-investigation">英紙ガーディアンの調査</a>で明らかになった。これを受け、Googleは一部の検索結果で同機能を非表示にしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_guardian_9ac7ce5634/the_guardian_9ac7ce5634.jpg" alt="the guardian.jpg" /></p>
<h2>Google検索の「AIによる概要」とは</h2>
<p>「AIによる概要」は、検索クエリに対してAIが複数の情報源をもとに要点を要約し、検索結果ページの上部に表示する機能だ。通常の検索結果リンクよりも上位に表示されることから、検索体験の効率化を目的として導入されている。</p>
<p>一方で、表示位置の特性上、内容が利用者の判断に与える影響が大きい点も指摘されてきた。</p>
<h2>健康関連クエリで指摘された問題</h2>
<p>調査報道でガーディアンは、Googleの「AIによる概要」が健康・医療分野の検索クエリにおいて、不正確または文脈を欠いた情報を提示している事例があると報じた。</p>
<p>同紙によると、疾患や検査値に関する説明が一般化されすぎており、年齢や既往歴などの前提条件を十分に考慮していないケースが確認されたという。こうした要約が検索結果の最上部に表示されることで、利用者が内容を過度に信頼し、誤った自己判断につながる可能性がある点が問題視された。</p>
<p>ガーディアンは、医療情報のように解釈に専門性が求められる分野では、AIによる要約が誤解やリスクを生む恐れがあると伝えている。</p>
<h2>Googleの対応</h2>
<p>この報道を受け、米テックメディア The Vergeは、Googleが一部の健康・医療関連検索クエリについて「AIによる概要」の表示を停止していると報じた。</p>
<p>The Vergeによると、該当する検索では従来どおり検索結果リンクは表示される一方、AIによる要約のみが表示されない状態になっているという。Googleは、医療分野のようなセンシティブな領域では、情報の正確性と安全性を重視した対応を取っているとされる。</p>
<p>同メディアは、今回の措置がすべての健康関連クエリに一律で適用されているわけではなく、限定的な対応である点にも言及している。</p>
<h2>背景</h2>
<p>医療・健康分野は、検索エンジンにおいて利用者の生活や生命に直接影響を与え得る情報を扱う領域とされている。AIによる要約は利便性を高める一方、情報の切り取り方次第で誤解を招くリスクを内包している。</p>
<h2>今後の焦点</h2>
<p>今後は、健康・医療といった高リスク分野において、AI要約をどの範囲で表示するのか、また品質管理や表示基準をどのように設計するのかが焦点となる。Google検索におけるAI活用のあり方が、引き続き注目される。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>AIの進化を支え続けるNVIDIA　グラフィックス企業からAIインフラの巨人への軌跡</title>
      <link>https://ledge.ai/articles/interview_nvidia</link>
      <description><![CDATA[<p>現在の生成AIブームを、NVIDIAの存在を抜きに語ることはできないだろう。同社のGPUはAIモデルの学習と推論を支える心臓部となり、その圧倒的な市場シェアは、単なる半導体メーカーという枠を超えた、巨大な影響力を物語っている。しかし、その成功は単一の技術的勝利ではなく、2006年のCUDAに始まり、現在に至るまで一貫して貫かれる「開発者中心のプラットフォーム戦略」という強固な哲学の結晶である。</p>
<p>今回、その軌跡を紐解くために話を伺ったのは、NVIDIAでテクニカルマーケティング マネージャーを務める澤井理紀氏だ。同社に15年間在籍し、グラフィックスが事業の中心であった時代から、AIへの歴史的な大変革を社内で目撃してきた。彼の言葉から、NVIDIAがAI時代の覇者となり得た必然性を探る。</p>
<p>※インタビューは2025年11月26日にエヌビディア合同会社の会議室で行われた。</p>
<h2>「偶然」ではないAIへの転換。すべては開発者コミュニティから始まった</h2>
<p>NVIDIAの今日の成功を理解するためには、同社がAIブームの遥か以前から、いかに戦略的な布石を打ってきたかを振り返ることが不可欠だ。その軌跡は、偶然の産物ではなく、開発者コミュニティの声に真摯に耳を傾け、未来への投資を続けた結果であった。</p>
<h3>グラフィックスから汎用計算へ：研究者たちの「ハック」が示した新たな可能性</h3>
<p>NVIDIAの歴史は、1999年に発表したGPU（Graphics Processing Unit）から本格的に始まる。当初、その用途はゲームや3D CGといったグラフィックス処理に限定されていた。しかし2000年代初頭、一部の科学技術計算の研究者たちの間で、グラフィックス描画用のAPIをいわば「ハック」する形で、自身の研究における膨大な並列計算にGPUを応用する動きが生まれたのだ。</p>
<p>澤井氏は当時をこう振り返る。「グラフィックス用のAPIを無理やり自分の計算に当てて動かす、というハックのような動きがありました。我々はそうした研究者の動きをちゃんと理解していて、グラフィックス以外にもGPUのニーズがあるということに目をつけたのです」。この開発者コミュニティの小さな、しかし熱量の高い動きこそが、NVIDIAの運命を大きく変える最初の兆候だったのである。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_v2_330ed396a8/image2_v2_330ed396a8.jpg" alt="image2_v2.jpg" /></p>
<h3>決定的な一手「CUDA」の誕生とエコシステムの構築</h3>
<p>その新たな可能性に応えるべく、NVIDIAは2006年に歴史的な一手「NVIDIA CUDA」を発表する。これは、GPUをグラフィックス以外の汎用的な並列計算に利用するための統合開発環境であり、同社の歴史における極めて重要な戦略的転換点となった。</p>
<p>CUDAが画期的だったのは、C言語ベースのプログラミング言語やコンパイラ、デバッガといった開発に必要なツール一式を提供したことだ。これにより、それまで一部の研究者の「ハック」に過ぎなかったGPUの汎用計算が、公式にサポートされるようになった。澤井氏は、「CUDAを使えば、スーパーコンピューターでなくても、手元のPCで科学計算を動かすことができた」と語る。高価なスパコンを必要とせず、誰もが購入できるコンシューマー向けGPU「NVIDIA GeForce」で高度な並列計算が実行できるようになったことで、世界中の研究者や開発者がNVIDIAのプラットフォームに集結した。これが、今日まで続く巨大な開発者エコシステムの礎となったのである。</p>
<h3>AlexNetの衝撃とジェンスン・フアンCEOの強力なリーダーシップ</h3>
<p>CUDAによって築かれた土壌の上で、AIという新たな芽が育ち始める。その萌芽は2011年に見られた。NVIDIAの研究者が、スタンフォード大学と共同で、わずか12基のGPUを使い、Googleが2000台のCPUで実現した猫の顔認識プロジェクト「Google Brain」と同等の成果を叩き出したのだ。</p>
<p>そして翌年、その可能性は決定的な形で証明される。画像認識の国際コンテスト「ILSVRC」において、トロント大学のジェフリー・ヒントン教授の研究室に所属していたアレックス・クリジェフスキー氏が開発した「AlexNet」が、2枚のコンシューマー向けGPUを駆使して他のチームを圧倒的な精度で打ち破り、優勝したのだ。この出来事は、ディープラーニングのブレークスルーとして歴史に刻まれ、GPUがAI研究のデファクトスタンダードとなる引火点となった。</p>
<p>この好機を逃さなかったのが、創業者/CEOのジェンスン・フアン氏だ。澤井氏によれば、フアン氏はAlexNetの衝撃を受け、「これからはソフトウェアがソフトウェアを作る機械学習の時代が来る」と確信し、会社全体の舵をAIへと大きく切っていった。ここに、NVIDIAを単なる高性能チップメーカーからAI時代の覇者へと押し上げた、ジェンスン・フアン氏の経営者としての真骨頂が見える。</p>
<p>研究者の「ハック」から始まり、CUDAによるエコシステムの構築、そしてAIの可能性を確信した経営陣の強力なリーダーシップへ。NVIDIAの過去の歩みは、一貫して「開発者中心のプラットフォーム戦略」に貫かれている。こうして築かれたAIにおける圧倒的優位性も、半導体技術の物理的限界という新たな壁に直面する。NVIDIAは、過去の成功方程式であった「チップ性能の向上」から、より包括的な戦略へと舵を切る必要に迫られたのだ。</p>
<h2>チップ性能の先へ。プラットフォーム全体で最適化する「Co-design」戦略</h2>
<p>半導体のプロセス微細化といった単一の指標だけでは、NVIDIAの現在の競争優位性を測ることはできない。同社の真の強みは、ハードウェアの性能を極限まで引き出すための、より包括的なアプローチ「Co-design」戦略にある。</p>
<p>「いわゆるムーアの法則は終焉に近づいています」と澤井氏は指摘する。かつてのように、プロセス微細化だけで劇的な性能向上が見込める時代は終わった。この課題に対し、NVIDIAはアルゴリズムからソフトウェア、GPUアーキテクチャ、システム、そしてデータセンター全体に至るまでを統合的に設計する「Co-design」というアプローチで応えている。</p>
<p>その象徴的な例が、最新のBlackwellアーキテクチャだ。驚くべきことに、Blackwell世代のGPUは、前世代のHopperと同じ半導体プロセスで製造されている。しかし、澤井氏によれば、「プラットフォームを刷新することで、Hopperの10倍の電力効率を実現」しているという。これは、プロセス微細化に依存せず、システム全体の最適化によって性能の壁を突破できることを証明している。この「Co-design」は、かつてCUDAでソフトウェアとハードウェアを統合し開発者エコシステムを築いた成功体験の、現代における正統進化と言えるだろう。</p>
<h3>量子コンピュータとフィジカルAIへの貢献</h3>
<p>NVIDIAの戦略の根底には、「エンドプロダクトを自社で作るのではなく、それらを開発する人々を支援するプラットフォームを提供する」という一貫した哲学がある。澤井氏はこれを自動車業界に例えて説明する。</p>
<p>「我々は自動運転技術を開発していますが、自社で車は作っていません。自動車メーカーの開発を支援しているのです。それと同じように、量子コンピュータ自体は作りません。量子コンピュータを作りたい人の計算を加速するのです」</p>
<p>この思想は、同社が設立した「NVAQC (NVIDIA Accelerated Quantum Research Center)」にも表れている。NVIDIAは自ら量子コンピュータを開発するのではなく、既存のAIスーパーコンピュータ上で量子コンピュータの研究開発をシミュレーションし、加速させる役割を担う。</p>
<p>同様のアプローチは、ロボティクスや自動運転といった「フィジカルAI」の分野でも貫かれている。シミュレーションプラットフォームである「NVIDIA Omniverse」や「NVIDIA Isaac Sim」、エッジデバイス用の「NVIDIA Jetson」などを提供し、産業全体の進化を支援する。あくまで黒子に徹し、あらゆるイノベーターたちのためのインフラとなることが、NVIDIAの戦略の核なのだ。</p>
<p>AIへの長期的な投資は、今や明確な成果となって表れている。2020年の第2四半期には、データセンター部門の売上が、長年同社の屋台骨であったゲーミング部門を初めて逆転。これは、NVIDIAが名実ともにAIインフラ企業へと変貌を遂げた象徴的な出来事だった。しかし、社内でこのマイルストーンが盛大に祝われることはなかったという。なぜなら、データセンター部門の目標は「ゲーミング部門を超えることではなく、とんでもなく大きな目標があったから」だ。このエピソードは、NVIDIAが当時から既に、過去の事業を遥かに超える未来を見据えていたことを物語っている。</p>
<p>その注力領域は、今やロボティクスや自動運転といった花形分野にとどまらない。澤井氏は、「ヘルスケアやテレコムといった領域にも全方位で注力している」と語る。特定の産業に偏ることなく、あらゆるバーティカル市場でAI活用を推進する姿勢は、同社のプラットフォーム戦略がいかに広範な応用可能性を持つかを示している。</p>
<p>チップ性能の追求から、システム全体を最適化するプラットフォーム戦略へ。NVIDIAの現在の姿は、開発者中心という哲学を現代的に昇華させたものだ。現在のプラットフォーム戦略は、単に今日のAIを動かすに留まらない。それは、量子やフィジカルAIといった「まだ見ぬ未来」のイノベーションすらも自社のエコシステムに取り込むための、壮大な布石なのである。NVIDIAの視線は、もはや現在のAIの先、次なる産業革命の基盤そのものに向けられている。</p>
<h2>AIは「バブル」ではない、「始まり」に過ぎない</h2>
<p>市場の一部では、現在の熱狂を「AIバブル」と懸念する声も囁かれる。しかし、インフラの最前線から未来を見据えるNVIDIAにとって、今はバブルどころか、壮大な物語の「始まり」に過ぎない。</p>
<h3>金融市場と技術進化の切り分け</h3>
<p>「AIバブル」という言葉について、澤井氏は冷静な視点を示す。「金融的な評価がバブルかどうかは分かりません。しかし、AIという技術自体がバブルではないことには、全く疑いの余地がありません」。これは、市場の短期的な評価と、社会に不可逆的な変化をもたらす基盤技術の進化とは、明確に切り分けて考えるべきだというNVIDIAの姿勢を物語っている。AIが社会に浸透し、当たり前に使われる未来は揺るぎないという確信がそこにはある。</p>
<h3>新たな産業革命「AIファクトリー」構想</h3>
<p>ジェンスン・フアンCEOは、AIがもたらす未来を「AIファクトリー」というビジョンで表現している。これは、データセンターが単なる計算施設ではなく、データを原材料として「知能」を生成する工場へと変貌するという構想だ。あらゆる企業が、自社の日々の業務データを「AIファクトリー」に入力し、そこから生み出されたインテリジェンス（知能）を活用して事業を革新していく。NVIDIAは、AIを一時的なブームではなく、社会基盤そのものを根底から作り変える、新たな産業革命と捉えているのだ。</p>
<h3>変わらぬ原点：すべての開発者のために</h3>
<p>企業規模が拡大し、巨大テック企業との取引が増える中で、「NVIDIAはもはや大企業だけを相手にするのではないか」という声も聞かれる。この問いに対し、澤井氏の答えは明確だ。NVIDIAのDNAは、創業以来変わっていない。</p>
<p>「2006年にCUDAを作った時も、ハイパフォーマンスコンピューティング用のGPUに限定せず、コンシューマー向けのGeForceでも動くようにしました。それによって開発者が手軽に利用できるようになったのです。我々はそのことを覚えています」</p>
<p>大規模なデータセンターから個人のPCに至るまで、あらゆる規模の「開発者をサポートする」という姿勢こそが、NVIDIAの揺るぎない原点であり、強固なエコシステムを維持し続ける力の源泉なのだ。この哲学は今後も変わることはない。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image4_v2_0fa05944cd/image4_v2_0fa05944cd.png" alt="image4_v2.png" /></p>
<h3>次のブレークスルーとNVIDIAの役割</h3>
<p>現在主流のTransformerモデルの次に来る、革新的な技術は何だろうか。この問いに対し、澤井氏は「それは誰にも分かりません」と率直に認める。未来の不確実性を受け入れた上で、彼はNVIDIAの使命をこう語る。</p>
<p>「我々の役割は、AIの進化に向けて、どのような技術が登場しても対応できる、最先端のプラットフォームを構築し続けることです」</p>
<p>特定のアルゴリズムに賭けるのではなく、あらゆるイノベーションが花開くための最高の土壌を用意し続けること。それこそが、AIインフラの巨人としてNVIDIAが自らに課した役割なのである。</p>
<p>AIの概念が生まれて70年。我々は今、新たな産業革命の入り口に立っている。その不確実で、しかし可能性に満ちた未来に向かっていく上で、これからもNVIDIAが支える技術進化に期待したい。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>日本・ASEAN、「信頼できるAI」推進で共同声明──デジタル大臣会合で協力深化</title>
      <link>https://ledge.ai/articles/japan_asean_trustworthy_ai_joint_statement_2026</link>
      <description><![CDATA[<p>総務省は2026年1月15日、日本とASEAN（東南アジア諸国連合）が、安全・安心で信頼できるAIの推進に向けた共同声明を採択したことを<a href="https://www.soumu.go.jp/menu_news/s-news/01tsushin09_02000190.html">発表</a>した。ベトナムで開催された第5回 日ASEANデジタル大臣会合で合意したもので、日本とASEANがAI分野に関する大臣共同声明を発出するのは初めてとなる。</p>
<p>会合ではあわせて、今後1年間の協力方針をまとめた「日ASEANデジタルワークプラン2026」も承認された。</p>
<h2>日ASEANデジタル大臣会合で共同声明を採択</h2>
<p>ベトナムで開催された日ASEANデジタル大臣会合には、日本から総務大臣である林芳正氏が出席した。会合は、日本とASEAN各国のICT所管大臣が一堂に会し、デジタル分野における協力方針を決定する唯一の閣僚級会合と位置づけられている。</p>
<p>今回の会合では、ホスト国であるベトナムの閣僚とともに林総務大臣が共同議長を務め、
日ASEANデジタルワークプラン2026
安全、安心で、信頼できるAIの推進に関する日ASEANデジタル大臣共同声明</p>
<p>の2つが正式に承認・採択された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/asean_japan_statement_7be3e05969/asean_japan_statement_7be3e05969.jpg" alt="asean japan statement.jpg" /></p>
<h2>「信頼できるAI」を軸に協力を深化</h2>
<p>採択された共同声明は、AIの開発・導入・利用の各段階において、安全性・信頼性・安心感を確保することを基本方針としている。日ASEAN間でAI協力を深化させることで、各国のAIエコシステムの発展とともに、グローバルなAIエコシステムの構築に貢献する考えを示した。</p>
<p>AIをめぐっては国際的な開発競争が激化する一方、安全性やガバナンスをどう確保するかが共通課題となっている。今回の声明は、そうした状況を踏まえ、日ASEANが協調して取り組む姿勢を明確にしたものといえる。</p>
<h2>ガバナンスから人材育成まで、声明が示した協力分野</h2>
<p>共同声明では、信頼できるAIの推進に向け、幅広い協力分野が整理された。</p>
<p>ガバナンス面では、広島AIプロセスの国際行動規範を踏まえ、AIシステムの安全性・セキュリティ・信頼性の強化を進めるとした。各国の制度整備に向けた協力や、ガバナンスの相互運用性を高めるための連携も盛り込まれている。</p>
<p>開発・インフラ分野では、各国の文化や価値観、言語を尊重したAIモデルの開発協力や、AI関連インフラ整備での連携を明記した。また、ASEANにおけるAI安全性ベンチマークや評価手法の取組を担うWG-AI（AIガバナンス作業部会）との連携強化、ASEAN AI安全ネットワークに関する協力も掲げられている。</p>
<p>人材育成・能力構築では、AI分野の能力構築や技術移転、若手AI開発者の育成に向けた協力を通じ、各国におけるローカルなAIエコシステムの構築と発展に貢献するとした。</p>
<p>さらに、AIソリューションの共創として、各国のAI活用事例を共有し、社会課題の解決に資するAIの利活用を進める方針を示した。プライバシーやデータガバナンス、知的財産の尊重、偽情報や情報操作への対応など、包摂的で信頼できるAIの推進も盛り込まれている。</p>
<h2>ワークプラン2026で示された具体的な協力施策</h2>
<p>日ASEANデジタルワークプラン2026は、今後1年間の協力・連携施策を整理したものだ。AI分野では、各国における大規模言語モデル（LLM）の開発や人材育成に関する協力、ASEANのAIエコシステム構築に向けた取組が位置づけられている。</p>
<p>このほか、サイバーセキュリティ分野における能力構築支援の拡充や、オープンRANの普及促進を通じたデジタルインフラ整備など、AI以外の分野についても協力を進める方針が示された。</p>
<h2>日本とASEAN、AI協力を実装フェーズへ</h2>
<p>今回の共同声明とワークプランの承認により、日ASEANのAI協力は理念共有の段階から、具体的な取組を進める実装フェーズへと移行することになる。各国の状況やAIエコシステムを尊重しつつ、地域全体として安全・安心で信頼できるAIの活用を広げていく。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>LLMは日本の司法試験を突破できるのか──慶應義塾大研究、短答式で合格点に到達</title>
      <link>https://ledge.ai/articles/llm_japanese_bar_exam_self_verification</link>
      <description><![CDATA[<p>慶應義塾大学の研究者は2026年1月6日、日本の司法試験（短答式）において、大規模言語モデル（LLM）が実際の出題形式と公式の採点基準を変更せずに、合格水準の得点を記録したとする研究成果を<a href="https://arxiv.org/abs/2601.03144">発表</a>した。出題を簡略化せず、採点ルールも変更しない条件下で合格水準に達した例は、研究チームによると初めてだという。</p>
<h2>評価を変えずに測る──「日本の司法試験」という高い壁</h2>
<p>研究の対象となったのは、日本の司法試験における短答式試験である。短答式は多肢選択式ではあるものの、単純な一問一答ではなく、複数の命題を同時に評価し、その正誤の組み合わせ全体を一つの解答として選択させる形式を取る。</p>
<p>採点は厳格で、部分点は存在するものの、複数の命題がまとめて評価されるため、1つの判断ミスで大きく減点され、条件によっては0点となる。さらに、合否判定には総合点に加え、憲法・民法・刑法の各科目で40％以上の得点を求める要件が設けられている。</p>
<p>従来のAI研究では、こうした設問を○×形式に分解して学習・評価する手法が多く用いられてきた。しかしこの場合、本来の組み合わせ評価や採点ルールが再現されず、実際の試験形式で通用するかは不明確だった。同研究は、評価方法を簡略化せず、実試験と同一条件で検証する点を特徴としている。</p>
<h2>自己検証を用いた単一モデルによるアプローチ</h2>
<p>同研究を主導したのは、Andrew Shin氏で、成果は論文「Self-Verification is All You Need To Pass The Japanese Bar Examination」として公開されている。</p>
<p>研究では、OpenAIのGPT-4.1をベースモデルとし、日本の司法試験短答式の過去問を用いてファインチューニングを行った。特徴的なのが、「自己検証（Self-Verification）」と呼ばれる手法だ。</p>
<p>モデルはまず通常どおり解答を生成し、その後、同一モデルが別のプロンプトを用いて自らの解答を再確認する。この追加推論は1回のみで、外部ツールや別モデルは使用しない。再検証の段階では、形式的な誤りや明確な不整合がある場合に限り、保守的に修正を行う設計となっている。</p>
<p>研究では、マルチエージェント型の推論手法や、問題分解型データセット（JBE-QA）を用いた手法とも比較を行ったが、いずれも単一モデル＋自己検証の成績を下回ったとしている。</p>
<h2>検証結果の位置づけ</h2>
<p>2024年（令和6年）司法試験の短答式問題を用いた評価では、自己検証を組み込んだモデルが平均94.7点、最高96点を記録した。同年の合格基準は93点であり、科目別の最低得点要件も満たしている。一方、GPT-4.1をそのまま用いたゼロショット推論や、問題分解型の手法では合格水準に達しなかった。</p>
<p>もっとも、同研究は短答式試験に限定した検証であり、論文式（記述式）試験や、実務における法的判断能力を示すものではない。論文でも、その点については明確に留保が付されている。</p>
<p>同研究は、日本の司法試験という厳格な形式を対象に、評価条件を変更しない形でLLMの到達点を検証した事例として位置づけられる。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>日本テレ自社開発のオンデバイスAI「viztrick AiDi」、NBC Sportsでライブ中継への採用が決定</title>
      <link>https://ledge.ai/articles/ntv_viztrick_aidi_nbc_sports_live_adoption</link>
      <description><![CDATA[<p>日本テレビ放送網株式会社は、自社開発した直感的オンデバイスAIソリューション「viztrick AiDi」が、米国の大手スポーツ放送ネットワークであるNBC Sportsに採用されたと<a href="https://tech.ntv.co.jp/news/nbc-sports-release/">発表</a>した。2026年以降、NBC Sportsが手がける複数のライブスポーツ中継での利用が予定されている。</p>
<p>「viztrick AiDi」は、放送現場での実運用を前提に設計されたオンデバイス型AIソリューションで、ネットワーク接続に依存せず、低遅延でリアルタイム処理を行える点を特徴とする。ライブ映像から被写体となる選手を自動で抽出・追従し、スマートフォン視聴を想定した縦型（9:16）映像として即時に切り出すことが可能だ。</p>
<p>近年、スポーツコンテンツの視聴はテレビ放送に加え、スマートフォンを中心としたデジタル配信が急速に拡大している。NBC Sportsでは、モバイル視聴に最適化された映像を効率的に制作する手法を模索しており、従来は人手によるカメラ操作や編集作業が必要だった。こうした課題に対し、放送現場で即応できる「viztrick AiDi」のオンデバイス処理と直感的な操作性が評価され、採用に至ったとしている。</p>
<p>NBC Sportsの技術部門シニア・バイスプレジデントであるティム・カナリー氏は、ライブスポーツのストリーミング配信において、アスリートを自動追従しながら縦型映像をリアルタイムで生成できる点を重視したとコメントしている。特に、低遅延で安定した処理が可能な点が、ライブ中継用途に適していると判断したという。</p>
<p>日本テレビ側は、世界有数のスポーツ放送事業者であるNBC Sportsに技術が採用されたことを、グローバル展開に向けた重要な実績と位置付けている。同社は中期経営計画（2025〜2027）で「グローバルコンテンツ企業への変革」を掲げており、海外戦略センター内に設置したTech事業部門を通じて、放送現場発のAI技術を海外市場へ展開していく方針だ。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとソフトバンクグループ、SB Energyに10億ドル投資──「Stargate」構想 1.2GW級データセンター建設を加速</title>
      <link>https://ledge.ai/articles/openai_softbank_sb_energy_stargate_data_center_investment</link>
      <description><![CDATA[<p>OpenAIとソフトバンクグループは2026年1月9日（米太平洋時間）、ソフトバンクグループ傘下の米インフラ企業SB Energyと戦略的パートナーシップを締結し、同社に総額10億ドル（各社5億ドル）を投資すると<a href="https://openai.com/ja-JP/index/stargate-sb-energy-partnership/">発表</a>した。今回の提携は、米国における次世代AI・エネルギー基盤の構築を目的とする「Stargate」構想の一環と位置づけられている。</p>
<p>OpenAIは同社を、テキサス州ミラム郡に計画されている1.2GW規模のデータセンターサイトの建設・運営パートナーに選定。OpenAIはこの初期データセンター構築に向け、1.2GW分のデータセンターリース契約を締結している。今回の出資は、SB Energyが大規模データセンターキャンパスおよび関連エネルギーインフラの開発・実行パートナーとして成長することを支援する狙いがある。</p>
<p>SB Energyは現在、複数のマルチギガワット級データセンターキャンパスを開発中で、最初の施設はすでに建設段階にあり、2026年から順次稼働を開始する予定だという。今回の取り組みは、ホワイトハウスで1月に発表された5,000億ドル規模の「Stargate」コミットメントを基盤とするものだ。</p>
<p>今回の取引の一環として、OpenAI、ソフトバンクグループ、SB Energyの3社は、非独占の優先パートナーシップも締結した。OpenAIの自社設計によるデータセンターと、SB Energyのスピード、コスト管理、統合型エネルギー供給の知見を組み合わせ、AI専用インフラを大規模に構築する新たなモデルの開発を目指すとしている。SB Energyは各プロジェクトを通じて、雇用創出や人材育成、送電網の近代化など、地域社会への投資も行う方針だ。</p>
<p>またSB Energyは、データセンター事業の成長を支えるため、データセンター建設管理・調達・設計・運用を手がけるStudio 151を買収した。20以上のデータセンターキャンパスで実績を持つ同社を取り込むことで、開発から運用までの内製能力を強化する。</p>
<p>なお、SB Energyは2025年に、米投資会社Aresから8億ドルの償還可能優先株式による出資を受けており、今回の投資はAresとの長期的な関係をさらに深めるものだとしている。</p>
<p>今回の投資と提携は、AIモデルの開発競争そのものではなく、大規模な計算資源を支える電力・用地・建設能力を含めた「AIインフラ」を確保する動きとして位置づけられる。</p>
<p>Stargate構想のもと、OpenAIとソフトバンクグループは、計算基盤の主導権を中長期で握る体制づくりを進めている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ロボット開発の“データ不足”をどう埋める？Pantographが数千台規模の「幼稚園」構想を提示</title>
      <link>https://ledge.ai/articles/pantograph_robot_preschool_data_collection</link>
      <description><![CDATA[<p>米ロボティクス企業のPantographは2026年1月、ロボット開発における深刻な「データ不足」の課題に対する新たなアプローチとして、「ロボットのための幼稚園（preschool for robots）」と名付けた構想を公式<a href="https://pantograph.com/blog/building-a-preschool-for-robots.html">ブログ</a>で明らかにした。探索・失敗・継続的な改善を通じて、ロボット自身が現実世界で学習データを収集する環境を構築するという。</p>
<h2>実世界のデータが不足するロボティクス領域</h2>
<p>Pantographによると、近年急速に進歩した深層学習分野の多くは、言語モデルや画像生成のように、インターネット規模の豊富なデータを利用できた領域に集中している。一方、ロボティクスでは同等の大規模データセットが存在せず、学習に必要なデータを一から作り出す必要があるという。</p>
<p>特に、動画だけでは推定が難しい素材の物性――質感、粘性、密度、曲げたときの感触、物同士を擦り合わせた際の挙動など――は、実際に触れて試すことでしか得られない情報だと説明している。</p>
<h2>「ロボットの幼稚園」で探索をスケール</h2>
<p>同社が提示した解決策が、「ロボットのための幼稚園」構想だ。初期フェーズでは、数千台規模の小型で低コストなロボットを用意し、実世界で自由に探索させる。ロボットは物を掴む、投げる、擦る、積み上げるといった行動を繰り返しながら、周囲の環境についての内部表現を徐々に構築していく。</p>
<p>Pantographは、このように多様で大規模な実世界データを蓄積することで、未知のタスクにも対応できる汎用的なモデルの学習につなげる狙いだとしている。また、ロボットは外界だけでなく、自身のハードウェア特性や癖についても学習し、人が操作するよりもロボット自身に適した制御モデルを獲得できるとする。</p>
<h2>幼稚園フェーズに最適化した小型ロボット</h2>
<p>構想とあわせて、同社は「ロボットの幼稚園」を前提に設計した自社ハードウェアの早期プレビューも公開した。小型で低重心の設計とすることで、製造コストを抑え、量産や交換を容易にするほか、学習初期の失敗による破損リスクを低減する狙いがある。</p>
<p>実世界での探索では耐久性が重要になるとして、Pantographはハードウェアを自社設計し、部品レベルでの検証を重ねてきたという。これまでに、重要部品について1万時間を超える社内のストレス試験・耐久試験データを蓄積しているとしている。</p>
<p>移動機構には車輪ではなくクローラ（履帯）を採用し、安定性や走破性、モーター効率を重視した。製造面では、打ち抜き加工やレーザーカット、板金曲げといった2次元加工を活用する「オリガミ」的設計により、材料効率と量産性を高めている。</p>
<h2>強度・器用さ・工具使用のデモを公開</h2>
<p>公開されたデモでは、小型ながらも一定の強度と操作性を備える点が示された。ロボットのアームは、伸ばした状態でそれぞれ約1キログラムの連続ペイロードに対応し、より重い物体を動かす例も紹介されている。</p>
<p>また、結束バンドの接続やUSBケーブルの挿入、木製ブロックを用いた構造物の組み立てといった細かな操作や、ハサミや電動ドライバー、ラベルライターなど、人間向けに設計された工具を扱う様子も示された。これらのデモデータは、シンプルなテレオペレーション環境を用いて収集されたものだとしている。</p>
<p><strong>■ シンプルな遠隔操作のセットアップ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/teleop_image_2156096eb1/teleop_image_2156096eb1.jpeg" alt="teleop_image.jpeg" /></p>
<h2>数千台規模への拡大と未踏の研究課題</h2>
<p>Pantographは今後、数カ月以内にロボットの台数を数千台規模へと拡大し、信頼性や製造性、能力の向上に向けた反復的な改良を進める計画だ。あわせて、ロボットを継続的に稼働させながらデータ収集を行う体制を構築するとしている。</p>
<p>研究面では、どのようなタスク分布が適切か、事前学習をどう組み込むか、学習したモデルをどのように制御・誘導するかなど、多くの未解決課題が残されているとし、これらはまだ大規模に検証されたことのない領域だと位置付けている。</p>
<p>同社は、こうした取り組みを通じて、人間の作業能力や創造性を拡張する汎用ロボットの実現を目指すとしており、現在エンジニアや研究者の採用も進めている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>リコー、「文書×AI」を現場仕様に──Qwen2.5-VL-32B基盤、視覚データ60万枚でチューニング</title>
      <link>https://ledge.ai/articles/ricoh_multimodal_llm_qwen25_vl_32b_business_documents</link>
      <description><![CDATA[<p>リコーは2026年1月8日、中国Alibaba Cloudが開発・提供する大規模言語モデル（LLM）ファミリーの「Qwen2.5-VL-32B-Instruct」をベースに、日本企業の図表を含む業務文書の読み取りに対応したマルチモーダル大規模言語モデル（LMM）を開発したと<a href="https://jp.ricoh.com/release/2026/0108_2">発表</a>した。今後、「RICOH オンプレLLMスターターキット」に搭載し、オンプレミス環境での提供を予定している。</p>
<p>開発されたLMMは、文字情報に加え、円グラフ、棒グラフ、フローチャートなど、ビジネス文書で一般的に用いられる視覚情報を同時に理解できる点が特徴だ。企業内に蓄積された文書を対象に、検索にとどまらない高度な利活用を実現することを目的としている。</p>
<h2>顧客フィードバックを反映し、より実務向けの構成に</h2>
<p>リコーは、経済産業省と国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）が推進する生成AI開発力強化プロジェクト「GENIAC（Generative AI Accelerator Challenge）」第2期において、マルチモーダルLLMの開発に取り組み、700億パラメータの基本モデルを無償公開してきた。</p>
<p>今回のLMMは、そうした取り組みの中で得られた顧客からのフィードバックを踏まえ、サービング環境の構築の容易さや利活用のしやすさを重視し、よりコンパクトで高性能、かつアプリケーションとの親和性が高い構成とした点が特徴となる。あわせて、4bit量子化モデルも提供するとしている。</p>
<h2>視覚データ約60万枚を用いた独自チューニング</h2>
<p>同モデルの学習には、リコーが自社で開発したチューニングデータを使用した。文字情報に加え、円グラフ、棒グラフ、フローチャートなど、ビジネス文書で活用される視覚データ約60万枚を用い、LMMに学習させている。</p>
<p>性能評価には、視覚情報とテキスト情報の双方を参照する日本語質問応答データセット「JDocQA」などのベンチマークツールを用いた。その結果、他モデルと比較しても優れた性能を示すことを確認したとしている。評価は2025年12月17日時点の結果に基づく。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ricoh_qwen2_5vl_b660355681/ricoh_qwen2_5vl_b660355681.jpg" alt="ricoh qwen2-5vl.jpg" /></p>
<h2>企業内文書活用をめぐる課題に対応</h2>
<p>企業内には、請求書や領収書といったトランザクションデータ、経営戦略や事業計画などの経営資料、サービスマニュアルや技術標準、品質管理基準といった技術文書など、多様な形式のドキュメントが蓄積されている。これらにはテキスト情報だけでなく、図表や画像といった視覚情報も含まれる。</p>
<p>一方で、従来の検索手法では意図した情報を十分に引き出せない、検索にとどまった活用に限界があるといった課題が指摘されてきた。加えて、労働力人口の減少、技能・ノウハウ継承、多言語対応といった経営課題が複雑化する中、企業内に蓄積された知識をより高付加価値で活用したいというニーズが高まっている。</p>
<p>リコーは、こうした背景を踏まえ、既存のLLMやLMMでは課題とされてきた、きめ細かな画像認識を必要とするビジネス文書の読解精度に対応するモデルとして、同LMMを位置づけている。</p>
<h2>個別提供に対応、オンプレ環境での展開も視野</h2>
<p>リコーは、同LMMが顧客の要望に応じて個別提供可能としている。今後は「RICOH オンプレLLMスターターキット」に搭載し、リコージャパンから提供する予定だという。同社は画像認識や自然言語処理に加え、音声認識AIの研究開発も進めており、音声対話機能を備えたAIエージェントの提供にも取り組む。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>AGIは来ない、バブルは続かない──スタンフォード大 HAI研究所が示す2026年のAI、過剰期待の時代は終わり、評価フェーズへ</title>
      <link>https://ledge.ai/articles/stanford_hai_ai_2026_evaluation_phase</link>
      <description><![CDATA[<p>巨額投資と急速な技術進展が続いてきたAI分野は、2026年に転機を迎える可能性がある。Stanford Human-Centered AI Institute（HAI）は2025年12月15日（米国時間）、同研究所に所属する研究者らの予測をまとめた記事を<a href="https://hai.stanford.edu/news/stanford-ai-experts-predict-what-will-happen-in-2026">発表</a>し、AIをめぐる議論は「できるかどうか」から「どの程度役に立つのか」を問う評価フェーズへ移行するとの見方を示した。</p>
<p>同記事では、計算機科学、医学、法学、経済学など複数分野の研究者が共通して、過剰な期待や宣伝が先行してきたAI開発のあり方に転換点が訪れていると指摘している。</p>
<h2>AGIは2026年にも実現しない、AI主権が主要テーマに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/James20_Fall202022_aefa4ec674/James20_Fall202022_aefa4ec674.webp" alt="James20Fall202022.webp" /></p>
<p>HAI共同ディレクターで計算機科学教授のJames Landay氏は、2026年に汎用人工知能（AGI）が実現することはないと明言した。その上で、各国が自国のデータや計算資源を管理する「AI主権（AI Sovereignty）」への関心が急速に高まると予測している。</p>
<p>AI主権の形は一様ではなく、自国で大規模言語モデル（LLM）を構築するケースもあれば、他国が開発したモデルを自国内のGPU上で運用し、データを国外に出さない方式も含まれる。HAIでは、こうした複数の主権モデルを整理・分析する研究にも取り組んでいるという。</p>
<p>一方で、世界各地で進む大規模データセンター投資については、投機的な側面も指摘されている。Landay氏は、AI関連投資が無制限に拡大し続けるわけではなく、バブル的な様相が意識される局面に入るとの見解を示した。</p>
<h2>生産性向上は限定的、失敗するAIプロジェクトが増加</h2>
<p>2026年には、AIがもたらす生産性向上について、より冷静な評価が広がるとみられている。プログラミング支援やコールセンター業務など一部の領域では効果が確認される一方、多くのAI導入プロジェクトは期待した成果を上げられない可能性があると指摘された。</p>
<p>その結果、企業や組織は「AIをどこに適用すべきか」という選別を迫られ、成功確率の高い用途に資源を集中させる動きが強まるとみられる。</p>
<h2>巨大モデルの限界と、高品質データ重視への転換</h2>
<p>HAIの研究者らは、モデルの巨大化が必ずしも性能向上につながらなくなりつつある点にも言及している。データの量的枯渇や品質低下が課題となる中、より小規模でも高品質なデータセットを用いたモデル開発への関心が高まると予測されている。</p>
<p>この流れは、計算資源や環境負荷への懸念とも結びつき、AI開発の効率性を重視する方向性を後押しする可能性がある。</p>
<h2>医療・科学分野で進む「ブラックボックス」の解体</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/russ_altman_1_be03daceca/russ_altman_1_be03daceca.webp" alt="russ_altman_1.webp" /></p>
<p>科学・医療分野では、AIモデルの予測精度だけでなく、なぜその結論に至ったのかを説明できることが強く求められるようになる。HAI上級フェローのRuss Altman氏は、高性能なニューラルネットワーク内部を解析し、重要な特徴や判断根拠を明らかにする研究が進展すると見ている。</p>
<p>医療分野では、自己教師あり学習の進展により、大規模かつ高品質な医療データを用いた基盤モデルが登場し、診断精度の向上や希少疾患への応用が広がる可能性も示された。</p>
<h2>法務、経済分野でも「測るAI」へ</h2>
<p>法務分野では、「文章を書けるか」ではなく、正確性やリスク、業務効率への寄与といった具体的な成果を評価する指標が重視される見通しだ。複数文書を横断して推論する高度なタスクに対応するAIの評価手法も整備されつつある。</p>
<p>また、経済分野では、AIが雇用や生産性に与える影響を職種・タスク単位で可視化する「AI経済ダッシュボード」が登場し、政策立案や企業経営に活用される可能性があるとされている。</p>
<h2>人間中心のAI設計が問われる段階へ</h2>
<p>HAIの研究者らは、AIが人間の思考力や判断力、長期的な成長に与える影響にも目を向ける必要があると指摘する。短期的な利便性や満足度ではなく、人間の能力をどのように補完し、育てるのかを前提とした設計思想が、今後のAI開発で重要になると結論づけている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/17 [SAT]XでのGrok画像生成を巡り方針転換──イーロン・マスク氏が規制圧力下で技術的制限に踏み切る、一方米国防省は業務用途でGrok活用へ</title>
      <link>https://ledge.ai/articles/us_war_department_ai_acceleration_strategy_grok_adoption_controversy</link>
      <description><![CDATA[<p>イーロン・マスク氏率いるxAIの生成AI「Grok」を巡り、画像生成・編集機能の運用方針が転換された。</p>
<p>合意のない性的画像生成が国際的な問題として拡大する中、xAIは2026年1月15日、生成AI「Grok」の画像生成・編集機能について、実在する人物の画像を露出の多い服装に編集する行為を技術的に制限したと<a href="https://x.com/safety/status/2011573102485127562">発表</a>した。この制限は、X（旧Twitter）上で提供されているGrokの機能に適用されている。</p>
<p>Grokの画像生成機能は、ユーザーの指示に基づき投稿画像を加工・生成できる点が特徴だったが、第三者の写真を「ビキニ姿にする」といった編集が可能であったことから、非合意の性的表現や未成年への影響を懸念する声が各国で強まっていた。
各国当局が調査・遮断、規制圧力が表面化
問題はSNS上の炎上にとどまらず、各国の規制当局が動く事態へと発展した。
英国では通信・放送規制当局が、Grokによる性的画像生成をめぐりXに対する正式調査を開始。法令違反が確認された場合、制裁金やサービス停止に発展する可能性があるとされた。</p>
<p>また、インドネシアおよびマレーシアでは、合意のない性的コンテンツ生成を理由に、Grokへのアクセスが事実上遮断される措置が取られた。Grokを巡る問題は、複数の法域で同時並行的に扱われる国際的な規制テーマとなっていた。
Xが公式に説明、ビキニ画像生成を技術的に禁止
こうした状況を受け、Xは安全対策として具体的な技術的対応を実施した。
Xのセーフティ公式アカウントは2026年1月、Grokアカウントにおける画像生成・編集機能について、実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したと説明している。</p>
<p><strong>■ Xのセーフティ公式アカウントが公表した、Grokアカウントにおける画像生成・編集機能の制限に関する説明。実在する人物の画像をビキニなどの露出の多い服装に編集する行為を技術的に禁止したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Grok_Account_Image_Generation_Updates_7e8a3c53b0/Grok_Account_Image_Generation_Updates_7e8a3c53b0.jpg" alt="Grok Account Image Generation Updates.jpg" /></p>
<p>この制限は、有料プランを含むすべての利用者に適用されるとしており、運用ルールの明確化ではなく、機能レベルでの制約が導入された形だ。Grokを巡る一連の対応は、マスク氏が掲げてきた比較的自由度の高い生成AI運用からの実質的な方針転換と受け止められている。
一方で米国防省は業務用途での活用を進める
民間向けサービスで制限が進む一方、別の文脈ではGrokの活用が進められている。
米国防省は2026年1月12日、軍事分野におけるAI活用を加速する戦略の中で、全省横断の生成AI基盤にGrokを含める方針を明らかにした。</p>
<p>国防省の戦略では、民間SNSでの利用状況とは切り分け、業務用途としての生成AIを閉域環境で活用することが想定されている。
Grokを巡っては、規制対応と実利用の判断が異なるレイヤーで同時に進んでいる状況だ。</p>
<p><strong>■ 米国防省のピート・ヘグセス長官（左）とxAIのイーロン・マスク氏。ヘグセス長官は2026年1月、テキサス州スターベースを訪問した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_h_O_Icr_Wo_AA_Ia3m_64538f880e/G_h_O_Icr_Wo_AA_Ia3m_64538f880e.jpg" alt="G-hOIcrWoAAIa3m.jpg" /></p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Wikipediaが25周年、AI時代の知識基盤に──MicrosoftやMistral AIなどと新たなパートナーシップ</title>
      <link>https://ledge.ai/articles/wikipedia_25th_anniversary_ai_partnerships</link>
      <description><![CDATA[<p>Wikimedia Foundationは2026年1月15日、オンライン百科事典「Wikipedia」が創設から25周年を迎えたと<a href="https://wikimediafoundation.org/news/2026/01/15/wikipedia-celebrates-25years/">発表</a>した。</p>
<p>これにあわせて、記念キャンペーン「Wikipedia 25」を開始し、ボランティア編集者の活動を紹介する動画シリーズの公開や、AI時代におけるWikipediaの価値を示す取り組みを打ち出した。</p>
<p>Wikipediaは2001年に公開され、誰でも編集に参加できる百科事典として発展してきた。現在では300以上の言語で6500万超の記事を掲載し、月間の閲覧数は約150億回にのぼる。非営利組織によって運営されている点も特徴で、世界で最も利用されているウェブサイトの一つとなっている。</p>
<p>@<a href="https://www.youtube.com/watch?v=C5rPmv27YzY">YouTube</a></p>
<h2>編集者に焦点を当てた公式動画シリーズを公開</h2>
<p>25周年キャンペーンの一環として、ウィキメディア財団は初めて公式の動画ドキュメンタリーシリーズを公開した。世界各地のボランティア編集者8人を取り上げ、Wikipediaの記事がどのように作られ、検証されているのかを紹介している。</p>
<p>Wikipediaのコンテンツは、約25万人の編集者によって執筆・編集・ファクトチェックが行われており、財団は「AI時代においても、信頼できる知識は人によって支えられている」と強調している。</p>
<h2>タイムカプセルや参加型企画も展開</h2>
<p>同日には「<a href="https://wikipedia25.org/ja/">25 Years of Wikipedia</a>」と題したデジタル・タイムカプセルも公開された。創設者のジミー・ウェールズ氏が語る立ち上げ当時のエピソードや、世界的な出来事とWikipediaの関わりを振り返る内容が盛り込まれている。
このほか、Wikipediaの将来像をテーマにしたインタラクティブなクイズなど、利用者が参加できる企画も用意された。</p>
<h2>AI時代の知識基盤としてのWikipedia</h2>
<p>財団は、生成AIの普及が進む中で、Wikipediaの役割が一層重要になっていると位置づける。Wikipediaの記事は、検索エンジンや音声アシスタント、生成AIチャットボットなどで参照・活用されており、高品質な学習データとしても利用されている。公式発表では、Wikipediaが「人間によって作られ、検証された知識の集合体」である点が、AI時代における強みとして示された。</p>
<h2>MicrosoftやMistral AIなどと新たなパートナーシップ</h2>
<p>こうした背景のもと、ウィキメディア財団はWikimedia Enterpriseを通じて、テクノロジー企業との連携を拡大している。
過去1年間で、Microsoft、Mistral AI、Perplexityのほか、Ecosia、Pleias、ProRataといった企業が新たにパートナーに加わった。既存のパートナーにはAmazon、Google、Metaなどが含まれる。
これらの企業は、Wikipediaのコンテンツを大規模に利用できる一方で、非営利モデルを支える形で財団を支援する仕組みとなっている。</p>
<h2>人間中心のAI戦略を継続</h2>
<p>ウィキメディア財団は、AIの活用についても「編集者を支援するための技術」と位置づけており、人間中心のAI戦略を掲げている。編集作業の効率化やアクセシビリティの向上を図りつつ、知識の信頼性を維持することを目的としている。</p>
<p>財団は今後も2026年を通じて、オンラインイベントや各地のコミュニティによる取り組みなど、25周年を記念した活動を継続する予定だとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
  </channel>
</rss>