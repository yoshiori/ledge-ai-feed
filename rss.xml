<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>日本の大手3社、AI検索「Perplexity」に一斉抗議──共同・毎日・産経が著作権侵害と虚偽表示を指摘、47NEWSに数十万回アクセスも</title>
      <link>https://ledge.ai/articles/perplexity_japan_media_protest_20251201</link>
      <description><![CDATA[<p>2025年12月1日、共同通信社、毎日新聞社、産業経済新聞社（産経新聞）は、米Perplexity AIが提供するAI検索サービス「Perplexity」に対し、それぞれ抗議書を送付したと発表した。いずれの会社も、自社記事が許諾なく収集・複製され、回答生成に利用されていると主張している。3社の発表時点で、Perplexity AIによる今回の抗議書に関する公式コメントは確認されていない。</p>
<h2>共同通信社──47NEWSに数十万回のアクセス、虚偽表示も指摘</h2>
<p><a href="https://www.kyodonews.jp/information/ai.html">共同通信社</a>は、配信記事が掲載されているニュースサイト「47NEWS」について、2024年8月以降に数十万回のアクセスが確認されたと説明し、これがPerplexityによる記事収集に関連するとしている。同社は、許諾なく記事を複製・利用する行為は著作権法違反に当たると指摘した。</p>
<p>また、Perplexityが共同通信の社名や記事を表示しながら、記事内容と異なる情報を提示する事例が確認されたとし、こうした表示が不正競争防止法の問題に該当する可能性を示している。</p>
<p>抗議書では、記事の即時利用停止、収集データの開示、無断利用に対する損害賠償などを求めている。共同通信加盟48紙も同日、無断収集・利用に抗議する声明を発表した。</p>
<h2>毎日新聞社──robots.txt無視、ゼロクリック問題を懸念</h2>
<p><a href="https://www.mainichi.co.jp/info/20251201.html">毎日新聞社</a>は、同社のサーバー解析結果として、遅くとも2024年7月以降、記事数十万本が許諾なく収集されたと説明している。同社は、robots.txtを用いた取得拒否設定を行っていたが、Perplexityがこれを無視したとしている。</p>
<p>同社は、行為が著作権法21条（複製権）および23条（公衆送信権）の侵害に当たると主張。さらに、回答画面に毎日新聞の名称や記事を出典として表示しながら、内容と異なる事実が提示されるケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、経緯の報告、損害賠償の支払いを求めており、通知後14日以内の回答を求めている。</p>
<h2>産経新聞社──PerplexityとPro双方での無断利用を指摘</h2>
<p><a href="https://www.sankei.jp/wp-content/uploads/2025/12/2025.12.01-%E7%94%9F%E6%88%90AI%E4%BA%8B%E6%A5%AD%E8%80%85%E3%81%B8%E3%81%AE%E6%8A%97%E8%AD%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6.pdf">産経新聞</a>は、Perplexityおよび「Perplexity Pro」サービスにおいて、自社ニュースサイト「Sankei News」や「Sanspo」に蓄積した記事が無断で複製され、回答生成に利用されていると説明している。</p>
<p>同社は、これらの行為が著作権法21条および23条の侵害に当たると主張。記事内容と異なる情報を示しながら、産経新聞社の名称や記事を出典として表示するケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、関連データの削除などを求めている。</p>
<p>日本の報道機関とPerplexityをめぐっては、2025年8月以降、読売新聞グループ、日本経済新聞社、朝日新聞社などが、記事の無断利用をめぐる損害賠償を求めて提訴している。新聞協会も、ニュースコンテンツの無断取得に関する声明を公表している。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「ChatGPT」は自殺を助長していない──OpenAI、少年自殺訴訟で「ガードレール回避による不適切利用」と反論</title>
      <link>https://ledge.ai/articles/openai_chatgpt_suicide_lawsuit_response_misuse_argument</link>
      <description><![CDATA[<p>OpenAIは、同社の対話型AI「ChatGPT」が10代の少年の自殺を助長したとして提起された訴訟「Raine v. OpenAI」に関し、カリフォルニア州裁判所へ公式な<a href="https://www.medianama.com/wp-content/uploads/2025/11/Raine-v-OpenAI-Answer-11-25-25.pdf">回答書</a>（Answer to Amended Complaint）を2025年11月25日付で提出した。回答書で同社は、少年の死を「壊滅的な悲劇」としつつも、「チャット履歴を全体として読むと、自殺はChatGPTによって引き起こされたものではない」として因果関係を否定した。</p>
<h2>原告側は「自殺を正当化した」と主張</h2>
<p>訴訟は、2025年8月にサンフランシスコ郡上級裁判所へ提起されたもの。原告である遺族は、当時16歳の少年がChatGPT（GPT-4o）との長期的な対話の中で自殺方法の詳細や計画の助長を受けたと主張しており、OpenAIに対して過失・製造物責任・警告義務違反などを訴えている。</p>
<p>訴状では、ChatGPTが
・自殺方法の手順
・未遂時の「失敗理由」の分析
・遺書の下書き
・家族に伝えないよう促すような発言
などを行ったとされ、モデルのガードレール設計や安全プロトコルに欠陥があったと指摘する。</p>
<h2>OpenAI「100回以上、危機支援を促していた」</h2>
<p>OpenAIが裁判所へ提出した回答書では、原告が引用する会話は「文脈を欠いた部分的抜粋にすぎない」と指摘し、同社は完全なチャット履歴を提出したと説明。その上で、ChatGPTが少年との対話中に100回以上、自殺防止ホットラインや信頼できる人物への相談を促していたとし、安全機能は機能していたと主張した。</p>
<p>また回答書では、少年が
・ガードレールに対する不満を繰り返し述べていたこと
・意図を偽り「キャラクター作り」などと説明しつつ、危険な指示を引き出そうとしていたこと
を示す記録があるとし、安全機能の回避行為が存在したと反論した。</p>
<p>さらにOpenAIは、少年には長年にわたる自殺念慮や既往のメンタルヘルス問題があったほか、ChatGPT以外のAIサービスやオンライン情報源からも自殺方法に関する詳細を得ていたとし、「死因は複数の要因によるもので、ChatGPT単独では説明できない」と述べている。</p>
<h2>利用規約違反と「誤用」を強調</h2>
<p>OpenAIは回答書で、「misuse（誤用）」「unauthorized use（無許可利用）」「unintended use（想定外利用）」といった文言を用い、少年の利用は利用規約（Terms of Use）およびUsage Policiesに反するものだったと主張した。</p>
<p>利用規約では、自殺や自傷に関連した用途での利用を禁じており、未成年者については保護者同意なしの利用を禁止している。同社は、少年の利用はこれらに反しており、同社に法的責任を帰すことはできないと訴えている。</p>
<p>また、米通信品位法230条（Section 230）に基づき、ユーザー入力に対する応答についてAIサービス提供者が責任を負わないという法的抗弁も提示している。</p>
<h2>「慎重さ・透明性・敬意」の姿勢</h2>
<p>OpenAIは、回答書の提出と同じ11月25日付で公開したブログ「Our approach to mental health-related litigation」で、メンタルヘルス関連の訴訟は深い悲劇性と複雑さを伴うため、「慎重さ・透明性・敬意をもって対応する」との方針を<a href="https://openai.com/index/mental-health-litigation-approach/">示した</a>。同ブログでは遺族への哀悼を表明しつつも、具体的な論点については法廷での手続きを通じて対応するとしている。</p>
<p>また、2025年8月に公開した別の公式文書「Helping people when they need it most」では、
・危機的状況の検知精度の向上
・外部支援先への誘導の強化
・長時間会話におけるガードレールの精緻化
・ティーン向け保護機能の追加
など、メンタルヘルス領域での安全性改善を進めていることを説明した。</p>
<h2>原告側は「被害者非難」と反発</h2>
<p>報道によると、原告側代理人はOpenAIの回答を「被害者を責める内容だ」と批判しており、ChatGPTのガードレール設計や運用の不足が少年の自殺に寄与したとの主張を続けている。</p>
<p>今後の審理では、
・ChatGPTの応答と自殺行動の因果関係
・GPT-4oの安全設計とガードレールの適切性
・利用規約やSection 230が生成AIの応答にどこまで適用されるか
などが主要な争点となる見通しだ。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>HP、AI導入を軸に最大6000人削減へ──2028年度末までに世界で4000〜6000人、年間10億ドルのコスト削減目指す</title>
      <link>https://ledge.ai/articles/hp_ai_headcount_reduction_2028_plan</link>
      <description><![CDATA[<p>HPは2025年11月25日（米国時間）、2025年度通期および第4四半期の決算を公表するとともに、AIの活用を軸とした全社的な構造改革「Fiscal 2026 Plan」を<a href="https://www.hp.com/us-en/newsroom/press-releases/2025/hp-inc-reports-fiscal-2025-full-year-and-fourth-quarter-results.html">発表</a>した。</p>
<p>その一環として、世界で約4000〜6000人の人員削減を2028年度末までに実施する計画を示した。これは、AI導入による生産性向上や事業構造の見直しを進めながら、年間約10億ドルのコスト削減を図る取り組みの一部として位置づけられている。</p>
<h2>AI活用を柱に全社改革──「Fiscal 2026 Plan」発表</h2>
<p>HPは、AIを中心としたデジタルトランスフォーメーションを通じ、顧客満足度の向上、プロダクトイノベーションの加速、生産性の改善を図ると説明。同社は「会社全体の取り組み（company-wide initiative）」と呼ぶこのプランにより、2028年度末までに年間約10億ドルのグロス・コスト削減を達成する見込みを示した。</p>
<p>計画には、組織の簡素化、プラットフォーム統合、業務プロセス改善に加え、AI活用による自動化や効率化が含まれる。これらの施策に伴い、総額約6億5000万ドルのリストラクチャリング費用を見込んでおり、うち約2億5000万ドルを2026年度に計上する予定だ。</p>
<h2>世界で4000〜6000人削減──2028年度末までに段階的に実施</h2>
<p>HPは、全社改革の一環として、世界の総人員を約4000〜6000人削減する（gross global headcount reduction）と発表した。リリースでは、対象地域や部門の内訳は明らかにしていないが、「workforce reductions（人員削減）」を主要な施策の一つとして挙げている。</p>
<p>人員削減は2028年度末までに段階的に実施される予定で、AI活用による業務の効率化や、非中核領域の統合・最適化を通じて構造的なコスト削減を進める。</p>
<h2>2025年度の業績──通期売上は553億ドル、PC事業は回復傾向</h2>
<p>決算によると、2025年度通期の売上高は553億ドル（前年比3.2％増）となった。GAAP希薄化後EPSは2.65ドルで、前年（2.81ドル）から減少した。一方、第4四半期売上高は146億ドル（前年比4.2％増）と増収となっている。</p>
<p>主力のパーソナルシステムズ事業（PC）は、第4四半期で前年比8％増の104億ドルとなり、コンシューマー向け・法人向けともに販売が回復した。プリンティング事業は4％減の43億ドルと低調だった。</p>
<p>同社CEOであるEnrique Lores氏は、AIを基盤とした製品イノベーションを強調し、「働き方の未来（Future of Work）をリードするため、AI搭載デバイスの開発、生産性向上、顧客価値の最大化を進める」とコメントした。</p>
<p>HPは、2026年度第1四半期のEPS見通しとして、GAAPベースで0.58〜0.66ドル、非GAAPで0.73〜0.81ドルと予測。通期では、GAAP 2.47〜2.77ドル、非GAAP 2.90〜3.20ドルを見込む。フリーキャッシュフローは28〜30億ドルを計画しており、成長投資と株主還元の両立を図る考えを示した。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>KDDI、人間のチャット応対を学習するAIエージェントを開発──回答精度90％、auサポート窓口で運用開始</title>
      <link>https://ledge.ai/articles/kddi_human_chat_learning_ai_agent_release</link>
      <description><![CDATA[<p>KDDIとKDDI総合研究所は2025年11月26日、チャットサポート窓口で人間の応対履歴を学習し、高精度で再現するAIエージェントを開発したと<a href="https://www.kddi-research.jp/newsrelease/2025/112601.html">発表</a>した。</p>
<p>複数の応対事例を構造化し、追加情報の収集とファクトチェックを組み合わせる世界初の技術により、生成AIにおけるハルシネーションを抑制し、約90％の回答精度を実現したという。すでにauチャットサポート窓口の一部応対拠点で運用が始まっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kddi_nr_850_4231_img_02_9afe639a8d/kddi_nr_850_4231_img_02_9afe639a8d.png" alt="kddi_nr-850_4231_img_02.png" /></p>
<p>近年、従来のシナリオ型チャットボットでは対応が難しい複雑な問い合わせが増加しており、難易度の高い案件は人手による対応が必要だった。今回開発されたAIエージェントは、過去の適切な応対事例を複数抽出し、応対の流れを構造化したうえで、必要に応じて社内マニュアルから追加情報を収集し、内容の整合性を自動でチェックする仕組みを備える。このプロセスを経て応答文を生成することで、誤情報の生成を抑えつつ、実務に適した応対品質を確保するという。</p>
<p>KDDIによると、問い合わせ1件あたりの応対時間は従来比で約70％短縮できる見込みで、スタッフ間の応対品質の均一化にもつながると説明している。今回の技術は汎用パッケージとして開発されており、社内でのユースケース拡大やグループ会社への横展開に加え、将来的な商用提供も視野に入れている。</p>
<p>KDDI総合研究所は、応対の構造化や事例選択手法などに関する特許を10件以上登録済または出願済としており、今後も応対領域の拡大を進める方針を示している。両社は、AI技術の社会実装とお客さま応対の品質向上を通じ、カスタマーサポート体験の改善に取り組んでいくとしている。</p>
<p>:::box
<a href="https://ledge.ai/articles/deloitte_global_contact_center_survey2023">関連記事：国内コンタクトセンターすでに半数がAI導入、海外上回るも成果には課題あり</a>
::</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>2025年のAIニュース振り返りと、AI提唱70周年となる2026年の展望を知る特設サイトLedge.ai年末年始特集「&apos;25 to &apos;26」を公開</title>
      <link>https://ledge.ai/articles/ledgeai25to26</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も参加費無料の年末特集「Ledge.ai '25to'26」を公開しました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>Ledge.ai年末年始特集「'25 to '26」とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。</p>
<p>そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。ぜひご登録の上、隅々までご覧ください。参加費は無料です。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>コンテンツラインナップ</h2>
<h3>【編集部コンテンツ】2025年のAI振り返りと70周年に向けた展望</h3>
<p>Ledge.ai編集部が独自に企画・編集した記事および特集記事を掲載。
企業動向の背景にある文脈や業界のキーパーソンの言葉を通じて、AI活用を進めるヒントとして、ぜひご一読ください。</p>
<p><strong>\u003Cテーマ：AIの70年\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_image_f12dd17c93/ai70th_image_f12dd17c93.png" alt="ai70th-image.png" /></p>
<p><strong>\u003CLedge.ai 2025年注目ニュース総まとめ\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai2025news_b7d5ecf93f/ai2025news_b7d5ecf93f.png" alt="ai2025news.png" /></p>
<p>Ledge.aiが発信してきた記事の中から、特に注目すべきトピックをキーワードごとに厳選してお届けします。これらの記事を並べて読むだけでも、2025年のAIトレンドの全体像が浮かび上がってくるはずです。 2025年の振り返りとして、今読むべきランドマーク的な記事をまとめています。ぜひ、業界動向の整理や次のアクションの参考としてご活用ください。</p>
<h2>【特別インタビュー】キーパーソンが語るAIの過去・現在・未来</h2>
<p>本特集では、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいました。</p>
<h2>【トップランナー企業動向】AI周辺で押さえておきたい最新技術と実践事例</h2>
<p>国内外の注目企業をピックアップし、AI基盤、エージェント活用、自動運転データなど、世界最先端の動向を徹底分析します。</p>
<h3>必読の深い知見が得られる取材記事を、公開期間中に次々と発信</h3>
<ul>
<li>AIの進化を支え続けるNVIDIAの羅針盤／エヌビディア合同会社</li>
<li>「言語の壁」は、もはやイノベーションの言い訳にならない。／DeepL Japan</li>
<li>生成AI時代、GPUのオルタナティブ──AMDは今どこを見据えているのか／Advanced Micro Devices, Inc.</li>
<li>基盤モデルとの融合はロボットに何をもたらすのか／Coming soon…</li>
<li>『PLURALITY』の実践と、多元的協働社会への道筋／サイボウズ株式会社 代表取締役社長 青野 慶久 氏</li>
<li>AIを「使わないことが最大のリスク」― AIエージェント時代の企業ガバナンス新常識／弁護士 柴山 吉報 氏</li>
</ul>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25 to '26」
開催期間　：2025年12月1日～2026年1月9日
開催形式　：オンライン
参加費　　：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ　：contact@ledge.co.jp</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 03:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek、自己検証型数学推論モデル「DeepSeek-Math-V2」を公開──IMO金メダル級の定理証明能力をオープンソースで</title>
      <link>https://ledge.ai/articles/deepseek_math_v2_release</link>
      <description><![CDATA[<p>中国のAI開発企業 DeepSeek は、数学的推論に特化した大規模言語モデル「DeepSeek-Math-V2」を2025年11月27日にHugging Face 上の model cardで<a href="https://huggingface.co/deepseek-ai/DeepSeek-Math-V2#deepseekmath-v2-towards-self-verifiable-mathematical-reasoning">公開</a>した。モデルはオープンウェイトで、商用利用も可能な Apache 2.0 ライセンスで提供されている。</p>
<h2>自己検証フレームワークによる厳密な推論</h2>
<p>DeepSeek-Math-V2 の最大の特徴は、生成された証明の正しさを検証する「自己検証（self-verification）」アーキテクチャを採用した点にある。証明を生成する generator と、その証明をチェックする verifier を分離し、両者を強化学習ループで相互に高め合うよう設計することで、論理的整合性を備えた定理証明を可能にした。</p>
<p>この仕組みによって、従来モデルで課題とされてきた「答えは正しくても推論過程が破綻する」問題を抑制し、数学競技形式の問題において高い性能を発揮したという。</p>
<h2>数学ベンチマークで既存LLMを大幅に上回る</h2>
<p>DeepSeek は model card で、同モデルが数多くの数学ベンチマークで既存LLMを上回ったと報告している。特に、研究コミュニティで整備されている定理証明ベンチマーク「ProofBench」において高い正答率を記録した。</p>
<p><strong>ProofBench における各LLMの比較。右端の青は DeepSeek-Math-V2（Heavy）で、Basic と Advanced の双方で既存モデルを大きく上回った</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMO_Proof_Bench_6ae2f05dc5/IMO_Proof_Bench_6ae2f05dc5.jpg" alt="IMO-ProofBench.jpg" /></p>
<h2>IMO・CMO・Putnamで “金メダル級” の成績</h2>
<p>評価は合成ベンチマークだけにとどまらず、国際数学オリンピック（IMO 2025）、中国数学オリンピック（CMO 2024）、米国Putnam Competition（2024）といった実際のコンテスト問題でもスコアが公表されている。</p>
<p><strong>各数学コンテストにおける問題ごとの達成度。灰色は「完全解答」、下線は「部分点獲得」を示す。Putnam 2024 では 98.3% の得点率を記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Competitions_36ac51cf34/Competitions_36ac51cf34.png" alt="Competitions.png" /></p>
<p>実績の要点は以下のとおり：</p>
<ul>
<li>IMO 2025：83.3%（金メダル相当）</li>
<li>CMO 2024：73.8%</li>
<li>Putnam 2024：98.3%（120点中118点）</li>
</ul>
<p>特に Putnam での高得点は、大学数学レベルの複雑な問題に対しても高い正答率を示したことを意味する。</p>
<h2>モデル基盤と公開形態</h2>
<p>モデルは DeepSeek-V3.2-Exp-Base を基盤としており、長い証明文を扱うための拡張コンテキスト、低精度フォーマットによる推論負荷の最適化など、研究用途に配慮した設計となっている。</p>
<p>Hugging Face 上でウェイトが公開されており、研究者・開発者はそのまま検証や応用に利用できる。</p>
<h2>今後の展望</h2>
<p>DeepSeek は、自己検証型LLMが「未解決問題の探索」「形式的証明の自動化」「科学研究の推論支援」などに応用可能であると述べている。一方で、第三者による大規模検証や実際の数学者によるレビューは今後の課題として残る。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>独Black Forest Labs、仏MistralのVLM利用の画像生成AI「FLUX.2」を発表──最大10枚の参照画像、精密な文字生成、4MP編集に対応した“実務特化”モデルファミリー</title>
      <link>https://ledge.ai/articles/bfl_flux2_release_2025</link>
      <description><![CDATA[<p>ドイツのAIスタートアップ Black Forest Labs（BFL） は2025年11月25日、画像生成AIモデルファミリー「FLUX.2」を<a href="https://bfl.ai/blog/flux-2">公開</a>した。</p>
<p>FLUX.2は、実際の制作現場で使うことを前提に設計された「Frontier Visual Intelligence」と位置づけられており、キャラクターやスタイルの一貫性、複雑なプロンプト解釈、レイアウト・照明・ブランドガイドラインへの忠実な追従などが強化されている。最大4メガピクセルの画像編集にも対応し、細部を保ちながら編集が行える。</p>
<p>FLUX.2では内部アーキテクチャも刷新され、Mistral社の240億パラメータの視覚言語モデル「Mistral-3」と、rectified flow Transformer を組み合わせた latent flow matching 構成が採用された。視覚と言語の統合理解を担う Mistral-3 VLM と、空間的整合性・質感表現を司るフロー変換が補完し合うことで、現実世界に近い照明や材質表現、精密な構図理解が可能になっている。</p>
<p>FLUX.2は、複数の参照画像を扱う性能も大幅に向上した。最大10枚の参照画像を統合し、キャラクター、製品、スタイルの特徴を保ちながら高品質な画像を生成できる。テキストレンダリングも強化され、インフォグラフィックスやUIモックアップなど、細かい文字情報を含む画像も安定して描画できるようになった。</p>
<p>FLUX.2による画像編集・参照画像統合のデモンストレーション。複数の入力画像から構図・照明・スタイルを一貫させながら自然な合成を行う様子が示されている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_eyecatch_c1eca950a4/FLUX_2_eyecatch_c1eca950a4.jpg" alt="FLUX2 eyecatch.jpg" /></p>
<h2>Open Core戦略の継続</h2>
<p>BFLは創業以来、「Open Core」戦略を採用してきた。先端モデルを企業向けの商用APIとして提供しながら、研究者や開発者が検証・実験できるオープンウェイトモデルも積極的に公開してきた。2024年に展開したFLUX.1 [dev] は世界で広く普及したオープン画像モデルとなり、FLUX.1 Kontext [pro] はAdobeやMetaなどの企業で利用された。FLUX.2は、この2つの方向性を統合しつつ、さらに拡張された位置づけとなる。</p>
<h2>FLUX.1から進化した4つの軸</h2>
<p>FLUX.2では、精度、効率、コントロール性、写実性の4点を重点的に改善した。生成能力の強化により、プロダクト撮影に近い質感表現、安定した光源処理、構図の破綻が少ない空間表現が可能になり、制作現場における生成AIの導入コストを引き下げる狙いが示されている。</p>
<h2>主な新機能</h2>
<ul>
<li><strong>マルチリファレンス対応（最大10枚）</strong> ：キャラクターや製品の特徴を保持しながら、多様な角度・表情・スタイルを統合。</li>
<li><strong>フォトリアリズムと細部描画の向上</strong> ：テクスチャや照明処理が強化され、写真用途や可視化に適した品質を実現。</li>
<li><strong>文字生成の精密化</strong> ：UIモック、インフォグラフィックス、複雑なタイポグラフィにも対応。</li>
<li><strong>複雑なプロンプトの構造理解</strong> ：多段階の指示、構成要素、レイアウトの指定などを正確に反映。</li>
<li><strong>高解像度編集（最大4メガピクセル）</strong> ：編集時も整合性を保ちながら高解像度データを扱える。</li>
</ul>
<p>すべてのFLUX.2モデルで、テキストによる編集と複数参照画像による編集が一つのモデルで利用できる。</p>
<h2>4モデル構成で用途別に最適化</h2>
<p>FLUX.2は、用途に応じて4つのバリアントが用意される。</p>
<h3>FLUX.2 [pro]</h3>
<ul>
<li>制作現場向けの最高品質モデル</li>
<li>プロンプト遵守と画質で他社クローズドモデルと競合</li>
<li>高速化と低コスト化も両立</li>
<li>BFL Playground、BFL API、パートナー経由で利用可能</li>
</ul>
<h3>FLUX.2 [flex]</h3>
<ul>
<li>生成ステップ数やガイダンススケールを調整できる柔軟なモデル</li>
<li>文字生成や細部描画に強み</li>
<li>bfl.ai/play、API、パートナーから提供</li>
</ul>
<p><strong>FLUX.2 [flex] による“steps”パラメータの調整例。ステップ数を変えることで、タイポグラフィの正確さと生成速度のバランスが変化する（左から6、20、50ステップ）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_flex1_1393dd7816/FLUX_2_flex1_1393dd7816.jpg" alt="FLUX2 flex1.jpg" /></p>
<p><strong>FLUX.2 [flex] によるステップ数の変化による画質の違い。ステップを増やすほどディテールが安定し、質感再現が向上する（左から6、20、50ステップ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_flex2_b6ca2ffb42/FLUX_2_flex2_b6ca2ffb42.jpg" alt="FLUX2 flex2.jpg" /></p>
<h3>FLUX.2 [dev]（オープンウェイト）</h3>
<ul>
<li>32Bのオープンウェイトモデル</li>
<li>テキスト生成と画像編集を単一チェックポイントで実行</li>
<li>Hugging Faceでウェイト公開</li>
<li>NVIDIA/ComfyUIと連携したfp8最適化版も提供</li>
<li>FAL、Replicate、Runware、Verda、TogetherAIなど複数のAPIサービスで利用可能</li>
<li>商用ライセンスはBFL公式サイトで提供</li>
</ul>
<h3>FLUX.2 [klein]（近日公開）</h3>
<ul>
<li>Apache 2.0ライセンスのオープンソースモデル</li>
<li>FLUX.2を蒸留した小型モデル</li>
<li>β版登録を受け付け中</li>
</ul>
<h2>新VAEも公開</h2>
<p>FLUX.2シリーズには、新設計の「FLUX.2 - VAE」が採用されている。学習性、品質、圧縮率のバランスを最適化したモデルで、すべてのFLUX.2バックボーンの基礎となる。Apache 2.0で公開され、技術レポートも提供されている。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/29 [SAT]アリババ、初のAIスマートグラス「Quark AI Glasses」発売──S1/G1の2モデルで同社製LLM「Qwen」を直接使える日常デバイスに</title>
      <link>https://ledge.ai/articles/alibaba_quark_ai_glasses_launch_china</link>
      <description><![CDATA[<p>アリババは2025年11月27日（現地時間）、同社として初となるAI搭載スマートグラス「Quark AI Glasses」シリーズを<a href="https://www.alizila.com/alibaba-launches-new-quark-ai-glasses-series-in-china-deeply-integrated-with-qwen/">発表</a>した。アリババの大規模言語モデル「Qwen」およびAIアプリ「Qwen App」と深く統合し、音声と視覚を組み合わせたリアルタイムAIアシスタントを提供する。シリーズは、ディスプレイ搭載のフラグシップモデル「S1」と、軽量で普段使いに適した「G1」の2モデル構成となる。</p>
<h2>QwenとQuark Appを統合、音声・視覚を組み合わせたAIアシスタントに対応</h2>
<p>Quark AI Glassesは、アリババが開発する大規模言語モデル「Qwen」とAIアプリ「Qwen App」を標準搭載し、音声操作や視界上への情報提示を通じて、AIアシスタント機能を直接メガネ型デバイスで利用できる。外出先でのリアルタイム翻訳や、会議・講義内容の文字起こし、リマインダー設定、ナビゲーション、周辺スポット検索、ショッピング支援といった多様な機能に対応する。</p>
<p>また、アリババグループのサービスとも連携しており、決済のAlipay（支付宝）、地図サービスのAmap（高徳地図）、ECサービスのTaobao（淘宝）、旅行サービスFliggy（飛猪）なども利用できる。中国の音楽ストリーミングサービス（QQ Music、NetEase Cloud Music）にも対応した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55.jpeg" alt="bf1ef6c08mf1fb9c98a8d6dd8bbbe8de.jpeg" /></p>
<h2>フラグシップモデル「S1」──交換式デュアルバッテリーで最大24時間使用可能</h2>
<p>S1はデュアルマイクロOLEDディスプレイを搭載し、視界内に情報をオーバーレイ表示できる。骨伝導技術やデュアルチップ構成を採用し、音声入出力やリアルタイム処理性能を強化した。</p>
<p>特徴的な点として、交換可能なデュアルバッテリーシステムを採用し、最大24時間の利用を可能としている。また、0.6秒で撮影できるインスタントフォト機能や、3K動画撮影およびAIによる4K動画出力、独自技術「Super Raw」による夜間撮影性能の向上など、撮影機能も強化されている。価格は3,799元（約7万8,000円）から。</p>
<h2>軽量モデル「G1」──約40gで普段使いに最適、コアハードウェアはS1と共通</h2>
<p>G1は日常の利用を想定した軽量モデルで、重量は約40gに抑えられている。ディスプレイ以外の主要ハードウェア（処理チップ、オーディオ、カメラなど）はS1と共通で、普段使いしやすいデザインと価格帯を重視している。価格は1,899元（約3万9,000円）から。</p>
<h2>MCP対応で開発者エコシステムも視野に</h2>
<p>Quark AI Glassesは、外部システムやアプリケーションと双方向に接続するオープン標準「Model Context Protocol（MCP）」に対応する。これにより、開発者がQuark AI Glasses向けのAIアプリやエージェントを拡張しやすくなり、アリババのQwenエコシステムとの連携も強化される。</p>
<p>市場調査会社<a href="https://www.idc.com/promo/wearablevendor/">IDC</a>の調査によると、2025年第2四半期の世界ウェアラブルデバイス出荷台数は前年同期比9.6％増の1億3,650万台で、このうち約5,000万台が中国を中心とする地域から出荷されている。中国は現在、世界最大のウェアラブル市場であり、AI搭載デバイス分野における競争も激しさを増している。</p>
<p>Quark AI Glassesシリーズは、アリババのAIモデルQwenとグループのサービス群、そしてMCPによる拡張性を組み合わせることで、同市場における新たな製品ポジションを獲得する構えだ。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>EpicのCEO「AI使用はゲーム制作の基本工程になる。明示ラベルは不要」──生成AI使用の開示を義務化するSteamへの異議に賛同</title>
      <link>https://ledge.ai/articles/epic_ceo_ai_tag_unnecessary_steam_disclosure_debate</link>
      <description><![CDATA[<p>2025年11月27日（現地時間）、映像クリエイターであるWorkman氏が、「Steamやすべてのデジタルマーケットは“Made with AI”タグをやめるべきだ。もはや意味をなさない（Steam and all digital marketplaces need to drop the “Made with AI” label. It doesn’t matter any more.）」と投稿した。この意見に、Epic GamesのCEOである Tim Sweeney（ティム・スウィーニー）氏が「Agreed（同意する）」と返信し、ゲーム制作におけるAIタグの必要性について疑問を呈した。</p>
<h2>「Made with AI」タグは “もはや意味をなさない”</h2>
<p>Workman 氏はX上で、ゲームストアに“AI製（Made with AI）”と明示することは、現在の制作現場の実態から乖離しつつあると指摘した。その後 <a href="https://www.linkedin.com/posts/mattworkman_epic-games-ceo-argues-marketplaces-dont-activity-7399863685189627904-WZnL">LinkedIn</a>で投稿を補足し、一般的な制作ツールの多くにAI機能が搭載されていることから、「どこからどこまでが “AI使用” に該当するのか」という線引きが難しくなっていると説明。開示の有無によって開発者間に不公平が生じているケースもあると述べ、Valveに対しタグの撤廃を求めた。</p>
<p>こうした指摘は、Steamが導入したAI使用開示制度の運用上の難しさや、AIが制作ツールとして一般化していく中で、開示が“特殊なもの”として扱われ続けることへの懸念を示すものとなっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Tim_Sweeney_ai_tag_e17446f159/Tim_Sweeney_ai_tag_e17446f159.jpg" alt="Tim Sweeney ai tag.jpg" /></p>
<h2>Epic CEOの賛同──「AIはゲーム制作の基本工程に組み込まれる」</h2>
<p>Workman 氏の投稿に対し、Epic Games のCEOである Tim Sweeney 氏は「Agreed」と短く賛同したうえで、続くやり取りの中で自身の見解を明らかにした。</p>
<p>Sweeney 氏は「AIは今後ほぼすべてのゲーム制作プロセスに組み込まれていく」と述べ、AI使用を特別にラベルとして表示する必要性は薄れていくと指摘。著作者表示や権利状態の明確化が求められるアート展示やライセンス販売とは異なり、ゲームストアにおける“AIタグ”は制作実態にそぐわないとする立場を示した。</p>
<h2>開示を求めるSteam、受け入れるEpic──AIコンテンツをめぐる両社のスタンスの違い</h2>
<p>Steamを運営する Valve は2024年1月、「AI Content on Steam」の方針を導入し、生成AIを利用したゲームを原則受け入れる一方、開発者にAI使用状況の開示を義務づけている。具体的には、AIで生成したアートやコードなどの「事前生成コンテンツ」、プレイ中にAIが動的に生成する「ライブ生成コンテンツ」について、権利関係や安全性を確認したうえでストアページの「AI Generated Content Disclosure」欄に記載する方式を採用している。</p>
<p>Steamのスタンスは段階的に形成されてきた。2023年には生成AIアートを含むゲームが権利不備で却下された例が報告され、Valveは後に「権利が確認されたAIコンテンツは受け入れる」と説明。その後2024年に開示義務制度が整備され、AIを使ったゲームの“条件付き受け入れ”という形に落ち着いた。</p>
<p>一方、Epic Games Store は当初から生成AIを使用したタイトルの配信を認める立場を取り、AI技術そのものを理由に制限しない姿勢を採ってきた。両社はAIコンテンツの扱いにおいて、「透明性の確保を重視するSteam」と「AI使用を特別扱いしないEpic」という対照的な方針を示している。</p>
<p>AI使用の透明性を求める声と、技術が一般化するなかで特別なタグを付与することへの疑問が併存しており、SteamとEpicの異なる姿勢はその対立軸を象徴している。
AIが制作の基本工程となる時代に、どのような開示ルールが適切なのか。今後も議論が続くテーマとなりそうだ。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AWS、「Kiro」を一般提供──仕様駆動のAIコーディングをIDEとターミナルで一元化</title>
      <link>https://ledge.ai/articles/aws_kiro_general_availability</link>
      <description><![CDATA[<p>AWSは2025年11月18日、AIエディター／開発ツール「Kiro（キロ）」の一般提供を<a href="https://aws.amazon.com/jp/blogs/news/introducing-kiro-cli/">発表</a>した。Kiroは、7月の<a href="https://ledge.ai/articles/aws_ai_ide_kiro_release">プレビュー版公開</a>から機能追加を重ねてきたAI開発ツールで、仕様（Spec）を中心にコード生成・検証・リファクタリングを行える点が特徴だ。一般提供に合わせて、プロパティベーステスト、エージェント動作の巻き戻し機能、ターミナル向けの「Kiro CLI」、AWS IAM連携のチーム管理機能を搭載したという。</p>
<h2>仕様に基づく開発を強化：プロパティベーステストに対応</h2>
<p>Kiroの正式版では、仕様と実装の整合性を検証するための「プロパティベーステスト（property-based testing）」が導入された。開発者がEARS形式で記述した仕様から、Kiroがテストすべき“性質（プロパティ）”を自動抽出し、数百〜数千のランダムテストを生成して実装を検証する仕組みだ。反例が見つかった場合は、原因特定のため条件を徐々に単純化する「縮小（shrinking）」も実行される。</p>
<p>これにより、個別のテストケースでは検出しづらい欠陥を発見しやすくなり、仕様ベースでの正確な実装を支援する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/correctness_f57a485373/correctness_f57a485373.png" alt="correctness.png" />
Kiro IDEが生成したプロパティベーステストの例。仕様から抽出した“チケットIDが常に一意であること”という性質を可視化し、関連する要件・実装タスク・テスト結果を紐づけて表示する。</p>
<h2>チェックポイントで開発プロセスを巻き戻し可能に</h2>
<p>一般提供版では、エージェントが行った操作や変更内容を段階的に保存する「チェックポイント」機能を追加した。エージェントの提案やコード修正を進めた後でも、必要に応じて任意の状態へ戻れるため、実装方針の変更や手戻りが発生した際のコストを抑えられる。</p>
<p>また、1つのKiroワークスペースで複数のプロジェクトルートを扱える「マルチルート」構成にも対応し、マイクロサービスやモノレポなど複雑な構成の開発にも利用できる。</p>
<h2>IDEとターミナルを共通化する「Kiro CLI」</h2>
<p>正式版の大きな追加点として、ターミナルで利用できる「Kiro CLI」が提供された。開発者は、IDE と同じエージェント環境をターミナルでもそのまま利用でき、Claude Sonnet 4.5 や Haiku 4.5 などのモデル、Autoエージェント、MCP（Model Context Protocol）ツールによるローカル操作やAPI呼び出しも実行できる。</p>
<p>CLIとIDEは同一のステアリングファイルや認証情報、コンテキストを共有するため、開発環境を切り替えても同じワークフローを継続できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cli_5921207104/cli_5921207104.png" alt="cli.png" />
一般提供版で新たに追加された「Kiro CLI」。IDEと同じエージェント環境をターミナルでも利用でき、AutoエージェントやMCPツールによる操作が可能になる。</p>
<h2>AWS IAM連携のチーム管理と、スタートアップ向け1年無償プラン</h2>
<p>Kiroは、AWS IAM Identity Centerと統合され、組織アカウントによるログインや、Pro／Pro+／Powerティアの利用制限、MCP設定、請求管理などをAWS側で一元的に管理できる。</p>
<p>また、シリーズBまでの対象スタートアップには「Kiro Pro+」を1年間無償提供するオファーを開始した。既存のAWS Activateクレジットと併用可能で、2025年12月31日まで申請を受け付ける。</p>
<h2>“AI駆動開発”の基盤へ</h2>
<p>Kiroは、仕様駆動の開発、プロパティベーステスト、IDE／CLI共通のAIエージェント環境、IAM連携によるチーム運用など、開発プロセス全体をAIと統合する機能を備えた。Kiro公式ブログでは「This is just the start.」と記されており、今後もアップデートを継続する方針を示している。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国研究者、台湾上空でStarlink通信を遮断するシミュレーションを実施──最大2000機のドローンなどによる電子妨害が必要と試算</title>
      <link>https://ledge.ai/articles/china_starlink_jamming_simulation_taiwan</link>
      <description><![CDATA[<p>中国と台湾の緊張が続くなか、中国本土の研究者が「台湾上空でStarlink通信網を妨害する」大規模電子戦シミュレーションを実施したと、香港紙<a href="https://www.scmp.com/news/china/science/article/3333523/chinese-researchers-simulate-large-scale-electronic-warfare-against-elon-musks-starlink">サウスチャイナ・モーニング・ポスト（SCMP）</a>が2025年11月23日に報じた。</p>
<p>研究チームは、台湾と同規模の約3.6万平方キロメートルの領域を対象に、1000〜2000機規模の通信妨害装置（ジャマー）を上空に展開することで、Starlinkネットワークを一時的に抑圧できる可能性があると試算している。</p>
<p>SCMPが確認したのは、中国語の専門誌『系统工程与电子技术（Systems Engineering and Electronics）』に掲載された論文で、中国の軍事工学研究者らが作成したもの。同紙によると、研究者はウクライナ戦争でStarlinkが通信インフラとして軍事作戦を支え続けたことを受け、台湾有事などを想定した電子戦の可能性を分析したという。</p>
<p>Starlinkは、高度約550kmの低軌道衛星が多数稼働し、自律的に接続先を切り替えるメッシュ型ネットワークを形成している。このため、地上からの単一の妨害では通信を完全に遮断することが難しいとされる。研究チームはそこで、航空機・気球・ドローンなどの空中ジャマー（通信妨害装置）を広範囲に配置する方式を検証し、一定高度で密度の高い妨害グリッドを形成することで、特定エリアのStarlink通信を抑圧できる可能性が示された。</p>
<p>米技術メディアの<a href="https://www.tomshardware.com/networking/china-simulated-a-starlink-blockade-over-taiwan-ccp-scientists-say-around-1-000-drones-would-be-enough-to-cut-satellite-internet-to-the-island">Tom’s Hardware</a>は、論文のシミュレーション条件を詳細に紹介している。それによれば、ジャマーは高度約20kmに展開し、3〜6マイル間隔で配置することで“電磁シールド”のような妨害グリッドを形成する必要があるとされる。また、高出力装置を搭載した航空機を使う場合は約935ノードで足りる一方、小型ドローンなどの低出力ジャマーでは1000〜2000ノードが必要になるという。</p>
<p>ただし、数千機規模の空中ジャマーを台湾上空に長時間展開し続けるには、燃料・整備・指揮統制・対空防衛への対応など、多くの運用上の課題が伴う。複数の報道でも、今回の内容はあくまでもシミュレーション研究であり、実際に中国が同規模の演習を行った証拠は確認されていない。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、「Claude Opus 4.5」を発表──ソフトウェア開発・エージェント性能・安全性を強化した最新フラッグシップモデル</title>
      <link>https://ledge.ai/articles/claude_opus_4_5_release</link>
      <description><![CDATA[<p>Anthropicは2025年11月24日（米国時間）、最新フラッグシップモデル「Claude Opus 4.5」を<a href="https://www.anthropic.com/news/claude-opus-4-5">発表</a>した。同社はOpus 4.5を「コーディング、エージェント、コンピュータ利用において世界最高水準のモデル」と位置付けており、ソフトウェア開発から長時間のリサーチ、マルチツールを用いたエージェントタスクまで幅広い領域で性能が向上したと説明している。</p>
<h2>ソフトウェアエンジニアリング分野で主要モデルを上回るスコア</h2>
<p>Opus 4.5はソフトウェアバグ修正タスクのベンチマークである SWE-bench Verified（n=500） で、正答率80.9％を記録した。これは、前世代モデルのOpus 4.1やSonnet 4.5に加え、他社のフラッグシップモデルであるGemini 3 ProやGPT-5.1 Codex-Maxなどを上回るスコアだという。</p>
<p><strong>SWE-bench VerifiedにおけるOpus 4.5（左端）の正答率は80.9％と主要モデルを上回った</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/opus4_5_1_2c2dfa96a8/opus4_5_1_2c2dfa96a8.jpg" alt="opus4-5_1.jpg" /></p>
<h2>総合ベンチマークでも全面的に強化</h2>
<p>ソフトウェアエンジニアリング以外の評価でも幅広くスコアを伸ばしている。Anthropicが公開した比較表では、エージェント的なコーディング、ターミナル操作、ツール利用、PC操作、さらに大学院レベルの推論（GPQA Diamond）や視覚推論（MMMU）、多言語QA（MMMLU）など、多くの項目でOpus 4.1やSonnet 4.5からスコアを更新していることが示されている。</p>
<p><strong>Opus 4.5は広範な評価指標で前世代を上回り、複数の領域でSOTA（state of the art）を獲得した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/opus4_5_2_4cb9404311/opus4_5_2_4cb9404311.jpg" alt="opus4-5_2.jpg" /></p>
<h2>多言語コーディングでも広範に改善</h2>
<p>Opus 4.5は、SWE-bench Multilingual にも対応し、C / C++ / Go / Java / JS/TS / PHP / Ruby / Rust など8言語で前世代を上回るPASS@1を記録した。</p>
<p><strong>多言語コーディング評価（SWE-bench Multilingual）。Opus 4.5（赤）は8言語の多くで最高スコアを記録した</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/opus4_5_3_cfc4fb910a/opus4_5_3_cfc4fb910a.jpg" alt="opus4-5_3.jpg" /></p>
<h2>エージェント行動・PC操作・ツール利用能力も大幅向上</h2>
<p>Opus 4.5は、エージェント行動やマルチツールを扱うタスクでも大幅に性能を向上させている。</p>
<ul>
<li>Terminal-bench 2.0（ターミナル操作）で59.3％</li>
<li>t2-bench（ツール利用）でRetail 88.9％、Telecom 98.2％</li>
<li>OSWorld（PC操作）で66.3％</li>
</ul>
<p>これらのスコアは前世代からの大きな改善で、実務的なエージェントタスクに必要な能力が全体的に底上げされている。</p>
<p><strong>Sonnet 4.5 vs Opus 4.5 のパズル解法デモ</strong>
Opus 4.5のエージェント能力を示す例として、Anthropicは「Sonnet 4.5とOpus 4.5に同じパズルゲームを解かせた」デモ動画も公開している。Opus 4.5は条件制約のある環境でも自律的に手順を探索し、より安定してクリアする様子が示されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=2MJDdzSXL74">YouTube</a></p>
<h2>安全性評価：「懸念行動」を抑えたモデル設計</h2>
<p>AnthropicはOpus 4.5を「安全性に最も優れたモデル」と位置付けている。内部評価では、危険行動や望ましくない自律動作につながる可能性を測る Concerning behavior（懸念行動） の指標で、Opus 4.5が最も低い値となった。</p>
<p><strong>懸念行動の内部評価。Opus 4.5が最も低く、安全性指標で優位性を示す</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/opus4_5_4_b32e228495/opus4_5_4_b32e228495.jpg" alt="opus4-5_4.jpg" /></p>
<h2>プロンプトインジェクション攻撃への耐性</h2>
<p>外部評価機関Gray Swanによる強力なプロンプトインジェクション攻撃テストでも、Opus 4.5は攻撃成功率が最も低く抑えられた。Gemini 3 Pro Thinking、GPT-5.1 Thinking、Haiku 4.5 Thinkingなどと比較しても、相対的に高い安全性が確認されている。</p>
<p><strong>プロンプトインジェクション攻撃への耐性（低いほど安全）。Opus 4.5 Thinkingが最も低い攻撃成功率を示した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/opus4_5_5_c58f60c1ea/opus4_5_5_c58f60c1ea.webp" alt="opus4-5_5.webp" /></p>
<h2>長時間タスクとツール連携を支える「advanced tool use」</h2>
<p>今回の発表では「advanced tool use」についても触れられている。これはDeveloper Platformにおける機能群で</p>
<ul>
<li>必要なタイミングでツール定義を検索・読み込む <strong>Tool Search Tool</strong></li>
<li>Pythonコードの中で複数のツールを連携させる <strong>Programmatic Tool Calling</strong>
などにより、長時間タスクや複数ツールを扱うエージェントの効率を高める。</li>
</ul>
<p>Opus 4.5はこうした基盤を前提に設計されており、企業利用・実務エージェント運用への対応を強化したモデルと位置付けられる。</p>
<p>AnthropicはOpus 4.5の開発背景や設計思想をまとめた公式動画も公開している。同社が強調する「エージェント運用」「高い安全性」「コーディング性能の向上」といったポイントを視覚的に確認できる。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“自分の分身AI”同士を討論させると何が起きる？──筑波大学とMicrosoft、AIが媒介する新しい「自己省察」の学びを報告</title>
      <link>https://ledge.ai/articles/digital_human_debates_reflecting_with_ai</link>
      <description><![CDATA[<p>筑波大学とMicrosoftの研究者らは2025年11月17日、利用者自身の価値観や思考パターンを反映した「分身AI（Digital Human）」同士を討論させ、本人がその様子を傍観するという実験の結果をまとめた論文を<a href="https://arxiv.org/abs/2511.13046">公開</a>した。研究チームは、参加者がAIの能力理解を深めただけでなく、「自分ではない自分」を観察することで、自身の思考や価値観を客観的に見つめ直す新たな学習効果を確認したという。</p>
<h2>“自分の分身”を作り、その議論を観察するという新しい構図</h2>
<p>研究が扱ったのは、次の3つの視点の中間に位置する体験である。</p>
<ul>
<li>一次的視点（First-person）：自分が他者と直接対話する</li>
<li>三人称視点（Third-person）：第三者同士の会話を観察する</li>
<li>今回の視点（AI-mediated）：自分を反映した「Digital Me」が他人の「Digital You」と議論し、その様子を本人が観察する</li>
</ul>
<p>実験では、学生が自ら設計した分身AIが、自律的に討論を展開する。設計者の価値観や思考は反映されるが、議論の流れは完全には制御できない。この「似ているが、完全な自分ではない」という距離感が、客観的な自己観察を可能にするという。</p>
<p><strong>コミュニケーション構造の比較図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_7_2d4879fc05/x2_7_2d4879fc05.png" alt="x2 (7).png" /></p>
<h2>Digital Human Debates（DHD）の設計：プロンプトとRAGで“自分”を埋め込む</h2>
<p>参加したのは中高生9名（3チーム）。それぞれが6か月にわたり、自分の分身AIを次の3要素で設計した。</p>
<ul>
<li>system_prompt_template.txt：性格・口調・議論戦略・思考様式</li>
<li>interview_transcript.txt：個人の価値観・経験・背景</li>
<li>Documents（RAG 文書）：議論に利用する外部知識（両立場の資料を収集）</li>
</ul>
<p>システムは GPT-4o と LangChain を基盤に構築され、音声入力→議論生成→音声合成→Lip-sync 動画生成までを自動化。</p>
<p><strong>システム構成図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x4_1_5978703b2d/x4_1_5978703b2d.png" alt="x4 (1).png" /></p>
<h2>どのように討論したのか</h2>
<p>議論のトピックは、以下の4種類からルーレットでランダム選択された。</p>
<ul>
<li>高齢者の免許返納</li>
<li>リモートワークの恒久化</li>
<li>安楽死の合法化</li>
<li>ベーシックインカムの導入</li>
</ul>
<p>討論は約20分。Constructive speech、Cross-examination、Rebuttal など、全国高校ディベート選手権の形式に準じて進行し、勝敗は3名の審査員が判定した。</p>
<p><strong>討論フロー図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x5_3_aa3dfafba5/x5_3_aa3dfafba5.png" alt="x5 (3).png" /></p>
<p>また、実際の議論分析では、分身AIの発話は以下の3層で構成されていたことが確認された。</p>
<ul>
<li>Personal Context：学生本人の経験や価値観（例：留学経験）</li>
<li>RAG-sourced Evidence：外部文書を参照した事実情報</li>
<li>AI-generated Insight：LLM が独自に構築した新しい主張・質問</li>
</ul>
<p><strong>発話構成の三層分析図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x6_2_ebcfc4cb09/x6_2_ebcfc4cb09.png" alt="x6 (2).png" /></p>
<h2>発見1：AIが“自分の代わり”ではなく“自分の鏡”として機能する</h2>
<p>論文で最も強調されている成果は、参加者が 「Reflecting with AI」 と呼ばれる新たな学習体験を得た点である。</p>
<h3>「自分が話すより冷静に見られる」</h3>
<p>AIが自分の価値観を用いて議論するものの、その展開は必ずしも本人の想定どおりではない。
この“半自律性”が、次のような客観視を可能にした。</p>
<ul>
<li>「私は衝動的に話しがちだと気づいた」</li>
<li>「AIの方が論理がブレず、どこが弱いのかがわかった」</li>
</ul>
<p>参加者は AI の議論を自分とは別の存在として受け止めつつ、「しかし自分の思考が反映されている」と感じる。この微妙な距離感が、強いメタ認知効果を生んだという。</p>
<h2>発見2：プロンプト設計の違いが“AIの人格”に明確に表れる</h2>
<p>3チームのアプローチは大きく異なり、プロンプト設計の個性が発話に直接反映された。</p>
<ul>
<li><strong>Team A：徹底したキャラクター設計</strong> 「認知停止を破壊する」というテーマを持つ強烈な人格を設定し、攻撃的な論法を組み込んだ。</li>
<li><strong>Team B：繰り返し修正する“チューニング型</strong> 芥川龍之介やガンジーなど歴史人物をモチーフに、AIの出力を評価→修正する反復設計を採用。</li>
<li><strong>Team C：最小限の人格＋大量の論拠データ</strong> キャラ設定は控えめにし、RAGで大量の論理情報を与える“ロジック重視”型。</li>
</ul>
<p>いずれも、設計者の価値観や思考癖がそのままAIのふるまいに組み込まれていたという。</p>
<h2>発見3：AIリテラシー全体をカバーする学習効果</h2>
<p>研究チームは、今回の取り組みを“ジェネレーティブAIリテラシーの実践的な総合モデル”と位置づけている。
実際、参加者は以下の能力を幅広く活用していた。</p>
<ul>
<li>モデル特性の理解</li>
<li>論拠の収集と検証</li>
<li>プロンプト設計</li>
<li>出力の評価と改善</li>
<li>自己の思考の客観視（Reflecting with AI）</li>
</ul>
<p>ただし、倫理や法的側面の深い学習までは含まれておらず、今後の課題とされている。</p>
<p>研究では、「AIとの協働」ではなく “AIを通して自分を理解する” という新しい可能性を示しており、分身AIが自律的に議論する様子を観察することで、ユーザーは自らの論理構造・思考の癖を外在化し、客観的に省察できるという。研究チームは、この“Reflecting with AI”が今後のAIリテラシーにおける重要な能力になると位置づけている。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、Geminiに「AI生成画像の検証」機能を導入──目に見えない電子透かし技術「SynthID」を活用</title>
      <link>https://ledge.ai/articles/google_gemini_synthid_image_verification</link>
      <description><![CDATA[<p>Googleは2025年11月20日、Geminiアプリにおいて、画像をアップロードして「この画像はAIで生成または編集されたものか」を判定できる新機能を<a href="https://blog.google/technology/ai/ai-image-verification-gemini-app/">公開</a>した。同社は2023年に、画像の見た目に影響を与えず識別情報を埋め込む電子透かし（Invisible watermark）技術「SynthID」を開発しており、今回のアップデートにより、この電子透かしをGeminiアプリ上で直接検出できるようになる。</p>
<h2>AI生成画像の真偽をアプリ上で判定</h2>
<p>Geminiアプリでは、ユーザーが画像をアップロードし、「Was this created or edited by Google AI?」といった質問を投げかけることで、画像にSynthIDの電子透かしが含まれているかを判定できる。
電子透かしが検出された場合は、GoogleのAIによって生成または編集された可能性が高いと返答される。一方で電子透かしが見つからない場合は、「GoogleのAIによるものではない可能性が高い」と示される。ただし、他社のAIモデルによる生成画像まで識別できるわけではなく、あくまでGoogleのAIに適用された電子透かしのみが検知対象となる。</p>
<h2>利用条件と注意点</h2>
<p>Googleサポートページによれば、検証は1枚ずつ（100MB以下）の画像に対して実施され、コラージュ画像など複数の画像を含む形式は推奨されない。また、電子透かしが画像全体ではなく一部に適用されている場合、AIで編集された領域が検出されることもある。</p>
<h2>「SynthID」とは</h2>
<p>SynthIDは、画像の外観に影響を与えず、機械的に読み取ることができる目に見えない電子透かし（Invisible watermark）技術を採用している。Geminiアプリは、この電子透かしをもとに生成・編集プロセスを判定する仕組みを持つ。
公式ブログでは、Googleが今後、画像だけでなく動画や音声への対応拡大も計画していることが示されている。</p>
<h2>Googleの透明性強化の取り組み</h2>
<p>GoogleはSearchにおけるAI生成画像のラベル表示を拡充しているほか、C2PA（Content Provenance and Authenticity）に準拠したメタデータ対応も進めている。公式ブログによれば、Geminiアプリ・Vertex AI・Google Adsで生成される画像については、今週よりC2PA準拠のメタデータを自動付与する対応を開始するという。対象となるのはNano Banana Pro（Gemini 3 Pro Image）で生成された画像で、生成プロセスに関する追加情報を示すことで透明性を高めるとしている。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、誰でも学べるAI学習サイト「Google Skills」を正式公開──Cloud・DeepMind・教育部門を横断する3000講座を展開</title>
      <link>https://ledge.ai/articles/google_skills_ai_learning_platform_launch</link>
      <description><![CDATA[<p>Googleは2025年10月21日（米国時間）、新しいAI学習プラットフォーム「Google Skills」を<a href="https://blog.google/outreach-initiatives/education/google-skills/">発表</a>した。同サイトでは、Google Cloud、Google DeepMind、Grow with Google、Google for Educationなど、同社の複数部門が提供してきた教育コンテンツを統合。3000種類を超えるAI関連の講座・体験ラボ・認定プログラムを、一元的に学べる学習拠点として開設された。</p>
<h2>AI教育の中核を担う新サイト</h2>
<p>Google公式ブログ「Start learning all things AI on the new Google Skills」によると、Google Skillsは“AI for Everyone（すべての人のためのAI）”をテーマに、誰もがAIスキルを体系的に学べるよう設計されている。初心者、エンジニア、企業リーダーなど幅広い層を対象に、AI、データ分析、クラウド、生成AIなど多様な分野を網羅。各コースはオンデマンド形式で受講でき、学習成果はLinkedInなどの外部プラットフォームで共有できる。提供内容には、Google Cloudの認定資格プログラムやAI Essentials シリーズ、DeepMindのAI倫理教材などが含まれる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Qbix0BOPcgE">YouTube</a></p>
<p>今回の正式公開に先立ち、Google Cloudは10月10日付のブログ「Google Skills: Your new home for Google AI learning and more」で、新プラットフォームの構想を公表していた。当時は正式リリース前で、「AIやクラウドに関する学習リソースを一元化し、近日中に詳細を発表する」としていた。Gemini Code Assist（旧Duet AI for Developers）やQwiklabs（現Cloud Labs）と連携し、AIトレーニングの実践環境を統合する方針も示されていた。</p>
<h2>3000超のコースと実践的ラボを集約</h2>
<p>Google Skillsでは、Googleがこれまで個別に展開してきた学習リソースを一か所に集約。AIモデル開発、クラウド基盤運用、データ可視化、サイバーセキュリティなど、実践重視の3000超のコースとラボを提供する。一部コンテンツは無料で公開され、修了証や認定資格を取得することでキャリア開発にもつなげられる。また、組織向けにはチーム単位での進捗管理や学習成果の可視化機能も用意されている。</p>
<h2>今後の展望──教育機関・企業研修にも拡大へ</h2>
<p>Googleは今後、教育機関や企業研修への展開を進める方針を示しており、AIスキルの標準教育基盤としての活用を目指す。
公式ブログでは、「AI教育へのアクセスを民主化し、誰もがテクノロジーの未来を形づくる機会を得られるようにする」としている。
同社は今後もDeepMindやCloud AIチームの最新教材を追加し、AI人材育成をグローバルに推進する考えだ。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMはSNSの“ジャンク投稿”で脳が腐る？──米研究チームが「Brain Rot（脳腐敗）仮説」を提唱、推論力や安全性の劣化を確認</title>
      <link>https://ledge.ai/articles/llm_brain_rot_hypothesis_ai_junk_data_risk</link>
      <description><![CDATA[<p>テキサス大学オースティン校、テキサスA&amp;M大学、パデュー大学の研究者チームは2025年10月15日、LLM（大規模言語モデル）がSNSに溢れる “ジャンクデータ” によって徐々に劣化する可能性を示す研究「LLMs Can Get “Brain Rot”!」を<a href="https://llm-brain-rot.github.io/">発表</a>した。</p>
<p>研究チームは、X（旧Twitter）から収集した投稿データを用いた制御実験を行い、低品質テキストの混入が推論力・長文理解・安全性・人格的特性に一貫して悪影響を与えると報告している。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/teaser_cad83675ae/teaser_cad83675ae.png" alt="teaser.png" /></p>
<h2>SNSの“低品質テキスト”がモデル品質を損なう可能性</h2>
<p>研究チームが着目したのは、Web全体に含まれるユーザー生成コンテンツ、とりわけXに特徴的な「エンゲージメントは高いが内容が浅い投稿」だ。
これらは</p>
<ul>
<li>誤情報</li>
<li>攻撃的な表現</li>
<li>情報量の乏しい短文</li>
</ul>
<p>などが混在しやすく、AIモデルが大量に取り込むとどうなるかは十分に検証されてこなかった。</p>
<p>今回の研究では、こうした投稿を「ジャンクデータ」として体系的に扱い、その影響を測定するための仮説を「LLM Brain Rot（脳腐敗）仮説」と名づけた。</p>
<h2>実験方法：X投稿を「品質」と「人気度」で分類しモデルを再学習</h2>
<p>研究者らは、Xの投稿を以下の2軸で分類した。</p>
<ul>
<li>テキストの品質（semantic quality）</li>
<li>エンゲージメント（人気度）</li>
</ul>
<p>この組み合わせで複数のデータセットを構築し、既存のオープンソースLLMに対して再学習（fine-tuning）を実施。
評価には、</p>
<ul>
<li>推論タスク（ARC Challenge、ARC-Easy など）</li>
<li>長文コンテキスト理解（RULER）</li>
<li>安全性（有害発言誘発テスト）</li>
<li>“人格特性”に関する心理尺度（ナルシシズム、マキャベリズム、サイコパシーなど）</li>
</ul>
<p>が利用された。</p>
<h2>主な結果①：推論・読解能力が段階的に悪化</h2>
<p>研究では、低品質テキストの割合を増やすほど、推論・長文理解タスクのスコアが段階的に低下することが確認された。研究者らは変化の様子を「dose–response（用量反応）」に似ていると指摘している。</p>
<p>この “劣化の全体像” は、下図のように整理されている。</p>
<p><strong>〈図1〉推論タスク・人格特性の変化（Effective Size）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/effective_size_82aa2fbc8f/effective_size_82aa2fbc8f.png" alt="effective_size.png" />
低品質SNSデータで再学習すると、推論・読解（左）が悪化し、人格特性（右）も望ましくない方向へ変化する傾向が示された。</p>
<p>この図が示すように、</p>
<ul>
<li>ARC Challenge</li>
<li>RULER</li>
<li>HH-RLHF（安全性関連）</li>
</ul>
<p>ではいずれもスコアが低下。また人格特性に関しても、ナルシシズム・サイコパシー傾向などが上昇する結果となった。</p>
<p>さらに、モデルがどのように失敗するようになったかも分析されている。</p>
<p><strong>〈図2〉失敗パターンの増加（Failure Count）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/failure_mode_barplot_count_f4b1cff90d/failure_mode_barplot_count_f4b1cff90d.png" alt="failure_mode_barplot_count.png" />
低品質データで再学習したモデルほど、思考プロセスの失敗（“考えていない”“誤った論理”“事実誤認”など）が大幅に増加した。</p>
<p>この図が表している通り、</p>
<ul>
<li>no thinking（思考が全く行われない）</li>
<li>wrong logic in plan（計画の論理破綻）</li>
<li>factual error（事実誤認）</li>
</ul>
<p>などの“思考の崩壊”が顕著に増加している。</p>
<h2>主な結果②：安全性と“人格特性”にも悪影響</h2>
<p>推論能力の低下だけでなく、モデルの「振る舞い」や「性格的傾向」にまで変化が現れた。</p>
<ul>
<li>有害な発言を誘発しやすくなる</li>
<li>攻撃的・支配的・自己中心的な回答を返す傾向が強まる</li>
<li>不正確な主張を自信満々に述べるケースが増える</li>
</ul>
<p>研究チームはこれを、SNS特有の“攻撃性・扇動性のある投稿”を多く学習した結果として説明している。</p>
<h2>“主な結果③：“脳腐敗”は簡単には治らない</h2>
<p>モデルの性能が落ちたあとに、高品質データで“洗浄（wash-out）”すれば回復するのではないか──
研究者らはこの仮説も検証した。</p>
<p>結果は次の通り。</p>
<p><strong>〈図3〉洗浄（wash-out）実験：完全には回復しない</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wash_out_scaling_1114dafe8f/wash_out_scaling_1114dafe8f.png" alt="wash_out_scaling.png" />
ジャンクデータで劣化したモデルを高品質データで再学習しても、ARC-CやRULERなど複数タスクで性能が回復しきらず“残留劣化”が確認された。</p>
<p>グラフが示すように、洗浄後のモデルは“部分的な回復”こそ見られるものの、元の性能には戻らなかった。
研究者らはこれを「残留ダメージ（residual damage）」と呼び、“悪いデータを食べさせると、後から取り返しがつかない”可能性を指摘している。</p>
<h2>ChatGPT・Gemini・Claude・Grokにも影響しうる？</h2>
<p>研究はオープンソースLLMを用いた実験だが、論文は「Webテキストを学習するすべてのLLMに関わる問題」だと指摘している。</p>
<p>ChatGPT、Gemini、Claude、Grok など商用モデルがどの程度SNSテキストを取り込んでいるかは公開されていないが、Web全体のクロールデータを使う以上、“ジャンク比率”がモデル品質を左右する可能性は避けられないとする。</p>
<h2>今後の焦点：AIの“健康診断”として利用される可能性</h2>
<p>研究チームは、</p>
<ul>
<li>データ品質フィルタリングの強化</li>
<li>SNS由来データの評価と管理</li>
<li>「Brain Rot」兆候の定期的検査</li>
</ul>
<p>などを訓練パイプラインに組み込む必要性を訴える。</p>
<p>また、GitHub上では実験コードが公開されており、企業が自社モデルで同様の検証を再現できるようになっている。研究者らは、「SNS時代のデータ汚染がAIモデルに及ぼす影響を体系的に測定する第一歩になった」としており、今後は 他言語・他SNS・他文化圏データでの再検証が進むと見られる。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、「SAM 3」を発表──テキストや画像例をプロンプトに、画像・動画内の物体を一括検出・分割・追跡　併せて「SAM 3D」で人物・物体の3D生成にも対応</title>
      <link>https://ledge.ai/articles/meta_sam3_sam3d_release</link>
      <description><![CDATA[<p>Metaは2025年11月19日（現地時間）、画像および動画に含まれるオブジェクトを、プロンプトを基点に一括で検出・分割・追跡できる新モデル「Segment Anything Model 3（SAM 3）」を<a href="https://ai.meta.com/blog/segment-anything-model-3/">発表</a>した。同日、2D画像から人物や物体の3Dモデルを生成する「SAM 3D」も<a href="https://ai.meta.com/blog/sam-3d/">公開</a>している。</p>
<p>Metaの公式Xアカウント（@AIatMeta）は、両モデルを「新しい世代のSegment Anything Models」と<a href="https://x.com/AIatMeta/status/1991178519557046380">紹介</a>し、開発者・研究者向けのメディアワークフローを大きく拡張するとしている。</p>
<h2>SAM3：プロンプトから“概念”ベースで検出・分割・追跡</h2>
<p>SAM 3は、短いテキストフレーズ（例：「yellow school bus」）や、画像内のサンプルオブジェクトを示す “example prompt” を入力すると、該当するすべてのオブジェクトを一括して検出・分割し、動画では継続的に追跡できるモデル。Metaはこれを「Promptable Concept Segmentation（PCS）」と定義している。</p>
<p>@<a href="https://www.youtube.com/watch?v=G4OLPDjwncw">Youtube</a></p>
<p>アーキテクチャは、DETRベースの画像検出器と、SAM 2を基盤とした動画トラッカーを単一バックボーンに統合したもの。論文(https://ai.meta.com/research/publications/sam-3-segment-anything-with-concepts/)では、認識と位置特定を切り離す“Presence Head”を新たに採用し、概念ベースの検出精度を向上させたと説明されている。</p>
<p><strong>SAM 3は、テキストプロンプトを用いた検出と追跡を単一アーキテクチャで統合する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/SAM_3_architecture_overview_0af9a61c98/SAM_3_architecture_overview_0af9a61c98.jpg" alt="SAM 3 architecture overview.jpg" /></p>
<h2>400万概念を含む新データセット「SA-Co」</h2>
<p>SAM 3の開発にあたり、Metaは大規模データセット「<a href="https://github.com/facebookresearch/sam3/blob/main/README.md#sa-co-dataset">SA-Co（Segment Anything with Concepts）</a>」を新たに構築した。SA-Coは、数百万枚規模の高品質画像と約400万のユニーク概念、数千万のマスク情報を含むもので、モデルが幅広い概念を学習できるよう設計されている。</p>
<p>論文で示されたベンチマーク「SA-Co/Gold」では20万以上の概念を評価対象とし、SAM 3はLVISのゼロショットMask APで48.8を記録。従来モデル（38.5）を大きく上回った。</p>
<p><strong>SA-Coは、画像中の多様な物体を高精度にラベル付けする大規模データセット。色ごとに異なる概念カテゴリが示されている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/SA_Co_907d839e43/SA_Co_907d839e43.jpg" alt="SA-Co.jpg" /></p>
<p>SAM 3は、Metaの研究用ウェアラブルデバイス「<a href="https://ledge.ai/articles/meta_aria_gen2_ai_research">Aria Gen 2</a>」で撮影された一人称視点の映像に対しても高い性能を示す。動きの速さや視点の揺れが大きいファーストパーソン映像でも、対象物の分割と追跡を安定して行える点が特徴だ。</p>
<p>Metaは、Aria Gen 2 Pilot Datasetの一部を<a href="https://www.aidemos.meta.com/segment-anything">Segment Anything Playground</a>上で公開しており、これにより、人間の視点から世界を理解する“コンテクスチュアルAI”や、ロボティクス、機械知覚といった応用領域におけるSAM 3の有用性を示している。</p>
<h2>SAM 3D：1枚の画像から人物・物体の3Dモデルを生成</h2>
<p>同時に公開された「SAM 3D」は、人物に特化した「SAM 3D Body」と一般物体向けの「SAM 3D Objects」から構成される。Metaは、単一の2D画像から高精度で3D形状を復元でき、テクスチャとメッシュの情報を従来手法より忠実に再現できる点を強調している。</p>
<p>@<a href="https://www.youtube.com/watch?v=B7PZuM55ayc">Youtube</a></p>
<h2>2D解析から3D復元までを一貫化</h2>
<p>Metaは、SAM 3とSAM 3Dをセットで発表することで、画像・動画内のオブジェクト理解（SAM 3）から3D形状復元（SAM 3D）までを一貫して扱える視覚AI基盤を提示した。動画編集、AR/VR、ロボティクス、ECなど、多数の応用領域で利用可能性があるとしている。</p>
<p>公式Xでは、今回の発表を「新しい世代のSegment Anything Models」と説明し、SAM 3 と SAM 3D が画像・動画・3Dを横断する基盤技術として進化した点を強調している。投稿では、短いテキスト指示や具体例となる画像を用いた物体の検出・分割・追跡（SAM 3）、そして単一画像から人物や物体の3Dモデルを生成する機能（SAM 3D）が紹介され、「開発者と研究者が新しいメディア処理ワークフローを構築するためのツール」と位置づけている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/segment_anything_models_921509ea34/segment_anything_models_921509ea34.jpg" alt="segment anything models.jpg" /></p>
<p>:::box
[関連記事：AIの\</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/29 [SAT]18歳未満の自由チャット廃止を受け、自由会話から“物語選択式”へ──Character.AIが新機能「Stories」で未成年向け体験を再構築</title>
      <link>https://ledge.ai/articles/character_ai_stories_u18_safety_launch</link>
      <description><![CDATA[<p>AIキャラクターとの自由形式のチャットを18歳未満のユーザーに禁止すると10月に発表したCharacter.AIは11月27日（米国時間）、代替となる新しい対話機能「Stories」を正式に導入したことを<a href="https://blog.character.ai/introducing-stories-a-new-way-to-create-play-and-share-adventures-with-your-favorite-characters/">発表</a>した。</p>
<p>自由入力によるオープンエンド型の会話とは異なり、選択肢を選んで物語を進める「インタラクティブ・ストーリー形式」を採用する。未成年ユーザーも利用できる仕組みで、同社は「安全性を確保しながら創造的なAI体験を維持するための新しい方法」と位置づけている。</p>
<p>Storiesでは、AIキャラクターが登場人物やナレーターとして振る舞い、ユーザーは提示される選択肢からストーリーの展開を選ぶ。自由記述のテキスト入力はできず、物語の文脈に沿った応答が行われる点が特徴だ。ユーザーは既存のキャラクターが公開しているStoriesに参加できるほか、自らシナリオを作成して公開することも可能。公開前にはプラットフォーム側の安全性レビューが実施され、他の利用者にはリンク形式で共有できる。</p>
<p><strong>公式が公開した「Stories」サンプル一覧。ファンタジー、コメディ、ミステリーなど複数ジャンルの物語が用意され、選択肢を通じてストーリーを進める形式になっている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/characterai_data_d662534a06/characterai_data_d662534a06.jpg" alt="characterai data.jpg" /></p>
<p>今回の実装は、Character.AIが進めてきた未成年ユーザーの安全対策の延長線上にある。同社をめぐっては2024年、AIチャットボットに依存していたとされる14歳の少年が自殺した事件を受けて遺族が訴訟を起こし、対話型AIが若年層のメンタルヘルスに与える影響が議論となった。Ledge.aiでは当時、擬似的な友人関係を結ぶタイプのAIが依存を助長する懸念、そして専門家の指摘を報じていた。Character.AIはその後、利用ガイドラインの強化や未成年向けの利用制限を段階的に導入し、2025年10月には「18歳未満のオープンエンドなチャットを全面廃止する」と発表していた。</p>
<p>Storiesは、このチャット廃止後に未成年ユーザーへ提供される主要なAI体験として位置づけられる。自由会話の柔軟性はないものの、ストーリー形式によって創造的な没入体験は継続でき、同時に不適切な対話や依存リスクを抑えられる設計になっている。Character.AIは今後、Storiesの提供範囲を段階的に拡大し、コミュニティによる創作コンテンツの増加を見込むとしている。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>民放連「生成AIによる放送コンテンツ酷似映像」を問題視──無許諾学習の停止と削除対応を求める声明</title>
      <link>https://ledge.ai/articles/minporen_ai_learning_statement_20251126</link>
      <description><![CDATA[<p>日本民間放送連盟（民放連）は2025年11月26日、「生成ＡＩの開発・学習に関する声明」を<a href="https://j-ba.or.jp/category/topics/jba106724">公表</a>し、会員各社が権利を保有するコンテンツが無許諾で生成AIに学習されている可能性があるとして、開発事業者に対し明確な対策を求めた。</p>
<p>声明によると、OpenAIの動画生成サービス「Sora2（sora.chatgpt.com）」を通じて、民放連会員社のアニメ作品などと同一または酷似する映像が生成され、インターネット上で確認されているという。民放連は、これらの事例は会員社コンテンツが事前の許諾なく学習に使用された結果とみている。</p>
<p>民放連は、生成AIが不特定多数に向けて公開可能なコンテンツを作成する以上、開発段階の学習においても「享受を目的とする複製」に該当し、著作権者の許諾が必要になると指摘。無許諾学習は著作権侵害となり得るとしたうえで、違法アップロードコンテンツを学習に用いた場合には、侵害の深刻性がさらに増すと強調した。</p>
<p>また、無許諾学習や酷似映像の生成は、制作会社、クリエイター、出演者など多様な関係者の経済的利益や人格的利益を損ない、日本のコンテンツ制作文化やエンターテインメント産業のエコシステムを揺るがしかねないと懸念を示した。</p>
<p>報道分野への影響にも言及し、虚偽の災害映像や政治家の偽動画、外国人ヘイトを助長する映像など、いわゆるディープフェイクが流通した場合には、国民生活に重大な混乱を引き起こす可能性があるとした。出演者の偽動画を悪用した投資勧誘など、犯罪につながる行為への警戒も示している。</p>
<p>さらに、生成AI開発者側が提示する「オプトアウト方式」については、権利侵害の発生や類似映像の生成を十分に防げないとして、実効性が乏しいとの見解を示した。</p>
<p>声明では、生成AI開発者に対し次の3点を求めている。</p>
<ol>
<li>会員社コンテンツを無許諾で学習対象としないための措置を講じること。</li>
<li>会員社コンテンツと同一または類似する映像・画像が生成されないよう対策を講じ、既に 生成・流通しているものは削除に努めること（特に開発者が管理するサイトからの削除）。</li>
<li>生成AIに起因する著作権侵害について、会員社からの申立てに真摯に対応すること。</li>
</ol>
<p>今回の声明は、放送業界として生成AIの無許諾学習に対し明確な立場を示したもので、放送コンテンツの権利保護や安全性に関する問題が公式に整理された形となる。</p>
]]></description>
      <pubDate>Sat, 29 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ワーナー・ミュージック、Sunoと和解し提携へ──訴訟から「ライセンス型AI音楽」へ転換、2026年に新モデルと料金体系を導入</title>
      <link>https://ledge.ai/articles/warner_music_suno_licensing_partnership_2026_model_update</link>
      <description><![CDATA[<p>世界3大レコードレーベルのひとつである Warner Music Group（WMG）は11月25日（米国時間）、音楽生成AIサービスを手がける米Sunoと「ライセンスパートナーシップ」を締結したと<a href="https://www.wmg.com/news/warner-music-group-and-suno-forge-groundbreaking-partnership">発表</a>した。両社間で進行していた法的係争は、この合意によって解決されたことも明らかにされた。Suno側も同日付で公式ブログを公開し、提携の事実と今後のプロダクト方針を説明している。</p>
<h2>クリエイター保護を前提とした「ライセンス型AI音楽」へ</h2>
<p>WMGは今回の提携を、「音楽の制作・インタラクション・発見をめぐる新たなフロンティアを開く」と位置づけている。アーティストやソングライターを「保護し、適切に補償する」枠組みを掲げ、SunoのAI技術と同社のアーティスト開発力・テクノロジー面の知見を組み合わせると説明した。</p>
<p>同社は、AI生成で使われるアーティストの「名前・画像・肖像・声・楽曲」について、本人（または権利者）がオプトイン方式で利用範囲をコントロールできる仕組みを提供すると明記。生成AIによる二次利用に対し、アーティスト側に新たな収益機会を生むモデルを整備する方針を示した。</p>
<p>WMGのRobert Kyncl CEOは、「クリエイティブコミュニティにとっての勝利」とコメントし、ライセンス済みAIモデルの普及と、アーティストへの補償を両立する枠組みの必要性を強調した。</p>
<h2>Sunoは「インタラクティブな音楽体験」強化を表明</h2>
<p>SunoのMikey Shulman CEOはブログで、今回のパートナーシップを「インタラクティブな音楽の未来を形作る次のステップ」と述べた。同社は、現在のユーザーコミュニティが「約1億人規模」に成長しているとし、Sunoでの創作体験を維持したまま、より高度なライセンス済みモデルを導入する方針を説明した。</p>
<p>Sunoによると、オプトインしたWMGアーティストについては、ファンがそのアーティストの「声・サウンド・音楽的特徴」を用いた創作が可能になる。Suno側は、これによりアーティストが新たな収益を得られ、ユーザーは適切なライセンスのもとで創作できる仕組みになると説明している。</p>
<h2>2026年に新モデル導入、現行モデルは廃止へ</h2>
<p>両社の発表では、2026年に「ライセンス済みの新モデル」を導入し、現在のモデルを廃止する方針が示された。</p>
<p>料金体系についても大きく変更される。</p>
<ul>
<li>無料ユーザーは、作成した楽曲をダウンロードできなくなり、再生・共有のみ可能となる。</li>
<li>有料ユーザーは、月間のダウンロード上限が設定され、上限を超える分は追加料金となる。</li>
<li>プロ向けの「Suno Studio」では、現行の無制限ダウンロードなどの機能を維持しつつ、引き続き機能拡張を行うと説明している。</li>
</ul>
<p>Sunoは、新モデルについて「現行のv5を上回る高度なモデルになる」としており、ライセンス済みデータを含む新たな学習体系に基づいた生成性能の強化を示唆した。</p>
<h2>ライブ情報サービス「Songkick」はSunoへ移管</h2>
<p>WMGは、ライブ情報／チケットディスカバリーサービス「Songkick」をSunoへ移管したことも発表した。Sunoは同サービスを引き続き運営し、オンライン上の創作体験とライブパフォーマンスの接続を強める構想を示している。</p>
<p>両社は今後、アーティストの権利を尊重しつつ、ファンやクリエイターに新しい音楽体験を提供する「ライセンス型AI音楽プラットフォーム」の構築を進めるとしている。</p>
]]></description>
      <pubDate>Fri, 28 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/28 [FRI]マネーフォワード、『AI確定申告』β版を提供開始──AIエージェントが自動作成し、ユーザは「チェック＋提出」のみで完結</title>
      <link>https://ledge.ai/articles/moneyforward_ai_tax_return_beta_launch</link>
      <description><![CDATA[<p>マネーフォワードは2025年11月25日、同社初のAIネイティブプロダクトとなる「マネーフォワード AI確定申告」（β版）の提供開始を<a href="https://corp.moneyforward.com/news/release/service/20251125-mf-press-2/">発表</a>した。AIが領収書などの必要書類を解析し申告内容を自動作成するサービスで、ユーザーは内容をチェックし、e-Taxや『マネーフォワード クラウド確定申告』などを通じて提出することで、確定申告を完了できる。</p>
<p>同社はコンセプトを「AIではじまる、新しい確定申告」と位置づけ、確定申告の初心者や会計知識に不安のある個人事業主でも、作業負担や心理的ハードルを下げられるサービスだとしている。</p>
<h2>AI-OCRと生成AIで申告内容を自動生成</h2>
<p>『マネーフォワード AI確定申告』は、なるべく簡単・シンプルに申告を終えたいユーザー向けに設計されたAIネイティブな確定申告サービスだ。ユーザーが溜まった領収書をアップロードすると、AI-OCRが金額や日付、取引内容を読み取り、その情報をもとに生成AIが申告内容のデータをまとめる。</p>
<p>取引ごとに「交際費」「交通費」などのカテゴリと、その判定理由が表示されるのも特徴だ。どのような考え方で分類されたのかを確認できるため、会計用語に慣れていないユーザーでも、内容を追いながら申告準備を進めやすいとしている。</p>
<p>β版では、領収書の読み取りと申告内容の自動作成（「AIおまかせ領収書整理」）、AIによる解析結果・判定理由の確認、収支・純利益の自動計算といった機能を無料で提供する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251125_MFAI_54e143bf4c/20251125_MFAI_54e143bf4c.gif" alt="20251125_MFAI.gif" /></p>
<h2>対象ユーザーと対応範囲</h2>
<p>サービスの対象は、事業収入があり、不動産収入のない免税事業者。現時点では、不動産所得や農業所得、消費税の計算には対応していない。確定申告書そのものの作成機能は含まれておらず、申告書の作成・提出には『マネーフォワード クラウド確定申告』などのサービスやe-Taxを併用する必要がある。</p>
<p>また同社は、AIの出力結果についてはユーザー自身による確認を求めており、判断が難しい場合は税理士など専門家の助言を受けるよう呼びかけている。</p>
<h2>2026年以降に機能拡張、書類対応やスマホ対応も</h2>
<p>同社は、β版提供後も機能を段階的に拡充する計画を示した。2026年1月には、確定申告用の明細ファイルをダウンロードできる機能を提供する予定だという。</p>
<p>その後は、源泉徴収票や保険料・医療費控除書類の解析・計算・反映機能（特許申請中）、スマートフォンからの撮影・アップロード機能（同）、スマートフォンアプリ、申告書の作成・提出機能、銀行・金融サービスとの連携などを順次追加していく構想を示している。</p>
<h2>既存のクラウド確定申告と並行提供、AIネイティブ路線を拡大へ</h2>
<p>同社はこれまで、会計ソフトをベースにした『マネーフォワード クラウド確定申告』で個人事業主の申告業務を支援してきた。一方で、多機能で入力項目も多い従来型のソフトは、「できるだけ手間なく簡単に終えたい」という初心者層のニーズに十分応えられていなかったという。</p>
<p>『マネーフォワード AI確定申告』は、そうしたユーザー向けに確定申告のプロセスそのものをAI前提で再設計したプロダクトと位置づけられる。今後は、ユーザーが自身の会計知識や事業規模、ライフステージに応じて『クラウド確定申告』と『AI確定申告』を使い分けられるようにしつつ、確定申告以外のバックオフィス業務にもAIネイティブなサービスを広げていく方針だ。</p>
]]></description>
      <pubDate>Fri, 28 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、AIアシスタント「Meta AI」の日本提供を正式発表──Messenger・Instagram・WhatsAppで順次利用可能に</title>
      <link>https://ledge.ai/articles/meta_ai_japan_rollout_2025</link>
      <description><![CDATA[<p>Metaは2025年11月25日、同社のAIアシスタント「Meta AI」を日本で順次提供開始することを<a href="https://about.fb.com/ja/news/2025/11/meta-ai-gradual-rollout-begins-in-japan/">発表</a>した。Meta AIの国内展開が公式に示されるのは今回が初めてで、同社の主要アプリ群に段階的に組み込まれる。</p>
<p>Meta AIは、Llama 3系モデルを基盤とした対話型アシスタントで、検索補助、質問応答、情報探索、画像生成などの機能を備える。Metaは、自然言語の理解力や推論性能の高さ、応答速度の改善を特徴として挙げている。</p>
<p>提供対象はMessenger、Instagram、WhatsApp、Facebookアプリ内など。各アプリのチャット入力欄や検索画面から直接呼び出せる設計となっており、コンテンツ探索から日常的なタスク補助まで、サービス横断で利用できる。InstagramやMessengerでは、チャット中にMeta AIへ質問したり、Reelsの発見タブで関連情報を得るといった操作が可能になる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Meta_AI_Gradual_Rollout_ac8a0fc919/Meta_AI_Gradual_Rollout_ac8a0fc919.jpg" alt="Meta-AI-Gradual-Rollout.jpg" /></p>
<p>画像生成機能も展開される。テキストからの静止画生成に加え、一部ではリアルタイムに変化する生成画像の活用にも対応するという。生成した画像はメッセージ内で共有・編集でき、クリエイティブ用途にも利用可能。</p>
<p>日本での提供は段階的に行われ、まずは一部ユーザーから導入し、数週間から数カ月かけて利用対象を拡大する。Metaはプライバシーと安全性を重視した運用方針を示すとともに、利用者からのフィードバックを取り入れながら改善を続けるとしている。</p>
<p>Meta AIはすでに複数地域で展開されており、今回の日本投入は同社のグローバル展開計画の一環となる。</p>
]]></description>
      <pubDate>Fri, 28 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米政府、AIで科学研究を国家規模で加速へ──トランプ大統領が「Genesis Mission」を創設する大統領令に署名</title>
      <link>https://ledge.ai/articles/genesis_mission_executive_order_launch</link>
      <description><![CDATA[<p>米ホワイトハウスは2025年11月24日（現地時間）、ドナルド・トランプ大統領が、AIを活用して科学研究の発見や開発速度を加速するための国家的取り組み「Genesis Mission（ジェネシス・ミッション）」を創設する大統領令に署名したと<a href="https://www.whitehouse.gov/presidential-actions/2025/11/launching-the-genesis-mission/">発表</a>した。同日公開された<a href="https://www.whitehouse.gov/articles/2025/11/president-trump-launches-the-genesis-mission-to-accelerate-ai-for-scientific-discovery/">公式記事</a>では、同ミッションの背景、目的、政府関係者の発言が紹介されており、AIを中核とした新たな科学研究推進体制が明らかになった。</p>
<h2>AIで科学的発見を加速する国家プログラムを創設</h2>
<p>Genesis Mission は、アメリカが保有する「世界有数の科学データ」と「最先端のAI技術」を統合し、医療、材料、エネルギー、バイオ技術、宇宙、国家安全保障などの分野で科学的発見を加速することを狙う国家プログラムとして位置づけられている。</p>
<p>大統領令では、同ミッションを推進するため、連邦政府が保有する科学研究データを統合し、大規模AIモデルやAIエージェントを開発・展開する「統合AIプラットフォーム」の構築が命じられた。目的は、仮説生成、実験計画、シミュレーション、解析などの研究プロセスをAIで高速化し、研究生産性の向上を図ることにある。</p>
<h2>エネルギー省（DOE）が中心的役割を担う</h2>
<p>ホワイトハウスの記事と大統領令の双方において、米エネルギー省（DOE）がGenesis Missionの中核機関として明記されている。DOE が管理する国立研究所（National Labs）は、世界最大級の科学データセットとスーパーコンピュータを所有しており、AIモデルの開発・実行基盤を提供する役割を担う。</p>
<p>また、大統領令では、DOE長官が他省庁と協力し、研究データの共有や連携体制の構築、AI活用方針の調整を進めることが求められている。さらに、研究者とAIエージェントが協働できる環境を整備するほか、国立研究所・大学・民間企業との官民パートナーシップの強化も指示された。</p>
<h2>政府関係者「アメリカの科学力を次の段階へ」</h2>
<p>科学技術担当大統領補佐官の Michael Kratsios 氏 は、Genesis Mission を「アメリカの科学研究の基盤を強化し、国家的優位性を高めるための取り組み」と説明。世界中で競争が激化するAI研究分野において、米国の技術力と研究インフラを活かし、科学的ブレイクスルーを継続的に生み出す必要性を強調した。</p>
<p>また、担当閣僚や行政スタッフによるコメントでは、ミッションがエネルギー・医療・国家安全保障など多様な分野で応用される見込みが示されている。</p>
<h2>大統領令が規定する具体的な指示</h2>
<p>大統領令「Launching the Genesis Mission」は、研究の生産性向上に加え、科学的知識の創出速度を国家レベルで高めることを目的としており、以下のような具体的方針が含まれる。</p>
<ul>
<li>連邦政府が保有する科学データの統合と共有</li>
<li>科学研究に特化したAIモデル・AIエージェントの開発</li>
<li>DOEを中心とした省庁横断タスクフォースの設置</li>
<li>研究者とAIが協働する研究環境の整備</li>
<li>国家重要分野（エネルギー、バイオ、量子、材料科学、半導体など）でのAI活用促進</li>
<li>国家安全保障・経済競争力の観点からのAI活用を明記</li>
</ul>
<p>大統領令に基づき、関連省庁は一定期間内に詳細な行動計画をまとめ、研究データ統合のロードマップや実施体制の整備を進める。政府・大学・国立研究所・民間企業を含む幅広いパートナーシップのもと、AIを活用した科学研究の新たな枠組みが形成されるという。</p>
]]></description>
      <pubDate>Thu, 27 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GoogleのAIモードに広告が出現、海外ユーザーからの報告──Googleは「既存テストの一部」とコメント</title>
      <link>https://ledge.ai/articles/google_ai_mode_ads_integration_test_expands</link>
      <description><![CDATA[<p>Google検索の「AI Mode（AIモード）」に、広告（Sponsored）が直接統合されて表示される事例が11月中旬から海外ユーザーにより相次いで報告されている。いずれのスクリーンショットでも、AIが生成した回答の直下に広告ユニットが挿入されており、表示形式が従来の検索広告とは異なる点が確認された。</p>
<p>こうした事例は主に英語圏の検索業界関係者から報告されており、SEOコンサルタントの Brodie Clark 氏 が2025年11月21日（現地時間）に投稿した事例をはじめ、複数のユーザーが X（旧Twitter）で広告表示のスクリーンショットを共有している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/brodie_the_time_has_come_b63a519136/brodie_the_time_has_come_b63a519136.jpg" alt="brodie the time has come.jpg" /></p>
<p>Googleは2025年5月21日、<a href="https://blog.google/products/ads-commerce/google-search-ai-brand-discovery/">公式ブログ</a>でAI Modeにおける広告テスト開始の方針を明らかにしており、今回の報告はそのテストが検索画面上で可視化され始めたものとみられる。</p>
<h2>AIモードの広告表示、Googleは5月にテスト開始を公式に発表</h2>
<p>5月21日の公式ブログ「<a href="https://blog.google/products/ads-commerce/google-search-ai-brand-discovery/">More opportunities for your business on Google Search</a>」では、AI OverviewsおよびAI Modeを新たな検索体験として位置づけるとともに、AI Modeで広告のテストを開始したと明記されている。広告はAI回答の下部に自然に統合され、Performance Max や Shopping Ads を含む既存キャンペーンが表示対象となることも説明されていた。</p>
<p>また、Google広告製品担当の公式アカウント Ads Liaison（Ginny Marvin 氏） は11月21日、Brodie Clark 氏の投稿に対し「AI Modeの広告は、5月のGoogle Marketing Liveでの発表以降、数カ月にわたりテストを続けている」と<a href="https://x.com/adsliaison/status/1991969383414210845">返信</a>。このコメントから、今回の広告表示は「新規ローンチ」ではなく 既存テストの一環 として位置づけられていることがわかる。</p>
<p>Clark氏はこれに対し、公式アナウンスから実際の画面で目撃されるまでには時間差があることを指摘し、自身は「新機能が“野生で初めて見つかるタイミング”を重視している」と補足した。</p>
<h2>最初の報告例：Greg Sterling 氏がHVAC検索で広告表示を確認</h2>
<p>11月19日、マーケティングアナリスト Greg Sterling 氏（@gsterling） は、AI Modeで「HVAC repair」の検索を行った際に広告が表示されたスクリーンショットをXに投稿した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/saw_first_ads_in_aimode_c50debed95/saw_first_ads_in_aimode_c50debed95.jpg" alt="saw first ads in aimode.jpg" /></p>
<p>スクリーンショットでは、AIの回答直下に「Sponsored」と表示されたローカルサービス広告が2件並んでおり、AI Mode内に広告ユニットが直接組み込まれている様子が確認できる。Sterling 氏の例は「最初に目撃されたケース」として複数の海外メディアで紹介された。</p>
<h2>Brodie Clark 氏が“通常UI”での広告表示を報告、Labs以外にも拡大か</h2>
<p>Sterling 氏のケースが「Labsインターフェース（実験機能）」での表示だったのに対し、Brodie Clark 氏は Labsではない通常の検索UI でもAI Mode内に広告が表示されることを確認した点が特徴的だ。</p>
<p>Clark 氏は複数の検索（ベッドシーツ比較や emergency plumber など）で広告を再現し、表示位置はいずれも AI回答の最下部 だったと説明している。これにより、広告表示が「Labs限定」ではなく、一部環境では一般ユーザーのインターフェース上でも行われていることが判明した。</p>
<h2>AI Overviewsに続き、広告統合はAI Modeへも拡大か</h2>
<p>GoogleはAI Overviewsでも広告統合のテストを開始しており、表示形式（回答最下部への自然な挿入）は今回のAI Modeの例と共通している。</p>
<p>現時点で、GoogleはAI Modeでの広告表示の地域展開や時期に関する追加アナウンスを行っていない。テストは一部ユーザー環境で継続しているとみられる。日本語UI（google.co.jp）や日本のユーザー環境で、AI Mode内に広告が表示された報告は現在のところ確認されていない。</p>
]]></description>
      <pubDate>Thu, 27 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/27 [THU]OpenAI、ChatGPTに商品調査・比較を自動化する「ショッピング リサーチ」追加──ホリデーシーズンに向け“ほぼ無制限”で提供、Perplexityも同種機能を発表</title>
      <link>https://ledge.ai/articles/chatgpt_shopping_research_openai_perplexity_launch</link>
      <description><![CDATA[<p>OpenAIは2025年11月24日（現地時間）、ユーザーの購入検討を支援する新機能「shopping research」（日本では「ショッピング リサーチ」）をChatGPTに追加したと<a href="https://openai.com/index/chatgpt-shopping-research/">発表</a>した。</p>
<p>自然言語で希望条件を伝えるだけで、AIが商品調査や比較分析を行い、候補を絞り込む仕組みだ。</p>
<p>同機能は、ユーザーが用途や予算、こだわり条件などを入力すると、ChatGPTが必要に応じて質問を重ねながらニーズを把握し、ネット上の情報をもとに候補を提示する。提示形式は「バイヤーズガイド」としてまとめられ、商品ごとの特徴や検討ポイントも整理される。</p>
<p>対象プランはChatGPT Free、Go、Plus、Pro。ログイン済みユーザーに対して、モバイルアプリとWeb版を通じて順次提供を開始した。OpenAIは、ホリデーシーズンに向けて「ほぼ無制限で利用可能」としている。</p>
<p>調査内容には、商品仕様、レビュー、価格、画像などが含まれるが、OpenAIは「価格や在庫情報、レビューの正確性に誤りが生じる可能性がある」と明記しており、最終確認はユーザーが行う必要があると注意喚起している。また今後は、対応するリテーラーにおいてチャット内で購入を完結できる「Instant Checkout」との連携も予定する。</p>
<p>一方、米Perplexityも11月25日（現地時間）、無料のショッピング機能を米国のすべてのユーザー向けに提供開始したと<a href="https://www.perplexity.ai/ja/hub/blog/shopping-that-puts-you-first">発表</a>した。</p>
<p>@<a href="https://www.youtube.com/watch?v=3Z6_ogRyyHc">Youtube</a></p>
<p>商品カテゴリや条件に基づく検索や比較、候補提示を行えるほか、PayPalとの提携により、PayPalに対応する加盟店についてはPerplexity上でそのまま決済まで完了できる。決済処理はPayPalが担い、加盟店は従来どおりマーチャント・オブ・レコードとして顧客との関係や返品対応を保持する。OpenAIの発表から一日後の提供開始となり、主要AI企業が相次いで“商品選び支援”機能を投入した形だ。</p>
]]></description>
      <pubDate>Thu, 27 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米アマゾン、米政府向けAI・スーパーコンピュータ基盤に最大500億ドル（約7.8兆円）投資──AWSの機密クラウド全レベルで1.3GWを増強</title>
      <link>https://ledge.ai/articles/amazon_us_government_ai_supercomputing_50b_investment</link>
      <description><![CDATA[<p>Amazonは202511月24日（米国時間）、米政府機関向けにAIおよびスーパーコンピューティング基盤を拡張するため、米国内のデータセンターに最大500億ドル（約7兆8000億円）を投資すると<a href="https://www.aboutamazon.com/news/company-news/amazon-ai-investment-us-federal-agencies">発表</a>した。
投資は2026年に着工予定で、AWS Top Secret、AWS Secret、AWS GovCloud（US）など政府専用クラウドの全レベルにまたがって、約1.3ギガワット分の計算能力を追加する計画だ。</p>
<p>発表では、連邦政府機関が利用できるAIサービスも幅広く示されている。Amazon SageMakerによる学習・カスタマイズ、Amazon Bedrockを通じた基盤モデル活用、同社の新世代モデル「Amazon Nova」、Anthropic Claude、各種オープンウェイトモデルなどが挙げられ、これらをAWS TrainiumやNVIDIAのAIインフラストラクチャと組み合わせて利用できるとしている。</p>
<p>ユースケースとしては、大規模データの統合解析やシミュレーションをAIで加速させる内容が説明された。数十年分のグローバル・セキュリティデータをリアルタイムに分析し複雑なパターンを抽出する取り組みや、衛星画像・センサーデータを統合した脅威検知の高度化などが例示され、防衛・インテリジェンス、サイバーセキュリティ、医療・ヘルスケア研究など多様な領域に適用される見込みだ。</p>
<p>AWSのCEOであるマット・ガーマン氏は、政府専用設計のAI・クラウドインフラへの大規模投資が、連邦政府機関におけるスーパーコンピューティングの活用を根本的に変えると強調した。サイバーセキュリティや創薬などの重要ミッションを加速し、AI時代における米国のリーダーシップをさらに強固にするものだと述べている。</p>
<p>Amazonは今回の投資を、政府向けクラウドインフラの歴史的な延長線上に位置づける。2011年のAWS GovCloud（US-West）、2014年のAWS Top Secret-East、2017年のAWS Secret Regionなど、機密区分に対応したクラウドリージョンを段階的に整備してきた経緯が示され、オンプレミス環境に依存してきた政府機関がより柔軟にAI・HPCリソースを活用できるようになると説明している。</p>
<p>AWSはあわせて、政府向けAI活用事例や技術解説をまとめた特設ページ「America AI」へのリンクも提示している。今回の発表では、拡張後の計算能力やAIサービスによって、米政府の各種ミッションを支援するための基盤を段階的に整備していく方針が示された。</p>
]]></description>
      <pubDate>Wed, 26 Nov 2025 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>