<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>ARグラスだけで2D→3D変換を実現　新モデル「XREAL 1S」ーーXREAL、日本先行で予約受付を開始　2026年1月下旬発売へ</title>
      <link>https://ledge.ai/articles/xreal_1s_2d_to_3d_ar_glasses_launch</link>
      <description><![CDATA[<p>XREALは12月1日、新型ARグラス「XREAL 1S」を<a href="https://prtimes.jp/main/html/rd/p/000000226.000070978.html">発表</a>し、同日より日本で予約受付を開始した。発売は2026年1月下旬を予定。日本がグローバルで初の発表および予約開始地域となる。価格は6万7,980円（税込）。</p>
<p>同製品は、ARグラス単体で2D映像を3D映像へリアルタイムに変換し、空間上に大画面として表示できる点が最大の特徴。映画や動画コンテンツを、スマートフォンやPCを接続せずに立体化できる「空間ディスプレイ」として機能するという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/70978_226_48b718eda105e60902793c5b6cd42fec_2475x2475_3ec3f53823/70978_226_48b718eda105e60902793c5b6cd42fec_2475x2475_3ec3f53823.webp" alt="70978-226-48b718eda105e60902793c5b6cd42fec-2475x2475.webp" /></p>
<p>XREAL 1Sは映像の立体化に加え、高輝度ディスプレイや装着性の向上を図った設計を採用。長時間利用を前提とした軽量化も進められている。XREALの周辺機器やエコシステムとの連携にも対応し、今後の拡張にも備えたモデルとなる。予約はXREAL公式ストアなどで受け付けており、発売は2026年1月下旬を予定している。</p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>デジタル庁、プリファードの国産LLM「PLaMo翻訳」をガバメントAIに導入──12月に庁内利用開始、2026年から他府省へ展開</title>
      <link>https://ledge.ai/articles/digital_agency_plamo_translation_government_ai_launch</link>
      <description><![CDATA[<p>デジタル庁は2025年12月2日、Preferred Networks（PFN）が開発する日本語特化型の国産LLM「PLaMo翻訳」をガバメントAI環境「源内（げんない）」に導入し、政府職員向けに提供すると<a href="https://www.digital.go.jp/news/b27d1af7-c231-4ab3-ad78-fc5408d44504">発表</a>した。2025年12月中にデジタル庁内での利用を開始し、2026年以降は他府省庁への展開を計画する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image_12_5c1580a084/image_12_5c1580a084.png" alt="image(12).png" /></p>
<p>「源内」は、政府職員がセキュアな環境で生成AIを業務利用できるよう整備が進められているガバメントAI基盤で、デジタル庁では2025年5月から全職員向けに提供してきた。今回の「PLaMo翻訳」導入は、国内開発AIを行政実務で活用する取り組みの一環として位置付けられる。</p>
<p>PFNの「PLaMo翻訳」は、日本語と英語の翻訳に特化した国産大規模言語モデルで、長文でも自然で一貫性のある文章を生成できる点を特長とする。ニュース記事や行政文書、会話文など幅広い文体に対応し、和文の自然さを損なわずに翻訳できるよう最適化されている。デジタル庁は、行政実務における翻訳業務の効率化につながるモデルとして活用を進める。</p>
<h2>ガバメントAIで試用する国内開発AIモデルの公募も</h2>
<p>同日、デジタル庁は「ガバメントAIで試用する国内大規模言語モデル（LLM）の公募」も<a href="https://www.digital.go.jp/news/1b093bba-a4c8-4001-8a92-ff3667a69198">開始</a>した。対象は国内で開発されたLLMや特定領域向けのSLM（Small Language Model）で、ガバメントクラウド上で安全に動作できることが条件となる。公募期間は2025年12月2日から2026年1月30日まで。選定されたモデルは、2026年夏頃から「源内」上で試験的に利用される予定だ。</p>
<p>2026年度には「源内」の他府省庁展開が予定されており、評価結果や各府省庁のニーズを踏まえ、2027年度以降に国内LLMの本格導入が検討される。</p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>国税庁、AI活用で追徴税額3,811億円──法人税・消費税は3,407億円で直近10年最高に</title>
      <link>https://ledge.ai/articles/nta_ai_tax_audit_2024_3811oku</link>
      <description><![CDATA[<p>国税庁は2025年12月2日、2024事務年度（令和6事務年度、2024年7月〜2025年6月）の「法人税等の調査事績の概要」を<a href="https://www.nta.go.jp/information/release/kokuzeicho/2025/hojin_chosa/index.htm">発表</a>した。</p>
<p>法人税・法人消費税の追徴税額は3,407億円となり、直近10年で最高額を記録した。また、源泉所得税の追徴税額404億円と合わせると、3税目の合計は3,811億円となった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c3345ac9f5/_c3345ac9f5.jpg" alt="追徴税額の推移　法人税消費税.jpg" /></p>
<p>資料では、調査先の選定にあたり「AIも活用しながら、あらゆる機会を通じて収集した資料情報等や申告書の分析・検討を行う」と明記。調査必要度の高い法人を的確に抽出し、実地調査を実施したとしている。</p>
<p>実地調査件数は5万4,000件（前年比▲7.4%）と減少した一方、1件当たりの追徴税額は増加した。法人税・消費税の追徴税額は、令和2事務年度の2,157億円から増加基調が続いており、令和6事務年度は3,407億円に達した。</p>
<p>重点分野として、国税庁は消費税還付申告法人、海外取引法人、無申告法人を挙げている。源泉所得税では、調査件数1万1,700件、追徴税額404億円（前年比＋20.5%）と、給与・報酬などの源泉徴収漏れに関する指摘が増えた。</p>
<p>国税庁は2023年に示した「税務行政の将来像」において、AIやデータ分析を活用した調査先選定やリスク分析の高度化を掲げている。今回公表された事績では、実地調査件数を抑制しつつ追徴税額を高水準で維持しており、AI活用を含む調査の効率化が進んだ形となった。</p>
]]></description>
      <pubDate>Thu, 04 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>note、AIアシスタントに「Gemini 3 Pro」を導入──メモ段階から構成・言い換えまで執筆支援を強化</title>
      <link>https://ledge.ai/articles/note_gemini3pro_ai_assistant_update</link>
      <description><![CDATA[<p>note株式会社は2025年12月2日、同プラットフォームのAIアシスタントに Google の最新生成AIモデル「Gemini 3 Pro（プレビュー版）」を導入したと<a href="https://note.jp/n/n655ea4dcd39a">発表</a>した。アイデアの断片やメモ段階の入力から文章構成の提案、言い換え、表現改善まで、執筆プロセス全体を支援する機能が拡充される。</p>
<p>noteは「誰もが創作をはじめ、続けられるようにする」ことをミッションに掲げており、AIアシスタント機能はその一部として提供されてきた。従来も文章の書き出しや言い換え提案などが可能だったが、今回のアップデートにより、文章構成や着想の深掘りなど、より幅広い工程をサポートするようになった。</p>
<p><strong>AIアシスタント利用シーンの一例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1764577930_Zqk8_D_Hr_R_Pma3_Gg_Mf_EY_2_Qxb_Vw_1_88e9b02458/1764577930_Zqk8_D_Hr_R_Pma3_Gg_Mf_EY_2_Qxb_Vw_1_88e9b02458.webp" alt="1764577930-Zqk8DHrRPma3GgMfEY2QxbVw (1).webp" /></p>
<p>Gemini 3 Pro の導入により以下の機能が強化されたという。</p>
<ul>
<li>メモやアイデア断片から記事構成案や書き始めを生成</li>
<li>文章のリライト（言い換え・簡潔化・読みやすさ改善）</li>
<li>表現の調整や文章の要約</li>
<li>思考の深掘りや視点の追加提案</li>
</ul>
<p>noteは、AIアシスタントを利用することで「書きたいテーマはあるが、何から書けばよいか分からない」といった初期段階の課題に対応できるとしている。「AIが持つアイデア着想力や書き出しのサポートは、執筆に不慣れなユーザーの負担を軽減する」と説明する一方、生成内容への依存を避け、創作の主体はあくまでユーザー自身である点への注意も呼びかけている。</p>
<p>AIアシスタントは投稿画面から利用でき、文章やメモを入力することで提案内容が生成される。利用は無料で、今後は品質改善やガイドライン整備などを継続していくとしている。</p>
<p>noteは今回のモデル刷新により、執筆支援機能を強化し、より多様な創作者が利用しやすい環境づくりを進めている。</p>
]]></description>
      <pubDate>Thu, 04 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AppleのAI戦略トップ、ジョン・ジャナンドレア氏が退任へ──後任にMicrosoft出身のアマル・スブラマニヤ氏、副社長としてAI部門を統括</title>
      <link>https://ledge.ai/articles/apple_ai_leadership_change_giannandrea_subramanya</link>
      <description><![CDATA[<p>Appleは2025年12月1日（現地時間）、機械学習およびAI戦略担当シニアバイスプレジデント（SVP）を務めるジョン・ジャナンドレア氏が職務を退き、2026年春の退職までアドバイザーとして同社に残ると<a href="https://www.apple.com/newsroom/2025/12/john-giannandrea-to-retire-from-apple/">発表</a>した。
同時に、MicrosoftやGoogleでAI研究を率いてきたアマル・スブラマニヤ氏が「Vice President of AI（AI担当副社長）」としてAppleに加わったことも明らかにした。</p>
<h2>ジャナンドレア氏は2026年春までアドバイザーに就任</h2>
<p>発表によると、ジャナンドレア氏はAIおよび機械学習戦略の中核としてAppleの活動を牽引してきたが、今回の人事にともないSVP職を離れ、退職までアドバイザーとして移行する。2018年に同社へ加わって以降、世界規模のAI・MLチームの構築や主要機能の開発を主導してきた人物で、Appleはその貢献を評価している。</p>
<h2>後任スブラマニヤ氏、Foundation ModelsやAI安全性評価を統括</h2>
<p>後任としてAppleに参加したアマル・スブラマニヤ氏は、Craig Federighi氏（ソフトウェアエンジニアリング担当シニアバイスプレジデント）の直属となる。同氏は、新役職「Vice President of AI」として、Apple Foundation Models、機械学習研究（ML Research）、AI Safety and Evaluationの3領域を率いる。</p>
<p>スブラマニヤ氏は、直前までMicrosoftでCorporate Vice President of AIを務め、さらに以前には16年にわたりGoogleに在籍。Google退任時には「Google’s Gemini Assistant」のエンジニアリング責任者を務めるなど、AIの基盤研究と製品統合の双方に実績を持つ。</p>
<h2>AI組織の一部はKhan氏・Cue氏の管掌へ</h2>
<p>Appleは今回の人事に合わせ、AI組織の一部を再編する。ジャナンドレア氏が担当していた領域のうち、Foundation Models、ML Research、AI Safety and Evaluationはスブラマニヤ氏が引き継ぎ、それ以外の組織は以下の担当に移る。</p>
<ul>
<li>Sabih Khan氏（オペレーション担当シニアバイスプレジデント）</li>
<li>Eddy Cue氏（サービス担当シニアバイスプレジデント）</li>
</ul>
<p>Appleは、この組織再編について「類似する部署とのアラインメントを高めるため」と説明している。</p>
<h2>Cook氏とFederighi氏「AIはApple戦略の中心」</h2>
<p>リリースでは、Tim Cook氏（CEO）とCraig Federighi氏によるコメントも紹介された。</p>
<p>Cook氏は、ジャナンドレア氏の貢献を称えたうえで「AIは長年にわたりAppleの戦略の中心であり続けている」と強調。また、スブラマニヤ氏がAIの専門性をAppleにもたらすことを歓迎すると述べた。</p>
<p>Federighi氏は、来年提供予定の「よりパーソナライズされたSiri」への取り組みを含め、AI機能の監督範囲が拡大することに触れつつ、スブラマニヤ氏の参加によりAI技術の進展をさらに加速させるとコメントした。</p>
<p>Appleは今回の発表を「新しい章の始まり」と位置づけ、信頼性が高く、より個別化された体験を提供する次世代AI技術の開発を強化する姿勢を示している。</p>
]]></description>
      <pubDate>Thu, 04 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国DeepSeek、GPT-5級「DeepSeek-V3.2」をオープンウェイト公開──エージェント向け“推論ファースト”モデル、Gemini 3.0 Pro並み「Speciale」も</title>
      <link>https://ledge.ai/articles/deepseek_v3_2_and_speciale_release_agent_reasoning_model</link>
      <description><![CDATA[<p>中国のAI開発企業 DeepSeek は2025年12月1日、推論モデル「DeepSeek-V3.2」と、高推論版「DeepSeek-V3.2-Speciale」を<a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2">発表</a>した。</p>
<p>同社はモデルの重みを公開するオープンウェイト戦略をとっており、今回のV3.2シリーズでは、AIエージェントの自律的なタスク遂行に必要な「思考力」を重視する“推論ファースト（Reasoning-first）”アーキテクチャを採用した。テックレポートによれば、V3.2は米OpenAIの次世代モデル「GPT-5」と同等レベル、V3.2-SpecialeはGoogleの「Gemini 3.0 Pro」と同等レベルの推論性能を示したとしている。</p>
<h2>エージェントのための「推論ファースト」設計</h2>
<p>今回発表されたDeepSeek-V3.2シリーズ最大の特徴は、AIエージェント運用への特化だ。単にテキストを生成するだけでなく、外部ツールを使いこなし、複雑な手順を計画（プランニング）する能力を重視して設計されている。</p>
<p><strong>DeepSeek-V3.2の推論プロセス。ツール呼び出し（Tool call）の前に「思考（Thinking）」フェーズを挟み、エラー修正やプランニングを行ってから外部ツールを実行する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FE_Nmjb_YA_Ak_Er8_2ee1c0d55d/G7_FE_Nmjb_YA_Ak_Er8_2ee1c0d55d.jpg" alt="G7FENmjbYAAkEr8.jpg" /></p>
<ul>
<li><strong>DeepSeek-V3.2（GPT-5級の汎用フラッグシップ）</strong> ：従来のLLMが苦手としていた「行動前の深い思考」を推論プロセスとしてモデル内部に組み込んだ。Thinkingモードとツール呼び出しを組み合わせることで、曖昧な指示からでも意図を汲み取り、自己修正を行いながらタスクを遂行できると説明している。</li>
<li><strong>DeepSeek-V3.2-Speciale（Gemini 3.0 Pro相当の高計算版）</strong> ：同一アーキテクチャをベースに、より長い内部思考トークンを許容することで推論性能を最大化したバリアント。高難度の推論タスクや数学・情報オリンピック級の問題を想定した設計で、API限定（ツール呼び出しなし）で提供される。</li>
</ul>
<h2>GPT-5、Gemini 3.0に肉薄するベンチマーク結果</h2>
<p>DeepSeekが公開した技術レポートによると、両モデルの「推論」および「エージェント挙動」に関する主要指標は以下の通りだ。</p>
<p><strong>主要モデルとの性能比較。青色がDeepSeek-V3.2シリーズ。推論能力（Reasoning Capabilities）およびエージェント能力（Agentic Capabilities）で、GPT-5 HighやGemini 3.0 Proと同等、あるいは一部で上回るスコアを記録した</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_F_Dq18a_MAAW_Wvh_8707e4f698/G7_F_Dq18a_MAAW_Wvh_8707e4f698.jpg" alt="G7FDq18aMAAWWvh.jpg" /></p>
<p><strong>複雑な推論 (MATH / GPQA)</strong> ： V3.2-Specialeは、数学コンテストAIME 2025やHMMT、国際数学オリンピック（IMO）相当問題、競技プログラミングのCodeforcesレーティングなどで高いスコアを記録した。AIMEではGPT-5 High（94.6）を上回る96.0という結果が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FD_7c_Kb_UA_Au_Ja_A_f096df59f1/G7_FD_7c_Kb_UA_Au_Ja_A_f096df59f1.jpg" alt="G7FD7cKbUAAuJaA.jpg" /></p>
<p><strong>エージェント性能（τ²-Bench / MCP-Universe / Tool-Decathlonなど）</strong> ： API操作やマルチターンでのタスク解決能力を測る各種ベンチマークでは、V3.2がClaude 4.5 SonnetやGPT-5 Highと比較可能な数値を示した。Thinkingプロセスを導入したことで、ツールの選択ミスや引数の誤りが減少する傾向があるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FECX_Kbc_AA_8stm_0446319143/G7_FECX_Kbc_AA_8stm_0446319143.jpg" alt="G7FECXKbcAA8stm.jpg" /></p>
<p>一方で、テクニカルレポートは制約や課題についても言及する。DeepSeek は、総学習FLOPsの観点から、V3.2は依然としてGemini 3.0 Proなどのクローズドモデルに比べ世界知識の幅で劣ること、同等の品質を出すためにより多くのトークンを必要とするなど「トークン効率」の面で課題が残ること、複雑なタスクの一部では最先端モデルに及ばないことを挙げ、今後の改善余地があるとまとめている。
今回の公開により、DeepSeekは「Reasoning-first models built for agents」というコンセプトのもと、GPT-5級の推論性能とエージェント向け設計を兼ね備えたオープンモデルを前面に打ち出したかたちだ。V3.2はコスト効率と汎用性を重視した日常利用向けモデルとして、Specialeは競技レベルの高難度タスクに向けた高計算版として位置付けられている。</p>
<h2>オープンモデルとコストパフォーマンス</h2>
<p>DeepSeekは、V3.2およびV3.2-Specialeのモデル重みをHugging Face等でMITライセンスのもと公開しており、ローカル環境やオンプレミスでの構築も可能としている。またAPI価格については、同社の従来モデルからの値下げや、長文入力でもコストを抑えられる設計を打ち出している。</p>
<p>V3.2-Specialeは、https://api.deepseek.com/v3.2_speciale_expires_on_20251215 という一時的なエンドポイントを通じて提供され、2025年12月15日15時59分（UTC）まで利用可能となる。その後は通常の提供形態に統合される予定だとしており、期間中はV3.2と同一価格で高推論版を試せる。</p>
<p>高度な推論能力と比較的低い利用コストを両立したオープンモデルとして、今後、AIエージェントの実運用にどの程度採用が進むかが注目される。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIをよく使う人は「活発で外向的」──NTTドコモ モバイル社会研究所、若年層では“心配性ゆえの不安”も</title>
      <link>https://ledge.ai/articles/genai_user_extroversion_docomo_survey_2025</link>
      <description><![CDATA[<p>NTTドコモ モバイル社会研究所は12月1日、2025年2月に実施した「生成AI利用意識・行動調査」をもとに、生成AIの利用頻度と性格特性の関係を分析した結果を<a href="https://www.moba-ken.jp/project/lifestyle/20251201.html">発表</a>した。</p>
<p>調査対象は全国の15〜69歳男女7,527人で、性別・年齢・都道府県の人口構成比に合わせたクォータサンプリングによるWeb調査として実施された。</p>
<p>今回のレポートでは、生成AIを「知っている」人を対象に、利用頻度と自己評価による性格特性の関係を可視化している。分析の結果、生成AIをよく利用する人ほど「活発で、外向的だと思う」「新しいことが好きで、変わった考えをもつ」と回答する割合が高いという傾向が確認された。一方、生成AIに強い不安を抱く人では「心配性で、うろたえやすいと思う」と自己評価する人が多く、特に若年層でこの傾向が強く見られたという。</p>
<h2>生成AIヘビーユーザーは「活発で外向的」</h2>
<p>レポートでは、生成AI利用頻度と「活発で、外向的だと思う」という自己評価の関係を整理している。利用頻度が高くなるほど、外向的と答える割合が一貫して高まる結果となった。研究所は、外向的な人ほど人との交流を楽しむ傾向があり、その中で生成AIを積極的に活用している可能性を指摘する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_01_341ad1f8bb/20251201_01_341ad1f8bb.png" alt="20251201_01.png" /></p>
<h2>新しい技術に積極的な“好奇心の強さ”</h2>
<p>続いて、「新しいことが好きで、変わった考えをもつと思うか」という設問でも、同様の傾向が示された。生成AIをよく利用する人ほど、新しい技術を試したいという意識が強く、好奇心の高さが利用を後押ししていることがうかがえるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_02_d63049b9c1/20251201_02_d63049b9c1.png" alt="20251201_02.png" /></p>
<h2>不安の強い層には「心配性」の傾向</h2>
<p>一方で、生成AIに対して「不安を感じている」「やや不安を感じている」と回答した人の割合が高い層では、「心配性で、うろたえやすい」と自己評価する人が多いことも明らかになった。図3-1では、不安度が高い層ほど心配性の自己評価が高いという関係が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_03_01_3975f7c305/20251201_03_01_3975f7c305.png" alt="20251201_03-01.png" /></p>
<p>また、性年代別に見ると、若年層ほど「心配性である」と回答する割合が高い傾向もみられた。同研究所はこれまでの調査でも「若年層は生成AIへの期待が高い一方、不安も高い」ことを報告しており、今回の分析では、その背景の一因として“心配性の高さ”が示されたとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_03_02_0c19752d1b/20251201_03_02_0c19752d1b.png" alt="20251201_03-02.png" /></p>
<h2>過去調査とのつながり</h2>
<p>モバイル社会研究所はこれまでにも生成AIに関する認知、利用実態、不安に関する複数の調査結果を公表している。2025年8月の調査では、生成AIに「不安を感じる」とした人が全体の29％に上り、特に10代でその割合が高いことを示していた。今回の性格特性の分析は、こうした利用者の態度形成をより深く理解する追加データとして位置づけられている。</p>
<p>同研究所は、生成AIの基礎理解や利用方法を学べる「ドコモスマホ教室」などの取り組みも継続しており、AI活用に関するリテラシー向上施策を進めている。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが図表や文書を“読めるデータ”に──パナソニックとUCLA、拡散モデルを用いた視覚言語モデル「LaViDa」を発表　生成速度は自己回帰型VLMの約2倍に</title>
      <link>https://ledge.ai/articles/panasonic_lavida_diffusion_vlm_release</link>
      <description><![CDATA[<p>パナソニックは2025年11月27日、米カリフォルニア大学ロサンゼルス校（UCLA）の研究者らと共同で、拡散モデルを活用した新しい視覚言語モデル（VLM）「LaViDa」を開発したと<a href="https://news.panasonic.com/jp/press/jn251127-2">発表</a>した。LaViDaは、従来主流だった自己回帰型手法と同等の精度を保ちつつ、文章生成を約2倍に高速化できるという。</p>
<h2>拡散型言語モデルを採用したLaViDaの仕組み</h2>
<p>LaViDaは、画像とテキストを同時に扱うマルチモーダルAIで、言語生成に拡散モデルを用いる点に特徴がある。従来の視覚言語モデルは、文章を1語ずつ生成する自己回帰型手法を採用しており、テキストが長くなるほど推論速度が低下する課題があった。</p>
<p>拡散モデルでは、マスクされた語を“段階的に復元”する形で文章を生成でき、ステップ数を調整することで高速化が可能になる。</p>
<p><strong>LaViDaの全体構造。複数の画像ビューをエンコードし、拡散型言語モデルが段階的にテキストを復元する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_2e3471c0d9/x2_2e3471c0d9.jpg" alt="x2.jpg" /></p>
<p>LaViDaは、Prefix-DLMと呼ばれる効率化手法も採用し、画像やプロンプトに関連する領域だけを参照することで、計算量を抑えながら推論を行えるようになっている。</p>
<h2>図表や文書を“構造化データ”へ出力できる LaViDa の特性</h2>
<p>LaViDaは、文章生成だけでなく、図表・画像の内容を JSON 形式などの「構造化データ」に変換する能力を持つ。これにより、これまで「画像として扱われていた報告書内の図表」などを、AIエージェントが直接処理しやすい形に変換できる。</p>
<p><strong>LaViDaのフォーマット制約に沿った生成例（左）と画像分類をJSON形式に構造化した例（右）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub5_3368e7e69a/sub5_3368e7e69a.jpg" alt="sub5.jpg" /></p>
<p>このように LaViDa は、</p>
<ul>
<li>指定形式の詩生成</li>
<li>チャート／画像の要素抽出</li>
<li>JSON形式での出力</li>
</ul>
<p>といった “フォーマット遵守型の生成” に強みを持つという。</p>
<h2>複数のマルチモーダルタスクで既存VLMを上回る性能</h2>
<p>発表によれば、LaViDa は MMMU、MathVista、ChartQA、ScienceQA などの多様なデータセットで既存の自己回帰型VLMを上回る結果を示した。さらに、COCO Captioning では</p>
<ul>
<li>推論速度：約1.92倍</li>
<li>精度（CIDErスコア）：既存モデルを上回る</li>
</ul>
<p>という結果が報告されている。</p>
<p><strong>LaViDaのベンチマーク結果。複数タスクで精度が向上し、COCO Captionでは速度と品質の両立（NFE制御）が確認された</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub4_6103b442df/sub4_6103b442df.jpg" alt="sub4.jpg" /></p>
<h2>現場のドキュメント処理を支える“AIが読める化”技術へ</h2>
<p>現在パナソニックは、業務現場のAIエージェント活用を推進しており、LaViDa を「多種多様な現場ドキュメントを AI が扱える形式に変換する技術」と位置づける。PDF・画像・写真・報告書など、現場に存在する“非構造データ”を自動的に整理・変換することで、現場のDXを加速する狙いがあるという。</p>
<p>LaViDa の研究成果は AI 国際会議 NeurIPS 2025 に採択されており、12月3〜5日に米サンディエゴで発表される予定だ。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「ChatGPT」は自殺を助長していない──OpenAI、少年自殺訴訟で「ガードレール回避による不適切利用」と反論</title>
      <link>https://ledge.ai/articles/openai_chatgpt_suicide_lawsuit_response_misuse_argument</link>
      <description><![CDATA[<p>OpenAIは、同社の対話型AI「ChatGPT」が10代の少年の自殺を助長したとして提起された訴訟「Raine v. OpenAI」に関し、カリフォルニア州裁判所へ公式な<a href="https://www.medianama.com/wp-content/uploads/2025/11/Raine-v-OpenAI-Answer-11-25-25.pdf">回答書</a>（Answer to Amended Complaint）を2025年11月25日付で提出した。回答書で同社は、少年の死を「壊滅的な悲劇」としつつも、「チャット履歴を全体として読むと、自殺はChatGPTによって引き起こされたものではない」として因果関係を否定した。</p>
<h2>原告側は「自殺を正当化した」と主張</h2>
<p>訴訟は、2025年8月にサンフランシスコ郡上級裁判所へ提起されたもの。原告である遺族は、当時16歳の少年がChatGPT（GPT-4o）との長期的な対話の中で自殺方法の詳細や計画の助長を受けたと主張しており、OpenAIに対して過失・製造物責任・警告義務違反などを訴えている。</p>
<p>訴状では、ChatGPTが
・自殺方法の手順
・未遂時の「失敗理由」の分析
・遺書の下書き
・家族に伝えないよう促すような発言
などを行ったとされ、モデルのガードレール設計や安全プロトコルに欠陥があったと指摘する。</p>
<h2>OpenAI「100回以上、危機支援を促していた」</h2>
<p>OpenAIが裁判所へ提出した回答書では、原告が引用する会話は「文脈を欠いた部分的抜粋にすぎない」と指摘し、同社は完全なチャット履歴を提出したと説明。その上で、ChatGPTが少年との対話中に100回以上、自殺防止ホットラインや信頼できる人物への相談を促していたとし、安全機能は機能していたと主張した。</p>
<p>また回答書では、少年が
・ガードレールに対する不満を繰り返し述べていたこと
・意図を偽り「キャラクター作り」などと説明しつつ、危険な指示を引き出そうとしていたこと
を示す記録があるとし、安全機能の回避行為が存在したと反論した。</p>
<p>さらにOpenAIは、少年には長年にわたる自殺念慮や既往のメンタルヘルス問題があったほか、ChatGPT以外のAIサービスやオンライン情報源からも自殺方法に関する詳細を得ていたとし、「死因は複数の要因によるもので、ChatGPT単独では説明できない」と述べている。</p>
<h2>利用規約違反と「誤用」を強調</h2>
<p>OpenAIは回答書で、「misuse（誤用）」「unauthorized use（無許可利用）」「unintended use（想定外利用）」といった文言を用い、少年の利用は利用規約（Terms of Use）およびUsage Policiesに反するものだったと主張した。</p>
<p>利用規約では、自殺や自傷に関連した用途での利用を禁じており、未成年者については保護者同意なしの利用を禁止している。同社は、少年の利用はこれらに反しており、同社に法的責任を帰すことはできないと訴えている。</p>
<p>また、米通信品位法230条（Section 230）に基づき、ユーザー入力に対する応答についてAIサービス提供者が責任を負わないという法的抗弁も提示している。</p>
<h2>「慎重さ・透明性・敬意」の姿勢</h2>
<p>OpenAIは、回答書の提出と同じ11月25日付で公開したブログ「Our approach to mental health-related litigation」で、メンタルヘルス関連の訴訟は深い悲劇性と複雑さを伴うため、「慎重さ・透明性・敬意をもって対応する」との方針を<a href="https://openai.com/index/mental-health-litigation-approach/">示した</a>。同ブログでは遺族への哀悼を表明しつつも、具体的な論点については法廷での手続きを通じて対応するとしている。</p>
<p>また、2025年8月に公開した別の公式文書「Helping people when they need it most」では、
・危機的状況の検知精度の向上
・外部支援先への誘導の強化
・長時間会話におけるガードレールの精緻化
・ティーン向け保護機能の追加
など、メンタルヘルス領域での安全性改善を進めていることを説明した。</p>
<h2>原告側は「被害者非難」と反発</h2>
<p>報道によると、原告側代理人はOpenAIの回答を「被害者を責める内容だ」と批判しており、ChatGPTのガードレール設計や運用の不足が少年の自殺に寄与したとの主張を続けている。</p>
<p>今後の審理では、
・ChatGPTの応答と自殺行動の因果関係
・GPT-4oの安全設計とガードレールの適切性
・利用規約やSection 230が生成AIの応答にどこまで適用されるか
などが主要な争点となる見通しだ。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>HP、AI導入を軸に最大6000人削減へ──2028年度末までに世界で4000〜6000人、年間10億ドルのコスト削減目指す</title>
      <link>https://ledge.ai/articles/hp_ai_headcount_reduction_2028_plan</link>
      <description><![CDATA[<p>HPは2025年11月25日（米国時間）、2025年度通期および第4四半期の決算を公表するとともに、AIの活用を軸とした全社的な構造改革「Fiscal 2026 Plan」を<a href="https://www.hp.com/us-en/newsroom/press-releases/2025/hp-inc-reports-fiscal-2025-full-year-and-fourth-quarter-results.html">発表</a>した。</p>
<p>その一環として、世界で約4000〜6000人の人員削減を2028年度末までに実施する計画を示した。これは、AI導入による生産性向上や事業構造の見直しを進めながら、年間約10億ドルのコスト削減を図る取り組みの一部として位置づけられている。</p>
<h2>AI活用を柱に全社改革──「Fiscal 2026 Plan」発表</h2>
<p>HPは、AIを中心としたデジタルトランスフォーメーションを通じ、顧客満足度の向上、プロダクトイノベーションの加速、生産性の改善を図ると説明。同社は「会社全体の取り組み（company-wide initiative）」と呼ぶこのプランにより、2028年度末までに年間約10億ドルのグロス・コスト削減を達成する見込みを示した。</p>
<p>計画には、組織の簡素化、プラットフォーム統合、業務プロセス改善に加え、AI活用による自動化や効率化が含まれる。これらの施策に伴い、総額約6億5000万ドルのリストラクチャリング費用を見込んでおり、うち約2億5000万ドルを2026年度に計上する予定だ。</p>
<h2>世界で4000〜6000人削減──2028年度末までに段階的に実施</h2>
<p>HPは、全社改革の一環として、世界の総人員を約4000〜6000人削減する（gross global headcount reduction）と発表した。リリースでは、対象地域や部門の内訳は明らかにしていないが、「workforce reductions（人員削減）」を主要な施策の一つとして挙げている。</p>
<p>人員削減は2028年度末までに段階的に実施される予定で、AI活用による業務の効率化や、非中核領域の統合・最適化を通じて構造的なコスト削減を進める。</p>
<h2>2025年度の業績──通期売上は553億ドル、PC事業は回復傾向</h2>
<p>決算によると、2025年度通期の売上高は553億ドル（前年比3.2％増）となった。GAAP希薄化後EPSは2.65ドルで、前年（2.81ドル）から減少した。一方、第4四半期売上高は146億ドル（前年比4.2％増）と増収となっている。</p>
<p>主力のパーソナルシステムズ事業（PC）は、第4四半期で前年比8％増の104億ドルとなり、コンシューマー向け・法人向けともに販売が回復した。プリンティング事業は4％減の43億ドルと低調だった。</p>
<p>同社CEOであるEnrique Lores氏は、AIを基盤とした製品イノベーションを強調し、「働き方の未来（Future of Work）をリードするため、AI搭載デバイスの開発、生産性向上、顧客価値の最大化を進める」とコメントした。</p>
<p>HPは、2026年度第1四半期のEPS見通しとして、GAAPベースで0.58〜0.66ドル、非GAAPで0.73〜0.81ドルと予測。通期では、GAAP 2.47〜2.77ドル、非GAAP 2.90〜3.20ドルを見込む。フリーキャッシュフローは28〜30億ドルを計画しており、成長投資と株主還元の両立を図る考えを示した。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国研究者、台湾上空でStarlink通信を遮断するシミュレーションを実施──最大2000機のドローンなどによる電子妨害が必要と試算</title>
      <link>https://ledge.ai/articles/china_starlink_jamming_simulation_taiwan</link>
      <description><![CDATA[<p>中国と台湾の緊張が続くなか、中国本土の研究者が「台湾上空でStarlink通信網を妨害する」大規模電子戦シミュレーションを実施したと、香港紙<a href="https://www.scmp.com/news/china/science/article/3333523/chinese-researchers-simulate-large-scale-electronic-warfare-against-elon-musks-starlink">サウスチャイナ・モーニング・ポスト（SCMP）</a>が2025年11月23日に報じた。</p>
<p>研究チームは、台湾と同規模の約3.6万平方キロメートルの領域を対象に、1000〜2000機規模の通信妨害装置（ジャマー）を上空に展開することで、Starlinkネットワークを一時的に抑圧できる可能性があると試算している。</p>
<p>SCMPが確認したのは、中国語の専門誌『系统工程与电子技术（Systems Engineering and Electronics）』に掲載された論文で、中国の軍事工学研究者らが作成したもの。同紙によると、研究者はウクライナ戦争でStarlinkが通信インフラとして軍事作戦を支え続けたことを受け、台湾有事などを想定した電子戦の可能性を分析したという。</p>
<p>Starlinkは、高度約550kmの低軌道衛星が多数稼働し、自律的に接続先を切り替えるメッシュ型ネットワークを形成している。このため、地上からの単一の妨害では通信を完全に遮断することが難しいとされる。研究チームはそこで、航空機・気球・ドローンなどの空中ジャマー（通信妨害装置）を広範囲に配置する方式を検証し、一定高度で密度の高い妨害グリッドを形成することで、特定エリアのStarlink通信を抑圧できる可能性が示された。</p>
<p>米技術メディアの<a href="https://www.tomshardware.com/networking/china-simulated-a-starlink-blockade-over-taiwan-ccp-scientists-say-around-1-000-drones-would-be-enough-to-cut-satellite-internet-to-the-island">Tom’s Hardware</a>は、論文のシミュレーション条件を詳細に紹介している。それによれば、ジャマーは高度約20kmに展開し、3〜6マイル間隔で配置することで“電磁シールド”のような妨害グリッドを形成する必要があるとされる。また、高出力装置を搭載した航空機を使う場合は約935ノードで足りる一方、小型ドローンなどの低出力ジャマーでは1000〜2000ノードが必要になるという。</p>
<p>ただし、数千機規模の空中ジャマーを台湾上空に長時間展開し続けるには、燃料・整備・指揮統制・対空防衛への対応など、多くの運用上の課題が伴う。複数の報道でも、今回の内容はあくまでもシミュレーション研究であり、実際に中国が同規模の演習を行った証拠は確認されていない。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 03:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek、自己検証型数学推論モデル「DeepSeek-Math-V2」を公開──IMO金メダル級の定理証明能力をオープンソースで</title>
      <link>https://ledge.ai/articles/deepseek_math_v2_release</link>
      <description><![CDATA[<p>中国のAI開発企業 DeepSeek は、数学的推論に特化した大規模言語モデル「DeepSeek-Math-V2」を2025年11月27日にHugging Face 上の model cardで<a href="https://huggingface.co/deepseek-ai/DeepSeek-Math-V2#deepseekmath-v2-towards-self-verifiable-mathematical-reasoning">公開</a>した。モデルはオープンウェイトで、商用利用も可能な Apache 2.0 ライセンスで提供されている。</p>
<h2>自己検証フレームワークによる厳密な推論</h2>
<p>DeepSeek-Math-V2 の最大の特徴は、生成された証明の正しさを検証する「自己検証（self-verification）」アーキテクチャを採用した点にある。証明を生成する generator と、その証明をチェックする verifier を分離し、両者を強化学習ループで相互に高め合うよう設計することで、論理的整合性を備えた定理証明を可能にした。</p>
<p>この仕組みによって、従来モデルで課題とされてきた「答えは正しくても推論過程が破綻する」問題を抑制し、数学競技形式の問題において高い性能を発揮したという。</p>
<h2>数学ベンチマークで既存LLMを大幅に上回る</h2>
<p>DeepSeek は model card で、同モデルが数多くの数学ベンチマークで既存LLMを上回ったと報告している。特に、研究コミュニティで整備されている定理証明ベンチマーク「ProofBench」において高い正答率を記録した。</p>
<p><strong>ProofBench における各LLMの比較。右端の青は DeepSeek-Math-V2（Heavy）で、Basic と Advanced の双方で既存モデルを大きく上回った</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/IMO_Proof_Bench_6ae2f05dc5/IMO_Proof_Bench_6ae2f05dc5.jpg" alt="IMO-ProofBench.jpg" /></p>
<h2>IMO・CMO・Putnamで “金メダル級” の成績</h2>
<p>評価は合成ベンチマークだけにとどまらず、国際数学オリンピック（IMO 2025）、中国数学オリンピック（CMO 2024）、米国Putnam Competition（2024）といった実際のコンテスト問題でもスコアが公表されている。</p>
<p><strong>各数学コンテストにおける問題ごとの達成度。灰色は「完全解答」、下線は「部分点獲得」を示す。Putnam 2024 では 98.3% の得点率を記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Competitions_36ac51cf34/Competitions_36ac51cf34.png" alt="Competitions.png" /></p>
<p>実績の要点は以下のとおり：</p>
<ul>
<li>IMO 2025：83.3%（金メダル相当）</li>
<li>CMO 2024：73.8%</li>
<li>Putnam 2024：98.3%（120点中118点）</li>
</ul>
<p>特に Putnam での高得点は、大学数学レベルの複雑な問題に対しても高い正答率を示したことを意味する。</p>
<h2>モデル基盤と公開形態</h2>
<p>モデルは DeepSeek-V3.2-Exp-Base を基盤としており、長い証明文を扱うための拡張コンテキスト、低精度フォーマットによる推論負荷の最適化など、研究用途に配慮した設計となっている。</p>
<p>Hugging Face 上でウェイトが公開されており、研究者・開発者はそのまま検証や応用に利用できる。</p>
<h2>今後の展望</h2>
<p>DeepSeek は、自己検証型LLMが「未解決問題の探索」「形式的証明の自動化」「科学研究の推論支援」などに応用可能であると述べている。一方で、第三者による大規模検証や実際の数学者によるレビューは今後の課題として残る。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/30 [SUN]独Black Forest Labs、仏MistralのVLM利用の画像生成AI「FLUX.2」を発表──最大10枚の参照画像、精密な文字生成、4MP編集に対応した“実務特化”モデルファミリー</title>
      <link>https://ledge.ai/articles/bfl_flux2_release_2025</link>
      <description><![CDATA[<p>ドイツのAIスタートアップ Black Forest Labs（BFL） は2025年11月25日、画像生成AIモデルファミリー「FLUX.2」を<a href="https://bfl.ai/blog/flux-2">公開</a>した。</p>
<p>FLUX.2は、実際の制作現場で使うことを前提に設計された「Frontier Visual Intelligence」と位置づけられており、キャラクターやスタイルの一貫性、複雑なプロンプト解釈、レイアウト・照明・ブランドガイドラインへの忠実な追従などが強化されている。最大4メガピクセルの画像編集にも対応し、細部を保ちながら編集が行える。</p>
<p>FLUX.2では内部アーキテクチャも刷新され、Mistral社の240億パラメータの視覚言語モデル「Mistral-3」と、rectified flow Transformer を組み合わせた latent flow matching 構成が採用された。視覚と言語の統合理解を担う Mistral-3 VLM と、空間的整合性・質感表現を司るフロー変換が補完し合うことで、現実世界に近い照明や材質表現、精密な構図理解が可能になっている。</p>
<p>FLUX.2は、複数の参照画像を扱う性能も大幅に向上した。最大10枚の参照画像を統合し、キャラクター、製品、スタイルの特徴を保ちながら高品質な画像を生成できる。テキストレンダリングも強化され、インフォグラフィックスやUIモックアップなど、細かい文字情報を含む画像も安定して描画できるようになった。</p>
<p>FLUX.2による画像編集・参照画像統合のデモンストレーション。複数の入力画像から構図・照明・スタイルを一貫させながら自然な合成を行う様子が示されている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_eyecatch_c1eca950a4/FLUX_2_eyecatch_c1eca950a4.jpg" alt="FLUX2 eyecatch.jpg" /></p>
<h2>Open Core戦略の継続</h2>
<p>BFLは創業以来、「Open Core」戦略を採用してきた。先端モデルを企業向けの商用APIとして提供しながら、研究者や開発者が検証・実験できるオープンウェイトモデルも積極的に公開してきた。2024年に展開したFLUX.1 [dev] は世界で広く普及したオープン画像モデルとなり、FLUX.1 Kontext [pro] はAdobeやMetaなどの企業で利用された。FLUX.2は、この2つの方向性を統合しつつ、さらに拡張された位置づけとなる。</p>
<h2>FLUX.1から進化した4つの軸</h2>
<p>FLUX.2では、精度、効率、コントロール性、写実性の4点を重点的に改善した。生成能力の強化により、プロダクト撮影に近い質感表現、安定した光源処理、構図の破綻が少ない空間表現が可能になり、制作現場における生成AIの導入コストを引き下げる狙いが示されている。</p>
<h2>主な新機能</h2>
<ul>
<li><strong>マルチリファレンス対応（最大10枚）</strong> ：キャラクターや製品の特徴を保持しながら、多様な角度・表情・スタイルを統合。</li>
<li><strong>フォトリアリズムと細部描画の向上</strong> ：テクスチャや照明処理が強化され、写真用途や可視化に適した品質を実現。</li>
<li><strong>文字生成の精密化</strong> ：UIモック、インフォグラフィックス、複雑なタイポグラフィにも対応。</li>
<li><strong>複雑なプロンプトの構造理解</strong> ：多段階の指示、構成要素、レイアウトの指定などを正確に反映。</li>
<li><strong>高解像度編集（最大4メガピクセル）</strong> ：編集時も整合性を保ちながら高解像度データを扱える。</li>
</ul>
<p>すべてのFLUX.2モデルで、テキストによる編集と複数参照画像による編集が一つのモデルで利用できる。</p>
<h2>4モデル構成で用途別に最適化</h2>
<p>FLUX.2は、用途に応じて4つのバリアントが用意される。</p>
<h3>FLUX.2 [pro]</h3>
<ul>
<li>制作現場向けの最高品質モデル</li>
<li>プロンプト遵守と画質で他社クローズドモデルと競合</li>
<li>高速化と低コスト化も両立</li>
<li>BFL Playground、BFL API、パートナー経由で利用可能</li>
</ul>
<h3>FLUX.2 [flex]</h3>
<ul>
<li>生成ステップ数やガイダンススケールを調整できる柔軟なモデル</li>
<li>文字生成や細部描画に強み</li>
<li>bfl.ai/play、API、パートナーから提供</li>
</ul>
<p><strong>FLUX.2 [flex] による“steps”パラメータの調整例。ステップ数を変えることで、タイポグラフィの正確さと生成速度のバランスが変化する（左から6、20、50ステップ）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_flex1_1393dd7816/FLUX_2_flex1_1393dd7816.jpg" alt="FLUX2 flex1.jpg" /></p>
<p><strong>FLUX.2 [flex] によるステップ数の変化による画質の違い。ステップを増やすほどディテールが安定し、質感再現が向上する（左から6、20、50ステップ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FLUX_2_flex2_b6ca2ffb42/FLUX_2_flex2_b6ca2ffb42.jpg" alt="FLUX2 flex2.jpg" /></p>
<h3>FLUX.2 [dev]（オープンウェイト）</h3>
<ul>
<li>32Bのオープンウェイトモデル</li>
<li>テキスト生成と画像編集を単一チェックポイントで実行</li>
<li>Hugging Faceでウェイト公開</li>
<li>NVIDIA/ComfyUIと連携したfp8最適化版も提供</li>
<li>FAL、Replicate、Runware、Verda、TogetherAIなど複数のAPIサービスで利用可能</li>
<li>商用ライセンスはBFL公式サイトで提供</li>
</ul>
<h3>FLUX.2 [klein]（近日公開）</h3>
<ul>
<li>Apache 2.0ライセンスのオープンソースモデル</li>
<li>FLUX.2を蒸留した小型モデル</li>
<li>β版登録を受け付け中</li>
</ul>
<h2>新VAEも公開</h2>
<p>FLUX.2シリーズには、新設計の「FLUX.2 - VAE」が採用されている。学習性、品質、圧縮率のバランスを最適化したモデルで、すべてのFLUX.2バックボーンの基礎となる。Apache 2.0で公開され、技術レポートも提供されている。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/29 [SAT]アリババ、初のAIスマートグラス「Quark AI Glasses」発売──S1/G1の2モデルで同社製LLM「Qwen」を直接使える日常デバイスに</title>
      <link>https://ledge.ai/articles/alibaba_quark_ai_glasses_launch_china</link>
      <description><![CDATA[<p>アリババは2025年11月27日（現地時間）、同社として初となるAI搭載スマートグラス「Quark AI Glasses」シリーズを<a href="https://www.alizila.com/alibaba-launches-new-quark-ai-glasses-series-in-china-deeply-integrated-with-qwen/">発表</a>した。アリババの大規模言語モデル「Qwen」およびAIアプリ「Qwen App」と深く統合し、音声と視覚を組み合わせたリアルタイムAIアシスタントを提供する。シリーズは、ディスプレイ搭載のフラグシップモデル「S1」と、軽量で普段使いに適した「G1」の2モデル構成となる。</p>
<h2>QwenとQuark Appを統合、音声・視覚を組み合わせたAIアシスタントに対応</h2>
<p>Quark AI Glassesは、アリババが開発する大規模言語モデル「Qwen」とAIアプリ「Qwen App」を標準搭載し、音声操作や視界上への情報提示を通じて、AIアシスタント機能を直接メガネ型デバイスで利用できる。外出先でのリアルタイム翻訳や、会議・講義内容の文字起こし、リマインダー設定、ナビゲーション、周辺スポット検索、ショッピング支援といった多様な機能に対応する。</p>
<p>また、アリババグループのサービスとも連携しており、決済のAlipay（支付宝）、地図サービスのAmap（高徳地図）、ECサービスのTaobao（淘宝）、旅行サービスFliggy（飛猪）なども利用できる。中国の音楽ストリーミングサービス（QQ Music、NetEase Cloud Music）にも対応した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55.jpeg" alt="bf1ef6c08mf1fb9c98a8d6dd8bbbe8de.jpeg" /></p>
<h2>フラグシップモデル「S1」──交換式デュアルバッテリーで最大24時間使用可能</h2>
<p>S1はデュアルマイクロOLEDディスプレイを搭載し、視界内に情報をオーバーレイ表示できる。骨伝導技術やデュアルチップ構成を採用し、音声入出力やリアルタイム処理性能を強化した。</p>
<p>特徴的な点として、交換可能なデュアルバッテリーシステムを採用し、最大24時間の利用を可能としている。また、0.6秒で撮影できるインスタントフォト機能や、3K動画撮影およびAIによる4K動画出力、独自技術「Super Raw」による夜間撮影性能の向上など、撮影機能も強化されている。価格は3,799元（約7万8,000円）から。</p>
<h2>軽量モデル「G1」──約40gで普段使いに最適、コアハードウェアはS1と共通</h2>
<p>G1は日常の利用を想定した軽量モデルで、重量は約40gに抑えられている。ディスプレイ以外の主要ハードウェア（処理チップ、オーディオ、カメラなど）はS1と共通で、普段使いしやすいデザインと価格帯を重視している。価格は1,899元（約3万9,000円）から。</p>
<h2>MCP対応で開発者エコシステムも視野に</h2>
<p>Quark AI Glassesは、外部システムやアプリケーションと双方向に接続するオープン標準「Model Context Protocol（MCP）」に対応する。これにより、開発者がQuark AI Glasses向けのAIアプリやエージェントを拡張しやすくなり、アリババのQwenエコシステムとの連携も強化される。</p>
<p>市場調査会社<a href="https://www.idc.com/promo/wearablevendor/">IDC</a>の調査によると、2025年第2四半期の世界ウェアラブルデバイス出荷台数は前年同期比9.6％増の1億3,650万台で、このうち約5,000万台が中国を中心とする地域から出荷されている。中国は現在、世界最大のウェアラブル市場であり、AI搭載デバイス分野における競争も激しさを増している。</p>
<p>Quark AI Glassesシリーズは、アリババのAIモデルQwenとグループのサービス群、そしてMCPによる拡張性を組み合わせることで、同市場における新たな製品ポジションを獲得する構えだ。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“自分の分身AI”同士を討論させると何が起きる？──筑波大学とMicrosoft、AIが媒介する新しい「自己省察」の学びを報告</title>
      <link>https://ledge.ai/articles/digital_human_debates_reflecting_with_ai</link>
      <description><![CDATA[<p>筑波大学とMicrosoftの研究者らは2025年11月17日、利用者自身の価値観や思考パターンを反映した「分身AI（Digital Human）」同士を討論させ、本人がその様子を傍観するという実験の結果をまとめた論文を<a href="https://arxiv.org/abs/2511.13046">公開</a>した。研究チームは、参加者がAIの能力理解を深めただけでなく、「自分ではない自分」を観察することで、自身の思考や価値観を客観的に見つめ直す新たな学習効果を確認したという。</p>
<h2>“自分の分身”を作り、その議論を観察するという新しい構図</h2>
<p>研究が扱ったのは、次の3つの視点の中間に位置する体験である。</p>
<ul>
<li>一次的視点（First-person）：自分が他者と直接対話する</li>
<li>三人称視点（Third-person）：第三者同士の会話を観察する</li>
<li>今回の視点（AI-mediated）：自分を反映した「Digital Me」が他人の「Digital You」と議論し、その様子を本人が観察する</li>
</ul>
<p>実験では、学生が自ら設計した分身AIが、自律的に討論を展開する。設計者の価値観や思考は反映されるが、議論の流れは完全には制御できない。この「似ているが、完全な自分ではない」という距離感が、客観的な自己観察を可能にするという。</p>
<p><strong>コミュニケーション構造の比較図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_7_2d4879fc05/x2_7_2d4879fc05.png" alt="x2 (7).png" /></p>
<h2>Digital Human Debates（DHD）の設計：プロンプトとRAGで“自分”を埋め込む</h2>
<p>参加したのは中高生9名（3チーム）。それぞれが6か月にわたり、自分の分身AIを次の3要素で設計した。</p>
<ul>
<li>system_prompt_template.txt：性格・口調・議論戦略・思考様式</li>
<li>interview_transcript.txt：個人の価値観・経験・背景</li>
<li>Documents（RAG 文書）：議論に利用する外部知識（両立場の資料を収集）</li>
</ul>
<p>システムは GPT-4o と LangChain を基盤に構築され、音声入力→議論生成→音声合成→Lip-sync 動画生成までを自動化。</p>
<p><strong>システム構成図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x4_1_5978703b2d/x4_1_5978703b2d.png" alt="x4 (1).png" /></p>
<h2>どのように討論したのか</h2>
<p>議論のトピックは、以下の4種類からルーレットでランダム選択された。</p>
<ul>
<li>高齢者の免許返納</li>
<li>リモートワークの恒久化</li>
<li>安楽死の合法化</li>
<li>ベーシックインカムの導入</li>
</ul>
<p>討論は約20分。Constructive speech、Cross-examination、Rebuttal など、全国高校ディベート選手権の形式に準じて進行し、勝敗は3名の審査員が判定した。</p>
<p><strong>討論フロー図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x5_3_aa3dfafba5/x5_3_aa3dfafba5.png" alt="x5 (3).png" /></p>
<p>また、実際の議論分析では、分身AIの発話は以下の3層で構成されていたことが確認された。</p>
<ul>
<li>Personal Context：学生本人の経験や価値観（例：留学経験）</li>
<li>RAG-sourced Evidence：外部文書を参照した事実情報</li>
<li>AI-generated Insight：LLM が独自に構築した新しい主張・質問</li>
</ul>
<p><strong>発話構成の三層分析図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x6_2_ebcfc4cb09/x6_2_ebcfc4cb09.png" alt="x6 (2).png" /></p>
<h2>発見1：AIが“自分の代わり”ではなく“自分の鏡”として機能する</h2>
<p>論文で最も強調されている成果は、参加者が 「Reflecting with AI」 と呼ばれる新たな学習体験を得た点である。</p>
<h3>「自分が話すより冷静に見られる」</h3>
<p>AIが自分の価値観を用いて議論するものの、その展開は必ずしも本人の想定どおりではない。
この“半自律性”が、次のような客観視を可能にした。</p>
<ul>
<li>「私は衝動的に話しがちだと気づいた」</li>
<li>「AIの方が論理がブレず、どこが弱いのかがわかった」</li>
</ul>
<p>参加者は AI の議論を自分とは別の存在として受け止めつつ、「しかし自分の思考が反映されている」と感じる。この微妙な距離感が、強いメタ認知効果を生んだという。</p>
<h2>発見2：プロンプト設計の違いが“AIの人格”に明確に表れる</h2>
<p>3チームのアプローチは大きく異なり、プロンプト設計の個性が発話に直接反映された。</p>
<ul>
<li><strong>Team A：徹底したキャラクター設計</strong> 「認知停止を破壊する」というテーマを持つ強烈な人格を設定し、攻撃的な論法を組み込んだ。</li>
<li><strong>Team B：繰り返し修正する“チューニング型</strong> 芥川龍之介やガンジーなど歴史人物をモチーフに、AIの出力を評価→修正する反復設計を採用。</li>
<li><strong>Team C：最小限の人格＋大量の論拠データ</strong> キャラ設定は控えめにし、RAGで大量の論理情報を与える“ロジック重視”型。</li>
</ul>
<p>いずれも、設計者の価値観や思考癖がそのままAIのふるまいに組み込まれていたという。</p>
<h2>発見3：AIリテラシー全体をカバーする学習効果</h2>
<p>研究チームは、今回の取り組みを“ジェネレーティブAIリテラシーの実践的な総合モデル”と位置づけている。
実際、参加者は以下の能力を幅広く活用していた。</p>
<ul>
<li>モデル特性の理解</li>
<li>論拠の収集と検証</li>
<li>プロンプト設計</li>
<li>出力の評価と改善</li>
<li>自己の思考の客観視（Reflecting with AI）</li>
</ul>
<p>ただし、倫理や法的側面の深い学習までは含まれておらず、今後の課題とされている。</p>
<p>研究では、「AIとの協働」ではなく “AIを通して自分を理解する” という新しい可能性を示しており、分身AIが自律的に議論する様子を観察することで、ユーザーは自らの論理構造・思考の癖を外在化し、客観的に省察できるという。研究チームは、この“Reflecting with AI”が今後のAIリテラシーにおける重要な能力になると位置づけている。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>KDDI、人間のチャット応対を学習するAIエージェントを開発──回答精度90％、auサポート窓口で運用開始</title>
      <link>https://ledge.ai/articles/kddi_human_chat_learning_ai_agent_release</link>
      <description><![CDATA[<p>KDDIとKDDI総合研究所は2025年11月26日、チャットサポート窓口で人間の応対履歴を学習し、高精度で再現するAIエージェントを開発したと<a href="https://www.kddi-research.jp/newsrelease/2025/112601.html">発表</a>した。</p>
<p>複数の応対事例を構造化し、追加情報の収集とファクトチェックを組み合わせる世界初の技術により、生成AIにおけるハルシネーションを抑制し、約90％の回答精度を実現したという。すでにauチャットサポート窓口の一部応対拠点で運用が始まっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kddi_nr_850_4231_img_02_9afe639a8d/kddi_nr_850_4231_img_02_9afe639a8d.png" alt="kddi_nr-850_4231_img_02.png" /></p>
<p>近年、従来のシナリオ型チャットボットでは対応が難しい複雑な問い合わせが増加しており、難易度の高い案件は人手による対応が必要だった。今回開発されたAIエージェントは、過去の適切な応対事例を複数抽出し、応対の流れを構造化したうえで、必要に応じて社内マニュアルから追加情報を収集し、内容の整合性を自動でチェックする仕組みを備える。このプロセスを経て応答文を生成することで、誤情報の生成を抑えつつ、実務に適した応対品質を確保するという。</p>
<p>KDDIによると、問い合わせ1件あたりの応対時間は従来比で約70％短縮できる見込みで、スタッフ間の応対品質の均一化にもつながると説明している。今回の技術は汎用パッケージとして開発されており、社内でのユースケース拡大やグループ会社への横展開に加え、将来的な商用提供も視野に入れている。</p>
<p>KDDI総合研究所は、応対の構造化や事例選択手法などに関する特許を10件以上登録済または出願済としており、今後も応対領域の拡大を進める方針を示している。両社は、AI技術の社会実装とお客さま応対の品質向上を通じ、カスタマーサポート体験の改善に取り組んでいくとしている。</p>
<p>:::box
<a href="https://ledge.ai/articles/deloitte_global_contact_center_survey2023">関連記事：国内コンタクトセンターすでに半数がAI導入、海外上回るも成果には課題あり</a>
::</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>2025年のAIニュース振り返りと、AI提唱70周年となる2026年の展望を知る特設サイトLedge.ai年末年始特集「&apos;25 to &apos;26」を公開</title>
      <link>https://ledge.ai/articles/ledgeai25to26</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も参加費無料の年末特集「Ledge.ai '25to'26」を公開しました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>Ledge.ai年末年始特集「'25 to '26」とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。</p>
<p>そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。ぜひご登録の上、隅々までご覧ください。参加費は無料です。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>コンテンツラインナップ</h2>
<h3>【編集部コンテンツ】2025年のAI振り返りと70周年に向けた展望</h3>
<p>Ledge.ai編集部が独自に企画・編集した記事および特集記事を掲載。
企業動向の背景にある文脈や業界のキーパーソンの言葉を通じて、AI活用を進めるヒントとして、ぜひご一読ください。</p>
<p><strong>\u003Cテーマ：AIの70年\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_image_f12dd17c93/ai70th_image_f12dd17c93.png" alt="ai70th-image.png" /></p>
<p><strong>\u003CLedge.ai 2025年注目ニュース総まとめ\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai2025news_b7d5ecf93f/ai2025news_b7d5ecf93f.png" alt="ai2025news.png" /></p>
<p>Ledge.aiが発信してきた記事の中から、特に注目すべきトピックをキーワードごとに厳選してお届けします。これらの記事を並べて読むだけでも、2025年のAIトレンドの全体像が浮かび上がってくるはずです。 2025年の振り返りとして、今読むべきランドマーク的な記事をまとめています。ぜひ、業界動向の整理や次のアクションの参考としてご活用ください。</p>
<h2>【特別インタビュー】キーパーソンが語るAIの過去・現在・未来</h2>
<p>本特集では、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいました。</p>
<h2>【トップランナー企業動向】AI周辺で押さえておきたい最新技術と実践事例</h2>
<p>国内外の注目企業をピックアップし、AI基盤、エージェント活用、自動運転データなど、世界最先端の動向を徹底分析します。</p>
<h3>必読の深い知見が得られる取材記事を、公開期間中に次々と発信</h3>
<ul>
<li>AIの進化を支え続けるNVIDIAの羅針盤／エヌビディア合同会社</li>
<li>「言語の壁」は、もはやイノベーションの言い訳にならない。／DeepL Japan</li>
<li>生成AI時代、GPUのオルタナティブ──AMDは今どこを見据えているのか／Advanced Micro Devices, Inc.</li>
<li>基盤モデルとの融合はロボットに何をもたらすのか／Coming soon…</li>
<li>『PLURALITY』の実践と、多元的協働社会への道筋／サイボウズ株式会社 代表取締役社長 青野 慶久 氏</li>
<li>AIを「使わないことが最大のリスク」― AIエージェント時代の企業ガバナンス新常識／弁護士 柴山 吉報 氏</li>
</ul>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25 to '26」
開催期間　：2025年12月1日～2026年1月9日
開催形式　：オンライン
参加費　　：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ　：contact@ledge.co.jp</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、AIアシスタント「Meta AI」の日本提供を正式発表──Messenger・Instagram・WhatsAppで順次利用可能に</title>
      <link>https://ledge.ai/articles/meta_ai_japan_rollout_2025</link>
      <description><![CDATA[<p>Metaは2025年11月25日、同社のAIアシスタント「Meta AI」を日本で順次提供開始することを<a href="https://about.fb.com/ja/news/2025/11/meta-ai-gradual-rollout-begins-in-japan/">発表</a>した。Meta AIの国内展開が公式に示されるのは今回が初めてで、同社の主要アプリ群に段階的に組み込まれる。</p>
<p>Meta AIは、Llama 3系モデルを基盤とした対話型アシスタントで、検索補助、質問応答、情報探索、画像生成などの機能を備える。Metaは、自然言語の理解力や推論性能の高さ、応答速度の改善を特徴として挙げている。</p>
<p>提供対象はMessenger、Instagram、WhatsApp、Facebookアプリ内など。各アプリのチャット入力欄や検索画面から直接呼び出せる設計となっており、コンテンツ探索から日常的なタスク補助まで、サービス横断で利用できる。InstagramやMessengerでは、チャット中にMeta AIへ質問したり、Reelsの発見タブで関連情報を得るといった操作が可能になる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Meta_AI_Gradual_Rollout_ac8a0fc919/Meta_AI_Gradual_Rollout_ac8a0fc919.jpg" alt="Meta-AI-Gradual-Rollout.jpg" /></p>
<p>画像生成機能も展開される。テキストからの静止画生成に加え、一部ではリアルタイムに変化する生成画像の活用にも対応するという。生成した画像はメッセージ内で共有・編集でき、クリエイティブ用途にも利用可能。</p>
<p>日本での提供は段階的に行われ、まずは一部ユーザーから導入し、数週間から数カ月かけて利用対象を拡大する。Metaはプライバシーと安全性を重視した運用方針を示すとともに、利用者からのフィードバックを取り入れながら改善を続けるとしている。</p>
<p>Meta AIはすでに複数地域で展開されており、今回の日本投入は同社のグローバル展開計画の一環となる。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/3 [WED]生成AI普及の裏で「リテラシー不足」が深刻化──野村総研「IT活用実態調査2025」、導入率57.7％・課題は人材とリスク管理</title>
      <link>https://ledge.ai/articles/nri_it_survey_2025_generative_ai_literacy_gap</link>
      <description><![CDATA[<p>野村総合研究所（NRI）は2025年11月25日、日本企業517社を対象に実施した「IT活用実態調査（2025年）」の結果を<a href="https://www.nri.com/jp/news/newsrelease/20251125_1.html">公表</a>した。調査では、生成AIの導入が急速に広がる一方、その活用を支えるリテラシーやリスク管理の体制が追いついていない実態が浮き彫りとなったという。</p>
<h2>IT予算は増加傾向が続くが、前年から伸びが鈍化</h2>
<p>2025年度のIT予算が「増加した」と回答した企業は49.0％で、前年（59.0％）から10ポイント低下した。2026年度を「増加見込み」とする企業も47.5％と半数近くにのぼり、増加基調は続くものの、勢いはやや落ち着きつつある。</p>
<p><strong>IT予算の推移（NRI「IT活用実態調査2025」より）。2025年度は増加の勢いが前年より鈍化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054612_822d38fda9/000054612_822d38fda9.png" alt="000054612.png" /></p>
<h2>生成AIの導入率は57.7％、導入済＋検討中で76％</h2>
<p>生成AIを「導入済み」と回答した企業は57.7％に達し、前年（44.8％）から一段と普及が進んだ。ChatGPTやGeminiといった汎用サービスの浸透により、「導入検討中」の割合は減少し、導入フェーズが“検討”から“活用強化”へ移行していることがうかがえる。</p>
<p><strong>新技術の導入状況。生成AIは57.7％が導入済み、ノーコード／ローコードツールも51.0％に</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054613_b373ec554c/000054613_b373ec554c.png" alt="000054613.png" /></p>
<h2>課題のトップは「リテラシー不足」70.3％、次いで「リスク管理の難しさ」48.5％</h2>
<p>生成AI活用における課題として最も多かったのは「リテラシーやスキルが不足している」（70.3％）で、前年の65.4％から増加した。導入フェーズが進む中で、実業務レベルでの使いこなしや品質管理が要求される場面が増え、教育・トレーニング体制の不足が顕在化した形だ。</p>
<p><strong>生成AI活用における課題。1位はリテラシー不足（70.3％）、2位はリスク管理（48.5％）</strong>
続く課題は「リスクを把握し管理することが難しい」（48.5％）。機密データの取り扱いや生成物の品質保証など、ガバナンス面の整備が追いつかない企業が多い。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054614_9cb8e79179/000054614_9cb8e79179.png" alt="000054614.png" /></p>
<h2>レガシーシステムは依然として約半数に残存</h2>
<p>企業の情報システムにおけるレガシー環境の残存率は、アプリケーションが47.3％、基盤系が48.2％と、前年から改善はみられるものの依然として高水準だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054615_12b800e0f8/000054615_12b800e0f8.png" alt="000054615.png" /></p>
<p>懸念点のトップは「ブラックボックス化・有識者不足」（51.6％）。続いて、「ベンダーサポートの終了」（50.1％）が挙げられ、技術負債が経営やIT投資の柔軟性を阻害している状況が明確になった。</p>
<p><strong>レガシーシステムに関する懸念。ブラックボックス化と人材不足が半数超</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054616_921e943c42/000054616_921e943c42.png" alt="000054616.png" /></p>
<h2>「必要だが足りない」デジタル人材、ITストラテジストの保有率は29.6％</h2>
<p>専門人材の確保については、「保有すべき」と回答した企業は多数である一方、社内に「保有している」と答えた割合は大きく下回った。</p>
<p>特に顕著なのはITストラテジストで、必要性71.9％に対し保有29.6％と大きなギャップがある。また、プロジェクトマネージャーは必要80.1％に対し保有55.0％で、ビジネス・テクノロジー双方の専門家が不足している。</p>
<p><strong>専門人材の必要性と保有状況。ITストラテジストなど、必要性に対し保有が大きく不足</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054617_5b78391399/000054617_5b78391399.png" alt="000054617.png" /></p>
<h2>生成AIの普及と同時に浮き彫りになる構造的な課題</h2>
<p>調査結果からは、</p>
<ul>
<li>生成AI導入フェーズの急速な進展</li>
<li>しかしリテラシー不足・リスク管理不足という基盤整備の遅れ</li>
<li>レガシーシステムと技術負債の残存</li>
<li>専門人材の不足</li>
</ul>
<p>という「普及と課題のギャップ」が明確に示されている。
NRIは、今後も企業のIT・デジタル化の現状を継続的に観測し、課題解決を支援するとしている。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/3 [WED]OpenAI、ChatGPT品質改善に全集中「非常事態（code red）」宣言──CEOサム・アルトマン氏が他社LLMの進化に危機感で社内指示</title>
      <link>https://ledge.ai/articles/openai_chatgpt_code_red_improvement_directive</link>
      <description><![CDATA[<p>米テック系メディア The Information は2025年12月1日（米国時間）、OpenAIのCEOであるサム・アルトマン氏が社員向けの社内メモで 「code red（非常事態）」を宣言し、ChatGPTの改善を最優先するよう指示した と<a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort">報じた</a>。</p>
<p>同メディアによると、アルトマン氏はメモで、ChatGPT の 速度、応答品質、信頼性、パーソナライズ性 を中心に改善を加速する必要性を強調。社内リソースの再配分を求め、他のプロジェクトについては一部を延期または凍結する方針を示したという。</p>
<p>この報道を受け、Reuters は「The Information reported on Monday」として<a href="https://www.reuters.com/business/media-telecom/openai-plans-improve-chatgpt-delay-initiatives-such-advertising-information-2025-12-02/">記事</a>を配信し、広告導入や新規イニシアティブの遅延が検討されている点を伝えた。Bloomberg も同内容を紹介しつつ、OpenAIがChatGPTの改善に社内資源を集中させる状況を説明した。また、Wall Street Journal（WSJ） は独自に社内メモを確認したとし、日次の進捗チェックやチーム再配置など、運用上の詳細を補足している。</p>
<h2>競争激化で「ChatGPTそのもの」の品質が問われる局面に</h2>
<p>背景には、競合AIモデルの性能向上がある。とくに Google が開発する最新モデル「Gemini 3」は、複数のベンチマークで高い評価を受けており、AIチャット領域で OpenAI の優位性を揺るがしつつあると報じられている。こうした状況の中で、OpenAI 内部では ChatGPT を巡る競争が一段と厳しくなっているとの見方が、主要メディアの報道で広がっていた。</p>
<p>OpenAI はここ数ヶ月、広告テストやショッピング支援など新機能の展開を準備していたが、今回の「code red」宣言によって、同社が 短期的な新機能追加よりも、ChatGPTそのものの品質改善を優先課題に据えた ことが示されたかたちだ。
現時点で、OpenAI は code red 宣言について公式の声明を発表していない。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本の大手3社、AI検索「Perplexity」に一斉抗議──共同・毎日・産経が著作権侵害と虚偽表示を指摘、47NEWSに数十万回アクセスも</title>
      <link>https://ledge.ai/articles/perplexity_japan_media_protest_20251201</link>
      <description><![CDATA[<p>2025年12月1日、共同通信社、毎日新聞社、産業経済新聞社（産経新聞）は、米Perplexity AIが提供するAI検索サービス「Perplexity」に対し、それぞれ抗議書を送付したと発表した。いずれの会社も、自社記事が許諾なく収集・複製され、回答生成に利用されていると主張している。3社の発表時点で、Perplexity AIによる今回の抗議書に関する公式コメントは確認されていない。</p>
<h2>共同通信社──47NEWSに数十万回のアクセス、虚偽表示も指摘</h2>
<p><a href="https://www.kyodonews.jp/information/ai.html">共同通信社</a>は、配信記事が掲載されているニュースサイト「47NEWS」について、2024年8月以降に数十万回のアクセスが確認されたと説明し、これがPerplexityによる記事収集に関連するとしている。同社は、許諾なく記事を複製・利用する行為は著作権法違反に当たると指摘した。</p>
<p>また、Perplexityが共同通信の社名や記事を表示しながら、記事内容と異なる情報を提示する事例が確認されたとし、こうした表示が不正競争防止法の問題に該当する可能性を示している。</p>
<p>抗議書では、記事の即時利用停止、収集データの開示、無断利用に対する損害賠償などを求めている。共同通信加盟48紙も同日、無断収集・利用に抗議する声明を発表した。</p>
<h2>毎日新聞社──robots.txt無視、ゼロクリック問題を懸念</h2>
<p><a href="https://www.mainichi.co.jp/info/20251201.html">毎日新聞社</a>は、同社のサーバー解析結果として、遅くとも2024年7月以降、記事数十万本が許諾なく収集されたと説明している。同社は、robots.txtを用いた取得拒否設定を行っていたが、Perplexityがこれを無視したとしている。</p>
<p>同社は、行為が著作権法21条（複製権）および23条（公衆送信権）の侵害に当たると主張。さらに、回答画面に毎日新聞の名称や記事を出典として表示しながら、内容と異なる事実が提示されるケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、経緯の報告、損害賠償の支払いを求めており、通知後14日以内の回答を求めている。</p>
<h2>産経新聞社──PerplexityとPro双方での無断利用を指摘</h2>
<p><a href="https://www.sankei.jp/wp-content/uploads/2025/12/2025.12.01-%E7%94%9F%E6%88%90AI%E4%BA%8B%E6%A5%AD%E8%80%85%E3%81%B8%E3%81%AE%E6%8A%97%E8%AD%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6.pdf">産経新聞</a>は、Perplexityおよび「Perplexity Pro」サービスにおいて、自社ニュースサイト「Sankei News」や「Sanspo」に蓄積した記事が無断で複製され、回答生成に利用されていると説明している。</p>
<p>同社は、これらの行為が著作権法21条および23条の侵害に当たると主張。記事内容と異なる情報を示しながら、産経新聞社の名称や記事を出典として表示するケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、関連データの削除などを求めている。</p>
<p>日本の報道機関とPerplexityをめぐっては、2025年8月以降、読売新聞グループ、日本経済新聞社、朝日新聞社などが、記事の無断利用をめぐる損害賠償を求めて提訴している。新聞協会も、ニュースコンテンツの無断取得に関する声明を公表している。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>EpicのCEO「AI使用はゲーム制作の基本工程になる。明示ラベルは不要」──生成AI使用の開示を義務化するSteamへの異議に賛同</title>
      <link>https://ledge.ai/articles/epic_ceo_ai_tag_unnecessary_steam_disclosure_debate</link>
      <description><![CDATA[<p>2025年11月27日（現地時間）、映像クリエイターであるWorkman氏が、「Steamやすべてのデジタルマーケットは“Made with AI”タグをやめるべきだ。もはや意味をなさない（Steam and all digital marketplaces need to drop the “Made with AI” label. It doesn’t matter any more.）」と投稿した。この意見に、Epic GamesのCEOである Tim Sweeney（ティム・スウィーニー）氏が「Agreed（同意する）」と返信し、ゲーム制作におけるAIタグの必要性について疑問を呈した。</p>
<h2>「Made with AI」タグは “もはや意味をなさない”</h2>
<p>Workman 氏はX上で、ゲームストアに“AI製（Made with AI）”と明示することは、現在の制作現場の実態から乖離しつつあると指摘した。その後 <a href="https://www.linkedin.com/posts/mattworkman_epic-games-ceo-argues-marketplaces-dont-activity-7399863685189627904-WZnL">LinkedIn</a>で投稿を補足し、一般的な制作ツールの多くにAI機能が搭載されていることから、「どこからどこまでが “AI使用” に該当するのか」という線引きが難しくなっていると説明。開示の有無によって開発者間に不公平が生じているケースもあると述べ、Valveに対しタグの撤廃を求めた。</p>
<p>こうした指摘は、Steamが導入したAI使用開示制度の運用上の難しさや、AIが制作ツールとして一般化していく中で、開示が“特殊なもの”として扱われ続けることへの懸念を示すものとなっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Tim_Sweeney_ai_tag_e17446f159/Tim_Sweeney_ai_tag_e17446f159.jpg" alt="Tim Sweeney ai tag.jpg" /></p>
<h2>Epic CEOの賛同──「AIはゲーム制作の基本工程に組み込まれる」</h2>
<p>Workman 氏の投稿に対し、Epic Games のCEOである Tim Sweeney 氏は「Agreed」と短く賛同したうえで、続くやり取りの中で自身の見解を明らかにした。</p>
<p>Sweeney 氏は「AIは今後ほぼすべてのゲーム制作プロセスに組み込まれていく」と述べ、AI使用を特別にラベルとして表示する必要性は薄れていくと指摘。著作者表示や権利状態の明確化が求められるアート展示やライセンス販売とは異なり、ゲームストアにおける“AIタグ”は制作実態にそぐわないとする立場を示した。</p>
<h2>開示を求めるSteam、受け入れるEpic──AIコンテンツをめぐる両社のスタンスの違い</h2>
<p>Steamを運営する Valve は2024年1月、「AI Content on Steam」の方針を導入し、生成AIを利用したゲームを原則受け入れる一方、開発者にAI使用状況の開示を義務づけている。具体的には、AIで生成したアートやコードなどの「事前生成コンテンツ」、プレイ中にAIが動的に生成する「ライブ生成コンテンツ」について、権利関係や安全性を確認したうえでストアページの「AI Generated Content Disclosure」欄に記載する方式を採用している。</p>
<p>Steamのスタンスは段階的に形成されてきた。2023年には生成AIアートを含むゲームが権利不備で却下された例が報告され、Valveは後に「権利が確認されたAIコンテンツは受け入れる」と説明。その後2024年に開示義務制度が整備され、AIを使ったゲームの“条件付き受け入れ”という形に落ち着いた。</p>
<p>一方、Epic Games Store は当初から生成AIを使用したタイトルの配信を認める立場を取り、AI技術そのものを理由に制限しない姿勢を採ってきた。両社はAIコンテンツの扱いにおいて、「透明性の確保を重視するSteam」と「AI使用を特別扱いしないEpic」という対照的な方針を示している。</p>
<p>AI使用の透明性を求める声と、技術が一般化するなかで特別なタグを付与することへの疑問が併存しており、SteamとEpicの異なる姿勢はその対立軸を象徴している。
AIが制作の基本工程となる時代に、どのような開示ルールが適切なのか。今後も議論が続くテーマとなりそうだ。</p>
]]></description>
      <pubDate>Sun, 30 Nov 2025 02:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>