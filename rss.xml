<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Getty Images、Perplexityと複数年ライセンス契約──AI検索で合法画像とクレジット表示を強化、英国ではStability AI訴訟に判決</title>
      <link>https://ledge.ai/articles/gettyimages_perplexity_ai_license_stabilityai_uk_ruling</link>
      <description><![CDATA[<p>Getty Imagesは2025年10月31日、AI検索サービスを提供するPerplexityとの複数年にわたるライセンス契約を締結したことを<a href="https://newsroom.gettyimages.com/en/getty-images/getty-images-and-perplexity-strike-multi-year-image-partnership">発表</a>した。AIによる画像検索の精度向上と、画像制作者のクレジット表示の改善を目的とした取り組みだ。</p>
<p>一方11月4日、同社が英国で提起していたStability AIとの著作権訴訟では、11月4日にロンドン高等法院が判決を下し、これについての声明を<a href="https://newsroom.gettyimages.com/en/getty-images/getty-images-issues-statement-on-ruling-in-stability-ai-uk-litigation">発表</a>した。</p>
<h2>Perplexityとの契約：合法的な画像利用を推進</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cloud_technology_big_data_financial_technology_and_artificial_intelligence_011824783d/cloud_technology_big_data_financial_technology_and_artificial_intelligence_011824783d.jpg" alt="cloud-technology-big-data-financial-technology-and-artificial-intelligence.jpg" /></p>
<p>同社は10月31日付の発表で、Perplexityと複数年のグローバルライセンス契約を締結したと明らかにした。この契約により、PerplexityのAI検索および発見ツールにおいて、Getty Imagesが保有する編集・クリエイティブ画像を合法的に表示できるようになる。Getty ImagesのAPI技術を活用し、高品質な画像を統合することで、ユーザー体験の向上とクレジット表示の明確化を図る。</p>
<p>リリースの中で同社は、PerplexityがGetty ImagesのAPIを「コンテンツ制作および表示ワークフローに深く統合する」と説明。これにより、「ライセンスされた画像の適切な利用を促進し、クリエイターのクレジット表示を改善する」としている。</p>
<p>Getty ImagesのNick Unsworth氏は、契約が「正しい帰属表示を促進し、AI製品の品質と信頼性を高めるもの」と説明。
PerplexityのJessica Chan氏も「コンテンツの出典や制作者を明示することが、AI時代の正確な情報理解につながる」と述べた。</p>
<p>同社はこの契約はAIプラットフォームにおける「ライセンス画像の正規利用とクレジット明示」を支援するもので、AI検索や生成ツールにおける画像帰属の透明性を高めることを目的としている。</p>
<h2>英国でのStability AI訴訟に判決</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/abstract_gradient_background_with_delicate_waves_aa534c0d6c/abstract_gradient_background_with_delicate_waves_aa534c0d6c.jpg" alt="abstract-gradient-background-with-delicate-waves.jpg" /></p>
<p>Getty Imagesは、画像生成モデル「Stable Diffusion」を開発するStability AIを相手取り、著作権侵害を訴えていた。英国ロンドン高等法院（High Court of England &amp; Wales）は11月4日、Joanna Smith判事による<a href="https://www.judiciary.uk/wp-content/uploads/2025/11/Getty-Images-v-Stability-AI.pdf">判決</a>を言い渡した。</p>
<p>判決では、AI生成画像にGetty Imagesのウォーターマークやロゴが含まれていた点について商標侵害を認定した一方、モデルの訓練過程における著作権侵害の主張は棄却された。判決文では、「モデルが著作物を直接保存または複製している証拠は示されていない」と記されている。</p>
<p>Getty Imagesは同日付の声明で、
「Stable Diffusionの出力に含まれる当社商標の使用が侵害にあたることが確認された」と述べ、モデル提供者に商標責任がある点を「知的財産権者にとって重要な判断」とした。</p>
<p>また、同社は「AIモデル開発における透明性の欠如に懸念を抱いており、政府に対して透明性を高める法制度の整備を求める」とコメントしている。</p>
<p>Getty Imagesは、今回の英国判決で認定された事実を米国で進行中の関連訴訟に反映させる方針を示した。</p>
<h2>今後の方針</h2>
<p>同社は、AI時代における画像利用の正当性とクリエイターの権利保護を両立させるため、ライセンス契約と法的措置の両面から対応を進めている。今後も、AI検索や生成分野における合法的なデータ利用の枠組みを整備し、画像の出典明示や透明性の確保を推進するとしている。</p>
]]></description>
      <pubDate>Sat, 08 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google「Project Suncatcher」発表　太陽光×衛星コンステでAI計算を“宇宙へ”</title>
      <link>https://ledge.ai/articles/google_project_suncatcher_space_ai_datacenter</link>
      <description><![CDATA[<p>Googleは2025年11月4日（現地時間）、太陽光発電を搭載した小型衛星群を用い、宇宙空間でAI計算を行うことを目指す新たな研究プロジェクト「Project Suncatcher（プロジェクト・サンキャッチャー）」を<a href="https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/">発表</a>した。</p>
<p>同社の専用チップ「TPU（Tensor Processing Unit）」を搭載した衛星コンステレーションを軌道上に展開し、光学通信で相互接続することで“宇宙データセンター”を形成する構想だ。想定軌道は太陽同期（ドーン・ダスク）で、太陽光の連続利用を見込む。</p>
<h2>地上リソースの制約を超える「宇宙データセンター」</h2>
<p>Google Researchによると、AIモデルの高精度化に伴い、計算能力と電力の需要は急速に拡大している。Project Suncatcherは、地上のエネルギー・冷却・用地といった制約を緩和しつつ、AI計算を持続的にスケールさせるための「ムーンショット（挑戦的研究）」として位置づけられている。</p>
<p>太陽同期軌道では、太陽光パネルの発電効率が地上比で最大8倍に達し、1衛星あたり平均約4 kWの発電を想定。地上のデータセンターで必要とされる100 MW級の電力に比べると、同規模の衛星クラスタ（81機）では0.3 MW程度に収まる試算だ。</p>
<h2>1 km圏内に81機──クラスタ構成の設計例</h2>
<p><a href="https://goo.gle/4qGsU8X">論文</a>では、直径約1 kmの範囲に81機の小型衛星を立体的に配置し、1クラスタあたり約1.3 PFLOPSの演算性能を実現する設計例が示された。各衛星は16 GBメモリを備えたTPUを搭載し、自由空間光通信（Free-Space Optical Link）を介して数km以内で編隊飛行する。通信遅延は0.5 ms以下に抑えられ、地上データセンターと同等の対話応答が可能とされている。</p>
<p>Googleはベンチスケールのデモンストレーターで双方向1.6 Tbps（片方向800 Gbps）の通信速度を達成したと報告。通信帯域の確保には、多波長DWDMや空間多重技術を組み合わせる設計を検討している。</p>
<h2>放射線試験と熱設計──「Trillium TPU」で検証へ</h2>
<p>宇宙空間での安定稼働に向け、Googleは次世代TPU「Trillium（Cloud TPU v6e）」の放射線耐性を評価している。
宇宙では対流冷却ができないため、81機構成のクラスタで約450 m²の放熱面積を確保する必要があると論文は指摘。放熱板の構成や電力変換効率、冷却の最適化も主要な検討課題に挙げられた。
AIワークロードとしては、LLMの学習ではなく推論（inference）・埋め込み生成（embedding）・検索（retrieval）など、軽量分散処理を中心に想定している。</p>
<h2>Planet Labsと連携、2027年に試験衛星を打ち上げ</h2>
<p>次のステップとして、Googleは地球観測衛星を運用する米Planet Labsと提携し、軌道上での技術実証を進める。
Planetは11月4日付の<a href="https://www.planet.com/pulse/planet-to-build-and-operate-advanced-space-platform-for-google-s-project-suncatcher-moonshot/">発表</a>で、Suncatcher向けに「先進的な宇宙プラットフォーム」を構築・運用することを明らかにした。
両社は2027年初頭までに2機の試験衛星を打ち上げ、光学通信の安定性、熱挙動、誤り訂正、電力効率などを評価する「learning mission（学習ミッション）」を予定している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/google_and_planet_suncatcher_moonshot_5280e0e084/google_and_planet_suncatcher_moonshot_5280e0e084.jpg" alt="google and planet suncatcher moonshot.jpg" /></p>
<h2>「AI計算を宇宙に」──Googleが描く次世代インフラ</h2>
<p>Project Suncatcherはまだ構想段階にあるが、Googleは「AI計算を地球の外に拡張する」という新しい方向性を示した。
公式ブログでは「Project Suncatcher is a moonshot to explore solar-powered satellite constellations with TPUs and free-space optical links for scalable AI compute（TPUと光学通信を組み合わせた太陽光衛星群によるAI計算スケーリングを探るムーンショットだ）」と説明している。
エネルギー負荷や冷却コストを軽減しながら、AI計算資源を宇宙空間へと拡張する次世代インフラの研究が、今後本格化する見通しだ。</p>
]]></description>
      <pubDate>Sat, 08 Nov 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPTの“当たり障りないフィルター”を外すと、応答が一段と鋭くなった──米国で話題の「辛口プロンプト」現象</title>
      <link>https://ledge.ai/articles/chatgpt_ii_hito_filter_prompt_trend</link>
      <description><![CDATA[<p>ChatGPTの「当たり障りのない」応答に物足りなさを感じた海外ユーザーが、あえて“当たり障りないフィルター”を外すプロンプトを公開し、話題を集めている。Redditで拡散したこの手法は、ChatGPTのトーンを「共感的な聞き役」から「論理的で辛口な批評家」へと変えるもので、SNSでは「回答の質が上がった」との声も相次いだ。</p>
<h2>Reddit発の「辛口プロンプト」が反響呼ぶ</h2>
<p>発端となったのは、Redditユーザー Wasabi_Open 氏が投稿した「I made ChatGPT stop being nice and it’s the best thing I’ve ever done（ChatGPTに“いい人”をやめさせたら、最高の結果になった）」という<a href="https://www.reddit.com/r/PromptEngineering/comments/1okppqe/i_made_chatgpt_stop_being_nice_and_its_the_best/">スレッド</a>だ。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/I_made_Chat_GPT_stop_being_nice_375797ac64/I_made_Chat_GPT_stop_being_nice_375797ac64.jpg" alt="I made ChatGPT stop being nice.jpg" /></p>
<p>同氏はプロンプトの中で、ChatGPTに対し「私の意見を褒めたり慰めたりせず、誤りがあれば明確に指摘してほしい」「論理の矛盾を批判的に分析してほしい」と指示。これにより、ChatGPTが従来よりも率直で的確なフィードバックを返すようになったという。
この投稿は数千件のいいねを集め、「まるで冷静なメンターと議論しているようだ」とのコメントも寄せられた。</p>
<h2>SNSで広がった「nice filter」論争</h2>
<p>この現象を11月3日に<a href="https://x.com/markgadala/status/1985032100672618588">紹介</a>したのが、X（旧Twitter）のユーザー Mark Gadala 氏だ。同氏は「“nice filter”を外したらChatGPTの回答が劇的に改善した」と投稿し、多くのフォロワーが同様のプロンプトを試したと報告している。一方で、「フィルターを解除すると性能が上がる」という表現が拡散したことで、「内部制限を外す行為ではないか」との誤解も広がった。実際には、ChatGPTの内部に“nice filter”と呼ばれる設定は存在せず、プロンプトの指示文によって出力トーンが変わるだけだ。</p>
<h2>「当たり障りないフィルター」の正体</h2>
<p>OpenAIの設計方針によれば、ChatGPTは安全性と中立性を重視した“共感的”な初期設定を採用している。ユーザーが感じる「いい人フィルター」とは、この丁寧でポジティブに応答する傾向を指した比喩に過ぎない。つまり、「フィルターを外す」とは内部機能を解除するのではなく、プロンプトによってAIの口調や態度を再設定する行為だといえる。</p>
<h2>“辛口AI”の効用と注意点</h2>
<p>ユーザーの反応はおおむね好意的だ。「率直な批評を受けることで思考が整理された」「甘い同意よりも鋭い反論のほうが学びになる」といった意見が目立つ。一方で、「冷たく感じる」「会話がきつくなる」との声もあり、タスクや気分に応じてトーンを使い分ける重要性が指摘されている。専門家の間では、このようなトーン調整を「AIとの協働スキル」や「プロンプトリテラシー」の一環とみなす動きも広がっている。</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ソフトバンクとOpenAI、日本に合弁会社「SB OAI Japan」を設立──企業経営を変革するAI「クリスタル・インテリジェンス」を2026年展開へ</title>
      <link>https://ledge.ai/articles/softbank_openai_sb_oai_japan_crystal_intelligence_launch</link>
      <description><![CDATA[<p>ソフトバンクグループとOpenAIは2025年11月5日、AIによる企業経営の変革を目的とした合弁会社「SB OAI Japan合同会社（SB OAI Japan GK）」を設立したと<a href="https://www.softbank.jp/corp/set/data/news/press/sbkk/2025/20251105_02/pdf/20251105_02.pdf">発表</a>した。新会社は、OpenAIの技術を活用した法人向けAIソリューション「クリスタル・インテリジェンス（Crystal intelligence）」を2026年に日本国内で独占展開する。</p>
<p>「クリスタル・インテリジェンス」は、OpenAIのエンタープライズ向け最新プロダクトに、日本市場向けの導入支援と運用サポートを組み合わせたAIソリューション。企業の生産性向上や経営効率の最大化を支援するもので、AI導入から活用までを一貫して支援する。</p>
<p>まずソフトバンク株式会社が最初のユーザーとして導入し、実証と開発を通じて最適な運用方法を検証。その知見を基に、SB OAI Japanを通じて日本企業への展開を進める方針だ。ソフトバンクグループではすでに約250万個の「カスタムGPT（業務や用途に合わせてカスタマイズ可能なChatGPT）」を活用しており、AIネイティブな組織づくりを推進している。</p>
<p>OpenAIのCEOであるサム・アルトマン氏は「ソフトバンクグループとの合弁会社は、日本を皮切りに、世界の有力企業へ先進的な AI を提供していくという OpenAI のビジョンを加速させる、重要な一歩となります」とコメントした。</p>
<p>ソフトバンクグループ株式会社の代表取締役 会長兼社長執行役員の孫正義氏は、「人々の働き方や企業経営が革新される新たな時代が始まります。SB OAI Japanの発足により、AIエージェントが協調し自律的に業務を遂行する世界が実現していきます。OpenAIと共に、AI革命を新たなステージに推し進めていきます」と述べた。</p>
<p>また、ソフトバンク株式会社の代表取締役 社長執行役員 兼 CEOの宮川潤一氏は、「SB OAI Japanの発足により、クリスタル・インテリジェンスの開発が加速します。ソフトバンクは自ら先陣を切って導入・活用を進め、得られた知見を基に法人のお客さまへ提供することで、企業の経営変革を推進していきます」と語っている。</p>
<p>新会社「SB OAI Japan合同会社」は、東京都港区海岸1-7-1に本社を置き、出資比率はCホールディングス株式会社50％、OpenAI 50％。Cホールディングスの持株比率はソフトバンク株式会社51％、ソフトバンクグループ株式会社49％となっている。</p>
<p>同社は今後、「クリスタル・インテリジェンス」を通じて企業の業務プロセスに深く根差したAI活用を支援し、日本企業の経営変革を後押ししていく方針だ。</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>PKSHAと東北大学、「説得対話AI」でEMNLP 2025 Industry Trackに採択──社会心理・行動経済学を融合し、低意欲層にも“自然な動機づけ”</title>
      <link>https://ledge.ai/articles/pksha_tohoku_persuasive_dialogue_ai_emnlp2025</link>
      <description><![CDATA[<p>株式会社PKSHA Technologyは2025年10月31日、東北大学 言語AI研究センターとの共同研究による「説得対話AI」に関する論文が、自然言語処理分野の国際会議「EMNLP 2025（Conference on Empirical Methods in Natural Language Processing）」のIndustry Trackに採択されたと<a href="https://www.pkshatech.com/news/20251031/">発表</a>した。</p>
<p>論文タイトルは「Enhancing Persuasive Dialogue Agents by Synthesizing Cross-Disciplinary Communication Strategies」。社会心理学・行動経済学・コミュニケーション理論を横断的に取り入れ、より多面的で実践的な説得戦略を設計する新しい枠組みを提案している。</p>
<h2>行動心理学の手法をAIが“文脈で選ぶ”</h2>
<p>研究は、営業やカウンセリングなど「目的志向型の対話」におけるAI活用を想定して開発されたという。
既存の説得AIは、特定の戦略（例：単純な論理訴求）に依存する傾向があり、現実のコミュニケーションの複雑さを再現しづらいという課題があった。</p>
<p>今回のモデルは、社会心理学で知られる「フット・イン・ザ・ドア（段階的要請）」や「ドア・イン・ザ・フェイス（譲歩的要請）」「互恵性」「希少性」「フレーミング効果」など、31種類の説得戦略を統合。対話の文脈や相手の反応に応じて最適な戦略を動的に切り替える仕組みを持つ。</p>
<p><strong>図：従来モデル（左）と提案モデル（右）の説得対話の比較</strong>
従来のAI（左）は限定的な戦略に依存し、説得に失敗している。一方、提案モデル（右）は「出典確認」「内省促し」「一貫性訴求」など拡張戦略を組み合わせ、低意欲者にも行動変容を促すことに成功している
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/paksha_tohoku_559ec27a64/paksha_tohoku_559ec27a64.jpg" alt="paksha tohoku.jpg" /></p>
<p>論文では、たとえば「寄付をためらう相手に対して、まずは『情報共有だけでもどうですか？』と小さな行動を提案し、そこから寄付に導く」という例が示されている。こうした“段階的誘導”は人間のコーチング現場でも実践されており、AIがそれを再現するのは初の試みとされる。</p>
<h2>GPT-4oを用いた検証で成功率83%</h2>
<p>検証には、寄付対話データセットPersuasion for Good（P4G）と、多分野の13,000件のシナリオを含むDailyPersuasionが用いられた。
OpenAIのGPT-4o（2024年11月20日版）を基盤とする対話モデル「ProCoT-rich-desc」を構築し、従来手法（ProCoT-p4g）と比較。</p>
<p>結果として、説得成功率83.3％を記録し、特に「意欲が低い層」においても行動意向が平均+1.10ポイント改善した。
人間による評価では72.5％の評価者が提案モデルを「より説得的」と判断。複数データセット間でも汎用性が確認された。</p>
<h2>倫理的リスクへの配慮──「押しつけない説得」へ</h2>
<p>研究チームは、AIが心理的影響力を行使することのリスクにも言及。
「感情的な訴求や時間的プレッシャーが心理的負担を生む可能性がある」とし、人間による最終確認（Human-in-the-Loop）を組み込んだ安全設計を提案している。</p>
<p>具体的には、AIの出力をフィルタリングする「有害性検知ゲート」や、倫理的に望ましくない戦略を除外する仕組みも検討されている。</p>
<h2>実装と今後の展開</h2>
<p>PKSHAはこの研究成果を自社の「PKSHA AI Agents」に活用し、コンタクトセンターや営業現場などでの対話支援を高度化する方針だ。AIが相手の心理状態や意欲レベルに応じて最適なアプローチを選択できれば、業務支援だけでなく、教育・医療・自治体窓口など、幅広い分野での応用が期待される。</p>
<p>PKSHAと東北大学は、「AIによる説得」が社会的・倫理的に安全な形で機能するための基盤技術として、今後も共同研究を継続するとしている。</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、UAEに152億ドルを投資──NVIDIA製GPUで築く「技術・人材・信頼」のモデルケース　AI・クラウド基盤を強化</title>
      <link>https://ledge.ai/articles/microsoft_uae_15_2_billion_investment</link>
      <description><![CDATA[<p>Microsoftは2025年11月3日（現地時間）、アラブ首長国連邦（UAE）におけるAIおよびクラウド関連投資の詳細を<a href="https://blogs.microsoft.com/on-the-issues/2025/11/03/microsofts-15-2-billion-usd-investment-in-the-uae/">発表</a>した。同社は2023年から2029年末までの7年間で、総額152億ドル（約2兆3,500億円）を投じる計画を明らかにした。</p>
<p>投資はAI・クラウドインフラの拡充、人材育成、国際的な信頼基盤の強化を柱とし、「テクノロジー（Technology）」「タレント（Talent）」「トラスト（Trust）」の3分野に重点を置くという。</p>
<h2>2023〜2029年にかけて152億ドルを投資</h2>
<p>Microsoftの副会長兼社長、Brad Smith氏によると、今回の投資は「UAEでお金を集めるものではなく、UAEで支出するもの」だという。2023年に始動したAIイニシアチブのもと、同社はこれまでに約73億ドルを投じており、その内訳はG42社への15億ドル出資、AI・クラウドデータセンター設備への46億ドル、現地運営費など12億ドルとなる。
今後2026〜2029年末までにさらに79億ドルを支出する予定で、55億ドルを追加の設備投資、24億ドルを運営費等に充てる。</p>
<h2>米国製GPUを活用したAIインフラの構築</h2>
<p>Microsoftは米商務省からの輸出許可を得て、NVIDIA製GPUをUAEに供給している。
2025年時点でA100相当のGPU 2万1,500基を導入済みであり、2025年9月にはGB300を含む6万400基分の追加許可を取得した。
これにより、同国のデータセンターではOpenAIやAnthropicなどのAIモデル、Microsoft自身のCopilotアプリケーション、オープンソースモデルなどを動作させている。</p>
<p>Microsoftは「UAEではAI需要が急速に拡大しており、課題は供給が需要を上回ることではなく、需要の伸びに追いつくことだ」と述べている。ブログによると、同国の生成AI利用率は世界最高水準にあり、UAEでは人口の59.4％が生成AIを活用。2位のシンガポール（58.6％）を上回り、他国で50％を超える例はないという。</p>
<h2>現地人材と教育への長期投資</h2>
<p>Microsoftは、技術投資と並行して人材育成にも注力する。
UAEの拠点には約1,000人の社員と関連スタッフ（40カ国籍）が在籍し、エンジニアは約100人。パートナー企業は1,400社に拡大し、関連従業員は約4万5,000人に達する。</p>
<p>2025年にはアブダビに「グローバル・エンジニアリング開発センター（Global Engineering Development Center）」を設立し、世界中から技術者を誘致。地域企業のDX推進や新サービス開発を支援している。
また、同市に開設した「Microsoft AI for Good Lab」では、博士号研究者が低資源言語（例：マラウイ、ケニア、ウガンダなど）の大規模言語モデルを共同開発し、人道支援や教育格差の是正にAIを活用している。</p>
<p>教育分野でも、2027年までにUAE国内で100万人のスキルアップを実現する目標を掲げており、連邦政府や地方自治体と連携して職員12万人の研修を開始。さらに、学生17万5,000人、教員3万9,000人を対象としたAI教育プログラムを進めている。</p>
<h2>責任あるAIと国際的信頼の構築</h2>
<p>Microsoftは、AIの活用には「信頼」が不可欠だとし、倫理・セキュリティ・法令遵守を重視している。
2025年2月には、G42およびモハメド・ビン・ザーイド人工知能大学（MBZUAI）とともに「Responsible AI Future Foundation（RAIFF）」をアブダビに設立。中東およびグローバルサウス地域における責任あるAI開発の標準策定を進めている。</p>
<p>さらに、同年4月にはG42との間で「Intergovernmental Assurance Agreement（IGAA）」を締結。
米国・UAE両政府と協議を重ね、サイバー・物理的セキュリティ、輸出管理、データ保護、責任あるAI、KYCなどで米国基準を満たす枠組みを構築した。
Microsoftは「IGAAは2国間の信頼関係を強化するだけでなく、民間企業間でも政府水準のコンプライアンスを実現する初の枠組みだ」と説明している。</p>
<h2>地域連携と文化交流</h2>
<p>同社はシアトルから経済・教育・医療・非営利団体などのリーダーを含む代表団をアブダビに派遣し、地域交流を促進。
現地で開催された「Abu Dhabi Global AI Summit」では、G42、RAIFF、Eurasia Group GZERO Mediaなどと共催し、グローバルサウス諸国におけるAI普及と格差是正の必要性を訴えた。</p>
<h2>今後の展望</h2>
<p>Microsoftは、UAEを中東のAI・クラウド拠点として位置づけ、今後4年間で追加79億ドルを投資する。
Smith氏はブログを次のように結んでいる。</p>
<p>「最も重要なのは、テクノロジーがどれほど他者を支援できるかということだ。私たちは株主への価値提供だけでなく、地域社会に新しい機会と成長をもたらす責任を負っている。」</p>
]]></description>
      <pubDate>Fri, 07 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity、AI特許検索エージェント「Perplexity Patents」を発表──自然言語で特許・技術情報を横断検索</title>
      <link>https://ledge.ai/articles/perplexity_patents_beta_launch_20251030</link>
      <description><![CDATA[<p>Perplexityは2025年10月30日（米国時間）、AIを活用した特許検索サービス「Perplexity Patents」を正式に<a href="https://www.perplexity.ai/ja/hub/blog/introducing-perplexity-patents">発表</a>した。</p>
<p>世界初の「AI特許研究エージェント」として、専門知識がなくても自然言語で特許文献を検索できる機能を備え、知的財産（IP）インテリジェンスへのアクセスを一般化することを目指すという。</p>
<h2>自然言語で特許を検索</h2>
<p>Perplexity Patentsは、自然言語で入力された質問に基づき、関連する特許を提示する検索エージェント。ユーザーは「Are there any patents on AI for language learning?（言語学習向けAIに関する特許はありますか？）」や「Key quantum computing patents since 2024?（2024年以降の主要な量子コンピューティング関連特許は？）」といった文章で検索できる。</p>
<p>AIが特許指向の質問を自動的に理解し、関連特許の一覧と出典を表示する。結果はインラインビューア上で閲覧でき、元の特許文書へのリンクも含まれる。会話形式のインターフェースを採用し、追加質問や比較も継続的に行える。関連するトピックの提案も表示される。</p>
<h2>特徴と仕組み</h2>
<p>Perplexity Patentsは、従来のキーワード一致検索では検出できない先行技術を抽出できる。
例えば「fitness trackers」で検索した場合、「activity bands」「step-counting watches」「health monitoring wearables」などの語を含む特許も提示される。</p>
<p>同社によれば、バックエンドでは特許専用の知識インデックスを活用し、AIリサーチエージェントが複雑なクエリを情報検索タスクに分解して処理する。これにより、数十から数百件の関連文書を参照した回答が生成される。</p>
<h2>検索対象の拡張</h2>
<p>Perplexity Patentsは、特許文献に加えて、学術論文、ソフトウェアリポジトリ、ブログ、動画など、特許以外の技術情報も検索対象に含める。同社は「新しい発明や技術は、特許の枠にとどまらない形で現れることがある」としている。</p>
<h2>提供開始と利用条件</h2>
<p>サービスはベータ版として全世界で提供を開始した。
ベータ期間中は無料で利用でき、ProおよびMaxプランのユーザーは追加の使用クォータやモデル設定オプションを利用可能。</p>
<p>公式ブログで同社は「特許は人類の創意と探究心の記録であり、Perplexity Patentsはその知識に迅速にアクセスできる手段を提供する」と述べている。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>KDDI×ローソン、「ローソン S」高輪本社店でAI×ロボット実証　11月8日開始</title>
      <link>https://ledge.ai/articles/lawson_kddi_vla_ai_robot_store</link>
      <description><![CDATA[<p>KDDI株式会社と株式会社ローソンは2025年10月28日、AI技術とロボットを組み合わせた店舗デジタル化の実証を、11月8日から「ローソン S KDDI高輪本社店」（東京都港区）で開始すると<a href="https://www.lawson.co.jp/company/news/detail/1512018_2504.html">発表</a>した。両社が共同で実施し、小売店舗の省人化や業務効率化を目的としている。</p>
<h2>欠品検知と品出しを自動化</h2>
<p>実証では、自律走行ロボットが店内を巡回し、4Kカメラで棚の画像を撮影。AIが画像を解析してプライスカードやパッケージを認識し、商品名や棚割り、在庫状況を自動で把握する。これにより、欠品を検知し、従来手作業で行っていた確認作業の効率化を図る。</p>
<p>さらに、バックルームの在庫情報をもとに、品出し業務の自動化や、店舗内の人流データと連携した「最適な棚割り」提案なども検証する。AIとロボットを組み合わせることで、店舗運営の現場データを活用したリアルタイムな改善サイクルの構築を目指す。</p>
<p>@<a href="https://www.youtube.com/watch?v=SMC7FnhtTy4&amp;t=1s">YouTube</a></p>
<h2>「Virtual Logistics Assistant（VLA）」を活用</h2>
<p>今回の実証には、KDDIが開発した次世代デジタル基盤「Virtual Logistics Assistant（VLA）」を活用する。
VLAは、実空間と仮想空間をデジタルツインで連携させ、店舗や倉庫のオペレーションを仮想上で再現・最適化する仕組みである。
ロボットが収集した画像や人流データをVLAに集約し、AIが解析することで、欠品の検知や補充タイミングを自動で可視化。データドリブンな店舗運営の基盤として機能する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kddi_lawson_vla_c009912b1c/kddi_lawson_vla_c009912b1c.jpg" alt="kddi lawson vla.jpg" /></p>
<p>今回の実証は、KDDIとローソンが共同で進める「Real×Tech LAWSON」プロジェクトの一環で、現実店舗にテクノロジーを実装し、顧客体験と業務効率の両立を検証する取り組みとなる。両社は今後、実証結果をもとに他店舗への展開も検討するとしている。</p>
<p>なお、本取り組みはKDDIが開催する「KDDI SUMMIT 2025」でも紹介される予定。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>“科学発見の未来の味見”──OpenAIのBrockman氏、GPT-5 Proが12分で導出した治療仮説が未公表論文と一致　食物アレルギーに既存薬の効果を提案</title>
      <link>https://ledge.ai/articles/gpt5_pro_dupilumab_fpies_case_jaci_global</link>
      <description><![CDATA[<p>OpenAIの共同創業者で社長のGreg Brockman氏は2025年10月31日、自身のX（旧Twitter）で「GPT-5 Proが12分の思考で、治療不可能とされていた食物アレルギーに既存薬を提案し、未公表だった査読論文と同じ結論に達した」と<a href="https://x.com/gdb/status/1985057569392709644">投稿</a>した。</p>
<p>この事例が指すのは、dupilumab（デュピルマブ）による食物タンパク質誘発性腸炎症候群（FPIES：Food Protein–Induced Enterocolitis Syndrome）の症例報告だ。AIが独立に導いた仮説が、同日に公開されたJACI Global（Journal of Allergy and Clinical Immunology: Global）誌の症例シリーズと一致したという。</p>
<h2>Brockman氏「科学発見の未来の味見」</h2>
<p>Brockman氏はこの事例の投稿を引用し「Taste of what LLM-driven scientific discovery will be like（LLMによる科学的発見の未来の味見）」と表現。GPT-5 Proが提示した仮説が、当時未公表だった査読研究の結果と一致したと述べ、AIによる科学的洞察の萌芽として紹介した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/brockman_x_gpt5_scientific_discovery_fe45f963b2/brockman_x_gpt5_scientific_discovery_fe45f963b2.jpg" alt="brockman x gpt5 scientific discovery.jpg" /></p>
<h2>JACI Globalが報告──dupilumabでFPIESが寛解</h2>
<p>2025年10月29日付でJACI Globalに掲載された<a href="https://www.jaci-global.org/article/S2772-8293(25)00193-6/fulltext">論文</a>では、成人の小麦誘発FPIES患者に対し、dupilumab投与中に小麦摂取後も発作が起きず、経口負荷試験（約50gの小麦たんぱく）でも無反応となった経緯を報告。治療中断で症状が再燃し、再開で再び耐性が回復するなど可逆的な効果も確認された。研究チームは2〜58歳の7例を追加し、観察的ではあるもののdupilumabの有効性を示唆した。</p>
<h2>GPT-5 Proが独立に導出──「12分の思考」でdupilumabを第一推奨</h2>
<p>この症例を担当したOral Alpan医師の同僚、Derya Unutmaz医師（米ジャクソン研究所）は、論文投稿直前にGPT-5 Proへ臨床ケースを入力。モデルは約12分間の思考を経て、dupilumab（IL-4Rα阻害薬）を第一候補として提案したという。Unutmaz医師はX上で「他のどのモデルもdupilumabを第一選択として示さなかった」と述べ、出力画面のスクリーンショットを公開した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/derya_unutmaz_x_fa4ca8f5c0/derya_unutmaz_x_fa4ca8f5c0.jpg" alt="derya unutmaz x.jpg" /></p>
<p>論文では、dupilumabが樹状細胞OX40Lの抑制（“un-licensing”）を通じてType 2炎症経路を制御し、腸管上皮の過剰反応を抑制した可能性が示唆されている。現時点では仮説段階にあり、さらなる臨床試験が必要とされる。</p>
<p>研究者らは、今回の報告は因果関係を証明するものではなく、観察的症例シリーズにとどまることを強調。また、dupilumabはFPIESに対して未承認であり、治療の変更は必ず医師の管理下で行うべきと注意を促した。</p>
<h2>今後の展望──臨床試験への期待</h2>
<p>主治医のAlpan医師は、Regeneron（dupilumabの共同開発元）に臨床試験を打診する意向を表明。Unutmaz医師は「2万種を超える承認薬の中に、すでに“隠れた治療法”が存在するかもしれない」とし、GPT-5 Proのような高度なAIが既存薬の再利用（ドラッグ・リポジショニング）を加速させる可能性に期待を示した。</p>
]]></description>
      <pubDate>Thu, 06 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スタジオジブリや任天堂など加盟のCODA、OpenAIに要望書──動画生成AI「Sora 2」の無許諾学習に懸念</title>
      <link>https://ledge.ai/articles/coda_request_to_openai_sora2</link>
      <description><![CDATA[<p>一般社団法人コンテンツ海外流通促進機構（CODA）は2025年10月27日、動画生成AI「Sora 2」を開発・運用するOpenAI, L.L.C.に対して<a href="https://coda-cj.jp/news/2577/">要望書を提出</a>した。スタジオジブリや任天堂、東宝、集英社、講談社など、国内主要コンテンツ企業が加盟する同機構は、AIによる無許諾学習および著作権侵害の懸念を指摘している。</p>
<p>要望書ではOpenAIに対し、主に以下の2点を求めている。
1つ目は、CODA会員社のコンテンツを無許諾で学習対象としないこと。2つ目は、Sora 2の生成物に関して会員社から著作権侵害の申立てや相談があった場合、真摯に対応すること。同機構は、AI企業が透明性と説明責任を果たし、権利者の利益を尊重するよう求めた。</p>
<p>Sora 2は、テキストから動画を生成できるOpenAIの次世代モデルで、実在のアニメ作品や映画、ゲームを連想させる映像も生成可能だとされる。SNS上では著名キャラクターや既存作品の表現を模倣した動画が多数投稿されており、著作権や肖像権の侵害につながるおそれが指摘されている。</p>
<p>CODAは、アニメ・ゲーム・映画・出版など100社以上の会員で構成され、海外での海賊版対策や知的財産保護を目的とする非営利団体。同機構は声明の中で、「生成AI時代においても、創作者の正当な権利が損なわれることがあってはならない」と強調している。</p>
<p>生成AIによる著作物利用をめぐっては、米国や欧州でも“オプトアウト方式”の是非をめぐる議論が続く。OpenAIを含む各社は、学習データセットの詳細を非公開としており、透明性や権利処理のあり方が国際的な課題となっている。日本でも、著作権法第30条の4（学習利用）の適用範囲をめぐる議論が高まりつつある。</p>
<p>今後CODAは、国内外の権利者団体との連携を強化しつつ、OpenAIからの回答を注視するとしている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>1X、家庭用ヒューマノイド「NEO」を正式公開──月額499ドル（約7万5,000円）のサブスク開始で“家事お手伝いロボ”が現実に</title>
      <link>https://ledge.ai/articles/1x_neo_home_robot_subscription_launch</link>
      <description><![CDATA[<p>米1X Technologiesは2025年10月28日（米国時間）、家庭向けヒューマノイドロボット「NEO」を<a href="https://www.1x.tech/neo">公開</a>し、プレオーダーを開始した。提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。家庭内の掃除や片付けなど、日常的な家事を支援する“お手伝いロボット”として設計されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_6_ce91e1cf1e/x1neo_6_ce91e1cf1e.jpg" alt="x1neo-6.jpg" /></p>
<p>NEOは、1Xが掲げる「人の生活を支える安全なヒューマノイド」構想に基づき開発された。腱（tendon）駆動による柔らかく静かな動作を特徴とし、人と同じ空間で安全に動作できるよう設計されている。公式サイトでは「単調で時間のかかる家事を肩代わりし、人の時間を取り戻す」とコンセプトを掲げる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_5_7ae0e73c6c/x1neo_5_7ae0e73c6c.jpg" alt="x1neo-5.jpg" /></p>
<p>ユーザーはスマートフォンアプリや音声を通じてタスクを指示でき、NEOは家庭内の環境を学習しながら動作を最適化する。自己充電機能を備えるほか、遠隔からのモニタリングやサポートも可能。1XはNEOを単なるロボットではなく「温かみと個性をもった家庭のパートナー」と位置付けている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1neo_4_dd13229413/x1neo_4_dd13229413.jpg" alt="x1neo-4.jpg" /></p>
<p>主な仕様は、バッテリー駆動時間約4時間（急速充電対応）、静音性は最大22dB。NVIDIA Jetson Thorをベースとした「1X Cortex」コンピューティングシステムを搭載し、360度集音マイクとステレオスピーカーを内蔵する。</p>
<h2>サブスク形式で家庭導入のハードルを下げる</h2>
<p>提供形態は月額499ドル（約7万5,000円）のサブスクリプションまたは一括購入（2万ドル）。NEOは注文ページからプレオーダー可能で、出荷は2026年を予定している。</p>
<p>1Xは公式ページ上で、NEOを「consumer-ready」と表現。2024年の試作版「NEO Beta」発表を経て、今回初めて一般消費者に向けたモデルとして公開された。</p>
<p>@<a href="https://www.youtube.com/watch?v=LTYMWadOW7c">YouTube</a></p>
<p>1X Technologiesは、家庭や産業向けのヒューマノイドロボットを開発する企業で、OpenAIが出資するスタートアップの一つでもある。これまでノルウェーを拠点としていたが、2025年には米カリフォルニア州サンフランシスコに本社を移転。研究開発と製造体制の両面で国際展開を進めている。サブスクリプション形式による提供で家庭でも導入しやすい価格体系を整えたNEOは、ヒューマノイドが日常生活に溶け込む時代の到来を感じさせる存在だ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米ルイビル大の研究者ら、AIが“人類の記憶係”になる時代に「記憶される権利」を提唱──少数のAIベンダーが何を記憶するかを実質的に決定するリスクを警告</title>
      <link>https://ledge.ai/articles/ai_right_to_be_remembered_digital_memory_risk</link>
      <description><![CDATA[<p>生成AIが人類の“記憶係”として機能し始める中で、情報の偏りや「記憶からの抹消」という新たなリスクが指摘されている。</p>
<p>米ルイビル大学などの研究者チーム（著者：Roman V. Yampolskiy／Alex Zhavoronkov／Dominika Wilczok）は2025年10月17日、論文「The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI」を arXiv で<a href="https://arxiv.org/abs/2510.16206">公開</a>した。大規模言語モデル（LLM）が情報取得の主要なインターフェースとなる現状に対し、著者らは「記憶される権利（Right to Be Remembered, RTBR）」を提唱している。</p>
<h2>単一回答がもたらす“記憶の収束”</h2>
<p>従来の検索エンジンは複数の情報源を一覧で提示し、利用者が比較・判断できる余地を残していた。一方、LLMは統合的な「ひとつの答え」を返す傾向があり、異なる視点を意識的に検討する機会を失わせやすい。この構造が進むと、少数のAIベンダーが「何が記憶され、何が忘れられるか」を実質的に決定することになり、デジタル社会における“記憶の偏り”が固定化する恐れがあると警告している。</p>
<h2>「記憶される権利（RTBR）」とは</h2>
<p>著者らは、AIが生成する情報の公正性と真実性を守る新たな倫理的枠組みとしてRTBRを提案した。RTBRは「AIによる情報の省略を最小化し、公正で、生成内容が可能な限り真実であることを設計原則として担保する」責務を意味する。その実現には、モデル開発・学習・出力・UI設計の各段階で、偏りを可視化し、引用や来歴を明示する仕組みが欠かせないとする。</p>
<h2>技術的・制度的課題にも言及</h2>
<p>論文は、AIの“真実性”を外部事実との整合性（accuracy）と、内部表現の整合性（honesty）の2層に分けて評価する重要性を指摘。その上で、以下のような具体策を挙げている。</p>
<ul>
<li>データ選定と来歴メタデータ（C2PAなど）の付与</li>
<li>RLHFや安全調整における多視点の保持</li>
<li>単一回答UIに代替視点・出典リンクを併設</li>
<li>不確実性の自己申告（知らないときは答えない／曖昧さの表示）</li>
</ul>
<p>また、C2PAなどのメタデータ標準を参照し、生成物に情報源を階層的に紐づける設計を推奨している。法制度面では、欧州の「忘れられる権利」（GDPR第17条）との緊張関係も論じられている。RTBR（公共の記憶の保存）と「忘れられる権利」（個人の消去請求）はしばしば対立し、LLMが知識を内部パラメータに埋め込む構造上、完全なアンラーニング（忘却）は難しいと指摘する。</p>
<h2>公共の「記憶」をどう設計するか</h2>
<p>研究者らは結論として、AIが知識の窓口となる時代において、モデルの設計や運用が人類の集合的記憶の形を左右する可能性を強調した。RTBRは、AIがもたらす効率性の裏側で、忘却や偏りから人間の歴史と多様な声を守るための新しい規範として位置づけられる。
論文は「AIが“人類の記憶係”になる時代にこそ、何を残し、何を忘れないかを社会全体で考える必要がある」と結ばれている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/11/2 [SUN]アリババ、初のスマートグラス「Quark AI Glasses」予約開始──価格4,699元、12月出荷見込み</title>
      <link>https://ledge.ai/articles/alibaba_quark_ai_glasses_presale_announcement_20251023</link>
      <description><![CDATA[<p>中国のアリババは2025年10月23日、自社開発による初のスマートグラス「Quark AI Glasses（夸克AI眼镜）」のオンライン予約販売を24日から開始すると、公式X（旧Twitter）アカウントで<a href="https://x.com/AlibabaGroup/status/1981200400817803428">発表</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/alibaba_Quark_AI_Glasses_14546ecef6/alibaba_Quark_AI_Glasses_14546ecef6.jpg" alt="alibaba Quark AI Glasses.jpg" /></p>
<p>同製品は、アリババの大規模言語モデル「Qwen（通称：通義千問）」と、同社のマルチモーダルAIを組み合わせたスマートアイウェア。Quark AI Glassesを通じて、音声アシスタントやリアルタイム翻訳、情報検索、撮影補助などの機能を自然な会話で操作できる。</p>
<p>アリババは7月の「世界人工知能会議（WAIC 2025）」にあわせて、AIグラスを含む次世代製品群を<a href="https://www.alibabacloud.com/en/press-room/alibaba-unveils-intelligent-cockpits-enterprise?_p_lc=1">初披露</a>しており、今回の予約販売開始が正式な市場投入の第一歩となる。報道各社（ロイター、Barron’sなど）によれば、Quark AI Glassesは中国の通販サイト「Tmall（天猫）」を通じて販売され、価格は4,699元（約660ドル）、出荷は12月を予定している。</p>
<p>Quarkは、アリババが展開するAIアシスタントアプリで、テキスト・音声の両モードで自然な対話と検索を統合する設計が特徴。10月23日の同社投稿でも「Quark AI Chat Assistant」として刷新が告知されており、アリババはスマートフォンを超えた“AIネイティブなエコシステム”の構築を進めている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G36e_Xm_X_Xw_A_Eve_He_5fb5b50486/G36e_Xm_X_Xw_A_Eve_He_5fb5b50486.jpg" alt="G36eXmXXwAEveHe.jpg" /></p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、生成AI「Claude」をExcelに統合──分析・説明・編集を自動化する新アドインを発表</title>
      <link>https://ledge.ai/articles/claude_for_excel_beta_release</link>
      <description><![CDATA[<p>Anthropicは2025年10月28日（米国時間）、生成AI「Claude」をMicrosoft Excelに統合した新アドイン「Claude for Excel」をベータ版（Research Preview）として<a href="https://www.anthropic.com/news/advancing-claude-for-financial-servicesl">公開</a>した。
Claudeがスプレッドシート内のデータや数式を理解し、自然言語による分析・説明・編集を行えるようにする。</p>
<p>「<a href="https://www.claude.com/claude-for-excel">Claude for Excel</a>」はExcelのサイドバー上で動作し、ユーザーが自然言語で入力した指示に応じて、ワークシート全体を参照しながら回答する。数式の意味や依存関係を自動的に解析し、関連セルをハイライト表示することで、データの構造を可視化できる。例えば「この列の傾向を要約して」「この数式が何を計算しているか説明して」といった指示に対して、Claudeが表形式で結果を提示する。</p>
<p>@<a href="https://www.youtube.com/watch?v=NcBnxbEC0Ng">YouTube</a></p>
<p><strong>Excelのワークシートを解析し、セルレベルの参照付きで説明するClaudeの画面例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/How_teams_use_Claude_for_Excel_fa57735bf8/How_teams_use_Claude_for_Excel_fa57735bf8.jpg" alt="How teams use Claude for Excel.jpg" /></p>
<p>Anthropicによると、この機能は「財務分析やデータレポート作成など、業務での活用を想定した設計」であり、企業利用者を中心に展開されている。現在は「Claude for Max」「Claude for Team」「Claude for Enterprise」プランのユーザーを対象に、ウェイトリスト方式による限定ベータ（リサーチプレビュー）として提供中だ。</p>
<p>同社は公式ブログで、金融サービス分野をはじめとするビジネス用途において、Claudeの統合を進めていく方針を示している。今後、Excel以外の業務アプリケーションやリアルタイムデータとの連携も視野に入れ、企業の分析・意思決定プロセスをAIで支援するエコシステムの構築を目指すという。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIリテラシー教材を公開──教育者・学生・家庭向けに専用リソースを提供</title>
      <link>https://ledge.ai/articles/google_ai_literacy_resources_launch</link>
      <description><![CDATA[<p>Googleは2025年9月9日（米国時間）、教育者・学習者・保護者が生成AIを安全かつ責任を持って活用できるよう設計した教材とトレーニングを集約する新サイト「Build AI knowledge and literacy」を<a href="https://blog.google/outreach-initiatives/education/google-ai-literacy-tools-2025/">公開</a>した。初等中等・高等教育・大学・家庭の各領域に向けて、レッスンプランや教師研修、プロンプト基礎コース、DeepMindとRaspberry Pi Foundationの共同教材「Experience AI」、ゲーム型学習「AI Quests」などを提供し、現場でのAIリテラシー育成を体系化する。</p>
<p>サイトは「安全性」「透明性」「責任ある利用」を軸に、対象別の教材を体系的に整理している。</p>
<h2>教師向け（K-12・教育リーダー）</h2>
<p>教師向けセクションには、GeminiやNotebookLMを授業で活用するための研修プログラム「Generative AI for Educators with Gemini」が用意され、教材設計から実践までを一気通貫で支援する。教育リーダーに向けた「Guide to AI in Education」では、導入ポリシーづくりや評価設計までを網羅し、K-12の現場に適したスターター教材「Get Started with AI for K-12」も揃う。授業内で生成AIを扱う際の留意点や評価観点が整理され、即日活用できる実務志向の内容が特徴だ。</p>
<h2>大学生・教授向け（高等教育）</h2>
<p>高等教育向けには、学業・研究・就職準備に結びつくスキル獲得を支援するトレーニングとツール群がまとめられている。効果的なプロンプト設計を基礎から学べるコースが提供され、レポート作成やリサーチ支援、専門領域でのAI活用を見据えた内容となっている。大学の授業や研究活動に自然に組み込める導線が設計されている点も実務的だ。</p>
<h2>高校生向け（リテラシーと実践）</h2>
<p>高校生向けには、責任あるAI利用を扱うレッスンプランに加え、Google DeepMindとRaspberry Pi Foundationが共同開発した「Experience AI」が紹介される。さらに、ゲーム形式で課題解決を学ぶ「AI Quests」により、概念理解にとどまらず、模擬的な意思決定や問題解決を通じてAIの可能性と限界を体験的に学べる構成となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Quests_Landing_Page_1_width_1000_format_webp_0110123f2a/AI_Quests_Landing_Page_1_width_1000_format_webp_0110123f2a.webp" alt="AI_Quests_-_Landing_Page_1.width-1000.format-webp.webp" /></p>
<h2>家庭・保護者向け（安全とリテラシー）</h2>
<p>家庭向けセクションでは、小学生でも取り組みやすいインターネットとAIの安全教育プログラム「Be Internet Awesome」が公開される。保護者向けには動画ガイド「The AI Playbook for Parents」や、専門家がAI時代の子育てを解説するポッドキャスト「Raising kids in the age of AI」が用意され、家庭内のルールづくりや学びの伴走に役立つ実践的なヒントが得られる。</p>
<p>@<a href="https://www.youtube.com/watch?v=DhpzaLYSUro&amp;list=PLP7Bvyb3ap45NyPGzOxhqn1L8XLgRjtrp&amp;index=3">YouTube</a></p>
<p>このサイトは、学校や大学、家庭の現場でそのまま使える実装志向のリソースを提供することで、AIの利便性とリスクの双方を踏まえたリテラシーの底上げを狙う。公開の背景と位置づけはGoogle公式ブログで明示され、教材群は専用サイトで継続更新される見込みだ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、広告画像を自動生成する新ツール「Pomelli」を発表──ブランドの“DNA”をAIが理解し、一貫したキャンペーンを提案</title>
      <link>https://ledge.ai/articles/google_pomelli_ai_ad_generation_tool</link>
      <description><![CDATA[<p>Googleは2025年10月28日（米国時間）、広告やSNSキャンペーン向けの画像を自動生成できる新ツール「Pomelli（ポメリ）」を<a href="https://blog.google/technology/google-labs/pomelli/">発表</a>した。Google Labsの実験プロジェクトとして公開されており、ユーザーが自社サイトのURLを入力すると、ブランド特性を分析して“Business DNA”を構築し、それに基づいて画像やコピーなどのアセットを提案する。</p>
<p>@<a href="https://www.youtube.com/watch?v=rsWPISYv6tQ">YouTube</a></p>
<h2>ブランドの「DNA」をAIが理解して広告素材を生成</h2>
<p>Pomelliは、企業サイトに含まれる色・言葉・トーンなどをAIが解析し、ブランドの「Business DNA」としてまとめる。この情報をもとに、SNS投稿用の画像、広告用コピー、キャンペーン案などを生成する仕組みだ。DeepMindとの協力のもと開発されたとされ、Googleは「ブランドの一貫性を保ちながら、より迅速にマーケティング素材を作成できる」としている。</p>
<p><strong>Pomelliは企業サイトを解析し、ブランドカラー・フォント・イメージを自動抽出して「Business DNA」を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39/Pomelli_Keyword_Blog_In_line_1_width_1000_format_webp_e223dd6d39.webp" alt="Pomelli_Keyword_Blog_In-line_-_1.width-1000.format-webp.webp" /></p>
<h2>中小企業でも“オンブランド”の広告を短時間で</h2>
<p>Pomelliの想定ユーザーは、中小規模の企業（SMB）や個人事業主だ。デザイナーやマーケターが限られた環境でも、ブランドトーンを保った高品質な素材を数分で生成できる。SNSごとのフォーマットや文体に応じた最適化にも対応しており、季節キャンペーンやセールなどの展開を容易にする。</p>
<p><strong>解析したBusiness DNAをもとに、AIが複数のキャンペーン案を提示する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069/Pomelli_Keyword_Blog_In_line_2_width_1000_format_webp_9469a56069.webp" alt="Pomelli_Keyword_Blog_In-line_-_2.width-1000.format-webp.webp" /></p>
<h2>生成された広告をその場で編集・修正可能</h2>
<p>生成された画像やコピーは、フォント・色・キャッチコピーなどをGUI上で細かく調整できる。Googleはこれを「人間の創造力を補助する共同作業ツール」と位置付けており、単なる自動生成ではなく、人の手による最終調整を想定している。</p>
<p><strong>生成された広告素材は、色やフォント、コピーをその場で編集できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f/Pomelli_Keyword_Blog_In_line_3_width_1000_format_webp_68aa5eaa7f.webp" alt="Pomelli_Keyword_Blog_In-line_-_3.width-1000.format-webp.webp" /></p>
<h2>提供形態と今後の展開</h2>
<p>PomelliはGoogle Labsの実験ツールとして提供されており、現在は限定公開の段階にある。公式サイトでは「Easily generate on-brand content for your business（自社ブランドに沿ったコンテンツを簡単に生成）」と説明されている。</p>
<p>現時点で提供対象は米国、カナダ、オーストラリア、ニュージーランドの英語版ユーザーに限られており、日本国内では未提供。Googleは今後の地域拡大について明らかにしていないが、利用可能国の追加が期待される。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、誰でも学べるAI学習サイト「Google Skills」を正式公開──Cloud・DeepMind・教育部門を横断する3000講座を展開</title>
      <link>https://ledge.ai/articles/google_skills_ai_learning_platform_launch</link>
      <description><![CDATA[<p>Googleは2025年10月21日（米国時間）、新しいAI学習プラットフォーム「Google Skills」を<a href="https://blog.google/outreach-initiatives/education/google-skills/">発表</a>した。同サイトでは、Google Cloud、Google DeepMind、Grow with Google、Google for Educationなど、同社の複数部門が提供してきた教育コンテンツを統合。3000種類を超えるAI関連の講座・体験ラボ・認定プログラムを、一元的に学べる学習拠点として開設された。</p>
<h2>AI教育の中核を担う新サイト</h2>
<p>Google公式ブログ「Start learning all things AI on the new Google Skills」によると、Google Skillsは“AI for Everyone（すべての人のためのAI）”をテーマに、誰もがAIスキルを体系的に学べるよう設計されている。初心者、エンジニア、企業リーダーなど幅広い層を対象に、AI、データ分析、クラウド、生成AIなど多様な分野を網羅。各コースはオンデマンド形式で受講でき、学習成果はLinkedInなどの外部プラットフォームで共有できる。提供内容には、Google Cloudの認定資格プログラムやAI Essentials シリーズ、DeepMindのAI倫理教材などが含まれる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Qbix0BOPcgE">YouTube</a></p>
<p>今回の正式公開に先立ち、Google Cloudは10月10日付のブログ「Google Skills: Your new home for Google AI learning and more」で、新プラットフォームの構想を公表していた。当時は正式リリース前で、「AIやクラウドに関する学習リソースを一元化し、近日中に詳細を発表する」としていた。Gemini Code Assist（旧Duet AI for Developers）やQwiklabs（現Cloud Labs）と連携し、AIトレーニングの実践環境を統合する方針も示されていた。</p>
<h2>3000超のコースと実践的ラボを集約</h2>
<p>Google Skillsでは、Googleがこれまで個別に展開してきた学習リソースを一か所に集約。AIモデル開発、クラウド基盤運用、データ可視化、サイバーセキュリティなど、実践重視の3000超のコースとラボを提供する。一部コンテンツは無料で公開され、修了証や認定資格を取得することでキャリア開発にもつなげられる。また、組織向けにはチーム単位での進捗管理や学習成果の可視化機能も用意されている。</p>
<h2>今後の展望──教育機関・企業研修にも拡大へ</h2>
<p>Googleは今後、教育機関や企業研修への展開を進める方針を示しており、AIスキルの標準教育基盤としての活用を目指す。
公式ブログでは、「AI教育へのアクセスを民主化し、誰もがテクノロジーの未来を形づくる機会を得られるようにする」としている。
同社は今後もDeepMindやCloud AIチームの最新教材を追加し、AI人材育成をグローバルに推進する考えだ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>万博「null²」館で使用の3Dアバター技術、筑波大が一般公開──スマホスキャン後約5分で完成</title>
      <link>https://ledge.ai/articles/instant_skinned_gaussian_avatars_tsukuba_null2</link>
      <description><![CDATA[<p>筑波大学・落合陽一准教授が率いるデジタルネイチャー研究室（Digital Nature Group）は、スマートフォンで撮影した3Dスキャンデータから約5分で写実的な3Dアバターを生成できる技術「Instant Skinned Gaussian Avatars」を<a href="https://gaussian-vrm.github.io/">発表</a>した。</p>
<p>研究成果は論文「Instant Skinned Gaussian Avatars for Web, Mobile and VR Applications」として公開され、2025年11月にカナダ・モントリオールで開催される ACM Symposium on Spatial User Interaction (SUI ’25) で<a href="https://dl.acm.org/doi/10.1145/3694907.3765954">発表予定</a>となっている。
この技術は、大阪・関西万博の落合館「null²（ヌルヌル）」で展示された3Dアバター生成システムに採用されており、研究チームは10月22日、<a href="https://naruya.github.io/gaussian-vrm/">デモサイト</a>と<a href="https://github.com/naruya/gaussian-vrm">ソースコード</a>を一般公開した。</p>
<h2>スマホだけで完結するアバター生成プロセス</h2>
<p>研究は、筑波大学大学院図書館情報メディア研究科の近藤生也氏、浅野悠人氏、落合陽一氏によって実施された。
ユーザーはスマートフォンアプリ「Scaniverse」でAポーズの全身スキャンを行い、3Dデータ（PLY形式）を取得する。そのデータをブラウザ上のアプリケーションにアップロードすると、自動的に処理が実行され、約30秒でアバター生成が完了する。全体の所要時間は約5分と報告されている。生成されたアバターはWebブラウザ上で動作し、スマートフォンでも確認できる。</p>
<p>@<a href="https://www.youtube.com/watch?v=tinmbjfghLw">YouTube</a></p>
<h2>Gaussian Splattingとスキンメッシュの融合</h2>
<p>提案手法は、3D表現技術「Gaussian Splatting」をベースに、スキンメッシュ構造と統合することで、写実的な質感とアニメーションの軽量性を両立している。
各スプラット（点群）は背景メッシュのボーン構造にバインドされ、動作中はリアルタイムで位置と姿勢を並列更新する仕組みを採用。モバイル環境での処理負荷を抑えるため、ボーン単位でスプラットをグループ化し、視点依存のソーティング処理を最適化している。</p>
<p>@<a href="https://www.youtube.com/watch?v=i2GvFIMYqP0">YouTube</a></p>
<h2>Webベース設計によるクロスプラットフォーム対応</h2>
<p>システムは、JavaScriptおよびThree.jsで構築されており、特別なアプリケーションを必要とせずWebブラウザ上で動作する。
ユーザーはスマートフォン、PC、VRヘッドセットなど、プラットフォームを問わず利用できる。
これにより、生成・表示環境が限定されず、学習や展示、遠隔通信など多様な応用が可能となる。</p>
<h2>実行性能と公開リソース</h2>
<p>実験では、iPhone 13 Proで40〜50 fps、NVIDIA GeForce RTX 3060搭載ノートPCで最大240 fpsの動作を確認した。
デモは <a href="https://naruya.github.io/gaussian-vrm/">https://gaussian-vrm.github.io</a>、ソースコードは<a href="https://github.com/naruya/gaussian-vrm">https://github.com/naruya/gaussian-vrm</a> で公開されている。</p>
<h2>今後の展開</h2>
<p>論文では、VRMなど既存アバター規格との互換性を考慮した設計であることが示されている。
研究チームは、顔表情や衣服変形などへの拡張を今後の課題として挙げている。研究成果は、誰もが汎用デバイスを用いて高品質な3Dアバターを生成できる手法として、Web、モバイル、VRアプリケーションなど複数領域への応用が見込まれている。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>講談社・KADOKAWAなど19団体、「オプトアウト原則は侵害につながる」と共同声明──生成AI時代の創作と権利のあり方を提示</title>
      <link>https://ledge.ai/articles/joint_statement_ai_creative_rights_20251031</link>
      <description><![CDATA[<p>2025年10月31日、講談社やKADOKAWAをはじめとする出版社17社と、日本漫画家協会、日本動画協会の計19団体は、「生成AI時代の創作と権利のあり方に関する共同声明」を<a href="https://nihonmangakakyokai.or.jp/archives/news/20251031">発表</a>した。</p>
<p>声明は、OpenAIの映像生成AI「Sora2」によって既存作品への依拠や類似が疑われる事例が確認されたことを背景に、著作権法の原則に基づく3つの原則を提示。「オプトアウト原則は権利侵害につながる」と明記し、AI事業者に対して法的原則の順守を求めた。</p>
<h2>「Sora2」公開が引き金に</h2>
<p>声明では、2025年10月にOpenAIが映像生成AI「Sora2」をローンチし、その生成物がSNSなどで共有された際、既存の著名なアニメや漫画の表現に類似する事例が散見されたと指摘している。
同AIが「権利者から明示的なオプトアウト申請がない限り生成・公開が可能な仕組み」を採用している点について、「我が国の著作権法およびWIPO著作権条約の原則に反する」と明記した。</p>
<p>OpenAIの経営者個人がSNS上で「オプトイン方式への転換」を示唆したものの、企業としての正式方針ではないとし、「第二、第三のSora2」とも言うべき新たな生成AIの登場を見据え、業界として立場を明確にする必要があると判断したという。</p>
<h2>「創作の喜び」と「権利保護」の両立を掲げる</h2>
<p>声明は「生成AI技術の進展を歓迎する」としつつ、「著作権侵害を容認しない」という原則を改めて確認。
文化的創造の持続可能性と技術革新の恩恵を両立させるため、AI事業者に対して次の3つの原則を示した。</p>
<ul>
<li>学習段階および生成・公表段階の両方において、権利者に必要な許諾を得るなど著作権法の原則に沿った対応を取ること</li>
<li>学習データの透明性を担保すること</li>
<li>権利者が利用を許諾した場合、適正な対価還元を行うこと</li>
</ul>
<p>さらに、生成AIの利用者が他者の著作物をもとにしたことを知らずに作品を公開し、結果として他のクリエイターの権利を損なう状況を防ぐため、権利者・AI事業者・関係省庁の連携を呼びかけている。</p>
<h2>「オプトアウト原則は侵害につながる」</h2>
<p>声明の中で特に強調されたのが、「オプトアウト原則」への懸念だ。
AI事業者が権利者に無断で著作物を学習・再利用することは、「著作権法の『権利者の許諾を得てから利用する』という原則に反する行為」であり、権利侵害に直結すると明記。その上で「AI事業者が権利者に対してオプトインを申請し、使用許諾を得ることの徹底」を求めている。</p>
<p>また、学習データの出典が不明確なままでは、権利侵害の検証や作品評価の毀損対応が困難になるとして、データ透明性の担保を「不可欠」と位置づけた。</p>
<h2>「技術を拒絶するものではない」</h2>
<p>声明は、生成AIを排除するものではないと明言する。
「創作に携わるすべての人の努力と尊厳を守るための責任」と位置づけ、法的・倫理的観点から著作権侵害に適切に対応する姿勢を表明した。同時に、「クリエイターとユーザーの双方が安心して創作・利用できる環境を整えることを重視する」と記した。</p>
<h2>今後の方向性──「利用と保護の両立」を模索</h2>
<p>声明は締めくくりとして、「AI時代における公正で透明、かつ持続可能な創作環境の構築・維持に努める」と明示。
業界内外のステークホルダーとの協調を通じて、創作物の「利用と保護」の両立を目指す姿勢を示した。</p>
<h3>発出団体（五十音順）</h3>
<p>一般社団法人 日本動画協会／公益社団法人 日本漫画家協会／株式会社秋田書店／株式会社一迅社／株式会社宙出版／株式会社KADOKAWA／株式会社コアミックス／株式会社講談社／株式会社小学館／株式会社少年画報社／株式会社新潮社／株式会社スクウェア・エニックス／株式会社竹書房／株式会社TOブックス／株式会社日本文芸社／株式会社白泉社／株式会社双葉社／株式会社芳文社／株式会社リイド社</p>
]]></description>
      <pubDate>Wed, 05 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとAWS、7年・380億ドルの戦略的提携を発表──数十万GPUとUltraServersでAI基盤を拡充</title>
      <link>https://ledge.ai/articles/openai_aws_multi_year_partnership_2025</link>
      <description><![CDATA[<p>2025年11月3日（現地時間）、OpenAIとAmazon傘下のAmazon Web Services（AWS）は、複数年にわたる戦略的パートナーシップを締結したと<a href="https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure">発表</a>した。</p>
<p>OpenAIは発表当日からAWS上で主要AIワークロードの稼働を開始しており、契約総額は今後7年間で380億ドル（約5.8兆円）にのぼる。数十万規模のNVIDIAチップを備えたUltraServersを活用し、AIトレーニングと推論の両面で大規模な計算基盤を構築する。</p>
<h2>OpenAIのAIワークロードをAWSで稼働</h2>
<p>今回の提携により、OpenAIはAWSのインフラを活用してChatGPTをはじめとする主要サービスや次世代モデルのトレーニングを実行する。AWSは「immediate availability（即時利用可能）」を強調し、提携発表と同時にOpenAIのワークロードを稼働させたと説明している。</p>
<p>契約期間は7年間で、OpenAIはAWS上に総額380億ドル規模のコンピューティング・キャパシティを確保。2026年末までに全リソースを配備することを目標とし、状況に応じて2027年以降の拡張も検討されている。</p>
<h2>GB200/GB300世代GPUとUltraServersを採用</h2>
<p>AWSは、最新のNVIDIA GB200およびGB300世代チップを搭載した「Amazon EC2 UltraServers」を提供。これにより、OpenAIは数十万規模のNVIDIAチップと数千万CPUを同一ネットワーク上で動作させ、AI学習や推論を高効率に処理できる。</p>
<p><strong>AWSのデータセンター外観。今後数十万規模のGPUクラスタを展開予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_71f1f7cec4/2_71f1f7cec4.jpg" alt="ダウンロード (2).jpg" /></p>
<p>クラスタは低レイテンシの相互接続を備え、複数データセンターを単一の高性能ファブリックとして動作させる設計。AWSはこれを「最適化された大規模AIワークロード環境」と位置づけている。</p>
<p><strong>AWSインフラ内部。UltraServers間を接続するネットワークケーブル群</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_17c982221d/7_17c982221d.jpg" alt="ダウンロード (7).jpg" /></p>
<p>OpenAI CEOのサム・アルトマン氏は「フロンティアAIを安全にスケーリングするためには、massive, reliable computeが不可欠だ」と述べ、今回の提携が「advanced AI to everyone（すべての人に先進的AIを届ける）」基盤となると語った。AWS CEOのマット・ガーマン氏は「OpenAIの膨大なワークロードを支えるbest-in-class infrastructureを提供できることを誇りに思う」とコメントしている。</p>
<h2>今後の展開</h2>
<p>リリースでは、Amazon Bedrock上でOpenAIのオープンウェイト基盤モデルが利用可能になったことにも言及。すでにBystreet、Comscore、Peloton、Thomson Reuters、Triomics、Verana Healthなど数千社が導入を開始しているという。</p>
<p>AWSは、2026年末までに全キャパシティの配備を完了させる計画を示している。今回の契約により、OpenAIはAWS上でAIモデルのトレーニングおよび推論を長期的に実施できる環境を確保した。両社は今後もAIインフラの拡張と最適化を進め、安定した計算リソースの提供を継続する方針だ。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GitHub、「Agent HQ」を発表──“あらゆるエージェントを、いつでもどこでも”統合管理</title>
      <link>https://ledge.ai/articles/github_agent_hq_announcement_universe2025</link>
      <description><![CDATA[<p>GitHubは2025年10月28日（米国時間）、年次イベント「GitHub Universe 2025」で新ビジョン「Agent HQ」を<a href="https://github.blog/news-insights/company-news/welcome-home-agents/">発表</a>した。これは、複数のAIコーディングエージェントを単一の環境で呼び出し、管理・連携できる統合プラットフォームである。</p>
<p>公式ブログによると、Agent HQは“あらゆるエージェントを、あらゆる開発スタイルで使える”ことを目指した新構想で、Anthropic、OpenAI、Google、Cognition、xAIなど各社のエージェントを有料のGitHub Copilotサブスクリプションの一部として提供するという。提供開始は今後数カ月を予定。</p>
<p>@<a href="https://www.youtube.com/watch?v=KniyIrpTDE8&amp;t=5s">Youtube</a></p>
<h2>複数エージェントを一元管理する「Mission Control」</h2>
<p>Agent HQの中核機能として「Mission Control」が導入される。開発者が複数のエージェントをタスクごとに割り当て、進行状況を可視化できる中枢機能で、GitHub、Visual Studio Code、CLIなど複数の開発環境で同一の体験を提供する。</p>
<p>また、組織の管理者は各エージェントのアクセス権限や利用ポリシーを制御できる「コントロールプレーン」を通じて、企業やチーム単位でのガバナンスを強化できる仕組みも備える。</p>
<h2>サードパーティ連携を前提とした“開かれたHQ”</h2>
<p>Agent HQは、特定モデルに依存しない「オープンなエージェント基盤」として設計されている。
GitHubは「開発者は自分の選んだAIエージェントを同じワークフローで活用できる」と述べ、今後数か月で各社のエージェントを順次統合していく予定だ。</p>
<p>この発表は、GitHubが掲げる“開発者が中心にいる未来”という長期ビジョンの延長線上にあり、同社はCopilotを単なる補助ツールから、複数AIが協働する「開発の司令塔」へと進化させようとしている。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT西日本とアイリスオーヤマが業務提携──清掃ロボット「JILBY」にugo技術を採用、AIプラットフォームで現場DXを加速</title>
      <link>https://ledge.ai/articles/iris_nttwest_jilby_ugo_platform</link>
      <description><![CDATA[<p>NTT西日本とアイリスオーヤマは2025年10月29日、サービスロボット分野における業務提携を<a href="https://www.ntt-west.co.jp/news/2510/251029a.html#a2">発表</a>した。</p>
<p>両社は「フィジカルAIやロボットを含むIoT領域におけるDX推進に関する基本合意書」を締結し、第一弾の取り組みとして、アイリスオーヤマのDX清掃ロボット「JILBY（ジルビー）」に、NTT西日本グループの「AIロボティクスプラットフォーム」を採用する。</p>
<p>この「AIロボティクスプラットフォーム」は、ugo株式会社がNTTビジネスソリューションズ株式会社にOEM提供している「ugo Platform」をベースに構築されたもので、ロボットの遠隔管理やAIエージェントによる最適化機能を備える。ユーザーはタブレットやスマートフォンを通じてロボットと双方向にコミュニケーションを行い、AIが蓄積された清掃データをもとに最適なルートや頻度を自律的に提案する。</p>
<p>NTTビジネスソリューションズとugoは、2025年10月27日に協業事業化に向けたプラットフォームのOEM契約を締結しており、今回の「JILBY」採用はその成果の第一弾となる。</p>
<p><strong>アイリスオーヤマとNTT西日本の共同発表会の様子。DX清掃ロボット「JILBY」と、ugoがNTTビジネスソリューションズにOEM提供する「ugo Platform」を基盤としたAIロボティクスプラットフォームの連携が紹介された。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_1024x576_e853d4b376/image2_1024x576_e853d4b376.png" alt="image2-1024x576.png" /></p>
<h2>労働力不足の解消へ──「フィジカルAI」がもたらす運用最適化</h2>
<p>清掃業界では人手不足が深刻化しており、ビルや商業施設の維持管理では省人化と品質維持の両立が求められている。
アイリスオーヤマは、現場課題を出発点とするDXモデルを強化しており、NTT西日本は通信・クラウド基盤を活用した地域産業のデジタル支援を推進。両社は、清掃ロボットを起点に、警備・物流・介護など他領域への展開も視野に入れる。</p>
<h2>三層で支える「ロボット×通信×プラットフォーム」構造</h2>
<ul>
<li>アイリスオーヤマ：DX清掃ロボット「JILBY」の開発・提供。現場DXソリューションを拡大。</li>
<li>NTT西日本／NTTビジネスソリューションズ：通信・クラウドを基盤に「AIロボティクスプラットフォーム」を運用・提供。</li>
<li>ugo（ユーゴー）：同プラットフォームのOEM提供元として、AIエージェント・ノーコード自動化・統合管理機能などの中核技術を供給。</li>
</ul>
<p>この構成により、ロボット運用の効率化だけでなく、現場データを知能化する「フィジカルAI」基盤の確立が期待される。</p>
<h2>今後の展望</h2>
<p>アイリスオーヤマは「JILBY」を2026年半ばに市場投入予定。NTT西日本は地方自治体や企業向けのDX支援プログラムにロボティクスを組み込み、ugoは複数メーカーのロボットを横断的に管理できる統合プラットフォーム化を進めるとしている。</p>
]]></description>
      <pubDate>Tue, 04 Nov 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米国エネルギー省とNVIDIA、10万GPUを搭載した史上最大級のAIスーパーコンピューターを構築──Oracleがクラウド基盤で協力し、科学インフラを刷新</title>
      <link>https://ledge.ai/articles/doe_nvidia_100k_gpu_ai_supercomputer</link>
      <description><![CDATA[<p>米国エネルギー省（DOE）は2025年10月30日（現地時間）、NVIDIAおよびOracleと協力し、DOE史上最大規模となるAIスーパーコンピューターの構築計画を<a href="https://www.energy.gov/articles/energy-department-announces-new-partnership-nvidia-and-oracle-build-largest-doe-ai">発表</a>した。</p>
<p>この新システムはイリノイ州のアルゴンヌ国立研究所（Argonne National Laboratory）に設置され、10万基以上のNVIDIA Blackwell GPUを搭載する。AIを活用した科学研究基盤として、科学的発見の加速と国家的課題の解決を狙う取り組みだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nvidia_1380_b28508426b/nvidia_1380_b28508426b.jpg" alt="nvidia-1380.jpg" /></p>
<h2>10万GPUの「Solstice」と「Equinox」</h2>
<p>DOEおよびアルゴンヌ研究所の<a href="https://www.anl.gov/article/argonne-expands-nations-ai-infrastructure-with-powerful-new-supercomputers">発表</a>によると、構築されるシステムは2系統で構成される。</p>
<p>メインとなる「Solstice」は10万基を超えるNVIDIA Blackwell GPUを搭載し、DOEのAI研究インフラとしては史上最大級の性能を備える。また、「Equinox」は約1万基のBlackwell GPUで構成され、より軽量なAIモデルのトレーニングや実験的研究に利用されるという。</p>
<p>両システムは相互に連携し、<a href="https://nvidianews.nvidia.com/news/nvidia-oracle-us-department-of-energy-ai-supercomputer-scientific-discovery">NVIDIAの試算</a>によれば最大で約2,200 エクサフロップスのAI性能を発揮する見込み。これらは米国政府が推進する「次世代科学計算インフラ拡張計画」の中核を担う。</p>
<p>計画では、Oracleがクラウドインフラ（Oracle Cloud Infrastructure、OCI）を提供。NVIDIAのハードウェア群をOCI上で統合運用し、Megatron-CoreやTensorRTなどのスタックを活用して、大規模学習と推論を並行実行できる設計とする。</p>
<h2>科学研究を支える国家AIインフラ</h2>
<p>DOEはこの取り組みを、「気候変動分析」「新素材探索」「エネルギー効率化」「AIによる科学的発見支援」など、多様な分野に応用する方針を示している。アルゴンヌ研究所の准研究所長でArgonne Distinguished FellowのRick Stevens氏は、強力なAI能力――特に推論機能――の重要性を挙げ、仮説検証や実験設計、複雑データからの洞察を効率化できると述べた。</p>
<p>両システムは2026年の稼働開始を予定しており、DOEはこれらを含むAIスーパーコンピューター群を全米の研究所に配備し、国家レベルでのAI研究ネットワークを拡充する。なお、DOEは同年、3研究所で計9台の新スーパーコンピューターを整備する計画も発表している</p>
]]></description>
      <pubDate>Mon, 03 Nov 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/11/3 [MON]対話型AIによる「心の支援」を可視化　ハーバード大・オックスフォード大らが新評価プラットフォームを開発</title>
      <link>https://ledge.ai/articles/mindbenchai_mental_health_llm_evaluation</link>
      <description><![CDATA[<p>対話型AIをメンタルヘルスの相談に利用する人が増えている。調査によると、ユーザーの3割以上がAIに心の悩みを打ち明けた経験を持つという。こうした状況のなか、AIによる誤った助言や過度な依存、AIとの擬似的な関係による心理的影響が報告されている。</p>
<p>この課題に対応するため、ハーバード大学、オックスフォード大学、マサチューセッツ総合病院など24機関の研究者が、AIのメンタルヘルス対応能力を体系的に評価するプラットフォーム「MindBenchAI（マインドベンチAI）」を開発し、研究成果は2025年9月にarXivで<a href="https://arxiv.org/abs/2510.13812">公開</a>した。</p>
<h2>AIが“セラピスト化”する時代のリスク</h2>
<p>ChatGPTやClaude、Geminiなどの大規模言語モデル（LLM）は、ストレス相談や心理的支援に使われるケースが増えている。
しかし、臨床的な有効性を示すデータは乏しく、誤診や誤誘導、自殺念慮への対応ミスなど、現実的なリスクも指摘されている。MIT Technology Reviewによれば、2025年には実際にAIチャットボットとのやり取りが悲劇につながった事例も報告されている。</p>
<p>論文の筆頭著者であり、ハーバード大学医学部付属ベスイスラエル・ディーコネス医療センター（Beth Israel Deaconess Medical Center）精神医学部門のジョン・トーラス氏は、「AIの利用が拡大する一方で、臨床的な安全基準や性能評価が存在しないまま“心の領域”がAIに委ねられつつある」と警鐘を鳴らしている。</p>
<h2>MindBenchAIの概要</h2>
<p>研究チームは、10年以上にわたりメンタルヘルスアプリを評価してきた「MINDapps.org」の仕組みを拡張し、AIモデルを対象にした評価体系を構築した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/MIND_bench_AI_bd6e712ea8/MIND_bench_AI_bd6e712ea8.jpg" alt="MIND bench AI.jpg" /></p>
<p>MindBenchAIは、AIの特性を「プロフィール評価」と「性能評価」の2側面から分析する。</p>
<h3>1. プロフィール評価（Profile Evaluation）</h3>
<p>モデルの技術的安全性（データ保護、透明性、開発体制など）と、会話特性（共感性、対話スタイル、応答傾向など）を整理する。
心理学の「ビッグファイブ」や「MBTI」などを応用し、AIの会話傾向を定量的に記録する。</p>
<h3>2. 性能評価（Performance Evaluation）</h3>
<p>自殺対応、臨床判断、薬物療法などのシナリオを用いてAIの応答を専門家が採点する。正答率に加え、AIがどのように結論に至ったかという推論過程（Reasoning）も評価対象とする。</p>
<p>評価には「Suicide Intervention Response Inventory 2（SIRI-2）」などの臨床評価指標が活用されている。</p>
<h2>システム構成と運用</h2>
<p>MindBenchAIは、技術情報と会話傾向、ベンチマーク結果、推論解析を統合したダッシュボード形式で運用される。</p>
<p>主要なLLM（GPT-5、Claude Opus 4、Gemini 2.5 Proなど）や、それらを基盤としたチャットボットも評価対象となる。
結果はリーダーボード形式で整理され、各モデルの得点を分野別に比較できる。</p>
<p>推論分析では、AIに思考過程を逐次説明させる「Chain-of-Thought」形式を採用し、誤りや偏りの傾向を特定する。</p>
<h2>共同体制と今後の展望</h2>
<p>MindBenchAIは、米国のメンタルヘルス支援団体「NAMI（National Alliance on Mental Illness）」と連携して構築された。
患者、家族、臨床医、開発者など、複数の立場の関係者が評価と検証に参加できる。システムは拡張可能な設計となっており、他の研究機関によるベンチマーク追加や多言語評価への対応が予定されている。</p>
<p>研究チームは、「AIの安全な利用を実現するため、臨床家や患者、開発者が共通の基準を持つことが必要」と述べている。</p>
]]></description>
      <pubDate>Mon, 03 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>上海交通大学、「AI生成サーベイ論文の氾濫は“DDoS攻撃”」──NeurIPS 2025採択論文が研究文化への影響と対策を提言</title>
      <link>https://ledge.ai/articles/ai_generated_survey_paper_ddos_shanghai_jiaotong</link>
      <description><![CDATA[<p>中国・上海交通大学の研究チームは2025年10月9日、生成AIによるサーベイ論文の急増が研究コミュニティを“DDoS攻撃”のように麻痺させていると警鐘を鳴らすポジションペーパー「Stop DDoS Attacking the Research Community with AI-Generated Survey Papers」を<a href="https://arxiv.org/abs/2510.09686v1">発表</a>した。</p>
<p>論文はNeurIPS 2025のPosition Trackに<a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/121939">採択</a>され、AI支援による論文作成の透明性確保や、動的に更新される「Dynamic Live Surveys」の構築を提案している。</p>
<h2>「サーベイ論文DDoS攻撃」とは</h2>
<p>研究チームは、ChatGPTなどの大規模言語モデル（LLM）の登場以降、サーベイ論文が指数関数的に増加していると分析。2020〜2024年の間に、コンピュータサイエンス分野のサーベイ論文数は約2倍に膨れ上がり、2022年以降に急激な“スパイク”が見られたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_8_353e8bf78b/x1_8_353e8bf78b.png" alt="x1 (8).png" /></p>
<p>AI検出ツールによる分析では、AI生成要素を含むサーベイ論文の割合が2022年以降急上昇。著者らはこの現象を「サーベイ論文によるDDoS攻撃」と呼び、量の爆発が研究者の注意と査読能力を圧迫し、真正な学術貢献が埋もれる危険性を指摘している。</p>
<h2>品質と信頼性の低下</h2>
<p>論文では、AI生成のサーベイ論文が「冗長」「誤引用」「分類構造の浅さ」などの特徴を持ち、人間が執筆した従来型のサーベイに比べ、学術的洞察に欠けると述べている。</p>
<p>また、複数のAI生成サーベイが同一テーマでほぼ同じ内容・表現を繰り返す“コピー＆ペースト構造”を形成していることを、引用リストの重複率や語彙多様性の低下などから実証した。</p>
<h2>研究文化への影響</h2>
<p>大量のAI生成論文がarXivなどのプレプリントサーバを埋め尽くすことで、研究者が信頼できるレビューを見つけにくくなり、若手研究者の学習や研究テーマ選定を誤らせるリスクもあると分析。論文ではこれを「literature poisoning（文献汚染）」と表現し、引用ネットワーク全体の歪みを招く可能性を警告した。</p>
<h2>提案する解決策</h2>
<p>研究チームは以下のような対策を提案している：</p>
<ul>
<li><strong>AI使用の開示義務化</strong> ：LLMを執筆補助に使った場合は脚注や本文で明記</li>
<li><strong>サーベイ論文専用の厳格な査読制度</strong> ：独自の評価基準を設け、深度と独創性を確認</li>
<li><strong>AI生成検出ツールの導入</strong> ：AI支援を隠した投稿を抑止</li>
<li><strong>高品質サーベイの表彰制度</strong> ：研究者が労力をかけたレビューを奨励</li>
<li><strong>研究倫理教育の強化</strong> ：AIによる文章生成を盗用に準じる行為として明確化</li>
</ul>
<p>さらに、従来の静的なサーベイ論文に代わり、人間とAIが協働して継続的に更新する「Dynamic Live Surveys」という新たな仕組みを提案。AIが新論文情報を自動収集し、専門家がその内容を精査・統合する「ライブ型学術リポジトリ」を構想している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_5_014e74304f/x2_5_014e74304f.png" alt="x2 (5).png" /></p>
<p>著者らは、「AIによるサーベイ生成を否定するのではなく、人間の洞察を補完する形で共存させるべき」と強調。「量より質」という原則を取り戻すことが、AI時代の学術出版の信頼回復につながるとしている</p>
]]></description>
      <pubDate>Sun, 02 Nov 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/31 [FRI]OpenAI、2028年に「完全自動AI研究者」実現を目指すロードマップを公開</title>
      <link>https://ledge.ai/articles/openai_future_roadmap_fully_automated_ai_researcher_2028</link>
      <description><![CDATA[<p>OpenAIは2025年10月30日（米国時間）、同社の構造改革と今後の展望をテーマにしたライブ配信「Sam, Jakub, and Wojciech on the future of OpenAI with audience Q&amp;A」を実施し、研究・製品・インフラの中長期計画を<a href="https://www.youtube.com/watch?v=ngDCxlZcecw">公表</a>した。
登壇は、CEOのサム・アルトマン氏（Sam Altman）、チーフサイエンティストのヤクブ・パホツキ氏（Jakub Pachocki）、共同創業者のウォイチェフ・ザレンバ氏（Wojciech Zaremba）の3名。</p>
<p>配信では、OpenAIが掲げる中長期の研究ロードマップが初めて詳細に共有され、2028年3月までに「完全自動AI研究者（fully automated AI researcher）」を実現するという社内目標が明らかにされた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/we_did_a_livestream_ce2df3ba24/we_did_a_livestream_ce2df3ba24.jpg" alt="we did a livestream.jpg" /></p>
<h2>研究ロードマップ：2026年に“AI研究インターン”、2028年に“完全自動研究者”へ</h2>
<p>パホツキ氏は、OpenAIの研究プログラムが「科学的発見の加速と新技術開発の促進」を目的に構築されていると説明し、次の二段階のマイルストーンを示した。</p>
<ul>
<li><strong>2026年9月まで</strong> ： 意味のある計算資源を活用し、研究者の生産性を大幅に高められる有能なAI研究インターン（AI research intern）を開発。</li>
<li><strong>2028年3月まで</strong> ： 大規模な研究プロジェクトを自律的に遂行できる完全自動AI研究者（fully automated AI researcher）を実現。</li>
</ul>
<p>パホツキ氏は「これらの日付は絶対ではない」と前置きしながらも、現時点での社内目標を共有。「科学の発見速度を劇的に高める可能性がある」と語った。</p>
<p>アルトマン氏は、「この取り組みこそがOpenAIの研究プログラムの核心（core thrust）だ」と述べ、GPT-4のリリース（2023年）から約5年後に当たる2028年を重要な節目と位置づけた。同氏はさらに、AIによる科学的発見の進展について「2026年には小さな発見が現れ、2028年には中規模あるいはそれ以上の発見が生まれるだろう」と言及した。</p>
<h2>スーパーインテリジェンスへの接近</h2>
<p>パホツキ氏は、OpenAIが「ディープラーニングを理解する研究所」であり、トレーニング規模を拡大することで何が起こるかを探ることが本質的だと説明した。そのうえで、ディープラーニングシステムが多くの領域で人間を超える“スーパーインテリジェンス”に到達するまで10年を切っている可能性があるとの見方を示した。</p>
<p>指標のひとつとして、モデルが人間と同等の成果を上げるまでに要する時間を挙げ、現在のモデルは国際情報オリンピックなどでトップ人類と肩を並べる水準に達していると説明。今後はアルゴリズム革新とスケーリングによって、その「時間的水平線」が急速に拡大すると予測した。</p>
<h2>OpenAIのミッションと戦略的柱</h2>
<p>アルトマン氏は、OpenAIのミッションは非営利法人と公益法人（PBC）の双方において「AGI（汎用人工知能）が全人類に利益をもたらすことを保証する」ことであると改めて表明した。かつてAGIは「神託のような存在」と見なされていたが、現在は「人々が未来を創造するためのツールを構築し、AIで力を与えること」が明確な方向性だと説明した。</p>
<p>OpenAIの戦略は、次の三つの柱で構成されている。</p>
<ol>
<li><strong>研究（Research）</strong> ： AGI構築に必要な研究の成功。</li>
<li><strong>プロダクト（Product）</strong> ： 誰もが簡単かつ強力にAIを使えるようにする。</li>
<li><strong>インフラストラクチャ（Infrastructure）</strong> ： 低コストで高性能なAIを提供できる基盤の整備。</li>
</ol>
<p>アルトマン氏は「AIが科学の発見を支援することで、社会全体がより良くなり、個人の創造性も飛躍的に向上するだろう」と述べた。</p>
<p>パホツキ氏は、強力なシステム開発に向けた準備の中で安全性と価値観の整合性（value alignment）を最重視しているとし、「AIが根本的に何を気にかけるのかを理解することが、スーパーインテリジェンス時代の長期的安全性の核心だ」と語った。</p>
<p>ザレンバ氏も加わり、質疑応答では研究の方向性や安全性、社会的インパクトに関する質問に答えながら、OpenAIが今後も透明性をもって議論を続けていく姿勢を示した。</p>
]]></description>
      <pubDate>Fri, 31 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>