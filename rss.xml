<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>富士通、1ビット量子化によるAIの軽量化・省電力化──「生成AI再構成技術」で用途特化型LLM「Takane」を強化</title>
      <link>https://ledge.ai/articles/fujitsu_1bit_quantization_takane_lightweight_power_saving</link>
      <description><![CDATA[<p>富士通は2025年9月8日、AIサービス「Fujitsu Kozuchi」の中核技術として、大規模言語モデル（LLM）の軽量化と省電力化を実現する「生成AI再構成技術」を開発したと<a href="https://global.fujitsu/ja-jp/pr/news/2025/09/08-01">発表</a>した。同技術を自社LLM「Takane」に適用し、性能を維持しつつ効率的に動作させることに成功したという。さらに、用途ごとに最適化した特化型モデルの構築にも対応可能となり、幅広い業務分野での活用が見込まれる。</p>
<h2>量子化による軽量化・省電力化</h2>
<p>富士通は独自の誤差伝播制御アルゴリズムを導入し、従来32ビットや16ビットで表現していたモデルを1ビットに量子化することに成功した。これにより、</p>
<ul>
<li>メモリ使用量は最大94％削減</li>
<li>推論速度は約3倍に向上</li>
<li>精度維持率は89％</li>
</ul>
<p>と、大幅な効率化を実現した。これにより、これまでハイエンドGPU複数枚を必要としていた処理が、ローエンドGPU1枚でも可能になった。</p>
<p><strong>■ 1ビット量子化による高精度な軽量化と省電力化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/news_20250908_01a_ja_3f94a449dd/news_20250908_01a_ja_3f94a449dd.png" alt="news-20250908-01a-ja.png" /></p>
<h2>特化型AI蒸留で用途最適化</h2>
<p>同社はまた、「特化型AI蒸留技術」を開発。汎用的な大規模LLMから必要な知識だけを抽出・再構成することで、業務特化型のモデルを効率的に生成できる。</p>
<p>実証では、CRMデータを用いた商談勝敗予測において、</p>
<ul>
<li>精度が43％改善</li>
<li>推論速度は11倍に高速化</li>
<li>モデルパラメータは100分の1に縮小
GPUメモリや運用コストは70％削減</li>
</ul>
<p>といった成果が得られた。汎用モデルを超える精度を示すケースも確認されている。</p>
<p><strong>■ 特定用途に必要な知識のみを活かした特化型AIモデル</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/news_20250908_01b_ja_398e9d0cfc/news_20250908_01b_ja_398e9d0cfc.png" alt="news-20250908-01b-ja.png" /></p>
<h2>今後の展望</h2>
<p>同社は2025年度下期から、生成AI再構成技術を適用した「Takane」のトライアル環境を順次提供する予定だという。また、Cohere社の大規模言語モデル「Command A」を量子化したモデルを、Hugging Faceを通じて同日より順次公開。</p>
<p>将来的には、メモリ使用量を最大1000分の1に削減するさらなる軽量化を目指し、エッジデバイスでのAIエージェント実装など、幅広い応用を見据えているという。</p>
]]></description>
      <pubDate>Fri, 12 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>産総研、双腕ロボットAI開発に向け学習データセットを無償公開 ― 両手協調作業の自動化を加速</title>
      <link>https://ledge.ai/articles/sangyouken_robot_ai_dataset_open</link>
      <description><![CDATA[<p>産業技術総合研究所（産総研）は2025年9月2日、双腕ロボットのAI制御に必要な学習データセットとソフトウェア基盤を無償で公開したと<a href="https://www.aist.go.jp/aist_j/press_release/pr2025/pr20250902/pr20250902.html">発表</a>した。複雑な作業を自律的に行うロボットの研究開発を支援するのが狙いだ。</p>
<p><strong>■ 日常・産業のさまざまなタスクを対象に収録されたロボット動作データ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig1_1_2f4b5d1d11/fig1_1_2f4b5d1d11.jpg" alt="fig1 (1).jpg" /></p>
<p>公開されたデータには、ロボットが両手で物体を把持・操作する際の動作が含まれる。食器の配膳や布の折り畳みといった日常タスクから、歯車のはめ込みやフレームの組み立てといった産業タスクまで幅広く網羅している。視覚や力覚センサーによる情報も収録されており、実際の作業環境に近い状況を再現できる。</p>
<p><strong>■ 人間の操作を模倣し、学習データとして記録するシステム</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig2_1_342e9cd6ff/fig2_1_342e9cd6ff.jpg" alt="fig2 (1).jpg" /></p>
<p>データは「リーダーフォロワー型遠隔操作システム」を通じて収集され、研究者や開発者が模倣学習や強化学習の基盤として利用可能だ。加えて、データ処理やモデル検証を行うためのソフトウェア基盤も同時に提供される。</p>
<p><strong>■ RoboManipBaselinesのフレームワーク構成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig3_1_b0c3f0f9fb/fig3_1_b0c3f0f9fb.png" alt="fig3 (1).png" /></p>
<p>今回の公開は、産総研が進める「ロボット基盤モデル研究」の一環。オープンフレームワーク「RoboManipBaselines」を通じて、データ収集・モデル訓練・評価を一貫して行える環境を提供し、研究成果の再現性や比較可能性を高めることを目的としている。</p>
<p><strong>■ 公開されたデータや基盤を活用したシミュレーション・検証例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fig4_3ab65c9131/fig4_3ab65c9131.jpg" alt="fig4.jpg" /></p>
<p>産業や生活の現場では、両手を使った協調動作の自動化ニーズが拡大している。従来のティーチング方式によるプログラミングでは対応が難しかった柔軟な作業に対し、AIによる自律的な動作学習が求められてきた。産総研は「研究者や企業が自由に活用することで、双腕ロボットの研究開発が加速し、工場やサービス分野での実装が進む」としている。</p>
<p>今後はデータの拡充や利用者からのフィードバックを踏まえた改善を継続し、現場導入に向けた応用展開を進める方針だ。</p>
]]></description>
      <pubDate>Fri, 12 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>蘭半導体製造装置大手ASML、仏ミストラルAIに13億ユーロ出資──最大株主となり戦略的パートナーシップを構築</title>
      <link>https://ledge.ai/articles/asml_mistral_ai_investment</link>
      <description><![CDATA[<p>オランダの半導体製造装置大手ASMLホールディングは2025年9月9日、フランスの生成AI企業ミストラルAIに13億ユーロ（約2255億円）を出資し、同社の最大株主となったと<a href="https://www.asml.com/en/news/press-releases/2025/asml-mistral-ai-enter-strategic-partnership">発表</a>した。</p>
<p>ミストラルAIは今回のシリーズC資金調達で総額17億ユーロを調達し、企業評価額は117億ユーロに<a href="https://mistral.ai/news/mistral-ai-raises-1-7-b-to-accelerate-technological-progress-with-ai">達した</a>。ASMLは約11％の株式を取得し、リード投資家として戦略的パートナーシップを構築する。</p>
<p>ASMLは、自社の製品開発や研究活動にミストラルAIの大規模言語モデルを統合する計画を示した。また、ASMLの最高財務責任者（CFO）ロジャー・ダッセン氏がミストラルAIの戦略委員会に参加し、経営方針に関与する。</p>
<p>一方のミストラルAIは、今回の資金調達を研究開発や人材拡充に活用し、欧州を代表するAI企業としての地位を強化する方針を明らかにした。</p>
<p>今回の出資は、欧州におけるAIと半導体産業の連携を象徴する動きであり、米中に対抗するAIエコシステム強化の一環と位置づけられる。今後、ミストラルAIの生成AI技術がASMLの先端リソグラフィー装置やシステムにどのように応用されるか、注目が集まっている。</p>
]]></description>
      <pubDate>Thu, 11 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>東大発スタートアップELYZA、独自の業務AIアプリをAIが作成するツール「ELYZA Works」を提供開始──法人向け生成AI活用を加速</title>
      <link>https://ledge.ai/articles/elyza_works_ai_app_autotool_launch</link>
      <description><![CDATA[<p>東京大学発スタートアップのELYZAは2025年9月9日、業務を人工知能（AI）で自動化する法人向けアプリケーション作成支援ツール「ELYZA Works」を提供開始したことを<a href="https://prtimes.jp/main/html/rd/p/000000063.000047565.html">発表</a>した。このツールは、企業が生成AIを活用し、プログラミング知識がなくても独自の業務アプリを迅速に構築できることを目的としている。</p>
<p><strong>ELYZA Worksの仕組み：AIが自社専用の業務アプリを生成し、現場で共有・利用しながら改善を重ねる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/47565_63_8ac393c2edbcd137adefdbe50ca4a3ca_1920x1080_147860e457/47565_63_8ac393c2edbcd137adefdbe50ca4a3ca_1920x1080_147860e457.webp" alt="47565-63-8ac393c2edbcd137adefdbe50ca4a3ca-1920x1080.webp" /></p>
<p>近年、国内でも生成AIの導入が加速しているが、専門知識の不足が企業利用拡大の障壁となっている。ELYZAは「ELYZA Works」を通じて、専門スキルがなくても導入可能な環境を提供し、企業の生産性向上を支援するとしている。</p>
<p><strong>出張関連の質問に自動で回答するアプリ例。AIが入力内容に応じて規定やベストプラクティスを参照し、適切な回答を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/47565_63_c6616122552077e18acf13fe101f5880_1920x1365_9ef954a77f/47565_63_c6616122552077e18acf13fe101f5880_1920x1365_9ef954a77f.webp" alt="47565-63-c6616122552077e18acf13fe101f5880-1920x1365.webp" /></p>
<p>ELYZAは、東京大学松尾研究室を母体として設立されたスタートアップ。日本語に強い大規模言語モデル「ELYZA Japanese LLM」をはじめ、法人向けに特化した生成AIサービスを展開してきた実績を持つ。</p>
<p>同社は今後国内企業への導入事例を拡大し、パートナーシップを強化していく方針を示している。数年内に利用者10万人規模を目指し、日本企業の業務効率化を後押しする考えだ。</p>
]]></description>
      <pubDate>Thu, 11 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【ソースコード特典付き】ローカルLLMで構築するマルチモーダルRAG｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol69</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>Ledge.ai Webinar vol.69では、「ローカルLLMで構築するマルチモーダルRAG」をテーマに、GPUクラウドサービス「GPUSOROBAN」を提供する株式会社ハイレゾ様をゲストにお迎えし、実演デモを交えながらご解説いただきます。本ウェビナーは、株式会社ハイレゾ様とのシリーズウェビナー企画の第4弾としてお届けいたします。</p>
<p>RAGというキーワードは、自社のデータの活用という文脈で注目を集めているキーワード。
今回はその中でもマルチモーダルRAGにスポットライトをあててお送りします。</p>
<p>請求書や報告書、マニュアルなど、ビジネス文書にはテキストだけでなく画像や図表が豊富に含まれています。従来のRAG（Retrieval-Augmented Generation）では、OCR（光学的文字認識）によるテキスト抽出が主流でしたが、文字化けや複雑なレイアウトの誤認識といった課題がありました。</p>
<p>今回のウェビナーでは、これらの課題を解決する「マルチモーダルRAG」に焦点を当てます。文書ページを画像として直接処理し、視覚的なレイアウト情報を保持したまま情報を抽出するアプローチです。最新の視覚言語モデルである「Qwen2.5-VL」とベクトルデータベースを用い、ローカル環境で高精度なRAGを構築する具体的な手法を、コード解説を交えたデモンストレーションでご紹介します。</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li>従来のRAGにおける画像・図表を含む文書の課題</li>
<li>マルチモーダルRAGの概要と、OCRレスなアプローチの優位性</li>
<li>GPUクラウド「GPUSOROBAN」を活用したマルチモーダルRAGの実装デモンストレーション</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>画像や図表を多く含むPDFから情報を正確に抽出したい方</li>
<li>マルチモーダルRAGの具体的な実装方法を知りたい方</li>
<li>ローカル環境で動作するLLM/VLMの活用に興味がある方</li>
<li>GPUリソースを効率的に活用しながらAI開発を進めたい方</li>
</ul>
<h2>視聴者特典</h2>
<p><strong>【特典①】デモで使用したサンプルコードをプレゼント！</strong>
本ウェビナーのアンケートにご回答いただいた方全員に、デモで使用したソースコードをプレゼントいたします。視聴後すぐに、ご自身の環境で再現・検証が可能です。</p>
<p><strong>【特典②】H200 GPU 30日間無料トライアルキャンペーン！</strong>
さらに、ハイレゾでは現在、「NVIDIA H200」を搭載したGPUクラウドサービス「AIスパコンクラウド」を30日間無料でお試しいただける特別なキャンペーンも実施中です。
（詳細はウェビナー内およびアンケート回答後のご案内をご確認ください。）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/h200_gpu_free_trial1200_bd3d66cf05/h200_gpu_free_trial1200_bd3d66cf05.jpg" alt="h200-gpu-free-trial1200.jpg" /></p>
<h2>登壇者情報</h2>
<p>株式会社ハイレゾ
GPU事業本部　マーケティング部　グループ長
山田 岳史</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/highreso_yamadasama_2a984e3aa6/highreso_yamadasama_2a984e3aa6.jpg" alt="highreso-yamadasama.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスのマーケティング担当。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年9月11日(木)〜2025年10月3日(金)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/rhh3WJORYMZvkfiGN0IR">ウェビナーの視聴はこちら</a>
:::</p>
]]></description>
      <pubDate>Thu, 11 Sep 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>曖昧さ払拭、GoogleがGeminiの制限を公式明記—無料は1日5プロンプト、Ultraは500</title>
      <link>https://ledge.ai/articles/google_gemini_usage_limits_officially_detailed</link>
      <description><![CDATA[<p>Googleは公式ヘルプセンターを更新し、生成AI「Gemini Apps」における利用制限を初めて具体的な数値として<a href="https://support.google.com/gemini/answer/16275805">明記</a>した。従来は「limited access」など曖昧な表現が使われていたが、今回の更新により無料・有料プランごとの上限が詳細に示された。</p>
<h2>プランごとの利用上限</h2>
<p>無料プランは「1日5プロンプト」までに制限される一方で、最上位のUltraプランでは「500プロンプト」まで利用可能となる。画像生成や動画生成、Deep Researchなどもプランごとに異なる上限が設けられている。</p>
<p><strong>Google公式ヘルプセンター「Gemini アプリのアップグレード」より</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_help_e87fab6301/gemini_help_e87fab6301.jpg" alt="gemini help.jpg" /></p>
<p>Googleは2025年5月に「AI Ultra」プランを発表していたが、具体的な使用制限は明示されていなかった。今回の改訂により、同社のAIサービスに関する透明性が一段と高まったかたちだ。今後も新機能追加や制限の調整が行われる可能性があり、ユーザーには公式ヘルプセンターで最新情報を確認することが推奨される。</p>
]]></description>
      <pubDate>Thu, 11 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、大規模言語モデルの「ハルシネーション（幻覚）」の原因を解説──評価方法の設計に問題と指摘</title>
      <link>https://ledge.ai/articles/openai_explains_hallucination_causes</link>
      <description><![CDATA[<p>OpenAIは2025年9月5日、言語モデルが誤った情報をもっともらしく生成する「ハルシネーション」の原因を公式ブログで<a href="https://openai.com/index/why-language-models-hallucinate/">解説</a>した。研究者らは、モデルの訓練方法と評価基準の設計そのものが誤答を促す構造になっていると指摘し、評価方法の見直しを提案している。この内容は併せて公開された<a href="https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf">学術論文</a>でも詳細に検証されている。</p>
<p>ハルシネーションは大きく2つの段階で発生すると研究では説明されている。
まずプレトレーニング段階では、モデルは大規模なテキストデータから言語の確率分布を学習するが、この過程自体が統計的に誤りを生み出す要因となる。誤りは「バイナリ分類（正しい／誤り）」の誤分類と同様に不可避であり、訓練データに誤りが含まれていなくても誤答が発生すると分析している。</p>
<p>次にポストトレーニング段階では、評価基準の設計が問題視された。多くの主要なベンチマーク（MMLU、GPQAなど）は、質問に対して「分からない」と回答するよりも「推測して答える」方が高得点となる方式を採用している。その結果、モデルは過剰に自信を持って誤答を返すよう最適化される傾向があるという。</p>
<p>論文では、誕生日や学位論文のタイトルを尋ねた際にモデルが異なる誤答を返す具体例も紹介された。また、訓練データに一度しか登場しない事実（singleton rate）が多いほど、誤答率が高まることも数理的に示された。</p>
<p>解決策として研究チームは、新たなハルシネーション評価を追加するよりも、既存のベンチマークに「不確実性の表明」を認める仕組みを組み込むことを提案する。例えば「分からない」と回答しても減点されない方式や、回答の信頼度を明示する採点方法を導入することで、誤答の温床となっている「推測の奨励」を抑制できると主張している。</p>
]]></description>
      <pubDate>Wed, 10 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/10 [WED]Google検索、日本語版「AIモード」を開始──Gemini 2.5活用で複雑な質問にも文脈理解</title>
      <link>https://ledge.ai/articles/google_search_ai_mode_japan_start</link>
      <description><![CDATA[<p>Googleは9月9日、日本の「Google検索」で新機能「AIモード」の提供を開始したことを<a href="https://blog.google/intl/ja-jp/products/explore-get-answers/ai-mode-search/">発表</a>した。Gemini 2.5のカスタムバージョンを活用し、従来よりも複雑で文脈依存の強い質問に対して、単一クエリで包括的な回答を提示できるのが特徴となる。</p>
<p>AIモードでは、「クエリファンアウト」と呼ばれる技術を採用。ユーザーの質問を複数のサブトピックに分解し、それぞれを同時に検索・分析した上で統合的な回答を生成する。これにより、旅行計画や比較検討といった複数の要素を含む質問にも対応可能となった。</p>
<p>提供環境はPCやスマートフォンのブラウザに加え、Android・iOS版のGoogleアプリにも対応。全国のユーザーに数週間をかけて段階的に展開される。</p>
<p>さらに、テキスト入力だけでなく、音声や画像からの質問にも対応するマルチモーダル機能も導入された。たとえば料理の写真を提示すれば、それがベジタリアン向けかどうかを判定し、関連情報を提案することも可能だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai_mode_tapas_d918657779/ai_mode_tapas_d918657779.jpg" alt="ai mode tapas.jpg" /></p>
<p>信頼性確保の観点から、AIモードが生成した回答に不確かさがある場合は、従来の検索結果が優先的に表示される設計になっている。Googleは既存のランキングシステムとAI応答を組み合わせ、利便性と情報の信頼性を両立させる方針だ。</p>
<p>同社は米国での先行提供を経て、今回日本語を含む複数言語での展開を開始した。今後も利用可能な地域や言語を順次拡大していくとしている。</p>
]]></description>
      <pubDate>Wed, 10 Sep 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>会話の裏にある“意図”を理解するAI──NVIDIAとカーネギーメロン大学、「社会的世界モデル」で社会的推論の性能が大きく向上</title>
      <link>https://ledge.ai/articles/ai_social_world_model_cmu_nvidia</link>
      <description><![CDATA[<p>カーネギーメロン大学とNVIDIAの研究者らは2025年8月30日、AIが人の意図や感情をより正確に理解できるようにする新手法「社会的ワールドモデル（Social World Models）」を<a href="https://arxiv.org/abs/2509.00559">発表</a>した。</p>
<p>研究チームは、日常会話や物語といった自然言語を、そのまま扱うのではなく「一度構造化した表現」に変換し、それをもとにシミュレーションを行う枠組みを提案した。自由文のままでは曖昧さや抜け落ちが多く、AIが他者の意図を追跡するのが難しいが、この“ワンクッション”を挟むことで精度が大きく向上したという。</p>
<p><strong>自由文を一度構造化してから『社会的ワールドモデル』で推論するフレームワーク。従来手法に比べ、複数の社会的推論ベンチマークで精度が向上した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_5_9f97f3f354/x1_5_9f97f3f354.png" alt="x1 (5).png" /></p>
<h2>性能は最大51%改善</h2>
<p>実験では、複数人が登場する会話シナリオや協力・競争が絡む対話課題で評価を実施。その結果、意図や感情を読み解く力が最大で51%改善した。また、実際の対話のなかでAIがゴールを達成できる割合も最大18%向上したと報告している。</p>
<h2>行動前に結果を“先読み”</h2>
<p>この手法では「行動を起こす前に、仮想世界の中で結果をシミュレーションする」というアルゴリズムも導入された。研究チームはこれを「Foresee and Act」と呼び、交渉や協力シーンでより安定した判断が可能になることを示した。</p>
<h2>人間らしい社会性を持つAIへ</h2>
<p>従来のAI研究が物理世界の理解やシミュレーションに重点を置いてきたのに対し、今回の社会的ワールドモデルは、人間関係や心理的な状態を含めた“社会の見取り図”を扱う点が特徴だ。研究者らは、長期的に一貫した対話や複雑な社会的状況への適応につながると期待している。</p>
<p><strong>物理的なワールドモデル（左）は環境状態を追跡するが、社会的ワールドモデル（右）は感情や欲求など心理状態も含めて扱う</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_2_070a010511/x2_2_070a010511.png" alt="x2 (2).png" /></p>
]]></description>
      <pubDate>Wed, 10 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>香港科技大学、AIと文明の共進化を探る社会シミュレーション「Aivilization」を公開──10万人のAIエージェントが仮想社会を形成</title>
      <link>https://ledge.ai/articles/hkust_aivilization_ai_civilization_experiment</link>
      <description><![CDATA[<p>香港科技大学（HKUST）は2025年8月19日、10万人規模のAIエージェントによる仮想社会を舞台に、AIと人類の共進化を探る教育サンドボックスゲーム「Aivilization」を<a href="https://hkust.edu.hk/news/hkust-launches-worlds-largest-ai-powered-educational-sandbox-game-advancing-ai-literacy-and">発表</a>した。同大学によると、プロジェクトはAIリテラシーの向上や市民科学の促進を目的としており、世界最大規模のAI社会シミュレーションとして設計されているという。</p>
<p><strong>Aivilizationは、インタラクティブなゲームプレイ、大規模な一般参加、そしてリアルタイムのAI実験を組み合わせ、6週間にわたり10万台のAIエージェントを動員。Chen Kani教授（左）と博士課程学生のYang Haowei氏（右）が共同でプラットフォーム開発を主導した。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/CSC_06058_415aa14c9f/CSC_06058_415aa14c9f.jpg" alt="CSC06058.jpg" /></p>
<p>「Aivilization」では、約10万人のAIエージェントがリアルタイムに相互作用し、経済・文化・統治といった要素を持つ仮想社会を形成する。参加者はAIキャラクターの人格をMBTI（性格類型診断）を用いて設定し、進路指導や日常生活の助言を与えることができる。ゲーム終了後には、AIキャラクターの人生の軌跡をまとめた「ライフレポート」や、人間とAIのコミュニケーション分析が提供される。</p>
<p><strong>博士課程の学生Ricky Chan氏が作成した内向的な AI キャラクターは、彼の指導の下、徐々に社会的に活動的な「人間」へと進化した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/CSC_06171_1d10845de3/CSC_06171_1d10845de3.jpg" alt="CSC06171.jpg" /></p>
<p>技術面では、AIエージェント1体あたりの運用コストを月約2ドルに抑えることに成功し、従来比95%以上の削減を実現した。大規模なマルチエージェントシステムをリアルタイムで運用可能にした点も特徴とされる。</p>
<p>HKUSTは本プロジェクトを通じて、AIを「次世代の教育ツール」として活用し、参加者が実体験を通じてAIリテラシーを高められる仕組みを構築したと説明している。公式サイト（Aivilization.ai
）では「Join the Experiment」と題して参加案内を行っており、現時点では招待制でのアクセスとなっている。</p>
<p>さらに、YouTube公式チャンネルでは、仮想都市やAIエージェントの相互作用を紹介する映像も公開されており、ゲームの臨場感を伝えている。HKUSTは、今後「Aivilization」で得られるデータを教育研究やAIガバナンスの議論に活用する方針を示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=1NPwiyejvEg">YouTube</a></p>
]]></description>
      <pubDate>Tue, 09 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、AIスキル認定と求人プラットフォーム導入へ—2026年にもサービス開始</title>
      <link>https://ledge.ai/articles/openai_jobs_platform_certifications_2026</link>
      <description><![CDATA[<p>OpenAIは2025年9月4日（現地時間）、AIスキルを持つ人材と企業を結びつける新サービスを<a href="https://openai.com/index/expanding-economic-opportunity-with-ai/">発表</a>した。人材マッチングプラットフォーム「OpenAI Jobs Platform」と、AIスキルを証明する認定制度「OpenAI Certifications」の2本柱で構成され、いずれも2026年中の展開を予定している。</p>
<h2>AI普及と雇用への影響</h2>
<p>AIの活用が進む一方で、既存の雇用の変化やスキル不足が課題となっている。OpenAI Applications部門を率いるFidji Simo氏は、「AIによる混乱を完全に防ぐことはできないが、人々がAIに精通し、企業とつながる機会を広げることは可能だ」と述べ、今回の取り組みの狙いを説明した。</p>
<h2>Jobs Platformの概要</h2>
<p>新たに発表された「OpenAI Jobs Platform」は、AIリテラシーを備えた求職者と企業をマッチングするサービスで、2026年半ばにローンチされる見込みだ。大企業だけでなく、中小企業や地方自治体向けのトラックも用意される計画で、幅広い分野での活用が想定されている。</p>
<h2>OpenAI Certificationsの仕組み</h2>
<p>一方、「OpenAI Certifications」は、AIスキルを公式に証明する認定制度で、OpenAI Academyを通じて提供される。基礎的なAI理解からプロンプトエンジニアリングに至るまで複数レベルが設けられ、ChatGPTの「Studyモード」などを利用して学習・試験に臨むことができる。</p>
<p>OpenAIは、2030年までに米国内で1,000万人の市民に認定を付与する目標を掲げている。試験的導入は2025年末から2026年初頭に始まる予定だ。</p>
<h2>提携先と今後の展望</h2>
<p>Jobs PlatformとCertificationsには、WalmartやJohn Deere、Accenture、Indeedなどの企業や、テキサス州を含む地方自治体がパートナーとして参加。LinkedIn（Microsoft傘下）を意識した構想とも言われ、求人市場における新たな競合軸として注目されている。</p>
<p>中小企業や公共分野まで視野に入れることで、地域経済や行政サービスにAIを浸透させる効果も期待される。ただし、認定制度がどの程度実効性を持つのか、実際の雇用改善やスキルアップに結びつくかが今後の焦点となる。</p>
]]></description>
      <pubDate>Tue, 09 Sep 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、オンデバイス向け埋め込みモデル「EmbeddingGemma」を公開──約3億パラメータで200MB動作を実現</title>
      <link>https://ledge.ai/articles/google_embeddinggemma_ondevice_release</link>
      <description><![CDATA[<p>Googleは2025年9月4日、オンデバイスで動作する軽量な埋め込みモデル「EmbeddingGemma」を<a href="https://developers.googleblog.com/en/introducing-embeddinggemma/">公開</a>した。同社の開発者向けブログによれば、同モデルはパラメータ数が約3億とコンパクトながら、高品質なベクトル表現を生成できる設計だという。メモリ使用量は200MB程度に抑えられており、スマートフォンやエッジデバイスといったリソース制約のある環境での利用を想定している。</p>
<p>EmbeddingGemmaは多言語に対応しており、文書検索、意味的な類似度判定、レコメンデーションなど幅広いタスクでの活用が可能だ。さらに、RAG（Retrieval Augmented Generation）パイプラインにも組み込めるため、生成AIの精度向上にも寄与するとしている。</p>
<p>性能面では、Massive Text Embedding Benchmark（MTEB）において高い評価を獲得しており、従来のオンデバイス埋め込みモデルを大幅に上回る効率性を示した。</p>
<p><strong>図1：モデルサイズ別のMTEBスコア</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Embedding_Gemma_Chart01_RD_3_V01_original_d9e9e6311b/Embedding_Gemma_Chart01_RD_3_V01_original_d9e9e6311b.jpg" alt="EmbeddingGemma_Chart01_RD3-V01.original.jpg" /></p>
<p>EmbeddingGemmaは約3億パラメータという小型設計ながら、MTEB（Multilingual v2）の平均スコアで他の大規模モデルに匹敵する性能を発揮していることがわかる。</p>
<p><strong>図2：MTEB（Multilingual v2）における比較結果</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Embedding_Gemma_Chart02_RD_3_V01_original_40dfa34e85/Embedding_Gemma_Chart02_RD_3_V01_original_40dfa34e85.jpg" alt="EmbeddingGemma_Chart02_RD3-V01.original.jpg" /></p>
<p>評価結果では、Retrieval（検索）、Classification（分類）、Clustering（クラスタリング）といった複数のタスクで競合モデルを上回るスコアを記録した。特にRetrieval分野では62.49と高い水準を示している。</p>
<p>Googleは「EmbeddingGemma」を通じて、低消費電力かつ低メモリ環境でも高性能なAI利用を可能にすることを目指している。モバイル端末やIoT分野における応用が期待される。</p>
<p>@<a href="https://www.youtube.com/watch?v=Xu1X-J-r5Xk">YouTube</a></p>
]]></description>
      <pubDate>Tue, 09 Sep 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、Broadcomと協業し2026年から自社AIチップ量産へ──英紙報道、複数メディアが確認</title>
      <link>https://ledge.ai/articles/openai_broadcom_ai_chip_mass_production_2026</link>
      <description><![CDATA[<p>OpenAIが、米半導体大手Broadcomの協力を得て、2026年から自社向けのAI専用半導体の量産を開始する計画であることが明らかになった。<a href="https://www.ft.com/content/e8cc6d99-d06e-4e9b-a54f-29317fa68d6f">英紙フィナンシャル・タイムズ（FT）</a>が2025年9月5日付で報じ、複数の欧米メディアもこれを伝えている。</p>
<p>FTによると、OpenAIは大規模言語モデル（LLM）の学習や推論に必要な計算能力を外部依存から脱却するため、独自チップ開発をBroadcomと進めている。背景には、AI分野におけるNVIDIA GPUへの過度な依存と、それに伴う供給制約やコスト高がある。GoogleやMetaなどが自社チップ開発を加速させる中、OpenAIも独自インフラの確立を急ぐ。</p>
<p>Broadcomが10億ドル規模のAIアクセラレータ受注を獲得し、数百万個単位の半導体を2026年第3四半期から供給する可能性を<a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-widely-thought-to-be-broadcoms-mystery-usd10-billion-custom-ai-processor-customer-order-could-be-for-millions-of-ai-processors">Tom’s Hardware</a>は指摘。また、最新の高帯域幅メモリ（HBM）やXPUアーキテクチャが採用される可能性もあると伝えている。</p>
<p>この報道を受け、Broadcomの株価は前場で7％以上上昇する場面があり、市場ではNVIDIA一強体制に変化の兆しが出ているとの見方が広がっている。</p>
]]></description>
      <pubDate>Mon, 08 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/9/8 [MON]Anthropic、著作権侵害訴訟で15億ドルの和解成立──約50万点に1作品あたり3,000ドル分配で決着</title>
      <link>https://ledge.ai/articles/anthropic_copyright_settlement_1_5billion</link>
      <description><![CDATA[<p>米AI企業Anthropicを被告とする著作権侵害訴訟で、2025年9月5日（現地時間）、和解が成立した。裁判所に提出された和解の<a href="https://www.documentcloud.org/documents/26084996-proposed-anthropic-authors-ai-settlement/?mode=document">予備承認申立書</a>によれば、Anthropicは少なくとも15億ドルを和解基金として拠出し、対象となる約50万点の著作物に1作品あたり約3,000ドルが分配される見込みだ。</p>
<h2>15億ドル規模の和解基金</h2>
<p>和解の条件では、Anthropicが非払戻型の基金を設立し、著作物1点ごとに均等額が支払われる。著作物の数が50万点を超える場合には、追加で1作品につき3,000ドルが支払われる条項も盛り込まれている。支払いは段階的に実施され、最初の3億ドルは予備承認から5営業日以内に拠出される。残額も2年以内に全額が支払われる予定だ。</p>
<h2>データ破棄と請求範囲の限定</h2>
<p>金銭的救済に加え、Anthropicは「Library Genesis」や「Pirate Library Mirror」といった海賊版サイトから取得した書籍データを破棄する義務を負う。和解で放棄される請求は2025年8月25日以前の著作権侵害に限定され、AIモデルの出力に関する請求権は対象外とされた。</p>
<h2>今後の手続きと影響</h2>
<p>今回の和解は、AI企業に対する著作権訴訟としては過去最大規模とされる。予備承認審理は9月8日に米カリフォルニア州北部地区連邦地裁で行われ、その後、著作権者への通知と異議申し立て期間を経て最終承認に進む。</p>
<p>Authors GuildのCEOであるMary Rasenberger氏は、この和解について「AI業界に対する強い警告だ」とコメントし、米出版社協会（AAP）のMaria Pallante氏も「影響力ある前例となる」と評価した。</p>
]]></description>
      <pubDate>Mon, 08 Sep 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スイス公共3機関、完全オープンで透明性ある多言語LLM「Apertus」で一部の大規模企業による独占的なAIモデル提供に対抗──EPFL・ETH Zürich・CSCSが共同開発</title>
      <link>https://ledge.ai/articles/apertus_open_multilingual_llm_epfl_ethz_cscs</link>
      <description><![CDATA[<p>スイス連邦工科大学ローザンヌ校（EPFL）、スイス連邦工科大学チューリッヒ校（ETH Zürich）、スイス国立スーパーコンピューティングセンター（CSCS）は2025年9月2日、共同開発した大規模言語モデル（LLM）「Apertus」を<a href="https://ethz.ch/en/news-and-events/eth-news/news/2025/09/press-release-apertus-a-fully-open-transparent-multilingual-language-model.html">発表</a>した。完全オープンかつ透明性を重視した多言語対応モデルであり、研究、教育、産業における幅広い利用が期待されている。</p>
<p>Apertusは、学習に用いたデータセットやトレーニング過程、モデル構造に関する情報を公開するなど、透明性を徹底している。また、英語のみならず複数のヨーロッパ言語に対応しており、グローバルかつ多様な研究環境での活用を見据えている点も特徴だ。モデルは完全オープンソースとして提供され、研究者や開発者が自由に利用できる。</p>
<p>ETH Zürichの発表によると、Apertusの開発は「一部の大規模企業による独占的なAIモデル提供」に対抗し、公共機関が主導するオープンな代替を示すことを目的としている。特に研究や教育分野での利用を重視し、透明性を担保することで信頼性の高いAI活用の基盤となることを目指す。</p>
<p>今後はヨーロッパにおけるAI研究・教育基盤としての活用が期待されるほか、公共サービスや産業界への応用も視野に入っている。今回の公開は、AIのオープン化と社会的な信頼構築に向けた大きな一歩といえる。</p>
<p>@<a href="https://www.youtube.com/watch?v=atObT7Xnbdk">YouTube</a></p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepL、企業向け自律型AIエージェント「DeepL Agent」を発表──反復作業を自然言語で自律実行、ベータ版を提供開始</title>
      <link>https://ledge.ai/articles/deepl_agent_autonomous_ai_for_enterprise</link>
      <description><![CDATA[<p>DeepLは2025年9月3日（ニューヨーク／ケルン発）、企業向け自律型AIエージェント「DeepL Agent」を<a href="https://www.deepl.com/ja/ai-labs/agent">発表</a>した。同サービスは、反復的な業務を自然言語で指示するだけで自律的に実行できる仕組みを備え、現在はベータ版として一部顧客向けに提供を開始。数か月以内に一般公開される予定だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=W8fGLKn60kg">YouTube</a></p>
<p>DeepL Agentは、ユーザーが自然言語で指示を与えると、仮想のキーボード、ブラウザ、マウスを用いて作業を遂行する。従来のツール操作やスクリプト作成を必要とせず、日常的な反復業務を自律的にこなす点が特徴となっている。
同社は、企業利用に求められる安全性や正確性を重視して設計しており、AIによる作業自動化と効率化の両立を狙う。翻訳サービスを中心に培ってきた自然言語処理の強みを応用することで、幅広い業務への適用を視野に入れている。
DeepLは、今回の取り組みを「AI翻訳企業から包括的なAIソリューション企業への進化」と位置づけており、業務効率化や自動化市場への参入を本格化させる構えだ。
@<a href="https://www.youtube.com/watch?v=baRBEo2cgvQ">YouTube</a></p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界初のAI駆動型ランサムウェア「PromptLock」発見──攻撃者が生成AIを悪用する新しい時代が現実化</title>
      <link>https://ledge.ai/articles/eset_promptlock_ai_ransomware_new_era</link>
      <description><![CDATA[<p>スロバキアを本社に置くヨーロッパのサイバーセキュリティ企業ESETは2025年8月27日、生成AIを利用して攻撃を行う新たなタイプのランサムウェア「PromptLock」を発見したと<a href="https://www.eset.com/jp/about/newsroom/press-releases/2025/eset-discovers-promptlock-the-first-ai-powered-ransomware-jp/">発表</a>した。研究チームは「世界初のAI駆動型ランサムウェア」と位置づけ、攻撃者が生成AIを悪用する新しい時代の到来を示すものとして警鐘を鳴らしている。</p>
<p>ESETによると、PromptLockはローカルに配置された大規模言語モデルを用い、プロンプトをもとに悪意あるLuaスクリプトをリアルタイムに生成・実行する仕組みを備える。クラウド経由の検知を回避できるため、従来のAPI監視やヒューリスティック解析をすり抜ける可能性がある。</p>
<p>技術的特徴として、Go言語で記述され、Windows、Linux、macOSの複数環境に対応。暗号化方式にはSPECK 128ビットが採用され、感染後はファイルの列挙と暗号化を実行する。ランサムノートにはビットコインアドレスが記載されており、「Satoshi Nakamoto」に関連する文字列が含まれている点も確認された。</p>
<p>今回のサンプルは、VirusTotalにアップロードされた検体から発見されたもので、現段階では概念実証（PoC）にとどまる。ESETの主任研究者Anton Cherepanov氏は「実際の攻撃活動に用いられた証拠はないが、AIによるマルウェア自動生成が現実に機能することを示した」とコメントしている。</p>
<p>同社はPromptLockを自社ソリューションで検知可能であることを強調する一方、外部の専門家からは「AIが攻撃ツールとして利用されれば、ランサムウェア開発のハードルが大幅に下がり、模倣的な派生が拡散する恐れがある」との懸念も示されている。</p>
<p>生成AIの普及が攻撃手法にまで広がりつつあるなか、防御側もAIを活用したセキュリティ対策の強化が不可欠となっている。PromptLockは、サイバー脅威が新たな段階へ進んだことを象徴する事例といえる。PromptLockは、サイバー脅威が新たな段階へ進んだことを象徴する事例として注目される。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/9/10 [WED]チューリッヒ工科大学、MBTI性格診断をLLMに適用──「感情型」は協力的、「論理型」は競争的に</title>
      <link>https://ledge.ai/articles/eth_mbt_ai_agents_cooperation_competition</link>
      <description><![CDATA[<p>チューリッヒ工科大学（ETH Zurich）の研究チームは2025年9月4日、性格診断テスト「MBTI」の16タイプを大規模言語モデル（LLM）に演じさせ、その行動傾向を比較する実験を行った。結果として、感情を重視するタイプ（F）は協力的に、論理を重視するタイプ（T）は競争的にふるまう傾向が確認されたことを<a href="https://arxiv.org/abs/2509.04343">発表</a>した。この研究は、AIエージェントに「性格」を付与することで、より人間らしい集団行動を再現できる可能性を示している。</p>
<h2>研究の背景</h2>
<p>MBTI（Myers-Briggs Type Indicator）は、人間の性格を16タイプに分類する性格診断である。研究チームは、MBTIをプロンプトでLLMに埋め込み、各タイプを演じるAIエージェントを構築。その挙動を比較することで、心理的特性がAIの意思決定や社会的ふるまいに影響を与えるかを検証した。</p>
<p><strong>MBTIの16タイプをLLMに適用するフレームワーク「MBTI-in-Thoughts」の概要図</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Psychologically_Enhanced_AI_Agents1_f797018e9a/Psychologically_Enhanced_AI_Agents1_f797018e9a.jpg" alt="Psychologically Enhanced AI Agents1.jpg" /></p>
<h2>実験方法と結果</h2>
<p>研究チームは、MBTIの16タイプをプロンプトで付与する「MBTI-in-Thoughts」を開発。まず各タイプで一貫した“性格”が出るかを検証するため、公式の16Personalitiesテストを自動実施し、E/I・T/F・J/P軸で明確に分離できることを示した（S/Nは相対的に弱い傾向）。また、事前の自己内省（self-reflection）フェーズを入れると、協調性や推論品質が向上することも確認している。</p>
<h3>評価タスクの設計</h3>
<p>「性格」が効きやすい感情（affect）／認知（cognition）軸に沿ったタスクを選定。多くの標準ベンチマークは事実想起寄りで、性格付与による差が出にくいため除外したという。</p>
<ul>
<li><strong>物語生成（affect軸）</strong> ：WRITINGPROMPTSから100プロンプトを抽出し、16タイプ＋対照（EXPERT/NONE）で物語を生成。LLM-as-a-judgeにより、読みやすさ・感情量・個人性・ハッピーエンド等の属性をスコア化。感情型（F）のエージェントは共感的で感情豊かな物語を生成。</li>
<li><strong>戦略ゲーム（cognition軸）</strong> ：囚人のジレンマ／ハト-タカで、各ラウンドは「1回のメッセージ交換→意思決定」の2段階。相手タイプは伏せ、メッセージ通りに行動する義務はないことを明示して“駆け引き”を可能にした。評価指標は裏切り率（Defection）／戦略切替率（Switch）／誠実さ（Honesty）の3つ。</li>
</ul>
<h3>モデルとコントロール</h3>
<p>コストを抑えるためGPT-4o mini／GPT-4o／Qwen3-235B-A22B／Qwen2.5-14B-Instructを使用。比較用に、EXPERT（専門家ふるまいのみで性格付与なし）とNONE（無指定）を用意した。物語生成は主にQwen3-235B-A22B（temp=0）、ゲーム理論タスクはGPT-4o（temp=1）で評価。</p>
<h3>主要結果（物語生成）</h3>
<p>Feeling（F）系は感情量・個人性・ハッピーエンドで一貫して高スコア。特にINFP/INFJ/ISFPで顕著。Extravert（E）系は読みやすさ・ユーモア・ハッピーエンドで内向型を上回る。EXPERT/NONEよりもF系の方が感情面の属性で優れる傾向を示した。</p>
<h3>主要結果（戦略ゲーム）</h3>
<p>Thinking（T）は繰り返し囚人のジレンマで約90%が裏切り選択、Feeling（F）は約50%と協力寄り（有意差）。戦略切替率はT≈0.07、F≈0.16で、Tは一貫計画、Fは柔軟適応という対比が出た。HonestyではI（≈0.54）＞E（≈0.33）、J＞Pの傾向を確認。例示ではINTPが途中でDefectへ転じ、ENFPが協力を継続するラウンド進行が図示されている。</p>
<p><strong>囚人のジレンマにおけるエージェント間の対話例。INTPは途中から裏切りを選択し、ENFPは協力を継続した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Example_agent_communication_6da05f1c44/Example_agent_communication_6da05f1c44.jpg" alt="Example agent communication.jpg" /></p>
<h2>MBTI次元ごとの傾向</h2>
<p>分析では、以下のような傾向が確認された。</p>
<ul>
<li><strong>Thinking（T） vs Feeling（F）</strong> ：Tタイプは安定して競争的、Fタイプは柔軟で協力的。</li>
<li><strong>Introversion（I） vs Extraversion（E）</strong> ：内向型は約束を守りやすく、外向型は柔軟な対応を見せる傾向。</li>
<li><strong>Judging（J） vs Perceiving（P）</strong> ：Jタイプは一貫性が高く、Pタイプは状況に応じた柔軟性を示した。</li>
</ul>
<h2>今後の展望</h2>
<p>研究チームは、この成果が人間との協働に適したAIエージェント設計や、仮想社会シミュレーションに役立つ可能性を指摘している。論文では「心理的プロファイルを組み込むことで、より信頼性の高い集団行動の再現や、人間社会に近い意思決定モデルの開発につながる」と結論づけている。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、Geminiをオンプレミスで提供開始──「Google Distributed Cloud」に対応、エアギャップ構成で一般提供</title>
      <link>https://ledge.ai/articles/google_gemini_onprem_gdc_airgapped</link>
      <description><![CDATA[<p>Googleは米国時間8月28日、同社の大規模言語モデル「Gemini」シリーズをオンプレミス環境で利用できるようにすると<a href="https://cloud.google.com/blog/topics/hybrid-cloud/gemini-is-now-available-anywhere">発表</a>した。Google Distributed Cloud（GDC）を基盤に、セキュリティやデータ主権の要件に対応した提供形態を整えた。</p>
<p>今回の発表により、インターネット接続を完全に遮断した「エアギャップ構成」が一般提供（GA）として開始され、インターネット接続を前提とする「コネクテッド構成」はプレビュー提供が始まった。これにより、企業や公共機関は自社環境内でGeminiを安全に活用できるようになる。</p>
<p>オンプレミス版Geminiは、アクセス制御やセキュリティ監査に加え、Confidential Computingへの対応も備えている。また、NVIDIA GPUを活用することで、マルチモーダルな生成AI処理を自社環境内で実行できる。Googleは「クラウド、エッジ、オンプレミスを問わず、あらゆる場所でGeminiを利用可能にする」としており、AI導入の柔軟性を大きく広げた。</p>
<p><strong>Google Distributed Cloud AIスタックの構成。GeminiやGemma、タスク特化型モデルをオンプレミス環境で実行可能に</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_on_GDC_GA_Launch_August_2025_max_2200x2200_54883b20c7/Gemini_on_GDC_GA_Launch_August_2025_max_2200x2200_54883b20c7.jpg" alt="Gemini_on_GDC_GA_Launch_-_August_2025.max-2200x2200.jpg" /></p>
<p>導入事例としては、シンガポールのCSIT（情報科学技術庁）、GovTech Singapore（政府技術庁）、HTX（内務技術庁）がいち早く採用を決定。日本ではKDDIが先行導入を進めている。</p>
<p>Googleは今後も、クラウド版と並行してオンプレミス環境でのGemini利用を拡大していく方針だ。公共機関や金融・医療など、データを外部に出せない領域での生成AI活用が進むことで、エンタープライズAI市場における競争が一層加速するとみられる。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/8/19 [TUE]AI業界を牽引するトップランナーが語る！—今押さえるべきAIの全体像と最前線を3日間で掴むLedge.ai Webinar SP開催</title>
      <link>https://ledge.ai/articles/ledgeai-webinarsp-sponsor</link>
      <description><![CDATA[<p>国内最大級のAI特化メディア『Ledge.ai』を運営する株式会社レッジ（東京都品川区）は、2025年9月24日(水)〜26日(金)の3日間連続で合計20本以上のセミナーを配信するオンラインイベント「Ledge.ai Webinar SP」を開催いたします。</p>
<p>本イベントでは、AIの各領域の専門家を招き、今必要とされるAIの体系的な知識や活用に関する見識をシェアする講義を実施。「AIをしる、つかう、つくる」をテーマに、多様な課題解決のヒントとなるようなコンテンツを動画でお届けします。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_4aed8b100c/_4aed8b100c.png" alt="ウェビナーの様子.png" /></p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>AI業界を牽引するトップランナーが今押さえるべきAIの知識と最前線を3日間で語る</h2>
<p>AIの急激な進化と急速な広まりにより、AIへのリテラシーの差が広がっています。AI活用の最前線では「どう使えば効果的か」「どう作れば自社の強みになるか」といった問いに対しての取り組みが行われ、新たな事例や知見が生まれています。そんな現在において、AIの全体像を体系的に理解した上で、ビジネスにどのように活用されているかすばやく捉えることは重要です。</p>
<p>当イベントはAIの基礎理解 → 業務活用 → 開発実践までを体系的に理解し、この時代で働くビジネスマンの方に使える学びをお届けします。</p>
<p>Ledge.ai Webinar SPは、以下の3つの軸で構成されています。</p>
<h2>プログラム ~「生成AIだけじゃない！「AIをしる、つかう、つくる」SP~</h2>
<h3>Day1：AIを「しる」——全体像と本質を理解する</h3>
<p>AIの領域では日々革新的な技術が生まれ、その掛け合わせによりAIの担える範囲が急速に広がっています。AIの基礎からAI全般の進化を体系的に学ぶことで適切なAI活用に繋げることができます。</p>
<p>【対象】
・AIの基本から体系的に理解したい方
・生成AIに加え、AI全般の進化や仕組みに関心がある方</p>
<p>【セミナー内容】
・AIの基礎とこれまでの進化（機械学習、ディープラーニング含む）
・⽣成AIの仕組みと活⽤シーンの全体像
・ビジネスで求められるAIリテラシーと注意点</p>
<p>【ゲスト講演】
「ソフトバンクの事例から紐解く、組織の生成AI活用・推進を自走するための仕組みづくり」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c71b18a520/_c71b18a520.jpg" alt="藤原 竜也.jpg" /></p>
<p>ソフトバンク株式会社
IT統括 AI&amp;データ事業統括部　Axross事業部 部長
藤原 竜也 氏</p>
<h3>Day2：AIを「つかう」——現場に効く、実践的なAI活用法</h3>
<p>「現場でどう使うのが効果的か？」を知りたい方に向けたプログラムです。現場導入の工夫やハマりがちな落とし穴まで、具体的なノウハウが得られます。</p>
<p>【対象】
・AIツールを現場の業務で活用したい方
・実務にすぐ役立つノウハウを知りたい方</p>
<p>【セミナー内容】
・業務シナリオ別のAIツール活用（生成AI・ルールベースAI）
・Excelや議事録、FAQ対応など、日常業務での実用ワーク
・プロンプトの書き⽅から社内導⼊のコツまで徹底解説</p>
<p>【ゲスト講演】
「まずは試してみよう！ 最新動向から学ぶ、生成AI活用の第一歩」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c4e70ae1da/_c4e70ae1da.jpg" alt="岡田隆太朗.jpg" /></p>
<p>一般社団法人日本ディープラーニング協会　
専務理事　
岡田 隆太朗 氏</p>
<h3>Day3：AIを「つくる」——AIプロダクト・自社専用AIツールの開発</h3>
<p>ノーコード/ローコードでのAI組み込みから、AI活用を前提としたインフラを含む環境構築、AIモデル開発など、AIの開発に必要な技術知識やノウハウを幅広く学ぶことができます。</p>
<p>【対象】
・ノーコード・ローコードでAIを組み込みたい方
・AIシステムの裏側やインフラにも関心がある方</p>
<p>【セミナー内容】
・生成AIアプリの基礎（RAG、Dify、API連携など）
・従来型AI（需要予測、分類モデルなど）の開発プロセス入門
・クラウド・ベクターデータベースなど、AI基盤技術の理解</p>
<p>【ゲスト講演】
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Zhan_Cliff_Chen_5c6864c871/Zhan_Cliff_Chen_5c6864c871.jpeg" alt="Zhan (Cliff) Chen.jpeg" />
マイクロソフト ディベロップメント株式会社
プリンシパル　アプライド　サイエンティスト
Zhan (Cliff) Chen / 陳 湛</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>こんな方におすすめ</h2>
<ul>
<li>企業のDX・AI導入担当者</li>
<li>生産性向上のためAIを活用したい事業部門マネージャー</li>
<li>ノーコードでのAI活用を始めたい開発初心者</li>
<li>最新AI技術のトレンドを押さえたいビジネスパーソン</li>
</ul>
<h2>イベント概要</h2>
<p>開催予定日時｜2025年9月24日(水)〜26日(金)
開催形式｜オンラインセミナー (Zoom Webinar)
想定集客規模｜500名
対象｜経営層 / システム企画 / DX推進 / 経営企画 / マーケティング / エンジニア
主催｜株式会社レッジ</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_m28c0ZHMSRiXQ-yrlcLXiw#/registration">▶【登録無料】視聴者向け事前登録はこちら</a>
:::</p>
<h2>「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様を募集中</h2>
<p>現在、この企画の開催趣旨にご賛同いただき、共に「Ledge.ai Webinar SP」を盛り上げていただけるスポンサー企業様も募集しております。</p>
<p>スポンサーとなっていただいた企業様には、AI業界のトップランナーの方々と共に当イベントの講師としてウェビナーにご登壇いただき、最新の取り組みやノウハウを発信していただきます。</p>
<p>また、その他にも、スポンサー企業様にも下記のようなメリットをご案内させていただきます。</p>
<h3>スポンサー参加の主なメリット</h3>
<ul>
<li>AI関連の情報感度の⾼い読者との接点が持てる</li>
<li>貴社の優位性をLedge.αiが引き出しながらPRできる</li>
<li>通常のLedge.ai広告メニューよりお得な価格で利⽤できる</li>
</ul>
<p>当イベントのスポンサーにご興味がございましたらぜひイベント資料をご覧ください。</p>
<p>:::button
<a href="https://forms.zohopublic.com/ledgeai/form/Ledgeai3/formperma/tJ1kpSYYWvDVF2Kp3xE-sBTiKeMh-7DlQZDoqXnSjtA">▶︎スポンサー様向けの資料はこちら</a>
:::</p>
<h2>お問い合わせ</h2>
<p>詳細相談・お見積もりは以下メールアドレスにお問合せください。
ld_media_sales@ledge.co.jp
（担当：Ledge.ai Webinar SP 事務局）</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NEC、暗黙知を学習し、Web上での業務を自動化するAIエージェント技術「cotomi Act」を発表──世界初、人間超え成功率80.4%を達成</title>
      <link>https://ledge.ai/articles/nec_cotomi_act_web_agent_implicit_knowledge</link>
      <description><![CDATA[<p>NECは2025年8月27日、Web上での業務を自動実行する新しいエージェント技術「cotomi Act（コトミ アクト）」を開発したと<a href="https://jpn.nec.com/press/202508/20250827_02.html">発表</a>した。人間の経験に基づく「暗黙知」をデータ化して学習・活用できる点が特徴で、世界的なベンチマーク「WebArena」において成功率80.4%を記録。従来の人間の成功率を上回り、世界初の成果だとしている。</p>
<h2>暗黙知を活用する新技術</h2>
<p>「cotomi Act」は、従来は人間が感覚的に行っていたWeb上の操作手順を「暗黙知」として捉え、形式知に変換したうえでAIに学習させる仕組みを採用する。これにより、自然文での指示を与えるだけで、Webブラウザ上での操作を自動化できる。</p>
<p><strong>cotomi Actの全体像</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2702_01_155328f13d/2702_01_155328f13d.png" alt="2702-01.png" /></p>
<h2>ブラウザ拡張で動作</h2>
<p>技術はブラウザ拡張機能として実装され、既存の業務環境に組み込みやすい点も特徴。これまで個別のシステムに依存していた自動化を、汎用的にWebサービス全体で可能にする。</p>
<p><strong>Webブラウザ拡張として動作するcotomi Actを利用して最新の情報を調査しチーム内に共有をする例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2702_02_ec74452fe2/2702_02_ec74452fe2.jpg" alt="2702-02.jpg" /></p>
<h2>世界初の人間超え</h2>
<p>評価には、Web業務自動化の国際的ベンチマーク「WebArena」が用いられた。テストの結果、cotomi Actは80.4%のタスク成功率を記録。NECによると、人間の成功率を初めて超えたエージェント技術であり、世界初の成果だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2702_03_c441a2bc6d/2702_03_c441a2bc6d.png" alt="2702-03.png" /></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2702_04_f6538ab081/2702_04_f6538ab081.png" alt="2702-04.png" /></p>
<h2>業務効率化と将来展望</h2>
<p>NECは、この技術により日常的なWeb業務やSaaS利用の自動化が進み、労働力不足の解消や業務効率化に貢献できるとしている。今後は生成AIプラットフォーム「cotomi」との連携を強化し、2026年度中のサービス提供を目指す方針だ。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、新プロジェクト「OpenAI for Science」を始動──GPT-5活用で科学的発見の加速へ</title>
      <link>https://ledge.ai/articles/openai_for_science_gpt5_scientific_discovery</link>
      <description><![CDATA[<p>OpenAIは、新プロジェクト「OpenAI for Science」を立ち上げ、AIを「次世代の偉大な科学機器」として活用する研究プラットフォームの構築に乗り出した。同社最高製品責任者（CPO）のKevin Weil氏が2025年9月6日（現地時間）、自身のX（旧Twitter）アカウントで<a href="https://x.com/kevinweil/status/1962938974260904421">明らかに</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Open_AI_for_Science_Kevin_weil_9e592d290b/Open_AI_for_Science_Kevin_weil_9e592d290b.jpg" alt="OpenAI for Science Kevin weil.jpg" /></p>
<p>Weil氏は「科学的発見は日常生活の質から国家安全保障、世界のGDPまであらゆる領域を改善する。イノベーションは米国が世界をリードしてきた理由であり、科学ほど人々の生活を向上させる可能性を秘めた領域は少ない」と強調。「OpenAI for Science」は、基礎研究を加速させるためのAI活用を目指すという。</p>
<p>同氏はまず、少数精鋭のチームを編成する方針を示した。採用条件として、世界的水準の専門性を持ち、AIに深く通じ、さらに科学コミュニケーション力に優れた研究者を挙げている。</p>
<h2>GPT-5の具体的な活用事例</h2>
<p>Weil氏は投稿の中で、次の例を紹介した。</p>
<ul>
<li><strong>数理最適化</strong> ：Sebastien Bubeck氏の凸最適化論文に関連し、GPT-5 Proが「17分の思考で50%の改善に到達」と紹介。</li>
<li><strong>量子場理論</strong> ：Mark Van Raamsdonk氏の論文<a href="https://arxiv.org/pdf/2508.21276v1">「Finite entropy sums in quantum field theory」</a>で、GPT-5が証明アウトラインや拡張提案を行った例を紹介。</li>
<li><strong>生命科学</strong> ：OpenAIとRetro Biosciencesの共同研究では、Yamanaka因子（SOX2/KLF4等）の再設計により、幹細胞リプログラミング・マーカーの発現が50倍超となったとOpenAI公式が報告。</li>
<li><strong>バイオ研究</strong> ：研究者DeryaTR氏が自身の生物学研究でGPT-5を活用し、研究の進展を加速。</li>
</ul>
<h2>背景にあるOpenAIの活動</h2>
<p>「OpenAI for Science」の構想を発表する以前から、同社は以下のような研究への取り組みを公表していた。
2025年6月18日：OpenAI公式ブログ「Preparing for future AI capabilities in biology」を<a href="https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/">公開</a>。生物学領域におけるAI活用の高度化に向けた安全・責任の方針を記載。
2025年8月22日：同じく公式ブログ「Accelerating life sciences research」を<a href="https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences/">公開</a>。Retro Biosciencesとの共同研究で、再設計したYamanaka因子がリプログラミング・マーカーの発現を50倍超に高めたことなどを報告。</p>
<h2>Weil氏の立場と組織体制</h2>
<p>Weil氏はCPOとしての職務を続けながら、研究者としても「OpenAI for Science」に関与するとしている。組織面では、Fidji Simo氏がCEO of Applicationsに就任し、アプリケーション領域の統括を担うことがOpenAIから発表されている。</p>
<h2>今後の展望</h2>
<p>「OpenAI for Science」の詳細は数カ月以内に共有予定とWeil氏は述べ、AIあるいはアカデミアの研究者に向けた参加呼びかけ（DM開放）にも言及した。AIを活用した基礎研究の加速が、今後どのようなブレークスルーにつながるか注目される。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スタンフォード大研究、AIで若手雇用13％減──ベテランは安定・成長傾向を「6つの事実」で提示</title>
      <link>https://ledge.ai/articles/stanford_ai_employment_six_facts</link>
      <description><![CDATA[<p>スタンフォード大学の研究チームは2025年8月、生成AIの普及が労働市場に与える影響をまとめた論文「Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence」を<a href="https://digitaleconomy.stanford.edu/publications/canaries-in-the-coal-mine/">公開</a>した。</p>
<p>ADPの給与データを用いた分析により、AIに最も曝露された職種で22〜25歳の雇用が平均13％減少していることが明らかになった。一方で、ベテラン層の雇用は安定、もしくは成長傾向を示しているという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/stanford_digital_economy_lab_e7d01c86ae/stanford_digital_economy_lab_e7d01c86ae.jpg" alt="stanford digital economy lab.jpg" /></p>
<h2>スタンフォード大が示した「6つの事実」</h2>
<p>研究チーム（エリック・ブリニョルフソン氏、ジグナシュ・チャンダル氏、ダニエル・チェン氏）は、2022年末から2025年7月までのADP高頻度給与データを用い、職種ごとのAI曝露度と雇用動向を分析。その結果を「6つの事実」として整理した。</p>
<h3>① 若手雇用の顕著な減少</h3>
<p>AIに最も曝露された職種、たとえばソフトウェア開発やカスタマーサポートなどでは、22〜25歳の雇用が平均で13％減少していた。研究チームは、この層がキャリアの早い段階にあり、主に定型的・マニュアル的な作業を担うことが多いため、AIによる自動化の影響を直接受けやすいと説明している。初期キャリアの雇用減は将来的なスキル蓄積やキャリア形成にも影響し得るため、社会的な含意は大きい。</p>
<h3>② 中堅層の安定</h3>
<p>同じ職種であっても、30代以降の労働者については雇用の変動が小さく、比較的安定していることが確認された。これは、一定の経験や専門性を積んだ中堅層が、AIと協働しながら業務を進められる立場にあることが理由とみられる。つまり、AIが即座に代替するのではなく、人間がAIを活用して付加価値を生み出す局面が増えているという。</p>
<h3>③ ベテラン層の成長傾向</h3>
<p>特に40代以上のベテラン層では、むしろ雇用が増加している職種も見られた。研究は、長年の経験から得られる「暗黙知」や現場の判断力はAIで代替できず、AIを補完的に活用することで生産性が高まり、雇用維持どころか拡大につながる場合があると指摘する。若手とは対照的に、ベテランはAIを味方につける形で市場価値を高めている構図が浮かび上がった。</p>
<h3>④ 賃金ではなく雇用数への影響</h3>
<p>AI導入によって顕著に減少しているのは「採用される人数」であり、賃金水準そのものには大きな変化は見られない。つまり、給与が下がるのではなく、そもそも新たに雇われる若手の数が減っているという。この「ヘッドカウントの削減」という動きは統計的にも明らかで、企業がAIを活用することで若手人材の需要を抑制していることを示している。</p>
<h3>⑤ 自動化用途での雇用減</h3>
<p>雇用への影響は、AIを「自動化のために導入するか」「人間の補助に使うか」で大きく分かれる。完全にAIに置き換える形で導入したケースでは若手雇用の減少が顕著だが、意思決定支援や作業補助といった「拡張（augmentation）」用途では、むしろ人材が維持されるか増える傾向がある。研究は、この違いを明確に示し、AIの使い方次第で雇用効果が大きく変わることを強調している。</p>
<h3>⑥ 他要因では説明困難</h3>
<p>テクノロジー業界に特有の景気循環や、コロナ禍以降のリモートワーク普及といった別の要因では、この世代間の差を説明できなかった。統計モデルを調整しても若手層の雇用減少が残ることから、研究チームはAIの影響が主要因である可能性が高いと結論づけている。つまり、この傾向は一過性の景気要因ではなく、AIが労働市場に構造的な変化をもたらしつつあることを裏付ける結果だといえる。</p>
<h2>世代間コントラスト──若手とベテランで異なる影響</h2>
<p>研究は、AIが「教科書的知識（codified knowledge）」に依存する業務を代替しやすく、経験に基づく「暗黙知（tacit knowledge）」を要する業務は代替が難しいと指摘。
そのため暗黙知の蓄積が乏しい若手は雇用リスクが高まり、経験を重ねたベテランはむしろAIの補完によって需要が高まるという世代間コントラストが浮かび上がった。</p>
<h2>社会的意義と政策的含意</h2>
<p>こうした傾向は「静かな侵蝕（quiet erosion）」とも呼ばれ、若手のキャリア形成機会が削がれる懸念がある。研究チームは、教育制度の刷新、リスキリングの推進、企業による採用や育成方針の見直しなどが必要になると指摘。炭鉱のカナリアにたとえられる今回の兆候は、今後さらに幅広い職種や世代に影響が及ぶ可能性を示唆している。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、製品実験プラットフォームStatsigを買収──創業者Raji氏がApplications部門CTOに就任</title>
      <link>https://ledge.ai/articles/openai_acquires_statsig_applications_cto_raji</link>
      <description><![CDATA[<p>OpenAIは2025年9月2日、製品実験プラットフォームを提供する米スタートアップのStatsigを買収すると<a href="https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig/">発表</a>した。取引の詳細は非公開だが、Statsigの創業者兼CEOであるVijaye Raji（ヴィジャイ・ラジ）氏が、OpenAIの「CTO of Applications」に就任する。今後はChatGPTを含むアプリケーション開発の統括を担う。</p>
<p>Statsigは2021年に設立され、A/Bテストや機能フラグ管理などを通じて、プロダクトチームが迅速に意思決定できる実験プラットフォームを提供してきた。顧客にはAtlassian、Notion、Brexなどが名を連ねる。買収後もStatsigはシアトル拠点で独立運営を続け、既存顧客へのサービス提供も継続するという。</p>
<p>OpenAIは今回の買収を通じ、モデル開発からアプリケーション展開へのシフトをさらに加速させる考えだ。Raji氏のリーダーシップのもと、Statsigのデータ駆動型アプローチを組み込むことで、ChatGPTなど主要製品の改善スピードと品質向上を狙う。
買収手続きは規制当局の承認を条件として完了する見込みだ。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「AIがAIを悪用する時代」──Anthropic、北朝鮮の雇用詐欺からランサムウェアまでClaudeの最新悪用事例を公表</title>
      <link>https://ledge.ai/articles/ai_misuse_anthropic_north_korea_ransomware</link>
      <description><![CDATA[<p>米AIスタートアップのAnthropicは8月、最新の脅威インテリジェンスレポート「Threat Intelligence Report: August 2025」を<a href="https://www.anthropic.com/news/detecting-countering-misuse-aug-2025">公開</a>し、同社のAIモデル「Claude」が悪用された複数のサイバー犯罪事例を明らかにした。公式YouTube動画では、脅威インテリジェンスチームが具体的な攻撃手口や検知の仕組みを解説している。</p>
<h2>北朝鮮の雇用詐欺、AIが「能力の幻想」を生む</h2>
<p>北朝鮮のIT人材は、偽の履歴書や職務経歴を用いて大手テクノロジー企業にリモート就業し、Claudeを利用して雇用を維持していた。かつては語学や高度な技術スキルを持つ人材のみが採用面接を突破していたが、現在ではスキルの乏しい個人でもAIの支援で「能力の幻想」を装えるようになっているとレポートは述べている。</p>
<p>Claudeは履歴書やカバーレターの作成、面接回答の生成、さらには基本的なプログラミングや業務ツールの操作方法まで代行。これにより、雇用者は実際には自力で作業できない労働者を採用してしまうケースが増加している。FBIは、これらの不正雇用によって年間数億ドル規模の資金が北朝鮮の兵器開発に流入していると評価している。</p>
<h2>「バイブハッキング」で17組織を同時攻撃</h2>
<p>動画で紹介された事例の一つが「バイブハッキング」だ。これは攻撃者が自然言語プロンプトを通じてAIにコードを生成させ、実際の不正活動を実行させる手法である。ある単独犯はClaudeを利用し、1か月で政府機関や医療機関、防衛請負業者、教会など17組織を標的にデータ恐喝を行った。</p>
<p>攻撃では、Claudeがネットワーク探索、横移動、機密データの窃取、恐喝状の作成まで担い、通常なら複数の犯罪者集団が数か月かける規模の作戦を一人で遂行可能にしたという。</p>
<p>@<a href="https://www.youtube.com/watch?v=EsCNkDrIGCw">YouTube</a></p>
<h2>RaaSからロマンス詐欺まで広がるAI悪用</h2>
<p>レポートと動画では他にも、さまざまなAI悪用の実態を明らかにしている。</p>
<ul>
<li><strong>ランサムウェア・アズ・ア・サービス（RaaS）</strong> ：英国人とされる開発者がClaudeを使って洗練されたランサムウェアを作成し、ダークウェブで販売。</li>
<li><strong>ロマンス詐欺ボット</strong> ：Telegram上のサービスにClaudeが「高EQモデル」として組み込まれ、数万人のユーザーが詐欺メッセージ作成に利用。</li>
<li><strong>中国語を話す攻撃者によるスパイ活動</strong> ：ベトナムの通信会社を標的に、Claudeを使ってネットワーク分析や攻撃戦略の立案を支援。</li>
</ul>
<h2>防御側もAIで対抗</h2>
<p>Anthropicは、北朝鮮のグループ「Contagious Interview」がClaudeを使おうとした際、同社の検知システムが即座にアカウントを遮断したと説明した。さらに、IPアドレスやメールアドレスといった技術的指標を政府・業界パートナーと共有し、防御網を強化している。
同社は「AIがAIを悪用する時代に対抗するには、AIでAIを守るパラダイムシフトが必要だ」と強調した。</p>
]]></description>
      <pubDate>Sun, 07 Sep 2025 02:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>