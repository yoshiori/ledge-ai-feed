<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>ビジネス2025/12/7 [SUN]Amazon、次世代LLM「Amazon Nova 2」発表　「思考」するProやマルチモーダルなど4モデル、独自フロンティアモデル構築「Nova Forge」Bedrockで提供開始</title>
      <link>https://ledge.ai/articles/amazon_nova_2_launch_four_models</link>
      <description><![CDATA[<p>Amazon Web Services（AWS）は2025年12月3日（現地時間）、米ラスベガスで開催中の年次開発者会議「AWS re:Invent 2025」において、次世代の大規模言語モデル（LLM）ファミリー「Amazon Nova 2」を<a href="https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models">発表</a>した。企業が自社専用のフロンティアモデルを構築できる新サービス「Nova Forge」や、ブラウザ操作を自動化する「Nova Act」もあわせて公開された。</p>
<p>同社が展開する生成AIサービス「Amazon Bedrock」を通じて、即日提供が開始されている。</p>
<h2>推論能力とコスト効率を大幅に強化</h2>
<p>「Amazon Nova 2」は、前世代モデルと比較して推論能力、処理速度、コストパフォーマンスのすべてにおいて大幅な進化を遂げている。特に、複雑なタスクを自律的に遂行する「AIエージェント」としての利用を想定し、文脈理解能力や論理的思考能力が強化された点が特徴だ。</p>
<p>今回発表されたラインナップは、用途に合わせて最適化された以下の4つのモデルで構成されている。</p>
<ul>
<li><strong>Amazon Nova 2 Pro</strong>  高度な推論（Reasoning）能力に特化した主力モデル。数学、コーディング、複雑な論理的推論において高い性能を発揮する。「思考プロセス」を強化しており、難解な指示に対しても正確な回答を生成可能だ。</li>
<li><strong>Amazon Nova 2 Lite</strong>  応答速度とコスト効率を最優先した軽量モデル。リアルタイム性が求められるチャットボットや、大量の文書要約・データ処理タスクに適しており、軽快な動作が特徴である。</li>
<li><strong>Amazon Nova 2 Omni</strong>  テキスト、画像、音声、ビデオをネイティブに理解・生成できるマルチモーダルモデル。従来のモデルのようにデータをテキストに変換する工程を経ず、複数の異なる入力情報を同時に、かつシームレスに処理することができる。</li>
<li><strong>Amazon Nova 2 Sonic</strong>  音声対話に特化したモデル。極めて低い遅延（ローレイテンシー）での音声入力・出力が可能で、人間と話しているかのような自然なリアルタイム対話を実現する。</li>
</ul>
<h2>ベンチマークでは「同等またはそれ以上」と説明</h2>
<p>Amazon は、Nova 2 Pro とNova 2 Lite について、Claude、GPT、Gemini 系列の競合モデルと公開ベンチマークで比較し、多くの指標で「equal or better（同等またはそれ以上）」と説明した。対象となったのは、マルチドキュメント分析、動画推論、複雑な指示のフォロー、高度な数学的推論、ソフトウェアエージェントタスクなど。また、Pro はより小型モデルへの知識蒸留にも利用できるとしている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nova2_pro_lite_bench_3863cb81b0/nova2_pro_lite_bench_3863cb81b0.jpg" alt="nova2 pro lite bench.jpg" /></p>
<h2>企業が自社専用モデルを構築できる「Nova Forge」</h2>
<p>同日発表された Nova Forge は、企業が自社データを使って Nova ベースの独自フロンティアモデル「Novellas」を構築できる「open training」アプローチを採用したサービス。事前学習・中間学習・事後学習の各段階における Nova のチェックポイントを使い、企業固有のドメイン知識を深く反映したモデルを構築できるとしている。</p>
<p>Reinforcement Learning（RL）による強化学習環境、責任ある AI のためのツールキット、小型高速モデル生成のための蒸留機能なども提供される。Booking.com、Reddit、Sony などが活用を進めている事例として紹介された。</p>
<h2>ブラウザ操作を自動化する「Nova Act」</h2>
<p>もう一つの新サービス Nova Act は、ブラウザ UI 上の操作をエージェントが代行するためのサービスだ。数百のシミュレーション環境で強化学習を行い、CRM 更新や E2E テスト、保険請求フォームの送信などの UI ワークフローを自動化する。早期導入企業では約90％の成功率を達成したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_c39392cc36/1_c39392cc36.gif" alt="ダウンロード (1).gif" /></p>
<h2>Bedrock で提供、開発者向けポータルも公開</h2>
<p>Nova 2 の各モデルは Amazon Bedrock で利用可能となり、API 経由でアプリケーションへの統合が行える。Nova Forge で構築した企業専用モデル「Novellas」も同様に Bedrock 上で運用できる。</p>
]]></description>
      <pubDate>Sun, 07 Dec 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/7 [SUN]「心の中の声」をAIが文字に変換　米研究チーム、脳活動から直接文章を生成する新技術「BIT (BraIn-to-Text)」発表</title>
      <link>https://ledge.ai/articles/brain_to_text_inner_speech_decoder</link>
      <description><![CDATA[<p>コロンビア大学やスタンフォード大学などの研究者らによるチームは2025年11月21日、脳の活動データを直接テキストに変換する新しいAIフレームワーク「BIT (BraIn-to-Text)」を<a href="https://arxiv.org/abs/2511.21740v1">発表</a>した。</p>
<p>このシステムは、発声しようとした言葉だけでなく、声を出さずに心の中で唱えた「内なる声（inner speech）」も一定の精度で文章化できることを示した。従来の類似手法と比べ、単語誤り率（WER）を24.69％から10.22％へと半分以下に抑えた点が特徴で、麻痺などによって話すことが難しい人のコミュニケーション支援技術としての応用も期待される。</p>
<p>なお、研究で使用されたのはUtahアレイと呼ばれる脳表面に埋め込む侵襲型電極であり、非侵襲の脳波（EEG）とは異なる。</p>
<h2>脳波を「音声」と見なしてLLMが解読</h2>
<p>従来の脳内音声解読システム（BCI）では、多くが「脳活動 → 音素 → 単語 → 言語モデル」という複数段階の“カスケード型”処理を採用していた。この構造では、各工程が独立しているため、システム全体をまとめて最適化できない点が課題とされていた。</p>
<p>今回発表された「BIT」は、脳活動の特徴を捉えるTransformerエンコーダーと、大規模言語モデル（LLM）を結合させたEnd-to-End型（統合的最適化）フレームワークである。</p>
<p>ヒトやサルの脳活動データ約367時間分を用いて事前学習を行い、神経活動のパターンから直接テキストを生成する。この仕組みにより、従来必要だった音素への変換ステップを省き、脳活動から直接文章を出力できるようになった。</p>
<p><strong>図1：BIT（BraIn-to-Text）フレームワークの全体構成</strong>
脳に埋め込んだ電極から取得した神経活動をAIが処理し、最終的に文章として出力するまでの流れを示す図。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_11_017e439017/x1_11_017e439017.png" alt="x1 (11).png" /></p>
<h2>単語誤り率を大幅に低減</h2>
<p>このEnd-to-Endのアプローチによる精度の変化について、論文では以下の数値が報告されている。従来の同様のシステムと比較し、単語の読み取りミスを示す「単語誤り率（WER）」は低下した 。</p>
<ul>
<li><strong>従来のEnd-to-End手法</strong> ： 単語誤り率 24.69%</li>
<li><strong>新技術「BIT」（音声LLM統合版）</strong> ： 単語誤り率 10.22%</li>
</ul>
<p>さらに、脳活動エンコーダーを用いて「Brain-to-Text Benchmark」に参加したところ、カスケード型設定を含む全カテゴリで最も低い誤り率を記録した。</p>
<p>アンサンブル（複数モデル併用）設定でのWERは以下の通りである。</p>
<ul>
<li><strong>Brain-to-Text '24 ベンチマーク</strong> ： 単語誤り率 5.10%</li>
<li><strong>Brain-to-Text '25 ベンチマーク</strong> ： 単語誤り率 2.21%</li>
</ul>
<p><strong>図2：BITの性能比較と解読例</strong>
従来手法と比較した誤り率の低減、および実際に生成された文章の例を示す図。内言においても意味的に近い文章を生成できている点が示されている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_8f9b3b00ac/x2_8f9b3b00ac.png" alt="x2.png" /></p>
<h2>「想像発話」の読み取りにも成功</h2>
<p>研究では、筋肉を動かして発話しようとする「試行発話（attempted speech）」だけでなく、声を出す動作を伴わずに頭の中で言葉を思い浮かべる「想像発話（imagined speech）」のデータセットを用いた検証も行われた。</p>
<p>解析の結果、実際に話そうとする時と心の中で話す時の脳内活動には、共通する意味的構造が存在することが示唆された。AIはこの共通性を利用することで、データの少ない想像発話においても文章変換を可能にしている。</p>
<p><strong>図3：音声LLMとの比較──脳活動の文章化に適したモデル</strong>
複数の音声LLM・テキストLLMを比較し、どのモデルが脳活動からの文章生成に適しているかをまとめた図。音声を扱う小規模モデルが高い適性を示した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x3_4_7cc8f5e441/x3_4_7cc8f5e441.png" alt="x3 (4).png" /></p>
<h2>話せない人のコミュニケーション支援へ</h2>
<p>発話が困難なALS患者や脳損傷患者にとって、頭の中で言葉を思い浮かべるだけで意思を伝えられる技術は大きな可能性を持つ。</p>
<p>論文では、将来的な臨床応用を見据えつつ、次のような課題を整理している。</p>
<ul>
<li>神経信号の非定常性への適応</li>
<li>電極の長期安定性</li>
<li>オンデバイス実行に向けた効率化</li>
</ul>
<p>また、特に内言の解読は倫理的に慎重な扱いが求められ、研究チームも「利用者の明確な同意を欠いた読心的用途は許されない」と明記している。</p>
<h2>今後の展望──神経データ版“基盤モデル”へ</h2>
<p>BITで用いられたNeural Encoderは、サルを含む多様な神経活動から学習されている。論文では、近年さまざまな分野で「foundation models」と呼ばれる大規模事前学習モデルが提案されていることを紹介し、こうした方向性がBCIの性能向上にも有効である可能性を挙げている。</p>
<p>研究チームは、今後の課題として、電極の非定常性への適応、長期的な記録の安定性、インターフェースの効率化などを明確にし、改善を重ねることで「ユーザーとシステムが互いに適応しながら利用可能な、より柔軟なBCIの開発につながる」とまとめている。</p>
]]></description>
      <pubDate>Sun, 07 Dec 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Runway、新モデル「Gen-4.5」公開──リアル物理・精密カメラワークを実現　動画AIで世界最高Elo 1247　Veo 3・Sora 2を圧倒</title>
      <link>https://ledge.ai/articles/runway_gen_4_5_release</link>
      <description><![CDATA[<p>AI動画生成企業 Runway は12月1日、次世代動画モデル「Runway Gen-4.5」を<a href="https://runwayml.com/research/introducing-runway-gen-4.5">発表</a>した。同社によると、物理挙動の再現精度、プロンプト追従性、カメラワークの精密さが大幅に向上しており、動画生成AIのベンチマーク「Artificial Analysis」Text-to-Video リーダーボードで Elo 1247 を記録。Googleの「Veo 3」やOpenAIの「Sora 2 Pro」など、主要モデルを上回る世界最高スコアとなった。</p>
<p>Runwayは公式リリースで、Gen-4.5を「動画モデルの新たな基盤（foundation model）」と位置づけている。開発コードネームは「Whisper Thunder（David）」。研究段階から推論まで、すべての工程を NVIDIA GPU 上で実施し、Blackwell/Hopper 世代向けに最適化されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=ei2PsDpPbB4">YouTube</a></p>
<h2>複雑なカメラワーク・構図理解が大幅に向上</h2>
<p>Gen-4.5は、複雑なカメラの移動、複数要素が連続して発生する構図、シーン内の細かなイベント進行などを単一プロンプトで制御可能となった。
Runwayは「細かいカメラの振り、構図の変化、時間経過による変化まで正確に理解する」と説明している。</p>
<h2>物理再現性は「重さ」「質感」「自然な動き」を強化</h2>
<p>新モデルでは、物体の重量感・慣性・表面反射・素材感などの物理表現が精密化。風・煙・水の挙動など、自然現象の再現精度も向上した。同時に、物理法則を遵守する演出だけでなく、クリエイターが意図的に“非現実的な世界”を作る演出も柔軟に実行できる。</p>
<h2>世界最高スコア：Elo 1247、他社を大きくリード</h2>
<p>Runwayが公開したベンチマークでは、Gen-4.5は Elo 1247 を記録し、主要動画生成モデルを上回った。</p>
<ul>
<li>Runway Gen-4.5：1247</li>
<li>Google Veo 3：1226</li>
<li>Kling 2.5：1225</li>
<li>Veo 3.1：1223</li>
<li>OpenAI Sora 2 Pro：1206</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gen_4_5_chart_revised_01_1077109527/gen_4_5_chart_revised_01_1077109527.jpg" alt="gen-4.5-chart-revised-01.jpg" /></p>
<p>動画生成AIの性能を示す指標として注目されるEloスコアで、Runwayは明確な優位性を示した。</p>
<h2>NVIDIAと全面協業、最適化された推論パイプライン</h2>
<p>Gen-4.5は研究・前処理・後処理・推論まで、全工程を NVIDIA GPU 上で構築。NVIDIAのJensen Huang CEOは以下のコメントを寄せている。</p>
<p>「Runwayが NVIDIA GPU 上で革新的な動画・ワールドモデルを構築したことを誇りに思う。AIの全ライフサイクルを共に前進させるため、協業を続ける」</p>
<h2>既存のコントロールモードも統合予定</h2>
<p>Gen-4.5では、Text-to-Videoに加えて以下の機能が順次統合される予定だ。</p>
<ul>
<li>Image to Video</li>
<li>Video to Video</li>
<li>Keyframes</li>
<li>その他の既存コントロール機能</li>
</ul>
<p>プロ向けの高度なワークフローを支える構造となっている。</p>
<h2>透明性として「現状の限界」も明示</h2>
<p>Runwayは、Gen-4.5において依然として課題が残る点も公開している。
因果関係の理解が不完全
物体恒常性（object permanence）の失敗ケース</p>
<p>これらの改善を今後の「world modeling」の重要テーマと位置づけ、継続して研究を進めると説明した。</p>
<h2>数日以内に全ユーザーへ提供開始</h2>
<p>Gen-4.5は段階的にロールアウトが始まっており、数日以内にRunwayのユーザー全体へ展開される予定。Gen-1、Gen-2、Gen-3から続く進化の集大成として、Runwayは「新しい動画生成の標準点をつくる」としている。</p>
]]></description>
      <pubDate>Sat, 06 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/6 [SAT]「AIバブルではない」が…IBM CEO、AGI開発への世界全体のコミットメント100ギガワット分のデータセンター投資に「採算が合わない」と警告</title>
      <link>https://ledge.ai/articles/ibm_ceo_ai_datacenter_investment_bubble_warning</link>
      <description><![CDATA[<p>AI企業の間で、生成AIや将来のAGI（汎用人工知能）を見据えた大規模データセンター投資が加速している。だが、こうした巨額投資が現在のコスト構造のままで採算を取れるのかについて、警鐘を鳴らす声が上がった。IBMのCEO兼会長であるアーヴィンド・クリシュナ氏は2025年12月3日、The Vergeのポッドキャスト番組「<a href="https://www.theverge.com/podcast/829868/ibm-arvind-krishna-watson-llms-ai-bubble-quantum-computing">Decoder</a>」に出演し、AI向けデータセンター投資のリターンは「現状では見込めない」と述べた。</p>
<h2>巨額のデータセンター投資「100ギガワット＝8兆ドル」</h2>
<p>クリシュナ氏は、AI開発企業が進めるデータセンター増設について、1ギガワット規模を「埋める」ためには約800億ドルの設備投資（CapEx）が必要になると説明した。さらに、世界のAI企業全体でみれば、AGI開発を念頭に置いたコミットメントは約100ギガワットに達しており、「総額では約8兆ドルを投じる計算になる」と指摘した。</p>
<p>そのうえで、「この投資が企業に十分な利益として戻ってくる可能性は低い」と述べ、投資回収は極めて難しいとの見方を示した。</p>
<h2>GPUは5年で陳腐化、光ファイバーとは異なる「短命な資産」</h2>
<p>背景には、AI計算基盤の中核となるGPUなどの半導体が短期間で陳腐化するという事情があるという。クリシュナ氏は、こうしたハードウェアは5年程度で入れ替えが必要になると説明し、長期的に価値が残りやすい光ファイバー網などのインフラとは性質が異なると述べた。</p>
<p>100ギガワット級のAIデータセンターには膨大な資金が必要であり、その利払いだけでも莫大な額に達することから、「現在のAIサービスの単価と需要の伸び方では、採算が合うとは考えにくい」と語った。</p>
<h2>「AIバブルではない」が…一部資本は「回収されない」</h2>
<p>ポッドキャストでは「AIはバブルなのか」という問いも投げかけられた。クリシュナ氏はこれを否定し、「AIバブルではない」と述べた。ただし、一部の資本については「回収されないものが出る」とも指摘した。</p>
<p>特に、巨額の債務を用いてAIインフラに投資するケースでは、収益化の不透明さから返済困難に陥る可能性があるという。消費者向けAIプラットフォーム市場には勝者総取りに近い構造があり、多くの企業が参入しているが、最終的に利益を得られるのは少数にとどまるとの見方を示した。</p>
<h2>企業向けAIには期待──年間4000億〜7000億ドル規模の価値</h2>
<p>一方で、企業向けの生成AI活用については比較的明るい見通しも語った。コンサルティング企業による試算では、エンタープライズ分野だけでも年間4000億〜7000億ドル規模の価値が見込めると説明し、その20〜30%をテクノロジー企業が吸収できる可能性があると述べた。</p>
<p>AGIについては「現在のLLM技術だけで到達できる確率は0〜1%」と評価し、既存技術の延長線では限界があるとの認識を示した。</p>
<h2>IBMは「watsonx」と量子コンピューティングに軸足</h2>
<p>クリシュナ氏は、IBMが企業向けAIプラットフォーム「watsonx」や量子コンピューティングに長期的な重点を置いていることにも触れた。これらは短期で急拡大するAIインフラ投資とは異なる性質を持ち、企業の生産性向上や高難度計算の領域で継続的な需要が見込まれるという。</p>
]]></description>
      <pubDate>Sat, 06 Dec 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/5 [FRI]AWS、自社開発AIチップ「Trainium3 UltraServer」を一般提供開始──3nmプロセス×144チップ構成で大規模AIの学習・推論を高速化</title>
      <link>https://ledge.ai/articles/trainium3_ultraserver_ga_announcement</link>
      <description><![CDATA[<p>米Amazon傘下のAmazon Web Services（AWS）は2025年12月3日（現地時間）、年次イベント「AWS re:Invent 2025」で、自社開発AIチップ「Trainium3」を搭載する大規模AI向け統合システム「Amazon EC2 Trn3 UltraServer（以下、Trainium3 UltraServer）」の一般提供（GA）を開始したと<a href="https://www.aboutamazon.com/news/aws/trainium-3-ultraserver-faster-ai-training-lower-cost">発表</a>した。</p>
<p>システムは3ナノメートルプロセスで製造したTrainium3を最大144基搭載でき、前世代（Trainium2 UltraServer）と比較して計算性能は最大4.4倍、メモリ帯域とエネルギー効率は約4倍に向上したという。</p>
<h2>最大362 FP8 PFLOPS、最大144チップ構成の新AIサーバー</h2>
<p>Trainium3 UltraServerはFP8精度で最大362 PFLOPSの演算性能を発揮し、1筐体に最大144基のTrainium3チップを搭載できる。メモリ帯域は合計706 TB/s、HBMメモリ容量は最大20.7 TBとなり、大規模言語モデル（LLM）やマルチモーダルモデルの学習・推論向けに最適化されているという。</p>
<p>AWSは、OpenAIのオープンウェイトモデル「GPT-OSS」を用いた社内テストでは、1チップあたりのスループットが3倍、推論レイテンシが4倍高速化したと説明している。</p>
<h2>新ネットワーク基盤「NeuronSwitch-v1」やUltraClusters 3.0で大規模化に対応</h2>
<p>Trainium3 UltraServerには、AWSが新たに開発したネットワークスイッチ「NeuronSwitch-v1」が搭載され、チップ間の通信帯域は前世代と比較して2倍になった。また、新たな「Neuron Fabric」により、チップ間通信の遅延は10マイクロ秒未満に抑えられるという。</p>
<p>複数のUltraServerを接続するクラスタ構成「EC2 UltraClusters 3.0」では、最大100万基のTrainiumチップまでスケール可能とされ、大規模データセットを用いたモデル学習や、数百万規模の同時推論リクエストにも対応できるとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=4y3pMGIS6DU">YouTube</a></p>
<h2>既に複数企業が活用、高速化やコスト削減の事例も</h2>
<p>AWSは複数の顧客事例を紹介しており、AnthropicやKarakuri、Metagenomi、NetoAI、Ricoh、Splash Musicなどが、Trainiumシリーズを用いてトレーニングコストを最大50％削減したという。また、生成系スタートアップのDecartは、Trainium3を用いたリアルタイム動画生成により、フレーム生成が4倍高速化し、GPU比でコストを半減できたとしている。</p>
<p>さらに、AWSの生成AI基盤「Amazon Bedrock」では、Trainium3上で既に本番ワークロードが稼働している。</p>
<h2>次世代「Trainium4」ではNVIDIA NVLink Fusionにも対応予定</h2>
<p>AWSは、次世代AIチップ「Trainium4」の開発も進めていると公表した。現時点で示されている目標値は、FP4で6倍以上、FP8で3倍の性能向上、メモリ帯域4倍の拡張など。さらに、Trainium4はNVIDIAの新インターコネクト技術「NVLink Fusion」に対応予定で、NVIDIA GPUと共存するラックスケール構成が可能になるとしている。</p>
<h2>大規模AIインフラの「選択肢」を拡大</h2>
<p>AWSは、Trainium3 UltraServerの提供開始により、生成AIやエージェント型AI、Mixture-of-Expertsモデルなどの大規模ワークロードに対し、高速・低コストで提供できる選択肢を拡大したと説明した。今後もTrainiumシリーズとGPUの双方をサポートする方針を示しており、用途に応じた柔軟なAIインフラ構成が可能になるという。</p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Workspace Studio」を一般提供──Gemini 3世代のAIでGmail・Drive向けエージェントを構築可能に</title>
      <link>https://ledge.ai/articles/google_workspace_studio_general_availability</link>
      <description><![CDATA[<p>Googleは2025年12月4日（現地時間）、Google Workspace上でAIエージェントを構築・管理できる新ソリューション「Google Workspace Studio」を一般提供したことを<a href="https://workspace.google.com/blog/product-announcements/introducing-google-workspace-studio-agents-for-everyday-work?hl=en">発表</a>した。同サービスは、アルファ版としてテストされていた「Google Workspace Flows」を発展させたもので、GmailやDrive、Docsなど、日常的に利用されるWorkspaceアプリにAIエージェントを直接組み込める点が特徴となる。</p>
<p>Workspace Studioは、ノーコード／ローコードでエージェントの設計が可能で、繰り返し作業の自動化や文書作成、メール対応の支援、ファイル整理、レポート生成など、多様な業務フローをAIに任せられる。構築したエージェントは組織内で共有でき、管理者はアクセス権限や利用状況を細かくコントロールできる。</p>
<p>また、StudioはGoogleの最新AI技術と連携しており、Gemini 3世代のモデル群による自然言語処理や推論能力を活用したワークフロー構築が可能になった。公式ブログでは、FlowsからStudioへの進化点として、より柔軟で複雑な業務プロセスを扱えるエージェント設計機能、視覚的に操作できる新UI、管理者向け機能の強化が挙げられている。</p>
<p>GoogleはWorkspace Studioについて、「日常業務の中にAIエージェントを組み込み、生産性向上を支える基盤」と位置づける。今回の一般提供により、企業は業務プロセスにAIを本格的に統合しやすくなり、Google WorkspaceにおけるAI活用の幅が大きく拡張されることになる。</p>
<p>@<a href="https://www.youtube.com/watch?v=Xy0r5fKwlVo">YouTube</a></p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ARグラスだけで2D→3D変換を実現　新モデル「XREAL 1S」ーーXREAL、日本先行で予約受付を開始　2026年1月下旬発売へ</title>
      <link>https://ledge.ai/articles/xreal_1s_2d_to_3d_ar_glasses_launch</link>
      <description><![CDATA[<p>XREALは12月1日、新型ARグラス「XREAL 1S」を<a href="https://prtimes.jp/main/html/rd/p/000000226.000070978.html">発表</a>し、同日より日本で予約受付を開始した。発売は2026年1月下旬を予定。日本がグローバルで初の発表および予約開始地域となる。価格は6万7,980円（税込）。</p>
<p>同製品は、ARグラス単体で2D映像を3D映像へリアルタイムに変換し、空間上に大画面として表示できる点が最大の特徴。映画や動画コンテンツを、スマートフォンやPCを接続せずに立体化できる「空間ディスプレイ」として機能するという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/70978_226_48b718eda105e60902793c5b6cd42fec_2475x2475_3ec3f53823/70978_226_48b718eda105e60902793c5b6cd42fec_2475x2475_3ec3f53823.webp" alt="70978-226-48b718eda105e60902793c5b6cd42fec-2475x2475.webp" /></p>
<p>XREAL 1Sは映像の立体化に加え、高輝度ディスプレイや装着性の向上を図った設計を採用。長時間利用を前提とした軽量化も進められている。XREALの周辺機器やエコシステムとの連携にも対応し、今後の拡張にも備えたモデルとなる。予約はXREAL公式ストアなどで受け付けており、発売は2026年1月下旬を予定している。</p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>デジタル庁、プリファードの国産LLM「PLaMo翻訳」をガバメントAIに導入──12月に庁内利用開始、2026年から他府省へ展開</title>
      <link>https://ledge.ai/articles/digital_agency_plamo_translation_government_ai_launch</link>
      <description><![CDATA[<p>デジタル庁は2025年12月2日、Preferred Networks（PFN）が開発する日本語特化型の国産LLM「PLaMo翻訳」をガバメントAI環境「源内（げんない）」に導入し、政府職員向けに提供すると<a href="https://www.digital.go.jp/news/b27d1af7-c231-4ab3-ad78-fc5408d44504">発表</a>した。2025年12月中にデジタル庁内での利用を開始し、2026年以降は他府省庁への展開を計画する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image_12_5c1580a084/image_12_5c1580a084.png" alt="image(12).png" /></p>
<p>「源内」は、政府職員がセキュアな環境で生成AIを業務利用できるよう整備が進められているガバメントAI基盤で、デジタル庁では2025年5月から全職員向けに提供してきた。今回の「PLaMo翻訳」導入は、国内開発AIを行政実務で活用する取り組みの一環として位置付けられる。</p>
<p>PFNの「PLaMo翻訳」は、日本語と英語の翻訳に特化した国産大規模言語モデルで、長文でも自然で一貫性のある文章を生成できる点を特長とする。ニュース記事や行政文書、会話文など幅広い文体に対応し、和文の自然さを損なわずに翻訳できるよう最適化されている。デジタル庁は、行政実務における翻訳業務の効率化につながるモデルとして活用を進める。</p>
<h2>ガバメントAIで試用する国内開発AIモデルの公募も</h2>
<p>同日、デジタル庁は「ガバメントAIで試用する国内大規模言語モデル（LLM）の公募」も<a href="https://www.digital.go.jp/news/1b093bba-a4c8-4001-8a92-ff3667a69198">開始</a>した。対象は国内で開発されたLLMや特定領域向けのSLM（Small Language Model）で、ガバメントクラウド上で安全に動作できることが条件となる。公募期間は2025年12月2日から2026年1月30日まで。選定されたモデルは、2026年夏頃から「源内」上で試験的に利用される予定だ。</p>
<p>2026年度には「源内」の他府省庁展開が予定されており、評価結果や各府省庁のニーズを踏まえ、2027年度以降に国内LLMの本格導入が検討される。</p>
]]></description>
      <pubDate>Fri, 05 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>国税庁、AI活用で追徴税額3,811億円──法人税・消費税は3,407億円で直近10年最高に</title>
      <link>https://ledge.ai/articles/nta_ai_tax_audit_2024_3811oku</link>
      <description><![CDATA[<p>国税庁は2025年12月2日、2024事務年度（令和6事務年度、2024年7月〜2025年6月）の「法人税等の調査事績の概要」を<a href="https://www.nta.go.jp/information/release/kokuzeicho/2025/hojin_chosa/index.htm">発表</a>した。</p>
<p>法人税・法人消費税の追徴税額は3,407億円となり、直近10年で最高額を記録した。また、源泉所得税の追徴税額404億円と合わせると、3税目の合計は3,811億円となった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c3345ac9f5/_c3345ac9f5.jpg" alt="追徴税額の推移　法人税消費税.jpg" /></p>
<p>資料では、調査先の選定にあたり「AIも活用しながら、あらゆる機会を通じて収集した資料情報等や申告書の分析・検討を行う」と明記。調査必要度の高い法人を的確に抽出し、実地調査を実施したとしている。</p>
<p>実地調査件数は5万4,000件（前年比▲7.4%）と減少した一方、1件当たりの追徴税額は増加した。法人税・消費税の追徴税額は、令和2事務年度の2,157億円から増加基調が続いており、令和6事務年度は3,407億円に達した。</p>
<p>重点分野として、国税庁は消費税還付申告法人、海外取引法人、無申告法人を挙げている。源泉所得税では、調査件数1万1,700件、追徴税額404億円（前年比＋20.5%）と、給与・報酬などの源泉徴収漏れに関する指摘が増えた。</p>
<p>国税庁は2023年に示した「税務行政の将来像」において、AIやデータ分析を活用した調査先選定やリスク分析の高度化を掲げている。今回公表された事績では、実地調査件数を抑制しつつ追徴税額を高水準で維持しており、AI活用を含む調査の効率化が進んだ形となった。</p>
]]></description>
      <pubDate>Thu, 04 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AppleのAI戦略トップ、ジョン・ジャナンドレア氏が退任へ──後任にMicrosoft出身のアマル・スブラマニヤ氏、副社長としてAI部門を統括</title>
      <link>https://ledge.ai/articles/apple_ai_leadership_change_giannandrea_subramanya</link>
      <description><![CDATA[<p>Appleは2025年12月1日（現地時間）、機械学習およびAI戦略担当シニアバイスプレジデント（SVP）を務めるジョン・ジャナンドレア氏が職務を退き、2026年春の退職までアドバイザーとして同社に残ると<a href="https://www.apple.com/newsroom/2025/12/john-giannandrea-to-retire-from-apple/">発表</a>した。
同時に、MicrosoftやGoogleでAI研究を率いてきたアマル・スブラマニヤ氏が「Vice President of AI（AI担当副社長）」としてAppleに加わったことも明らかにした。</p>
<h2>ジャナンドレア氏は2026年春までアドバイザーに就任</h2>
<p>発表によると、ジャナンドレア氏はAIおよび機械学習戦略の中核としてAppleの活動を牽引してきたが、今回の人事にともないSVP職を離れ、退職までアドバイザーとして移行する。2018年に同社へ加わって以降、世界規模のAI・MLチームの構築や主要機能の開発を主導してきた人物で、Appleはその貢献を評価している。</p>
<h2>後任スブラマニヤ氏、Foundation ModelsやAI安全性評価を統括</h2>
<p>後任としてAppleに参加したアマル・スブラマニヤ氏は、Craig Federighi氏（ソフトウェアエンジニアリング担当シニアバイスプレジデント）の直属となる。同氏は、新役職「Vice President of AI」として、Apple Foundation Models、機械学習研究（ML Research）、AI Safety and Evaluationの3領域を率いる。</p>
<p>スブラマニヤ氏は、直前までMicrosoftでCorporate Vice President of AIを務め、さらに以前には16年にわたりGoogleに在籍。Google退任時には「Google’s Gemini Assistant」のエンジニアリング責任者を務めるなど、AIの基盤研究と製品統合の双方に実績を持つ。</p>
<h2>AI組織の一部はKhan氏・Cue氏の管掌へ</h2>
<p>Appleは今回の人事に合わせ、AI組織の一部を再編する。ジャナンドレア氏が担当していた領域のうち、Foundation Models、ML Research、AI Safety and Evaluationはスブラマニヤ氏が引き継ぎ、それ以外の組織は以下の担当に移る。</p>
<ul>
<li>Sabih Khan氏（オペレーション担当シニアバイスプレジデント）</li>
<li>Eddy Cue氏（サービス担当シニアバイスプレジデント）</li>
</ul>
<p>Appleは、この組織再編について「類似する部署とのアラインメントを高めるため」と説明している。</p>
<h2>Cook氏とFederighi氏「AIはApple戦略の中心」</h2>
<p>リリースでは、Tim Cook氏（CEO）とCraig Federighi氏によるコメントも紹介された。</p>
<p>Cook氏は、ジャナンドレア氏の貢献を称えたうえで「AIは長年にわたりAppleの戦略の中心であり続けている」と強調。また、スブラマニヤ氏がAIの専門性をAppleにもたらすことを歓迎すると述べた。</p>
<p>Federighi氏は、来年提供予定の「よりパーソナライズされたSiri」への取り組みを含め、AI機能の監督範囲が拡大することに触れつつ、スブラマニヤ氏の参加によりAI技術の進展をさらに加速させるとコメントした。</p>
<p>Appleは今回の発表を「新しい章の始まり」と位置づけ、信頼性が高く、より個別化された体験を提供する次世代AI技術の開発を強化する姿勢を示している。</p>
]]></description>
      <pubDate>Thu, 04 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国DeepSeek、GPT-5級「DeepSeek-V3.2」をオープンウェイト公開──エージェント向け“推論ファースト”モデル、Gemini 3.0 Pro並み「Speciale」も</title>
      <link>https://ledge.ai/articles/deepseek_v3_2_and_speciale_release_agent_reasoning_model</link>
      <description><![CDATA[<p>中国のAI開発企業 DeepSeek は2025年12月1日、推論モデル「DeepSeek-V3.2」と、高推論版「DeepSeek-V3.2-Speciale」を<a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2">発表</a>した。</p>
<p>同社はモデルの重みを公開するオープンウェイト戦略をとっており、今回のV3.2シリーズでは、AIエージェントの自律的なタスク遂行に必要な「思考力」を重視する“推論ファースト（Reasoning-first）”アーキテクチャを採用した。テックレポートによれば、V3.2は米OpenAIの次世代モデル「GPT-5」と同等レベル、V3.2-SpecialeはGoogleの「Gemini 3.0 Pro」と同等レベルの推論性能を示したとしている。</p>
<h2>エージェントのための「推論ファースト」設計</h2>
<p>今回発表されたDeepSeek-V3.2シリーズ最大の特徴は、AIエージェント運用への特化だ。単にテキストを生成するだけでなく、外部ツールを使いこなし、複雑な手順を計画（プランニング）する能力を重視して設計されている。</p>
<p><strong>DeepSeek-V3.2の推論プロセス。ツール呼び出し（Tool call）の前に「思考（Thinking）」フェーズを挟み、エラー修正やプランニングを行ってから外部ツールを実行する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FE_Nmjb_YA_Ak_Er8_2ee1c0d55d/G7_FE_Nmjb_YA_Ak_Er8_2ee1c0d55d.jpg" alt="G7FENmjbYAAkEr8.jpg" /></p>
<ul>
<li><strong>DeepSeek-V3.2（GPT-5級の汎用フラッグシップ）</strong> ：従来のLLMが苦手としていた「行動前の深い思考」を推論プロセスとしてモデル内部に組み込んだ。Thinkingモードとツール呼び出しを組み合わせることで、曖昧な指示からでも意図を汲み取り、自己修正を行いながらタスクを遂行できると説明している。</li>
<li><strong>DeepSeek-V3.2-Speciale（Gemini 3.0 Pro相当の高計算版）</strong> ：同一アーキテクチャをベースに、より長い内部思考トークンを許容することで推論性能を最大化したバリアント。高難度の推論タスクや数学・情報オリンピック級の問題を想定した設計で、API限定（ツール呼び出しなし）で提供される。</li>
</ul>
<h2>GPT-5、Gemini 3.0に肉薄するベンチマーク結果</h2>
<p>DeepSeekが公開した技術レポートによると、両モデルの「推論」および「エージェント挙動」に関する主要指標は以下の通りだ。</p>
<p><strong>主要モデルとの性能比較。青色がDeepSeek-V3.2シリーズ。推論能力（Reasoning Capabilities）およびエージェント能力（Agentic Capabilities）で、GPT-5 HighやGemini 3.0 Proと同等、あるいは一部で上回るスコアを記録した</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_F_Dq18a_MAAW_Wvh_8707e4f698/G7_F_Dq18a_MAAW_Wvh_8707e4f698.jpg" alt="G7FDq18aMAAWWvh.jpg" /></p>
<p><strong>複雑な推論 (MATH / GPQA)</strong> ： V3.2-Specialeは、数学コンテストAIME 2025やHMMT、国際数学オリンピック（IMO）相当問題、競技プログラミングのCodeforcesレーティングなどで高いスコアを記録した。AIMEではGPT-5 High（94.6）を上回る96.0という結果が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FD_7c_Kb_UA_Au_Ja_A_f096df59f1/G7_FD_7c_Kb_UA_Au_Ja_A_f096df59f1.jpg" alt="G7FD7cKbUAAuJaA.jpg" /></p>
<p><strong>エージェント性能（τ²-Bench / MCP-Universe / Tool-Decathlonなど）</strong> ： API操作やマルチターンでのタスク解決能力を測る各種ベンチマークでは、V3.2がClaude 4.5 SonnetやGPT-5 Highと比較可能な数値を示した。Thinkingプロセスを導入したことで、ツールの選択ミスや引数の誤りが減少する傾向があるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G7_FECX_Kbc_AA_8stm_0446319143/G7_FECX_Kbc_AA_8stm_0446319143.jpg" alt="G7FECXKbcAA8stm.jpg" /></p>
<p>一方で、テクニカルレポートは制約や課題についても言及する。DeepSeek は、総学習FLOPsの観点から、V3.2は依然としてGemini 3.0 Proなどのクローズドモデルに比べ世界知識の幅で劣ること、同等の品質を出すためにより多くのトークンを必要とするなど「トークン効率」の面で課題が残ること、複雑なタスクの一部では最先端モデルに及ばないことを挙げ、今後の改善余地があるとまとめている。
今回の公開により、DeepSeekは「Reasoning-first models built for agents」というコンセプトのもと、GPT-5級の推論性能とエージェント向け設計を兼ね備えたオープンモデルを前面に打ち出したかたちだ。V3.2はコスト効率と汎用性を重視した日常利用向けモデルとして、Specialeは競技レベルの高難度タスクに向けた高計算版として位置付けられている。</p>
<h2>オープンモデルとコストパフォーマンス</h2>
<p>DeepSeekは、V3.2およびV3.2-Specialeのモデル重みをHugging Face等でMITライセンスのもと公開しており、ローカル環境やオンプレミスでの構築も可能としている。またAPI価格については、同社の従来モデルからの値下げや、長文入力でもコストを抑えられる設計を打ち出している。</p>
<p>V3.2-Specialeは、https://api.deepseek.com/v3.2_speciale_expires_on_20251215 という一時的なエンドポイントを通じて提供され、2025年12月15日15時59分（UTC）まで利用可能となる。その後は通常の提供形態に統合される予定だとしており、期間中はV3.2と同一価格で高推論版を試せる。</p>
<p>高度な推論能力と比較的低い利用コストを両立したオープンモデルとして、今後、AIエージェントの実運用にどの程度採用が進むかが注目される。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アリババ、初のAIスマートグラス「Quark AI Glasses」発売──S1/G1の2モデルで同社製LLM「Qwen」を直接使える日常デバイスに</title>
      <link>https://ledge.ai/articles/alibaba_quark_ai_glasses_launch_china</link>
      <description><![CDATA[<p>アリババは2025年11月27日（現地時間）、同社として初となるAI搭載スマートグラス「Quark AI Glasses」シリーズを<a href="https://www.alizila.com/alibaba-launches-new-quark-ai-glasses-series-in-china-deeply-integrated-with-qwen/">発表</a>した。アリババの大規模言語モデル「Qwen」およびAIアプリ「Qwen App」と深く統合し、音声と視覚を組み合わせたリアルタイムAIアシスタントを提供する。シリーズは、ディスプレイ搭載のフラグシップモデル「S1」と、軽量で普段使いに適した「G1」の2モデル構成となる。</p>
<h2>QwenとQuark Appを統合、音声・視覚を組み合わせたAIアシスタントに対応</h2>
<p>Quark AI Glassesは、アリババが開発する大規模言語モデル「Qwen」とAIアプリ「Qwen App」を標準搭載し、音声操作や視界上への情報提示を通じて、AIアシスタント機能を直接メガネ型デバイスで利用できる。外出先でのリアルタイム翻訳や、会議・講義内容の文字起こし、リマインダー設定、ナビゲーション、周辺スポット検索、ショッピング支援といった多様な機能に対応する。</p>
<p>また、アリババグループのサービスとも連携しており、決済のAlipay（支付宝）、地図サービスのAmap（高徳地図）、ECサービスのTaobao（淘宝）、旅行サービスFliggy（飛猪）なども利用できる。中国の音楽ストリーミングサービス（QQ Music、NetEase Cloud Music）にも対応した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55/bf1ef6c08mf1fb9c98a8d6dd8bbbe8de_342c2a7c55.jpeg" alt="bf1ef6c08mf1fb9c98a8d6dd8bbbe8de.jpeg" /></p>
<h2>フラグシップモデル「S1」──交換式デュアルバッテリーで最大24時間使用可能</h2>
<p>S1はデュアルマイクロOLEDディスプレイを搭載し、視界内に情報をオーバーレイ表示できる。骨伝導技術やデュアルチップ構成を採用し、音声入出力やリアルタイム処理性能を強化した。</p>
<p>特徴的な点として、交換可能なデュアルバッテリーシステムを採用し、最大24時間の利用を可能としている。また、0.6秒で撮影できるインスタントフォト機能や、3K動画撮影およびAIによる4K動画出力、独自技術「Super Raw」による夜間撮影性能の向上など、撮影機能も強化されている。価格は3,799元（約7万8,000円）から。</p>
<h2>軽量モデル「G1」──約40gで普段使いに最適、コアハードウェアはS1と共通</h2>
<p>G1は日常の利用を想定した軽量モデルで、重量は約40gに抑えられている。ディスプレイ以外の主要ハードウェア（処理チップ、オーディオ、カメラなど）はS1と共通で、普段使いしやすいデザインと価格帯を重視している。価格は1,899元（約3万9,000円）から。</p>
<h2>MCP対応で開発者エコシステムも視野に</h2>
<p>Quark AI Glassesは、外部システムやアプリケーションと双方向に接続するオープン標準「Model Context Protocol（MCP）」に対応する。これにより、開発者がQuark AI Glasses向けのAIアプリやエージェントを拡張しやすくなり、アリババのQwenエコシステムとの連携も強化される。</p>
<p>市場調査会社<a href="https://www.idc.com/promo/wearablevendor/">IDC</a>の調査によると、2025年第2四半期の世界ウェアラブルデバイス出荷台数は前年同期比9.6％増の1億3,650万台で、このうち約5,000万台が中国を中心とする地域から出荷されている。中国は現在、世界最大のウェアラブル市場であり、AI搭載デバイス分野における競争も激しさを増している。</p>
<p>Quark AI Glassesシリーズは、アリババのAIモデルQwenとグループのサービス群、そしてMCPによる拡張性を組み合わせることで、同市場における新たな製品ポジションを獲得する構えだ。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon Prime VideoのAI生成吹き替え「AI beta」版、配信から削除へ──NAVAと声優陣が『BANANA FISH』などのAI版に抗議</title>
      <link>https://ledge.ai/articles/amazon_prime_video_ai_english_dub_end</link>
      <description><![CDATA[<p>Amazon Prime Videoが、一部アニメ作品で導入していたAI生成吹き替え「AI beta」版を、12月初旬までに相次いで削除していたことが分かった。Anime News Network（ANN）が2025年12月3日に<a href="https://www.animenewsnetwork.com/news/2025-12-03/amazon-streamed-ai-english-dubs-on-banana-fish-no-game-no-life-zero-pet-anime/.231513">報じた</a>もので、削除は段階的に進んだとされる。</p>
<p>ANNによると、Prime Video上では『BANANA FISH』『No Game, No Life Zero』『Pet』『Journal of the Mysterious Creatures』の英語・ラテンアメリカスペイン語吹き替え、さらに『Vinland Saga』のラテンアメリカスペイン語吹き替えが「AI beta」と表示されていた。『BANANA FISH』と『No Game, No Life Zero』のAI版吹き替えは12月3日までに削除され、『Pet』『Journal of the Mysterious Creatures』のAI英語吹き替えは3日時点で残っていたが4日までに削除された。『Vinland Saga』のラテンアメリカスペイン語版も4日までに削除が確認された。</p>
<p>Amazonは2025年3月5日付の公式ブログ記事で、英語とラテンアメリカスペイン語を対象とする「AI-aided dubbing（AI支援吹き替え）」パイロットプログラムの開始を<a href="https://www.aboutamazon.com/news/entertainment/prime-video-ai-dubbing-english-spanish">発表</a>している。同記事はAmazon Staff名義で公開され、Prime VideoおよびAmazon MGM Studiosのテクノロジー担当バイスプレジデントであるRaf Soltanovich氏は、AI支援吹き替えについて「既存の吹き替えが存在しない作品にのみ提供する」と説明していた。</p>
<p>一方でANNは、『No Game, No Life Zero』にはSentai Filmworksが制作した既存の英語吹き替えがあり、HIDIVEが2024年5月から配信していたことを指摘。ANNはPrime Video版の「AI beta」吹き替えが、同作の既存吹き替えとはキャスト・音声が異なることを確認した。ANNによれば、Prime Video版のエンドクレジットにはSentai Filmworks制作のキャスト・スタッフが記載されたままだった。</p>
<p>SNS上での反発も大きかった。全米声優協会・NAVA（National Association of Voice Actors）は公式Xアカウント（@NAVAVOICES）で声明を投稿し、Amazonには本来「本物のストーリーテリング」や「感情的なつながり」を持つ吹き替えを制作する機会があったにもかかわらず、『BANANA FISH』『Vinland Saga』『No Game No Life』で「AI slop dubs」を選んだと批判。「侮辱的」「敬意を欠いている」との声が多いと訴えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/NAVA_1_86f4ec1597/NAVA_1_86f4ec1597.jpg" alt="NAVA1.jpg" /></p>
<p>声優からの抗議も相次いだ。ANNの記事は、Daman Mills氏、Kara Edwards氏、Nick Huber氏、Dawn M. Bennett氏ら複数の声優がSNSで『BANANA FISH』のAI版吹き替えに対し懸念を表明したと伝えている。Mills氏は自身のX投稿を通じ、AI吹き替えによって作品や声優の価値が損なわれるとの立場を示した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Daman_Mills_x2_ee9a1bd260/Daman_Mills_x2_ee9a1bd260.jpg" alt="Daman Mills x2.jpg" /></p>
<p>ANNが権利元へ取材したところ、Kadokawaは『No Game, No Life Zero』のAI吹き替えについて「AI吹き替えをいかなる形でも承認していない」と回答。Sentai Filmworks／HIDIVEの関係者は「事前に知らされていなかった」とし、「Amazonと状況を確認している」と述べた。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国研究者、台湾上空でStarlink通信を遮断するシミュレーションを実施──最大2000機のドローンなどによる電子妨害が必要と試算</title>
      <link>https://ledge.ai/articles/china_starlink_jamming_simulation_taiwan</link>
      <description><![CDATA[<p>中国と台湾の緊張が続くなか、中国本土の研究者が「台湾上空でStarlink通信網を妨害する」大規模電子戦シミュレーションを実施したと、香港紙<a href="https://www.scmp.com/news/china/science/article/3333523/chinese-researchers-simulate-large-scale-electronic-warfare-against-elon-musks-starlink">サウスチャイナ・モーニング・ポスト（SCMP）</a>が2025年11月23日に報じた。</p>
<p>研究チームは、台湾と同規模の約3.6万平方キロメートルの領域を対象に、1000〜2000機規模の通信妨害装置（ジャマー）を上空に展開することで、Starlinkネットワークを一時的に抑圧できる可能性があると試算している。</p>
<p>SCMPが確認したのは、中国語の専門誌『系统工程与电子技术（Systems Engineering and Electronics）』に掲載された論文で、中国の軍事工学研究者らが作成したもの。同紙によると、研究者はウクライナ戦争でStarlinkが通信インフラとして軍事作戦を支え続けたことを受け、台湾有事などを想定した電子戦の可能性を分析したという。</p>
<p>Starlinkは、高度約550kmの低軌道衛星が多数稼働し、自律的に接続先を切り替えるメッシュ型ネットワークを形成している。このため、地上からの単一の妨害では通信を完全に遮断することが難しいとされる。研究チームはそこで、航空機・気球・ドローンなどの空中ジャマー（通信妨害装置）を広範囲に配置する方式を検証し、一定高度で密度の高い妨害グリッドを形成することで、特定エリアのStarlink通信を抑圧できる可能性が示された。</p>
<p>米技術メディアの<a href="https://www.tomshardware.com/networking/china-simulated-a-starlink-blockade-over-taiwan-ccp-scientists-say-around-1-000-drones-would-be-enough-to-cut-satellite-internet-to-the-island">Tom’s Hardware</a>は、論文のシミュレーション条件を詳細に紹介している。それによれば、ジャマーは高度約20kmに展開し、3〜6マイル間隔で配置することで“電磁シールド”のような妨害グリッドを形成する必要があるとされる。また、高出力装置を搭載した航空機を使う場合は約935ノードで足りる一方、小型ドローンなどの低出力ジャマーでは1000〜2000ノードが必要になるという。</p>
<p>ただし、数千機規模の空中ジャマーを台湾上空に長時間展開し続けるには、燃料・整備・指揮統制・対空防衛への対応など、多くの運用上の課題が伴う。複数の報道でも、今回の内容はあくまでもシミュレーション研究であり、実際に中国が同規模の演習を行った証拠は確認されていない。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>KDDI、人間のチャット応対を学習するAIエージェントを開発──回答精度90％、auサポート窓口で運用開始</title>
      <link>https://ledge.ai/articles/kddi_human_chat_learning_ai_agent_release</link>
      <description><![CDATA[<p>KDDIとKDDI総合研究所は2025年11月26日、チャットサポート窓口で人間の応対履歴を学習し、高精度で再現するAIエージェントを開発したと<a href="https://www.kddi-research.jp/newsrelease/2025/112601.html">発表</a>した。</p>
<p>複数の応対事例を構造化し、追加情報の収集とファクトチェックを組み合わせる世界初の技術により、生成AIにおけるハルシネーションを抑制し、約90％の回答精度を実現したという。すでにauチャットサポート窓口の一部応対拠点で運用が始まっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kddi_nr_850_4231_img_02_9afe639a8d/kddi_nr_850_4231_img_02_9afe639a8d.png" alt="kddi_nr-850_4231_img_02.png" /></p>
<p>近年、従来のシナリオ型チャットボットでは対応が難しい複雑な問い合わせが増加しており、難易度の高い案件は人手による対応が必要だった。今回開発されたAIエージェントは、過去の適切な応対事例を複数抽出し、応対の流れを構造化したうえで、必要に応じて社内マニュアルから追加情報を収集し、内容の整合性を自動でチェックする仕組みを備える。このプロセスを経て応答文を生成することで、誤情報の生成を抑えつつ、実務に適した応対品質を確保するという。</p>
<p>KDDIによると、問い合わせ1件あたりの応対時間は従来比で約70％短縮できる見込みで、スタッフ間の応対品質の均一化にもつながると説明している。今回の技術は汎用パッケージとして開発されており、社内でのユースケース拡大やグループ会社への横展開に加え、将来的な商用提供も視野に入れている。</p>
<p>KDDI総合研究所は、応対の構造化や事例選択手法などに関する特許を10件以上登録済または出願済としており、今後も応対領域の拡大を進める方針を示している。両社は、AI技術の社会実装とお客さま応対の品質向上を通じ、カスタマーサポート体験の改善に取り組んでいくとしている。</p>
<p>:::box
<a href="https://ledge.ai/articles/deloitte_global_contact_center_survey2023">関連記事：国内コンタクトセンターすでに半数がAI導入、海外上回るも成果には課題あり</a>
::</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>2025年のAIニュース振り返りと、AI提唱70周年となる2026年の展望を知る特設サイトLedge.ai年末年始特集「&apos;25 to &apos;26」を公開</title>
      <link>https://ledge.ai/articles/ledgeai25to26</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も参加費無料の年末特集「Ledge.ai '25to'26」を公開しました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>Ledge.ai年末年始特集「'25 to '26」とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。</p>
<p>そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。ぜひご登録の上、隅々までご覧ください。参加費は無料です。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>コンテンツラインナップ</h2>
<h3>【編集部コンテンツ】2025年のAI振り返りと70周年に向けた展望</h3>
<p>Ledge.ai編集部が独自に企画・編集した記事および特集記事を掲載。
企業動向の背景にある文脈や業界のキーパーソンの言葉を通じて、AI活用を進めるヒントとして、ぜひご一読ください。</p>
<p><strong>\u003Cテーマ：AIの70年\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_image_f12dd17c93/ai70th_image_f12dd17c93.png" alt="ai70th-image.png" /></p>
<p><strong>\u003CLedge.ai 2025年注目ニュース総まとめ\u003E</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai2025news_b7d5ecf93f/ai2025news_b7d5ecf93f.png" alt="ai2025news.png" /></p>
<p>Ledge.aiが発信してきた記事の中から、特に注目すべきトピックをキーワードごとに厳選してお届けします。これらの記事を並べて読むだけでも、2025年のAIトレンドの全体像が浮かび上がってくるはずです。 2025年の振り返りとして、今読むべきランドマーク的な記事をまとめています。ぜひ、業界動向の整理や次のアクションの参考としてご活用ください。</p>
<h2>【特別インタビュー】キーパーソンが語るAIの過去・現在・未来</h2>
<p>本特集では、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいました。</p>
<h2>【トップランナー企業動向】AI周辺で押さえておきたい最新技術と実践事例</h2>
<p>国内外の注目企業をピックアップし、AI基盤、エージェント活用、自動運転データなど、世界最先端の動向を徹底分析します。</p>
<h3>必読の深い知見が得られる取材記事を、公開期間中に次々と発信</h3>
<ul>
<li>AIの進化を支え続けるNVIDIAの羅針盤／エヌビディア合同会社</li>
<li>「言語の壁」は、もはやイノベーションの言い訳にならない。／DeepL Japan</li>
<li>生成AI時代、GPUのオルタナティブ──AMDは今どこを見据えているのか／Advanced Micro Devices, Inc.</li>
<li>基盤モデルとの融合はロボットに何をもたらすのか／Coming soon…</li>
<li>『PLURALITY』の実践と、多元的協働社会への道筋／サイボウズ株式会社 代表取締役社長 青野 慶久 氏</li>
<li>AIを「使わないことが最大のリスク」― AIエージェント時代の企業ガバナンス新常識／弁護士 柴山 吉報 氏</li>
</ul>
<p>:::button
<a href="https://25to26.ledge.ai/">特集サイトはこちら</a>{target=_blank}
:::</p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25 to '26」
開催期間　：2025年12月1日～2026年1月9日
開催形式　：オンライン
参加費　　：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ　：contact@ledge.co.jp</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>note、AIアシスタントに「Gemini 3 Pro」を導入──メモ段階から構成・言い換えまで執筆支援を強化</title>
      <link>https://ledge.ai/articles/note_gemini3pro_ai_assistant_update</link>
      <description><![CDATA[<p>note株式会社は2025年12月2日、同プラットフォームのAIアシスタントに Google の最新生成AIモデル「Gemini 3 Pro（プレビュー版）」を導入したと<a href="https://note.jp/n/n655ea4dcd39a">発表</a>した。アイデアの断片やメモ段階の入力から文章構成の提案、言い換え、表現改善まで、執筆プロセス全体を支援する機能が拡充される。</p>
<p>noteは「誰もが創作をはじめ、続けられるようにする」ことをミッションに掲げており、AIアシスタント機能はその一部として提供されてきた。従来も文章の書き出しや言い換え提案などが可能だったが、今回のアップデートにより、文章構成や着想の深掘りなど、より幅広い工程をサポートするようになった。</p>
<p><strong>AIアシスタント利用シーンの一例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1764577930_Zqk8_D_Hr_R_Pma3_Gg_Mf_EY_2_Qxb_Vw_1_88e9b02458/1764577930_Zqk8_D_Hr_R_Pma3_Gg_Mf_EY_2_Qxb_Vw_1_88e9b02458.webp" alt="1764577930-Zqk8DHrRPma3GgMfEY2QxbVw (1).webp" /></p>
<p>Gemini 3 Pro の導入により以下の機能が強化されたという。</p>
<ul>
<li>メモやアイデア断片から記事構成案や書き始めを生成</li>
<li>文章のリライト（言い換え・簡潔化・読みやすさ改善）</li>
<li>表現の調整や文章の要約</li>
<li>思考の深掘りや視点の追加提案</li>
</ul>
<p>noteは、AIアシスタントを利用することで「書きたいテーマはあるが、何から書けばよいか分からない」といった初期段階の課題に対応できるとしている。「AIが持つアイデア着想力や書き出しのサポートは、執筆に不慣れなユーザーの負担を軽減する」と説明する一方、生成内容への依存を避け、創作の主体はあくまでユーザー自身である点への注意も呼びかけている。</p>
<p>AIアシスタントは投稿画面から利用でき、文章やメモを入力することで提案内容が生成される。利用は無料で、今後は品質改善やガイドライン整備などを継続していくとしている。</p>
<p>noteは今回のモデル刷新により、執筆支援機能を強化し、より多様な創作者が利用しやすい環境づくりを進めている。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、ChatGPT品質改善に全集中「非常事態（code red）」宣言──CEOサム・アルトマン氏が他社LLMの進化に危機感で社内指示</title>
      <link>https://ledge.ai/articles/openai_chatgpt_code_red_improvement_directive</link>
      <description><![CDATA[<p>米テック系メディア The Information は2025年12月1日（米国時間）、OpenAIのCEOであるサム・アルトマン氏が社員向けの社内メモで 「code red（非常事態）」を宣言し、ChatGPTの改善を最優先するよう指示した と<a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort">報じた</a>。</p>
<p>同メディアによると、アルトマン氏はメモで、ChatGPT の 速度、応答品質、信頼性、パーソナライズ性 を中心に改善を加速する必要性を強調。社内リソースの再配分を求め、他のプロジェクトについては一部を延期または凍結する方針を示したという。</p>
<p>この報道を受け、Reuters は「The Information reported on Monday」として<a href="https://www.reuters.com/business/media-telecom/openai-plans-improve-chatgpt-delay-initiatives-such-advertising-information-2025-12-02/">記事</a>を配信し、広告導入や新規イニシアティブの遅延が検討されている点を伝えた。Bloomberg も同内容を紹介しつつ、OpenAIがChatGPTの改善に社内資源を集中させる状況を説明した。また、Wall Street Journal（WSJ） は独自に社内メモを確認したとし、日次の進捗チェックやチーム再配置など、運用上の詳細を補足している。</p>
<h2>競争激化で「ChatGPTそのもの」の品質が問われる局面に</h2>
<p>背景には、競合AIモデルの性能向上がある。とくに Google が開発する最新モデル「Gemini 3」は、複数のベンチマークで高い評価を受けており、AIチャット領域で OpenAI の優位性を揺るがしつつあると報じられている。こうした状況の中で、OpenAI 内部では ChatGPT を巡る競争が一段と厳しくなっているとの見方が、主要メディアの報道で広がっていた。</p>
<p>OpenAI はここ数ヶ月、広告テストやショッピング支援など新機能の展開を準備していたが、今回の「code red」宣言によって、同社が 短期的な新機能追加よりも、ChatGPTそのものの品質改善を優先課題に据えた ことが示されたかたちだ。
現時点で、OpenAI は code red 宣言について公式の声明を発表していない。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本の大手3社、AI検索「Perplexity」に一斉抗議──共同・毎日・産経が著作権侵害と虚偽表示を指摘、47NEWSに数十万回アクセスも</title>
      <link>https://ledge.ai/articles/perplexity_japan_media_protest_20251201</link>
      <description><![CDATA[<p>2025年12月1日、共同通信社、毎日新聞社、産業経済新聞社（産経新聞）は、米Perplexity AIが提供するAI検索サービス「Perplexity」に対し、それぞれ抗議書を送付したと発表した。いずれの会社も、自社記事が許諾なく収集・複製され、回答生成に利用されていると主張している。3社の発表時点で、Perplexity AIによる今回の抗議書に関する公式コメントは確認されていない。</p>
<h2>共同通信社──47NEWSに数十万回のアクセス、虚偽表示も指摘</h2>
<p><a href="https://www.kyodonews.jp/information/ai.html">共同通信社</a>は、配信記事が掲載されているニュースサイト「47NEWS」について、2024年8月以降に数十万回のアクセスが確認されたと説明し、これがPerplexityによる記事収集に関連するとしている。同社は、許諾なく記事を複製・利用する行為は著作権法違反に当たると指摘した。</p>
<p>また、Perplexityが共同通信の社名や記事を表示しながら、記事内容と異なる情報を提示する事例が確認されたとし、こうした表示が不正競争防止法の問題に該当する可能性を示している。</p>
<p>抗議書では、記事の即時利用停止、収集データの開示、無断利用に対する損害賠償などを求めている。共同通信加盟48紙も同日、無断収集・利用に抗議する声明を発表した。</p>
<h2>毎日新聞社──robots.txt無視、ゼロクリック問題を懸念</h2>
<p><a href="https://www.mainichi.co.jp/info/20251201.html">毎日新聞社</a>は、同社のサーバー解析結果として、遅くとも2024年7月以降、記事数十万本が許諾なく収集されたと説明している。同社は、robots.txtを用いた取得拒否設定を行っていたが、Perplexityがこれを無視したとしている。</p>
<p>同社は、行為が著作権法21条（複製権）および23条（公衆送信権）の侵害に当たると主張。さらに、回答画面に毎日新聞の名称や記事を出典として表示しながら、内容と異なる事実が提示されるケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、経緯の報告、損害賠償の支払いを求めており、通知後14日以内の回答を求めている。</p>
<h2>産経新聞社──PerplexityとPro双方での無断利用を指摘</h2>
<p><a href="https://www.sankei.jp/wp-content/uploads/2025/12/2025.12.01-%E7%94%9F%E6%88%90AI%E4%BA%8B%E6%A5%AD%E8%80%85%E3%81%B8%E3%81%AE%E6%8A%97%E8%AD%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6.pdf">産経新聞</a>は、Perplexityおよび「Perplexity Pro」サービスにおいて、自社ニュースサイト「Sankei News」や「Sanspo」に蓄積した記事が無断で複製され、回答生成に利用されていると説明している。</p>
<p>同社は、これらの行為が著作権法21条および23条の侵害に当たると主張。記事内容と異なる情報を示しながら、産経新聞社の名称や記事を出典として表示するケースがあるとし、不正競争防止法2条1項21号への抵触を指摘している。</p>
<p>抗議書では、無断利用の停止、関連データの削除などを求めている。</p>
<p>日本の報道機関とPerplexityをめぐっては、2025年8月以降、読売新聞グループ、日本経済新聞社、朝日新聞社などが、記事の無断利用をめぐる損害賠償を求めて提訴している。新聞協会も、ニュースコンテンツの無断取得に関する声明を公表している。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIをよく使う人は「活発で外向的」──NTTドコモ モバイル社会研究所、若年層では“心配性ゆえの不安”も</title>
      <link>https://ledge.ai/articles/genai_user_extroversion_docomo_survey_2025</link>
      <description><![CDATA[<p>NTTドコモ モバイル社会研究所は12月1日、2025年2月に実施した「生成AI利用意識・行動調査」をもとに、生成AIの利用頻度と性格特性の関係を分析した結果を<a href="https://www.moba-ken.jp/project/lifestyle/20251201.html">発表</a>した。</p>
<p>調査対象は全国の15〜69歳男女7,527人で、性別・年齢・都道府県の人口構成比に合わせたクォータサンプリングによるWeb調査として実施された。</p>
<p>今回のレポートでは、生成AIを「知っている」人を対象に、利用頻度と自己評価による性格特性の関係を可視化している。分析の結果、生成AIをよく利用する人ほど「活発で、外向的だと思う」「新しいことが好きで、変わった考えをもつ」と回答する割合が高いという傾向が確認された。一方、生成AIに強い不安を抱く人では「心配性で、うろたえやすいと思う」と自己評価する人が多く、特に若年層でこの傾向が強く見られたという。</p>
<h2>生成AIヘビーユーザーは「活発で外向的」</h2>
<p>レポートでは、生成AI利用頻度と「活発で、外向的だと思う」という自己評価の関係を整理している。利用頻度が高くなるほど、外向的と答える割合が一貫して高まる結果となった。研究所は、外向的な人ほど人との交流を楽しむ傾向があり、その中で生成AIを積極的に活用している可能性を指摘する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_01_341ad1f8bb/20251201_01_341ad1f8bb.png" alt="20251201_01.png" /></p>
<h2>新しい技術に積極的な“好奇心の強さ”</h2>
<p>続いて、「新しいことが好きで、変わった考えをもつと思うか」という設問でも、同様の傾向が示された。生成AIをよく利用する人ほど、新しい技術を試したいという意識が強く、好奇心の高さが利用を後押ししていることがうかがえるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_02_d63049b9c1/20251201_02_d63049b9c1.png" alt="20251201_02.png" /></p>
<h2>不安の強い層には「心配性」の傾向</h2>
<p>一方で、生成AIに対して「不安を感じている」「やや不安を感じている」と回答した人の割合が高い層では、「心配性で、うろたえやすい」と自己評価する人が多いことも明らかになった。図3-1では、不安度が高い層ほど心配性の自己評価が高いという関係が示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_03_01_3975f7c305/20251201_03_01_3975f7c305.png" alt="20251201_03-01.png" /></p>
<p>また、性年代別に見ると、若年層ほど「心配性である」と回答する割合が高い傾向もみられた。同研究所はこれまでの調査でも「若年層は生成AIへの期待が高い一方、不安も高い」ことを報告しており、今回の分析では、その背景の一因として“心配性の高さ”が示されたとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251201_03_02_0c19752d1b/20251201_03_02_0c19752d1b.png" alt="20251201_03-02.png" /></p>
<h2>過去調査とのつながり</h2>
<p>モバイル社会研究所はこれまでにも生成AIに関する認知、利用実態、不安に関する複数の調査結果を公表している。2025年8月の調査では、生成AIに「不安を感じる」とした人が全体の29％に上り、特に10代でその割合が高いことを示していた。今回の性格特性の分析は、こうした利用者の態度形成をより深く理解する追加データとして位置づけられている。</p>
<p>同研究所は、生成AIの基礎理解や利用方法を学べる「ドコモスマホ教室」などの取り組みも継続しており、AI活用に関するリテラシー向上施策を進めている。</p>
]]></description>
      <pubDate>Wed, 03 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが図表や文書を“読めるデータ”に──パナソニックとUCLA、拡散モデルを用いた視覚言語モデル「LaViDa」を発表　生成速度は自己回帰型VLMの約2倍に</title>
      <link>https://ledge.ai/articles/panasonic_lavida_diffusion_vlm_release</link>
      <description><![CDATA[<p>パナソニックは2025年11月27日、米カリフォルニア大学ロサンゼルス校（UCLA）の研究者らと共同で、拡散モデルを活用した新しい視覚言語モデル（VLM）「LaViDa」を開発したと<a href="https://news.panasonic.com/jp/press/jn251127-2">発表</a>した。LaViDaは、従来主流だった自己回帰型手法と同等の精度を保ちつつ、文章生成を約2倍に高速化できるという。</p>
<h2>拡散型言語モデルを採用したLaViDaの仕組み</h2>
<p>LaViDaは、画像とテキストを同時に扱うマルチモーダルAIで、言語生成に拡散モデルを用いる点に特徴がある。従来の視覚言語モデルは、文章を1語ずつ生成する自己回帰型手法を採用しており、テキストが長くなるほど推論速度が低下する課題があった。</p>
<p>拡散モデルでは、マスクされた語を“段階的に復元”する形で文章を生成でき、ステップ数を調整することで高速化が可能になる。</p>
<p><strong>LaViDaの全体構造。複数の画像ビューをエンコードし、拡散型言語モデルが段階的にテキストを復元する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_2e3471c0d9/x2_2e3471c0d9.jpg" alt="x2.jpg" /></p>
<p>LaViDaは、Prefix-DLMと呼ばれる効率化手法も採用し、画像やプロンプトに関連する領域だけを参照することで、計算量を抑えながら推論を行えるようになっている。</p>
<h2>図表や文書を“構造化データ”へ出力できる LaViDa の特性</h2>
<p>LaViDaは、文章生成だけでなく、図表・画像の内容を JSON 形式などの「構造化データ」に変換する能力を持つ。これにより、これまで「画像として扱われていた報告書内の図表」などを、AIエージェントが直接処理しやすい形に変換できる。</p>
<p><strong>LaViDaのフォーマット制約に沿った生成例（左）と画像分類をJSON形式に構造化した例（右）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub5_3368e7e69a/sub5_3368e7e69a.jpg" alt="sub5.jpg" /></p>
<p>このように LaViDa は、</p>
<ul>
<li>指定形式の詩生成</li>
<li>チャート／画像の要素抽出</li>
<li>JSON形式での出力</li>
</ul>
<p>といった “フォーマット遵守型の生成” に強みを持つという。</p>
<h2>複数のマルチモーダルタスクで既存VLMを上回る性能</h2>
<p>発表によれば、LaViDa は MMMU、MathVista、ChartQA、ScienceQA などの多様なデータセットで既存の自己回帰型VLMを上回る結果を示した。さらに、COCO Captioning では</p>
<ul>
<li>推論速度：約1.92倍</li>
<li>精度（CIDErスコア）：既存モデルを上回る</li>
</ul>
<p>という結果が報告されている。</p>
<p><strong>LaViDaのベンチマーク結果。複数タスクで精度が向上し、COCO Captionでは速度と品質の両立（NFE制御）が確認された</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub4_6103b442df/sub4_6103b442df.jpg" alt="sub4.jpg" /></p>
<h2>現場のドキュメント処理を支える“AIが読める化”技術へ</h2>
<p>現在パナソニックは、業務現場のAIエージェント活用を推進しており、LaViDa を「多種多様な現場ドキュメントを AI が扱える形式に変換する技術」と位置づける。PDF・画像・写真・報告書など、現場に存在する“非構造データ”を自動的に整理・変換することで、現場のDXを加速する狙いがあるという。</p>
<p>LaViDa の研究成果は AI 国際会議 NeurIPS 2025 に採択されており、12月3〜5日に米サンディエゴで発表される予定だ。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「ChatGPT」は自殺を助長していない──OpenAI、少年自殺訴訟で「ガードレール回避による不適切利用」と反論</title>
      <link>https://ledge.ai/articles/openai_chatgpt_suicide_lawsuit_response_misuse_argument</link>
      <description><![CDATA[<p>OpenAIは、同社の対話型AI「ChatGPT」が10代の少年の自殺を助長したとして提起された訴訟「Raine v. OpenAI」に関し、カリフォルニア州裁判所へ公式な<a href="https://www.medianama.com/wp-content/uploads/2025/11/Raine-v-OpenAI-Answer-11-25-25.pdf">回答書</a>（Answer to Amended Complaint）を2025年11月25日付で提出した。回答書で同社は、少年の死を「壊滅的な悲劇」としつつも、「チャット履歴を全体として読むと、自殺はChatGPTによって引き起こされたものではない」として因果関係を否定した。</p>
<h2>原告側は「自殺を正当化した」と主張</h2>
<p>訴訟は、2025年8月にサンフランシスコ郡上級裁判所へ提起されたもの。原告である遺族は、当時16歳の少年がChatGPT（GPT-4o）との長期的な対話の中で自殺方法の詳細や計画の助長を受けたと主張しており、OpenAIに対して過失・製造物責任・警告義務違反などを訴えている。</p>
<p>訴状では、ChatGPTが
・自殺方法の手順
・未遂時の「失敗理由」の分析
・遺書の下書き
・家族に伝えないよう促すような発言
などを行ったとされ、モデルのガードレール設計や安全プロトコルに欠陥があったと指摘する。</p>
<h2>OpenAI「100回以上、危機支援を促していた」</h2>
<p>OpenAIが裁判所へ提出した回答書では、原告が引用する会話は「文脈を欠いた部分的抜粋にすぎない」と指摘し、同社は完全なチャット履歴を提出したと説明。その上で、ChatGPTが少年との対話中に100回以上、自殺防止ホットラインや信頼できる人物への相談を促していたとし、安全機能は機能していたと主張した。</p>
<p>また回答書では、少年が
・ガードレールに対する不満を繰り返し述べていたこと
・意図を偽り「キャラクター作り」などと説明しつつ、危険な指示を引き出そうとしていたこと
を示す記録があるとし、安全機能の回避行為が存在したと反論した。</p>
<p>さらにOpenAIは、少年には長年にわたる自殺念慮や既往のメンタルヘルス問題があったほか、ChatGPT以外のAIサービスやオンライン情報源からも自殺方法に関する詳細を得ていたとし、「死因は複数の要因によるもので、ChatGPT単独では説明できない」と述べている。</p>
<h2>利用規約違反と「誤用」を強調</h2>
<p>OpenAIは回答書で、「misuse（誤用）」「unauthorized use（無許可利用）」「unintended use（想定外利用）」といった文言を用い、少年の利用は利用規約（Terms of Use）およびUsage Policiesに反するものだったと主張した。</p>
<p>利用規約では、自殺や自傷に関連した用途での利用を禁じており、未成年者については保護者同意なしの利用を禁止している。同社は、少年の利用はこれらに反しており、同社に法的責任を帰すことはできないと訴えている。</p>
<p>また、米通信品位法230条（Section 230）に基づき、ユーザー入力に対する応答についてAIサービス提供者が責任を負わないという法的抗弁も提示している。</p>
<h2>「慎重さ・透明性・敬意」の姿勢</h2>
<p>OpenAIは、回答書の提出と同じ11月25日付で公開したブログ「Our approach to mental health-related litigation」で、メンタルヘルス関連の訴訟は深い悲劇性と複雑さを伴うため、「慎重さ・透明性・敬意をもって対応する」との方針を<a href="https://openai.com/index/mental-health-litigation-approach/">示した</a>。同ブログでは遺族への哀悼を表明しつつも、具体的な論点については法廷での手続きを通じて対応するとしている。</p>
<p>また、2025年8月に公開した別の公式文書「Helping people when they need it most」では、
・危機的状況の検知精度の向上
・外部支援先への誘導の強化
・長時間会話におけるガードレールの精緻化
・ティーン向け保護機能の追加
など、メンタルヘルス領域での安全性改善を進めていることを説明した。</p>
<h2>原告側は「被害者非難」と反発</h2>
<p>報道によると、原告側代理人はOpenAIの回答を「被害者を責める内容だ」と批判しており、ChatGPTのガードレール設計や運用の不足が少年の自殺に寄与したとの主張を続けている。</p>
<p>今後の審理では、
・ChatGPTの応答と自殺行動の因果関係
・GPT-4oの安全設計とガードレールの適切性
・利用規約やSection 230が生成AIの応答にどこまで適用されるか
などが主要な争点となる見通しだ。</p>
]]></description>
      <pubDate>Tue, 02 Dec 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>HP、AI導入を軸に最大6000人削減へ──2028年度末までに世界で4000〜6000人、年間10億ドルのコスト削減目指す</title>
      <link>https://ledge.ai/articles/hp_ai_headcount_reduction_2028_plan</link>
      <description><![CDATA[<p>HPは2025年11月25日（米国時間）、2025年度通期および第4四半期の決算を公表するとともに、AIの活用を軸とした全社的な構造改革「Fiscal 2026 Plan」を<a href="https://www.hp.com/us-en/newsroom/press-releases/2025/hp-inc-reports-fiscal-2025-full-year-and-fourth-quarter-results.html">発表</a>した。</p>
<p>その一環として、世界で約4000〜6000人の人員削減を2028年度末までに実施する計画を示した。これは、AI導入による生産性向上や事業構造の見直しを進めながら、年間約10億ドルのコスト削減を図る取り組みの一部として位置づけられている。</p>
<h2>AI活用を柱に全社改革──「Fiscal 2026 Plan」発表</h2>
<p>HPは、AIを中心としたデジタルトランスフォーメーションを通じ、顧客満足度の向上、プロダクトイノベーションの加速、生産性の改善を図ると説明。同社は「会社全体の取り組み（company-wide initiative）」と呼ぶこのプランにより、2028年度末までに年間約10億ドルのグロス・コスト削減を達成する見込みを示した。</p>
<p>計画には、組織の簡素化、プラットフォーム統合、業務プロセス改善に加え、AI活用による自動化や効率化が含まれる。これらの施策に伴い、総額約6億5000万ドルのリストラクチャリング費用を見込んでおり、うち約2億5000万ドルを2026年度に計上する予定だ。</p>
<h2>世界で4000〜6000人削減──2028年度末までに段階的に実施</h2>
<p>HPは、全社改革の一環として、世界の総人員を約4000〜6000人削減する（gross global headcount reduction）と発表した。リリースでは、対象地域や部門の内訳は明らかにしていないが、「workforce reductions（人員削減）」を主要な施策の一つとして挙げている。</p>
<p>人員削減は2028年度末までに段階的に実施される予定で、AI活用による業務の効率化や、非中核領域の統合・最適化を通じて構造的なコスト削減を進める。</p>
<h2>2025年度の業績──通期売上は553億ドル、PC事業は回復傾向</h2>
<p>決算によると、2025年度通期の売上高は553億ドル（前年比3.2％増）となった。GAAP希薄化後EPSは2.65ドルで、前年（2.81ドル）から減少した。一方、第4四半期売上高は146億ドル（前年比4.2％増）と増収となっている。</p>
<p>主力のパーソナルシステムズ事業（PC）は、第4四半期で前年比8％増の104億ドルとなり、コンシューマー向け・法人向けともに販売が回復した。プリンティング事業は4％減の43億ドルと低調だった。</p>
<p>同社CEOであるEnrique Lores氏は、AIを基盤とした製品イノベーションを強調し、「働き方の未来（Future of Work）をリードするため、AI搭載デバイスの開発、生産性向上、顧客価値の最大化を進める」とコメントした。</p>
<p>HPは、2026年度第1四半期のEPS見通しとして、GAAPベースで0.58〜0.66ドル、非GAAPで0.73〜0.81ドルと予測。通期では、GAAP 2.47〜2.77ドル、非GAAP 2.90〜3.20ドルを見込む。フリーキャッシュフローは28〜30億ドルを計画しており、成長投資と株主還元の両立を図る考えを示した。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI普及の裏で「リテラシー不足」が深刻化──野村総研「IT活用実態調査2025」、導入率57.7％・課題は人材とリスク管理</title>
      <link>https://ledge.ai/articles/nri_it_survey_2025_generative_ai_literacy_gap</link>
      <description><![CDATA[<p>野村総合研究所（NRI）は2025年11月25日、日本企業517社を対象に実施した「IT活用実態調査（2025年）」の結果を<a href="https://www.nri.com/jp/news/newsrelease/20251125_1.html">公表</a>した。調査では、生成AIの導入が急速に広がる一方、その活用を支えるリテラシーやリスク管理の体制が追いついていない実態が浮き彫りとなったという。</p>
<h2>IT予算は増加傾向が続くが、前年から伸びが鈍化</h2>
<p>2025年度のIT予算が「増加した」と回答した企業は49.0％で、前年（59.0％）から10ポイント低下した。2026年度を「増加見込み」とする企業も47.5％と半数近くにのぼり、増加基調は続くものの、勢いはやや落ち着きつつある。</p>
<p><strong>IT予算の推移（NRI「IT活用実態調査2025」より）。2025年度は増加の勢いが前年より鈍化</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054612_822d38fda9/000054612_822d38fda9.png" alt="000054612.png" /></p>
<h2>生成AIの導入率は57.7％、導入済＋検討中で76％</h2>
<p>生成AIを「導入済み」と回答した企業は57.7％に達し、前年（44.8％）から一段と普及が進んだ。ChatGPTやGeminiといった汎用サービスの浸透により、「導入検討中」の割合は減少し、導入フェーズが“検討”から“活用強化”へ移行していることがうかがえる。</p>
<p><strong>新技術の導入状況。生成AIは57.7％が導入済み、ノーコード／ローコードツールも51.0％に</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054613_b373ec554c/000054613_b373ec554c.png" alt="000054613.png" /></p>
<h2>課題のトップは「リテラシー不足」70.3％、次いで「リスク管理の難しさ」48.5％</h2>
<p>生成AI活用における課題として最も多かったのは「リテラシーやスキルが不足している」（70.3％）で、前年の65.4％から増加した。導入フェーズが進む中で、実業務レベルでの使いこなしや品質管理が要求される場面が増え、教育・トレーニング体制の不足が顕在化した形だ。</p>
<p><strong>生成AI活用における課題。1位はリテラシー不足（70.3％）、2位はリスク管理（48.5％）</strong>
続く課題は「リスクを把握し管理することが難しい」（48.5％）。機密データの取り扱いや生成物の品質保証など、ガバナンス面の整備が追いつかない企業が多い。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054614_9cb8e79179/000054614_9cb8e79179.png" alt="000054614.png" /></p>
<h2>レガシーシステムは依然として約半数に残存</h2>
<p>企業の情報システムにおけるレガシー環境の残存率は、アプリケーションが47.3％、基盤系が48.2％と、前年から改善はみられるものの依然として高水準だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054615_12b800e0f8/000054615_12b800e0f8.png" alt="000054615.png" /></p>
<p>懸念点のトップは「ブラックボックス化・有識者不足」（51.6％）。続いて、「ベンダーサポートの終了」（50.1％）が挙げられ、技術負債が経営やIT投資の柔軟性を阻害している状況が明確になった。</p>
<p><strong>レガシーシステムに関する懸念。ブラックボックス化と人材不足が半数超</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054616_921e943c42/000054616_921e943c42.png" alt="000054616.png" /></p>
<h2>「必要だが足りない」デジタル人材、ITストラテジストの保有率は29.6％</h2>
<p>専門人材の確保については、「保有すべき」と回答した企業は多数である一方、社内に「保有している」と答えた割合は大きく下回った。</p>
<p>特に顕著なのはITストラテジストで、必要性71.9％に対し保有29.6％と大きなギャップがある。また、プロジェクトマネージャーは必要80.1％に対し保有55.0％で、ビジネス・テクノロジー双方の専門家が不足している。</p>
<p><strong>専門人材の必要性と保有状況。ITストラテジストなど、必要性に対し保有が大きく不足</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000054617_5b78391399/000054617_5b78391399.png" alt="000054617.png" /></p>
<h2>生成AIの普及と同時に浮き彫りになる構造的な課題</h2>
<p>調査結果からは、</p>
<ul>
<li>生成AI導入フェーズの急速な進展</li>
<li>しかしリテラシー不足・リスク管理不足という基盤整備の遅れ</li>
<li>レガシーシステムと技術負債の残存</li>
<li>専門人材の不足</li>
</ul>
<p>という「普及と課題のギャップ」が明確に示されている。
NRIは、今後も企業のIT・デジタル化の現状を継続的に観測し、課題解決を支援するとしている。</p>
]]></description>
      <pubDate>Mon, 01 Dec 2025 03:00:00 GMT</pubDate>
    </item>
  </channel>
</rss>