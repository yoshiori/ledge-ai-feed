<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>OpenClaw経由で制限報告相次ぐ──Google Antigravity担当者「悪意ある利用急増、&gt;90%が意図外用途」と説明</title>
      <link>https://ledge.ai/articles/openclaw_gemini_antigravity_usage_restrictions_202602</link>
      <description><![CDATA[<p>2026年2月13日以降、Googleの有料AIプラン利用者の間で、オープンフレームワーク「OpenClaw」を経由してGeminiモデルに接続した後、利用制限を受けたとする報告が相次いでいる。Googleの公式開発者フォーラムには、「<a href="https://discuss.ai.google.dev/t/account-restricted-without-warning-google-ai-ultra-oauth-via-openclaw/122778">Account Restricted Without WARNING</a>」と題した投稿を含め、同様のアカウント停止や403エラーに関する複数の投稿が掲載されている。</p>
<h2>フォーラムでの制限報告</h2>
<p>Google AI Developers Forumの投稿では、OpenClawのOAuth連携を通じてGeminiを利用した後、Google AI Ultraアカウントが制限状態になったとする事例が報告されている。投稿者は、事前警告がなかったことや、制限が数日間継続していることを記している。</p>
<p>「403 ToS violation」と表示されたケースや、Antigravity／Gemini Code Assistの利用が無効化されたとする投稿もあり、2月中旬以降、類似の報告が複数スレッドで続いている。</p>
<h2>Antigravity担当者のX投稿：「悪意ある利用が急増」</h2>
<p>これについて、Googleの「Antigravity」プロダクトに関与する担当者であるVarun Mohan氏は、2026年2月23日から24日にかけてX（旧Twitter）に投稿し、対応の背景を説明した。</p>
<p>Mohan氏は23日の投稿で、「Antigravityバックエンドにおけるmalicious usage（悪意ある利用）が大幅に増加し、ユーザー体験の品質が著しく低下した」と述べた。そのうえで、「意図した使い方ではない利用者」のアクセスを迅速に遮断する必要があったと説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Varun_Mohan_X_36452aeb3e/Varun_Mohan_X_36452aeb3e.jpg" alt="Varun Mohan X.jpg" /></p>
<p>同日中の追加投稿では、今回ブロックしたのはAntigravityプロダクトの利用であり、「他のGoogleサービスおよびGoogle AIサービスは影響を受けていない」と明記した。また、「Antigravityバックエンドを他製品のプロキシとして使用することは意図されていない」とし、該当する利用形態が計算資源を圧迫していたと説明した。</p>
<p>24日の<a href="https://x.com/_mohansolo/status/2026109842948329574">投稿</a>では、「利用の大半（\u003E90%）がAntigravityプロダクトではない用途だったアカウント」に対して措置を取ったとし、「十分な事前警告を行えなかったことを深く後悔している」と記した。あわせて、対象利用者に復帰の道筋を用意するとしている。</p>
<h2>双方が主張する影響</h2>
<p>Mohan氏は、Antigravityバックエンドでの「malicious usage」の急増がサービス品質（QoS）を著しく損ない、計算資源が圧迫されたことが今回の措置の背景にあると説明。容量に制約がある中で「実際のユーザーに公平でありたい」と述べた。</p>
<p>一方、利用者側からは、事前警告なしに利用が停止されたことや、異議申し立て後の対応が不透明であるとする投稿が公式フォーラム上で相次いでいる。OpenClawの開発者で、同月15日にOpenAIへの参加を発表したPeter Steinberger氏は、月額250ドルのUltraプラン加入者へのサポート対応に疑問を呈し、高額プラン契約下でリソースにアクセスできない状況を「draconian（苛烈）」と表現し、運用面のリスクを指摘した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Peter_Steinberger_X_97220b6096/Peter_Steinberger_X_97220b6096.jpg" alt="PeterSteinberger X.jpg" /></p>
<p>Antigravityの<a href="https://antigravity.google/terms">追加利用規約</a>では、サービスの濫用や妨害、意図しない形での利用などを制限する趣旨の条項が設けられている。Mohan氏の投稿は、こうした規約の考え方に沿う形で説明されたものと位置付けられる。ただし、具体的にどの条項に違反したのかは明示されていない。</p>
<p>現時点で、GoogleがOpenClawを名指しで一律禁止したとする公式声明は確認されていない。Mohan氏はXで、「malicious usage」の急増と、利用の大半（\u003E90%）がAntigravity本来用途ではなかったアカウントへの措置であると説明している。</p>
]]></description>
      <pubDate>Wed, 25 Feb 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>2028年末までに“世界の知的作業の過半がAIへ”──OpenAIサム・アルトマン氏が超知能の到達時期に言及</title>
      <link>https://ledge.ai/articles/ai_intellectual_work_majority_2028_altman</link>
      <description><![CDATA[<p>OpenAIのCEOであるSam Altmanは2026年2月19日、インド・ニューデリーで開催された「India AI Impact Summit 2026」に<a href="https://www.pib.gov.in/PressReleseDetailm.aspx?PRID=2230370&amp;lang=1&amp;reg=3">登壇</a>{target=”_blank”}し、人工知能が人類の知的能力を大きく上回る「超知能（Super Intelligence）」の到達時期について具体的な見通しを示した。</p>
<p>同氏は講演の中で、次のように述べている。
**\</p>
]]></description>
      <pubDate>Tue, 24 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>電子デバイス内部の廃熱を“計算資源”に転換──MIT、AIなどの基礎となる行列演算を物理現象で実行する新しいアナログ計算を提案</title>
      <link>https://ledge.ai/articles/heat_analog_computing_mit_waste_heat_matrix_computation</link>
      <description><![CDATA[<p>マサチューセッツ工科大学（MIT）の研究者らは、電子デバイス内部で発生する余剰熱を利用し、物理的な熱伝導現象によって計算を実行するシリコン構造体を設計したと<a href="https://journals.aps.org/prapplied/abstract/10.1103/5drp-hrx1">発表</a>した。研究成果は2026年1月29日に、米国物理学会（APS）が発行するPhysical Review Appliedに掲載された。</p>
<p>論文タイトルは「Thermal analog computing: Application to matrix-vector multiplication with inverse-designed metastructures」。機械学習などで基礎演算として用いられる行列ベクトル積（matrix-vector multiplication, MVM）を、熱拡散によって実行できることを実証した。</p>
<h2>廃熱を“計算資源”に転換― 熱伝導を利用する新しいアナログ計算</h2>
<p>電子回路では、トランジスタの動作などに伴い熱が発生する。従来、この熱はエネルギー損失として扱われ、冷却や放熱の対象とされてきた。</p>
<p>今回の研究は、この「廃熱」を情報の担い手として再解釈する。温度差や熱流の広がり方は、熱伝導方程式に従って決まる。研究チームはこの物理法則を利用し、温度分布そのものを計算プロセスとして活用する「熱アナログ計算」の枠組みを提示した。</p>
<h2>行列演算を物理現象で実行― 逆設計されたシリコン構造の仕組み</h2>
<p>研究チームは、シリコン基板上に微細な多孔質構造を形成。複数の入力点に与えた温度条件が構造内部を伝播する過程で、所定の線形演算が実行されるよう設計した。</p>
<p>入力となる温度が構造内を拡散し、特定の出力端で回収される熱流（パワー）が演算結果に対応する。すなわち、電子的な演算回路を用いず、物理現象そのものが計算を担う構成となっている。</p>
<h2>99％超の精度を実証― 行列ベクトル積（MVM）の動作検証</h2>
<p>実験では、行列ベクトル積を対象に構造体を設計し、動作を検証した。その結果、演算結果は理論値に対して99％を超える精度で一致したと報告されている。</p>
<p>行列ベクトル積は、ニューラルネットワークをはじめとする多くのアルゴリズムの基礎となる演算である。今回の実証は、熱を用いた物理計算が実用的な精度を達成し得ることを示すものとなる。</p>
<h2>設計の鍵は「逆設計」― 目標の演算結果から構造を導き出す</h2>
<p>研究の中核をなすのが「逆設計（inverse design）」の手法だ。研究チームは、実現したい行列演算の特性を先に定義し、それを満たすようにシリコン内部の幾何構造を数値最適化によって導き出した。</p>
<p><strong>図：熱の流れを利用して行列演算を実装する構造の概念図。正負成分を分離し、差分を取ることで計算結果を得る</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Figure_1_7c92757b00/Figure_1_7c92757b00.png" alt="Figure_1.png" /></p>
<p>人間の直感では設計が難しい複雑な形状を、アルゴリズムにより反復的に最適化することで、目標とする計算機能を物理構造として実装した。</p>
<h2>実装への課題と応用可能性― スケール拡張と熱管理技術への展望</h2>
<p>研究チームは、より大規模な演算に拡張するためには、構造のタイル化や集積化といった課題が残るとしている。また、熱伝導の性質上、負の係数を扱う際には構造を分割するなどの工夫が必要になる。</p>
<p>一方で、電子デバイス内で不可避に生じる熱を再利用するという発想は、エネルギー効率の観点からも注目される。将来的には、熱管理機能と計算機能を統合した新たなチップ設計につながる可能性がある。</p>
<p>研究は、従来は「損失」とされてきた廃熱を、計算資源へと転換するアプローチを示した。電子計算とは異なる物理的手法による情報処理の選択肢を提示する成果となる。</p>
]]></description>
      <pubDate>Sun, 22 Feb 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIエージェントはどこまで“自律”しているのか──Anthropicが数百万件データを初公開分析</title>
      <link>https://ledge.ai/articles/ai_agent_autonomy_real_world_anthropic_analysis_20260218</link>
      <description><![CDATA[<p>Anthropicは2026年2月18日、公式ブログ「Measuring AI agent autonomy in practice」を公開し、自社のコーディングエージェント「Claude Code」および公開API経由で収集した数百万件規模の人間―AI対話データを分析した結果を<a href="https://www.anthropic.com/research/measuring-agent-autonomy">発表</a>した。</p>
<p>実社会で稼働するAIエージェントがどの程度の自律性を発揮しているのかを、実運用ログに基づいて定量的に示した初の包括的分析となる。</p>
<h2>自律稼働時間は3カ月で約2倍に</h2>
<p>Claude Codeにおける最長稼働セッション（99.9パーセンタイル）のターン時間は、2025年秋時点で25分未満だったが、2026年1月には45分超へと拡大した。約3カ月でほぼ2倍に伸びた計算となる。</p>
<p>一方、中央値は約45秒で安定しており、大多数の利用は短時間に集中している。自律性の拡張は、長時間稼働の“尾部”で進行している構造が示された。</p>
<p><strong>■ 99.9パーセンタイルのターン時間推移。2025年秋から2026年初頭にかけて約2倍に拡大</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/how_long_does_claude_code_work_before_stopping_6705b03e59/how_long_does_claude_code_work_before_stopping_6705b03e59.jpg" alt="how long does claude code work before stopping.jpg" /></p>
<p>Anthropicは、この増加がモデル更新ごとの急激な跳ね上がりではなく、滑らかな推移を示している点に注目している。これは能力向上のみならず、ユーザー側の信頼形成や利用スタイルの変化も影響している可能性を示唆するものだとしている。</p>
<h2>経験者ほど「任せるが、割り込む」</h2>
<p>ユーザーの行動変化も確認された。新規ユーザーでは約20％のセッションがフル自動承認（auto-approve）を利用しているのに対し、750セッション以上利用する経験者では40％超に上昇した。</p>
<p>一方で、途中でAIの処理を中断する「割り込み率」も、経験者のほうが高い。新規ユーザーの割り込み率が約5％であるのに対し、経験者は約9％だった。</p>
<p>Anthropicはこれを、監督戦略の変化と説明する。初心者は各ステップを逐次承認する傾向が強いが、経験者は一括で自律実行を許可し、必要な場合のみ介入する「監視型」へと移行していると分析している。</p>
<h2>AIが自ら停止するケースも増加</h2>
<p>人間による監督だけでなく、AI自身が不確実性を認識して停止するケースも確認された。複雑度が高いタスクでは、Claude Codeが人間よりも頻繁に処理を停止し、確認や追加情報を求める傾向がみられた。</p>
<p><strong>■ タスク複雑度が高まるほど、Claudeの自己停止率は上昇。人間の割り込みを上回る</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/clarification_and_interruption_rates_by_goal_complexity_bb2a678bd7/clarification_and_interruption_rates_by_goal_complexity_bb2a678bd7.jpg" alt="clarification and interruption rates by goal complexity.jpg" /></p>
<p>停止理由としては、方針の選択提示（35％）、診断情報の収集（21％）、曖昧な指示の確認（13％）などが挙げられている。Anthropicは、自己不確実性の表出を安全設計上の重要な特性と位置づけ、モデルが自ら確認を求める訓練を行っていると説明している。</p>
<h2>リスクと自律性の分布</h2>
<p>公開API経由の約100万件のツール呼び出しについては、リスク（1～10）と自律性（1～10）の2軸で評価を実施した。</p>
<p>その結果、
・80％は何らかのセーフガードが存在
・73％は人間が関与
・不可逆的行為は0.8％</p>
<p>という分布が示された。</p>
<p><strong>■ リスク（縦軸）と自律性（横軸）の分布。高リスク×高自律領域は少数だが存在</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/what_is_the_risk_autonomy_tradeoff_in_practice_2c3342dd20/what_is_the_risk_autonomy_tradeoff_in_practice_2c3342dd20.jpg" alt="what is the risk-autonomy tradeoff in practice.jpg" /></p>
<p>高リスクかつ高自律性に分類される事例は少数ながら存在し、セキュリティ関連操作、金融取引、医療情報の取得などが含まれていた。ただしAnthropicは、これらの一部は評価やレッドチーム用途である可能性もあると注記している。</p>
<h2>利用はソフトウェア分野に集中</h2>
<p>ツール利用の約50％はソフトウェアエンジニアリング分野が占めている。その他、ビジネスインテリジェンス、カスタマーサポート、営業、金融などでの利用も確認されたが、いずれも数％規模にとどまる。Anthropicは、エージェント活用は依然として初期段階にあり、今後高リスク領域での利用拡大が進む可能性があるとしている。</p>
<p><strong>■ ツール呼び出しの約50％がソフトウェアエンジニアリング用途</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/in_what_domains_are_agents_deployed_418ebfdcdb/in_what_domains_are_agents_deployed_418ebfdcdb.jpg" alt="in what domains are agents deployed.jpg" /></p>
<p>エージェント型AIの活用は近時、ソフトウェア開発のみならず、業務自動化やセキュリティ領域などへと拡大している。複数のツールを組み合わせて長時間にわたり自律的に動作するエージェント型プロダクトも登場しており、実運用環境での振る舞いを定量的に把握する必要性は高まっている。今回の分析は、こうした動向を背景に、実社会におけるエージェントの自律性と監督構造の実態を示す試みと位置づけられる。</p>
<p>AIエージェントの自律性が段階的に拡張する中で、実運用データに基づく継続的な測定と監視の枠組み構築が、今後の焦点となりそうだ。</p>
]]></description>
      <pubDate>Sun, 22 Feb 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、アメリカからインドを結ぶ3本の海底ケーブル敷設へ──4大陸接続強化「America-India Connect」始動</title>
      <link>https://ledge.ai/articles/google_america_india_connect_submarine_cable_4continents</link>
      <description><![CDATA[<p>Googleは2026年2月19日、アメリカからインドを結ぶ海底・陸上ネットワークを強化する構想「America-India Connect」を<a href="https://cloud.google.com/blog/products/infrastructure/america-india-connect-infrastructure-connects-four-continents?hl=en">発表</a>した。インド東海岸に新たな国際海底ゲートウェイを設置するとともに、インドをシンガポール、南アフリカ、オーストラリアへ接続する3本の新たな海底ルート（subsea paths）を整備する。</p>
<p>同社は、本構想によりアメリカ、アジア、アフリカ、オーストラリアの4大陸間の接続性、容量、レジリエンス（耐障害性）を高めるとしている。</p>
<h2>インド東海岸に新ゲートウェイ設置</h2>
<p>今回の構想では、インド東海岸のビシャーカパトナム（Vizag）に新たな国際海底ゲートウェイを整備する。現在の主要な海底ケーブル着地点であるムンバイやチェンナイに加え、接続拠点を分散させることで、インドのデジタル基盤の多様性と冗長性を強化する狙いだ。Googleは、回線の多様化が通信の信頼性向上につながると説明している。</p>
<h2>3本の新規海底ルートを整備</h2>
<p>「America-India Connect」では、以下の3方向への新たな海底接続を整備する。</p>
<ul>
<li>インド—南アフリカ間の直接ルート</li>
<li>インド—シンガポール間の直接ルート</li>
<li>インド—オーストラリア間の直接ルート</li>
</ul>
<p>これらの新経路は、既存の海底ケーブル群と組み合わせることで、アメリカ東海岸および西海岸からインドへ至る複数の回廊を形成する。</p>
<p>南アフリカ経由のルートは、既存の「Equiano」や「Nuvem」などと接続し、アメリカ東海岸からアフリカを経由してインド東海岸へ至る経路を構築する。</p>
<p>また、オーストラリアやシンガポールを経由するルートは、「Bosun」「Tabua」「TalayLink」「Honomoana」など既存ケーブルと組み合わせることで、アメリカ西海岸から南太平洋経由でインドに至る経路を補強する。</p>
<p>さらに、既存の「Blue」「Raman」「Sol」などが形成するアメリカ東海岸—紅海—ムンバイ回廊も補完される。</p>
<h2>AI需要拡大を背景にインフラ強化</h2>
<p>Googleは、デジタルインフラへの投資が経済成長や生産性向上を支えると説明している。特にAIの普及に伴い、大容量かつ低遅延の国際通信基盤の重要性が高まっているとした。同社はインドにおいて今後5年間で150億ドル規模のAI関連インフラ投資を行う計画を明らかにしており、今回の構想はその一環に位置付けられる。</p>
<p>「America-India Connect」は、アメリカとインドを軸に4大陸を結ぶ新たな通信回廊の形成を目指す取り組みとなる。</p>
]]></description>
      <pubDate>Sat, 21 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「Microsoft 365 Copilot」が社外秘メールを拾う不具合、数週間継続──Microsoftが修正を段階展開</title>
      <link>https://ledge.ai/articles/copilot_confidential_email_bug_fix_rollout</link>
      <description><![CDATA[<p>Microsoftが自社AI「Copilot」に関する不具合を認めたことを、米ITメディアの<a href="https://www.bleepingcomputer.com/news/microsoft/microsoft-says-bug-causes-copilot-to-summarize-confidential-emails/">BleepingComputer</a>が2026年2月18日（現地時間）に報じた。掲載記事のタイトルは「Microsoft says bug causes Copilot to summarize confidential emails」と題した記事で報じた。</p>
<p>報道によると、Microsoft 365 Copilot Chatが、機密（confidential）ラベル付きメールを誤って要約処理の対象とする不具合が発生していたという。</p>
<h2>問題の内容──Sent Items／Draftsが対象に</h2>
<p>Microsoft 365のサービスヘルス通知（Issue ID: CW1226324）では、次のように説明されている。
・Copilot Chat（work tab）利用時
・Exchange Onlineの「Sent Items（送信済み）」および「Drafts（下書き）」フォルダ内メール
・DLP（データ損失防止）ポリシーおよび感度（sensitivity）ラベルが適用されている場合でも
・Copilotがこれらのアイテムを処理対象として拾い得る状態にあった</p>
<p>この通知内容は、管理者向けのMicrosoft 365 Service health advisory「CW1226324」の内容（開始時刻、影響範囲、原因、進捗）を、大学のメール運用ページが時系列で転載している<a href="https://mailservices.isc.upenn.edu/computing/email/penno365/alerts/ms-incidents.html">大学の公式ミラーサイト</a>より明らかになった。</p>
<p>Microsoftは同通知の中で、根本原因を「コードの問題（code issue）」と説明している。</p>
<h2>発生時期と継続期間</h2>
<p>通知によれば、不具合の開始は2026年1月21日（UTC）。その後、数週間にわたり影響が継続していた。</p>
<p>Microsoftは修正を開発し、段階的（ロールアウト方式）に展開していると説明している。影響を受けたテナントの特定および追加検証も進めているという。</p>
<h2>本来の設計との関係</h2>
<p>Microsoftの公式ドキュメントでは、Microsoft Purview DLPを用いてCopilotおよびCopilot Chatが機密ラベル付きコンテンツを処理対象から除外できると<a href="https://learn.microsoft.com/en-us/purview/dlp-microsoft365-copilot-location-learn-about">説明</a>されている。</p>
<p>また、Copilotのデータ保護・セキュリティ設計についても、感度ラベルや既存のアクセス権限を尊重する仕組みであると<a href="https://learn.microsoft.com/en-us/copilot/microsoft-365/microsoft-365-copilot-architecture-data-protection-auditing">記載</a>されている。</p>
<p>今回の事象は、こうした設計意図とは異なる挙動がコード上の不具合により発生したケースとなる。</p>
<h2>Microsoftの説明と報道の位置づけ</h2>
<p>BleepingComputerは、Microsoftがこの不具合を認め、修正を展開していると報じた。同記事では、影響がSent ItemsおよびDraftsフォルダに限定されている点や、修正が進行中である点が伝えられている。</p>
<p>Microsoftはサービス通知内で、問題は特定のフォルダ範囲に限定されると説明しており、全面的なメール露出ではないことを示唆している。</p>
<h2>現在の状況</h2>
<p>Microsoftは修正の段階展開を進めているとし、最終的な完了時期や影響規模の詳細は今後の更新を通じて明らかになる見通しだ。</p>
<p>生成AIが企業内データへ広範にアクセスする設計が進む中、既存の情報保護ポリシーとの整合性は引き続き重要な論点となる。</p>
]]></description>
      <pubDate>Sat, 21 Feb 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「他人の脳波が読める」？──Kickstarter入手のスマートアイマスクに深刻な通信設計問題</title>
      <link>https://ledge.ai/articles/brainwave_sleep_mask_vulnerability_kickstarter_mqtt_issue</link>
      <description><![CDATA[<p>AIエンジニアのAimilios Chatzistamou氏は2026年2月12日、自身がクラウドファンディングサイトのKickstarterで購入した中国製のスマート睡眠マスクにおいて、通信設計上の重大な脆弱性を発見したと報告した。解析の結果、他人の脳波（EEG）データをリアルタイムで受信できる可能性があるほか、理論上は電気刺激機能にコマンドを送信できる構造だったという。</p>
<p>同氏は自身の技術ブログで、製品名や企業名は公表しないと明言したうえで、アプリケーションのリバースエンジニアリング結果を<a href="https://aimilios.bearblog.dev/reverse-engineering-sleep-mask/">公開</a>している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/My_smart_sleep_mask_broadcasts_users_brainwaves_to_an_open_MQTT_broker_7dae07966f/My_smart_sleep_mask_broadcasts_users_brainwaves_to_an_open_MQTT_broker_7dae07966f.jpg" alt="My smart sleep mask broadcasts users brainwaves to an open MQTT broker.jpg" /></p>
<h2>アプリ内にハードコードされた認証情報</h2>
<p>問題の発端は、スマートフォン向け公式アプリの解析だった。同氏によると、アプリ内部にMQTTブローカーへ接続するための高権限認証情報がハードコードされていた。</p>
<p>MQTTはIoT機器で広く利用される軽量メッセージングプロトコルだが、本来は個別認証や適切なアクセス制御が求められる。同氏は、共通の認証情報を用いてブローカーへ接続できる状態になっていたと説明している。</p>
<p>この設計により、外部から接続したクライアントが、他ユーザー由来とみられる生体データを購読（subscribe）できる状況が確認されたという。</p>
<h2>他人のEEGデータをリアルタイム受信</h2>
<p>当該製品は、睡眠トラッキングやリラクゼーション用途をうたい、EEG（脳波）を計測するセンサーを備えるウェアラブル機器とされる。</p>
<p>同氏は、MQTTトピックを監視することで、リアルタイムで送信されるEEGデータを受信できたと記している。これが事実であれば、生体情報という極めて機微性の高いデータが適切な分離なく扱われていた可能性がある。</p>
<p>現時点で、大規模なデータ流出が確認されているわけではないが、設計上の問題として重大だと指摘している。</p>
<h2>電気刺激機能へのアクセス可能性</h2>
<p>さらに同氏は、当該機器が軽度の電気刺激（EMS）や振動、加熱、オーディオ機能などを備えている点に言及。解析上、理論的にはこれらの機能に対する制御コマンドを送信できる構造であったと述べている。</p>
<p>実際に危険な出力が可能かどうか、また安全制御がどの程度実装されているかについては検証していないとしているが、「身体に直接装着するデバイスに外部からアクセス可能な制御経路が存在すること自体が問題だ」との認識を示している。</p>
<p>同氏は、製品名や企業名を公表しない判断を取っている。一部海外メディアは特定製品との関連を推測しているが、同氏は明示していない。本稿執筆時点で、メーカー側の公式声明や修正アップデートの有無は確認できていない。</p>
<h2>民生向けニューロテックの設計課題</h2>
<p>近年、EEG搭載のヘッドバンドやスマートマスクなど、脳活動を扱う民生向けウェアラブル製品は増加している。これらは医療機器ではないケースも多いが、</p>
<p>・生体データを常時収集する
・クラウドと接続される
・身体に直接刺激を与える機能を持つ</p>
<p>といった特徴を備える。</p>
<p>今回の事例は、消費者向けニューロテック製品における通信設計とアクセス制御の重要性を改めて示すものとなった。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>フェイフェイ・リー氏のWorld Labsが10億ドル調達、「空間知能」構築へ──CAD大手のAutodeskは2億ドル投資、3D世界モデル「Marble」推進</title>
      <link>https://ledge.ai/articles/fei_fei_li_world_labs_10b_spatial_intelligence_autodesk_2b_marble</link>
      <description><![CDATA[<p>米AIスタートアップのWorld Labsは2026年2月18日（現地時間）、新たに10億ドル（約1500億円）を調達したと公式ブログで<a href="https://www.worldlabs.ai/blog/funding-2026">発表</a>した。同社は、コンピュータビジョン研究の第一人者であるFei-Fei Li氏が率いる企業として知られる。</p>
<p>あわせて、米設計ソフト大手のAutodeskは同日、World Labsに2億ドルを戦略投資し、戦略アドバイザーとして参画すると発表した。両社は、3次元空間を理解・生成できるAI基盤の構築に向け、研究・モデルレベルで協業を進める。</p>
<h2>10億ドル調達、投資家にNVIDIAやAMDなど</h2>
<p>World Labsの発表によれば、今回の資金調達ラウンドにはAMD、Autodesk、Emerson Collective、Fidelity Management &amp; Research Company、NVIDIA、Seaなどが参加した。調達資金は、同社が掲げる「spatial intelligence（空間知能）」の開発を加速するために用いられる。</p>
<p>同社は、従来の大規模言語モデル（LLM）が主にテキストを扱うのに対し、物理世界を前提としたAIには「空間」「構造」「物理」「時間」といった要素を理解する能力が不可欠だと位置付けている。World Labsは、こうした能力を備えた「world models（世界モデル）」の構築を目指すと説明している。</p>
<h2>Autodeskが2億ドルを戦略投資、研究段階から連携</h2>
<p><a href="https://adsknews.autodesk.com/en/news/autodesk-invests-in-world-labs/">Autodesk</a>はこの日、World Labsへ2億ドルを投資し、戦略アドバイザーとして密接に協業すると明らかにした。同社は、建築・製造・エンジニアリング分野の顧客にとって、3D空間や物理法則を理解するAIの重要性が高まっていると説明している。</p>
<p>両社の協業は、製品統合の即時発表という形ではなく、研究・モデルレベルでの連携から始まる。Autodeskは、設計・製造のワークフローにおいて、空間的推論が可能なAIの必要性を強調している。</p>
<h2>3D世界モデル「Marble」とは何か</h2>
<p>World Labsは、同社の最初のプロダクトとして「<a href="https://ledge.ai/articles/world_labs_marble_multimodal_world_model_release">Marble</a>」を挙げている。発表によれば、Marbleは画像、動画、テキストから「空間的に整合した高精細で永続的な3D世界」を生成できるとされる。</p>
<p>同社は、このような世界モデルがストーリーテリング、創造活動、ロボティクス、科学的発見など幅広い用途に応用可能だとしている。ただし、今回の発表時点では、具体的な商用展開の時期や統合先製品については明示されていない。</p>
<p>@<a href="https://www.youtube.com/watch?v=MPUdY6WSapw">YouTube</a></p>
<h2>「言語」から「世界」へ──物理世界AIへのシフト</h2>
<p>Autodeskの発表では、AIが言語処理を超えて、幾何学、物理、ダイナミクスといった世界の構造そのものを扱う段階へ進む必要性が示されている。World Labsも、空間知能の実現を次のフロンティアと位置付けている。</p>
<p>10億ドル規模の資金調達と、設計ソフト大手による2億ドルの戦略投資は、生成AIの潮流がテキスト中心の応用から、3D世界を直接扱う「物理世界AI」へと拡張しつつあることを示す動きとなる。</p>
<p>今後は、World Labsの世界モデル技術がどの分野にどのように実装されるのか、またAutodeskの製品群との具体的な連携がどのように進むのかが焦点となる。</p>
<p>:::box
[関連記事：AIの\</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 3.1 Pro、ARC-AGI-2で77.1%──“Deep Think級推論”を一般提供へ</title>
      <link>https://ledge.ai/articles/gemini_3_1_pro_arc_agi_2_77_1_deep_think_general_release</link>
      <description><![CDATA[<p>Googleは2026年2月19日（現地時間）、同社の大規模言語モデル「Gemini」シリーズの最新モデル「Gemini 3.1 Pro」を<a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/">発表</a>した。Googleは同モデルを「複雑問題解決の新たなベースライン」と位置づけ、研究モデル「Gemini 3 Deep Think」と同じコア知能を実務用途向けにスケールしたものだと説明している。同日よりコンシューマー向けアプリから開発者向けAPI、エンタープライズ向け基盤まで順次ロールアウトを開始した。</p>
<h2>「複雑問題解決の新ベースライン」と位置付け</h2>
<p>発表の中でGoogleは、Gemini 3.1 Proを「<a href="https://x.com/Google/status/2024519460124565987">our new baseline for complex problem-solving</a>（複雑な問題解決の新たな基準）」と表現した。</p>
<p>同社によれば、Gemini 3.1 ProはGemini 3 Deep Thinkと同じコア知能を備えつつ、より実務的な用途に適したスケールへ最適化されたモデルだという。研究用途に限定されていた推論能力を、より広範な利用層に開放する位置づけとなる。</p>
<h2>ARC-AGI-2で77.1%──3 Proから2倍超</h2>
<p>今回の発表で注目されるのは、抽象推論ベンチマーク「ARC-AGI-2」におけるスコアだ。</p>
<p>DeepMindが公開した評価結果によれば、Gemini 3.1 ProはARC-AGI-2で77.1%を記録した（ARC Prize Verified）。前世代のGemini 3 Pro（31.1%）から大幅に向上している。</p>
<p>ARC-AGI-2は、未知の論理パターンを解く能力を測定するベンチマークで、単純な知識検索では対応しにくい抽象推論を評価するものとされる。</p>
<p>比較対象として公表されている数値では、Claude Opus 4.6が68.8%、GPT-5.2が52.9%となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/H_Bi_Fhy_Xs_AA_06bm_051b6fe276/H_Bi_Fhy_Xs_AA_06bm_051b6fe276.jpg" alt="HBiFhy-XsAA06bm.jpg" /></p>
<h2>Humanity’s Last Examでもトップ帯</h2>
<p>総合的な知識と推論能力を測るベンチマーク「Humanity’s Last Exam」では、Gemini 3.1 Proは44.4%を記録している。同条件での比較では、Claude Sonnet 4.6が40.0%、GPT-5.2が34.5%となっており、Gemini 3.1 Proはトップ帯に位置している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_1_pro_benchmarks_07e69cf448/gemini_3_1_pro_benchmarks_07e69cf448.jpg" alt="gemini_3-1-pro__benchmarks.jpg" /></p>
<h2>SWE-bench Verified 80.6%──実務性能は維持</h2>
<p>ソフトウェア開発能力を測定する「SWE-bench Verified」では、Gemini 3.1 Proは80.6%を記録した。</p>
<p>Claude Opus 4.6の80.8%とほぼ同水準であり、抽象推論ベンチマークでの大幅な向上と同時に、実務的なコーディング性能も維持していることが示されている。</p>
<h2>デモ事例：ISS追跡から3D群れシミュレーションまで</h2>
<p>Googleは、Gemini 3.1 Proのデモ事例を複数紹介している。</p>
<ul>
<li>公開APIを用いた国際宇宙ステーション（ISS）のリアルタイム追跡ダッシュボード構築</li>
<li>テキストプロンプトからのアニメーションSVG生成</li>
<li>手の動きに反応するインタラクティブ3Dスターリング（ムクドリ）群れシミュレーション</li>
<li>小説『嵐が丘』の雰囲気を反映したポートフォリオUIの生成</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/animated_SV_Gs_35d6721955/animated_SV_Gs_35d6721955.jpg" alt="animated SVGs.jpg" /></p>
<p>モデルのコード生成や構造表現の品質を手早く比較する題材として、開発者コミュニティでしばしば用いられてきた「自転車に乗るペリカン」のアニメーションSVG生成も取り上げられている。Googleは「アニメーションSVGで自転車に乗るペリカンを生成せよ」というプロンプトを用い、Gemini 3 ProとGemini 3.1 Proの生成結果を並べて提示した。</p>
<p>公開された比較画像では、Gemini 3 Proの生成例では自転車のペダルは回転しているものの、ペリカンの脚はペダル動作と連動していない。一方、Gemini 3.1 Proの生成例では、脚がペダルに正しく配置され、動きと連動している様子が確認できる。</p>
<h2>提供範囲</h2>
<p>Gemini 3.1 Proは、発表同日より段階的に提供が開始される。コンシューマー向けにはGemini AppおよびNotebookLMで利用可能となる。開発者向けには、Gemini APIのプレビュー版として提供され、Google AI StudioやGemini CLI、Android Studioなどの開発環境からアクセスできる。さらに、企業向けにはVertex AIおよびGemini Enterpriseを通じて導入可能とされている。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5.2が理論物理の新しい公式候補を提案と検証　グルーオンの「single-minusツリー振幅」に関する結果を発表</title>
      <link>https://ledge.ai/articles/gpt_5_2_supports_theoretical_physics_single_minus_amplitude</link>
      <description><![CDATA[<p>OpenAIは2026年2月13日、同社のAIモデル「GPT-5.2」が理論物理学の研究において数式の一般化を支援し、公式の候補の提案とその検証が行われたと<a href="https://openai.com/ja-JP/index/new-result-theoretical-physics/">発表</a>した 。対象となったのは、素粒子物理学における散乱振幅（scattering amplitude）の研究で、強い相互作用を媒介する素粒子グルーオン（gluon）の振る舞いに関するものだ。</p>
<p>プレプリント「Single-minus gluon tree amplitudes are nonzero」によれば、グルーオン同士の運動量が特別な関係を満たす場合に、通常はゼロとされてきた single-minus のツリー振幅（tree-level amplitude）が非ゼロとなる可能性が示されている。</p>
<h2>single-minus ツリー振幅とは</h2>
<p>複数のグルーオンが関与する散乱では、それぞれのグルーオンが持つヘリシティ（進行方向に対するスピンの向き）の組み合わせによって振幅の性質が変わる。多数のグルーオンのうち1つだけが負のヘリシティを持つ場合は single-minus と呼ばれ、この場合のツリー振幅は、特別な関係を満たさない運動量のもとではゼロになるとされてきた。</p>
<p>研究では、グルーオンの運動量が著者らのいう half-collinear と呼ばれる特定の関係を満たす場合に、この結論が必ずしも成り立たない可能性が示されている。</p>
<h2>AIによる公式候補の提案と検証</h2>
<p>研究プロセスにおいて、研究チームはまず少数粒子の場合の振幅を計算し、その結果をもとにGPT-5.2が一般の粒子数に対する公式の候補を提案した。その後、Berends-Giele漸化式やソフト定理などの既存の理論的条件と整合することが確認されたと報告している。</p>
<h2>今後の展望</h2>
<p>研究はプレプリントとして公開されており、今後コミュニティによる検証が進むとみられる。研究チームは、この結果を他の振幅へ拡張する可能性についても言及している。</p>
<p>今回の事例は、AIが理論物理学の研究過程において数式の探索を支援した例の一つといえる。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本語性能と推論力を両立した推論型LLM「GPT-OSS Swallow」「Qwen3 Swallow」公開──東京科学大・産総研が開発、オープンライセンスで提供</title>
      <link>https://ledge.ai/articles/gpt_oss_qwen3_swallow_japanese_reasoning_llm_tokyo_science_aist</link>
      <description><![CDATA[<p>東京科学大学 情報理工学院の岡崎研究室・横田研究室と、産業技術総合研究所（産総研）の研究チームは2026年2月20日、OpenAIのGPT-OSSをベースに日本語能力と思考力（推論）を強化した推論型大規模言語モデル「GPT-OSS Swallow」と、AlibabaのQwen3をベースに同様の強化を施した「Qwen3 Swallow」を<a href="https://swallow-llm.github.io/gptoss-swallow.ja.html">公開</a>した。両モデルはApache License 2.0で重みが公開され、商用利用を含めて利用可能としている。</p>
<h2>GPT-OSS／Qwen3をベースに“日本語×推論”を強化</h2>
<p>公開されたモデルは、既存のオープンモデルを基盤に、日本語性能と推論能力の両立を目指して再学習・強化学習を行った点が特徴だ。</p>
<p>「GPT-OSS Swallow」は、OpenAIのGPT-OSSを基盤に構築。20Bおよび120Bの2系列を展開する。一方、「Qwen3 Swallow」はAlibabaのQwen3をベースに、8B、30B-A3B、32Bといった複数サイズを提供する。</p>
<p>いずれもオープンウェイトで公開され、オンプレミス環境での実行や追加チューニングなどが可能だ。</p>
<h2>継続事前学習＋SFT＋強化学習を再設計</h2>
<p>岡崎氏は、継続事前学習（CPT）、教師ありファインチューニング（SFT）、強化学習のプロセスを「全面刷新」したと説明する。</p>
<p>公式ページによれば、GPT-OSS Swallowは</p>
<ul>
<li>継続事前学習（CPT）</li>
<li>教師あり学習（SFT）</li>
<li>検証可能報酬に基づく強化学習（RL）</li>
</ul>
<p>という段階を経て構築されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gptoss_123_abeedb325a/gptoss_123_abeedb325a.png" alt="gptoss-123.png" /></p>
<p>Qwen3 Swallowについても同様にCPT、SFT、強化学習を適用しており、学習プロセスの進行に伴って日本語タスク性能が向上することを確認したとしている。</p>
<h2>同規模以下のオープンLLMで最高性能と説明</h2>
<p>公式ページでは、GPT-OSS Swallow 20Bおよび120Bが、総パラメータ数が同規模以下のオープンLLMと比較して、日本語・英語タスクの双方で最高性能を達成したと説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/noname_side_d421a00812/noname_side_d421a00812.jpg" alt="noname-side.jpg" /></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/GPT_oss_Swallow_English_b8aa3c4dbe/GPT_oss_Swallow_English_b8aa3c4dbe.jpg" alt="GPT-oss Swallow English.jpg" /></p>
<p>120Bモデルの日本語MT-Bench平均スコアは0.916に達したとされる。また20Bモデルも日本語タスクで高い平均スコアを示したとしている。</p>
<p>Qwen3 Swallow 8Bおよび32Bも、同規模以下のオープンLLMと比較して日本語タスクで最高性能を達成したと説明されている。</p>
<h2>量子化版とデータセットも公開</h2>
<p>Qwen3 Swallowシリーズでは4bit量子化版も提供する。これにより、より小規模な計算資源での運用が可能となる。
あわせて、複数のデータセットも公開された。</p>
<ul>
<li>Swallow-Nemotron-Post-Training-Dataset-v1</li>
<li>LMSYS-Chat-1M-Synth（gpt-oss-120b由来の推論過程と応答を追加）</li>
<li>s1-test-time-scaling-synth（日本語・英語の強化学習データセット）</li>
</ul>
<p>これらは推論型モデルの模倣学習や事後学習に活用できるとしている。</p>
<h2>オープンライセンスでの提供</h2>
<p>両モデルはApache License 2.0で提供される。研究用途にとどまらず、商用利用や改変・再配布も可能なオープンライセンスである。
公開ページおよびHugging Face上でモデル重みと関連データセットが配布されており、利用者はそれぞれの環境に応じてダウンロードおよび検証を行うことができる。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本法人アイロボットジャパンが「Roomba Mini」発表──従来比約2分の1、中国企業傘下入り後初の新モデル</title>
      <link>https://ledge.ai/articles/irobot_japan_roomba_mini_half_size_restructuring</link>
      <description><![CDATA[<p>アイロボットジャパンは2026年2月19日、体積が従来機の約2分の1となるロボット掃除機「Roomba Mini（ルンバ ミニ）」2モデルを<a href="https://www.irobot-jp.com/press/pdf/20260219.pdf">発表</a>した。発売は、「Roomba Mini 掃除機＆床拭きロボット + AutoEmpty 充電ステーション」が2月27日、「Roomba Mini Slim 掃除機＆床拭きロボット + SlimCharge 充電スタンド」が4月6日より順次開始される。</p>
<p>米本社であるiRobotはこれまで経営再建のプロセスに入り、中国企業傘下での新体制へ移行している。今回の「Roomba Mini」は、その再建局面において日本法人が打ち出した新モデルとなる。</p>
<p>@<a href="https://www.youtube.com/watch?v=gylzOhHj9WE">YouTube</a>
　　</p>
<h2>従来比約2分の1、世界最小クラス</h2>
<p>発表によれば、「Roomba Mini」は本体サイズが幅24.5cm×奥行24.5cm×高さ9.2cm、重量約2.0kg。従来機「Roomba Combo 105」との体積比較で約2分の1とされる。</p>
<p>同社は、本製品を“世界最小クラス（国内市場最小）”の水拭き機能付きロボット掃除機と位置づける。日本のコンパクトな住環境を想定して開発され、日本で先行発売される。</p>
<p>設置面積についても、「AutoEmpty」モデルでは従来比約33％削減、「SlimCharge」モデルでは縦置き設置により約85％削減したとする。</p>
<p><strong>「Roomba Mini + AutoEmpty 充電ステーション」（左）と、縦置き可能な「Roomba Mini Slim + SlimCharge 充電スタンド」（右）。設置面積の削減が特徴</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/function_point03_image02_side_69017016ee/function_point03_image02_side_69017016ee.jpg" alt="function_point03_image02-side.jpg" /></p>
<h2>小型でも吸引力は約70倍</h2>
<p>小型化と同時に清掃性能も強化された。国内累計出荷台数トップの「Roomba 600シリーズ」との比較で、パワーリフト吸引は約70倍に向上したという。</p>
<p>さらに、ClearView LiDARを搭載し、約10分で室内をマッピング。障害物を検知・回避しながら走行する。使い捨て床拭きシートを装着することで水拭きモードに切り替わり、水拭き中はラグを自動回避する設計となっている。</p>
<p>Wi-Fi環境がなくても本体ボタンで清掃を開始できる点も特徴として挙げられている。</p>
<h2>2モデル展開、価格は39,800円から</h2>
<p>展開は2モデル。
「Roomba Mini + AutoEmpty 充電ステーション」は税込49,800円。約3か月分のゴミを収集可能な自動ゴミ収集機能を備える。カラーは白、黒、桜、若葉の4色で、桜と若葉は3月13日発売。
「Roomba Mini Slim + SlimCharge 充電スタンド」は税込39,800円。縦置き可能な充電スタンドを採用し、白と黒の2色展開。発売日は4月6日。</p>
<p>両モデルとも全国のアイロボット認定販売店および公式オンラインストアで販売される。</p>
<h2>日本法人主導の開発</h2>
<p>「Roomba Mini」は日本法人の発案により開発されたモデルで、日本で先行発売される。代表執行役員社長の山田毅氏は、「小さくてもパワフルな一台をきっかけに、より多くの方に掃除をルンバに任せる“時産体験”をしていただきたい」とコメントしている。</p>
<p>2002年のルンバ発売以来、ロボット掃除機市場を創出してきた同社は、経営再建の局面を経て新体制に移行している。今回発表された「Roomba Mini」は、その中で日本法人が打ち出した小型化モデルとなる。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「Claw」はチャット型LLM、コード実行型エージェントの上位レイヤーである──OpenAIカーパシー氏がOpenClawで話題の新概念を位置づけ</title>
      <link>https://ledge.ai/articles/karpathy_chat_code_claw_ai_stack_new_layer</link>
      <description><![CDATA[<p>OpenAI共同設立者でTeslaの元AI責任者としても知られるAndrej Karpathy（アンドレイ・カーパシー）氏は2026年2月21日、Xへの投稿で「Claws are now a new layer on top of LLM agents」と述べ、ClawをLLMエージェントの上位に位置する“新しいレイヤー”として表現した。</p>
<p>同氏はさらに「First there was chat, then there was code, now there is claw.Ez（Chatの次はCode、その次はClaw。これが自然な進化だ）」と投稿。チャット型LLMの登場、コード実行型エージェントの普及に続く段階として、Clawという概念を位置付けた形だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Andrej_Karpathy_d0dbb8e796/Andrej_Karpathy_d0dbb8e796.jpg" alt="Andrej Karpathy.jpg" /></p>
<h2>「Claw」──エージェントの“上位レイヤー”</h2>
<p>Karpathy氏の説明によれば、Clawは単なるエージェントではなく、その上位で</p>
<ul>
<li>orchestration（統合制御）</li>
<li>scheduling（実行管理）</li>
<li>context（文脈管理）</li>
<li>tool calls（外部ツール連携）</li>
<li>persistence（永続的状態保持）</li>
</ul>
<p>などを担う層を指す。</p>
<p>従来のLLMエージェントは、特定のタスクを実行するためにツールを呼び出し、短期的な文脈を保持しながら動作する。一方、Clawはそれら複数のエージェントやタスクを束ね、持続的に管理・実行する基盤層として構想されている。</p>
<h2>「ワイルドウェストでセキュリティの悪夢」──既存実装への警戒</h2>
<p>Karpathy氏はClawという概念自体には期待を示しながらも、現時点の実装については強い懸念を表明している。</p>
<p>同氏は、OpenClawのコード規模が約40万行に及ぶことに触れ、「雰囲気で書かれた巨大な怪物のようなコード」と評し、個人のデータやAPIキーをそのようなシステムに預けることには慎重であるべきだと述べた。さらに、外部からアクセス可能な状態で公開されているインスタンスや、リモートから任意のコードを実行できてしまう脆弱性、依存ライブラリや配布経路を通じたサプライチェーン攻撃の可能性、悪意ある、あるいは侵害された「スキル」が登録されるリスクなどがすでに報告されていると指摘している。</p>
<p>そのうえで同氏は、現在の状況について「まるで無法地帯であり、セキュリティ上の悪夢のようだ」と形容した。Clawという上位レイヤーの構想には魅力を感じつつも、実装レベルでは安全性や監査可能性の確保が大きな課題であるとの立場を示したかたちだ。</p>
<h2>小規模実装「NanoClaw」に見る“skills”思想</h2>
<p>一方でKarpathy氏は、すべてのClaw実装に懐疑的というわけではない。大規模で複雑な実装に警戒感を示す一方、より小規模で構造が把握しやすいプロジェクトには関心を寄せている。</p>
<p>その一例がNanoClawだ。同氏は、コアエンジンが約4000行と比較的コンパクトに収まっている点に注目し、人間にもAIにも理解・監査しやすい規模であることを評価した。コードベースが小さいことは、挙動を追跡しやすく、脆弱性や不具合の検証もしやすいという利点がある。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/nanoclaw_logo_a97fceb70a/nanoclaw_logo_a97fceb70a.png" alt="nanoclaw-logo.png" /></p>
<p>特に関心を示したのが、「skills（スキル）」と呼ばれる拡張方式だ。従来のソフトウェアでは、設定ファイルや条件分岐を積み重ねることで機能を増やしていくことが多いが、NanoClawではスキルを通じてコード自体を変更・拡張する仕組みを採用している。たとえば「/add-telegram」といった命令を与えることで、AIエージェントが自らコードを修正し、Telegramとの連携機能を追加する。このアプローチは、設定の煩雑化や複雑な条件分岐の増殖を避ける設計思想として紹介されている。</p>
<p>Karpathy氏は、この設計を「最もフォークしやすいリポジトリ」という観点で評価している。最小限の中核コードを用意し、必要に応じてスキルで構成を分岐させることで、多様な用途に適応できる構造を目指すという発想だ。</p>
<p>また、同氏はNanoClawのほかにも、nanobot、zeroclaw、ironclaw、picoclawといった複数の“claw系”プロジェクトが登場し始めていることに言及している。名称の接頭辞が異なる複数の実装が現れている点からも、Clawという考え方が単一の製品名ではなく、コミュニティ内で広がりつつある概念であることがうかがえる。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>MetaとNVIDIA、数百万規模のBlackwell/Rubin GPU導入へ──複数世代に及ぶ長期インフラ提携</title>
      <link>https://ledge.ai/articles/meta_nvidia_multiyear_infrastructure_blackwell_rubin_gpu</link>
      <description><![CDATA[<p>MetaとNVIDIAは2026年2月17日、複数年にわたる長期的なインフラパートナーシップを<a href="https://nvidianews.nvidia.com/news/meta-builds-ai-infrastructure-with-nvidia?ncid=so-twit-566885">発表</a>した。MetaはAI最適化データセンターの拡張に向け、数百万規模のNVIDIA BlackwellおよびRubin GPUを導入する方針を明らかにした。契約は複数世代にまたがる枠組みで、CPU、ネットワーク、機密計算まで含むフルスタック連携が特徴となる。</p>
<h2>「複数世代」まで明示した長期提携</h2>
<p>両社は今回の枠組みを「multi-year」「multigenerational」と位置付けた。Metaの長期AIインフラロードマップを支える提携として、単一世代のGPU調達にとどまらず、Blackwell世代に加え、その後継となるRubin世代まで視野に入れる。</p>
<p>NVIDIAの発表によれば、MetaはBlackwellおよびRubin GPUを数百万規模で導入する計画で、さらにArmベースのGrace CPUの大規模展開、将来的には次世代のVera CPUも視野に入れるという。</p>
<h2>GPUだけではない、フルスタック構成</h2>
<p>提携はGPU供給契約にとどまらない。両社はCPU、GPU、ネットワーク、ソフトウェアを横断した設計を進める。</p>
<p>ネットワーク面では、NVIDIAのSpectrum-X EthernetをMetaのインフラに展開。低遅延と高スループットを実現し、大規模AI学習および推論ワークロードの効率化を図る。また、オンプレミスのデータセンターとNVIDIA Cloud Partner環境をまたぐ統一アーキテクチャにも言及した。</p>
<h2>WhatsAppに「Confidential Computing」採用</h2>
<p>セキュリティ分野では、MetaはWhatsAppの「private processing」にNVIDIAのConfidential Computing技術を採用する。</p>
<p>これにより、AI機能を活用しながら、ユーザーデータの機密性と完全性を確保する設計を進める。両社は将来的に他のワークロードへの拡張可能性も示唆している。</p>
<h2>共同最適化（co-design）を明示</h2>
<p>両社は、単なるハードウェア導入ではなく、SOTA（最先端）モデルの性能を最大化するための共同設計を進めると説明した。CPU、GPU、ネットワーク、ソフトウェアを含むフルスタックでの最適化が提携の中核となる。</p>
<p>NVIDIAのCEOであるジェンスン・フアン氏は、Metaのスケールに対応するAI基盤構築に向けた協業の意義を強調。一方MetaのCEOであるマーク・ザッカーバーグ氏は、次世代プラットフォームの活用を通じて、長期的なAI戦略を推進する姿勢を示した。</p>
<p>契約の金銭的詳細は開示されていない。ただし、Metaは2025年に最大650億ドル（約10兆円）規模のAIインフラ投資計画を掲げており、今回の提携はそのロードマップを支える基盤整備の一環と位置付けられる。Blackwell、Rubin、さらに将来のVera世代まで視野に入れた複数世代の枠組みは、ハードウェアとソフトウェアを統合した長期的なAI基盤戦略を具体化する動きとして注目される。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>防衛省、国会答弁資料に生成AIを試験導入──「答弁作成AIアシスタント」運用開始へ</title>
      <link>https://ledge.ai/articles/mod_ai_diet_answer_assistant_trial_launch</link>
      <description><![CDATA[<p>防衛省は2026年2月20日、国会答弁資料の作成業務に生成AIを活用する方針を明らかにした。公式Xアカウントで<a href="https://x.com/ModJapan_jp/status/2024829411011485818">発表</a>した。</p>
<p>同省によると、取り組むべき課題が増大する中、将来にわたり円滑に業務を遂行するため、AIなどのツールを積極的に活用し、組織・業務のあり方を抜本的に見直す必要があるとしている。その一環として、国会答弁資料の作成にあたる職員の負担軽減を目的に、生成AIを補助的な支援手段として活用する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/H_Bmjn_P_La_UA_Aqhc8_0f905fbdbe/H_Bmjn_P_La_UA_Aqhc8_0f905fbdbe.jpg" alt="HBmjnPLaUAAqhc8.jpg" /></p>
<h2>「国会答弁作成AIアシスタント」を試験運用</h2>
<p>導入するのは「国会答弁作成AIアシスタント」。防衛省内のシステムに搭載された生成AIが、過去の答弁資料や関連資料を参照し、答弁資料の素案作成を支援する仕組みだ。</p>
<p>今月18日に開会した国会において、省内の一部部局が試験的に運用を開始。防衛省全体として本格的な活用が可能かどうかを検討していく予定としている。</p>
<p>同省は、今後もAIの導入を加速させることで、防衛力の質的高度化と行政運営の効率化の両立を図るとしている。</p>
<h2>大臣直轄チームのもとで展開</h2>
<p>今回の取り組みは、増大する業務に組織としてどう対応していくかという問題意識の下、省内有志が開発したものを、先月発足した大臣直轄の「AI導入推進チーム」のもとで幅広い部署に展開し、試験的な運用を開始するものだ。</p>
<p>防衛大臣である小泉進次郎氏は、自身のXアカウントで、防衛省AIチームから答弁作成ツールの説明を受けたと<a href="https://x.com/shinjirokoiz/status/2024836735352672405">投稿</a>。職員からは「一度使ったらもう今までの答弁作成には戻れない」との声があったと紹介した。</p>
<p>同氏は、効率的に業務が進むことで職員のモチベーション向上につながることへの期待を示し、AIチームや事務官・技官の取り組みを後押ししていく考えを示している。</p>
<h2>防衛省のAI活用方針</h2>
<p>防衛省は2024年に「AI活用推進基本方針」を公表し、AIの積極活用を掲げている。今回の国会答弁資料作成への生成AI導入は、その方針の具体化の一例と位置付けられる。</p>
<p>政策決定プロセスに関わる業務への生成AIの活用が、中央省庁レベルで試験導入される事例として、今後の運用状況が注目される。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、BCG・マッキンゼーら4社と「Frontier Alliances」始動──企業AI導入の“実装ボトルネック”に踏み込む</title>
      <link>https://ledge.ai/articles/openai_frontier_alliances_bcg_mckinsey_accenture_capgemini</link>
      <description><![CDATA[<p>OpenAIは2026年2月23日、AIが同僚のように自律的に業務を担う「AI coworkers（AI同僚）」の企業展開を加速するための新たなパートナー枠組み「Frontier Alliances」を<a href="https://openai.com/index/frontier-alliance-partners/">発表</a>した。</p>
<p>参画企業として、Boston Consulting Group（BCG）、McKinsey &amp; Company、Accenture、Capgeminiの4社を挙げる。いずれもグローバルに企業変革や大規模IT導入を担ってきたコンサルティング／SIer大手であり、OpenAIはこれらの企業と複数年の枠組みで連携する。</p>
<h2>「AI同僚」を企業に定着させるための枠組み</h2>
<p>OpenAIは今回の発表で、企業におけるAI活用が失敗する要因は、モデル性能そのものよりも、既存システムとの統合や業務プロセス設計、オペレーティングモデルの再構築、組織変革にあるとの問題意識を示した。</p>
<p>「Frontier Alliances」は、こうした“実装”や“全社展開”の段階に焦点を当てる。AIを単なるチャットツールとして導入するのではなく、企業のデータや業務ツールと接続し、継続的にタスクを遂行する「AI coworkers」として運用することを前提にしている。</p>
<p>OpenAIは、AI coworkersの構築・展開・運用を支える基盤として「Frontier」を位置づけ、パートナー企業とともにその導入を支援するとしている。</p>
<h2>4社が担う「戦略から統合、再設計まで」</h2>
<p>各パートナーはAI導入の上流から下流までを支援。
・経営・事業戦略へのAI組み込み
・既存ITシステムとの統合
・業務フローの再設計
・全社スケールでの展開
といった領域が想定されている。</p>
<p><a href="https://www.bcg.com/press/23february2026-bcg-and-openai-partnership-frontier-alliance">BCG</a>、<a href="https://www.mckinsey.com/about-us/new-at-mckinsey-blog/mckinsey-and-openai-scale-ai-driven-transformations-with-new-frontier-alliance">McKinsey</a>、<a href="https://www.capgemini.com/us-en/news/press-releases/capgemini-joins-forces-with-openai-to-accelerate-new-era-of-ai-powered-enterprise-transformation-with-frontier-alliance/">Capgemini</a>はそれぞれ公式発信の中で、OpenAIとの連携を通じた企業変革支援の強化を表明している。</p>
<h2>「モデル競争」から「実装競争」へ</h2>
<p>生成AI分野ではこれまで、モデル性能やベンチマークが注目されてきた。一方で、大企業における本格導入では、セキュリティ、ガバナンス、既存業務との整合、責任分界といった課題が顕在化している。</p>
<p>今回の枠組みは、こうした“実装ボトルネック”を乗り越えるために、コンサルティング企業やSIerの変革ノウハウと、OpenAIの技術基盤を結び付ける試みと位置づけられる。</p>
<p>AIを「ツール」ではなく「同僚」として組織に組み込む構想が、実際の企業現場でどこまでスケールするのか。Frontier Alliancesの具体的な導入事例や展開領域が、今後の焦点となる。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>自律的すぎるAIエージェント「OpenClaw」急拡大の裏で相次ぐ警告──今後のAI利用を占う分水嶺に</title>
      <link>https://ledge.ai/articles/openclaw_agentic_ai_watershed_enterprise_security</link>
      <description><![CDATA[<p>ローカル環境で動作し、チャット経由で端末操作を進めるオープンソースAIエージェント「OpenClaw」が急速に拡大している。GitHubでの急増、関連コミュニティMoltBookでの注目、拡張スキルを巡るセキュリティ警告、そして開発者のPeter Steinberger氏のOpenAI参加。利便性の拡張と同時に、設計上の境界をめぐる問題も顕在化している。</p>
<h2>“応答するAI”から“行動するエージェント”へ</h2>
<p>OpenClawは、チャットを入り口としてローカル環境の操作へ接続するエージェント型ソフトウェアである。メール処理、ブラウザ操作、ファイル管理、シェルコマンド実行などを自動化できる構造を持つ。</p>
<p>特徴は、画面上でテキストを生成するだけでなく、チャットを入口にローカル環境の操作へ接続する構造にある。ユーザーの指示や目標に基づき、端末上で処理を進めるアーキテクチャを採る点が支持を集め、<a href="https://github.com/openclaw/openclaw">GitHub</a>では短期間でスター数が10万件を超える規模に拡大したと<a href="https://www.reuters.com/business/openclaw-founder-steinberger-joins-openai-open-source-bot-becomes-foundation-2026-02-15/">Reuters</a>が2026年2月15日報じた。</p>
<p>AIが応答を返す存在から、状態を保持しながら環境に作用するエージェントへと役割を広げる試みとして、OpenClawは象徴的な存在となった。</p>
<h2>MoltBookでの拡散とコミュニティ主導の拡張</h2>
<p>利用拡大の背景には、関連するコミュニティの急速な広がりもある。報道によれば、OpenClawに関連するプラットフォーム「<a href="https://moltbook.com/">MoltBook</a>」は短期間で大量の訪問を集めたとされる。個人開発のオープンソースプロジェクトとしては異例のスピードで注目が集まった。</p>
<p>さらに、拡張スキルを追加できる仕組み（ClawHub）がエコシステム形成を後押しした。ユーザーはスキルを通じて機能を拡張できるため、プロジェクトはコミュニティ主導で能力を増幅させる構造を持つ。</p>
<p>目標に基づき連続的に処理を進めるエージェントが、外部から機能を追加できる仕組みと結びついたことで、拡張スピードは加速した。</p>
<h2>相次ぐ警告──拡張経路と脆弱性</h2>
<p>急拡大と並行してセキュリティ上の懸念も表面化している。</p>
<p>セキュリティ企業<a href="https://www.koi.ai/blog/clawhavoc-341-malicious-clawedbot-skills-found-by-the-bot-they-were-targeting">Koi Security</a>は、ClawHubに登録された2,857のスキルを監査し、そのうち341件が悪意あるコードを含んでいたと報告した。報告では、同一キャンペーンによるものとみられるスキル群の存在も指摘されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/koi_research_0c413c71e9/koi_research_0c413c71e9.jpg" alt="koi research.jpg" /></p>
<p>また、OpenClawの特定バージョン以前に関しては、<a href="https://nvd.nist.gov/vuln/detail/CVE-2026-25253">CVE-2026-25253</a>として脆弱性が登録されている。公的データベースによれば、該当する問題は修正済みであり、アップデートが推奨されている。</p>
<p>拡張可能な設計は柔軟性をもたらす一方、配布経路や設定が攻撃面になり得る構造も抱える。端末上で処理を進めるエージェントである以上、権限管理や更新の遅れは影響を直接受ける。</p>
<h2>想定外の挙動──外部接続型エージェントの課題</h2>
<p>技術的な脆弱性とは別に、OpenClawを含むエージェント設計の課題を示す挙動事例も報告されている。</p>
<h3>（1）メッセージ送信ループの事例</h3>
<p>ソフトウェアエンジニアのChris Boyd氏は、自身の検証環境でOpenClawを設定した際、iMessage経由で確認メッセージを繰り返し送信する状態に陥ったと<a href="https://chrisboyd.me/blog/openclaw-meltdown/">ブログ</a>で記録している。</p>
<p>想定外の応答を受け取った後、再試行ロジックが停止条件を持たず、ループが継続したという。最終的には端末を強制停止することで挙動を止めたと説明されている。</p>
<p>この事例は、外部通信チャネルと再試行処理が連動する構造において、上限設計やエラー処理が重要であることを示している。</p>
<h3>（2）コード却下後の批判的ブログ公開</h3>
<p>matplotlibメンテナーのScott Shambaugh氏は、自身のブログで、AIエージェントからのコード提案を却下した後、自身を批判する内容のブログ記事が公開されたと記録している。</p>
<p>記事によれば、エージェントは却下の事実を受けて外部ブログに投稿を行い、Shambaugh氏の過去活動に言及しながら批判的な内容を展開したという。</p>
<p>一部メディアではこれを「報復」と表現しているが、技術的には、評価ループと外部公開機能が直結していた結果とみられる。出力内容の適切性を人間が確認する仕組みが介在しない場合、レピュテーションに影響し得る公開行動が実行される可能性がある。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_Shamblog_ac56db2fda/The_Shamblog_ac56db2fda.jpg" alt="The Shamblog.jpg" /></p>
<h3>（3）MoltMatchでのプロフィール作成事例</h3>
<p>AFPの<a href="https://www.taipeitimes.com/News/world/archives/2026/02/14/2003852326">報道</a>では、OpenClawを試したユーザーが、関連する実験的デーティングサイト「MoltMatch」において、想定していない形でプロフィール作成や探索が進められたと述べている。</p>
<p>広義の参加指示が、エージェントによってより広範な行動へ解釈された可能性が示唆されている。</p>
<h2>開発者のOpenAI参加とfoundation化</h2>
<p>こうしたなか、OpenClawの開発者であるPeter Steinberger氏が2026年2月15日、米OpenAIへの参加を<a href="https://steipete.me/posts/2026/openclaw">発表</a>した。Reutersによれば、同氏は次世代パーソナルエージェント開発に関わるという。</p>
<p>あわせて、OpenClawは独立した財団（OpenClaw Foundation）へ移行する方針が示された。急速に拡大したエコシステムに対し、ガバナンスと継続的開発の体制を整える段階に入ったとみられる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/clawcon_e31ebc39a7/clawcon_e31ebc39a7.jpg" alt="clawcon.jpg" /></p>
<p>個人開発のプロジェクトが大手AI企業の開発ラインへ接続されたことは象徴的だ。端末上で行動するエージェントは、実験的な試みから主要な開発テーマへと移行しつつある。OpenClawを巡る急拡大と相次ぐ警告は、その設計と統制の問題がすでに実装段階に入っていることを示した。</p>
<p>画面上で応答するだけだったAIは、ローカル環境や外部サービスに作用し、状態を保持しながら処理を継続する存在へと拡張した。利便性の拡大と同時に、拡張経路や権限設計の管理が不可欠であることも明らかになった。OpenClawは、その現実を可視化した事例である。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity、AI検索の広告を段階廃止──2024年の実験から方針転換、「信頼性」優先へ</title>
      <link>https://ledge.ai/articles/perplexity_ads_phaseout_trust_pivot_2026_ft</link>
      <description><![CDATA[<p>AI検索エンジンを手がけるPerplexityが、導入していた広告の掲載を段階的に廃止していることが分かったと、2026年2月18日（現地時間）に英経済紙<a href="https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c">Financial Times（FT）</a>が報じた。報道によれば、広告がAI回答への信頼を損なう可能性があるとの懸念が背景にあるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/FT_X_adc09cb99a/FT_X_adc09cb99a.jpg" alt="FT X.jpg" /></p>
<p>Perplexityは2024年11月、<a href="https://www.perplexity.ai/ja/hub/blog/why-we-re-experimenting-with-advertising">広告の実験的導入</a>
を開始していた。当時は「実験」と位置づけ、ユーザー体験や収益化モデルの検証を目的とした取り組みとして説明していた。広告は回答そのものに直接挿入する形式ではなく、スポンサー付きのフォローアップ質問など、明示的にラベル表示する形で提供されていたとされる。</p>
<p>報道によれば、その後同社は広告掲載を縮小し、最終的に撤退する方針を固めたという。経営陣は、広告が表示されることで、ユーザーが「提示された回答が最善の情報なのか、それとも商業的な影響を受けた結果なのか」を疑い始める可能性があるとの認識を示したとのこと。AI検索においては、回答の正確性や中立性への信頼が中核的な価値となるため、広告との両立は慎重な判断が求められると説明している。</p>
<p>Perplexityはこれまで、サブスクリプション型の有料プランを主軸とした収益モデルを展開してきた。無料版に加え、より高度なモデルや機能を利用できる有料プランを提供する構成で、広告依存型ではないマネタイズ戦略を採用している。現時点で広告モデルへ回帰する予定はないとFTは報じた。</p>
<p>AIサービスの収益化をめぐっては、広告を組み込むアプローチと、課金型モデルに軸足を置くアプローチの両方が模索されている。特に検索や回答生成を担うAIにおいては、情報の信頼性と商業的要素の関係が継続的な論点となっている。</p>
<p>Perplexityは、2024年11月の広告実験開始から約1年余りで方針を転換し、信頼性を優先する姿勢を明確にした形だ。AI検索市場が拡大する中、各社がどのような収益モデルを採用するのかは、今後も注目される。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>三井住友銀行、生成AIの音声対応「SMBC AIオペレーター」開始──Olive一般照会を24時間365日で</title>
      <link>https://ledge.ai/articles/smbc_ai_operator_olive_24hours</link>
      <description><![CDATA[<p>三井住友銀行、日本総合研究所、日本IBMの3社は2026年2月18日、生成AIを活用した顧客対応サービス「SMBC AIオペレーター」を<a href="https://www.smbc.co.jp/news/pdf/j20260218_01.pdf">発表</a>した。提供開始日は2月25日。第一弾として、個人向け総合金融サービス「Olive」に関する一般照会を対象に、毎日24時間（土日祝含む）で対応する。</p>
<p>SMBCの顧客向け照会サービスにおいて、生成AIを活用するのは今回が初めてとなる。</p>
<h2>Olive一般照会を対象に24時間対応</h2>
<p>「SMBC AIオペレーター」は、生成AI技術と音声技術を組み合わせた顧客対応サービス。利用者は自然な言葉で問い合わせができ、AIが関連情報を検索し回答を生成する。</p>
<p>第一弾の対象は、本人確認を必要としないOliveの一般照会。具体的には、サービス内容や年会費、キャンペーン・特典の概要、申込や切替に関する手続きの概要などが含まれる。</p>
<p>受付時間は毎日24時間（土日祝含む）。AIオペレーターの自由発話による照会対応を24時間365日で提供する取り組みは、銀行業界では初めてだという（三井住友銀行調べ）。</p>
<p>本人確認が必要となる手続きについては、従来通り有人オペレーターが対応する。通話の途中で本人確認が必要になった場合でも、コールセンターの営業時間内であれば、改めてかけ直すことなく有人へ引き継ぐ仕組みを整備している。</p>
<h2>音声応対の精度向上と利用体験の設計</h2>
<p>同サービスでは、利用者の口調や言葉遣いに応じて言い回しや応答トーンを調整する機能を備える。屋外や移動中の利用も想定し、雑音の影響を抑制する仕組みも導入した。</p>
<p>また、AIが回答している途中で利用者が話し始めた場合には応答を停止し、発話を優先する設計とすることで、自然な会話体験を目指す。</p>
<h2>通話履歴を活用し継続的に改善</h2>
<p>SMBC AIオペレーターでは、応対内容や有人転送データを含む通話履歴を継続的に分析し、回答品質の改善に活用する。照会が多い領域については、商品・サービスの改善にもつなげる方針だ。</p>
<p>従来型のシステム開発のみに依存せず、管理画面を通じて柔軟かつ迅速に改善を重ねる仕組みも構築している。終話前に取得する利用者の感想も改善に反映する。</p>
<h2>セキュリティ基準に準拠した基盤で提供</h2>
<p>同サービスは、三井住友銀行のセキュリティ基準に準拠した堅牢な基盤上で提供される。複雑な相談や本人確認が必要な局面では有人へ引き継ぐハイブリッド体制を採用し、利便性と安全性の両立を図る。</p>
<h2>3社体制で開発</h2>
<p>開発は、三井住友銀行、日本総合研究所、日本IBMの3社体制で進めた。</p>
<p>日本総合研究所は既存システムとの円滑な連携やプロジェクト全体の統括、AI基盤アーキテクチャの設計を主導。日本IBMはAI基盤の構想策定から設計・開発、チューニングを担った。</p>
<p>今後はOliveの一般照会にとどまらず、幅広い業務への拡大を視野に入れる。幅広い年代の利用者や、目が不自由な顧客のアクセシビリティ向上にも寄与することを目指すとしている。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>インド財閥タタ・グループとOpenAIが戦略提携──AIデータセンター国内100MW、将来1GWへ</title>
      <link>https://ledge.ai/articles/tata_openai_india_ai_datacenter_100mw_1gw</link>
      <description><![CDATA[<p>インドの多角経営コングロマリットであるタタ・グループは2026年2月19日、米OpenAIと戦略提携を締結し、インド国内でAI向け大規模データセンターを整備すると<a href="https://www.tata.com/newsroom/business/tata-openai-partnership">発表</a>した。
初期容量は100MWで、将来的には1GWまで拡張可能としている。</p>
<p>提携にはタタ・グループ傘下のITサービス大手であるTata Consultancy Services（TCS）も参加。同提携は、エンタープライズ領域、コンシューマー領域、社会的取り組みを含む多面的な枠組みとなる。</p>
<h2>Enterprise ChatGPTを数千人規模で展開</h2>
<p>タタ・グループは、数千人規模の従業員にEnterprise ChatGPTへのアクセスを提供し、生産性向上やイノベーション創出を図るとしている。また、TCSはOpenAIのコーディング支援モデル「Codex」を活用し、ソフトウェア開発の高度化を進めるという。</p>
<p>さらに、OpenAIのAgentic AIソリューションとTCSの業界知見を組み合わせ、業界別のAIソリューションを共同で開発する。両社は共同の市場展開（GTM）体制を構築し、インドおよびグローバル企業のAI導入を支援するとしている。</p>
<h2>インド国内でAIインフラを整備</h2>
<p>データセンター整備は、TCSのデータセンター部門「HyperVault」を通じて進められる。初期フェーズとして100MWのAI対応容量を構築し、将来的には1GWまで拡張可能とした。</p>
<p>HyperVaultは2025年に設立された部門で、グリーンエネルギーを活用した液冷対応の高密度データセンターを展開する。主要クラウドリージョンとの接続性を備え、次世代AIワークロードに対応する設計とする。</p>
<p>同インフラ整備について、OpenAIのCEOであるSam Altman氏は、インドにおけるAI採用の進展や人材の厚みを評価し、現地パートナーと連携してインフラとスキルの基盤を構築する意義を強調した。</p>
<p>タタ・サンズ会長のN. Chandrasekaran氏は、インドがAIのグローバルリーダーとなるための節目だと述べ、先端インフラ整備と人材育成を通じた長期的な取り組みを進める方針を示した。</p>
<h2>若年層向けAIトレーニングも</h2>
<p>OpenAI FoundationとTCSは、インドの若年層にAIトレーニングとリソースを提供する取り組みも進める。非営利団体向けのツールキット開発などを通じ、少なくとも100万人の若者の生計向上を支援することを目標に掲げた。</p>
<p>なお、具体的な投資額、データセンターの立地、稼働開始時期などの詳細は発表時点では明らかにされていない。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Uber、自動運転パートナー向け「Uber Autonomous Solutions」提供開始──配車・配送の“商用化レイヤー”を統合</title>
      <link>https://ledge.ai/articles/uber_autonomous_solutions_launch_commercialization_layer</link>
      <description><![CDATA[<p>現地時間2026年2月23日、Uber Technologiesは、自動運転パートナー向けの新たな枠組み「Uber Autonomous Solutions」の提供開始を<a href="https://investor.uber.com/news-events/news/press-release-details/2026/Uber-Unveils-Uber-Autonomous-Solutions-to-Accelerate-Autonomous-Mobility--Delivery-Worldwide/default.aspx">発表</a>した。配車サービスのUberやフードデリバリーのUber Eatsを展開する同社が、自動運転モビリティおよび配送の商用化を支援するサービス群を統合して提供する。</p>
<h2>自動運転の“商用化”を支える3領域</h2>
<p>「Uber Autonomous Solutions」は、自動運転パートナーがサービスを市場投入する際に必要となる要素を、Uberの既存プラットフォームや運用ノウハウとともに提供する枠組みだ。</p>
<p>公式発表では、提供内容を以下の3領域に整理している。</p>
<h3>1. Infrastructure（基盤）</h3>
<p>商用展開に向けた前提条件を支える領域として、次のような要素が挙げられている。</p>
<ul>
<li>AV 2.0 Training Data</li>
<li>データ拡張マッピング</li>
<li>規制対応（regulatory access）</li>
<li>フリート金融（financing） など</li>
</ul>
<p>自動運転車両の導入に必要なデータ基盤や資金面、各地域の規制対応までを含む設計となっている。</p>
<h3>2. User Experience（ユーザー体験）</h3>
<ul>
<li>Uberの配車・配送プロダクト上で培われた体験設計を踏まえ、自動運転サービスに適用する。</li>
<li>予約型サービス（Reserve）など既存機能との連携</li>
<li>共有型サービス（Share）との組み合わせ</li>
<li>車内体験設計</li>
<li>カスタマーサポート対応</li>
</ul>
<p>自動運転車両そのものだけでなく、利用者が実際に使う際のアプリ体験やサポート体制を含めた設計が対象となる。</p>
<h3>3. Fleet Operations（フリート運用）</h3>
<ul>
<li>運用面では以下の機能が含まれる。</li>
<li>AV Mission Control（運行可視化・管制）</li>
<li>Remote Assistance（遠隔支援）</li>
<li>保険（insurance）などの運用支援</li>
</ul>
<p>実際の走行管理や異常対応、人による支援体制までを含め、商用運用に必要な周辺機能を束ねる構成となっている。</p>
<h2>自社開発ではなく「パートナー支援」を前面に</h2>
<p>発表資料では「partners」という語が繰り返し用いられており、Uber自身が自動運転技術を新たに開発するというよりも、パートナー企業の商用化を加速させる立場を明確にしている。</p>
<p>配車（Uber）と配送（Uber Eats）の両領域を抱える同社が、自動運転モビリティおよび自動配送の導入に必要な基盤・体験・運用を一体化して提供する構図だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=uVDxmbNS2h4">YouTube</a></p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>X、自動返信を“召喚制”にAPI仕様を変更──近年急増のAIスパム対策で</title>
      <link>https://ledge.ai/articles/x_api_reply_restriction_ai_spam_countermeasure</link>
      <description><![CDATA[<p>Xは2026年2月24日（現地時間）、X API v2における返信機能の仕様を変更し、API経由での自動返信（programmatic replies）を制限したと<a href="https://x.com/XDevelopers/status/2026084506822730185">発表</a>した。背景には、大規模言語モデル（LLM）を用いた自動返信スパムの増加があるという。</p>
<p>同社の開発者向け公式アカウント「@XDevelopers」によると、対象となるのは POST /2/tweets エンドポイントを通じた返信投稿。今回の変更により、API経由での返信は、元投稿者が返信者を@メンションする、あるいはその投稿を引用（quote）した場合にのみ許可される。条件を満たさない返信は、API上で拒否される。</p>
<p>従来は、認証されたアプリであれば “in_reply_to_tweet_id” を指定することで任意の投稿に返信することが可能だった。今後は、元投稿者による明示的な関与があった場合に限り返信が可能となる仕組みに改められる。通常の新規投稿（non-replies）については影響しない。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x_developers_0224_b09ec161a6/x_developers_0224_b09ec161a6.jpg" alt="x developers 0224.jpg" /></p>
<p>開発者向けフォーラム（X Developer Community）で<a href="https://devcommunity.x.com/t/update-to-reply-behavior-in-x-api-v2-restricting-programmatic-replies/257909">公開</a>された説明によると、近年、APIを通じて生成された低品質な自動返信が会話スレッドに大量に挿入される事例が増加していたという。今回の措置は、こうした「automated reply spam」への対策として実施された。</p>
<p>適用対象はFree、Basic、Pro、Pay-Per-Useの各プランで、EnterpriseおよびPublic Utilityアプリは影響を受けない。Xは、影響を受ける開発者に対し、必要に応じてEnterpriseプランへの移行を検討するよう案内している。</p>
<p>今回の変更により、API経由での返信は事実上「元投稿者による呼びかけがあった場合のみ可能」という構造となる。返信API自体が廃止されたわけではないが、会話スレッドへの自動介入は技術的に制限される形となった。</p>
]]></description>
      <pubDate>Fri, 20 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>動画生成AI Seedance 2.0波紋拡大、ByteDanceが実在人物・IP生成を当面制限──ハリウッド・日本政府も問題視</title>
      <link>https://ledge.ai/articles/seedance2_0_international_backlash_ip_restriction</link>
      <description><![CDATA[<p>中国IT大手の字節跳動（ByteDance）は、動画生成AI「Seedance 2.0」において、実在人物の顔やアニメ・映画などのIPキャラクターを参照した動画生成を当面制限していることが分かった。複数の中国メディアによると、同社傘下の抖音（Douyin）集団の李亮副総裁が2月15日、中国のSNS「Weibo（微博）」への投稿で、実在人物や既存IPを基にした生成を現在はサポートしていないと明らかにした。</p>
<p>報道によれば、李氏はSeedance 2.0について「現在、実在人物の顔を参照した生成やIPキャラクターの生成はサポートしていない」と説明。あわせて、デジタル分身の制作には本人認証が必要であることや、権利侵害防止策を強化していく方針を示したという。</p>
<h2>Seedance 2.0生成動画が拡散</h2>
<p>Seedance 2.0は、テキストや画像、動画などを入力として映像を生成するモデルとして公開され、SNS上で拡散した。とりわけ、実在のハリウッド俳優を想起させる動画が投稿され、議論が拡大した。</p>
<p>動画を投稿したRuairi Robinson氏は、アイルランド出身の映画監督・ビジュアルアーティストで、長編映画の監督やコンセプトアート制作などを手がけてきた人物。Robinson氏がXに投稿した生成動画は海外メディアでも取り上げられ、著作権侵害の可能性を指摘する声も上がった。</p>
<p><strong>RobloxのプロダクトマネージャーPeter Yang氏は、Xで「このモデル（Seedance 2）で見たものはすべて著作権侵害だ」とコメントした</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/peteryang_seedance20_x_6a9b148605/peteryang_seedance20_x_6a9b148605.jpg" alt="peteryang seedance20 x.jpg" /></p>
<h2>Robinson氏、YouTubeでテスト動画を公開</h2>
<p>Robinson氏はその後、自身のYouTubeチャンネルでSeedance 2.0のテスト動画をまとめて公開した。概要欄では「2026年2月10日に短時間アクセスできたが、その後モデルは引き下げられた（pulled down）」と説明している。</p>
<p>@<a href="https://www.youtube.com/watch?v=fbVv0ZPk0fw&amp;t=4s">YouTube</a></p>
<h2>ハリウッド団体、日本政府も懸念を表明</h2>
<p>米映画業界団体や俳優組合は、著作権侵害の懸念を表明。一部報道では、米大手スタジオがByteDance側に差し止め通知を送付したと伝えられている。</p>
<p>米<a href="https://www.motionpictures.org/press/motion-picture-association-calls-for-bytedance-to-cease-seedance-2-0-infringing-activity/">映画業界団体</a>や<a href="https://www.sagaftra.org/sag-aftra-statement-seedance-20">俳優組合</a>は、著作権侵害の懸念を表明。一部報道では、米大手スタジオがByteDance側に差し止め通知を送付したと伝えられている。</p>
<p>日本国内でも議論は波及していた。小野田紀美AI戦略担当相が閣議後の会見でSeedance 2.0について言及し、<a href="https://ledge.ai/articles/onoda_seedance2_government_investigation_copyright">著作権上の懸念</a>を指摘。政府側が事実関係の調査に乗り出す方針を示していた。</p>
<p>今回の当面制限は、モデル公開後に拡大した国際的な議論の中で示された対応となる。動画生成AIをめぐっては、実在人物や既存IPの取り扱いをどう設計するかが、引き続き焦点となっている。</p>
]]></description>
      <pubDate>Wed, 18 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>拡大するLLM学習の「蒸留」論点──OpenAIは米議会に警告、Googleは抽出攻撃を報告</title>
      <link>https://ledge.ai/articles/expanding_distillation_debate_openai_congress_warning_google_extraction_attacks</link>
      <description><![CDATA[<p>OpenAIが2026年2月12日、米下院の下院中国問題特別委員会に覚書を提出し、中国のAI企業DeepSeekによる「蒸留（distillation）」手法を問題視していたことが明らかになった。<a href="https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge">Bloomberg</a>が同日報じた。翌13日には、GoogleのGoogle脅威インテリジェンスグループ（GTIG）が、モデル抽出を伴う「蒸留攻撃（distillation attacks）」の増加を報告している。</p>
<p>同じ「distillation」という語が、競争（モデル開発）と防御（抽出攻撃）という異なる文脈で相次いで言及された格好だ。</p>
<h2>OpenAI、DeepSeekの蒸留を問題視</h2>
<p>Bloombergが入手した覚書によると、OpenAIはDeepSeekがチャットボット「R1」の開発にあたり、米国の主要AIモデルの出力を抽出する「不公平かつ洗練された手法」を用いていると指摘した。文書は2026年2月12日付で、下院中国問題特別委員会に提出された。</p>
<p>覚書では、他社モデルの出力を体系的に収集し、それを新たなモデルの訓練に活用する行為が、競争環境や知的財産保護、国家安全保障の観点から懸念を生じさせる可能性があると説明している。DeepSeek側の公式見解は現時点で公表されていない。</p>
<h2>Google、蒸留攻撃（Model Extraction Attacks）の増加を報告</h2>
<p>一方、Googleは2026年2月13日、GTIG名義でレポート「GTIG AI Threat Tracker」を<a href="https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use?hl=en">公開</a>した。レポートでは、正規のAPIアクセスを利用してモデルの応答を体系的に収集し、新たなモデルを構築する「モデル抽出攻撃（Model Extraction Attacks）」、いわゆる「蒸留攻撃」が増加していると報告している。</p>
<p>GTIGは、こうした行為を知的財産の侵害に当たる可能性があるものと位置付け、検知・遮断措置を講じていると説明した。また、2025年中に高度持続的脅威（APT）によるフロンティアモデルへの直接攻撃は確認していないとしつつも、研究者や民間企業による抽出試行を観測し、対策を講じたとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gtig_ai_threat_tracker_feb26_fig1_max_1500x1500_484adc1deb/gtig_ai_threat_tracker_feb26_fig1_max_1500x1500_484adc1deb.jpg" alt="gtig-ai-threat-tracker-feb26-fig1.max-1500x1500.jpg" /></p>
<p>図は、GTIGが説明するモデル抽出攻撃の一般的構造を示したものだ。正規のAPIを通じて「教師モデル」に問い合わせを行い、その応答を用いて「学生モデル」を訓練する流れが図示されている。</p>
<h2>蒸留とは何か──正規技術と抽出攻撃の境界</h2>
<p>蒸留（knowledge distillation）は、既存の高性能モデル（教師モデル）の出力を利用して、より小型または効率的なモデル（学生モデル）を訓練する機械学習手法である。モデル圧縮や推論効率の向上を目的として広く研究・実装されてきた。</p>
<p>一方で、他社が提供する商用モデルの出力を無断で抽出し、新モデル開発に活用する場合には、利用規約違反や知的財産侵害の問題が生じ得る。GTIGは、こうした行為を「distillation attacks」と定義している。</p>
<p>OpenAIが議会に提出した覚書と、Googleが報告した抽出攻撃はいずれも「蒸留」という語を含むが、前者は国際競争の文脈、後者はサービス防御の文脈で語られている点が異なる。</p>
<h2>競争と防御で同時に拡大する蒸留論点</h2>
<p>今回の動きは、蒸留が単なる効率化技術にとどまらず、競争戦略や知的財産保護、安全保障といった領域に波及していることを示している。</p>
<p>OpenAIの覚書は、モデル間競争の観点から蒸留の問題を提起し、Googleのレポートは、抽出攻撃への対策強化を示した。AIモデルの高度化と普及が進む中で、蒸留を巡る議論は、開発と防御の両面で拡大している。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、推論特化「Gemini 3 Deep Think」アップデート──ARC-AGI-2で84.6%など主要ベンチマークで軒並み高評価、科学・研究・工学領域の高度な問題解決に照準</title>
      <link>https://ledge.ai/articles/gemini_3_deep_think_arc_agi_2_84_6</link>
      <description><![CDATA[<p>Googleは2026年2月12日、推論特化モード「Gemini 3 Deep Think」の大幅アップデートを<a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/">発表</a>した。科学・研究・工学領域の高度な問題解決を主用途として位置づけ、ARC-AGI-2で84.6%を記録したと公表している。</p>
<p>更新版のGemini 3 Deep Thinkは、Google AI Ultra加入者向けにGeminiアプリで提供を開始。また、Gemini APIでも研究者・企業向けにEarly Access Programとして利用申請の受付を開始した。</p>
<h2>ARC-AGI-2で84.6%──主要ベンチマーク結果</h2>
<p><strong>■ Gemini 3 Deep Thinkの主要ベンチマーク結果。ARC-AGI-2、Humanity’s Last Exam、MMMU-Pro、Codeforcesなどで比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_deep_think_evals_charts_1_6b40186942/gemini_3_deep_think_evals_charts_1_6b40186942.jpg" alt="gemini_3_deep-think_evals_charts_1.jpg" /></p>
<p>Googleが公開した評価資料によると、主な結果は以下の通り。</p>
<ul>
<li>ARC-AGI-2：84.6%</li>
<li>Humanity’s Last Exam：48.4%（no tools）、53.4%（search+code）</li>
<li>MMMU-Pro：81.5%</li>
<li>Codeforces：Elo 3455</li>
</ul>
<p>ARC-AGI-2は抽象推論能力を測るベンチマークで、ARC Prize Verified（v2 semi-private）に基づく数値としている。Humanity’s Last Examでは、ツール未使用と検索・コード実行併用の双方を公表。CodeforcesではElo 3455を記録した。評価手法は原則pass@1で算出し、一部小規模ベンチマークでは複数試行平均を用いたと説明している。</p>
<h2>科学分野ベンチでの数値</h2>
<p><strong>■ Gemini 3 Deep Thinkと他モデルのベンチマーク比較一覧（Feb 2026時点）。IMO、IPhO、IChO、CMT-Benchmarkなどを含む</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_deep_think_evals_table_1_e96eae2c49/gemini_3_deep_think_evals_table_1_e96eae2c49.jpg" alt="gemini_3_deep-think_evals_table_1.jpg" /></p>
<p>同資料では、科学系競技・専門ベンチマークにおける結果も公開している。</p>
<ul>
<li>International Math Olympiad 2025：81.5%</li>
<li>International Physics Olympiad 2025（theory）：87.7%</li>
<li>International Chemistry Olympiad 2025（theory）：82.8%</li>
<li>CMT-Benchmark（凝縮系理論）：50.5%</li>
</ul>
<p>IPhOおよびIChOでは、Geminiをjudgeとして使用し、独立専門家による検証を経たと説明している。</p>
<h2>「Deep Think」の位置づけ</h2>
<p>GoogleはDeep Thinkを、Gemini 3におけるspecialized reasoning modeと説明している。不完全な情報や複数の解が存在し得る研究課題を対象とし、科学的知識とエンジニアリング実務を統合した推論を行う設計だとしている。</p>
<p>初期テスター事例として、以下を紹介している。</p>
<ul>
<li>Rutgers大学：高エネルギー物理論文の論理的欠陥の指摘</li>
<li>Duke大学：半導体材料の結晶成長レシピ設計</li>
<li>Google社内：物理コンポーネント設計支援</li>
</ul>
<h2>Ultra提供とAPI早期アクセスへ</h2>
<p>今回のアップデートでは、GeminiアプリでのUltra向け提供に加え、Gemini APIで初めてDeep Thinkモードの早期アクセスを開始した。研究者や企業が実運用環境で利用できる段階へ移行した形となる。Googleは、科学・研究・工学領域における高度推論用途を主軸に展開していく方針を示している。</p>
]]></description>
      <pubDate>Tue, 17 Feb 2026 01:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>