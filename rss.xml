<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Google、月額1,200円のAI有料プラン「Google AI Plus」日本展開　Geminiなどの利用枠を拡張</title>
      <link>https://ledge.ai/articles/google_ai_plus_launch_japan_1200yen</link>
      <description><![CDATA[<p>Googleは2026年1月28日、AI機能の利用上限を拡大できる有料サブスクリプションプラン「Google AI Plus」を日本で提供開始したことを<a href="https://blog.google/intl/ja-jp/company-news/technology/google-ai-plus/">発表</a>した。月額料金は1,200円。Geminiをはじめとする同社の生成AI機能を、無料プランよりも広い枠で利用できる。</p>
<p>Google AI Plusは、Google Oneを通じて提供される個人向けAIプランの一つで、生成AIを日常的に活用するユーザーを主な対象とする。新規登録者向けには、最初の2カ月間を月額600円とする半額キャンペーンも用意されている。</p>
<p>同プランでは、Geminiアプリで高性能モデルである「Gemini 3 Pro」や「Nano Banana Pro」を利用できるほか、AIを活用した映像制作ツール「Flow」、リサーチや執筆を支援する「NotebookLM」など、複数のAI機能が含まれる。GmailやGoogleドキュメント、スプレッドシートといったGoogleの各種サービスに統合されたGemini機能についても、利用枠が拡張される。</p>
<p>また、Google AI Plusには200GBのクラウドストレージが付帯し、Google Drive、Gmail、Google Photosで共通利用が可能だ。ストレージやAI特典は、最大5人までの家族メンバーと共有できる。既存のGoogle One プレミアム（2TB）ユーザーについては、数日以内にGoogle AI Plus相当のAI特典が利用可能になるとしている。</p>
<p><strong>GoogleのAIサブスクリプション3プランの比較。AI Plusは月額1,200円で提供される入門プラン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae.jpg" alt="JP_aiplus_comparison.width-1000.format-webp.jpg" /></p>
<p>一方で、Googleは同プランについて、Google Workspaceのビジネスおよび教育機関向けアカウントでは利用できないとしている。</p>
<p>Googleは、個人向けに段階的なAIサブスクリプションを用意しており、Google AI Plusはその中でも入門・中核的な位置づけとなる。今後は、より高い利用上限や機能を備えた上位プランと併せて、生成AIの利用拡大を図る。</p>
]]></description>
      <pubDate>Wed, 28 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Sakana AIがGoogleと戦略的パートナーシップ締結　出資受け、基幹産業向け「信頼できるAI実装」を共同推進</title>
      <link>https://ledge.ai/articles/sakana_ai_google_strategic_partnership_reliable_ai_mission_critical</link>
      <description><![CDATA[<p>東京に拠点を置くAI企業のSakana AIは2026年1月23日、Googleと戦略的パートナーシップを締結したと<a href="https://sakana.ai/google/">発表</a>した。あわせて、Googleからの出資を受けたことも明らかにした。両社は、研究開発から社会実装までを見据えた協力関係を構築し、基幹産業向けに「信頼できるAI」の実装を共同で推進するとしている。</p>
<p>Sakana AIによると、今回の提携は、同社が掲げる研究成果を実社会のインパクトにつなげる取り組みを加速させることを目的とする。Googleの技術基盤やプロダクト群と、Sakana AIの研究開発力を組み合わせることで、AIの品質向上と実運用に耐える信頼性の確保を図る。</p>
<p>技術面では、Googleの最先端AIモデルである「Gemini」や「Gemma」を含む技術群を、Sakana AIの研究開発および製品開発に活用する方針だ。これにより、AIエージェント開発や科学研究の自動化など、同社が注力する研究テーマの高度化を目指すとしている。</p>
<p>また両社は、最高水準のセキュリティとデータ主権（data sovereignty）が求められる規制産業を中心に、Googleのプラットフォームを活用した「信頼できるAI」ソリューションの展開を進める方針を示した。リリースでは導入先の例として金融機関や政府機関を挙げている一方、個別の導入先や時期は明らかにしていない。</p>
]]></description>
      <pubDate>Tue, 27 Jan 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「AIは5層のケーキ」NVIDIAのフアンCEO、ダボス会議で語ったエネルギーからアプリまでのAI構造</title>
      <link>https://ledge.ai/articles/ai_five_layer_cake_jensen_huang_davos_wef</link>
      <description><![CDATA[<p>NVIDIAのCEOであるジェンスン・フアン氏は、スイス・ダボスで開催された世界経済フォーラム（WEF）年次総会のメインステージに登壇し、AIを<a href="https://blogs.nvidia.com/blog/davos-wef-blackrock-ceo-larry-fink-jensen-huang/">「5層のケーキ」にたとえて説明</a>した。AIを単一の技術としてではなく、エネルギーからアプリケーションに至るまで、複数の層が積み重なって初めて成立する産業基盤として捉える考え方を示した。</p>
<p>この発言は、世界経済フォーラム年次総会（通称ダボス会議）の公式セッション「Conversation with Jensen Huang, President and CEO of NVIDIA」で2026年1月21日（現地時間）に行われたもので、対談相手は米資産運用大手ブラックロックのCEO、ラリー・フィンク氏だった。</p>
<h2>ダボス会議メインステージで示された「5層」の構造</h2>
<p>フアン氏は対談の中で、「AIは5層のケーキのようなものだ」と述べ、次のような層構造を示した。</p>
<ul>
<li><strong>第1層 エネルギー：</strong> AIを動かす前提となる電力供給の層。大規模なAI計算には膨大な電力が必要であり、電力インフラそのものがAI時代の基盤になるとした。</li>
<li><strong>第2層 チップとコンピューティング・インフラ：</strong> GPUなどの半導体や計算基盤の層。AIの性能やスケールを左右する中核で、計算能力の拡張が上位層を支える。</li>
<li><strong>第3層 クラウドおよびデータセンター：</strong> 計算資源を実際に運用・提供するためのシステム全体の層。フアン氏は、ここまで含めて初めてAIの「工場」が成立すると説明した。</li>
<li><strong>第4層 AIモデル：</strong> 大規模言語モデル（LLM）などの基盤モデルが該当する層。下位層の計算資源と密接に結びつきながら進化するとした。</li>
<li><strong>第5層 アプリケーション：</strong> 企業や個人が実際に利用するサービスや業務システムの層。医療、製造、金融など、産業ごとの具体的な活用はこの層で実現される。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e.jpg" alt="Gemini_Generated_Image_mf83p4mf83p4mf83.jpg" /></p>
<h2>「どれか一つ欠けても成立しない」</h2>
<p>フアン氏は、これら5つの層は独立して存在するものではなく、どれか一つが欠けてもAIは社会的・産業的な価値を生み出せないと強調した。特に、モデルやアプリケーションへの注目が集まりがちな一方で、エネルギーや計算インフラといった下位層への投資が不可欠であるとの認識を示した。</p>
<p>WEFも<a href="https://www.weforum.org/stories/2026/01/nvidia-ceo-jensen-huang-on-the-future-of-ai/">公式ストーリー記事</a>で、フアン氏の発言を「AIが次の大規模インフラ構築になる」という文脈で紹介しており、AIを電力網や通信網と同様の基盤産業として捉える視点が、ダボス会議という国際経済・政策の場で共有された形となった。</p>
<p>@<a href="https://www.youtube.com/watch?v=hoDYYCyxMuE&amp;t=160s">YouTube</a></p>
]]></description>
      <pubDate>Mon, 26 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本発ヒューマノイド「cinnamon 1」初公開　ドーナッツロボティクス、無言で操作できる特許技術も発表</title>
      <link>https://ledge.ai/articles/donut_robotics_cinnamon1_humanoid_silent_gesture</link>
      <description><![CDATA[<p>ヒューマノイド開発に取り組むスタートアップ、ドーナッツロボティクスは2026年1月21日、日本ブランドのヒューマノイド『cinnamon 1（シナモン ワン）』を<a href="https://prtimes.jp/main/html/rd/p/000000041.000057944.html">発表</a>した。二足歩行が可能な量産型ヒューマノイドとして、同社は2026年内の市場投入を目指す。</p>
<h2>二足歩行の量産ヒューマノイド、年内投入を目標に</h2>
<p>「cinnamon 1」は、同社が保有する特許技術を搭載した二足歩行のヒューマノイドロボットだ。現時点では海外企業から提供された機体をベースに、独自開発のAIを搭載している。将来的には、機体も含めた国産ヒューマノイドの実現を目指すとしている。</p>
<p>AIには、視覚情報・言語理解・行動を統合する「Vision-Language-Action（VLA）」の概念を取り入れる予定で、人の指示を理解し、自律的に行動するロボットの開発を進める。</p>
<h2>声を出さずに指示できる「サイレント ジェスチャー コントロール」</h2>
<p>同社はあわせて、手振りや指の動きだけでロボットに指示を伝える特許技術「サイレント ジェスチャー コントロール」を発表した。音声を使わずに操作できる点が特徴で、同社はこの技術を搭載したヒューマノイドとして「世界初」としている。</p>
<p>騒音の大きい工場や建設現場、声を出しにくい家庭環境などでの利用を想定しており、難聴者が多い環境でも使いやすい技術として位置づけている。</p>
<h2>工場・建設現場での作業代替を想定</h2>
<p>ドーナッツロボティクスは、2026年内に工場内や建設現場での作業代替を進める計画を示している。2025年10月には、建築関連事業を手がける株式会社エムビーエスと資本業務提携を発表しており、建設業界での活用を見据える。</p>
<p>また、VLA開発を支える国内データセンターの設立構想にも言及しており、ヒューマノイド開発を軸にしたAI基盤づくりを進める方針だ。</p>
<p>YouTube動画を引用する場合　　　
@<a href="https://www.youtube.com/watch?v=1vBI0GYjAKM">YouTube</a></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「中国AIは米国に“数カ月差”」DeepMindのデミス・ハサビスCEO―—追随能力を認める一方、焦点は“フロンティアを越える革新”</title>
      <link>https://ledge.ai/articles/china_ai_months_behind_us_deepmind_hassabis</link>
      <description><![CDATA[<p>GoogleDeepMindのCEOである Demis Hassabis 氏は現地時間の2026年1月15日、CNBCの新ポッドキャスト番組「The Tech Download」に出演し、中国のAI開発についての<a href="https://www.cnbc.com/2026/01/16/google-deepmind-china-ai-demis-hassabis.html">見解を示した</a>。同氏は、中国のAIモデルが米国および西側諸国の最先端モデルに対し、「数カ月程度の遅れ」まで迫っている可能性があると述べた。</p>
<h2>想定より近い位置にある中国AI</h2>
<p>ハサビス氏は、CNBCのインタビューで、中国のAI開発について「1〜2年前に考えられていたよりも、はるかに近い位置にいる」と語り、「現時点では数カ月差かもしれない」と評価した。これは、中国がAI分野で依然として大きく立ち遅れているとする見方とは異なる認識であり、世界のAI競争に対する見方の変化を示すものとなっている。</p>
<p>こうした評価の背景には、中国勢による近年の技術的進展がある。約1年前には、中国のAI研究機関DeepSeekが、比較的制約のある計算資源と低コストで高い性能を示すモデルを発表し、市場に大きな衝撃を与えた。その後も、中国の大手テクノロジー企業やスタートアップが相次いで高性能なAIモデルを公開しており、ハサビス氏は中国企業が既存技術を迅速に追随する能力を示している点を認めている。</p>
<h2>「追随」と「フロンティア突破」は別の課題</h2>
<p>一方で、ハサビス氏は中国のAI開発が最先端に近づいていることを認めつつも、「フロンティアを越える革新」については慎重な見方を示した。同氏は、中国の企業が「非常に近いところまでは到達している」とした上で、「新しいTransformerのように、フロンティアを押し広げる技術を生み出せるかどうかは、まだ示されていない」と述べた。</p>
<p>Transformerは2017年にGoogleの研究者らが発表した技術で、現在の大規模言語モデルの基盤となっている。同氏は、このような根本的な技術革新が生まれるかどうかが、今後のAI競争における重要な分水嶺になるとの考えを示した。</p>
<h2>制約ではなく「研究文化」を重視</h2>
<p>中国企業は、先端半導体へのアクセス制限など、構造的な課題を抱えている。こうした制約についても触れつつ、ハサビス氏は、フロンティア突破の難しさを単なる技術や資源の問題とは捉えていない姿勢を示した。</p>
<p>同氏は、DeepMindを「現代のベル研究所」に例え、既存技術を拡張するだけでなく、探索的で科学的な発明を生み出す研究文化の重要性を強調した。
ハサビス氏の発言は、中国のAIが急速に米国へ接近している現状を認めつつ、競争の焦点が単なる性能差から、次の技術的ブレークスルーを誰が生み出すかという段階へ移行しつつあることを示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=q6fq4_uP7aM">YouTube</a></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>マスク氏、ダボス会議でロボット量産に言及　人型ロボ「Optimus」一般販売は2027年末までに</title>
      <link>https://ledge.ai/articles/musk_davos2026_optimus_humanoid_robot_sales_2027</link>
      <description><![CDATA[<p>世界経済フォーラム（WEF）の年次総会「ダボス会議2026」で、テスラおよびSpaceXのCEOである イーロン・マスク氏が2026年1月22日、米資産運用大手ブラックロックのCEO ラリー・フィンク 氏との特別対談に<a href="https://www.youtube.com/watch?v=IgifEgm1-e0">登壇</a>した。マスク氏がダボス会議の公式セッションに登場するのは初めてとされる。</p>
<p>対談の中でマスク氏は、テスラが開発を進める人型ロボット「Optimus」について、2027年末までに一般向け販売を開始する見通しを示した。2026年中は工場など産業用途での展開が中心となり、段階的に高度な作業を担わせていくと説明した。</p>
<h2>「ロボットが人口を上回る可能性」に言及</h2>
<p>マスク氏は、人型ロボットの量産が進めば、将来的にロボットの数が人類の人口を上回る可能性があるとの見方を示した。時期については明確に限定しなかったものの、2030年前後を念頭に置いた発言として言及している。</p>
<p>ロボットの普及により、労働の在り方や経済構造が大きく変化する可能性があるとし、ロボットが生産やサービスの多くを担う社会像を描いた。</p>
<h2>AIの進化とインフラ制約</h2>
<p>AIの進化についても触れ、マスク氏は、単一の人間を上回る知能を持つAIは近い将来に登場するとの見通しを示した。さらに、2030年から2031年頃には、AIが人類全体の集合知を上回る可能性があるとも述べた。</p>
<p>一方で、AIの拡大を制約する要因として、計算資源そのものよりも電力供給がボトルネックになるとの認識を示した。AIチップの生産能力は急速に拡大しているものの、電力インフラの成長が追いつかない場合、AIの本格的な普及が制限される可能性があると指摘した。</p>
<h2>エネルギーと宇宙を含めた長期構想</h2>
<p>マスク氏は、AIとロボットを支える基盤として、太陽光発電を中心とした大規模な再生可能エネルギーの拡張が不可欠だと説明した。加えて、将来的には宇宙空間にデータセンターを配置することで、発電効率や冷却効率の面で優位性が生まれる可能性にも言及した。</p>
<p>今回の対談は、AIとロボットの進展が経済や社会に与える影響を議論する場となった。人型ロボットの一般販売時期に具体的な言及があったことで、テスラのロボット戦略と社会実装の時間軸がより明確になった形だ。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、Acrobatに生成AIを活用した3つの新機能「プレゼン生成」「ポッドキャスト生成」「自然言語PDF編集」──Acrobat Studioで提供開始（英語版）</title>
      <link>https://ledge.ai/articles/adobe_acrobat_studio_ai_presentation_podcast_pdf_edit</link>
      <description><![CDATA[<p>Adobeは2026年1月21日（米国時間）、PDFとコンテンツ制作を統合する「Adobe Acrobat Studio」において、生成AIを活用した3つの新機能の提供を<a href="https://blog.adobe.com/jp/publish/2026/01/26/dc-work-smarter-acrobat-turn-docs-presentations-podcasts-edit-pdfs-ai">開始</a>した。新たに追加されたのは、「プレゼンテーションを生成」「ポッドキャストを生成」「自然言語によるPDF編集」の各機能で、文書を起点にした情報活用とアウトプット作成を効率化する。これらの機能は、現時点では英語版で利用可能としている。</p>
<h2>文書からスライドを自動作成する「プレゼンテーション生成」</h2>
<p>新機能の「プレゼンテーションを生成」は、PDFや関連資料をもとに、AIが内容を整理し、プレゼンテーション用のアウトラインを自動作成するものだ。ユーザーは生成前にアウトラインを確認し、長さやトーンを調整したうえでスライド化できる。</p>
<p>入力データには、Acrobat内の「PDF スペース」に追加した文書ファイルやリンクを利用でき、財務報告書、製品仕様書、競合分析資料、Webページなど複数の情報源をまとめて扱える。生成されたスライドは、Adobe Expressと連携し、テンプレートやデザインライブラリを活用しながら、画像の差し替えや動画の追加、フォント変更などの編集が可能だ。これにより、デザインの専門知識がなくても、短時間で体裁の整ったプレゼン資料を作成できるとしている。</p>
<h2>長文資料を音声で要約する「ポッドキャスト生成」</h2>
<p>「ポッドキャストを生成」は、文書内容をAIが要約し、音声コンテンツとして出力する機能だ。PDF スペースに追加したメモ、文字起こし、数百ページ規模のレポートなどを対象に、AIアシスタントへ要約を依頼すると、ポッドキャスト形式の音声が生成される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c.jpg" alt="media_18964bee91bcdcb676c009037bc19e7eba3f8275d.jpg" /></p>
<p>会議資料の事前把握や移動中の情報収集、学習用コンテンツの音声化などを想定しており、読む時間が確保しづらい場面でも、文書の要点を把握できる手段として位置づけられている。</p>
<h2>チャットで操作できる「自然言語によるPDF編集」</h2>
<p>3つ目の新機能である「自然言語によるPDF編集」では、チャット形式のAIインターフェースを通じて、PDFの編集操作を行える。ユーザーは自然言語で指示を入力するだけで、ページやテキスト、コメント、画像の削除、電子署名の追加、パスワード設定などの基本的な編集作業を実行できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02.jpg" alt="media_106fc491d70ca3f2de8116afcbc18a917ceafb64b.jpg" /></p>
<p>あわせてヘルプ機能も強化されており、操作方法の案内やトラブルシューティングをチャット形式で受けられるようになった。従来のメニュー操作に不慣れなユーザーでも、直感的にPDF編集が可能になるとしている。</p>
<h2>「PDF スペース」を軸にした共同作業を強化</h2>
<p>これらの新機能は、Acrobat Studioに統合された共有ワークスペース「PDF スペース」を中心に提供される。PDF スペースでは、ファイルの整理やインサイト抽出に加え、招待したメンバーが資料を追加したり、メモやコメントを残したりできる。生成AI機能と組み合わせることで、個人作業だけでなく、チームでの資料準備やレビューの効率化を狙う。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>フィールズ賞のテレンス・タオ氏、「GPT-5.2 Proが数学の未解決問題をほぼ自律的に解き切った」と評価──エルデシュ問題#728で示されたAIの新たな到達点</title>
      <link>https://ledge.ai/articles/ai_autonomous_solution_erdos_problem_728</link>
      <description><![CDATA[<p>AIが数学の未解決問題を「ほぼ自律的に解き切った」と、数学者が評価した。著名な数学者であるテレンス・タオ氏が2026年1月8日、分散型SNS「Mathstodon」への投稿で、エルデシュ問題の一つである #728 が、AIツールによって「more or less autonomously（ほぼ自律的に）」解かれたと<a href="https://mathstodon.xyz/@tao/115855840223258103">述べた</a>。</p>
<p>この成果についてタオ氏は「私たちの知る限り、既存の文献では再現されていない」としたうえで、近年のAIツールの能力向上を示す「節目（milestone）」だと位置づけた。</p>
<h2>エルデシュ問題とは</h2>
<p>エルデシュ問題は、20世紀を代表する数学者ポール・エルデシュが提起した数多くの問題をもとに整理された、数学の未解決問題群を指す。現在も多くの問題が未解決のまま残されており、世界中の数学者が長年にわたって取り組んできた。</p>
<p>今回タオ氏が言及した エルデシュ問題#728 は、その中の一つで、問題の内容や背景はエルデシュ問題の<a href="https://www.erdosproblems.com/728">公式サイト</a>で公開されている。</p>
<p>未解決問題は、数学界において特別な位置づけを持つ。解決に至れば理論的に重要な意味を持つだけでなく、長年の研究の蓄積を塗り替える可能性があるためだ。</p>
<p><strong>■ ポール・エルデシュ（左）と、当時10歳のテレンス・タオ。1985年撮影。</strong> エルデシュ問題は、エルデシュ自身が提起した未解決問題群に由来する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Paul_Erdos_with_Terence_Tao_952867730e/Paul_Erdos_with_Terence_Tao_952867730e.jpg" alt="Paul_Erdos_with_Terence_Tao.jpg" /></p>
<h2>GPT-5.2 Proと人間の役割分担</h2>
<p>証明には、OpenAIの大規模言語モデル GPT-5.2 Pro が用いられた。人間側は、計算環境の整備や初期試行へのフィードバック、結果の検証、形式的な証明への整理といった役割を担ったとされる。</p>
<p>AIが完全に単独で問題を解決したわけではないものの、思考の主導権がどこにあったのかが、今回の評価における重要なポイントとなった。</p>
<p><strong>■ 「ほぼ自律的に」解いた、という表現</strong>
従来、AIは数学分野において計算の高速化や文献探索、発想の補助といった役割を担ってきた。一方で今回のケースでは、問題の解釈から解法の構築、証明に至るまでの過程をAIが主導したと評価された。</p>
<p>タオ氏によれば、AIは初期の試行に対する一定のフィードバックを受けた後、問題の趣旨に沿った形で解決に到達したという。この点が、「ほぼ自律的」という表現につながった。</p>
<h2>「解決以上に興味深い点」</h2>
<p>タオ氏は今回の投稿で、解決結果そのものに加え、「それ以上に興味深い点がある」とも述べている。投稿では、</p>
<p>「より興味深いのは、解法の説明（exposition）を迅速に書き、書き直し、再構成するAI主導の能力が現れつつある点だ」
と指摘し、証明文書の作成や改稿をめぐるAIの能力向上に言及した。</p>
<p><strong>■ テレンス・タオ氏がMathstodonに投稿したエルデシュ問題#728に関する発言。AIが「ほぼ自律的に」問題を解いたと評価している。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/terencetao_mathstodon_b05b8af4d5/terencetao_mathstodon_b05b8af4d5.jpg" alt="terencetao mathstodon.jpg" /></p>
<p>従来、数学論文の執筆や大幅な改稿には多大な時間と労力が必要だったが、AIによる文章生成と形式証明ツールを組み合わせることで、説明文を用途や読者に応じて柔軟に作り直すことが可能になりつつあるという。</p>
<h2>他のAI解決事例との位置づけ</h2>
<p><strong>■ エルデシュ問題を巡るAI活用事例を整理した公式Wikiの一部。#728は、AIによる解決後に類似文献が確認されたケースとして位置づけられている。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/github_erdos_problem_058007f757/github_erdos_problem_058007f757.jpg" alt="github erdos problem.jpg" /></p>
<p>タオ氏自身も、AIによるエルデシュ問題の解決例の多くでは、後に類似の結果が既存文献で確認されてきたと説明している。#728についても、問題文の再構成が比較的最近まで行われていなかったことが、先行研究が見当たらなかった理由の一つだとされている。</p>
<h2>数学とAIの関係に生じた変化</h2>
<p>今回の発言は、AIが数学者の役割を代替したことを示すものではない。一方で、未解決問題を対象とした成果について、数学者がAIの関与を明示的に評価し、その能力の到達点を具体的に言及した点は確認できる事実である。エルデシュ問題#728をめぐる今回の事例は、AIの活用がどの段階まで進んでいるのかを示す一例として位置づけられ、今後、同様の評価が他の問題や分野でも示されるかどうかが注目される。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが高次元幾何学の難問に挑む──中国研究チーム、接吻数問題で複数次元の記録更新</title>
      <link>https://ledge.ai/articles/ai_kissing_number_problem_game_theoretic_rl</link>
      <description><![CDATA[<p>中国の北京大学や上海科学智能研究院などの研究グループが2026年1月26日、AIを用いて、高次元幾何学の難問として知られる「接吻数問題」に取り組み、複数の次元で既存の下界を更新する成果を報告した。研究成果は論文「<a href="https://arxiv.org/abs/2511.13391">Finding Kissing Numbers with Game-theoretic Reinforcement Learning</a>」として発表された。</p>
<p>接吻数問題は、同じ大きさの球が1つの球の周囲に互いに重ならないよう最大でいくつ接触できるかを問う問題で、1694年にアイザック・ニュートンらが議論して以来、長年にわたり研究が続けられてきた。次元が高くなるにつれて幾何構造が複雑化し、解析や探索が極めて困難になることが知られている。</p>
<h2>球の配置を「行列」として扱うAI手法</h2>
<p>研究チームは、接吻数問題をGram行列（内積行列）の補完問題として定式化し、ゲーム理論と強化学習を組み合わせたAIシステム「PackingStar」を開発した。従来のように高次元空間上の座標を直接最適化するのではなく、球同士の内積関係のみを行列として扱うことで、数値的不安定性を抑えつつ大規模な並列探索を可能にしたとしている。</p>
<p>PackingStarでは、2つのAIエージェントが協調的に動作する。一方のエージェントが行列を拡張して配置候補を追加し、もう一方が全体構造を考慮して不適切な要素を削除・修正する。この「追加」と「修正」を繰り返すことで、より大きな配置、すなわちより高い接吻数に対応する構造を探索する仕組みだ。</p>
<p><strong>【図：PackingStarの3段階（シミュレーション→行列初期化→2プレイヤー行列補完ゲーム）を示した模式図】</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x2_1_12e03bdc99/x2_1_12e03bdc99.png" alt="x2 (1).png" /></p>
<h2>25〜31次元で既存の下界を更新</h2>
<p>論文によると、PackingStarは25次元から31次元までのすべての次元で、これまでに知られていた最良の下界を上回る接吻配置を発見した。特に25次元では、得られた配置が高次元格子として知られるLeech格子の部分構造と対応する明確な幾何パターンを示しており、最適構造である可能性を示唆しているという。ただし、厳密な数学的証明は現時点では示されていない。</p>
<p>研究チームは、2011年や2016年に提案されていた構成テンプレートを超える配置が得られたとし、高次元における探索能力の拡張を成果として位置づけている。</p>
<p><strong>【図：次元ごとの接吻数と、本研究による更新点を示したグラフ】</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_76eb8d2f20/x1_76eb8d2f20.png" alt="x1.png" /></p>
<h2>13次元で「合理構造」を刷新</h2>
<p>また13次元では、1971年以来更新されていなかった「合理構造」と呼ばれる構成を刷新し、接吻数1146の配置を発見した。合理構造とは、球同士の内積がすべて有理数で表される配置を指す。現在知られている13次元での最高記録は非合理構造による1154だが、合理構造は厳密な解析が可能である点から、理論的価値が高いとされる。</p>
<p>論文では、今回の成果が高次元幾何学や球面符号、情報理論分野での研究に資する可能性にも言及している。</p>
<h2>一般化接吻数でも新記録</h2>
<p>さらに、球同士の角度制約を変更した「一般化接吻数」においても成果を報告した。12次元（内積制約1/4）、14次元および17次元（内積制約1/3）で既存記録を更新し、数千件規模の新たな配置を発見したとしている。</p>
<h2>AIによる数学探索の新たな事例に</h2>
<p>研究チームは、PackingStarが既存の構造を単に最適化するのではなく、新しい幾何構造を体系的に発見できる点を特徴として挙げている。一方で、得られた配置が真に最適であることを示す証明は今後の課題とした。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>技術の思春期に入ったAI──Anthropic CEOダリオ・アモデイ氏、国家安全保障・経済・民主主義へのリスクに警鐘</title>
      <link>https://ledge.ai/articles/ai_technology_adolescence_amodei_democracy_risk</link>
      <description><![CDATA[<p>AI開発企業AnthropicのCEOである ダリオ・アモデイ 氏は2026年1月27日、強力なAIが社会にもたらすリスクについて論じた長文エッセイ「The Adolescence of Technology（技術の思春期）」を<a href="https://www.darioamodei.com/essay/the-adolescence-of-technology">公開</a>した。同氏は、AIが急速に能力を高める一方で、制度や社会の成熟が追いついていない「危険な過渡期」にあると指摘し、国家安全保障、経済、民主主義の3領域で深刻な影響が生じうると警告している。</p>
<h2>「技術の思春期」とは──能力が先行する危うい段階</h2>
<p>アモデイ氏は現在のAIを、人間の成長過程になぞらえて「技術の思春期（Adolescence）」にあると表現する。この段階では、技術的な能力が急速に拡大する一方で、それを安全かつ安定的に運用するためのガバナンスや社会制度が十分に整っていない。</p>
<p>強い影響力を持ち始めながらも、判断力や自制が成熟していない――同氏は、こうした「能力の増大」と「未成熟さ」が同居する状態こそが、現在のAIを最も不安定で危険な存在にしていると論じている。</p>
<h2>国家安全保障：AIが不安定化させる軍事・サイバー空間</h2>
<p>国家安全保障の領域では、AIの高度化が軍事、諜報、サイバー分野に新たな不安定要因をもたらす可能性があると指摘した。
サイバー攻撃や情報操作の高度化により、従来の抑止や防御の枠組みが機能しにくくなる恐れがあるという。</p>
<p>また、国家間の技術競争が激化する中で、安全対策や慎重な検証が後回しにされる構造的リスクにも言及しており、AIは一度広く普及すると制御が難しくなる点を強調している。</p>
<h2>経済：生産性向上の裏で進む急激な再編</h2>
<p>経済面では、AIが生産性を大きく押し上げる可能性を認めつつ、その恩恵が均等に分配されないリスクを挙げた。雇用構造の急変や、特定の企業や国家への権力集中が進めば、社会的な不安定化につながりかねないとしている。</p>
<p>技術進歩のスピードに制度的・社会的な調整が追いつかない場合、短期間で大きな歪みが生じる可能性があるとし、経済的影響を過小評価すべきではないとの認識を示した。</p>
<h2>民主主義：情報環境の脆弱化と「共通の現実」の喪失</h2>
<p>民主主義への影響について、アモデイ氏は特に強い懸念を示している。AIによる情報生成・拡散能力の向上は、世論操作や偽情報の高度化を招き、民主主義が前提としてきた「共通の現実」や情報の信頼性を損なう恐れがあるという。</p>
<p>同氏は、こうした情報環境の変化が、有権者の判断基盤そのものを弱体化させる可能性がある点を、深刻なリスクとして位置づけている。</p>
<h2>米ミネソタ州での出来事が浮き彫りにした「国内の民主主義」</h2>
<p>アモデイ氏は、このエッセイが主にAIと将来を論じたものであるとしつつも、公開時点で米ミネソタ州をめぐって起きている出来事に触れ、民主主義的価値と権利を国内で守る重要性が一層切実になっていると述べている。</p>
<p>同州では連邦当局の強制執行をめぐる死亡事件などをきっかけに、権利や法の在り方を巡る議論と抗議が広がっており、アモデイ氏はこうした現実の緊張が、エッセイで論じた「民主主義の脆弱性」を現実の問題として浮き彫りにしていると示唆した。</p>
<p>なお、ミネソタ州での出来事をめぐっては、Reutersが、OpenAIの サム・アルトマン CEOが従業員向けの内部メッセージで、移民当局ICEの対応を「行き過ぎ」と批判したと報じている。</p>
<h2>前作「Machines of Loving Grace」との関係</h2>
<p>アモデイ氏は今回のエッセイを、約1年前に発表した「<a href="https://www.darioamodei.com/essay/machines-of-loving-grace">Machines of Loving Grace</a>」（強力なAIを正しく活用できた場合に何が実現できるかを論じたエッセイ）の“対”に位置づけている。</p>
<p>前作では、AIがもたらしうる可能性や理想像に焦点が当てられていたのに対し、今回のエッセイでは、その裏側にあるリスクや、社会が備えるべき課題が正面から論じられている。</p>
<h2>「止める」か「進める」かではなく、どう向き合うか</h2>
<p>アモデイ氏は、AI開発を止めるべきだと主張しているわけではない。一方で、無条件に加速させる姿勢にも警鐘を鳴らしている。必要なのは、ガバナンス、制度設計、国際的な協調を含め、社会全体でAIと向き合う枠組みを整えることだとし、「技術の思春期」にある今の判断が、将来の安定性を大きく左右すると結論づけている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AmazonがOpenAI出資を検討、最大500億ドル（約7.6兆円）規模と報道　今ラウンドでの資金調達は1000億ドル超も</title>
      <link>https://ledge.ai/articles/amazon_openai_investment_50b_funding_100b_reported</link>
      <description><![CDATA[<p>AmazonがOpenAIに対し、最大500億ドル（約7兆6000億円）規模の出資を検討していると、<a href="https://www.reuters.com/business/retail-consumer/amazon-talks-invest-up-50-billion-openai-wsj-reports-2026-01-29/">Reuters</a>や<a href="https://www.cnbc.com/2026/01/29/amazon-openai-investment-jassy-altman.html">CNBC</a>など複数の米メディアが2026年1月29日に報じた。協議は進行中で、最終的な出資額や条件は流動的だとしている。</p>
<h2>最大500億ドル規模、交渉はなお初期段階</h2>
<p>関係者の話として伝えられているところによると、AmazonはOpenAIに数百億ドル規模の投資を協議しており、その金額は最大500億ドルに達する可能性がある。ただし、協議はまだ初期段階にあり、最終的な条件や金額は確定していないとされる。Amazonはコメントを控え、OpenAIも現時点で公式な見解を示していない。</p>
<h2>条件書は数週間以内に署名の可能性も</h2>
<p>報道では、関係者によると条件書（term sheet）が数週間以内に署名される可能性があるとも伝えられている。今回の資金調達は、Amazonのほか、MicrosoftやNVIDIAといった戦略投資家を先行させ、その後に他の投資家が参加する2段階構成となる可能性があるという。</p>
<h2>OpenAI、最大1000億ドル調達・評価額8300億ドルの可能性</h2>
<p>OpenAIは今回のラウンドで、最大1000億ドルの資金調達を目指しているとされ、評価額は約8300億ドルに達する可能性がある。報道では、SoftBankや中東の政府系ファンドなども投資家候補として名前が挙がっている。</p>
<p>交渉には、AmazonのCEOであるAndy Jassy氏と、OpenAIのCEOのSam Altman氏が直接関与しているとされる。米紙<a href="https://www.wsj.com/tech/ai/amazon-in-talks-to-invest-up-to-50-billion-in-openai-43191ba0">The Wall Street Journal</a>は、この協議について先行して報じていた。</p>
<p>Amazonは、OpenAIの競合であるAnthropicにもこれまでに巨額投資を行ってきた。今回の動きについては、大手テック企業が複数のAI企業に同時に投資する構図が鮮明になりつつあるとの見方も出ている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、Claudeで外部業務ツール連携を拡充　SlackやAsana、Figmaなどを会話内で操作可能に</title>
      <link>https://ledge.ai/articles/anthropic_claude_interactive_tools_slack_asana_figma</link>
      <description><![CDATA[<p>米AI企業の Anthropic は2026年1月26日、同社のAIサービス Claude において、外部業務ツールを会話内でインタラクティブに利用できる機能を拡充したと<a href="https://claude.com/blog/interactive-tools-in-claude">発表</a>した。今回のアップデートにより、Slack、Asana、Figma、Canva、Box などのツールを、Claudeのチャット画面内で直接操作できるようになる。</p>
<h2>会話の流れでツールを操作、画面切り替え不要に</h2>
<p>対応したツールでは、単なる情報参照にとどまらず、各サービスの操作をClaudeの会話の流れの中で行える。</p>
<p>例えばSlackではメッセージの下書きや送信、Asanaではタスクやプロジェクトの更新、FigmaやCanvaではデザインや資料の作成・確認といった作業を、別タブに移動することなく進められるという。</p>
<p>これにより、複数の業務ツールを行き来しながら作業する従来のワークフローを簡略化し、AIとの対話を起点に業務を進める形を想定している。</p>
<p>@<a href="https://www.youtube.com/watch?v=bluAmTHoEow">YouTube</a></p>
<h2>Model Context Protocol（MCP Apps）を活用</h2>
<p>こうしたインタラクティブな連携は、Anthropicが推進するオープン標準プロトコル「Model Context Protocol（MCP）」の拡張仕様である「MCP Apps」によって実現されている。
MCP Appsは、外部ツール側が提供するインターフェースをAIクライアント上で扱えるようにする仕組みで、Claudeはこの仕様に対応することで、外部サービスの操作画面を会話の文脈に沿って表示・利用できるようになった。</p>
<p>Anthropicは、MCPを通じてClaudeと業務ツールの接続性を高め、開発者や企業が独自のツールを統合できる環境整備も進めている。</p>
<h2>対象プランと今後の展開</h2>
<p>今回のインタラクティブツール連携は、Claudeの有料プラン（Pro、Team、Enterpriseなど）を中心に提供される。対応ツールは今後も拡大予定としており、Claudeを業務のハブとして活用するユースケースを広げていく方針だ。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国AIテック、オープンソース推論モデルを相次ぎ公開──Alibabaが「Qwen3-Max-Thinking」、Moonshot AIは「Kimi K2.5」発表</title>
      <link>https://ledge.ai/articles/china_ai_open_source_reasoning_models_qwen3_max_thinking_kimi_k2_5</link>
      <description><![CDATA[<p>中国のAIテック企業が、推論能力を前面に打ち出したオープンソース大規模言語モデル（LLM）を相次いで公開している。</p>
<p>Alibabaは2026年1月26日、同社の「Qwen」シリーズにフラッグシップ推論モデル「<a href="https://qwen.ai/blog?id=qwen3-max-thinking">Qwen3-Max-Thinking</a>」を追加した。続く27日には、中国のAIスタートアップであるMoonshot AIが、生成AIサービス「Kimi」の新モデルとして「<a href="https://www.kimi.com/blog/kimi-k2-5.html">Kimi K2.5</a>」を発表した。</p>
<h2>Alibaba、推論特化のオープンソースLLM「Qwen3-Max-Thinking」を公開</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Qwen3_Max_Thinking_a4f4c3f239/Qwen3_Max_Thinking_a4f4c3f239.jpg" alt="Qwen3-Max-Thinking.jpg" /></p>
<p>Alibaba傘下のQwen開発チームは2026年1月26日、同社が開発する大規模言語モデル「Qwen」シリーズの新モデルとして、「Qwen3-Max-Thinking」を<a href="https://qwen.ai/blog?id=qwen3-max-thinking">発表</a>した。公開した。</p>
<p>同モデルは、モデル規模の拡大と大規模な強化学習を組み合わせることで、知識量、複雑な推論能力、指示追従性、人間の嗜好との整合性、エージェント機能など複数の側面で性能を高めたとしている。</p>
<p>Qwenチームによると、19の既存ベンチマークにおいて、GPT-5.2-ThinkingやClaude Opus 4.5、Gemini 3 Proと同等水準の性能を示したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/score_c57592148d/score_c57592148d.jpg" alt="score.jpg" />
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/qwen3_max_bench_a596df956e/qwen3_max_bench_a596df956e.jpg" alt="qwen3 max bench.jpg" /></p>
<p>また、必要に応じて検索やコード実行を自律的に呼び出す適応的なツール利用機能を備え、Qwen Chat上で利用可能としている。推論時に追加計算を割り当てるテスト時スケーリング手法も導入し、複数の推論系ベンチマークで性能向上を確認したとしている。</p>
<p>Qwen3-Max-Thinkingは、Qwen ChatおよびAPIを通じて提供されており、オープンソースモデルとして公開されている。</p>
<h2>Moonshot AI、オープンソース推論モデル「Kimi K2.5」発表</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Kimiai_704db61aa9/Kimiai_704db61aa9.jpg" alt="Kimiai.jpg" /></p>
<p>Moonshot AIは2026年1月27日、同社が提供する生成AIサービス「Kimi」の新たな基盤モデルとして、「Kimi K2.5」を<a href="https://www.kimi.com/blog/kimi-k2-5.html">発表</a>した。</p>
<p>同社はKimi K2.5を、視覚理解と推論、エージェント機能を統合した「オープンソースのVisual Agentic Intelligence」と位置づけている。</p>
<p>同社の公式Xアカウントによると、Kimi K2.5はエージェント関連ベンチマークにおいて、HLE（full set）で50.2%、BrowseCompで74.9%のスコアを記録したという。また、視覚理解やコード生成に関する評価では、MMMU Proで78.5%、VideoMMMUで86.6%、SWE-bench Verifiedで76.8%を示し、オープンソースモデルとして最高水準の性能だとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f.jpg" alt="G_pUaPlaoAAa9as.jpg" /></p>
<p>Kimi K2.5の特徴として、最大100のサブエージェントを自律的に生成・統括する「Agent Swarm」機能を挙げている。複数のエージェントが並列に最大1,500回のツール呼び出しを行うことで、単一エージェント構成と比べて処理速度が最大4.5倍向上するとしている。Agent Swarmは現在ベータ版として提供されている。</p>
<p>Kimi K2.5は、KimiのWeb版およびアプリで利用可能で、チャットモードとエージェントモードをサポートする。APIも提供されており、同社は本番環境でのソフトウェア開発用途として、開発者向けツール「Kimi Code」との併用を推奨している。モデルの重みとコードはHugging Face上で公開されている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スマートファクトリーの未来を描く――デロイト トーマツ×NVIDIA×デル・テクノロジーズが語った最新潮流</title>
      <link>https://ledge.ai/articles/deloitte_tohmatsu_innovation_park</link>
      <description><![CDATA[<p>12月3日、丸の内「Deloitte Tohmatsu Innovation Park」にてスマートファクトリー共同セミナーが開催された。当日は主催の合同会社 デロイト トーマツのほか、エヌビディア合同会社（NVIDIA）やデル・テクノロジーズ株式会社、シュナイダーエレクトリックホールディングス株式会社、アルテアエンジニアリング株式会社、パロアルトネットワークス株式会社といった、スマートファクトリー関連企業から担当者が登壇。製造業が抱える課題と、スマートファクトリー化に向けたさまざまな提言を行った。
本記事ではその中から、デロイト トーマツの芳賀氏、NVIDIAの高橋氏、デル・テクノロジーズの比留間氏、水口氏による講演をレポートする。</p>
<h2>デロイト トーマツが語るSDMと製造業の変革ポイント</h2>
<p>芳賀氏はまず、製造業が直面する2025年に向けた課題として、「地政学リスクへの対応で複雑さを増すグローバルビジネス」「労働力人口が減少する中、製造業を支える新たな人員体制の必要性」「AIテクノロジーの進化スピードへの適応が競争力を左右すること」を挙げた。</p>
<p>特にAIの進化は製造業に大きなインパクトをもたらしており、現場データをいかに価値創造やイノベーションに活用していくかが重要だと指摘する。また、中国をはじめとする新興国の製造業におけるデジタル活用の動きにも危機感を示し、日本の製造業もスピード感を持ってキャッチアップしていかなければならないと強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_e1aeeee499/1_e1aeeee499.jpg" alt="1.jpg" /></p>
<p>製造業へのデジタル活用といえば、本イベントのテーマでもある「スマートファクトリー」が注目されている。しかし、芳賀氏によると「目的別のITと設備・組織別のOTは相容れない考え方」とのことで、両者の統合にはまだ課題が多いという。</p>
<p>そのような製造領域のデジタル化における複雑性を解消する鍵となるのが「ソフトウェア・デファインド・マニュファクチャリング（SDM）」だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_4b4a0a1b81/2_4b4a0a1b81.png" alt="2.png" /></p>
<p>「SDMは仮想化テクノロジーをベースにした柔軟かつオープンなテクノロジーで、自由度の高い管理を実現しています。たとえばSDVがそうです。物理的に実現した機能を電子的に変更するだけでなく、ソフトウェア上でのシミュレーションを通じて機能や性能を高め、それを物理世界に落とし込むサイクルが重要です」（芳賀氏）</p>
<p>こうしたデジタル空間における物理世界の再現は、これまでにも議論されてきた話題ではある。しかし、それらの取り組みは“再現”で終わることが多く、その先にあるイノベーションに結びつくことが少なかった。</p>
<p>その理由の一つとして芳賀氏が挙げるのは、工場内にある設備機器や人の仕事がまだ本当にモデル化されているとは言えないことだ。タクトタイムやチョコ停、品質など、さまざまな要素をモデル化し、あらゆる設定や配置の中でシミュレーションする。そこから新たな課題を発見し、改善する。こうしたプロセスが重要になると芳賀氏は語った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_f35b4a1e1d/3_f35b4a1e1d.jpg" alt="3.jpg" /></p>
<p>続いてSDMを支える技術的なアーキテクチャについても解説があった。芳賀氏によると、SDMは従来のデータベースとデータの標準化による連携ではなく、AIの機能を活用した連携がポイントになるという。</p>
<p>「特にフィジカルAIでは、上位システムからの指示を現場の制御系機器やデバイス制御に落とし込んだ上で、実際の制御データと実績のフィードバックを組み合わせ、物理法則も理解しながらモデルをチューニングしていくことが重要です」（芳賀氏）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4_891ddf14bf/4_891ddf14bf.png" alt="4.png" /></p>
<p>このように、ドメインごとの業務マネジメントの仕組みをAIエージェントが管理し、人の要求に対してシステムが自動的に調整を行う動きが今後は一般的になっていくだろう。</p>
<p>芳賀氏はさらに、現場で発生するさまざまな出来事に対して必要なデータを紐づけ、「現場の事実情報」として構造化する考え方を提示した。</p>
<p>たとえば品質エラーが発生した際、単なるエラーコードだけでなく、設備、製品、部品、環境条件、オペレーター情報などを含めた5W1Hを確認することで初めて原因特定が可能になるわけだ。</p>
<p>現在はデータレイクから情報を取り出して加工しなくても、ストリーミングで上がってくるデータを加工してアノテーションできる時代になっている。こうした取り組みを通して、データを意思決定に活用できるようにしていくことがポイントなのだ。</p>
<p>また、芳賀氏はAIがデータの範囲内で答えを出す一方で、人間がAIの問いに対して現場を見ながら最適な判断をして新しい仮説を創造する役割分担が重要だと強調。日本の製造業における競争力の源泉である「変更点管理」「なぜなぜ分析」「横展開」といった改善活動について、AIを活用して支援する「活動・意思決定モデル」の構築を提案した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/5_0613a158d8/5_0613a158d8.png" alt="5.png" /></p>
<p>芳賀氏は最後に「新興国が投資だけでなく、製品の進化や品質向上のスピードでも勝負をかけてきている」と指摘。日本の製造業全体の競争力を維持するために、SDMの導入が必要だとあらためて訴えた。</p>
<p>SDMはツールでも目的でもなく、大きな変革の流れそのものであり、事業課題を解決する切り口として欠かせない考え方だ。人の役割や価値が変わっていく中で、現場を支えるワーカー、そしてグローバルなデジタル人材の重要性はさらに増していくだろう。</p>
<h2>フィジカルAIとデジタルツインがもたらす新しい工場の形</h2>
<p>続いて登壇したのは、NVIDIAのデジタルツイン開発プラットフォーム「Omniverse」のビジネス開発を担当する高橋氏だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_7f6f83f2c8/7_7f6f83f2c8.jpg" alt="7.jpg" /></p>
<p>高橋氏はまず、フィジカルAIの定義について「物理空間を認識・理解し、正しいアクションを導き出すAI」と説明、「入力された映像やテキストに対して、ロボットの動作や自動運転車両の制御、工場設備の全体最適化などを行うAIモデル」と位置づけた。</p>
<p>このフィジカルAIを作るための3つのコンピューティングリソースが、「AIの学習環境」「ロボットや自動運転車両などのAGX」「シミュレーション/デジタルツイン」である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/8_96bfab254f/8_96bfab254f.png" alt="8.png" /></p>
<p>このうち本講演で高橋氏が深堀りするのが「シミュレーション/デジタルツイン」だ。仮想空間でデータを取得するデジタルツインは、発生頻度が低い事象や危険を伴う状況、効率的にデータを取得できないケースなどにおいて有効な手法となる。</p>
<p>NVIDIAが提供するデジタルツイン開発プラットフォーム「Omniverse」は、物理ベースのビジュアライゼーション、リアルタイムコラボレーション、生成AIの統合、ロボットトレーニングといった機能を持ち、自動車会社や製造業、工場、物流倉庫などで活用され始めているという。</p>
<p>さらに高橋氏が紹介するのがNVIDIAの世界基盤モデル開発プラットフォーム「Cosmos」。これは物理的に正しい動画データを生成する基盤モデルであり、プロンプトからのデータ作成や、最初のフレームから次の動きを予測する機能などを搭載している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9_c9fd4faaa1/9_c9fd4faaa1.png" alt="9.png" /></p>
<p>これらのサービスを活用して企業はさまざまなアプリケーションを開発するわけだが、とはいえゼロから取り組むのは簡単ではない。そこでNVIDIAでは「Isaac GR00T」「Metropolis VSS」という二つのBlueprintを用意している。</p>
<p>「GR00Tはヒューマノイドロボットの学習データを作成するBlueprintであり、Cosmosと組み合わせることで3Dデータの質感や環境情報をもとにバリエーション豊かな合成モーションを作成できます」（高橋氏）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/10_340f853192/10_340f853192.jpg" alt="10.jpg" /></p>
<p>ただし、ヒューマノイドロボットを動かしてデータを作成するのは、オペレーターのリソースの都合もあり簡単ではない。そこでGR00Tではデータを水増しして、効率的に学習データを作るというアプローチをとっているという。</p>
<p>「GR00Tを使えば、数十パターンの人間の動きを数百まで簡単に増やすことができます。従来ならオペレーターが8時間もかけて行っていたデータ収集を効率化し、AIの学習を進めることができます」（高橋氏）</p>
<p>さらにVSS（Video Search and Summarization）というAIエージェントを活用することで、工場や物流倉庫のカメラ映像データなどから多くの洞察を得られるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/11_7782a14095/11_7782a14095.png" alt="11.png" /></p>
<p>たとえばバスケットボールの試合の映像を分析して、シュートの確率が高い選手を見つけたり、高所作業でハーネスを着用しているかチェックしたりといった活用が可能になるのだ。</p>
<p>講演ではこれらのBrueprintを活用した事例も紹介された。具体的にはNVIDIAの新工場における機器レイアウトの最適化やロボットシミュレーション、自動搬送ロボットの経路最適化などに活用されているという。</p>
<p>また、IoTセンサー情報をデジタルツインに紐づけることで、機器の稼働状況や問題発生時のエラー情報をリアルタイムに確認でき、担当者が現場に向かう前に状況を把握できるメリットがあるとのことだ。たとえば医薬品業界では処方に合わせた薬剤調合ロボットのシミュレーションや、実験室で創薬を行う際のレイアウト検討に活用されている。</p>
<h2>NativeEdgeが支えるスマートファクトリーのインフラ基盤</h2>
<p>最後に紹介するのはデル・テクノロジーズで「NativeEdge」のビジネス開発を担当する比留間氏の講演だ。</p>
<p>比留間氏はまず、「エッジデバイスの増加に伴って、現場（エッジ）でのデータ収集とリアルタイム利活用の重要性が増している」点を強調する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/13_ca517aae7b/13_ca517aae7b.jpg" alt="13.jpg" /></p>
<p>これまではオンプレミスからクラウドへのデータの流れが主流だったが、今後はエッジや小規模な分散データセンターにデータが集約されていくことが予測されるのだ。</p>
<p>ただし、エッジや分散データセンターには独自の課題がある。</p>
<p>「たとえば工場内に分散配置されるデバイスの運用管理、IT専任者がいない場所でのサポート、セキュリティの確保、ソフトウェアの継続的な運用管理などです」（比留間氏）</p>
<p>これらの課題に対応するのが、「エッジ」と「分散データセンター」にフォーカスしたデル・テクノロジーズのソフトウェアプラットフォームが「NativeEdge」である。</p>
<p>NativeEdgeの主な機能はふたつ。まず、管理マネージャーからハードウェアデバイスを遠隔で管理できるオーケストレーター機能、そしてハードウェア上のアプリケーションを一括配信できる機能である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/14_ce3fa0a66e/14_ce3fa0a66e.png" alt="14.png" /></p>
<p>さらに、NativeEdgeはブループリント機能も備えている。通常、アプリケーションを導入する際はOSを導入し、ネットワークストレージを設定し、アプリケーションをインストールするといった手順が必要だ。</p>
<p>この導入手順を一つのファイルで作成したものがブループリントであり、一括でデプロイメントできる仕組みになっているのだ。</p>
<p>そして、NativeEdge最大の特徴ともいえるのが「ゼロタッチプロビジョニング」機能である。</p>
<p>「これにより、サーバーやエッジデバイスを現地に直送し、お客様が電源ケーブルとLANケーブルを接続して電源を入れるだけで、あとはすべてオーケストレーターから一括で設定できるようになります」（比留間氏）</p>
<p>NativeEdgeの登場により、従来のようにIT専任者が各拠点を訪問してOSやアプリケーションを導入するのではなく、よりスマートに遠隔で一括配信する導入プロセスが定着していきそうだ。</p>
<p>比留間氏はNativeEdgeの仕組みについて、「各エッジデバイスにNativeEdge OSというカスタマイズされたSOSがインストールされており、Hypervisorとして使用できる」と説明。ユーザーはその上に仮想マシンやコンテナアプリケーションをデプロイできるわけだ。</p>
<p>さらにNativeEdgeはクラスタリング機能も備えており、1台のデバイスが故障してもサービスを継続できる冗長性も確保できるという。</p>
<p>比留間氏はNativeEdgeの全体像についても解説した。それによると、デバイス単体での使用だけでなくHCIとしても利用できるほか、各デバイスにストレージを接続して大容量ボリュームを確保することも可能とのことだ。また、基本的にデル製品に特化しているが、他社製品においても一部機能の制約はあるものの利用可能だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/15_e03a199dea/15_e03a199dea.png" alt="15.png" /></p>
<p>次にNativeEdgeのセキュリティについて、比留間氏は「ゼロトラストの考え方に基づいて構成されている」と説明する。</p>
<p>具体的にはデバイスのオンボーディング時には「バウチャー」と呼ばれる秘密鍵を使用して認証を行うほか、物理的なセキュリティとして、デバイスの外部端子は基本的にすべて無効化されているという。外部端子を使用する際は、オーケストレーターからの設定で、必要なポートのみを仮想マシンに許可するわけだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/16_579ec65445/16_579ec65445.png" alt="16.png" /></p>
<p>「NativeEdgeはさまざまなセキュリティ機関の厳しい審査をすべてパスしており、セキュアにお使いいただける環境をご提供しています」（比留間氏）</p>
<p>続いて比留間氏は、デル・テクノロジーズとNVIDIAによる「Dell AI Factory with NVIDIA」ソリューションについても紹介した。</p>
<p>これはデジタルアシスタントなどのユースケースに対して、サーバー、ネットワーク、ストレージといったインフラストラクチャーと、NVIDIAのソフトウェアプラットフォーム、デル・テクノロジーズの構築サービスを一つのパッケージとして提供するものだ。Tシャツのサイズ（S、M、Lなど）のように簡単に選べる形で提供されているため、AIを始めてみたい企業には最適なソリューションと言える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/17_493df32d54/17_493df32d54.png" alt="17.png" /></p>
<p>ここで登壇者が比留間氏から、インフラストラクチャー・ソリューション営業統括本部の水口氏にチェンジ。エッジ向けに開発されたサーバー「XR」シリーズについて説明を行った。</p>
<p>XRサーバーは専用フィルターを持っており、人の多い場所でも使用できるほか、マイナス5度から55度までの環境に耐えられる特性を持っている。当然、あらゆる工場で安定して使用できるわけだ。</p>
<p>また、T160、R260、R360といった通常のサーバーにフィルターをつけることで、エッジ環境で使用することも可能だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/19_5c6844a120/19_5c6844a120.png" alt="19.png" /></p>
<p>「ぜひサーバーが必要なときは、我々にお声がけをいただければと思います」（水口氏）</p>
<p>最後に水口氏が紹介したのは、デル・テクノロジーズとシュナイダーとの取り組みである「IT×OTフュージョンプロジェクト」だ。</p>
<p>PLC（プログラマブルロジックコントローラー）のパイオニアでOTのプロフェッショナルであるシュナイダーと、サーバーを作れるITの専門家であるデル・テクノロジーズが協力し、問い合わせから提案、導入、サポートまでの一連のプロセスを共同で行う。これにより、顧客の負担を減らすことを目的とした取り組みである。20年以上のビジネス関係がある両社ならではの協業と言えるだろう。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20_17a184b1b4/20_17a184b1b4.png" alt="20.png" /></p>
<p>イベント後は、会場であるDeloitte Tohmatsu Innovation ParkのThe Smart Factory by Deloitte @ Tokyoの見学も行った。</p>
<p>The Smart Factory by Deloitte @ Tokyoにはデル・テクノロジーズのPowerEdgeサーバーと、シュナイダーのバーチャルPLCが展示されており、実際に装置のデータを収集・分析するところを体感することができる。</p>
<p>国内でもまれな“ミニスマートファクトリー”を実機で体験できる施設なのだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/21_9196a35396/21_9196a35396.jpg" alt="21.jpg" /></p>
<p>本イベントを通して、日本の製造業の現状と課題、そしてスマートファクトリーの展望が伺えた。単にデジタルツールを導入するだけではない、真のトランスフォーメーションに向けて、大きなヒントが得られたイベントだったのではないだろうか。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/22_603e1c1515/22_603e1c1515.png" alt="22.png" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI活用の“壁”を突破する鍵はエッジにあり──デル・テクノロジーズが描く「分散型エージェントとハイブリッドAI」の未来</title>
      <link>https://ledge.ai/articles/edgetechplus20251121</link>
      <description><![CDATA[<p>生成AIはすでに私たちの生活に浸透しつつある一方で、ビジネスの現場では「スキル不足」「セキュリティ」「データのサイロ化」などが障壁となり、本格活用に踏み切れない企業も少なくない。</p>
<p>11月21日にパシフィコ横浜で開催された展示会「EdgeTech+」では、AI Elite(AIエリート)としてアジア太平洋地域のAI戦略を担う増月氏が登壇し、ビジネスにおけるAI活用の突破口は「クラウド」から「エッジ」への発想転換にあると語った。</p>
<p>本記事では、識別型AIと生成AIを組み合わせたハイブリッドコンピューティングモデルや分散型エージェント、さらに「Dell AI Factory with NVIDIA」、および、「Dell NativeEdge」によるエッジAI戦略について、同氏の講演内容をもとにひもといていく。</p>
<p>::: box
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_b53adeff8b/2_b53adeff8b.jpg" alt="2.jpg" />
デル・テクノロジーズ株式会社
インフラストラクチャー・ソリューションズSE統括本部
AIプラットフォーム・ソリューションズ
シニア システム エンジニア | AI Elite
CTO Ambassador
増月 孝信 氏</p>
<p>国内大手電機メーカの研究所にてAI研究職を経て、外資ITベンダーにてOS、ミドルウエア、データセンタなど幅広い分野で技術職, 技術マーケティングおよび製品企画を経験。過去に Java, OpenSolaris, OpenStack などOSSコミュニティーの幹事として貢献。2011年デル株式会社(現デル・テクノロジーズ株式会社)へ入社。
現在はAIソリューションのビジネス開発を担当。2023年にCTO Ambassadorを拝命。
:::</p>
<h2>AI活用は進みつつあるがビジネスでは課題も多い</h2>
<p>増月氏はデル・テクノロジーズでAI Eliteとして活躍する人物だ。AI Eliteはその名の通りデル・テクノロジーズのAIスペシャリストから選出認定された役職で、全世界でも20名弱しかいない。AI Eliteは同社のAIに関するビジネスに深く関わっており、増月氏もアジア・パシフィック地域におけるAI戦略を担当しているという。</p>
<p>そんなデル・テクノロジーズが近年注力するのが「エッジAI」である。これはクラウドではなく、PCのような端末で動作するAIのこと。クラウド型のAIとは対極的な特徴を持っており、今後需要がさらに高まることが予想されている。</p>
<p>本講演の主題ともいえるエッジAIについて語る前に、増月氏はまずAI活用の現状について説明を行った。</p>
<p>調査によると、現在「何らかの形で生活の中で生成AIを使用している」人は80％に達しており、さらに「仕事に使ったことがある」人も63％に上っている。すでにAIは人々の生活に溶け込んでいると言えるのだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_4bee902b23/3_4bee902b23.png" alt="3.png" /></p>
<p>一方で、ビジネスの現場でのAI活用については課題も見えてきたと増月氏は話す。</p>
<p>「一番の課題はAIのスキルです。調査によると組織の41％が従業員の専門知識やスキルがAIの導入に課題であると回答しています」</p>
<p>そしてもう一つの大きな課題がAIにおけるセキュリティの問題だ。アンケートでは組織の73％が「データのプライバシーとセキュリティが生成AIを使用する際に懸念されるリスク」と回答している。</p>
<p>「外部からのサイバー攻撃もAIによって高度化しており、社内にAIを導入するしないとは関係ないところでのAIリスクも考えられます」</p>
<p>さらに増月氏は「データそのものがAI活用の課題になっている」とも指摘する。</p>
<p>「皆さん、AIのモデルや分析プラットフォームなどは非常に考えているのですが、そもそもデータが整っていないと成果はまったく上がりません。データにもっと投資して、うまく使える状態にしなければならないのです」</p>
<h2>レイテンシーやセキュリティ面でエッジAIの重要度は高い</h2>
<p>データに関する課題としてよく語られるのがサイロ化の問題だ。コーポレートシステムにおけるデータウェアハウスやトランザクションデータ、事業や部門に蓄積された製品や顧客のデータ、さらに支社や関連会社に存在する様々なビジネスデータ――こうしたデータが分断されていてはAIによる成果も期待できない。</p>
<p>またサイロ化という点で何よりも「置いてきぼりになっている」のが、まさに「エッジ」のデータだと増月氏は述べる。</p>
<p>「実際のデータが生成される場所というのは、クラウドやデータセンターの中ではなく、エッジなのです。たとえば皆さんが持っている携帯電話、あるいは製造や医療などの現場で発生するデータの方が、クラウドやデータセンターのデータよりも重要度が高い場合もあります」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4_10389fe9ec/4_10389fe9ec.jpg" alt="4.jpg" /></p>
<p>だからこそ、デル・テクノロジーズは今「エッジAI」に着目しているというわけだ。</p>
<p>エッジAIには他にも様々なメリットがある。</p>
<p>たとえばローカル処理を行うことによるレイテンシーの短縮だ。仮に製造現場で生成された画像データを処理するのにいちいちクラウドやデータセンターに送信していては遅延が発生し、意思決定に遅れにつながる恐れがある。また何らかの問題でネットワークが機能しなくなると、処理自体が行えなくなってしまう。</p>
<p>またセキュリティについてもメリットは大きい。エッジAIなら重要な機密情報をクラウドに送信することなく端末内で処理できるわけだから、情報漏洩にもつながりにくいのだ。</p>
<p>こうしたメリットの大きさからエッジAI活用も少しずつ進みつつあるが、現状はまだ多くの企業がクラウド型の生成AI活用に目が向いている状態だ。</p>
<p>調査によると「エッジにAIを完全、または部分的に実装した」と回答しているのはITの意思決定者の29％に留まっている。増月氏はこの現状に対し、「これからもっとエッジAIにフォーカスしていく必要がある」と述べた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/5_cb622891a1/5_cb622891a1.png" alt="5.png" /></p>
<h2>エッジAIの課題を分散型エージェントが解決する</h2>
<p>製造現場などではすでにエッジAIが導入されており、業務で活用が進んでいる。ただし、それはあくまでも「画像データを分析して製品の不良を見つける」といった「識別型AI」であり、昨今トレンドとなっている生成AIではない。というのも生成AIを動作させるには膨大なリソースが必要であり、現状のエッジの性能では難しいからだ。これが、LLMを用いた多くのサービスがクラウド型で提供されている大きな理由でもある。</p>
<p>また各AIを組み合わせるなど、何らかの処理を自動で行うことも識別型AIでは難しい。AI同士を連携して業務を進めるには、現状ではまだ人間が介在する必要がある。</p>
<p>こうした課題を解決しうるのが「エージェント」の存在だ。</p>
<p>「単一ではなく分散型でエージェントを運用することで、従来の識別型AIの処理を自動化するなどのユースケースを生み出せるのではないかと考えています」</p>
<p>ただしエージェントが勝手に意思決定し、アクションをとるところまで自動化するのはリスクも伴う。そこで増月氏が提案するのが「ヒューマン・イン・ザ・ループ」だ。これはエージェントによるワークフローの中に人間が介入し、条件付きでワークフローを自動化する考え方。最初は人による関与を多くしてエージェントを監視するが、次第にエージェントが学習し、人間の介在を少なくするというアプローチである。</p>
<p>この他にも、従来型のエッジAIとエージェント型AIには様々な違いがある。</p>
<p>たとえば管理・オーケストレーションについては、従来型エッジAIが中央集約型のコントロールプレーンで一元管理するのに対し、エージェント型AIは分散・自律型で、各ノードやエージェントがそれぞれ状態管理・意思決定を実施する。</p>
<p>ユーザーインターフェースについては、従来型エッジAIはダッシュボードやコマンドラインが中心で、複雑な操作や習熟が必要となる。ダッシュボードの多重化による負担も増えがちだ。一方、エージェント型AIは自然言語インターフェースでユーザーが対話的に指示・確認できるため、直感的かつ低学習コストで操作が可能だ。当然、ダッシュボードの負担も軽減できる。</p>
<p>「エージェント型AIにより、今までの専門知識を持った人しか扱えなかった世界から、もう少しフレキシビリティの高い環境を作ることができるのではないかと考えています」</p>
<p>複数のエージェントがネットワーク全体で動作しユーザーの意図を理解して、特定のタスクを効果的に実行する。そんな「分散型エージェント」のワークフローはどのように構築できるのか。増月氏は次のように一例を示した。</p>
<p>「まず人が命令するのは自然言語です。コマンドを叩きたり、ダッシュボードで操作したりするのではなく、自然言語で命令を入力します。するとAPIを介在してエージェントが検出され、ワークフローマネージャーで実際のステップを構築していきます。メモリーストアはエージェント間のステートを共有する仕組みで、これにより精度の高い結果を生むことができます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/6_9ee6548d1d/6_9ee6548d1d.png" alt="6.png" /></p>
<h2>「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルとは</h2>
<p>続いて増月氏が解説するのが「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルだ。</p>
<p>識別型AIは前述したようにデータをもとに分類や予測を行うAIのこと。たとえばスマートフォンの顔認証もその一つ。あらかじめ「自分の顔の特徴」というデータを学習させることで、カメラに映っている人物が持ち主であると“識別”させているわけだ。この識別型AIは生成AIがブームになる前から世の中のあらゆる場所で活用されている。</p>
<p>同じAIであっても、この識別型AIと生成AIの違いを理解することは重要だ。。昨今は生成AIのインパクトがことさら強調されがちだが、何かのエラー判定を行うような場合など、分野によっては識別型AIの方がはるかに高い精度を出せる場面も多い。また比較的少ないリソースで動作するのも識別型AIのメリットだ。</p>
<p>一方で生成AIはコンテキストの認識や汎用化において識別型AIを寄せ付けないほどの強みを持っている。両者の特徴は異なり、うまく両方のメリットを組み合わせることが今後は重要になってくるのだ。</p>
<p>「低レイテンシーやリアルタイム性が要求されるケースでは、できるだけワークロードをデータが生成されるエッジに持ってくる必要があります。ただ難しい処理になるとエッジよりもある程度コンピューティングリソースのある環境が必要になるため、クラウド活用が重要になってきます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_68105acef1/7_68105acef1.jpg" alt="7.jpg" /></p>
<p>では具体的にどのようなアーキテクチャを構築すべきなのか。増月氏が一例として示すのが、ハイブリッド分散型AI推論システムだ。</p>
<p>製造ラインの例では、エッジサイドで識別型AIが製品の合否判定を行い、不良品が検出された場合は比較的小さなリソースで稼働する生成AI VLM（ビジュアル言語モデル）を使って異常を分析する。一方で、複雑な処理はデータセンター側のLLMと連携し、分散型のLFMを使ってネットワークトラフィックを削減するわけだ。</p>
<p>このアーキテクチャにより、デジタルツインでのシミュレーションも可能になるほか、ロボットや自動運転、スマートシティなどのフィジカルAIの実現にもつながると増月氏は語った。</p>
<h2>「Dell AI Factory with NVIDIA」と「Dell NativeEdge」――デル・テクノロジーズが進めるAI戦略</h2>
<p>こうした発想に基づき、デル・テクノロジーズが進めるAI戦略が「Dell AI Factory」である。</p>
<p>柱となるのは「AI in/AI on/AI for/AI with」という4つの考え方だ。PCやストレージといった製品の中にAI機能を組み込み（AI in）、ハードウェアやコンピュート環境の上でAIを実装する（AI on）。さらにデル・テクノロジーズ一社ではなく、グローバルでパートナー企業と協力し（AI with）、デル社内でのAI活用で培ったノウハウを提供していく（AI for）とのことだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/8_10f5e922bc/8_10f5e922bc.png" alt="8.png" /></p>
<p>デル・テクノロジーズの強みについて増月氏は、ユースケース定義、データパイプライン設計、エッジからスーパーコンピュータまで網羅する幅広いインフラ提供、シリコンベンダーやソフトウェアベンダーとの多様なパートナーリング、サービスデリバリーまでエンド・トゥ・エンドで提供できる点にあると述べた。</p>
<p>Dell AI Factoryにおいてチャレンジとなるのが、エッジのワークロードをどのようにオーケストレートするのかという点だ。そのための仕組みが「Dell NativeEdge Platform」である。</p>
<p>「識別型AIや生成AIなどのワークロードを展開するのに、わざわざITの管理者が現場に行くことなくオーケストレートする仕組みです。現場に行かなくてもリモートで運用ができる“ゼロタッチ”により、AIだけでなくいろいろな環境とインテグレートすることができます」</p>
<p>デル・テクノロジーズのAI Factoryは、特にNVIDIAと強いリレーションを持っている。GPUやソフトウェアスタック、ネットワーキングなどをすべてインテグレートする仕組みがあり、エッジサイドではGB10を搭載した超小型スーパーコンピュータSparkも提供可能とのことだ。</p>
<p>講演ではHugging Face上のLLMポータルからモデルを選択し、ブループリントを生成、NativeEdgeを通じてエッジデバイスに展開するデモも行われた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9_535c14c78e/9_535c14c78e.jpg" alt="9.jpg" /></p>
<p>デル・テクノロジーズが考えるハイブリッドモデルは、NativeEdgeとDell AI Factoryを連携させ、一元管理する仕組みだ。これはクラウドベンダーではできないことであり、同時にエッジのみにフォーカスしているベンダーにも難しい取り組みである。まさにデル・テクノロジーズだからこそ可能な提案と言える。</p>
<p>増月氏は最後にエージェント間のコミュニケーションの重要性について触れ、パートナーリングのエコシステムをさらに加速させる必要があると呼びかけて講演を締めくくった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/10_f010c9bc0b/10_f010c9bc0b.png" alt="10.png" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Googleカレンダー、Geminiで会議日程調整を自動化──最適な候補提示と“辞退後の再調整”をワンクリックで</title>
      <link>https://ledge.ai/articles/google_calendar_gemini_meeting_scheduling_update</link>
      <description><![CDATA[<p>Googleは2026年1月26日、Googleの「Google カレンダー」において、会議のスケジュール設定と再調整を支援する新機能を<a href="https://workspaceupdates.googleblog.com/2026/01/improved-meeting-suggestions-gemini-calendar.html">発表</a>した。生成AI「Gemini」を活用し、参加者の空き状況などを踏まえた候補時間の提示や、招待後の再スケジュールを簡素化する。</p>
<h2>Geminiが最適な会議時間を自動提案</h2>
<p>新機能では、イベント作成時に表示される「Suggested times」を選択すると、Geminiが参加者全員の空き状況を分析し、最適な会議時間の候補を提示する。タイムゾーンや勤務時間、既存予定との重複などを考慮したうえで候補が示され、主催者は提示された時間から選ぶだけで会議を設定できる。</p>
<h2>辞退が出た場合も、ワンクリックで再調整</h2>
<p>会議招待後に複数の参加者が欠席を選択するなどして成立が難しくなった場合、イベント画面上部に全員が参加可能な代替時間を示すバナーが表示される。主催者はそのバナーをクリックすることで、新しい時間帯への再スケジュールを行える。</p>
<h2>利用条件と制約</h2>
<p>Geminiによる時間候補の提示は、主催者が参加者のカレンダー情報にアクセスできることが前提となる。Googleのヘルプページによると、利用環境や会議の条件によっては候補が表示されない場合があるなど、一定の制約も設けられている。</p>
<h2>提供時期と対象プラン</h2>
<p>同機能は、Google WorkspaceのBusiness Standard／Plus、Enterprise Standard／Plus、および「Google AI Pro for Education」アドオンのユーザーが利用できる。Rapid Releaseドメインではすでに提供が始まっており、Scheduled Releaseドメインでは2026年2月2日から段階的に展開される予定だ。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、ピクサー出身監督と制作した短編アニメをサンダンス映画祭でプレビュー上映へ──AIを制作工程に組み込む新たな表現手法を提示</title>
      <link>https://ledge.ai/articles/google_sundance_ai_animation_workflow</link>
      <description><![CDATA[<p>Googleは2026年1月26日（現地時間）、同社が制作した短編アニメ映画を、米国で開催されるサンダンス映画祭のプログラム「Sundance Institute Story Forum」でプレビュー上映すると<a href="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/dear-upstairs-neighbors">発表</a>した。作品は、Google DeepMindの研究チームと、ピクサー出身の監督が協働して制作したもので、AIをアニメーション制作工程に組み込む新たな表現手法を示す事例として紹介される。</p>
<p>なお、Sundance Film Festivalは、インディペンデント映画を中心に、新しい表現手法や制作アプローチを積極的に紹介してきた国際的な映画祭として知られている。上映作品だけでなく、物語の作り方や制作プロセスを議論する場も設けられており、映画表現の変化をいち早く取り上げる場として注目されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=eCk5VFKKz08">YouTube</a></p>
<h2>ピクサー出身監督とGoogle DeepMindが共同制作</h2>
<p>今回プレビュー上映される短編アニメは、ピクサー出身の監督 Connie He 氏と、Google DeepMindの研究者・エンジニアが共同で制作した。同作は、研究成果のデモンストレーションではなく、完成した短編アニメ作品として制作された点が特徴だ。Googleは、AI研究の成果を実際のクリエイティブ制作に適用する試みとして位置づけている。</p>
<h2>AIを“主役”にしない制作ワークフロー</h2>
<p>制作では、Google DeepMindが開発する画像生成モデル「Imagen」や動画生成モデル「Veo」などが用いられた。ただし、テキストプロンプトのみを入力して映像を生成する一般的な生成AIの使い方は採られていない。</p>
<p><strong>Imagenをファインチューニングして生成された主人公「Ada」のビジュアル例。単一のプロンプト生成ではなく、制作者の素材や意図を反映させながら表現の幅を広げたとしている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/WM_Ada_T2_I_1080p_max_1080x1080_format_webp_abc27ecd3f/WM_Ada_T2_I_1080p_max_1080x1080_format_webp_abc27ecd3f.webp" alt="WM_AdaT2I_1080p.max-1080x1080.format-webp.webp" /></p>
<p>Googleによると、制作工程ではまずアーティストが手描きのスケッチや絵コンテ、ラフアニメーションを作成し、それらのビジュアル素材をもとにAIモデルを調整・活用する手法が取られたという。Veoは既存のアニメーションや映像素材を入力として受け取り、動きや質感を保ったまま表現を拡張する用途で使われ、Imagenはキャラクターや背景のビジュアル表現を補完する役割を担ったとしている。</p>
<p>このように、AIは制作工程の各段階で補助的に組み込まれており、物語構成や演出、最終的な表現の判断は人間の制作者が担う設計となっている。Googleは、AIを「自動生成の主体」ではなく、アーティストの意図を反映するための制作ツールとして位置づけている。</p>
<h2>「Story Forum」でのプレビュー上映という位置づけ</h2>
<p>上映が行われる「Sundance Institute Story Forum」は、完成作品の優劣を競うコンペティションではなく、物語表現や制作手法、創作プロセスそのものを共有・議論することを目的としたプログラムだ。</p>
<p>今回の短編アニメも、AIを活用した新しい制作工程の事例として紹介され、制作の背景や手法についての説明とあわせて上映される予定となっている。</p>
<h2>AI研究成果を創作の現場へ</h2>
<p>Googleは同作品について、AI研究の成果を実験段階にとどめず、映画やアニメーションといった創作の現場でどのように活用できるかを示す試みだとしている。表現の幅を広げることや、制作工程の選択肢を増やすことを目的としており、現時点で商用配信や一般公開の予定については明らかにしていない。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4oが再び退場へ──OpenAI、ChatGPTで旧モデル整理　2月13日に提供終了、利用の大半はGPT-5.2に移行</title>
      <link>https://ledge.ai/articles/gpt-4o_retirement_chatgpt_feb_13</link>
      <description><![CDATA[<p>OpenAIは2026年1月29日、ChatGPTで提供している「GPT-4o」「GPT-4.1」「GPT-4.1 mini」「OpenAI o4-mini」の4モデルを、2026年2月13日をもって提供終了（retire）すると<a href="https://openai.com/index/retiring-gpt-4o-and-older-models/">発表</a>した。同日には、すでに発表されている「GPT-5（InstantおよびThinking）」のChatGPTでの提供終了も実施される。なお、APIについては現時点で変更はないとしている。ChatGPT上で利用可能な旧世代モデルを整理し、より新しいモデルにリソースを集中させる狙いだ。</p>
<h2>2月13日にChatGPTから4モデルを除外</h2>
<p>提供終了の対象となるのは、以下の4モデルだ。</p>
<ul>
<li>GPT-4o</li>
<li>GPT-4.1</li>
<li>GPT-4.1 mini</li>
<li>OpenAI o4-mini</li>
</ul>
<p>これらのモデルは2月13日以降、ChatGPTのモデル選択肢から削除され、同サービス上では利用できなくなる。一方で同社は、APIについては「現時点では変更はない」と明記している。</p>
<h2>GPT-4oは一度引退後に復活、再び退場へ</h2>
<p>OpenAIは今回の告知の中で、GPT-4oについて特別に背景を説明している。</p>
<p>GPT-4oは、過去に一度ChatGPTから非推奨（deprecated）となった後、GPT-5のリリース時にアクセスが復活した経緯がある。復活の背景には、PlusおよびProユーザーの一部から寄せられたフィードバックがあった。具体的には、創造的なアイデア出しなどの用途で移行に時間が必要だったことや、GPT-4oの「会話のスタイルや温かみ」を評価する声があったとしている。</p>
<p><strong>「GPT-5切替で “4oロス” 広がる──ChatGPT界隈を席巻した「#keep4oムーブ」と期間限定 “里帰りモード”」</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Chat_GPT_Image_2025_8_12_18_58_22_d73354f1a7/Chat_GPT_Image_2025_8_12_18_58_22_d73354f1a7.jpg" alt="ChatGPT Image 2025年8月12日 18_58_22.jpg" /></p>
<h2>利用の大半はGPT-5.2に移行、GPT-4o選択は0.1％</h2>
<p>OpenAIは、今回あらためてGPT-4oを提供終了とする理由について、「必要な改善がすでに整った」ことと、「利用状況の変化」を挙げた。</p>
<p>同社によると、現在のChatGPT利用の大半はすでにGPT-5.2に移行しており、日常的にGPT-4oを選択しているユーザーは全体の0.1％にとどまっているという。この状況を踏まえ、GPT-4oの役割は事実上、新世代モデルに引き継がれたと判断した。</p>
<h2>GPT-5.1／5.2で人格や創造性を強化</h2>
<p>OpenAIは、GPT-4oに寄せられたフィードバックが、GPT-5.1およびGPT-5.2の改良に直接反映されたと説明している。</p>
<p>新世代モデルでは、人格や創造性の改善に加え、ChatGPTの応答スタイルを調整できる仕組みを拡充。ベースとなるスタイルやトーンの選択に加え、温かみや熱量といった要素をユーザーが調整できるようになっている。</p>
<h2>過剰な拒否や説教的応答の是正にも言及</h2>
<p>OpenAIは今後の方向性として、ChatGPTの人格や創造性のさらなる改善に加え、「不要な拒否」や「過度に慎重、あるいは説教的な応答」への対処を進めていく方針も示した。これらについては、近くアップデートを予定しているという。</p>
<p>また、18歳以上の成人ユーザー向けに、適切な安全策の範囲内で選択肢と自由度を拡張したChatGPT体験を目指す考えも示している。この取り組みの一環として、OpenAIは18歳未満と推定される利用者を対象に、年齢に応じた体験を提供するための年齢推定（age prediction）を、多くの市場で展開していることにも触れた。</p>
<h2>「苦渋の判断」としつつ改善に集中</h2>
<p>OpenAIは、GPT-4oの提供終了について「一部のユーザーにとっては不満や不便を感じる決定であることは理解している」としつつ、「モデルの引退は決して容易ではないが、より良いモデルの改善に集中するために必要な判断だ」と説明している。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>判断から実行までをAIが担う──日立ソリューションズ、RPAと連携するAIエージェント業務自動化を提供開始</title>
      <link>https://ledge.ai/articles/hitachi_solutions_ai_agent_rpa_business_automation</link>
      <description><![CDATA[<p>日立ソリューションズは2026年1月21日、AIとRPAを連携させ、複数の業務システムを横断して操作しながら、業務プロセスを自律的に判断・遂行する「AIエージェント活用業務自動化ソリューション」の提供を開始したことを<a href="https://www.hitachi-solutions.co.jp/company/press/news/2026/0121_1.html">発表</a>した。業務の判断をAIが担い、実行をRPAが担う構成により、従来は人手が介在していた複雑な業務の自動化を可能にする。</p>
<p>同ソリューションでは、AIエージェントが業務内容や処理状況を把握し、次に取るべき操作を判断する。判断結果に基づき、RPA（Robotic Process Automation、定型業務を自動化するソフトウエアロボット）が実際のシステム操作を行うことで、業務全体を一連の流れとして自動実行する。単一業務の自動化にとどまらず、業務プロセス全体を対象とする点が特徴だ。</p>
<p><strong>見積作成業務におけるAIエージェント活用イメージ。業務5ステップ中4ステップを自動化する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/hitachi_aiagent_overview_44c100e94b/hitachi_aiagent_overview_44c100e94b.jpg" alt="hitachi aiagent overview.jpg" /></p>
<p>API連携が難しい既存の業務システムや、画面操作が前提となるレガシーシステムにも対応する。AIによる判断と、RPAによる画面操作を組み合わせることで、複数システムをまたぐ業務を横断的に自動化できるとしている。また、AIエージェントは自律的な判断だけでなく、必要に応じて人への確認を行うなど、柔軟な業務対応も可能だという。</p>
<p>導入にあたっては、自然言語やノーコード／ローコードによるAIエージェント作成を前提とし、業務部門でも扱いやすい設計を採用した。オープンな標準規格「MCP（Model Context Protocol）」に対応し、複数のAIエージェントを組み合わせた構成も可能としている。AIエージェントの設計からRPAとの連携、運用、改善までを一体で支援する。</p>
<p>同社は実業務での検証も行っており、見積作成業務を対象に、作業工程の約80％を自動化し、担当者の作業時間を約90％削減したとしている。判断が必要な工程がボトルネックとなっていた業務に対し、AIエージェントが判断を担うことで、自動化の適用範囲を拡大できると説明している。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、推論向けAIアクセラレータ「Maia 200」発表──GPT-5.2を含む最新モデルを支える基盤に</title>
      <link>https://ledge.ai/articles/microsoft_maia_200_inference_ai_accelerator</link>
      <description><![CDATA[<p>Microsoftは米国時間2026年1月26日、AI推論に特化した自社設計のカスタムアクセラレータ「Maia 200」を<a href="https://blogs.microsoft.com/blog/2026/01/26/maia-200-the-ai-accelerator-built-for-inference/">発表</a>した。大規模言語モデル（LLM）などの推論処理を想定した設計で、同社はクラウドサービス「Azure」におけるAI基盤を支える中核技術の一つと位置づけている。</p>
<p>Maia 200は、学習用途ではなく推論ワークロードに最適化したアクセラレータとして設計された。Microsoftによると、トークン生成を中心とする推論処理において、スループットや電力効率、システム全体でのスケーラビリティを重視しているという。製造にはTSMCの3ナノメートルプロセスを採用し、FP8およびFP4演算に対応したテンソル演算機構を備える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Maia200chip_960x540_c584507414/Maia200chip_960x540_c584507414.png" alt="Maia200chip-960x540.png" /></p>
<p>メモリ構成ではHBM3eを採用し、大容量かつ高帯域のメモリアクセスを可能にした。Microsoftは、Maia 200が従来世代と比べて性能あたりのコスト効率を向上させたと説明しているが、具体的な比較対象や条件については明らかにしていない。</p>
<p>同社は、Maia 200をAzureのデータセンターに段階的に導入する方針を示している。Azure AI FoundryやMicrosoft 365 CopilotといったAIサービスの基盤として活用されるほか、OpenAIの最新モデルであるGPT-5.2を含む複数のAIモデルを支えるインフラとして位置づけられている。</p>
<p>@<a href="https://www.youtube.com/watch?v=bGecvPR2QWo">YouTube</a>
Microsoftはこれまで、GPUを中心とした外部ベンダー製アクセラレータを活用してきたが、AI利用の急拡大を背景に、自社設計シリコンの開発を進めてきた。Maia 200は、その流れの中で推論処理に特化した最新世代のアクセラレータとなる。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>モスバーガー、AIが音声で注文を受けるドライブスルー実証開始──人と連携する「ハイブリッド応対」</title>
      <link>https://ledge.ai/articles/mos_burger_ai_drivethru_voice_order_test</link>
      <description><![CDATA[<p>モスフードサービスは2026年1月21日、同社が展開する「モスバーガー」店舗のドライブスルーにおいて、人工知能（AI）が来店客の音声を認識して注文を受けるシステムの実証実験を開始したと<a href="https://www.mos.co.jp/company/pr_pdf/pr_260121_1.pdf">発表</a>した。AIと店舗スタッフが連携して応対する「ハイブリッド応対」を採用し、接客品質の向上と人手不足への対応を両立する狙いだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/New_Innovations_mos_760e300280/New_Innovations_mos_760e300280.jpg" alt="New Innovations mos.jpg" /></p>
<h2>AIと人が連携、全面自動化は目指さず</h2>
<p>ファストフード業界では、ドライブスルーにおけるAI音声注文は欧米を中心に導入例がある一方、認識精度の低さが課題とされてきた。今回の実証実験では、AIに全ての工程を任せるのではなく、AIが受注を担い、店舗スタッフが必要に応じてサポートする方式を採用。人とAIが役割分担することで、円滑な注文対応と接客品質の維持・向上を図る。</p>
<h2>音声対話AI「AI Order Thru」を導入</h2>
<p>実証実験には、New Innovationsが開発した音声対話AI「AI Order Thru（エーアイ オーダー スルー）」を活用する。同システムは、実店舗のオーダー業務を音声による自然なコミュニケーションで行うことを想定して設計されており、ブランドごとのガイドラインに沿った対話設計や標準オペレーションを前提とした運用が可能とされる。モスフードサービスは、同システムのカスタマイズ性を生かし、同社が重視するホスピタリティの進化と店舗オペレーションの高度化を両立させたい考えだ。</p>
<h2>吉川美南店で開始、年度内に5店舗程度へ</h2>
<p>実証実験は2026年1月21日、埼玉県吉川市の「モスバーガー 吉川美南店」で開始した。今後は2026年度中に合計5カ所程度の店舗で実証実験を行い、そのうち複数店舗での常設運用を目指すとしている。</p>
<h2>将来はメニュー提案や演出拡張も視野</h2>
<p>将来的な展開として、来店客から「500キロカロリー以下のセットメニューを紹介して」といった要望があった場合に、AIが即座に提案する機能や、キャンペーン期間中にアニメの人気キャラクターなどが応答する演出も視野に入れる。AIドライブスルーを通じ、顧客体験の拡張可能性を検証していく。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/1/31 [SAT]AI研究の主要国際会議「NeurIPS 2025」採択論文でハルシネーション多数──GPTZero、「vibe citing（雰囲気引用）」を中心概念として定義し分析を公開</title>
      <link>https://ledge.ai/articles/neurips_2025_hallucinated_citations_gptzero</link>
      <description><![CDATA[<p>AI生成コンテンツの検出を手がけるGPTZeroは2026年1月21日、AI研究の主要国際会議NeurIPS 2025の採択論文を分析した結果、51本の論文にまたがる計100件の「ハルシネーション（幻覚引用）」を確認したと<a href="https://gptzero.me/news/neurips/">発表</a>{target=”_blank”}した。対象は、NeurIPS 2025で採択された論文のうち4,841本で、いずれも既に採択され、会議で発表済みの論文だとしている。</p>
<h2>採択論文4,841本を分析、51本で「確認済み」100件</h2>
<p>GPTZeroによると、今回確認された「幻覚引用」とは、実在しない、または事実と一致しない参考文献が、もっともらしい書誌情報として記載されている状態を指す。具体的には、実在論文に似たタイトルや著者名を組み合わせたもの、存在しないDOIやURL、別論文を指すarXiv IDなどが含まれるという。
同社は、専用ツール「Hallucination Check」でオンライン照合できない引用を抽出したうえで、人手による確認を経て“幻覚”と判断した例のみを集計したとしている。</p>
<h2>「vibe citing（雰囲気引用）」と定義、誤検出の可能性にも言及</h2>
<p>GPTZeroは、生成AIが実在文献を下敷きにしながら、著者名・タイトル・掲載先・年次などを混在させて作る引用を「vibe citing（雰囲気引用）」と呼び、今回の分析の中心概念として定義した。
一方で、同社は「照合不能＝即ハルシネーションではない」とも説明しており、未公開資料やアーカイブ文献などがオンラインで見つからない場合もあるとして、最終判断には人の確認が必要だと注意を促している。</p>
<h2>投稿数急増で査読負荷が拡大、公式統計も</h2>
<p>NeurIPS運営側の公式発表によると、NeurIPS 2025の有効投稿数は21,575本、採択数は5,290本、採択率は24.52％だった。投稿数は近年大きく増加しており、査読体制への負荷が高まっている状況が示されている。</p>
<p>GPTZeroは、今回の結果について、特定の著者や査読者を批判するものではなく、投稿規模の拡大と生成AIの普及が、従来の査読プロセスに新たな課題を突きつけていると説明している。</p>
<h2>LLM利用ポリシーでは、問題があれば措置の可能性も</h2>
<p>NeurIPSは、論文作成における大規模言語モデル（LLM）の利用について<a href="https://neurips.cc/Conferences/2025/LLM">公式ポリシー</a>{target=”_blank”}を設けており、内容の正確性は著者が責任を負うと明記している。科学的整合性に重大な問題が認められた場合、受理後であっても調査や措置の対象となり得るとしている。</p>
<p>GPTZeroは、引用確認を含むチェック工程を、著者・査読者・編集・運営の各段階で支援するツールの活用が有効だとし、今後も学術出版プロセスの透明性向上を目指すとしている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、GPT-5.2搭載の研究執筆AI「Prism」を無料で公開──人数制限なしの共同作業ワークスペース</title>
      <link>https://ledge.ai/articles/openai_prism_gpt5_2_research_writing_workspace</link>
      <description><![CDATA[<p>OpenAIは2026年1月27日、科学研究向けのAI執筆・共同作業ワークスペース「Prism」を<a href="https://openai.com/index/introducing-prism/">発表</a>した。GPT-5.2を中核に据えたAIネイティブ設計を採用し、論文執筆や修正、共同編集といった研究の日常業務を単一のクラウド環境に統合する。Prismは無料で利用でき、ChatGPTアカウントを持つユーザーであれば、人数制限なく共同作業を行える。</p>
<h2>研究執筆に残る分断を解消</h2>
<p>OpenAIは、AIは数学や生物学などの分野で研究の加速に寄与し始めている一方、論文執筆や推敲、数式管理、参考文献整理、共同編集といった日常業務は、依然として複数のツールに分断されたままだと述べる。研究者はエディタ、PDF、数式コンパイラ、文献管理ツール、チャットを行き来する必要があり、文脈の断絶が作業効率を下げてきた。Prismは、こうした断片化を解消する最初の取り組みとして位置付けられている。</p>
<h2>GPT-5.2を統合したAIネイティブ環境</h2>
<p>Prismは、OpenAIの最新モデルであるGPT-5.2を研究執筆のワークフローに直接組み込んだ点が特徴だ。数式や参考文献、論文全体の構造を文脈として理解したうえで、AIがドラフト作成や修正、推敲を支援する。研究者は、執筆環境の外にあるチャットツールを行き来することなく、同一のプロジェクト内でAIと対話しながら作業を進められる。</p>
<p><strong>OpenAIが公開したPrismの紹介動画。論文執筆とAI支援が同一ワークスペース内でどのように統合されているかを示している。</strong></p>
<p>@<a href="https://www.youtube.com/watch?v=xnInEsaaj9c">YouTube</a></p>
<h2>クラウド型・専門記法対応のワークスペース</h2>
<p>Prismは、学術論文で広く使われる数式や専門記法に対応したクラウドベースの執筆環境として設計されている。OpenAIが取得したクラウドLaTeX基盤「Crixet」を発展させたもので、既存の成熟した執筆・共同編集機能を土台に、AIを自然に統合したという。数式や図表、引用関係を横断的に理解しながら編集できる点を強みとする。</p>
<h2>研究チームでの共同作業を前提に設計</h2>
<p>科学研究は本質的に共同作業で進められる。Prismは、プロジェクト数や共同編集者数に制限を設けず、研究チーム全体での利用を前提に設計されている。クラウド型のため、ローカル環境の構築や専門ソフトのインストールは不要で、編集内容はリアルタイムに反映される。これにより、版管理や手動での統合作業にかかる負担を減らし、研究内容そのものに集中できるとしている。</p>
<h2>無料提供と今後の展開</h2>
<p>Prismは無料で利用でき、ChatGPTの個人アカウントを持つユーザーであれば、すぐに執筆や共同作業を開始できる。購読契約や席数の制限は設けられていない。OpenAIは今後、ChatGPT Business、Enterprise、Education向けにも提供を予定しており、より高度なAI機能については有料プランで順次展開するとしている。</p>
<p>OpenAIは、2025年にAIがソフトウェア開発の在り方を大きく変えたのに続き、2026年には科学研究でも同様の変化が起きると見ている。Prismは、研究者の日常業務に伴う摩擦を減らすことで、科学の進展を加速させるための第一歩と位置付けられている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>パナソニック、仮想タレント制作のAI modelに出資──大企業CVCが並ぶプレシリーズBで資金調達</title>
      <link>https://ledge.ai/articles/panasonic_virtual_talent_ai_model_investment</link>
      <description><![CDATA[<p>パナソニックは2026年1月23日、SBIインベストメントと共同で運営するコーポレートベンチャーキャピタル（CVC）を通じ、AIを活用して仮想タレントなどを制作するスタートアップのAI modelに出資したと<a href="https://news.panasonic.com/jp/press/jn260123-1">発表</a>した。AI modelは同日、プレシリーズBラウンドの<a href="https://prtimes.jp/main/html/rd/p/000000046.000097252.html">資金調達を実施</a>したことを明らかにしている。</p>
<p>パナソニックの出資は、同社とSBIインベストメントが共同で設立したCVCファンド「PC‐SBI投資事業有限責任組合（通称：パナソニックくらしビジョナリーファンド）」を通じて行われた。出資額は非公表としている。</p>
<p>AI modelの発表によると、今回の資金調達には、SBIインベストメントのほか、キヤノンマーケティングジャパンがグローバル・ブレインと共同で設立したCVCファンド「Canon Marketing Japan MIRAI Fund」、三菱UFJキャピタルなどが参加した。このほか、複数の事業会社や地域系ベンチャーキャピタルも引受先として名を連ねている。</p>
<p>AI modelは、AIを用いた仮想タレントやデジタルヒューマンの制作を手がけるスタートアップで、エンターテインメントやブランド活用などを想定したAIモデルの開発を進めている。今回の資金調達を通じ、事業拡大や技術開発を進めるとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/sub1_31d793e5a3/sub1_31d793e5a3.jpg" alt="sub1.jpg" /></p>
<p>パナソニックは、SBIインベストメントと共同でCVCを運営し、くらしやコンテンツ、デジタル領域を含む成長分野への投資を進めてきた。今回のAI modelへの出資も、そうした投資活動の一環として位置づけられる。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>データ連携の雄、セゾンテクノロジーが見据えるAI活用の未来図 ― 石田誠司常務が語る「データインテグレーター」の真価</title>
      <link>https://ledge.ai/articles/saison_ishida_interview2026</link>
      <description><![CDATA[<p>生成AIの登場がビジネスの風景を塗り替えつつある現在、多くの企業がその活用に乗り出す一方で、根源的な課題に直面している。それは、AIの知性を育む「データ」の分断と混乱である。ファイル転送の分野で20年以上国内トップシェアを誇る「HULFT」や、データ連携プラットフォーム（iPaaS）「HULFT Square」を擁するセゾンテクノロジーは、この課題を真正面から捉え、自らを「データインテグレーター」へと再定義し、戦略転換を宣言している。本稿では、同社の取締役 常務執行役員 営業本部長である石田誠司氏へのインタビューを通じ、企業のAI活用が直面するリアルな課題と、同社が描くデータ連携が拓く未来について話を聞いた。</p>
<h2>再定義「データインテグレーター」</h2>
<p>デジタルトランスフォーメーション（DX）という言葉が一般化して久しいが、多くのIT企業にとって、その本質を自社の事業モデルにどう落とし込むかは依然として重い課題だ。特に、従来のシステムインテグレーション事業は利益率の低下圧力に晒され、クラウドとSaaSの爆発的な普及は「データのサイロ化」という新たな分断を生み出した。</p>
<p><strong>自社を「データインテグレーター」と称されていますが、その狙いは何でしょうか？</strong></p>
<p><strong>石田氏:</strong> 当社は50年以上の歴史の中で、お客様の要望通りにシステムを構築する、いわゆる従来のシステムインテグレーションの事業と、「HULFT」に代表されるプロダクト事業の二軸で成長してきました。しかし、数年前から、市場の変化を見据え、当社の最大の強みであるファイル連携やデータ連携の領域に事業を大きくシフトさせる戦略転換を図りました。これにより、従来の受託開発事業で培った技術を活かしつつ、高付加価値なデータインテグレーション事業へと集中しています。「データインテグレーター」という呼称は、SIerと対比する形で、「我々はデータを中心にインテグレーションを行う企業である」という決意を込めて名乗り始めました。</p>
<p><strong>「データインテグレーター」という新たなポジショニングに対する、市場や顧客からの反応はいかがですか？</strong></p>
<p><strong>石田氏:</strong> ちょうど「DX」という言葉が一般に流通し始めた2018年から2019年頃に、我々はデータ連携ビジネスを本格化させました。当時から大手企業数百社のお客様にデータ連携基盤を納めてきた実績がありましたが、近年になってようやく「DXの成功には、その基盤となるデータ連携が不可欠である」という考え方が、お客様の間で共通言語になってきたと感じています。この手応えは、経営層だけでなく、現場の社員も強く感じているところです。我々が見据えていた世界観が、ようやく市場に浸透し始めたという実感がありますね。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_3861fa3e2b/3_3861fa3e2b.png" alt="3.png" /></p>
<h2>データ連携市場を勝ち抜く、セゾンテクノロジーならではの競争優位性</h2>
<p><strong>国内外の競合と比較した際の、貴社の競争優位点は何でしょうか？</strong></p>
<p><strong>石田氏:</strong> 我々の競争優位性は、大きく3つの点に集約されると考えています。これらの強みが個別に存在するのではなく、三位一体で機能している点が重要です。</p>
<p><strong>1. 12,000社以上の強固な顧客基盤</strong>
長年にわたり提供してきた「HULFT」は、現在12,000社を超えるお客様にご利用いただいています。この強固な顧客基盤と、そこで培われた信頼関係こそが、我々の最大の資産であり、競争優位性の源泉です。この信頼をベースに、データ連携という新たな価値提案へと繋げることができています。</p>
<p><strong>2. 実装まで手掛ける実行力</strong>
我々は単なるパッケージベンダーではありません。「データインテグレーター」として、お客様の要件を深く理解し、実際のインプリメンテーション（実装）まで手掛ける専門部隊を擁しています。また、様々なユースケースに対応するためのデータ連携テンプレートも豊富に保有しており、迅速な価値提供が可能です。これは、製品を提供するだけのベンダーにはない決定的な強みです。</p>
<p><strong>3. 北米トレンドを取り込む開発体制</strong>
当社は海外にも開発拠点を構えており、特に先進的なトレンドが生まれる北米の動向を常に製品開発にフィードバックしています。いわば「タイムマシン経営」のような形で、世界の最先端技術やユースケースを取り込み、製品を進化させ続けることができるのです。</p>
<p>これら3つの強みの相乗効果こそが、我々の戦略の核心です。圧倒的な顧客基盤が高度なソリューションを提案する信頼の入り口となり、実装チームがその提案を現実のものに変え、そして北米からのフィードバックがそのソリューションを常に最先端に保ち続けるのです。</p>
<h2>「データはあるが、使えない」企業の根深い課題を解決する</h2>
<p>多くの企業がデータ活用の重要性を認識し、巨額の投資を行っているにもかかわらず、その成果を十分に得られていない。その根源には、部門間の壁によってデータが分断される「サイロ化」や、存在はするものの活用方法が分からず放置された「休眠データ」といった根深い問題がある。企業はまさに、価値の源泉であるはずのデータという宝の山を前に、それを掘り起こす術を持てずに立ち尽くしているのである。</p>
<p><strong>昨今の企業におけるデータ活用のトレンドと、企業が陥りがちな課題をどのように捉えていますか？</strong></p>
<p><strong>石田氏:</strong> 企業が抱えるデータ活用の課題は、その規模によって少し様相が異なります。大手企業では、むしろ組織が強固であるために「部門間の壁」がデータ連携を阻害しています。製造部門と販売部門がそれぞれ独自のSaaSやクラウドを導入し、結果として「野良クラウド」「野良SaaS」が乱立してしまっているのです。 一方で、中堅・中小企業のお客様からは「うちは活用できるデータがない」というお話をよく聞きます。しかし、実際にはそんなことはありません。例えば、社員間のチャットツールでのやり取りやプロジェクトの報告書など、非構造化データの中には、個々の社員が何を志向しているかといった貴重な情報が眠っています。</p>
<p>さらに、両者に共通する課題として、「データはあるが、触れられない」という問題があります。メインフレーム上に存在するレガシーデータや、部門ごとにバラバラに管理されて統一されていないマスターデータなどがその典型です。こうした課題を解決する上で、AIは非常に有効な手段となり得ます。例えば、AIに商品説明や成分表を読み込ませることで、異なるコードで管理されていたマスターデータを「これは同じ製品だ」と瞬時に紐付けることも可能になるのです。</p>
<h2>「RAGの沼」を越え、データを真の洞察へ</h2>
<p>データ活用の課題は、生成AIの登場によって新たな局面を迎えている。特に社内データを参照して回答を生成するRAG（検索拡張生成）技術は、企業データ活用のゲームチェンジャーとして大きな期待を集めている。しかし、その回答精度は元となるデータの質に大きく依存するため、多くの企業が「期待した答えが返ってこない」という「RAGの沼」にはまり、AI投資のROIを見出せずにいる。この沼は、多くのAIプロジェクトが実証実験（PoC）段階で頓挫する「死の谷」であり、ここを乗り越えることこそが価値創出の鍵となる。</p>
<p><strong>多くの企業が直面する「RAGの沼」に対し、どのようなアプローチで支援していますか？</strong></p>
<p><strong>石田氏:</strong> まさにそこが我々の価値を発揮できる領域です。RAGの精度を上げるためには、AIがデータを読み込む前の「前処理」が決定的に重要になります。当社では、この前処理を効率化するため「HULFT Square」向けの「AI前処理テンプレートシリーズ」を提供しています。このテンプレートを使えば、PDF形式のマニュアルや画像データといったAIがそのままでは理解しにくい非構造化データを、タグなどのノイズ除去やQ&amp;A形式のCSVファイル変換など、AIが最も理解しやすい形式に自動で加工や整形することができます。実際に、あるPDFデータをそのまま読み込ませた場合、ある生成AIモデルでの正解率が50%だったのに対し、当社のテンプレートで前処理を施したデータでは90%まで劇的に向上しました。一度、自力でRAGを試してうまくいかなかった経験をお持ちのお客様ほど、この前処理の重要性をご理解いただけ、我々のアプローチが非常に響くようです。</p>
<p><strong>データとAIを連携させることで、企業活動そのものはどのように変わるのでしょうか？</strong></p>
<p><strong>石田氏:</strong> 一例として、人材活用（タレントマネジメント）の領域で劇的な変化が起きています。従来、プロジェクトへの人員アサインは、マネージャーの経験や勘、あるいはスキルシートといった限られた情報に頼らざるを得ず、そこには必ず個人のバイアスがかかっていました。しかしAIは、そうしたバイアスとは無縁です。例えば、社員が任意で受講したeラーニングの履歴や、チャットツールでの「会計の知識を深めたい」といった何気ない発言まで、多角的なデータを統合的に分析します。その結果、「英語はできないが、海外プロジェクトへの参加意欲が誰よりも高い」といった、人間のマネージャーでは見過ごしがちだった潜在的な意欲を汲み取り、最適人材としてアサインするといったことも可能になるでしょう。これは、社員のモチベーションを最大限に引き出す、従来とは全く異なるアサインメントの形であり、データとAIの連携がもたらす変革のほんの一例に過ぎません。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_729af42f23/2_729af42f23.png" alt="2.png" /></p>
<h2>自律的なAIエージェントの活用とガバナンスという新たな挑戦</h2>
<p>AIの進化は、RPAに代表されるような定型業務の自動化から、自ら状況を判断し、タスクを遂行する「AIエージェント」へとその主戦場を移している。AIエージェントは、人間の手を介さずに業務を完結させることで飛躍的な生産性向上をもたらすと期待される一方、管理・統制が取れなくなる「野良エージェント」が企業システム内で無秩序に活動し、セキュリティやコンプライアンス上の深刻なリスクとなる二面性を持つ。このパラダイムシフトは、企業に「いかにしてAIの力を解き放ち、同時にそのリスクを統制するか」という新たな問いを突きつけている。</p>
<p><strong>AIエージェントの進化をどう見ていますか？また、その中で貴社はどのような役割を果たしますか？</strong></p>
<p><strong>石田氏:</strong> AIエージェントには、RPAの延長線上にある業務自動化タイプのものと、より高度なインテリジェンスを持って自律的に判断するものの2種類があると考えており、我々は特に後者の進化に注目しています。例えば、コールセンターでお客様の感情を分析し、怒っているようであれば対応をエスカレーションするといった活用は、インテリジェントなエージェントならではの動きです。 そして、こうしたAIエージェントの活用が本格化する中で、我々が果たすべき最も重要な役割は「ガバナンス」の提供です。企業の様々なシステムやデータ、そしてAIエージェントが、我々のiPaaSである「HULFT Square」をハブとして連携するアーキテクチャを構築します。これにより、どのエージェントが、いつ、どのデータにアクセスし、どのような処理を行ったかをすべて可視化し、追跡することが可能になります。このハブを通過しないエージェントは「野良エージェント」として明確に判別できるため、企業はセキュリティと統制を担保しながら、AIエージェントの活用を推進できるのです。これが我々の描くビジョンです。</p>
<h2>「AI Foundation構想」が拓く、オープンなAIエコシステムの未来</h2>
<p>これまでの議論は、一つの壮大な構想へと収斂していく。それが、セゾンテクノロジーが掲げる「AI Foundation構想」である。これは、単なる製品開発ロードマップではない。同社が持つ競争優位性を最大限に活かし、AIエージェントのガバナンスという喫緊の課題に応え、そして経営層のマインドセット変革を後押しするための、オープンなAIエコシステムを社会に実装しようとする野心的な試みだ。</p>
<p><strong>貴社が掲げる「AI Foundation構想」とは、具体的にどのようなものでしょうか？</strong></p>
<p><strong>石田氏:</strong> 「AI Foundation構想」とは、当社のiPaaS「HULFT Square」を中核とした、オープンなAIエコシステムを構築する構想です。このプラットフォーム上には、これまで述べてきたRAGに読み込むデータを事前加工するAI前処理テンプレートや、AIエージェント同士が連携するためのA2A（Agent-to-Agent）プロトコルなどを取り揃えていきます。重要なのは、これを我々だけで開発するのではなく、パートナー企業が持つ優れた技術やエージェントも自由に組み込めるオープンな設計にしている点です。将来的には、このエコシステムを通じて、企業間をまたいでAIエージェント同士が自律的に連携する世界を見据えています。例えば、あるメーカーで製品のリコールが発生した際に、その情報がメーカーのAIエージェントから販売店のERPを管理するAIエージェントへ自動で伝達され、出荷停止や在庫確認が即座に行われる、といった世界が実現可能になります。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_Foundation_bbc64166ee/AI_Foundation_bbc64166ee.png" alt="AI Foundation.png" /></p>
<p><strong>2026年以降のAI市場、特に「国産」という文脈でどのような未来を描いていますか？</strong></p>
<p><strong>石田氏:</strong> 2026年は、AIエージェントの活用が本格化する年になると予測しています。その際、海外の大手ベンダーは、自社の製品群で固めたクローズドな「密結合」のエコシステムを構築してくるでしょう。それに対し、我々は様々なシステムやサービスを繋ぐオープンな「疎結合」のハブとなることを目指します。 また、「国産」という点も重要です。現在、多くの日本企業が高価な海外製ソリューションに依存しており、それがコストを圧迫しています。我々は、そうした高価なシステムから必要な機能だけを切り出す「オフロード」の受け皿となりたい。他の優れた国産ベンダーと連携し、安価で使いやすく、日本の商習慣に合ったソリューションを提供することで、日本企業全体のAI競争力を高めていく。それこそが、国産データインテグレーターとしての我々の使命だと考えています。</p>
<p>エンタープライズAIの戦場は、もはや最高のアルゴリズムを持つ者が制するのではない。そのアルゴリズムを動かす、混沌としたデータの流れを制する者が勝者となる。セゾンテクノロジーは、システムや部門、さらには企業の壁を越えてデータを「つなぐ」という長年磨き上げてきた技術を武器に、日本企業のデータ駆動型経営を根幹から支える中核的存在へと飛躍しようとしている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformerに代わる選択肢──ELYZA、日本語特化の拡散モデルベースのLLM「ELYZA-LLM-Diffusion」を商用利用可能な形で公開</title>
      <link>https://ledge.ai/articles/elyza_llm_diffusion_japanese_dllm_release</link>
      <description><![CDATA[<p>東京大学・松尾研究室から発足したAI開発企業の ELYZA は2026年1月16日、日本語に特化した拡散大規模言語モデル（dLLM）「ELYZA-LLM-Diffusion」シリーズを開発し、商用利用可能な形で<a href="https://prtimes.jp/main/html/rd/p/000000066.000047565.html">公開</a>した。</p>
<p>画像生成AIで発展してきた拡散モデルを言語生成に応用することで、従来主流のTransformerに代表される自己回帰型モデルとは異なる生成方式を採用。日本語の知識力や指示追従能力を高めつつ、効率的な推論を可能にする点を特徴としている。</p>
<h2>画像生成で培われた「拡散モデル」を言語生成へ</h2>
<p>拡散大規模言語モデル（Diffusion Large Language Model、dLLM）は、もともと画像生成分野で広く使われてきた拡散モデルを言語生成に応用したものだ。</p>
<p>自己回帰（Autoregressive）モデルがテキストを左から右へと逐次的に生成するのに対し、dLLMではテキスト全体にノイズを加え、そこから段階的にノイズを除去する「逆拡散過程」を通じて文章を生成する。</p>
<p>この方式では、設計次第で逐次生成を前提としない推論が可能となる。処理回数を抑えられるため、生成効率の向上や消費電力低減につながる可能性がある点が、dLLMの特徴とされている。一方で、学習コストの高さや推論基盤の成熟度といった課題も指摘されており、実利用はこれまで限定的だった。</p>
<h2>日本語データで追加学習、dLLMの日本語性能を強化</h2>
<p>今回ELYZAが開発した「ELYZA-LLM-Diffusion」は、HKU NLP Group が公開しているdLLM「Dream-v0-Instruct-7B」をベースに、日本語データによる追加事前学習と指示学習を施したモデルだ。</p>
<p>英語データ中心で学習された既存のdLLMが多い中、日本語に特化した知識力や指示追従能力の強化を狙った点が特徴となっている。</p>
<h2>日本語ベンチマークで既存dLLMと同等以上の性能</h2>
<p>ELYZAは本モデルの性能評価として、日本語タスクを中心とした複数のベンチマークを実施した。
一般的な日本語能力を測るタスクや、日本語MTベンチマーク、コーディング能力（JHumanEval）、数学タスク（MATH-500日本語版を含む）などで評価を行い、既存のオープンなdLLMと比較して同等、またはそれを上回る性能を示したとしている。</p>
<p>評価結果は、自己回帰型モデルとの直接的な優劣を示すものではなく、あくまでdLLMという枠組みの中での位置づけを示すものとされている。</p>
<p><strong>■ 日本語タスクを中心に実施したベンチマーク評価結果。ELYZA-Diffusion-Instruct-1.0-Dream-7Bは、既存のオープンな拡散言語モデルと比較して同等、またはそれを上回る性能を示したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8.webp" alt="47565-66-26607388b73b1b1ac71b2c88df8faeca-1329x830.webp" /></p>
<h2>自己回帰と拡散、生成プロセスの違いをデモで可視化</h2>
<p>ELYZAは、自己回帰モデルと拡散モデルの生成プロセスの違いを示すデモも公開している。
同一入力に対し、自己回帰モデルではトークンが順に確定していく一方、拡散モデルではテキスト全体が段階的に更新されていく様子を確認できる。
このデモは生成速度そのものを示すものではなく、生成方式の違いを直感的に理解するための技術的な可視化として位置づけられている。</p>
<p><strong>■ 自己回帰モデル（AutoRegressive、左）と拡散モデル（Diffusion、右）における文章生成プロセスの比較デモ。拡散モデルでは、テキスト全体が段階的に更新されていく様子を確認できる</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/file_48b854e8ad/file_48b854e8ad.gif" alt="file.gif" /></p>
<h2>Base／Instructの2モデルを公開、商用利用も想定</h2>
<p>今回公開されたモデルは以下の2種類だ。</p>
<ul>
<li><strong>ELYZA-Diffusion-Base-1.0-Dream-7B：</strong> 日本語データによる追加事前学習を行ったベースモデル</li>
<li><strong>ELYZA-Diffusion-Instruct-1.0-Dream-7B：</strong> Baseモデルに指示学習を施したモデル</li>
</ul>
<p>いずれもHugging Face上で公開されており、chatUI形式のデモも同時に提供されている。商用利用可能な形で公開されている点も、今回の発表の特徴の一つだ。</p>
<h2>電力消費増大という課題と、dLLM研究の狙い</h2>
<p>生成AIの利用拡大に伴い、電力消費の増大やAI向けデータセンター不足が国際的な課題となっている。
ELYZAは、dLLMが持つ「少ない処理回数で文章を生成できる」という特性に着目し、推論時間や電力消費を抑えられる可能性を持つアプローチとして研究を進めてきた。</p>
<p>今回の「ELYZA-LLM-Diffusion」は、自己回帰型が主流となっている言語モデルの設計に対し、別の選択肢を示す試みとして位置づけられる。</p>
]]></description>
      <pubDate>Thu, 22 Jan 2026 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>共通テスト2026、ChatGPT最新モデルが9科目満点──LifePrompt検証、精度の先で浮かぶ“弱点の質”</title>
      <link>https://ledge.ai/articles/common_test_2026_chatgpt_full_marks_9_subjects_lifeprompt_analysis</link>
      <description><![CDATA[<p>AIベンチャーのライフプロンプトは2026年1月20日、大学入学共通テスト（2026年度）の問題を複数の最新生成AIに解かせた検証結果を公式noteで<a href="https://note.com/lifeprompt/n/nb87edfb2e7ca">公開</a>した。OpenAIのGPT-5.2 Thinkingが、受験させた科目のうち9科目で満点を獲得したという。</p>
<p>同社は同一条件下で、Gemini 3 Pro、Claude Opus4.5 にも同テストを受験させ、得点だけでなく解答に要した時間や誤答の傾向まで比較した。ライフプロンプトが「AI vs 共通テスト」の年次検証を行うのは2023年からで、今回が4年目となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9.webp" alt="1768868571-lsp4EjCy6DWLX1rB8AcThYZb.webp" /></p>
<h2>共通テストを「そのまま解かせる」ための検証方法</h2>
<p>今回の検証では、人為的なコピペミスや恣意性を排除するため、共通テスト専用の自動受験システムを構築し、API経由で試験を実施した。</p>
<p>具体的には、共通テストの問題PDFをシステムに投入し、全ページを画像化すると同時にテキスト解析を行う。問題構造を自動判定したうえで大問ごとに分割し、各AIモデルにAPI経由で出題。AIが出力した自由記述の回答を、別のAIプロセスでマークシート形式に変換し、自動採点する仕組みだ。</p>
<p>例外措置として、英語リスニングは試験センターが公開している読み上げスクリプト（台本）をテキスト入力で使用した。また、国語の縦書き文章については、外部ツールで文字起こししたテキストを用いている。</p>
<p>今回比較したモデルは以下の3種だ。</p>
<ul>
<li>ChatGPT系列：GPT-5.2 Thinking</li>
<li>Gemini 3 Pro</li>
<li>Claude Opus 4.5</li>
</ul>
<h2>満点9科目、得点はGPT、速度はGeminiとClaude</h2>
<p>検証の結果、文系・理系いずれの合計点でもGPT-5.2 Thinkingが最も高得点を記録し、満点科目は9科目に達した。Gemini 3 ProとClaude Opus4.5 も900点台前半の高得点で続いた。</p>
<p>一方、解答に要した時間では明確な差が出た。GeminiとClaudeは約1時間40分前後で全科目を解き終えたのに対し、GPT-5.2 Thinkingは約5時間30分を要した。ライフプロンプトは、GPTが深い推論と検算を繰り返す「熟考型」であることが、高得点と引き換えに時間がかかった理由だとしている。</p>
<p>同社は、昨年の検証でAIが東京大学の合格水準に到達したと報告しており、今年は「合格できるかどうか」ではなく、「満点を取れるか」「どれだけ速く解けるか」といった次の段階に焦点を移したと位置付けている。</p>
<h2>なぜAIは間違えたのか──誤答に共通するパターン</h2>
<p>これほど高得点を記録したAIだが、3モデルすべてが共通して誤答した問題も存在した。ライフプロンプトは、誤答の傾向から現在の生成AIに残る課題が見えるとしている。</p>
<p>一つは図表やイラストの読み取りだ。英語リスニングの「バスの乗り方」を問う問題では、音声スクリプトの内容は正確に理解できていたものの、選択肢として示されたバスのイラスト（矢印の向き）を正しく判定できず、全モデルが誤答した。</p>
<p>次に挙げられるのが、国語（小説）の心情理解である。主人公が現状を正当化しようとしつつも割り切れない思いを抱える場面で、正解は「現状への妥協」を示す選択肢だったが、AIはいずれも「過去の過ちへの反省」を選んだ。ライフプロンプトは、一般論的な道徳観に引き寄せられ、人間特有の曖昧な感情を読み違えたと分析している。</p>
<p>さらに、地理などの視覚情報も弱点として浮かび上がった。色の濃淡で分布を示した地図問題では、ヒートマップの微妙な違いを識別できず、全モデルが誤答した。</p>
<h2>それでも差は出た──Geminiだけが正解した問題</h2>
<p>一方で、すべての問題で同じ結果になったわけではない。地理の別問題では、Gemini 3 Proのみが地図上の地形（アンデス山脈）と気候グラフを正しく結びつけ、唯一正解したケースもあった。</p>
<p>ライフプロンプトは、GPT-5.2 ThinkingやClaudeが画像を「文字情報の集合」として処理しようとする傾向があるのに対し、Geminiは画像を視覚情報として捉える能力が強く、地図やグラフの相関関係を直感的に把握できたと説明している。</p>
<h2>「AI入試挑戦」を巡る論点の変化</h2>
<p>同社はこれまで、毎年のように生成AIが入試に挑戦する検証を取り上げてきた。2024年頃は、共通テストでどのモデルが最も高得点を取るのか、人間の合格水準にどこまで迫ったのかが主な関心事だった。</p>
<p>2025年には、共通テストに加えて東大二次試験なども対象とした検証が登場し、「難関大学に通用する水準かどうか」が焦点となった。そして2026年の今回、論点はさらに一段階進み、満点科目の数、解答速度、誤答の質へと移っている。</p>
<p>AIが「解けるかどうか」ではなく、「どこで、なぜ落とすのか」が具体的に示される段階に入ったことを、今回の検証は示している。</p>
<p>共通テストで9科目満点という結果は、生成AIの推論能力が標準化試験レベルでは極めて高い水準に到達したことを示す。一方で、図表の読み取りや感情理解といった領域では、人間とは異なるつまずき方をすることも明らかになった。</p>
<p>今後も同社は同様の検証を続けるとしており、AIが入試問題を通じてどのように進化していくのかは、引き続き注目される。</p>
]]></description>
      <pubDate>Thu, 22 Jan 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>