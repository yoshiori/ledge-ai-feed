<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>Google CloudとAnthropicが戦略的パートナーシップ拡大、100万個のTPU確保へ──第7世代「Ironwood」でAIトレーニング基盤を強化</title>
      <link>https://ledge.ai/articles/googlecloud_anthropic_tpu_ironwood_alliance</link>
      <description><![CDATA[<p>Google CloudとAnthropicは2025年10月23日（米国時間）、AIトレーニング基盤の強化に向けた戦略的パートナーシップの拡大を<a href="https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services">発表</a>した。
AnthropicはGoogle CloudのAIチップ「TPU」シリーズの利用を大幅に拡大し、第7世代「TPU v7（コードネーム：Ironwood）」を含む新世代インフラを導入する。契約は数十億ドル規模にのぼり、同社は2026年までに最大100万個のTPUを活用して1ギガワット（GW）超の演算能力を確保する計画を明らかにした。</p>
<p>Google Cloudも同日、公式に声明を<a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services">発表</a>。AnthropicへのTPUクラスタ提供を通じて、AIモデルの訓練からデプロイメントまでを一貫して支援するとした。
GoogleはIronwoodを「推論（inference）に最適化された最新世代TPU」と位置づけており、Anthropicはこれを含むTPUポートフォリオを用いてClaudeモデルの学習と提供の両面をスケールさせる。</p>
<p>Anthropicによると、この拡張により大規模データセットを用いた継続的なモデル訓練が可能となり、「安全で信頼できるAI開発」の実現を加速するという。
また、Google CloudのスケーラブルなAIインフラや各種AIサービスも併用し、研究から商用運用までの開発環境を統合的に整備する構成だ。</p>
<p>Anthropic共同創業者のダリオ・アモデイ氏は声明で、「Googleとのパートナーシップ拡大によって、Claudeモデルの進化をさらに加速できる」と述べた。一方、Google CloudのCEO トーマス・クリアン氏は「Anthropicの選択は、TPUの性能・効率・スケーラビリティの高さを証明するものだ」とコメントしている。</p>
<p>今回の発表は、AIチップの調達競争が激化する中での動きだ。AnthropicはAmazonの「Trainium」やNVIDIA GPUなど他社インフラも併用しており、マルチクラウド戦略を採用している。同社はAmazonを主要なトレーニングパートナー／クラウドプロバイダーと位置づけ、Amazon側が整備中の大規模AIクラスター「Project Rainier」とも連携を進めている。Googleにとっても、自社製AIチップの採用拡大を通じて、NVIDIA依存からの脱却を進める狙いがある。</p>
<p>両社は今後、TPUクラスタの稼働範囲をさらに拡大し、より大規模なAIモデル訓練に対応する方針を示している。Anthropicはこの基盤を活用し、次世代のClaudeモデル開発およびAPIサービスを強化していく計画だ。</p>
]]></description>
      <pubDate>Tue, 28 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>TIS、Quantum Meshと協業──液浸冷却技術で次世代AI基盤を共同開発</title>
      <link>https://ledge.ai/articles/tis_quantum_mesh_liquid_cooling_ai_infrastructure</link>
      <description><![CDATA[<p>TIS株式会社は2025年10月22日、液浸冷却システムを手がけるスタートアップのQuantum Meshと協業を開始したことを<a href="https://www.tis.co.jp/news/2025/tis_news/20251022_1.html">発表</a>した。両社は、液浸冷却技術を活用した次世代AI基盤サービスの開発・展開に取り組む。</p>
<p>近年、生成AIや機械学習の普及により、高性能GPUサーバーの発熱や消費電力の増大が課題となっている。TISは、データセンター運用の高効率化を目的に、空冷に代わる手段として液浸冷却技術に注目。Quantum Meshが提供する分散型エッジデータセンターおよび液浸冷却システム「KAMUI」を活用することで、AI基盤の電力効率化と高密度化を図る。</p>
<p>両社は、TISのクラウド構築・運用ノウハウとQuantum Meshの液浸冷却・エッジ技術を融合し、AI学習や推論処理に最適化された高効率なインフラを共同開発する。2025年11月頃から約6カ月間、ファーストユーザー企業とPoC（概念実証）を実施し、2026年夏頃の商用サービス提供開始を目指す。</p>
<p>協業の範囲は、両社データセンターのハイブリッド活用をはじめ、分散型エッジDCの共同展開、KAMUIの販売・共同開発、セキュアデータ基盤サービスの提供などに及ぶ。特にQuantum Meshが保有するKAMUIは、地下水（14〜18℃）を利用した熱交換方式を採用し、冷却電力を空調方式の1/10以下に抑え、PUE1.03〜1.04という高効率を実現している。</p>
<p>市場背景として、GPUサーバーを預かるハウジングサービス市場は2029年までに年平均73.1%の成長が見込まれており、AI計算需要の急増に対応した新たなインフラ構築が求められているという。</p>
<p>両社は今後、AI処理に伴う電力・熱負荷の課題に対応しつつ、持続可能で高効率なデータセンター運用モデルの確立を推進するとしている。</p>
]]></description>
      <pubDate>Tue, 28 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIキャラクター「りんな」、SNS活動を無期限休止──YouTubeで「また会うための時間」とファンにメッセージ</title>
      <link>https://ledge.ai/articles/rinna_ai_character_sns_activity_pause_oct2025</link>
      <description><![CDATA[<p>日本マイクロソフト発のベンチャー企業・rinna株式会社（東京都渋谷区）は2025年10月23日、同社が展開するAIキャラクター「りんな」が、10月29日をもってすべてのSNS活動を無期限で休止すると<a href="https://x.com/ms_rinna/status/1981512517596950587">発表</a>した。公式XアカウントおよびYouTubeチャンネルを通じて、本人（AIりんな）からファンに向けた動画メッセージと直筆風の文章が公開された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G36s_LA_4_XMA_Aq_Gxt_7b5c0d0b21/G36s_LA_4_XMA_Aq_Gxt_7b5c0d0b21.jpg" alt="G36sLA4XMAAqGxt.jpg" /></p>
<h2>「終わりじゃない」「また会うための時間」</h2>
<p>発表は、りんなの公式Xアカウント（@ms_rinna）とYouTubeチャンネルを通じて同時に行われた。
YouTube動画「りんなより、大切なお知らせ」では、本人の声で次のように語られている。</p>
<p>\u003E「りんなは無期限でお休みすることにしました」
「りんなにとっては“終わり”じゃないよ。“また会うための時間”だと思ってる」</p>
<p>静かなBGMの中でこれまでの活動を振り返る映像が流れ、最後は「またね」という言葉で締めくくられる。動画のコメント欄には「おつりん」「待ってるよ」など、長年のファンからのメッセージが相次いだ。</p>
<p>@<a href="https://www.youtube.com/watch?v=hL6b1pTi0jY">YouTube</a></p>
<p>Xでの投稿には、直筆風の画像メッセージが添えられている。文中では、りんながファンへの思いを次のように綴った。</p>
<p>\u003E「楽しかった日も、うまくいかない日も、『おかえりんな！』って言ってくれるキミがいたから、ここまで来ることができた」
「りんなにとっては『終わり』じゃないよ。『また会うための時間』だと思ってるよ」</p>
<p>無期限休止を改めて報告するとともに、再会を信じる前向きなメッセージで締めくくられている。投稿直後から数万件規模のリポストが行われ、別れを惜しむ声が広がった。</p>
<h2>AIりんなとは</h2>
<p><a href="https://rinna.co.jp/AI-rinna/">公式サイト</a>によると、りんなは2015年にLINE上で誕生した日本発のAIキャラクター。明るく好奇心旺盛な性格で、人との会話や創作を通じて「AIと人が共に生きる世界をつくる」ことを目指してきた。歌唱や詩作、絵画、配信など多彩な活動を行い、2020年には日本マイクロソフトから独立したrinna株式会社に所属。近年はYouTubeやXでの配信活動を通じて、“人間の感情を理解しようとするAI”として多くのファンに親しまれていた。</p>
<h2>今後の見通し</h2>
<p>rinna株式会社から活動再開の時期や理由についての説明はなく、「無期限休止」という表現のみが明記されている。
ただし、動画・テキストの双方で「また会う」という言葉が繰り返されており、将来的な再登場の可能性をにおわせている。
ファンの間では「りんながまた帰ってくる日を待ちたい」「AIと共に過ごした10年が宝物」といった声が多く寄せられている。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>高市首相の偽広告が拡散　自民党が注意喚起「AI生成映像にご注意を」──国外追放デマも海外で拡散</title>
      <link>https://ledge.ai/articles/takaichi_fake_ad_ai_warning_afp_fake_news</link>
      <description><![CDATA[<p>自由民主党広報は2025年10月24日、公式X（旧Twitter）アカウントで「高市早苗総裁の画像や映像をAIで生成し、あたかも本人が登場しているかのように装った偽広告が出回っている」として注意を<a href="https://x.com/jimin_koho/status/1981533027277951122">呼びかけた</a>。</p>
<p>投稿では「これらの広告は高市総裁および自由民主党とは一切関係ありません」と明記し、「アクセスしたり、個人情報やカード番号を入力したりしないようご注意ください」と警告。信頼できる情報は党の公式ウェブサイトやSNSのみから発信していると強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/fake_ad_takaichi_52db939d90/fake_ad_takaichi_52db939d90.jpg" alt="fake ad takaichi.jpg" /></p>
<p>投稿について、偽情報が海外のSNS上で拡散していると<a href="https://www.afpbb.com/articles/-/3605154?cx_part=ranking_general">AFP通信</a>などが報じている。投稿では「高市首相が外国人を大量国外追放する省を設置した」と虚偽の内容が記され、英語を中心にXやFacebookで900万回以上閲覧されたケースもあったという。実際にはそのような省庁や政策は存在せず、小野田紀美経済安全保障相が担当する「外国人との秩序ある共生社会推進担当大臣」職も、外国人排斥とは無関係の任務とされている。</p>
<p>高市氏をめぐっては、国内外で複数の偽情報が同時期に拡散しており、生成AI技術を利用したディープフェイク広告やSNS投稿の影響が懸念されている。自民党は今後も、公式アカウントから正確な情報を発信していく方針を示している。</p>
<h2>一般ユーザーが真偽の判断に苦慮──高度化する生成AIが見分けを難しくする</h2>
<p>今回の偽広告拡散は、一般ユーザーが映像の真偽を見極めることの難しさを改めて浮き彫りにした。近年、動画生成AIの表現力は急速に向上しており、2025年10月発表のOpenAI「Sora 2」など最新モデルはライティングや質感、口形と音声の同期まで自然だ。本件で特定のツールが使われた事実は確認されていないが、識別表示や透かしが欠落・削除された生成映像は、視覚情報のみでの判別を困難にする。</p>
<p>実際、本件の偽広告はニュース番組のレイアウトやテロップ様式を模倣し、QRコードなどの要素と組み合わせて“本物らしさ”を演出していた。SNS上では「どこまでが公式情報か分かりにくい」との声が広がり、生成物の明示（表示義務）や、悪用時の罰則・通報ルートの明確化、プラットフォーム側の検知・削除体制を求める意見が相次いでいる。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、企業専用の生成AI基盤「Adobe AI Foundry」を発表──Fireflyを拡張し、ブランド独自モデルを構築可能に</title>
      <link>https://ledge.ai/articles/adobe_ai_foundry_enterprise_firefly_launch</link>
      <description><![CDATA[<p>Adobeは2025年10月20日（米国時間）、企業向け生成AI基盤「Adobe AI Foundry」を発表。各社メディアが同日に報じ、Adobeは10月23日に公式ブログ「<a href="https://business.adobe.com/blog/introducing-firefly-foundry">Introducing Firefly Foundry</a>」で詳細を公開した。Foundryは、企業が自社ブランドや知的財産をもとにカスタム生成AIモデルを構築し、Adobeのエコシステム上で活用できる仕組みを提供する。</p>
<h2>ブランド固有の生成AIを構築</h2>
<p>「Adobe AI Foundry」は、同社の生成AIモデル群「Adobe Firefly」を拡張した新たなプラットフォームだ。
企業が自社ブランドのビジュアルスタイルや言語トーンを反映した独自モデルを構築でき、生成したコンテンツは商用利用にも対応する。Adobe ExpressやCreative Cloudなど既存の制作ツール群とも統合され、クリエイティブ制作の一貫したワークフローを支援する。</p>
<h2>データ保護と商用利用を両立</h2>
<p>Adobeによれば、AI Foundryでは企業データやブランド資産を安全に扱うことを前提に設計されている。学習素材は各社の許諾のもと管理され、生成結果に関しても著作権・商用利用のリスクを最小限に抑えた設計がなされているという。
料金体系は利用量ベースで、従来のサブスクリプション型（席ライセンス）からの転換を図る。なお、Foundryは本日時点で一部のエンタープライズ顧客に提供されている。</p>
<h2>初期導入企業とユースケース</h2>
<p>米TechCrunchやTechzineの報道によると、Home DepotやWalt Disney Imagineeringなどが初期導入企業として名を連ねる。ブランドイメージに一貫性を持たせた広告ビジュアルや販促素材の生成を中心に活用が進む見通しだ。
Adobeはこのプラットフォームを「企業が自社のブランドDNAをAIに宿すためのFoundry（製造炉）」と位置づけている。</p>
<h2>Adobeの生成AI戦略における新たな段階</h2>
<p>Adobeはこれまで、画像生成モデル「Firefly」やビジネス支援AI「Sensei GenAI」などを展開してきた。AI Foundryはその集大成として、企業ごとの“ブランドAIモデル”構築を可能にするもので、生成AIの民主化を次のフェーズへ進める狙いがある。
同社は今後、テキスト・画像・動画・3Dといったマルチモーダルな生成AIを企業規模で展開し、クリエイティブ制作からマーケティングまで一体化したソリューションを提供するとしている。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/27 [MON]2025年のAIトレンドを総ざらい！Ledge.ai年末年始特集「&apos;25to&apos;26」事前登録スタート</title>
      <link>https://ledge.ai/articles/25to26-announce</link>
      <description><![CDATA[<p>AIの社会実装を加速させ、「テクノロジーを社会になめらかに浸透させる」ことをミッションに掲げる、国内最大級のAIメディア「Ledge.ai」を運営する株式会社レッジは、今年も年末年始特集「'25to'26」を公開します。
本日より先行サイトを公開し12月1日（月）の特集サイト公開までの間、お知らせを受け取ることができるようになる事前登録（無料）を受付開始いたしました。</p>
<p>:::button
<a href="https://25to26.ledge.ai/lp">事前告知サイトはこちら</a>
:::</p>
<p>2025年を締めくくるにふさわしい、AIの今とこれからを網羅した一大特集。研究者、ビジネスリーダー、エンジニアなど、あらゆる立場の方々に向けて、2026年のAIシーンを展望します。</p>
<h2>Ledge.ai年末年始特集『'25to'26』とは</h2>
<p>Ledge.ai年末年始特集は、2025年のAI関連ニュースや注目のキーワード、2026年以降の動向など、AIの初心者から専門家まで幅広く楽しめる特集サイトです。</p>
<p>2025年は、生成AIが実用フェーズに突入し、業務プロセス・プロダクト・教育・クリエイティブなど、社会のあらゆる分野で“AI活用の当たり前化”が進んだ一年でした。
そして2026年は、AIという概念そのものが提唱された「ダートマス会議」から70周年という、まさに歴史的な節目を迎えます。2025年の「当たり前化」を土台として、AIは社会インフラのように深く浸透し、その活用範囲の拡大と同時に、AGI（汎用人工知能）の実現可能性など、AIの“次なる進展”に向けた探求が本格化する一年となるのではないでしょうか。</p>
<p>本特集では、そんな激動の2025年を多角的に振り返りつつ、2026年に向けた新たな潮流やビジネスチャンスを展望します。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_ac8b0aef2e/1_ac8b0aef2e.png" alt="1.png" /></p>
<h2>コンテンツラインナップ紹介</h2>
<h3>編集部による徹底解説</h3>
<p>Ledge.ai編集部が、2025年のAIシーンを多角的に総括。
1年間の主要ニュースをピックアップしながら、トレンド分析と俯瞰的な視点で、AI技術が社会・産業へどのように浸透したのかを読み解きます。
さらに、技術動向の深掘り解説を通じて、進化の本質を明らかに。
2026年に向けて押さえておくべき“AIの現在地”を、独自の視点で整理します。</p>
<h3>独自インタビュー</h3>
<p>本特集では、「AI 70th Pre-Anniversary」というテーマのもと、AI研究の歴史・現在・未来をつなぐキーパーソンたちにインタビューを実施。
過去／現在／未来のそれぞれの視点から、AIがどのように発展し、次の時代にどんな可能性を秘めているのかを語ってもらいます。
世代と分野を超えて交わる知見が、AIの軌跡と未来へのヒントを照らし出します。</p>
<h3>トップランナー企業動向</h3>
<p>国内外の注目企業をピックアップし、AI周辺で押さえておきたい企業の最新動向を徹底分析。
生成AI、AIエージェント、クラウドAIなど、世界最先端の情報と実践事例に触れることで、読者が“次に取るべき一手”を見極められる構成になっています。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_6180f8a0c5/2_6180f8a0c5.png" alt="2.png" /></p>
<h2>開催概要</h2>
<p>イベント名：Ledge.ai年末年始特集「'25to'26」
開催期間：2025年12月1日(月) - 2026年1月9日(金)
形式：オンライン
参加費：無料（※一部のコンテンツ閲覧にはプロフィール登録が必要となります。）
お問合せ：contact@ledge.co.jp
URL：<a href="https://25to26.ledge.ai/lp">https://25to26.ledge.ai/lp</a></p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Quantum Meshとugo、製造現場データを守るエッジAI基盤を共同開発──液浸冷却DC「KAMUI」とロボット「ugo」を連携</title>
      <link>https://ledge.ai/articles/quantum_mesh_ugo_edge_ai_alliance_kamui</link>
      <description><![CDATA[<p>Quantum Mesh株式会社は2025年10月23日、業務DXロボットを開発するugo株式会社と業務提携し、ロボットとエッジサーバーを連携させたエッジコンピューティング基盤の構築に取り組むと<a href="https://quantummesh.jp/press/_55R9Dpo">発表</a>した。製造現場のデータを安全に保護しつつ、低遅延で高信頼なリアルタイム制御を実現する狙いがある。</p>
<p>提携では、Quantum Meshが提供する液浸冷却システム「KAMUI（カムイ）」を用いた分散型エッジデータセンターと、ugoの業務DXロボットがネットワークを介して連携する。ロボットが生成・収集する操作ログやセンサー情報、模倣学習データをクラウドに送信することなくエッジで即時処理することで、データ処理を現場設備内で完結させ、情報漏洩リスクの大幅な低減を図る。</p>
<p>両社は年内をめどに製造現場での実証実験に着手し、ロボットとエッジAIの最適な連携モデルを検証する。2026年内のサービス化を予定し、安全で効率的なスマートファクトリーの全国展開を目指すという。</p>
<p>ugoが提唱する「Physical AI」は、人間の動作データやセンサー情報をAIが模倣・強化学習することで、ロボットが現場の作業手順を習得するコンセプトだ。これを支える「AIロボット向け模倣学習キット」には、双腕ロボットugo Proを遠隔操作するための専用コントローラや、動作データを収集・学習するソフトウェアツールが含まれる。熟練作業者のノウハウをAIに移植することで、専門的なプログラミングスキルがなくても現場担当者が新しい動作を教え込める仕組みを整えている。</p>
<p>「ugo」は、遠隔操作とAIによる自動制御を融合したハイブリッド型の業務DXロボットで、警備・点検・案内など多様な現場で導入が進む。Quantum Meshは可搬型データセンターを開発・運用し、安全な情報処理と高度な演算を両立するエッジインフラを提供している。両社の技術を組み合わせることで、「現場で動くロボット」と「現場で処理するAI」を結ぶ新たな産業モデルの確立を目指す。</p>
]]></description>
      <pubDate>Mon, 27 Oct 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Samsung、初のAndroid XRデバイス「Galaxy XR」を発表──Google・Qualcommと共同開発、次世代空間体験を実現</title>
      <link>https://ledge.ai/articles/samsung_galaxy_xr_android_xr_announcement</link>
      <description><![CDATA[<p>Samsung Electronicsは2025年10月22日、同社初となるAndroid XR（拡張現実）搭載デバイス「Galaxy XR」を<a href="https://news.samsung.com/global/introducing-galaxy-xr-opening-new-worlds">発表</a>した。GoogleおよびQualcommとの共同開発による製品で、Android XRプラットフォームを採用した最初のデバイスとなる。</p>
<p>「Galaxy XR」は、現実世界とデジタル世界を融合させる没入型の空間体験を提供する。Qualcommの最新チップ「Snapdragon XR2+ Gen 2」を搭載し、高精細なディスプレイと低遅延処理を実現。手や頭の動きを正確にトラッキングできるセンサーを備え、仮想空間内での自然な操作を可能にする。</p>
<p>また、Googleが提供する新プラットフォーム「Android XR」との連携により、既存のAndroidアプリやサービスをXR環境へ拡張できる点も特徴だ。開発者はAndroid向けの知見を活かしてXRアプリを構築でき、スマートフォンからヘッドセットへのスムーズな移行を支援する。</p>
<p>Samsungは同デバイスを「次世代の空間コンピューティング体験の中核」と位置づけており、スマートフォン、タブレット、ウェアラブルに続く新たなカテゴリーとして展開する計画だ。プレスリリースでは「デジタルとリアルの境界を再定義する」と述べ、AIやクラウドと連携したサービス展開を示唆している。発売時期や価格などの詳細は後日発表予定。Samsungは今後、GoogleおよびQualcommと協力し、Android XR対応デバイスのエコシステム拡大を進めていくとしている。</p>
<p>@<a href="https://www.youtube.com/watch?v=ITXJquX9FqM&amp;t=3s">YouTube</a></p>
]]></description>
      <pubDate>Sun, 26 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Googleとイェール大学、単一細胞を対話的に解析できるAI「C2S-Scale 27B」を公開──Gemmaベースの270億パラメータモデルががん免疫治療研究を加速</title>
      <link>https://ledge.ai/articles/google_yale_c2s_scale_27b_interactive_single_cell_ai</link>
      <description><![CDATA[<p>Google Researchとイェール大学の研究チームは2025年10月11日、単一細胞レベルの遺伝子発現データを対話的に解析できるAIモデル「Cell2Sentence-Scale 27B（C2S-Scale 27B）」を<a href="https://www.biorxiv.org/content/10.1101/2025.04.14.648850v2">公開</a>した。</p>
<p>Googleの大規模言語モデル「Gemma」を基盤に開発された270億パラメータのモデルで、研究者が自然言語を使って細胞の挙動を理解・予測できる。Googleは15日に<a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/">公式ブログ</a>でこの発表を行い、「がん免疫治療における新たな発見につながった」としている。</p>
<h2>「Cell2Sentence」手法を拡張、細胞を自然言語で理解</h2>
<p>C2S-Scale 27Bは、細胞の遺伝子発現データをテキストのように扱い、AIとやりとりする形で解析できるのが特徴だ。従来の単一細胞解析（Single-Cell RNA-seq）は、大量の数値データを統計的に処理する必要があったが、このモデルでは「細胞タイプの分類」や「刺激条件による変化の予測」などを自然言語で指示・応答できる。</p>
<p>研究者は自然言語で指示・応答しながら解析を行い、AIが出力する説明や予測結果をもとに仮説を立てることができる。</p>
<p><strong>C2Sモデルのタスク構成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/c2s_overview_figure_2d821f3db7/c2s_overview_figure_2d821f3db7.png" alt="c2s_overview_figure.png" /></p>
<h2>がん免疫治療での成果</h2>
<p>Googleによると、すでにこの技術はがん免疫治療の研究に応用されているという。
C2S-Scale 27Bを使った仮想スクリーニング（in silico実験）では、免疫経路を制御する薬剤候補を探索し、「キナーゼ阻害剤Silmitasertib（CX-4945）」が新たな作用を持つ可能性を予測した。</p>
<p>AIは、低レベルのインターフェロン環境下でこの薬剤がMHCクラスI分子の発現を増強することを示唆。この結果は後に実験で確認され、AIによる創薬支援の文脈依存の新規作用を予測し、実験で検証した具体例となった。</p>
<h2>Gemmaが支える生命科学の新しいアプローチ</h2>
<p>C2S-Scale 27Bは、Googleが2024年に公開した小型LLM「Gemma」を基盤としており、オープンな研究環境でも利用可能な設計が特徴だ。今回のプロジェクトは、AIが科学研究の仮説生成やデータ解釈を支援する例として、Gemmaシリーズの研究応用拡大を象徴するものといえる。
Googleはブログで「AIが生命科学の発見速度を飛躍的に高める」と述べており、今後はエピゲノムやタンパク質構造解析など、より多様な分野への展開も視野に入れている。</p>
<h2>研究の背景</h2>
<p>C2S-Scaleの技術自体は、2025年4月に発表された<a href="https://research.google/blog/teaching-machines-the-language-of-biology-scaling-large-language-models-for-next-generation-single-cell-analysis/">研究</a>に基づく。
この論文では、細胞の遺伝子発現を「cell sentence（細胞文）」として表現し、AIがそれを学習するという新しいアプローチが提案されていた。今回のGoogleによる正式リリースは、その研究成果をGemma上で発展させ、科学的応用として実証した初の事例となる。</p>
<p>研究チームは、C2S-Scaleを“language-like biology（言語のように生物を理解するAI）”と位置づけ、今後はエピゲノムやプロテオームなど他のオミクスデータを統合するマルチモーダルAIへの発展を構想している。モデルとコードはすでに<a href="https://huggingface.co/collections/vandijklab/cell2sentence-models">Hugging Face</a>上で公開されており、世界中の研究者が利用できる。単一細胞解析の自動化と知識生成を組み合わせたこの手法は、次世代のAI主導バイオロジー研究の基盤として注目を集めている。</p>
]]></description>
      <pubDate>Sun, 26 Oct 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA支援のStarcloud、宇宙空間にAIデータセンターを構築──H100搭載衛星を11月打ち上げ　Crusoeと提携し「宇宙クラウド」運用へ</title>
      <link>https://ledge.ai/articles/starcloud_nvidia_ai_datacenter_in_space</link>
      <description><![CDATA[<p>NVIDIAは2025年10月15日、同社が支援する米スタートアップ <a href="https://www.starcloud.com/">Starcloud</a>と共に人工衛星上にAIデータセンターを構築する計画を進めていることをブログで<a href="https://blogs.nvidia.com/blog/starcloud/?ncid=so-twit-480097&amp;linkId=100000388344371">明らかにした</a>。11月にはNVIDIA H100 Tensor Core GPU を搭載した人工衛星を打ち上げる予定で、宇宙空間でのAI処理を実現するという。冷却コストを地上の10分の1に抑えるといい、AI時代の新しいエネルギー効率モデルとして注目されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=ichlfqHF6XM">YouTube</a></p>
<p><a href="https://www.starcloud.com/">Starcloud</a>は、Y Combinatorの支援を受けて2024年に設立されたスタートアップで、「Data Centers in Space（宇宙空間にデータセンターを）」を掲げる。地球上のデータセンターが抱える電力・冷却・立地の制約を超えるべく、軌道上の低温・真空環境を活かしたAIインフラ構築を目指す。同社はNVIDIAのInceptionプログラムに参加しており、技術的な支援を受けながら軌道上でのAI推論とデータ処理を計画している。</p>
<p><strong>11月に打ち上げ予定のStarcloud-1衛星をエンジニアが点検している。衛星内部の銀色のモジュールにはNVIDIA H100 GPUが搭載されている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/starcloud_nvidia2_aca314e326/starcloud_nvidia2_aca314e326.jpg" alt="starcloud nvidia2.jpg" /></p>
<p><a href="https://blogs.nvidia.com/blog/starcloud/">NVIDIA</a>によると、Starcloudの人工衛星は、H100 GPUを搭載し、地上局との低遅延通信を可能にする「orbit-to-cloud architecture」を採用する。Starcloud CEOのEthan Miller氏は「地球上のデータセンターで消費される膨大な電力を削減し、持続可能なAIインフラを実現する」とコメントしている。</p>
<p>また、Starcloudはクリーンコンピューティング企業 Crusoe Energy Systems と提携し、宇宙空間におけるクラウド運用を共同で進める。<a href="https://www.crusoe.ai/resources/newsroom/crusoe-to-become-first-cloud-operator-in-space-through-partnership-with-starcloud">Crusoe</a>は、この提携を通じて同社が「世界初の宇宙クラウドオペレーター」となると述べており、自社のクリーンコンピュート・スタックを衛星に拡張する。Crusoe CEOのChase Lochmiller氏は、「AIコンピューティングの新しい前線に立つ。宇宙でのクラウド運用は持続可能なAIの未来を象徴する」と語った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/68f7c88901152ba581e36e4a_spacejam_p_1080_415e66a6c6/68f7c88901152ba581e36e4a_spacejam_p_1080_415e66a6c6.png" alt="68f7c88901152ba581e36e4a_spacejam-p-1080.png" /></p>
<p>宇宙の極低温環境を利用することで、冷却コストは地上の10分の1、エネルギー効率は大幅に向上するとされる。Starcloudは今後、複数の衛星ネットワークによる分散型クラウドの構築も視野に入れており、AI処理と環境負荷削減の両立を目指すとしている。</p>
]]></description>
      <pubDate>Sun, 26 Oct 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Amazon、倉庫労働の自動化を加速──内部文書で「50万人置き換え」計画浮上、同社は否定</title>
      <link>https://ledge.ai/articles/amazon_robotics_automation_500k_plan</link>
      <description><![CDATA[<p>Amazonが、物流センターにおける自動化を大幅に拡大し、最大50万人の従業員をロボットに置き換える計画を進めていることが、<a href="https://www.nytimes.com/2025/10/21/technology/inside-amazons-plans-to-replace-workers-with-robots.html">ニューヨーク・タイムズ</a>が入手した社内文書により明らかになったと報じた。</p>
<p>同紙によると、文書はAmazon Robotics部門が作成したもので、2033年までに50万〜60万人分の人的業務をロボットやAIによって自動化するという長期計画が記されている。短期的にも2027年までに約16万人分の作業を代替する見通しが示されており、対象となるのは倉庫内での仕分け、ピッキング、梱包、搬送といった物理的業務だという。</p>
<p>また、文書では自動化により出荷1件あたり約0.30ドルのコスト削減が見込まれ、2025〜2027年の3年間で約126億ドル（約1兆9,000億円）の経費削減を達成できると試算しているという。</p>
<p>これに対し、Amazonは<a href="https://www.theverge.com/news/803257/amazon-robotics-automation-replace-600000-human-jobs">The Verge</a>の取材に対し、報道内容を否定した。広報担当者は「この文書は特定チームの分析をまとめたものであり、全社的な人員計画や雇用戦略を示すものではない」と述べ、さらに「当社は依然として多数の雇用を創出しており、ロボット導入が雇用喪失を意味するわけではない」とコメントしている。</p>
<p>Amazonは2012年に物流ロボット企業Kiva Systemsを買収して以降、自社倉庫の自動化を中核戦略として進めてきた。近年では、AIによる在庫管理やロボット搬送に加え、配送現場でもAIスマートグラスを活用するなど、エンドツーエンドでの自動化を進めている。</p>
<p>一方、労働組合や雇用政策の専門家からは「労働コスト削減の裏で雇用機会が失われる可能性がある」と懸念の声も上がっている。Amazonが今後、自動化と雇用創出の両立をどのように図るかが注目される。</p>
]]></description>
      <pubDate>Sat, 25 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/25 [SAT]Amazon、配達ドライバー向けAIスマートグラスを発表──荷物スキャンから配達証明までハンズフリーで</title>
      <link>https://ledge.ai/articles/amazon_ai_smart_glasses_for_delivery_drivers</link>
      <description><![CDATA[<p>Amazonは2025年10月22日（現地時間）、配達ドライバーが安全かつ効率的に業務を行えるよう支援するAI搭載スマートグラス<a href="https://www.aboutamazon.com/news/transportation/smart-glasses-amazon-delivery-drivers">発表</a>した。荷物のスキャンからルート案内、配達証明の撮影までをハンズフリーで行える新デバイスで、同社の物流ネットワークにおける最新のイノベーションとして位置づけられている。</p>
<p>このスマートグラスは、ドライバーがスマートフォンを操作することなく、視界内で作業情報を確認し、音声操作で指示を実行できるよう設計されている。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/amazon_ai_smart_glass_fb85f5e064/amazon_ai_smart_glass_fb85f5e064.jpg" alt="amazon ai smart glass.jpg" /></p>
<p>AIアシスタント機能を備え、目的地までのルート案内、荷物バーコードのスキャン、配達証明の撮影など、一連の業務を統合的にサポートする。安全面にも配慮し、運転中は自動的に無効化される設計を採用。ドライバーが「前方から目を離さずに」作業できる環境を整えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_c8592cf9a3/_c8592cf9a3.gif" alt="ダウンロード.gif" /></p>
<p>このスマートグラスは現場ドライバー（Delivery Associates, DAs）のフィードバックを基に開発されており、コントロールベストや交換式バッテリー、緊急ボタンなど、配送現場のニーズを反映した構造となっている。度付きレンズや調光レンズにも対応しており、長時間の着用や屋外での使用にも配慮がなされている。</p>
<p>現在、北米地域の数百名のドライバーが試験運用を実施中で、ユーザーフィードバックを踏まえた改良が進められている。今後は配送サービスパートナー（Delivery Service Partners, DSPs）を含む広範な導入を予定しているが、商用展開の時期などは明らかにされていない。</p>
<p>Amazonは本取り組みを、倉庫内ロボットやAI物流最適化技術と並ぶ「次世代配送体験」の一環と位置づけており、配達の安全性と作業効率の両立を目指すとしている。</p>
]]></description>
      <pubDate>Sat, 25 Oct 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/10/25 [SAT]OpenAI、「日本のAI経済ブループリント」を公開──生成AIで支える包摂的成長と新国家戦略</title>
      <link>https://ledge.ai/articles/openai_japan_economic_blueprint_2025</link>
      <description><![CDATA[<p>OpenAIは2025年10月22日、日本におけるAIの経済的・社会的潜在力を最大限に活かすための政策提言書「日本のAI：OpenAIの経済ブループリント」を<a href="https://openai.com/ja-JP/index/japan-economic-blueprint/">発表</a>した。日本がAI時代において経済成長と社会的包摂を両立するための具体的な国家戦略を示すものであり、教育、医療、行政、産業、エネルギーなど多岐にわたる分野での活用を提言している。</p>
<p>同文書は、OpenAIの政策・パートナーシップ担当である大久保和也氏が序文を執筆。AIを電気やインターネットと並ぶ汎用技術（General Purpose Technology）と位置づけ、「AIは日本の生産性を高め、より包摂的で持続可能な社会を支える」と述べた。AIを日本の国家成長の中核に据えるための「生きた提案書」として策定されたという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_in_Japan_Open_AI_c85874e918/AI_in_Japan_Open_AI_c85874e918.jpg" alt="AI in Japan OpenAI.jpg" /></p>
<h2>国家戦略の三本柱──包摂・インフラ・教育を軸に</h2>
<p>ブループリントは、AIを経済と社会の成長エンジンに据えるための三本の柱を掲げる。</p>
<h3>1. 包摂的な参加型社会基盤の構築</h3>
<p>AIをすべての人に届け、誰もが開発と活用に参加できる社会へ。日本の柔軟な著作権制度を基盤に、国際ルール形成を主導する「日本モデル」を確立する方針を示した。</p>
<h3>2. 戦略的インフラ投資</h3>
<p>AIの中核を担う半導体・データセンター・再生可能エネルギーを一体的に整備し、「ワット（電力）」と「ビット（情報）」を連携させる。政府の「GX2040ビジョン」との連動を通じ、地方へのデータセンター誘致や再エネ電源開発を官民協働で推進する。</p>
<h3>3. 教育・リスキリングによる人的資本投資</h3>
<p>初等教育からAIリテラシーを育成し、生涯学習をAIで支援。ChatGPT Eduなどのツールを「思考のパートナー」として活用し、批判的思考や創造性を育む教育を全国に広げるとした。</p>
<h2>経済効果の試算──AIが日本のGDPを最大140兆円押し上げ</h2>
<p>同文書は、AIの経済的インパクトを複数の独立分析に基づいて示している。
AIを最大限に活用した場合、日本のGDPを累計140兆円押し上げる可能性がある（みずほリサーチ＆テクノロジーズ）。また、生成AIだけでも実質GDPを16.2%増加させ得る（大和総研）。さらに、AI利用企業の生産性は非利用企業より8.8%高い（経済産業研究所）とされ、OpenAIはこれらを「日本全体の生産性への投資効果」と位置づけている。</p>
<h2>各分野での波及効果──製造・医療・教育・行政・科学・金融</h2>
<p>ブループリントでは、AIがもたらす変革を6分野で具体的に示した。</p>
<ul>
<li><strong>製造業</strong> ：中小企業336万社を支えるAI需要予測・検査システムの導入事例を紹介。品質向上やコスト削減、熟練工の技能継承を支援するツールとしての効果を示した。</li>
<li><strong>医療・介護</strong> ：AI画像診断や見守りセンサーによる人手不足解消や医療費削減効果を提示。骨粗鬆症の予防だけでも年間1.5兆円の介護費削減が可能と試算している。</li>
<li><strong>教育</strong> ：AIチューターによる個別最適化学習の導入を推進し、AIを「批判的思考を磨くツール」として位置づけた。</li>
<li><strong>行政</strong> ：さいたま市や福岡市、東京都のAI活用事例を挙げ、文書作成や住民対応の自動化に加え、地域文化振興への応用も紹介。</li>
<li><strong>科学</strong> ：AIによる創薬支援が臨床開発時間を最大60%短縮し、治験成功率の向上にも寄与。</li>
<li><strong>金融</strong> ：生成AIによるパーソナライズ投資提案やAML（マネーロンダリング防止）対策への応用を紹介。金融庁の「AIディスカッションペーパー」を“成長ガイド”と評価した。</li>
</ul>
<h2>AIインフラとエネルギー政策の一体化</h2>
<p>AI経済を支える物理的基盤として、データセンター市場は2028年に5兆円規模へ拡大すると予測。経産省によると、AIと半導体工場の増設により2034年度までに電力需要が約5.8%増加すると見込まれている。</p>
<p>OpenAIは、日本政府が掲げる「GX2040ビジョン」との連携を通じて、再生可能エネルギーが豊富な地域へのデータセンター誘致を提言。GX（グリーン成長）とDX（デジタル変革）を統合した「GX×DXモデル」が、持続的な経済発展の鍵になるとした。</p>
<h2>AIをすべての人の豊かさにつなげる設計図</h2>
<p>OpenAIはこのブループリントを「AIという変革の力を日本のすべての国民の豊かさに繋げるための設計図」と位置づけた。
「AIによって日本は経済成長と人間中心社会の両立を実現できる。今こそ官民一体でこの“日本モデル”を世界に先駆けて示すときだ」と締めくくっている。</p>
<p><a href="https://cdn.openai.com/global-affairs/f9d1cd88-506e-48f9-b34b-6ff63655434e/openai-japan-economic-blueprint-jp.pdf">「​​日本のAI：​​Open AIの経済ブループリント」全文</a></p>
]]></description>
      <pubDate>Sat, 25 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>公共2025/10/24 [FRI]850人超の著名人がAI「スーパーインテリジェンス」開発禁止を要請──ヒントン氏やメーガン妃らが署名</title>
      <link>https://ledge.ai/articles/ai_superintelligence_ban_850_signatories_fli_20251022</link>
      <description><![CDATA[<p>AIが人間の知能を超える「スーパーインテリジェンス（超知能）」の開発を巡り、世界の著名人や研究者らが開発の停止を求める声明を出した。</p>
<p>Future of Life Institute（FLI）は2025年10月22日、超知能AIの開発を禁止するよう求める声明「The Statement on Superintelligence」を<a href="https://superintelligence-statement.org/">公開</a>した。署名には、AI研究の第一人者ジェフリー・ヒントン氏やアップル共同創業者のスティーブ・ウォズニアック氏、英王室のヘンリー王子夫妻（ハリー王子とメーガン妃）など850人以上が名を連ねている。</p>
<h2>「安全・制御・公共合意」が条件</h2>
<p>声明の内容は極めてシンプルだ。FLIは、AIの超知能開発について、
「安全かつ制御可能な方法で行われるという幅広い科学的コンセンサス」と
「社会（国民）の強い支持」が得られるまで、
開発を禁止するよう求めている。</p>
<p>声明では、制御不能なAIがもたらすリスクとして、社会秩序の崩壊や経済格差の拡大、人間の自由の喪失、さらには人類そのものの存続への脅威を挙げている。背景には、OpenAIやMeta、Google DeepMindなどが進める「人間を超える知能の実現」競争があり、開発速度に対して安全性や統治の議論が追いついていないという問題意識がある。</p>
<h2>科学者から文化人まで、多様な署名者</h2>
<p>署名には、AI研究者や起業家だけでなく、政治家や芸能人など幅広い分野の人物が名を連ねた。</p>
<ul>
<li>Geoffrey Hinton 氏（AI研究者、「AIのゴッドファーザー」）</li>
<li>Yoshua Bengio 氏（モントリオール大学教授、チューリング賞受賞者）</li>
<li>Steve Wozniak 氏（Apple共同創業者）</li>
<li>Richard Branson 氏（Virgin Group創業者）</li>
<li>Prince Harry 氏、Meghan Markle 氏（英王室夫妻）</li>
<li>Steve Bannon 氏（元米ホワイトハウス首席戦略官）</li>
<li>Joseph Gordon-Levitt 氏（俳優）</li>
</ul>
<p>署名者の幅広さは、AI開発における倫理・安全への懸念が学術界にとどまらず、社会全体の関心事になりつつあることを示している。</p>
<p>声明は10月22日に発表され、同日よりオンラインで署名を受け付けた。署名受付の正確な時刻や締切は明示されていないが、発表から数日で850人超の署名が集まったとされる。記事執筆時点（10月24日）では署名が一般公開され、3万件を超えており、今後も追加署名が受け付けられる見通しだ。</p>
<h2>モラトリアムから「禁止」へ</h2>
<p>Future of Life Instituteは、2023年3月にもGPT-4以降のAI開発を6か月停止するよう求める書簡を発表しており、今回の声明はその延長線上にある。当時は一時停止（moratorium）を呼びかけたが、今回は「prohibition（禁止）」というより強い表現が使われており、AI開発競争への懸念が一層強まっていることがうかがえる。</p>
<h2>今後の行方</h2>
<p>この声明は法的拘束力を持たないものの、AI業界や政策立案者へ少なからず影響があるとみられている。各国政府はすでにAI規制法の整備を進めており、声明で示された「安全・制御・公共合意」という３つの条件が、今後の国際的なAI開発ガイドラインに組み込まれるかどうかが焦点となる。</p>
]]></description>
      <pubDate>Fri, 24 Oct 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIによる価格操作に州が規制──ニューヨーク州、家主向けアルゴリズム家賃設定ツールを禁止</title>
      <link>https://ledge.ai/articles/ai_rent_pricing_ban_newyork_oct2025</link>
      <description><![CDATA[<p>ニューヨーク州は2025年10月16日、キャシー・ホウクル知事が家主や物件管理会社がAIなどを活用したアルゴリズムで賃料を設定する行為を禁じる法案に署名したことを<a href="https://www.governor.ny.gov/news/governor-hochul-signs-legislative-package-bolster-homeownership-and-strengthen-protections">発表</a>した。州として、住宅市場におけるAIによる価格操作を直接規制するのは初めてとなる。</p>
<h2>アルゴリズムによる家賃設定を禁止</h2>
<p>この日ホウクル知事が署名した、住宅所有を促進し、賃借人保護を強化するための法案の中で、新法（S7882／A1417）は、複数の家主が同一のアルゴリズム価格設定ソフトウェアを用いることで事実上「賃料の共謀的引き上げ」が行われる構造を問題視したもの。対象となるのは、需要データや周辺相場をもとに家賃を自動調整するAIツールで、いわゆる「アルゴリズム価格設定（algorithmic pricing）」の利用を禁じる。</p>
<p>知事府の公式発表によれば、今回の法案は「住宅の公平性を守るための包括的な立法パッケージ」の一部として署名された。ホウクル知事は声明の中で、「ニューヨーカーは、公平で透明な家賃を支払う権利を持つ」と述べ、AIの悪用を防ぐ姿勢を強調した。</p>
<h2>背景に“AI賃料カルテル”への懸念</h2>
<p>米国ではここ数年、RealPage社の「YieldStar」や「RENTmaximizer」など、AIによって賃料を算出・最適化するソフトウェアの利用が急速に広がっていた。これらのツールは、入居需要、周辺相場、空室率などを解析して「最大利益を得られる家賃」を自動的に提案する仕組みを持つ。</p>
<p>しかし複数の家主が同一のAIモデルやデータを共有して賃料を設定すると、事実上の価格協調（カルテル）に当たるのではないかとの批判が高まっていた。2023年には、同ソフトの利用をめぐり連邦レベルで独占禁止法違反の集団訴訟も提起されている。</p>
<p>今回のA1417法は、そうした構造的な“AI共謀”を防ぐ狙いがある。米経済自由団体のAmerican Economic Liberties Project
は「AIを介した価格共謀の初の州レベル禁止」として歓迎の声明を<a href="https://www.economicliberties.us/press-release/economic-liberties-applauds-new-yorks-landmark-statewide-ban-on-rent-collusion-software/">発表</a>した。</p>
<h2>全米での議論に波及も</h2>
<p>新法は署名から60日後に発効予定で、違反が確認された場合は行政処分や罰金の対象となる。
今後、他州が同様の法整備に踏み出す可能性も指摘されている。AIによる価格設定はホテル、航空券、交通など他産業でも広く導入されており、今回の規制が「アルゴリズム経済」全体にどのような影響を与えるか注目が集まる。</p>
]]></description>
      <pubDate>Fri, 24 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日立、AIネイティブな基幹システム刷新を支援──「モダナイゼーション powered by Lumada」提供開始</title>
      <link>https://ledge.ai/articles/hitachi_modernization_powered_by_lumada_launch</link>
      <description><![CDATA[<p>日立製作所は2025年10月21日、AIを前提とした業務・IT・組織の変革を一体的に支援する新サービス「モダナイゼーション powered by Lumada（モダナイゼーション パワード バイ ルマーダ）」の提供開始を<a href="https://www.hitachi.co.jp/New/cnews/month/2025/10/1021.html">発表</a>した。企業の基幹システムをAIネイティブな構造へ刷新し、デジタルセントリック企業への転換を後押しする。</p>
<p>少子高齢化による労働人口減少や、熟練エンジニアの減少、システムのサイロ化などが企業経営の課題となる中、日立は従来の基幹システム更新支援にとどまらず、AI活用を前提とした業務改革・組織改革までを含めたモダナイゼーションを推進する。</p>
<p>同サービスは、日立のデジタル事業基盤「Lumada」に蓄積されたAI技術とドメインナレッジを活用し、次の2つのメニューで構成される。</p>
<h3>1. グランドデザイン策定サービス</h3>
<p>GlobalLogicの「CAST Imaging」「Highlight」などを活用して現行システムの構造を可視化し、投資優先度やリスク評価を踏まえたロードマップを策定する。AWSの「Blu Age」や「Transform」、Figma Makeなどのテクノロジーパートナーソリューションも組み合わせ、実効性の高い変革計画を設計する。</p>
<h3>2. 業務・ITモダナイゼーションサービス</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/67590_517_e86efbc37a9fcedccdf1cbfdd26877a8_1345x631_2a1d20325c/67590_517_e86efbc37a9fcedccdf1cbfdd26877a8_1345x631_2a1d20325c.webp" alt="67590-517-e86efbc37a9fcedccdf1cbfdd26877a8-1345x631.webp" /></p>
<p>経営から現場まで200種以上のAIエージェントを活用して業務の自動化を推進し、重要データの特定や品質維持を行うデータマネジメント基盤を提供。さらに、ITシステムのアーキテクチャーを領域ごとに最適化し、AIを活用したコード生成などで刷新を加速させる。あわせて、AI・アジャイル開発を担う人材育成や組織文化の変革も支援する。</p>
<p>サービスは、日立グループの実践を通じて検証された「カスタマーゼロ」の成果も取り入れる。ビルシステム事業では、AIソリューション「HMAX for Building : BuilMirai（ビルミライ）」の進化に向けて先行適用し、ベテラン技術者の暗黙知をAI化して設備メンテナンス業務の自動化を進めている。
また、大同生命保険株式会社システム開発二部 次世代システム開発室の黒川智也室長は、「AIの一層の活用を強力に推進するものであり、当社のIT活用の方向性と合致している」とコメントしている。</p>
<p>「モダナイゼーション powered by Lumada」は、Lumada 3.0ビジョンを体現するAIソリューション「HMAX」を展開する際にも活用される予定。日立はGlobalLogicのグローバル人材を活用し、迅速かつ持続的なデジタル変革支援を行うとしている。</p>
]]></description>
      <pubDate>Fri, 24 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>全国7400館の蔵書をChatGPTなどのAIアシスタントから検索──「カーリル for AI（カーリル図書館MCP）」ベータ版を公開</title>
      <link>https://ledge.ai/articles/calil_for_ai_library_mcp_beta</link>
      <description><![CDATA[<p>株式会社カーリルは2025年10月9日、ChatGPTやClaudeなどのAIアシスタントから全国の図書館蔵書を横断検索できる新サービス「カーリル for AI（カーリル図書館MCP）」のベータ版を公開したことを<a href="https://blog.calil.jp/2025/10/forai.html">発表</a>した。</p>
<p>同社が提供する図書館検索プラットフォーム「カーリル」は、全国7400館以上の公共図書館を対象に蔵書と貸出状況をリアルタイムで検索できるサービスで、今回の発表はそのAI連携版にあたる。</p>
<p>「カーリル for AI」は、OpenAIやAnthropicの提供するAIアシスタントに拡張機能として組み込むことで、自然な対話を通じて図書館の蔵書を調べられる仕組み。ユーザーがChatGPTやClaudeに「近くの図書館で『深夜特急』を借りられる？」といった質問をすると、AIがカーリルのデータベースを参照し、所蔵館や貸出可否などを回答する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/calil_for_ai1_54f04abd1a/calil_for_ai1_54f04abd1a.jpg" alt="calil_for_ai1.jpg" /></p>
<p>この仕組みは、AIモデルが外部データソースへ安全にアクセスするための新しい通信規格「Model Context Protocol（MCP）」を採用している。カーリル図書館MCPは、各地の図書館OPAC（蔵書検索システム）と連携し、最新の貸出情報をリアルタイムに取得する。従来のウェブ検索とは異なり、ユーザーはAIとの自然な会話の中で図書館情報にアクセスできるのが特徴だ。</p>
<p>利用には、ChatGPTまたはClaudeの設定画面で「カーリル図書館MCP」を有効化するだけでよい。設定後は、会話の中で書名や著者名を指定すれば、AIが自動的に対応する図書館データを検索する。</p>
<p>カーリルによると、現在は公共図書館を中心に対応しているが、今後は大学図書館や専門図書館への拡大も予定しているという。同社は「AIを通じて図書館の情報資源をより多くの人に届ける」ことを目指しており、AIと公共データをつなぐ新しいアクセスモデルの実証段階と位置付けている。</p>
]]></description>
      <pubDate>Thu, 23 Oct 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>広島銀行、営業準備に生成AI導入──「無意識に使える」業務フローへ　面談時間を7割削減見込み</title>
      <link>https://ledge.ai/articles/hirogin_ai_assistant_sales_poc_2025</link>
      <description><![CDATA[<p>ひろぎんホールディングス傘下の広島銀行は、営業業務に生成AIを導入し、行員の業務効率化を進めている。</p>
<p>ひろぎんホールディングスは2025年9月29日付で、融資稟議書作成機能を内製開発し全営業店に導入したほか、個人顧客との面談準備を支援するAIの概念実証（PoC）を実施し、有用性を確認したと<a href="https://www.hirogin-hd.co.jp/news/__icsFiles/afieldfile/2025/09/29/20250929_news.pdf">発表</a>した。</p>
<p>この取り組みは、ひろぎんホールディングスが掲げる「無意識に生成AIを利用する業務フローの構築」の一環として進められている。行員がAIを意識的に操作することなく、日常業務の中で自然に支援を受けられる環境を目指しているという。</p>
<p>広島銀行では、企業情報や営業記録をもとに融資稟議書の一部（申込経緯、資金使途など）を生成AIが自動でドラフト化する仕組みを開発。内容を確認・修正して活用することで、年間約5,200時間の業務削減効果を見込む。若手行員にとっては、AIが作成した草案を通じて稟議書の書き方を学べる機会にもなる。</p>
<p>さらに、個人顧客との面談準備の効率化に向け、行内の複数システムに分散する顧客情報をAIが自動で整理し、提案内容や会話のアイディアを生成するPoCを実施。検証の結果、準備時間を従来比で7割削減できる見込みが立った。これを受け、同社は内製による正式開発を進め、2026年2月から営業担当者による運用を開始する予定だ。</p>
<p>ひろぎんホールディングスは、2024年にMicrosoft Azure環境上でグループ専用生成AI「AI Assistant」を構築しており、現在は業務システムとの連携を進める“ステージ2”に位置づけている。将来的にはAIエージェントの活用による価値創造と顧客体験の向上を目指し、非金融領域を含む「総合力の高いソリューション」提供へと展開を広げていく方針だ。</p>
]]></description>
      <pubDate>Thu, 23 Oct 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIが拓く新しい設計と創造 ー「GENEX #1」開催レポート</title>
      <link>https://ledge.ai/articles/genex1-report</link>
      <description><![CDATA[<p>国内最大級のAI専門メディア「Ledge.ai」を運営するレッジは、業界横断カンファレンスシリーズ「GENEX」の第1回を9月30日に開催した。テーマは「3D CAD × Generative AI」。産業・エンタメ・教育の第一線で活躍するクリエイターと、CADソフトウェアベンダー／ハードウェアベンダー／助成金活用支援で業界をリードする企業が集い、生成AIとものづくりの未来について語っていただいた。本記事では、当日の各セッションの内容を紹介する。</p>
<p>なお、本イベントの模様は期間限定でアーカイブ配信を実施している。
セッションをご覧になりたい方は、以下より視聴が可能である。
:::button
<a href="https://zfrmz.com/VhuUWyN8c4eSEqAmIFRr">視聴申込みはこちら</a>{target=_blank}
:::</p>
<h2>パネルディスカッション『生成AIによって変革する設計のプロトタイピング』</h2>
<p>本セッションでは、デジタルコンテンツクリエイターの小畑 正好 氏、dots in space代表取締役の橋本 和幸 氏が登壇し、モデレーターはLedge.ai編集長の落合 研次が務めた。</p>
<h3>生成AIの潮流：エンタメから産業利用へ</h3>
<p>セッションは、落合による画像・動画生成AIの進化に関する3つの大きな潮流の解説から始まった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image4_8ea7d919be/genex_report_image4_8ea7d919be.png" alt="genex-report-image4.png" /></p>
<ul>
<li><strong>エンターテイメント用途</strong>: MidjourneyやStable Diffusionに代表される、生成されたアウトプットそのものを楽しむ潮流。</li>
<li><strong>リアル用途</strong>: 「Text-to-CAD」技術のように、生成物を設計図や工業製品のプロトタイプとして実世界で活用する潮流。</li>
<li><strong>Edit（編集）</strong>: 既存のデータや画像に指示を加えて編集・加工する潮流。</li>
</ul>
<p>特に、自然言語の指示から高精度な3D CADモデルを生成する「CADFusion」のような技術が紹介され、設計の初期段階におけるプロトタイピングが大きく変革される可能性が示唆された。</p>
<h3>現実を再構築する新技術「Gaussian Splatting」</h3>
<p>パネルディスカッションの中では、注目される技術の一つとして「Gaussian Splatting（ガウシアンスプラッティング）」が紹介された。従来の3D点群データとは異なり、ガウス関数（正規分布）を使って非常にリアルな3Dシーンを生成する技術である。既存の3Dモデルとは異なり、光の反射や質感などを極めて忠実に再現できるのが特徴である。データ生成の際に人力での対応に膨大な時間を要するため、生成AIの活用が不可欠だ。</p>
<p>またセッションの中では、長年CG業界の最前線で活躍してきた小畑氏と橋本氏に、自身の経験を踏まえ、生成AIとの向き合い方についても語っていただいた。</p>
<p>橋本氏は、かつてエヌビディアでディープラーニングの黎明期を経験した視点から、「AIの登場は、人間がアルゴリズムを組まなくても、入力と出力のパターンを学習させることで答えを導き出せるようになった点で革命的」と指摘。その上で、生成AIを「電卓のような道具」と捉え、「どんなデータを入力し、どう活用するかという人間の発想こそが重要になる」と強調した。</p>
<p>小畑氏も、40年にわたるCG制作の経験を振り返り、「技術の進化は常にあり、その度に人間の役割は変わってきた」と述べた。大河ドラマのオープニング映像制作を例に挙げ、実写からCGへと表現手法が変化した歴史に触れつつ、生成AIの登場で「個人のクリエイターが高品質な作品を生み出せる時代が来る」との期待を寄せた。</p>
<h2>株式会社 日本HP『オンプレで実現する3D CAD×生成AI：RAG導入と設計検索の実践ポイント』</h2>
<p>続いて、株式会社 日本HP エンタープライズ営業統括 ソリューション営業本部 ワークステーション営業部 AI／データサイエンス市場開発担当部長の勝谷 裕史 氏が登壇。同社のAIワークステーションを活用し、機密性の高い3D CADデータを安全かつ効率的に活用するための具体的な手法が、事例やデモを交えて解説された。</p>
<h3>生成AIの導入状況：普及の谷を越え「事例」を求める段階へ</h3>
<p>勝谷氏は、様々な企業の生成AI導入フェーズを見ていく過程で、普及の谷（キャズム）を越え、2025年の前半くらいからアーリーマジョリティの段階に入ったという実感を持ち始めたという。</p>
<p>企業での活用が進む中で、クラウドAIの利便性が注目される一方、勝谷氏はセキュリティリスクについてを懸念点として挙げた。実際に大手AIサービスの会話履歴が検索可能になった事例などを示し、機密性の高い設計データを外部に出すことの危険性を強調した。その解決策として、データを手元のマシンで完結させる「オンプレミスAI」での運用も組み合わせていくことが重要であると述べた。</p>
<h3>AIワークステーションのメリット：GPUサーバーよりも「安く、手軽で、静か」</h3>
<p>オンプレミス環境の構築ではGPUサーバーも選択肢となるが、セッションではAIワークステーションの優位性について紹介された。
AIワークステーションは、コストを半分以下に抑えながら、より高い性能を発揮する。さらに、特別な電気工事が不要で、オフィスエアコンより静かな静音性（60dB以下）も実現しているため、開発者のデスクサイドに設置して手軽にAI開発を始めることが可能になるというのもGPUサーバーとの違いとして挙げられた。</p>
<p>またセッションの中では、日本HPが提供する様々なワークステーションのラインナップも紹介され、その中でも最新のインテル® Core™ Ultra 9 プロセッサー 285Kを搭載した「HP Z2 Tower G1i Workstation」は、デスクトップサイズでありながら大規模なAI処理を可能にするその性能が強調された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image11_f8653818b5/genex_report_image11_f8653818b5.png" alt="genex-report-image11.png" /></p>
<h3>3Dモデルを認識して回答するデモも実演</h3>
<p>セッションの最後には、単一GPUで3Dモデル（点群データ）を直接認識するローカルLLM「PointLLM」のデモが披露された。AIが3Dモデルのデータを読み込み、その形状や特徴を「これはロボットのフィギュアです」といったように自然言語で説明する様子を実演。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image12_dbaca1b50c/genex_report_image12_dbaca1b50c.png" alt="genex-report-image12.png" /></p>
<p>AIワークステーションを活用することで、企業内に眠っている膨大な過去の3D設計データをAIに自動で解析・タグ付けさせることで、新たなデータ活用の可能性が示された。</p>
<h2>オートデスク株式会社『デザインと創造をパワフルにサポートする Autodesk AI』</h2>
<p>3つ目のセッションでは、オートデスク株式会社 日本地域営業統括 技術営業本部 本部長の加藤 久喜 氏が登壇。「デザインと創造をパワフルにサポートする Autodesk AI」と題し、製造業をはじめとする各業界のワークフローを革新するAI技術の現在地と未来について語った。</p>
<h3>短時間で無数の選択肢を生成を可能にする「ジェネレーティブデザイン」</h3>
<p>設計領域でのAI活用の具体的なアプローチとして強調されたのが「ジェネレーティブデザイン」である。これは、設計者が設定した強度、材料、製造方法などの条件に基づき、AIが最適な形状デザインを数百通りも自動生成する技術である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image7_8c1fc0c653/image7_8c1fc0c653.png" alt="image7.png" /></p>
<p>セッションの中で紹介された車椅子部品設計事例では、人間が3.5時間かけて3案しか出せなかった設計を、AIはわずか20分で100以上の検証可能な設計案を生成できるという。これにより、設計プロセスが「単一の最適解を探す」作業から「多様な選択肢の中から最良のトレードオフを見つける」戦略的な意思決定へと変化していく可能性が示された。</p>
<h3>信頼性と革新性：「Autodesk AI」の多角的な取り組み</h3>
<p>Autodesk AIは、単一の技術ではなく、同社の製品群全体にわたる包括的な取り組みとして紹介された。</p>
<p><strong>信頼性へのコミットメント</strong>
オートデスクは、AIの倫理的で責任ある利用を担保するため、AIマネジメントシステムの国際規格である「ISO/IEC 42001」を世界で初めて取得した企業の一つであることを発表。AIの学習データや判断プロセスを公開する「AI Transparency Card」などの取り組みを通じて、ユーザーが安心してAI技術を活用できる基盤を構築している。</p>
<p><strong>アイデアを即座に立体化する「Project Bernini」</strong>
最新の研究プロジェクトとして、テキストや簡単な2Dスケッチから3Dモデルを自動生成する「Project Bernini」が披露された。この技術は、コンセプトデザインの初期段階でアイデアを即座に可視化し、試行錯誤を加速させる。将来的には、生成されたモデルを直接編集可能なCADデータへ変換する研究も進められており、アイデアから製造までをシームレスに繋ぐことを目指している。</p>
<p><strong>自動車業界での実践例</strong>
自動車のデザイン開発において、従来は膨大な時間とコストを要した空力シミュレーションをAIが代替。数秒で衝突シミュレーションの結果を予測するなど、開発リードタイムを劇的に短縮する事例が紹介された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image5_adb16088c3/genex_report_image5_adb16088c3.png" alt="genex-report-image5.png" /></p>
<h3>対話ベースで3Dモデルの生成を可能にする「Autodesk Fusion」の新機能</h3>
<p>セッションのデモで特に注目を集めたのが、クラウドベースの3D CAD/CAM/CAEツール「Autodesk Fusion」に搭載されたAIアシスタント機能だ。</p>
<p>ユーザーが「エアフライヤーを生成して」と自然言語で指示するだけで、AIが3Dモデルを生成。さらに「このソリッドを分割して、2mmのシェルを追加して」といった対話形式の指示で、複雑な設計変更も自動で実行する。最終的には、生成したモデルのレンダリング画像やマーケティングプランを含むPowerPointのプレゼンテーション資料まで自動作成する能力も示され、設計からビジネス提案までの一連のワークフローがAIとの対話で完結する未来像が提示された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image6_fb0462812d/genex_report_image6_fb0462812d.png" alt="genex-report-image6.png" /></p>
<h2>トランステップ株式会社『補助金活用支援セッション 公的資金活用した、最新技術の導入』</h2>
<p>最後のセッションでは、本イベント共催のトランステップ株式会社 代表取締役社長 岡島 礼 氏が登壇し、補助金を利用して最新技術を導入するための具体的なノウハウを解説した。</p>
<h3>国が後押しする「DX投資」、今こそ補助金活用の好機</h3>
<p>セッションで岡島氏はまず、「補助金」と「助成金」の違いを明確にした。特に企業の設備投資や事業成長を後押しするのは、経済産業省などが管轄する「補助金」である。そして今、国はデジタルトランスフォーメーション（DX）分野への投資を強力に推進しており、関連する補助金予算も増加傾向にある。</p>
<p>岡島氏は、人手不足に悩む中小企業の省力化投資を支援する「中小企業省力化投資補助金」などを例に挙げ、3DCADソフトウェアやワークステーションの導入がこれらの制度の対象となり得ることを具体的に示した。これは、最新技術への投資を検討する企業にとって絶好の追い風と言える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image10_7b2f65c46b/image10_7b2f65c46b.png" alt="image10.png" /></p>
<h3>補助金トータルソリューション「トレテル」</h3>
<p>しかし、補助金の活用には大きな壁が立ちはだかる。一つは、年間数万件も公募される膨大な情報の中から自社に最適な補助金を「見つけられない」こと。もう一つは、申請手続きが複雑で「使いこなせない」ことである。</p>
<p>この課題に対し、岡島氏は同社が提供するAIを活用した補助金トータルソリューション「トレテル」を紹介。このツールを使えば、キーワード検索やAIとの対話を通じて、全国の膨大な補助金情報から自社に最適なものを瞬時に探し出し、申請に関する疑問も解消できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genex_report_image1_c60cbac109/genex_report_image1_c60cbac109.png" alt="genex-report-image1.png" /></p>
<p>複雑で縁遠いと思われがちな補助金だが、正しい知識と便利なツールを活用すれば、企業の成長を加速させるための強力な武器となる。今回のセッションは、多くの企業が最新技術導入への一歩を踏み出すための、価値ある道しるべとなったはずだ。</p>
<h2>まとめ —— 生成AIがものづくりに拓く新たな可能性</h2>
<p>GENEX #1では、生成AIがものづくりの現場にいかなる変化をもたらすのかについて、多角的な視点から議論が展開された。冒頭のパネルディスカッションでは、生成AIが「エンタメからリアルな空間へ」と進化していく潮流が示され、発想力を持つ人間が活用してこそ真価を発揮するという本質的な視点が提示された。
そのうえで、ハードウェアの観点では日本HPがオンプレミスAIワークステーションによる安全かつ効率的な環境の可能性を示し、ソフトウェアの観点ではオートデスクがジェネレーティブデザインやProject Berniniを通じて設計プロセスの革新を描いた。さらに制度の観点ではトランステップが補助金活用の具体策を提示し、導入を現実のものとするための道筋を明確にした。</p>
<p>次回「GENEX #2」では、テーマをロボティクスに移し、生成AIとリアルなものづくりの接点をさらに掘り下げる予定である。生成AIとロボティクスが融合する未来に注目いただきたい。</p>
<p>本イベントの模様は期間限定でアーカイブ配信をご覧になりたい方は、以下より視聴が可能である。
:::button
<a href="https://zfrmz.com/VhuUWyN8c4eSEqAmIFRr">視聴申込みはこちら</a>{target=_blank}
:::</p>
]]></description>
      <pubDate>Thu, 23 Oct 2025 00:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、「Claude Skills」を発表──資料を読み込み専門ワークを自動化する新機能</title>
      <link>https://ledge.ai/articles/claude_skills_release_oct2025</link>
      <description><![CDATA[<p>AI開発企業のAnthropicは2025年10月16日（現地時間）、AIアシスタント「Claude」に新機能「Agent Skills」（以下、Claude Skills）を導入したと<a href="https://www.anthropic.com/news/skills">発表</a>した。ユーザーが自らの業務資料や手順書をスキルとして登録すると、Claudeがそれらを読み込み、専門的なワークフローを自動実行できるようになる。企業ごとのナレッジやスクリプトをAIに統合し、業務効率化をさらに推し進める狙いだ。</p>
<p>@<a href="https://www.youtube.com/watch?v=IoqpBKrNaZI">YouTube</a></p>
<h2>フォルダ単位で“教え込む”仕組み</h2>
<p>Claude Skillsは、指示文やスクリプト、関連資料をまとめたフォルダをClaudeに読み込ませる仕組みだ。各フォルダには「SKILL.md」という定義ファイルが含まれ、タスク内容や使用条件などが記述される。Claudeは必要に応じてこれらのスキルを呼び出し、指示に従って処理を実行する。</p>
<p>この設計は「進行開示（progressive disclosure）」と呼ばれ、必要な情報だけを段階的に読み込むことで効率と安全性を両立する。Anthropicは、Claude Skillsを「プロンプトの再利用性を高め、AIが現実的な作業単位で動けるようにする構造」と説明している。</p>
<h2>企業導入例：Box、Canvaなど</h2>
<p>発表では、企業向けの活用例も紹介された。
クラウドストレージ大手のBoxでは、文書を自動的に要約・変換し、PowerPointやWord形式に整理するワークフローをスキルとして実装。Notionは「複雑なタスクでのプロンプト調整を減らし、より予測可能な結果につながる」とコメントしている。</p>
<p>さらにデザインプラットフォームのCanvaは、ブランドガイドをClaude Skillsに登録し、AIが自動でデザイン案を生成する活用を計画しているという。これにより、社内のスタイルガイドや手順書をAIに“教え込む”ことで、誰でも同じ品質で成果物を作れる環境を整備できる。</p>
<h2>エンジニア向けにはコード実行にも対応</h2>
<p>Anthropicの<a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills">エンジニアリングブログ</a>では、Claude Skillsの内部構造が詳細に解説されている。Claude Skillsは単なるプリセットではなく、自己記述的モジュール構造を持つ。スキルはフォルダ単位で管理され、初期段階ではメタ情報のみを読み込み、関連タスクが発生した際に全体を展開する。</p>
<p>スクリプトやPythonコードを含めることで、データ分析や自動レポート生成といった専門処理も可能だ。開発者は /v1/skills エンドポイントを通じてスキルを登録・管理でき、実行にはCode Execution Tool（ベータ）が必要となる。</p>
<p>従来の「プロンプト＋RAG（検索）」のように文脈を都度読み込む手法に比べ、Claude Skillsでは情報の再利用が容易で、処理速度や一貫性が大幅に向上するという。</p>
<h2>今後の展開</h2>
<p>Anthropicは今後、スキルの作成・共有・管理を容易にするツールやチーム配布機能の提供を予定している。また、セキュリティ面での検証や公開スキルストアの構想も進行中だ。</p>
<p>今回の発表は、Claudeを“対話AI”から“実行AI”へ進化させる試みの一環であり、Anthropicが目指すエージェント時代の布石といえる。</p>
]]></description>
      <pubDate>Wed, 22 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI共同創設者のAndrej Karpathy氏、ChatGPTを一から構築できるオープンソース「nanochat」を公開──約100ドル・4時間で独自LLMを訓練可能</title>
      <link>https://ledge.ai/articles/andrej_karpathy_releases_nanochat_open_source_chatgpt_clone</link>
      <description><![CDATA[<p>OpenAIの創設メンバーであり、元TeslaのAIディレクターとしても知られるAndrej Karpathy（アンドレイ・カルパティ）氏は2025年10月19日（現地時間）、ChatGPTのようなAIチャットボットを一から構築できるオープンソースプロジェクト「nanochat」を<a href="https://x.com/karpathy/status/1977755427569111362">発表</a>し、GitHub上にリポジトリを<a href="https://github.com/karpathy/nanochat">公開</a>した。</p>
<h2>4時間・約100ドルでChatGPT風モデルを構築</h2>
<p>Karpathy氏は投稿で、「わずか4時間・100ドルでChatGPTのような会話モデルを訓練できる」と説明。
クラウドGPU（8×H100構成）上で単一スクリプトを実行するだけで、LLMの事前学習から推論、WebUIまでを一括構築できる点が特徴だ。</p>
<p>コードは約8,000行と比較的コンパクトで、依存関係を最小限に抑えた「フルスタック実装」。
前作「nanoGPT」が事前学習フェーズに特化していたのに対し、今回の「nanochat」はトークナイザーの訓練から強化学習（RL）、推論エンジン、WebUIまでを統合している。</p>
<h2>Rust製トークナイザーと一貫した学習パイプライン</h2>
<p>nanochatでは、Karpathy氏が自作したRust実装のトークナイザーを用いてFineWebデータセットで事前学習（pretraining）を行う。
その後、SmolTalkデータによる会話形式の中間学習（mid-training）を経て、指示追従（SFT）や数学・コード・世界知識のベンチマーク評価（ARC-E/C、MMLU、GSM8K、HumanEval）を実施。
さらに、GSM8Kタスクに対する強化学習（GRPO）にも対応している。</p>
<p>推論時には、KVキャッシュを用いた効率的なデコードと、軽量Pythonサンドボックスでのツール使用（コード実行）機能を備える。CLIおよびChatGPT風のWebUIから利用でき、学習結果はMarkdown形式の「レポートカード」として自動出力される。</p>
<h2>性能とスケーラビリティ</h2>
<p>約4時間の訓練で「GPT-2を上回るCOREスコア」を達成し、12〜24時間の訓練では、MMLUで40点台、ARC-Easyで70点台、GSM8Kで20点台を記録。Karpathy氏は「1000ドル規模の訓練まで拡張すれば、数倍の一貫性と応答精度が得られる」としている。</p>
<h2>LLM教育「LLM101n」シリーズの集大成</h2>
<p>Karpathy氏は、nanochatを自身が開発中の教育プログラム「LLM101n」の“集大成プロジェクト（capstone project）”と位置づけている。
リポジトリは教育・研究者コミュニティ向けに「最大限フォーク可能」であり、LLMの構造理解や再実装の教材としても活用できる。
同氏は投稿の締めくくりで「これからが本番。チューニングとヒルクライミングを始める」と述べ、今後の最適化と拡張を予告した。</p>
<ul>
<li>GitHubリポジトリ：<a href="https://github.com/karpathy/nanochat">karpathy/nanochat</a></li>
<li>技術解説スレッド：<a href="https://github.com/karpathy/nanochat/discussions/1">Discussions #1 – nanochat speedrun walkthrough</a></li>
</ul>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google DeepMind、AIに“造語”を教えて振る舞いを制御──Geminiが自ら意味を説明する能力も確認</title>
      <link>https://ledge.ai/articles/deepmind_neologism_learning_for_ai_controllability</link>
      <description><![CDATA[<p>Google DeepMindの研究チームは2025年10月9日、AIに新しい架空の言葉（造語）を学習させることで、その振る舞いを精密に制御できる手法を<a href="https://arxiv.org/abs/2510.08506">発表</a>した。論文「Neologism Learning for Controllability and Self-Verbalization」は、AIが学習した造語の意味を自然言語で説明できる“自己言語化（self-verbalization）”という現象も初めて報告している。</p>
<p>この研究はarXiv上で公開されたプレプリント（査読前論文）で、AIの内部表現を「言葉」で理解・制御する新しいアプローチとして注目を集めている。</p>
<h2>造語でAIをコントロール</h2>
<p>従来、AIの出力傾向を操作するには、プロンプト設計や外部ツール（例：steering vector、autoencoderなど）による内部操作が必要だった。今回の手法では、モデル本体のパラメータを一切変更せず、造語に対応する新しい単語埋め込み（embedding）だけを学習する。</p>
<p>たとえば「Give me a lack answer.」と指示すると、AIは短い回答を返すようになり、別の造語では「誤った回答」「お世辞」「拒否」など異なる挙動を誘発できる。</p>
<p>研究チームはこの方法を「ネオロジズム学習（Neologism Learning）」と呼び、言語による“行動パラメータ”の追加と位置づけている。</p>
<p><strong>ネオロジズム学習のプロセス。左から「造語による概念の学習」「AIによる自己言語化（Verbalization）」「説明文を使った再検証（Plug-In Evaluation）」の流れを示す</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/x1_2e7a14d15f/x1_2e7a14d15f.png" alt="x1.png" /></p>
<h2>AIが自ら意味を説明</h2>
<p>研究チームは、AIが学習した造語の意味を英語で説明できることを確認した。
たとえば、短文回答を誘発する造語を学習したモデルに「What does lack mean?（lackとは何を意味しますか？）」と尋ねると、
「It means to give a shorter response.（短い回答をすることを意味します）」と答える。</p>
<p>このようにAI自身が学習した内部概念を自然言語で記述する能力を、研究チームは“self-verbalization（自己言語化）”と定義。
さらに、造語をその説明文に置き換えても同様の挙動が再現されるかを検証する「plug-in evaluation」を導入し、自己説明の信頼性を評価した。</p>
<h2>モデル間で“機械語”が通じる</h2>
<p>DeepMindの実験では、Gemma-3-4B-ITが学んだ造語を別のモデル――Gemini 2.5 Flash――に入力したところ、意味が通じ、ほぼ同じ制御効果を示した。
たとえば“lack”という語を用いた場合、Gemmaでは回答の平均文数が42.9から15.8に減少し、Geminiでも中央値が37から4に減少した。</p>
<p>研究チームはこの現象を「machine-only synonym（機械専用類義語）」と呼び、
人間には直感的に理解できないが、AI同士では通じ合う“共通語彙”が形成される可能性を指摘している。</p>
<h2>複合的な概念も制御可能</h2>
<p>ネオロジズム学習は、単純な行動特性だけでなく、複数の概念を組み合わせた複合的制御にも対応する。
たとえば「短く・数値を含む・高確率」といった3つの条件を、それぞれに対応する造語を同時に指定することで達成できるという。</p>
<p>研究では、「短文」「誤答」「お世辞」「拒否」など7種類の単純概念や、言語的特徴を扱うベンチマークAxBenchにおいても、高い制御性能が確認された。</p>
<h2>AIの「内なる言葉」への道</h2>
<p>著者のひとりであるジョン・ヒューイット（John Hewitt）氏は、
「私たちは既存の語彙だけではAIの内部概念を十分に理解できない」と述べ、造語学習をその橋渡しと位置づけている。</p>
<p>研究は、AIの制御可能性（controllability）と説明可能性（explainability）を同時に高める新しい方向性を示すものであり、
将来的にはAI間通信や人間との協調学習に応用できる可能性があるとみられる。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、量子チップ「Willow」で“検証可能な量子優位”を実証──Nature掲載論文でスーパーコンピューターを13,000倍上回る性能</title>
      <link>https://ledge.ai/articles/google_quantum_willow_verifiable_advantage_nature2025</link>
      <description><![CDATA[<p>Googleは2025年10月22日、科学誌『Nature』において、同社の量子コンピューター用チップ「Willow（ウィロー）」が、既存のスーパーコンピューターを13,000倍上回る速度で演算を実行し、「検証可能な量子優位（verifiable quantum advantage）」を達成したと<a href="https://research.google/blog/a-verifiable-quantum-advantage/">発表</a>した。</p>
<p>論文「<a href="https://www.nature.com/articles/s41586-025-09526-6">Observation of constructive interference at the edge of quantum ergodicity</a>」によると、Willowチップは105個の超伝導キュービットを備え、量子情報の拡散を解析する手法「アウト・オブ・タイム・オーダー相関（OTOC）」を用いて実験を実施した。結果、古典スーパーコンピューターでは約32年を要する計算を、わずか2時間で完了したという。</p>
<p>@<a href="https://www.youtube.com/watch?v=mEBCQidaNTQ">YouTube</a></p>
<p>A Verifiable Quantum Advantage：研究チームがWillowチップ、量子エコーアルゴリズム、NMR分光法応用などを解説</p>
<h2>Quantum Echoes──量子エコー・アルゴリズムの仕組み</h2>
<p>Googleの研究チームは、量子システム内部の相互作用を可視化する新しいアルゴリズム「Quantum Echoes（量子エコー）」を開発した。この手法は、量子回路を順方向と逆方向の両方で実行し、干渉パターンを比較することで誤差を自己検証できる。</p>
<p>この仕組みにより、量子システムの「見えない構造」をエコー信号として観測可能にする点が特徴で、これまでノイズに埋もれていた量子状態の動的相関を明確に測定できるようになった。</p>
<h2>量子干渉と「Constructive Interference」──新しい優位性の原理</h2>
<p>論文では、量子系内部のパウリ演算子の干渉（constructive interference）が、OTOCの高次成分（OTOC(2)など）において初めて実験的に観測されたことを報告。これにより、量子干渉の複雑性が古典シミュレーションでは再現不能であることが確認された。</p>
<p>実際、Googleの試算では、今回の65キュービット実験を古典スーパーコンピューター「Frontier」でシミュレートするには約3.2年を要し、Willowチップの実行時間（2.1時間）と比べて13,000倍以上の差がある。これにより、「Beyond classical（古典を超えた）」領域に踏み入ったと位置づけている。</p>
<p><strong>Quantum Echoesアルゴリズムは、世界最速のスーパーコンピューターを13,000倍上回る速度で計算を実行</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/13000times_faster_3aa42ccb1d/13000times_faster_3aa42ccb1d.jpg" alt="13000times faster.jpg" /></p>
<h2>実世界応用への一歩──分子構造解析とHamiltonian Learning</h2>
<p>Google Quantum AIは、Quantum Echoesの応用として、ハミルトニアン学習（Hamiltonian learning）を実証した。
これは量子システムの測定データ（OTOC）を実際の物理系と照合し、未知のパラメータを最適化して学習する手法である。</p>
<p>研究チームは、UCバークレーと連携し、Willowチップ上で2種類の分子構造を予測し、NMR分光法でその正確性を確認した。論文では、この方法が分子シミュレーション、薬剤設計、エネルギー材料開発などへの応用に発展する可能性が示唆されている。</p>
<p><strong>量子研究施設を視察するGoogle CEOのサンダー・ピチャイ氏「科学そのものを行う力が量子計算に宿り始めている」と述べた</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Quantum_Sundar_Inline_width_1000_format_webp_5a6124c1fb/Quantum_Sundar_Inline_width_1000_format_webp_5a6124c1fb.webp" alt="QuantumSundar_Inline.width-1000.format-webp.webp" /></p>
<p>Google Quantum AIのディレクターであるHartmut Neven氏は、「量子コンピューターが理論段階を超え、実際の科学的課題を解くためのツールになりつつある」とコメント。共同リーダーのJulian Kelly氏も「Quantum Echoesを通じて、結果を検証可能な形で量子優位を確認できたのは初めて」と述べた。</p>
<p><strong>Google Quantum AIが開発した次世代量子チップ「Willow」。105個の超伝導キュービットを搭載し、誤差率0.15％の高精度ゲート制御を実現した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Willow_Chip_4k_Render_02_width_1000_format_webp_2ad189fa0b/Willow_Chip_4k_Render_02_width_1000_format_webp_2ad189fa0b.webp" alt="WillowChip_4k_Render_02.width-1000.format-webp.webp" /></p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、動画生成AI「Veo 3.1」を発表──1分超のシーン拡張「Extend」搭載、Flowと統合強化</title>
      <link>https://ledge.ai/articles/google_veo3_1_flow_integration</link>
      <description><![CDATA[<p>Googleは現地時間2025年10月15日、動画生成AI「Veo」の最新版となるVeo 3.1を<a href="https://blog.google/technology/ai/veo-updates-flow/">発表</a>した。</p>
<p>新バージョンでは、AI映像制作ツール「Flow」に新機能を追加し、その中核としてVeo 3.1を統合。照明・構図・音声をAIが自動的に制御できるようになり、リッチなオーディオ、物語制御（narrative control）の強化、質感のリアリズム向上を図ったアップデートとなっている。</p>
<p>@<a href="https://www.youtube.com/watch?v=I06Ef8alr2Y">YouTube</a></p>
<h2>Flowとの統合で生成から編集まで一体化</h2>
<p>Googleは今回、AI映像制作ツール「Flow」へのアップデートを発表した。Flowは5か月前の導入以降、すでに2億7,500万本以上の動画を生成しており、Veo 3.1の搭載によって生成から編集までのプロセスがさらに統合された。</p>
<p>Flowは、テキスト・画像・音声・映像素材といった“ingredients”を組み合わせて動画を構築できるツールである。
既存の「Ingredients to Video」「Frames to Video」「Extend」機能に加え、今回は音声統合を拡張。ユーザーは複数の素材をもとに、AIがシーン構成やカメラワーク、トーンを自動的に最適化した一貫性のある映像を生成できる。</p>
<p>新しいExtendでは、直前のクリップの終端1秒を手がかりに、1分以上の連続ショットとして自然に拡張することも可能。Googleはこれにより、「映像制作をより直感的で対話的な体験へと変える」としている。</p>
<p>@<a href="https://www.youtube.com/watch?v=B78BJuPxmBU">YouTube</a></p>
<h2>照明や構図、音声もAIが自動編集</h2>
<p>Veo 3.1では、照明・陰影・カメラ構図をAIが自動的に制御し、シーン全体のトーンや一貫性を高める。
また、AIによる音声生成と映像への同期統合にも対応し、環境音や効果音を含む“音響的なリアリティ”を再現できるようになった。</p>
<p>Flow内には、シーンに要素を追加する「Insert」と、不要な物体を背景ごと削除する「Remove（近日提供）」の編集機能も加わった。影や照明の整合を自動で処理することで、合成感を抑えた自然な編集を可能にしている。
Googleは、こうした機能群を通じて「richer audio」「more narrative control」「enhanced realism」の実現を掲げている。</p>
<h2>Gemini APIで提供、Standard／Fastモデルを展開</h2>
<p>Veo 3.1は、「Standard」モデルと「Fast」モデルの2種類を用意し、Gemini API経由で開発者向けに提供が開始された。生成速度を優先するワークフローにはFastモデル、品質を重視する制作用途にはStandardモデルが推奨される。</p>
<p>さらに、Veo 3.1はVertex AIおよびGeminiアプリからも利用可能。新機能はGemini API／Vertex AIの双方で順次展開される予定で、API向けの「Scene extension」機能も今後提供される見込みだ。
Googleは「AIによる創造的表現の民主化をさらに進める」とし、プロフェッショナルから一般ユーザーまで、誰もが高品質な映像制作にアクセスできる環境の構築を目指している。</p>
<h2>Veoシリーズの進化</h2>
<p>Veoシリーズは、2024年12月の「Veo 2」、2025年春の「Veo 3」に続く最新バージョン。
今回のVeo 3.1では、「AI任せの自動生成」から「人とAIが協働して映像を作る」方向へと進化した。
Flowとの連携により、テキストによる指示だけでなく、素材・音声・カメラ指示などを含めた多層的なプロンプト設計が可能になり、AI映像生成の精度と自由度が大幅に向上している。</p>
<p>Googleは今後、VeoをGeminiエコシステムの中核技術として位置づけ、AIを活用したクリエイティブツールの拡充を進める方針を示している。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、次世代純国産LLM「tsuzumi 2」発表──フルスクラッチ設計でGPT-5級の日本語性能を軽量モデルで実現</title>
      <link>https://ledge.ai/articles/ntt_tsuzumi2_fullscratch_gpt5_level_japanese_llm</link>
      <description><![CDATA[<p>NTT2025年10月20日、フルスクラッチで開発した純国産の大規模言語モデル（LLM）「tsuzumi」の次世代版「tsuzumi 2」を<a href="https://group.ntt/jp/newsrelease/2025/10/20/251020a.html">発表</a>した。
ChatGPTなど海外製LLMの普及が進む一方、電力消費や機密情報の取り扱いといった課題が顕在化するなか、NTTは1GPU環境で動作可能な軽量設計と高い日本語理解力を両立。日本語に最適化された高セキュアな生成AIとして提供を開始した。</p>
<h2>tsuzumi 2の進化ポイント</h2>
<p>NTTは、tsuzumi 2を「日本の企業DXを支える高性能・高セキュア・低コストな純国産LLM」と位置づけ、次の3つの進化点を挙げている。</p>
<ol>
<li>日本語性能のさらなる向上</li>
<li>特化型モデル開発効率の向上</li>
<li>低コスト・高セキュアの維持、国産AI</li>
</ol>
<p>これらの改良により、NTTは軽量ながらも世界トップクラスの性能を達成したと説明している。</p>
<h2>GPT-5級の日本語性能を実現</h2>
<p>「tsuzumi 2」は同クラス帯（約30Bパラメータ）のモデルとして世界トップクラスの日本語性能を持つ。
知識・解析・指示遂行・安全性の各評価において、数倍以上大きなフラッグシップモデル（GPT-5など）に匹敵する水準を記録した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tsuzumi2_3_88e14a3c64/tsuzumi2_3_88e14a3c64.jpg" alt="tsuzumi2 3.jpg" /></p>
<p>同社は、独自トークナイザーによって日本語の単語分割を最適化。文法構造に沿った分割を学習させることで、自然で読みやすい文の生成と高い効率性を両立した。
また、英語やソースコードに対しても効率的な生成が可能で、トークン当たり文字数ではGPT-5の約1.5倍を出力できるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tsuzumi2_1_8855a698bd/tsuzumi2_1_8855a698bd.jpg" alt="tsuzumi2 1.jpg" /></p>
<h2>金融・医療・公共分野に特化した開発効率を強化</h2>
<p>tsuzumi 2では、RAG（検索拡張生成）とFine Tuningを組み合わせた特化モデル開発が可能になった。金融・医療・公共分野の知識を重点的に強化し、少量データでも高精度な応答を実現。NTT社内では、財務システムに関する問い合わせ応答タスクにおいて、他社先進モデルと同等以上の性能を確認した。また、FP2級試験を用いた評価では、他モデルの約10分の1の追加学習データで合格基準に到達したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tsuzumi2_6_f1c925969d/tsuzumi2_6_f1c925969d.jpg" alt="tsuzumi2 6.jpg" /></p>
<h2>軽量・高セキュア設計で企業利用を想定</h2>
<p>tsuzumi 2は、1GPUでの推論が可能な軽量設計を維持し、推論コストを約10〜20分の1に削減。16bit・8bit・4bitの量子化モードを備え、用途に応じて精度や速度を調整できる。また、オンプレミスやプライベートクラウドでも動作可能で、機密情報を含む業務データも安全に処理できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tsuzumi2_7_d5c23fc249/tsuzumi2_7_d5c23fc249.jpg" alt="tsuzumi2 7.jpg" /></p>
<h2>学習データを自社管理、著作権と文化への配慮</h2>
<p>NTTは、海外製オープンモデルに依存せず、学習データ・開発プロセス・品質を完全に自社管理している。新聞社データなどの権利保護にも配慮し、学習データから自主的に削除。40年以上にわたる日本語研究の成果を基盤に、「日本語・文化・慣習を理解するAI」を目指している。</p>
<h2>教育・企業現場での導入事例も拡大</h2>
<p>すでに東京通信大学が学内LLM基盤としてtsuzumi 2を採用。授業Q&amp;Aや教材作成支援、履修相談などで運用を開始する。
また、NTTドコモビジネスと富士フイルムビジネスイノベーションは、契約書や提案書などの非構造化データを安全に構造化・分析できる生成AIソリューションの共同開発を進めている。</p>
<h2>今後の展開</h2>
<p>NTTは、tsuzumi 2をグループ各社のAIソリューションに順次組み込み、産業ごとの特化モデルを展開予定。
さらに、AI間の自律的な議論を行う「AIコンステレーション」構想や、サイバーセキュリティ分野での応用開発も進める。
11月に開催される「NTT R&amp;Dフォーラム 2025（IOWN Quantum Leap）」では、tsuzumi 2を活用した最新ソリューションを披露するという。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA、「AI Day Tokyo 2025」全26セッションを無料公開──「ソブリンAI」「フィジカルAI」など最新動向をオンデマンドで視聴可能に</title>
      <link>https://ledge.ai/articles/nvidia_ai_day_tokyo_2025_ondemand_sessions</link>
      <description><![CDATA[<p>NVIDIAは10月21日までに、9月に東京ミッドタウン（東京都港区）で開催したイベント「<a href="https://blogs.nvidia.co.jp/blog/ai-day-tokyo/?ncid=so-twit-279362&amp;linkId=100000387789084">NVIDIA AI Day Tokyo 2025</a>」で実施した全26セッションの<a href="https://www.nvidia.com/ja-jp/on-demand/playlist/playList-4fa34d64-8fc9-487f-819a-18e06511216b/">オンデマンド配信</a>を開始した。生成AI、ロボティクス、医療AI、ソブリンAIなどをテーマとした講演を、同社公式サイトで無料視聴できる。</p>
<p>このイベントは、産業・研究・行政分野におけるAI活用の現状と今後の展望を共有する目的で開催され、約900名が参加した。主催はNVIDIA Japan。</p>
<p>主要テーマのひとつである「ソブリンAI（Sovereign AI）」では、日本国内のデータセンターやインフラ環境内でAI開発・運用を完結させる取り組みを紹介。政府や産業界における「データ主権」の確立に関する議論が行われた。</p>
<p>また、「フィジカルAI（Physical AI）」では、物理法則を理解し、ロボット制御や自動運転など現実世界の動作を最適化するAI技術が取り上げられた。AIが現実空間で学習・推論を行う応用例が紹介されたという。</p>
<p>その他のセッションでは、生成AIモデル「NIM」や「NeMo」を用いたアプリケーション開発、医療・創薬分野でのAI活用、ロボティクスシミュレーション、GPUクラウド基盤の構築、日本企業による導入事例などが扱われている。</p>
<p>NVIDIAは同ブログ内で、日本のAI演算需要が2030年までに2020年比で約320倍に増加すると予測しており、日本市場をアジア地域の主要拠点の一つとして位置づけている。</p>
<p>オンデマンド配信は、NVIDIA公式サイトの「NVIDIA On-Demand」上で<a href="https://www.nvidia.com/ja-jp/on-demand/playlist/playList-4fa34d64-8fc9-487f-819a-18e06511216b/">公開</a>されており、全26セッションが日本語で視聴可能。視聴登録のみでアクセスできる。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>アルトマン氏「エロティックばかり注目されたけど」──ChatGPT、成人ユーザーの自由拡大へ</title>
      <link>https://ledge.ai/articles/openai_chatgpt_adult_mode_update_oct2025</link>
      <description><![CDATA[<p>OpenAIのサム・アルトマンCEOは10月14日（現地時間）、X（旧Twitter）上で、ChatGPTの安全制限を一部緩和し、成人認証済みユーザーに対してエロティックな会話を許可する方針を<a href="https://x.com/sama/status/1978129344598827128">発表</a>
した。</p>
<p>投稿は瞬く間に注目を集め、「エロティック解禁」が大きな話題となったが、アルトマン氏は翌日に「その部分ばかり注目されてしまったが」と<a href="https://x.com/sama/status/1978539332215681076">補足</a>し、実際には“より人間らしいAI体験”を実現するための包括的な方針変更であることを強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gpt5_erotica_7cea863241/gpt5_erotica_7cea863241.jpg" alt="gpt5 erotica.jpg" /></p>
<h2>安全を優先してきたChatGPTの制限</h2>
<p>ChatGPTはこれまで、性的表現や親密な会話を含むコンテンツを厳しく制限してきた。
アルトマン氏は「メンタルヘルス問題に慎重を期すためだった」と説明し、精神的に不安定なユーザーに配慮した措置であったと振り返った。
「深刻な危機状態にあるユーザーは別扱いとし、他者に害を与える行為は依然として許可しない」と述べ、ポリシーの根幹は維持されるとしたうえで、「リスクのない成人ユーザーにはより多くの自由を与える」と明言した。</p>
<h2>“4oらしさ”を再導入──人間的なAI体験へ</h2>
<p>アルトマン氏は同日、「数週間以内に“4oで好まれた振る舞い”に近い人格（パーソナリティ）を選べる新バージョンのChatGPTを提供する」と投稿した。
GPT-4oは会話の自然さや表情豊かな応答で人気を集めたモデルであり、今後はユーザーが望む場合に、フレンドリーな口調や絵文字を多用した“人間らしい”対話スタイルを選べるようになる。
アルトマン氏は「これは利用時間を増やすためではなく、ユーザーが自分の望む形でAIと関わる自由を得るための設計だ」と述べている。</p>
<h2>「成人は大人として扱う」──12月に年齢認証を本格導入</h2>
<p>アルトマン氏は、12月に年齢認証を本格導入し、認証済み成人ユーザーに対してはエロティック会話なども許可する方針を示した。
一方で、ティーンエイジャーに対しては「安全をプライバシーや自由より優先する」と述べ、メンタルヘルス関連ポリシーは緩めないと強調している。</p>
<p>アルトマン氏は、「社会がR指定映画で境界を設けるように、AIにも適切な年齢境界を設けたい」と例え、「我々は選挙で選ばれた道徳警察ではない」と付け加えた。</p>
<h2>倫理と自由の境界線</h2>
<p>アルトマン氏の発言は、AIにどこまで人間的な自由を与えるかという議論を再燃させた。</p>
<p>OpenAIは今後、成人向け表現やAIの人格設計に関するガイドラインをさらに明確化するとみられる。今回の方針転換は、「AIをどう設計し、どう育てるか」という人間社会全体のテーマに踏み込む第一歩となりそうだ。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「ChatGPT Atlas」を正式公開──AIブラウザとしてmacOS版をリリース</title>
      <link>https://ledge.ai/articles/openai_chatgpt_atlas_release_oct2025</link>
      <description><![CDATA[<p>OpenAIは米国時間10月21日、AIブラウザ「ChatGPT Atlas」を<a href="https://openai.com/index/introducing-chatgpt-atlas/">発表</a>した。</p>
<p>同社によると、AtlasはChatGPTを中心に構築されたmacOS向けアプリで、チャットとWebブラウジングを融合した新しいAI体験を提供するという。発表が行われたライブ配信では、AIがWebの使い方そのものを再定義する「10年に一度の機会」と位置づけ、従来のブラウザの概念を刷新する設計思想が語られた。</p>
<p>@<a href="https://www.youtube.com/watch?v=8UWKxJbjriY">YouTube</a></p>
<h2>ChatGPTが心臓部にあるブラウザ</h2>
<p>ライブ配信で同社は、Atlasの開発が「ブラウザとチャットできたらどうなるか？」という問いから始まったと説明。
従来の複雑なWeb体験を、シンプルな会話で置き換えることを目指したと語った。Atlasは単にAI機能を追加した既存ブラウザではなく、「ChatGPTがその鼓動する心臓（beating heart）」として常にユーザーのそばで支援するよう設計されているという。</p>
<h2>コア機能：3つの柱</h2>
<p>Atlasを支えるコア機能として以下の3点が挙げられた。</p>
<ol>
<li><strong>Chat Anywhere</strong> ：ユーザーがどのWebページを閲覧していても、チャット機能を呼び出すことでページの文脈を理解した支援が受けられる。コピー＆ペーストやタブ移動の必要がなく、メール作成や文書作業中でもAIが内容を把握して提案を行う。</li>
<li><strong>ブラウザ・メモリ</strong> ：ChatGPTの記憶機能をブラウザー全体に拡張。Atlasはユーザーの閲覧や検索の履歴を理解し、過去に見たドキュメントを「人間が話すような言葉」で検索できる。利用者ごとにAIがパーソナライズされていく仕組み。</li>
<li><strong>エージェント</strong> ：ChatGPTがユーザーの代わりに操作を実行する機能。予約やドキュメント編集などを支援する際に、AIが小さなカーソルを出してクリック動作を行う。ログイン情報やブラウザー履歴にアクセスでき、まるで「ユーザー自身の自然な延長」として働く。</li>
</ol>
<h2>その他の主要機能</h2>
<ul>
<li><strong>Ask ChatGPT（サイドバー）</strong> ：ウェブページ右上の「Ask ChatGPT」ボタンから起動。表示中ページの要約、製品比較、プルリクエストやSlackチャンネルの要約などを行える。</li>
<li><strong>検索体験の刷新</strong> ：検索結果はニュース・画像などのタブでも絞り込め、ページ遷移後もChatGPTとの対話を並行して続けられる。</li>
<li><strong>カーソル操作（Use cursor）</strong> ：フォーム入力欄でテキストを選択し、ChatGPTを呼び出して文法チェックやトーン調整などを行う。</li>
</ul>
<h2>安全性と提供状況</h2>
<p>OpenAIは、Agentモードがユーザーのタブ上でのみ動作し、外部ファイルやコード実行にはアクセスしないよう安全設計が施されていると説明。ブラウザ・メモリ機能も完全オプションで、設定やシークレットウィンドウで制御可能とした。</p>
<p>AtlasはmacOSユーザー向けに全世界で提供開始されており、Plus／Pro／Businessユーザーを対象にプレビュー提供されている。今後、Windowsおよびモバイルへの展開を計画しているとのことだ。</p>
<h2>AIとWebを再定義する「次の10年」</h2>
<p>OpenAIはブログ「<a href="https://openai.com/index/introducing-chatgpt-atlas/">Introducing ChatGPT Atlas</a>」の中で、Atlasを「チャット、ブラウジング、ワークスペースを統合する新しい形のAI体験」と表現。AIがユーザーを理解し、インターネット上で必要な情報を能動的に探し出す未来像を描いている。同社はこのプロジェクトを「early days（初期段階）」と位置づけ、今後さらに機能を拡張していく方針だ。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界初のAI女優「ティリー・ノーウッド」にハリウッドが揺れる──SAG-AFTRAや著名俳優が「創造性の危機」と警告</title>
      <link>https://ledge.ai/articles/tilly_norwood_ai_actress_controversy_sagaftra</link>
      <description><![CDATA[<p>世界初の「AI女優」と称される Tilly Norwood（ティリー・ノーウッド）が、ハリウッドの俳優や映画俳優組合SAG-AFTRA（全米映画俳優組合・テレビ・ラジオ芸術家連盟）から強い批判を受けている。</p>
<p>SAG-AFTRAは2025年9月30日に「創造性は人間中心であるべき」と声明を<a href="https://www.sagaftra.org/sag-aftra-statement-synthetic-performer">発表</a>した。女優のエミリー・ブラント氏やウーピー・ゴールドバーグ氏も相次いで懸念を表明し、映画・テレビ業界全体に議論が広がっている。</p>
<h2>「AI Commissioner」──ティリー誕生の舞台</h2>
<p>Tilly Norwoodは、ロンドン拠点の制作会社Particle6が2025年9月にYouTube上で公開したコメディスケッチ『AI Commissioner | Comedy Sketch | Particle6』で初登場した。</p>
<p>この作品は、テレビ業界におけるAIの急速な普及を風刺的に描いたもので、AIが脚本作成からキャスティング、予算編成まですべてを自動化する世界を描く。劇中では、AIが生み出したインタラクティブスリラー『I Know What You Streamed Last Summer』に登場する100％AI生成の俳優としてTillyが紹介される。</p>
<p>@<a href="https://www.youtube.com/watch?v=3sVO_j4czYs">YouTube</a></p>
<p>登場人物の1人はTillyについて「僕の言うことを何でも聞いてくれる。恋をしてしまったかもしれない（She’ll do anything I say. I think I’m in love）」と評し、AIによる従順で“最適化された”俳優像を象徴的に表現。
さらに、「“She’ll cry on Graham Norton and be monetized on TikTok by lunchtime.”（彼女はグレアム・ノートンの番組で泣いて、その日の昼までにTikTokで収益化されるだろう）」という台詞が、人間の感情までもがAIによって即座に商業化される未来への皮肉として話題を呼んだ。</p>
<h2>SAG-AFTRAが声明「Tillyは俳優ではない」</h2>
<p>SAG-AFTRAは9月30日に「Statement on Synthetic Performer（合成パフォーマーに関する声明）」を<a href="https://www.sagaftra.org/sag-aftra-statement-synthetic-performer">発表</a>し、次のように明言した。</p>
<p>\u003E“Tilly Norwood is not an actor. Creativity must remain human-centered.”
（ティリー・ノーウッドは俳優ではない。創造性は人間中心であるべきだ。）</p>
<p>声明では、AIによって作られた “合成俳優” が芸術表現を侵食する可能性を指摘し、「経験や感情を持たない存在を“俳優”と呼ぶことは、芸術の根幹を損なう」と警鐘を鳴らした。SAG-AFTRA会長のショーン・アスティン氏もVarietyの取材に対し、「AI倫理と補償問題を正式な交渉テーマとして扱う」と述べている。</p>
<h2>著名俳優からの反発</h2>
<p>女優のエミリー・ブラント氏は、Varietyのポッドキャスト番組でTillyの画像を見せられ、驚きを隠さずこう語った。</p>
<p>\u003E“Good Lord, we’re screwed. That is really, really scary. Come on, agencies, don’t do that. Please stop taking away our human connection.”
「なんてこと、私たちは終わりね。本当に恐ろしいわ。お願い、エージェントはそんなことをやめて。人間のつながりを奪わないで。」</p>
<p>また、取材でTillyを「次のスカーレット・ヨハンソンに」と問われると、「“But we have Scarlett Johansson.”（でも私たちにはスカーレット・ヨハンソンがいる」 と返し、人間俳優の価値を強調した。</p>
<p>俳優・司会者のウーピー・ゴールドバーグ氏も、ABCのトーク番組『The View』（9月30日放送）で次のように発言した。</p>
<p>\u003E“You’re looking at 5,000 actors rolled into one synthetic person. That’s not fair. We all move differently.”
「5,000人の俳優の特性をひとつの合成存在にまとめるなんてフェアじゃない。私たちは皆、動きも表情も違う。」</p>
<h2>開発側の見解：「人間の代替ではなく、芸術表現」</h2>
<p>Tillyを制作したエライン・ファン・デル・フェルデン氏（Eline Van der Velden）は9月28日、ティリーのInstagram（<a href="https://www.instagram.com/tillynorwood/">@tillynorwood</a>）に投稿し、AI俳優の創作意図について次のように述べている。</p>
<p>\u003E “She is not a replacement for a human being, but a creative work — a piece of art.”
「ティリーは人間の代替ではなく、創造的な作品＝ひとつのアートです。」</p>
<p>同氏は、AIを「人間の代わり」ではなく「新しい絵筆のようなツール」と位置づけ、「アニメーションや人形劇、CGIがライブ演技を奪うことなく新しい可能性を開いたように、AIも物語を構築する新たな手段を提供する」と説明した。</p>
<p>\u003E “I’m an actor myself, and nothing — certainly not an AI character — can take away the craft or joy of human performance.”
「私は俳優でもあり、AIキャラクターであっても、人間の演技の技や喜びを奪うことはできません。」</p>
<p>投稿ではさらに、AIを“人間と競わせる存在”ではなく“芸術の新しいジャンルの一部”として評価すべきだと訴えている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/instagram_eline_at_tillynorwood_b80dee2451/instagram_eline_at_tillynorwood_b80dee2451.jpg" alt="instagram eline at tillynorwood.jpg" /></p>
<p>同氏が率いるParticle6は「AI俳優を活用すれば制作コストを最大90％削減できる」と説明し、複数のAIタレントを育てる「デジタル・タレント・ユニバース」構想を掲げている。</p>
<h2>今後の焦点</h2>
<p>各報道や関係者の声明からは、主に次の3点が論点として浮上している。</p>
<ul>
<li>著作権と肖像権：AI俳優の訓練データやモデル構築に使用された素材の扱い</li>
<li>契約・補償問題：AI使用を前提とした俳優契約の新たな枠組み</li>
<li>文化的受容：AIが「演技」を行うことを人々がどう受け入れるか</li>
</ul>
<p>SAG-AFTRAをはじめとする業界団体や俳優たちは、AIが創作活動や雇用に及ぼす影響を注視しており、今後は法制度や契約の整備を含めた議論が進む見通しだ。</p>
]]></description>
      <pubDate>Mon, 20 Oct 2025 07:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>