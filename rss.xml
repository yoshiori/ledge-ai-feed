<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>「AIは5層のケーキ」NVIDIAのフアンCEO、ダボス会議で語ったエネルギーからアプリまでのAI構造</title>
      <link>https://ledge.ai/articles/ai_five_layer_cake_jensen_huang_davos_wef</link>
      <description><![CDATA[<p>NVIDIAのCEOであるジェンスン・フアン氏は、スイス・ダボスで開催された世界経済フォーラム（WEF）年次総会のメインステージに登壇し、AIを<a href="https://blogs.nvidia.com/blog/davos-wef-blackrock-ceo-larry-fink-jensen-huang/">「5層のケーキ」にたとえて説明</a>した。AIを単一の技術としてではなく、エネルギーからアプリケーションに至るまで、複数の層が積み重なって初めて成立する産業基盤として捉える考え方を示した。</p>
<p>この発言は、世界経済フォーラム年次総会（通称ダボス会議）の公式セッション「Conversation with Jensen Huang, President and CEO of NVIDIA」で2026年1月21日（現地時間）に行われたもので、対談相手は米資産運用大手ブラックロックのCEO、ラリー・フィンク氏だった。</p>
<h2>ダボス会議メインステージで示された「5層」の構造</h2>
<p>フアン氏は対談の中で、「AIは5層のケーキのようなものだ」と述べ、次のような層構造を示した。</p>
<ul>
<li><strong>第1層 エネルギー：</strong> AIを動かす前提となる電力供給の層。大規模なAI計算には膨大な電力が必要であり、電力インフラそのものがAI時代の基盤になるとした。</li>
<li><strong>第2層 チップとコンピューティング・インフラ：</strong> GPUなどの半導体や計算基盤の層。AIの性能やスケールを左右する中核で、計算能力の拡張が上位層を支える。</li>
<li><strong>第3層 クラウドおよびデータセンター：</strong> 計算資源を実際に運用・提供するためのシステム全体の層。フアン氏は、ここまで含めて初めてAIの「工場」が成立すると説明した。</li>
<li><strong>第4層 AIモデル：</strong> 大規模言語モデル（LLM）などの基盤モデルが該当する層。下位層の計算資源と密接に結びつきながら進化するとした。</li>
<li><strong>第5層 アプリケーション：</strong> 企業や個人が実際に利用するサービスや業務システムの層。医療、製造、金融など、産業ごとの具体的な活用はこの層で実現される。</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e/Gemini_Generated_Image_mf83p4mf83p4mf83_197c3a0c7e.jpg" alt="Gemini_Generated_Image_mf83p4mf83p4mf83.jpg" /></p>
<h2>「どれか一つ欠けても成立しない」</h2>
<p>フアン氏は、これら5つの層は独立して存在するものではなく、どれか一つが欠けてもAIは社会的・産業的な価値を生み出せないと強調した。特に、モデルやアプリケーションへの注目が集まりがちな一方で、エネルギーや計算インフラといった下位層への投資が不可欠であるとの認識を示した。</p>
<p>WEFも<a href="https://www.weforum.org/stories/2026/01/nvidia-ceo-jensen-huang-on-the-future-of-ai/">公式ストーリー記事</a>で、フアン氏の発言を「AIが次の大規模インフラ構築になる」という文脈で紹介しており、AIを電力網や通信網と同様の基盤産業として捉える視点が、ダボス会議という国際経済・政策の場で共有された形となった。</p>
<p>@<a href="https://www.youtube.com/watch?v=hoDYYCyxMuE&amp;t=160s">YouTube</a></p>
]]></description>
      <pubDate>Mon, 26 Jan 2026 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「中国AIは米国に“数カ月差”」DeepMindのデミス・ハサビスCEO―—追随能力を認める一方、焦点は“フロンティアを越える革新”</title>
      <link>https://ledge.ai/articles/china_ai_months_behind_us_deepmind_hassabis</link>
      <description><![CDATA[<p>GoogleDeepMindのCEOである Demis Hassabis 氏は現地時間の2026年1月15日、CNBCの新ポッドキャスト番組「The Tech Download」に出演し、中国のAI開発についての<a href="https://www.cnbc.com/2026/01/16/google-deepmind-china-ai-demis-hassabis.html">見解を示した</a>。同氏は、中国のAIモデルが米国および西側諸国の最先端モデルに対し、「数カ月程度の遅れ」まで迫っている可能性があると述べた。</p>
<h2>想定より近い位置にある中国AI</h2>
<p>ハサビス氏は、CNBCのインタビューで、中国のAI開発について「1〜2年前に考えられていたよりも、はるかに近い位置にいる」と語り、「現時点では数カ月差かもしれない」と評価した。これは、中国がAI分野で依然として大きく立ち遅れているとする見方とは異なる認識であり、世界のAI競争に対する見方の変化を示すものとなっている。</p>
<p>こうした評価の背景には、中国勢による近年の技術的進展がある。約1年前には、中国のAI研究機関DeepSeekが、比較的制約のある計算資源と低コストで高い性能を示すモデルを発表し、市場に大きな衝撃を与えた。その後も、中国の大手テクノロジー企業やスタートアップが相次いで高性能なAIモデルを公開しており、ハサビス氏は中国企業が既存技術を迅速に追随する能力を示している点を認めている。</p>
<h2>「追随」と「フロンティア突破」は別の課題</h2>
<p>一方で、ハサビス氏は中国のAI開発が最先端に近づいていることを認めつつも、「フロンティアを越える革新」については慎重な見方を示した。同氏は、中国の企業が「非常に近いところまでは到達している」とした上で、「新しいTransformerのように、フロンティアを押し広げる技術を生み出せるかどうかは、まだ示されていない」と述べた。</p>
<p>Transformerは2017年にGoogleの研究者らが発表した技術で、現在の大規模言語モデルの基盤となっている。同氏は、このような根本的な技術革新が生まれるかどうかが、今後のAI競争における重要な分水嶺になるとの考えを示した。</p>
<h2>制約ではなく「研究文化」を重視</h2>
<p>中国企業は、先端半導体へのアクセス制限など、構造的な課題を抱えている。こうした制約についても触れつつ、ハサビス氏は、フロンティア突破の難しさを単なる技術や資源の問題とは捉えていない姿勢を示した。</p>
<p>同氏は、DeepMindを「現代のベル研究所」に例え、既存技術を拡張するだけでなく、探索的で科学的な発明を生み出す研究文化の重要性を強調した。
ハサビス氏の発言は、中国のAIが急速に米国へ接近している現状を認めつつ、競争の焦点が単なる性能差から、次の技術的ブレークスルーを誰が生み出すかという段階へ移行しつつあることを示している。</p>
<p>@<a href="https://www.youtube.com/watch?v=q6fq4_uP7aM">YouTube</a></p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>マスク氏、ダボス会議でロボット量産に言及　人型ロボ「Optimus」一般販売は2027年末までに</title>
      <link>https://ledge.ai/articles/musk_davos2026_optimus_humanoid_robot_sales_2027</link>
      <description><![CDATA[<p>世界経済フォーラム（WEF）の年次総会「ダボス会議2026」で、テスラおよびSpaceXのCEOである イーロン・マスク氏が2026年1月22日、米資産運用大手ブラックロックのCEO ラリー・フィンク 氏との特別対談に<a href="https://www.youtube.com/watch?v=IgifEgm1-e0">登壇</a>した。マスク氏がダボス会議の公式セッションに登場するのは初めてとされる。</p>
<p>対談の中でマスク氏は、テスラが開発を進める人型ロボット「Optimus」について、2027年末までに一般向け販売を開始する見通しを示した。2026年中は工場など産業用途での展開が中心となり、段階的に高度な作業を担わせていくと説明した。</p>
<h2>「ロボットが人口を上回る可能性」に言及</h2>
<p>マスク氏は、人型ロボットの量産が進めば、将来的にロボットの数が人類の人口を上回る可能性があるとの見方を示した。時期については明確に限定しなかったものの、2030年前後を念頭に置いた発言として言及している。</p>
<p>ロボットの普及により、労働の在り方や経済構造が大きく変化する可能性があるとし、ロボットが生産やサービスの多くを担う社会像を描いた。</p>
<h2>AIの進化とインフラ制約</h2>
<p>AIの進化についても触れ、マスク氏は、単一の人間を上回る知能を持つAIは近い将来に登場するとの見通しを示した。さらに、2030年から2031年頃には、AIが人類全体の集合知を上回る可能性があるとも述べた。</p>
<p>一方で、AIの拡大を制約する要因として、計算資源そのものよりも電力供給がボトルネックになるとの認識を示した。AIチップの生産能力は急速に拡大しているものの、電力インフラの成長が追いつかない場合、AIの本格的な普及が制限される可能性があると指摘した。</p>
<h2>エネルギーと宇宙を含めた長期構想</h2>
<p>マスク氏は、AIとロボットを支える基盤として、太陽光発電を中心とした大規模な再生可能エネルギーの拡張が不可欠だと説明した。加えて、将来的には宇宙空間にデータセンターを配置することで、発電効率や冷却効率の面で優位性が生まれる可能性にも言及した。</p>
<p>今回の対談は、AIとロボットの進展が経済や社会に与える影響を議論する場となった。人型ロボットの一般販売時期に具体的な言及があったことで、テスラのロボット戦略と社会実装の時間軸がより明確になった形だ。</p>
]]></description>
      <pubDate>Sun, 25 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Adobe、Acrobatに「プレゼン生成」「ポッドキャスト生成」「自然言語PDF編集」──Acrobat Studioで提供開始（英語版）</title>
      <link>https://ledge.ai/articles/adobe_acrobat_studio_ai_presentation_podcast_pdf_edit</link>
      <description><![CDATA[<p>Adobeは2026年1月21日（米国時間）、PDFとコンテンツ制作を統合する「Adobe Acrobat Studio」において、生成AIを活用した3つの新機能の提供を<a href="https://blog.adobe.com/jp/publish/2026/01/26/dc-work-smarter-acrobat-turn-docs-presentations-podcasts-edit-pdfs-ai">開始</a>した。新たに追加されたのは、「プレゼンテーションを生成」「ポッドキャストを生成」「自然言語によるPDF編集」の各機能で、文書を起点にした情報活用とアウトプット作成を効率化する。これらの機能は、現時点では英語版で利用可能としている。</p>
<h2>文書からスライドを自動作成する「プレゼンテーション生成」</h2>
<p>新機能の「プレゼンテーションを生成」は、PDFや関連資料をもとに、AIが内容を整理し、プレゼンテーション用のアウトラインを自動作成するものだ。ユーザーは生成前にアウトラインを確認し、長さやトーンを調整したうえでスライド化できる。</p>
<p>入力データには、Acrobat内の「PDF スペース」に追加した文書ファイルやリンクを利用でき、財務報告書、製品仕様書、競合分析資料、Webページなど複数の情報源をまとめて扱える。生成されたスライドは、Adobe Expressと連携し、テンプレートやデザインライブラリを活用しながら、画像の差し替えや動画の追加、フォント変更などの編集が可能だ。これにより、デザインの専門知識がなくても、短時間で体裁の整ったプレゼン資料を作成できるとしている。</p>
<h2>長文資料を音声で要約する「ポッドキャスト生成」</h2>
<p>「ポッドキャストを生成」は、文書内容をAIが要約し、音声コンテンツとして出力する機能だ。PDF スペースに追加したメモ、文字起こし、数百ページ規模のレポートなどを対象に、AIアシスタントへ要約を依頼すると、ポッドキャスト形式の音声が生成される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c/media_18964bee91bcdcb676c009037bc19e7eba3f8275d_c2f37df79c.jpg" alt="media_18964bee91bcdcb676c009037bc19e7eba3f8275d.jpg" /></p>
<p>会議資料の事前把握や移動中の情報収集、学習用コンテンツの音声化などを想定しており、読む時間が確保しづらい場面でも、文書の要点を把握できる手段として位置づけられている。</p>
<h2>チャットで操作できる「自然言語によるPDF編集」</h2>
<p>3つ目の新機能である「自然言語によるPDF編集」では、チャット形式のAIインターフェースを通じて、PDFの編集操作を行える。ユーザーは自然言語で指示を入力するだけで、ページやテキスト、コメント、画像の削除、電子署名の追加、パスワード設定などの基本的な編集作業を実行できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02/media_106fc491d70ca3f2de8116afcbc18a917ceafb64b_926d791d02.jpg" alt="media_106fc491d70ca3f2de8116afcbc18a917ceafb64b.jpg" /></p>
<p>あわせてヘルプ機能も強化されており、操作方法の案内やトラブルシューティングをチャット形式で受けられるようになった。従来のメニュー操作に不慣れなユーザーでも、直感的にPDF編集が可能になるとしている。</p>
<h2>「PDF スペース」を軸にした共同作業を強化</h2>
<p>これらの新機能は、Acrobat Studioに統合された共有ワークスペース「PDF スペース」を中心に提供される。PDF スペースでは、ファイルの整理やインサイト抽出に加え、招待したメンバーが資料を追加したり、メモやコメントを残したりできる。生成AI機能と組み合わせることで、個人作業だけでなく、チームでの資料準備やレビューの効率化を狙う。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>フィールズ賞のテレンス・タオ氏、「GPT-5.2 Proが数学の未解決問題をほぼ自律的に解き切った」と評価──エルデシュ問題#728で示されたAIの新たな到達点</title>
      <link>https://ledge.ai/articles/ai_autonomous_solution_erdos_problem_728</link>
      <description><![CDATA[<p>AIが数学の未解決問題を「ほぼ自律的に解き切った」と、数学者が評価した。著名な数学者であるテレンス・タオ氏が2026年1月8日、分散型SNS「Mathstodon」への投稿で、エルデシュ問題の一つである #728 が、AIツールによって「more or less autonomously（ほぼ自律的に）」解かれたと<a href="https://mathstodon.xyz/@tao/115855840223258103">述べた</a>。</p>
<p>この成果についてタオ氏は「私たちの知る限り、既存の文献では再現されていない」としたうえで、近年のAIツールの能力向上を示す「節目（milestone）」だと位置づけた。</p>
<h2>エルデシュ問題とは</h2>
<p>エルデシュ問題は、20世紀を代表する数学者ポール・エルデシュが提起した数多くの問題をもとに整理された、数学の未解決問題群を指す。現在も多くの問題が未解決のまま残されており、世界中の数学者が長年にわたって取り組んできた。</p>
<p>今回タオ氏が言及した エルデシュ問題#728 は、その中の一つで、問題の内容や背景はエルデシュ問題の<a href="https://www.erdosproblems.com/728">公式サイト</a>で公開されている。</p>
<p>未解決問題は、数学界において特別な位置づけを持つ。解決に至れば理論的に重要な意味を持つだけでなく、長年の研究の蓄積を塗り替える可能性があるためだ。</p>
<p><strong>■ ポール・エルデシュ（左）と、当時10歳のテレンス・タオ。1985年撮影。</strong> エルデシュ問題は、エルデシュ自身が提起した未解決問題群に由来する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Paul_Erdos_with_Terence_Tao_952867730e/Paul_Erdos_with_Terence_Tao_952867730e.jpg" alt="Paul_Erdos_with_Terence_Tao.jpg" /></p>
<h2>GPT-5.2 Proと人間の役割分担</h2>
<p>証明には、OpenAIの大規模言語モデル GPT-5.2 Pro が用いられた。人間側は、計算環境の整備や初期試行へのフィードバック、結果の検証、形式的な証明への整理といった役割を担ったとされる。</p>
<p>AIが完全に単独で問題を解決したわけではないものの、思考の主導権がどこにあったのかが、今回の評価における重要なポイントとなった。</p>
<p><strong>■ 「ほぼ自律的に」解いた、という表現</strong>
従来、AIは数学分野において計算の高速化や文献探索、発想の補助といった役割を担ってきた。一方で今回のケースでは、問題の解釈から解法の構築、証明に至るまでの過程をAIが主導したと評価された。</p>
<p>タオ氏によれば、AIは初期の試行に対する一定のフィードバックを受けた後、問題の趣旨に沿った形で解決に到達したという。この点が、「ほぼ自律的」という表現につながった。</p>
<h2>「解決以上に興味深い点」</h2>
<p>タオ氏は今回の投稿で、解決結果そのものに加え、「それ以上に興味深い点がある」とも述べている。投稿では、</p>
<p>「より興味深いのは、解法の説明（exposition）を迅速に書き、書き直し、再構成するAI主導の能力が現れつつある点だ」
と指摘し、証明文書の作成や改稿をめぐるAIの能力向上に言及した。</p>
<p><strong>■ テレンス・タオ氏がMathstodonに投稿したエルデシュ問題#728に関する発言。AIが「ほぼ自律的に」問題を解いたと評価している。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/terencetao_mathstodon_b05b8af4d5/terencetao_mathstodon_b05b8af4d5.jpg" alt="terencetao mathstodon.jpg" /></p>
<p>従来、数学論文の執筆や大幅な改稿には多大な時間と労力が必要だったが、AIによる文章生成と形式証明ツールを組み合わせることで、説明文を用途や読者に応じて柔軟に作り直すことが可能になりつつあるという。</p>
<h2>他のAI解決事例との位置づけ</h2>
<p><strong>■ エルデシュ問題を巡るAI活用事例を整理した公式Wikiの一部。#728は、AIによる解決後に類似文献が確認されたケースとして位置づけられている。</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/github_erdos_problem_058007f757/github_erdos_problem_058007f757.jpg" alt="github erdos problem.jpg" /></p>
<p>タオ氏自身も、AIによるエルデシュ問題の解決例の多くでは、後に類似の結果が既存文献で確認されてきたと説明している。#728についても、問題文の再構成が比較的最近まで行われていなかったことが、先行研究が見当たらなかった理由の一つだとされている。</p>
<h2>数学とAIの関係に生じた変化</h2>
<p>今回の発言は、AIが数学者の役割を代替したことを示すものではない。一方で、未解決問題を対象とした成果について、数学者がAIの関与を明示的に評価し、その能力の到達点を具体的に言及した点は確認できる事実である。エルデシュ問題#728をめぐる今回の事例は、AIの活用がどの段階まで進んでいるのかを示す一例として位置づけられ、今後、同様の評価が他の問題や分野でも示されるかどうかが注目される。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>中国AIテック、オープンソース推論モデルを相次ぎ公開──Alibabaが「Qwen3-Max-Thinking」、Moonshot AIは「Kimi K2.5」発表</title>
      <link>https://ledge.ai/articles/china_ai_open_source_reasoning_models_qwen3_max_thinking_kimi_k2_5</link>
      <description><![CDATA[<p>中国のAIテック企業が、推論能力を前面に打ち出したオープンソース大規模言語モデル（LLM）を相次いで公開している。</p>
<p>Alibabaは2026年1月26日、同社の「Qwen」シリーズにフラッグシップ推論モデル「<a href="https://qwen.ai/blog?id=qwen3-max-thinking">Qwen3-Max-Thinking</a>」を追加した。続く27日には、中国のAIスタートアップであるMoonshot AIが、生成AIサービス「Kimi」の新モデルとして「<a href="https://www.kimi.com/blog/kimi-k2-5.html">Kimi K2.5</a>」を発表した。</p>
<h2>Alibaba、推論特化のオープンソースLLM「Qwen3-Max-Thinking」を公開</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Qwen3_Max_Thinking_a4f4c3f239/Qwen3_Max_Thinking_a4f4c3f239.jpg" alt="Qwen3-Max-Thinking.jpg" /></p>
<p>Alibaba傘下のQwen開発チームは2026年1月26日、同社が開発する大規模言語モデル「Qwen」シリーズの新モデルとして、「Qwen3-Max-Thinking」を<a href="https://qwen.ai/blog?id=qwen3-max-thinking">発表</a>した。公開した。</p>
<p>同モデルは、モデル規模の拡大と大規模な強化学習を組み合わせることで、知識量、複雑な推論能力、指示追従性、人間の嗜好との整合性、エージェント機能など複数の側面で性能を高めたとしている。</p>
<p>Qwenチームによると、19の既存ベンチマークにおいて、GPT-5.2-ThinkingやClaude Opus 4.5、Gemini 3 Proと同等水準の性能を示したという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/score_c57592148d/score_c57592148d.jpg" alt="score.jpg" />
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/qwen3_max_bench_a596df956e/qwen3_max_bench_a596df956e.jpg" alt="qwen3 max bench.jpg" /></p>
<p>また、必要に応じて検索やコード実行を自律的に呼び出す適応的なツール利用機能を備え、Qwen Chat上で利用可能としている。推論時に追加計算を割り当てるテスト時スケーリング手法も導入し、複数の推論系ベンチマークで性能向上を確認したとしている。</p>
<p>Qwen3-Max-Thinkingは、Qwen ChatおよびAPIを通じて提供されており、オープンソースモデルとして公開されている。</p>
<h2>Moonshot AI、オープンソース推論モデル「Kimi K2.5」発表</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Kimiai_704db61aa9/Kimiai_704db61aa9.jpg" alt="Kimiai.jpg" /></p>
<p>Moonshot AIは2026年1月27日、同社が提供する生成AIサービス「Kimi」の新たな基盤モデルとして、「Kimi K2.5」を<a href="https://www.kimi.com/blog/kimi-k2-5.html">発表</a>した。</p>
<p>同社はKimi K2.5を、視覚理解と推論、エージェント機能を統合した「オープンソースのVisual Agentic Intelligence」と位置づけている。</p>
<p>同社の公式Xアカウントによると、Kimi K2.5はエージェント関連ベンチマークにおいて、HLE（full set）で50.2%、BrowseCompで74.9%のスコアを記録したという。また、視覚理解やコード生成に関する評価では、MMMU Proで78.5%、VideoMMMUで86.6%、SWE-bench Verifiedで76.8%を示し、オープンソースモデルとして最高水準の性能だとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f/G_p_Ua_Plao_A_Aa9as_b13b4a4d7f.jpg" alt="G_pUaPlaoAAa9as.jpg" /></p>
<p>Kimi K2.5の特徴として、最大100のサブエージェントを自律的に生成・統括する「Agent Swarm」機能を挙げている。複数のエージェントが並列に最大1,500回のツール呼び出しを行うことで、単一エージェント構成と比べて処理速度が最大4.5倍向上するとしている。Agent Swarmは現在ベータ版として提供されている。</p>
<p>Kimi K2.5は、KimiのWeb版およびアプリで利用可能で、チャットモードとエージェントモードをサポートする。APIも提供されており、同社は本番環境でのソフトウェア開発用途として、開発者向けツール「Kimi Code」との併用を推奨している。モデルの重みとコードはHugging Face上で公開されている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>スマートファクトリーの未来を描く――デロイト トーマツ×NVIDIA×デル・テクノロジーズが語った最新潮流</title>
      <link>https://ledge.ai/articles/deloitte_tohmatsu_innovation_park</link>
      <description><![CDATA[<p>12月3日、丸の内「Deloitte Tohmatsu Innovation Park」にてスマートファクトリー共同セミナーが開催された。当日は主催の合同会社 デロイト トーマツのほか、エヌビディア合同会社（NVIDIA）やデル・テクノロジーズ株式会社、シュナイダーエレクトリックホールディングス株式会社、アルテアエンジニアリング株式会社、パロアルトネットワークス株式会社といった、スマートファクトリー関連企業から担当者が登壇。製造業が抱える課題と、スマートファクトリー化に向けたさまざまな提言を行った。
本記事ではその中から、デロイト トーマツの芳賀氏、NVIDIAの高橋氏、デル・テクノロジーズの比留間氏、水口氏による講演をレポートする。</p>
<h2>デロイト トーマツが語るSDMと製造業の変革ポイント</h2>
<p>芳賀氏はまず、製造業が直面する2025年に向けた課題として、「地政学リスクへの対応で複雑さを増すグローバルビジネス」「労働力人口が減少する中、製造業を支える新たな人員体制の必要性」「AIテクノロジーの進化スピードへの適応が競争力を左右すること」を挙げた。</p>
<p>特にAIの進化は製造業に大きなインパクトをもたらしており、現場データをいかに価値創造やイノベーションに活用していくかが重要だと指摘する。また、中国をはじめとする新興国の製造業におけるデジタル活用の動きにも危機感を示し、日本の製造業もスピード感を持ってキャッチアップしていかなければならないと強調した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1_e1aeeee499/1_e1aeeee499.jpg" alt="1.jpg" /></p>
<p>製造業へのデジタル活用といえば、本イベントのテーマでもある「スマートファクトリー」が注目されている。しかし、芳賀氏によると「目的別のITと設備・組織別のOTは相容れない考え方」とのことで、両者の統合にはまだ課題が多いという。</p>
<p>そのような製造領域のデジタル化における複雑性を解消する鍵となるのが「ソフトウェア・デファインド・マニュファクチャリング（SDM）」だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_4b4a0a1b81/2_4b4a0a1b81.png" alt="2.png" /></p>
<p>「SDMは仮想化テクノロジーをベースにした柔軟かつオープンなテクノロジーで、自由度の高い管理を実現しています。たとえばSDVがそうです。物理的に実現した機能を電子的に変更するだけでなく、ソフトウェア上でのシミュレーションを通じて機能や性能を高め、それを物理世界に落とし込むサイクルが重要です」（芳賀氏）</p>
<p>こうしたデジタル空間における物理世界の再現は、これまでにも議論されてきた話題ではある。しかし、それらの取り組みは“再現”で終わることが多く、その先にあるイノベーションに結びつくことが少なかった。</p>
<p>その理由の一つとして芳賀氏が挙げるのは、工場内にある設備機器や人の仕事がまだ本当にモデル化されているとは言えないことだ。タクトタイムやチョコ停、品質など、さまざまな要素をモデル化し、あらゆる設定や配置の中でシミュレーションする。そこから新たな課題を発見し、改善する。こうしたプロセスが重要になると芳賀氏は語った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_f35b4a1e1d/3_f35b4a1e1d.jpg" alt="3.jpg" /></p>
<p>続いてSDMを支える技術的なアーキテクチャについても解説があった。芳賀氏によると、SDMは従来のデータベースとデータの標準化による連携ではなく、AIの機能を活用した連携がポイントになるという。</p>
<p>「特にフィジカルAIでは、上位システムからの指示を現場の制御系機器やデバイス制御に落とし込んだ上で、実際の制御データと実績のフィードバックを組み合わせ、物理法則も理解しながらモデルをチューニングしていくことが重要です」（芳賀氏）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4_891ddf14bf/4_891ddf14bf.png" alt="4.png" /></p>
<p>このように、ドメインごとの業務マネジメントの仕組みをAIエージェントが管理し、人の要求に対してシステムが自動的に調整を行う動きが今後は一般的になっていくだろう。</p>
<p>芳賀氏はさらに、現場で発生するさまざまな出来事に対して必要なデータを紐づけ、「現場の事実情報」として構造化する考え方を提示した。</p>
<p>たとえば品質エラーが発生した際、単なるエラーコードだけでなく、設備、製品、部品、環境条件、オペレーター情報などを含めた5W1Hを確認することで初めて原因特定が可能になるわけだ。</p>
<p>現在はデータレイクから情報を取り出して加工しなくても、ストリーミングで上がってくるデータを加工してアノテーションできる時代になっている。こうした取り組みを通して、データを意思決定に活用できるようにしていくことがポイントなのだ。</p>
<p>また、芳賀氏はAIがデータの範囲内で答えを出す一方で、人間がAIの問いに対して現場を見ながら最適な判断をして新しい仮説を創造する役割分担が重要だと強調。日本の製造業における競争力の源泉である「変更点管理」「なぜなぜ分析」「横展開」といった改善活動について、AIを活用して支援する「活動・意思決定モデル」の構築を提案した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/5_0613a158d8/5_0613a158d8.png" alt="5.png" /></p>
<p>芳賀氏は最後に「新興国が投資だけでなく、製品の進化や品質向上のスピードでも勝負をかけてきている」と指摘。日本の製造業全体の競争力を維持するために、SDMの導入が必要だとあらためて訴えた。</p>
<p>SDMはツールでも目的でもなく、大きな変革の流れそのものであり、事業課題を解決する切り口として欠かせない考え方だ。人の役割や価値が変わっていく中で、現場を支えるワーカー、そしてグローバルなデジタル人材の重要性はさらに増していくだろう。</p>
<h2>フィジカルAIとデジタルツインがもたらす新しい工場の形</h2>
<p>続いて登壇したのは、NVIDIAのデジタルツイン開発プラットフォーム「Omniverse」のビジネス開発を担当する高橋氏だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_7f6f83f2c8/7_7f6f83f2c8.jpg" alt="7.jpg" /></p>
<p>高橋氏はまず、フィジカルAIの定義について「物理空間を認識・理解し、正しいアクションを導き出すAI」と説明、「入力された映像やテキストに対して、ロボットの動作や自動運転車両の制御、工場設備の全体最適化などを行うAIモデル」と位置づけた。</p>
<p>このフィジカルAIを作るための3つのコンピューティングリソースが、「AIの学習環境」「ロボットや自動運転車両などのAGX」「シミュレーション/デジタルツイン」である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/8_96bfab254f/8_96bfab254f.png" alt="8.png" /></p>
<p>このうち本講演で高橋氏が深堀りするのが「シミュレーション/デジタルツイン」だ。仮想空間でデータを取得するデジタルツインは、発生頻度が低い事象や危険を伴う状況、効率的にデータを取得できないケースなどにおいて有効な手法となる。</p>
<p>NVIDIAが提供するデジタルツイン開発プラットフォーム「Omniverse」は、物理ベースのビジュアライゼーション、リアルタイムコラボレーション、生成AIの統合、ロボットトレーニングといった機能を持ち、自動車会社や製造業、工場、物流倉庫などで活用され始めているという。</p>
<p>さらに高橋氏が紹介するのがNVIDIAの世界基盤モデル開発プラットフォーム「Cosmos」。これは物理的に正しい動画データを生成する基盤モデルであり、プロンプトからのデータ作成や、最初のフレームから次の動きを予測する機能などを搭載している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9_c9fd4faaa1/9_c9fd4faaa1.png" alt="9.png" /></p>
<p>これらのサービスを活用して企業はさまざまなアプリケーションを開発するわけだが、とはいえゼロから取り組むのは簡単ではない。そこでNVIDIAでは「Isaac GR00T」「Metropolis VSS」という二つのBlueprintを用意している。</p>
<p>「GR00Tはヒューマノイドロボットの学習データを作成するBlueprintであり、Cosmosと組み合わせることで3Dデータの質感や環境情報をもとにバリエーション豊かな合成モーションを作成できます」（高橋氏）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/10_340f853192/10_340f853192.jpg" alt="10.jpg" /></p>
<p>ただし、ヒューマノイドロボットを動かしてデータを作成するのは、オペレーターのリソースの都合もあり簡単ではない。そこでGR00Tではデータを水増しして、効率的に学習データを作るというアプローチをとっているという。</p>
<p>「GR00Tを使えば、数十パターンの人間の動きを数百まで簡単に増やすことができます。従来ならオペレーターが8時間もかけて行っていたデータ収集を効率化し、AIの学習を進めることができます」（高橋氏）</p>
<p>さらにVSS（Video Search and Summarization）というAIエージェントを活用することで、工場や物流倉庫のカメラ映像データなどから多くの洞察を得られるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/11_7782a14095/11_7782a14095.png" alt="11.png" /></p>
<p>たとえばバスケットボールの試合の映像を分析して、シュートの確率が高い選手を見つけたり、高所作業でハーネスを着用しているかチェックしたりといった活用が可能になるのだ。</p>
<p>講演ではこれらのBrueprintを活用した事例も紹介された。具体的にはNVIDIAの新工場における機器レイアウトの最適化やロボットシミュレーション、自動搬送ロボットの経路最適化などに活用されているという。</p>
<p>また、IoTセンサー情報をデジタルツインに紐づけることで、機器の稼働状況や問題発生時のエラー情報をリアルタイムに確認でき、担当者が現場に向かう前に状況を把握できるメリットがあるとのことだ。たとえば医薬品業界では処方に合わせた薬剤調合ロボットのシミュレーションや、実験室で創薬を行う際のレイアウト検討に活用されている。</p>
<h2>NativeEdgeが支えるスマートファクトリーのインフラ基盤</h2>
<p>最後に紹介するのはデル・テクノロジーズで「NativeEdge」のビジネス開発を担当する比留間氏の講演だ。</p>
<p>比留間氏はまず、「エッジデバイスの増加に伴って、現場（エッジ）でのデータ収集とリアルタイム利活用の重要性が増している」点を強調する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/13_ca517aae7b/13_ca517aae7b.jpg" alt="13.jpg" /></p>
<p>これまではオンプレミスからクラウドへのデータの流れが主流だったが、今後はエッジや小規模な分散データセンターにデータが集約されていくことが予測されるのだ。</p>
<p>ただし、エッジや分散データセンターには独自の課題がある。</p>
<p>「たとえば工場内に分散配置されるデバイスの運用管理、IT専任者がいない場所でのサポート、セキュリティの確保、ソフトウェアの継続的な運用管理などです」（比留間氏）</p>
<p>これらの課題に対応するのが、「エッジ」と「分散データセンター」にフォーカスしたデル・テクノロジーズのソフトウェアプラットフォームが「NativeEdge」である。</p>
<p>NativeEdgeの主な機能はふたつ。まず、管理マネージャーからハードウェアデバイスを遠隔で管理できるオーケストレーター機能、そしてハードウェア上のアプリケーションを一括配信できる機能である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/14_ce3fa0a66e/14_ce3fa0a66e.png" alt="14.png" /></p>
<p>さらに、NativeEdgeはブループリント機能も備えている。通常、アプリケーションを導入する際はOSを導入し、ネットワークストレージを設定し、アプリケーションをインストールするといった手順が必要だ。</p>
<p>この導入手順を一つのファイルで作成したものがブループリントであり、一括でデプロイメントできる仕組みになっているのだ。</p>
<p>そして、NativeEdge最大の特徴ともいえるのが「ゼロタッチプロビジョニング」機能である。</p>
<p>「これにより、サーバーやエッジデバイスを現地に直送し、お客様が電源ケーブルとLANケーブルを接続して電源を入れるだけで、あとはすべてオーケストレーターから一括で設定できるようになります」（比留間氏）</p>
<p>NativeEdgeの登場により、従来のようにIT専任者が各拠点を訪問してOSやアプリケーションを導入するのではなく、よりスマートに遠隔で一括配信する導入プロセスが定着していきそうだ。</p>
<p>比留間氏はNativeEdgeの仕組みについて、「各エッジデバイスにNativeEdge OSというカスタマイズされたSOSがインストールされており、Hypervisorとして使用できる」と説明。ユーザーはその上に仮想マシンやコンテナアプリケーションをデプロイできるわけだ。</p>
<p>さらにNativeEdgeはクラスタリング機能も備えており、1台のデバイスが故障してもサービスを継続できる冗長性も確保できるという。</p>
<p>比留間氏はNativeEdgeの全体像についても解説した。それによると、デバイス単体での使用だけでなくHCIとしても利用できるほか、各デバイスにストレージを接続して大容量ボリュームを確保することも可能とのことだ。また、基本的にデル製品に特化しているが、他社製品においても一部機能の制約はあるものの利用可能だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/15_e03a199dea/15_e03a199dea.png" alt="15.png" /></p>
<p>次にNativeEdgeのセキュリティについて、比留間氏は「ゼロトラストの考え方に基づいて構成されている」と説明する。</p>
<p>具体的にはデバイスのオンボーディング時には「バウチャー」と呼ばれる秘密鍵を使用して認証を行うほか、物理的なセキュリティとして、デバイスの外部端子は基本的にすべて無効化されているという。外部端子を使用する際は、オーケストレーターからの設定で、必要なポートのみを仮想マシンに許可するわけだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/16_579ec65445/16_579ec65445.png" alt="16.png" /></p>
<p>「NativeEdgeはさまざまなセキュリティ機関の厳しい審査をすべてパスしており、セキュアにお使いいただける環境をご提供しています」（比留間氏）</p>
<p>続いて比留間氏は、デル・テクノロジーズとNVIDIAによる「Dell AI Factory with NVIDIA」ソリューションについても紹介した。</p>
<p>これはデジタルアシスタントなどのユースケースに対して、サーバー、ネットワーク、ストレージといったインフラストラクチャーと、NVIDIAのソフトウェアプラットフォーム、デル・テクノロジーズの構築サービスを一つのパッケージとして提供するものだ。Tシャツのサイズ（S、M、Lなど）のように簡単に選べる形で提供されているため、AIを始めてみたい企業には最適なソリューションと言える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/17_493df32d54/17_493df32d54.png" alt="17.png" /></p>
<p>ここで登壇者が比留間氏から、インフラストラクチャー・ソリューション営業統括本部の水口氏にチェンジ。エッジ向けに開発されたサーバー「XR」シリーズについて説明を行った。</p>
<p>XRサーバーは専用フィルターを持っており、人の多い場所でも使用できるほか、マイナス5度から55度までの環境に耐えられる特性を持っている。当然、あらゆる工場で安定して使用できるわけだ。</p>
<p>また、T160、R260、R360といった通常のサーバーにフィルターをつけることで、エッジ環境で使用することも可能だという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/19_5c6844a120/19_5c6844a120.png" alt="19.png" /></p>
<p>「ぜひサーバーが必要なときは、我々にお声がけをいただければと思います」（水口氏）</p>
<p>最後に水口氏が紹介したのは、デル・テクノロジーズとシュナイダーとの取り組みである「IT×OTフュージョンプロジェクト」だ。</p>
<p>PLC（プログラマブルロジックコントローラー）のパイオニアでOTのプロフェッショナルであるシュナイダーと、サーバーを作れるITの専門家であるデル・テクノロジーズが協力し、問い合わせから提案、導入、サポートまでの一連のプロセスを共同で行う。これにより、顧客の負担を減らすことを目的とした取り組みである。20年以上のビジネス関係がある両社ならではの協業と言えるだろう。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20_17a184b1b4/20_17a184b1b4.png" alt="20.png" /></p>
<p>イベント後は、会場であるDeloitte Tohmatsu Innovation ParkのThe Smart Factory by Deloitte @ Tokyoの見学も行った。</p>
<p>The Smart Factory by Deloitte @ Tokyoにはデル・テクノロジーズのPowerEdgeサーバーと、シュナイダーのバーチャルPLCが展示されており、実際に装置のデータを収集・分析するところを体感することができる。</p>
<p>国内でもまれな“ミニスマートファクトリー”を実機で体験できる施設なのだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/21_9196a35396/21_9196a35396.jpg" alt="21.jpg" /></p>
<p>本イベントを通して、日本の製造業の現状と課題、そしてスマートファクトリーの展望が伺えた。単にデジタルツールを導入するだけではない、真のトランスフォーメーションに向けて、大きなヒントが得られたイベントだったのではないだろうか。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/22_603e1c1515/22_603e1c1515.png" alt="22.png" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>日本発ヒューマノイド「cinnamon 1」初公開　ドーナッツロボティクス、無言で操作できる特許技術も発表</title>
      <link>https://ledge.ai/articles/donut_robotics_cinnamon1_humanoid_silent_gesture</link>
      <description><![CDATA[<p>ヒューマノイド開発に取り組むスタートアップ、ドーナッツロボティクスは2026年1月21日、日本ブランドのヒューマノイド『cinnamon 1（シナモン ワン）』を<a href="https://prtimes.jp/main/html/rd/p/000000041.000057944.html">発表</a>した。二足歩行が可能な量産型ヒューマノイドとして、同社は2026年内の市場投入を目指す。</p>
<h2>二足歩行の量産ヒューマノイド、年内投入を目標に</h2>
<p>「cinnamon 1」は、同社が保有する特許技術を搭載した二足歩行のヒューマノイドロボットだ。現時点では海外企業から提供された機体をベースに、独自開発のAIを搭載している。将来的には、機体も含めた国産ヒューマノイドの実現を目指すとしている。</p>
<p>AIには、視覚情報・言語理解・行動を統合する「Vision-Language-Action（VLA）」の概念を取り入れる予定で、人の指示を理解し、自律的に行動するロボットの開発を進める。</p>
<h2>声を出さずに指示できる「サイレント ジェスチャー コントロール」</h2>
<p>同社はあわせて、手振りや指の動きだけでロボットに指示を伝える特許技術「サイレント ジェスチャー コントロール」を発表した。音声を使わずに操作できる点が特徴で、同社はこの技術を搭載したヒューマノイドとして「世界初」としている。</p>
<p>騒音の大きい工場や建設現場、声を出しにくい家庭環境などでの利用を想定しており、難聴者が多い環境でも使いやすい技術として位置づけている。</p>
<h2>工場・建設現場での作業代替を想定</h2>
<p>ドーナッツロボティクスは、2026年内に工場内や建設現場での作業代替を進める計画を示している。2025年10月には、建築関連事業を手がける株式会社エムビーエスと資本業務提携を発表しており、建設業界での活用を見据える。</p>
<p>また、VLA開発を支える国内データセンターの設立構想にも言及しており、ヒューマノイド開発を軸にしたAI基盤づくりを進める方針だ。</p>
<p>YouTube動画を引用する場合　　　
@<a href="https://www.youtube.com/watch?v=1vBI0GYjAKM">YouTube</a></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AI活用の“壁”を突破する鍵はエッジにあり──デル・テクノロジーズが描く「分散型エージェントとハイブリッドAI」の未来</title>
      <link>https://ledge.ai/articles/edgetechplus20251121</link>
      <description><![CDATA[<p>生成AIはすでに私たちの生活に浸透しつつある一方で、ビジネスの現場では「スキル不足」「セキュリティ」「データのサイロ化」などが障壁となり、本格活用に踏み切れない企業も少なくない。</p>
<p>11月21日にパシフィコ横浜で開催された展示会「EdgeTech+」では、AI Elite(AIエリート)としてアジア太平洋地域のAI戦略を担う増月氏が登壇し、ビジネスにおけるAI活用の突破口は「クラウド」から「エッジ」への発想転換にあると語った。</p>
<p>本記事では、識別型AIと生成AIを組み合わせたハイブリッドコンピューティングモデルや分散型エージェント、さらに「Dell AI Factory with NVIDIA」、および、「Dell NativeEdge」によるエッジAI戦略について、同氏の講演内容をもとにひもといていく。</p>
<p>::: box
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_b53adeff8b/2_b53adeff8b.jpg" alt="2.jpg" />
デル・テクノロジーズ株式会社
インフラストラクチャー・ソリューションズSE統括本部
AIプラットフォーム・ソリューションズ
シニア システム エンジニア | AI Elite
CTO Ambassador
増月 孝信 氏</p>
<p>国内大手電機メーカの研究所にてAI研究職を経て、外資ITベンダーにてOS、ミドルウエア、データセンタなど幅広い分野で技術職, 技術マーケティングおよび製品企画を経験。過去に Java, OpenSolaris, OpenStack などOSSコミュニティーの幹事として貢献。2011年デル株式会社(現デル・テクノロジーズ株式会社)へ入社。
現在はAIソリューションのビジネス開発を担当。2023年にCTO Ambassadorを拝命。
:::</p>
<h2>AI活用は進みつつあるがビジネスでは課題も多い</h2>
<p>増月氏はデル・テクノロジーズでAI Eliteとして活躍する人物だ。AI Eliteはその名の通りデル・テクノロジーズのAIスペシャリストから選出認定された役職で、全世界でも20名弱しかいない。AI Eliteは同社のAIに関するビジネスに深く関わっており、増月氏もアジア・パシフィック地域におけるAI戦略を担当しているという。</p>
<p>そんなデル・テクノロジーズが近年注力するのが「エッジAI」である。これはクラウドではなく、PCのような端末で動作するAIのこと。クラウド型のAIとは対極的な特徴を持っており、今後需要がさらに高まることが予想されている。</p>
<p>本講演の主題ともいえるエッジAIについて語る前に、増月氏はまずAI活用の現状について説明を行った。</p>
<p>調査によると、現在「何らかの形で生活の中で生成AIを使用している」人は80％に達しており、さらに「仕事に使ったことがある」人も63％に上っている。すでにAIは人々の生活に溶け込んでいると言えるのだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/3_4bee902b23/3_4bee902b23.png" alt="3.png" /></p>
<p>一方で、ビジネスの現場でのAI活用については課題も見えてきたと増月氏は話す。</p>
<p>「一番の課題はAIのスキルです。調査によると組織の41％が従業員の専門知識やスキルがAIの導入に課題であると回答しています」</p>
<p>そしてもう一つの大きな課題がAIにおけるセキュリティの問題だ。アンケートでは組織の73％が「データのプライバシーとセキュリティが生成AIを使用する際に懸念されるリスク」と回答している。</p>
<p>「外部からのサイバー攻撃もAIによって高度化しており、社内にAIを導入するしないとは関係ないところでのAIリスクも考えられます」</p>
<p>さらに増月氏は「データそのものがAI活用の課題になっている」とも指摘する。</p>
<p>「皆さん、AIのモデルや分析プラットフォームなどは非常に考えているのですが、そもそもデータが整っていないと成果はまったく上がりません。データにもっと投資して、うまく使える状態にしなければならないのです」</p>
<h2>レイテンシーやセキュリティ面でエッジAIの重要度は高い</h2>
<p>データに関する課題としてよく語られるのがサイロ化の問題だ。コーポレートシステムにおけるデータウェアハウスやトランザクションデータ、事業や部門に蓄積された製品や顧客のデータ、さらに支社や関連会社に存在する様々なビジネスデータ――こうしたデータが分断されていてはAIによる成果も期待できない。</p>
<p>またサイロ化という点で何よりも「置いてきぼりになっている」のが、まさに「エッジ」のデータだと増月氏は述べる。</p>
<p>「実際のデータが生成される場所というのは、クラウドやデータセンターの中ではなく、エッジなのです。たとえば皆さんが持っている携帯電話、あるいは製造や医療などの現場で発生するデータの方が、クラウドやデータセンターのデータよりも重要度が高い場合もあります」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/4_10389fe9ec/4_10389fe9ec.jpg" alt="4.jpg" /></p>
<p>だからこそ、デル・テクノロジーズは今「エッジAI」に着目しているというわけだ。</p>
<p>エッジAIには他にも様々なメリットがある。</p>
<p>たとえばローカル処理を行うことによるレイテンシーの短縮だ。仮に製造現場で生成された画像データを処理するのにいちいちクラウドやデータセンターに送信していては遅延が発生し、意思決定に遅れにつながる恐れがある。また何らかの問題でネットワークが機能しなくなると、処理自体が行えなくなってしまう。</p>
<p>またセキュリティについてもメリットは大きい。エッジAIなら重要な機密情報をクラウドに送信することなく端末内で処理できるわけだから、情報漏洩にもつながりにくいのだ。</p>
<p>こうしたメリットの大きさからエッジAI活用も少しずつ進みつつあるが、現状はまだ多くの企業がクラウド型の生成AI活用に目が向いている状態だ。</p>
<p>調査によると「エッジにAIを完全、または部分的に実装した」と回答しているのはITの意思決定者の29％に留まっている。増月氏はこの現状に対し、「これからもっとエッジAIにフォーカスしていく必要がある」と述べた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/5_cb622891a1/5_cb622891a1.png" alt="5.png" /></p>
<h2>エッジAIの課題を分散型エージェントが解決する</h2>
<p>製造現場などではすでにエッジAIが導入されており、業務で活用が進んでいる。ただし、それはあくまでも「画像データを分析して製品の不良を見つける」といった「識別型AI」であり、昨今トレンドとなっている生成AIではない。というのも生成AIを動作させるには膨大なリソースが必要であり、現状のエッジの性能では難しいからだ。これが、LLMを用いた多くのサービスがクラウド型で提供されている大きな理由でもある。</p>
<p>また各AIを組み合わせるなど、何らかの処理を自動で行うことも識別型AIでは難しい。AI同士を連携して業務を進めるには、現状ではまだ人間が介在する必要がある。</p>
<p>こうした課題を解決しうるのが「エージェント」の存在だ。</p>
<p>「単一ではなく分散型でエージェントを運用することで、従来の識別型AIの処理を自動化するなどのユースケースを生み出せるのではないかと考えています」</p>
<p>ただしエージェントが勝手に意思決定し、アクションをとるところまで自動化するのはリスクも伴う。そこで増月氏が提案するのが「ヒューマン・イン・ザ・ループ」だ。これはエージェントによるワークフローの中に人間が介入し、条件付きでワークフローを自動化する考え方。最初は人による関与を多くしてエージェントを監視するが、次第にエージェントが学習し、人間の介在を少なくするというアプローチである。</p>
<p>この他にも、従来型のエッジAIとエージェント型AIには様々な違いがある。</p>
<p>たとえば管理・オーケストレーションについては、従来型エッジAIが中央集約型のコントロールプレーンで一元管理するのに対し、エージェント型AIは分散・自律型で、各ノードやエージェントがそれぞれ状態管理・意思決定を実施する。</p>
<p>ユーザーインターフェースについては、従来型エッジAIはダッシュボードやコマンドラインが中心で、複雑な操作や習熟が必要となる。ダッシュボードの多重化による負担も増えがちだ。一方、エージェント型AIは自然言語インターフェースでユーザーが対話的に指示・確認できるため、直感的かつ低学習コストで操作が可能だ。当然、ダッシュボードの負担も軽減できる。</p>
<p>「エージェント型AIにより、今までの専門知識を持った人しか扱えなかった世界から、もう少しフレキシビリティの高い環境を作ることができるのではないかと考えています」</p>
<p>複数のエージェントがネットワーク全体で動作しユーザーの意図を理解して、特定のタスクを効果的に実行する。そんな「分散型エージェント」のワークフローはどのように構築できるのか。増月氏は次のように一例を示した。</p>
<p>「まず人が命令するのは自然言語です。コマンドを叩きたり、ダッシュボードで操作したりするのではなく、自然言語で命令を入力します。するとAPIを介在してエージェントが検出され、ワークフローマネージャーで実際のステップを構築していきます。メモリーストアはエージェント間のステートを共有する仕組みで、これにより精度の高い結果を生むことができます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/6_9ee6548d1d/6_9ee6548d1d.png" alt="6.png" /></p>
<h2>「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルとは</h2>
<p>続いて増月氏が解説するのが「識別型AI」と「生成AI」のハイブリッドコンピューティングモデルだ。</p>
<p>識別型AIは前述したようにデータをもとに分類や予測を行うAIのこと。たとえばスマートフォンの顔認証もその一つ。あらかじめ「自分の顔の特徴」というデータを学習させることで、カメラに映っている人物が持ち主であると“識別”させているわけだ。この識別型AIは生成AIがブームになる前から世の中のあらゆる場所で活用されている。</p>
<p>同じAIであっても、この識別型AIと生成AIの違いを理解することは重要だ。。昨今は生成AIのインパクトがことさら強調されがちだが、何かのエラー判定を行うような場合など、分野によっては識別型AIの方がはるかに高い精度を出せる場面も多い。また比較的少ないリソースで動作するのも識別型AIのメリットだ。</p>
<p>一方で生成AIはコンテキストの認識や汎用化において識別型AIを寄せ付けないほどの強みを持っている。両者の特徴は異なり、うまく両方のメリットを組み合わせることが今後は重要になってくるのだ。</p>
<p>「低レイテンシーやリアルタイム性が要求されるケースでは、できるだけワークロードをデータが生成されるエッジに持ってくる必要があります。ただ難しい処理になるとエッジよりもある程度コンピューティングリソースのある環境が必要になるため、クラウド活用が重要になってきます」</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/7_68105acef1/7_68105acef1.jpg" alt="7.jpg" /></p>
<p>では具体的にどのようなアーキテクチャを構築すべきなのか。増月氏が一例として示すのが、ハイブリッド分散型AI推論システムだ。</p>
<p>製造ラインの例では、エッジサイドで識別型AIが製品の合否判定を行い、不良品が検出された場合は比較的小さなリソースで稼働する生成AI VLM（ビジュアル言語モデル）を使って異常を分析する。一方で、複雑な処理はデータセンター側のLLMと連携し、分散型のLFMを使ってネットワークトラフィックを削減するわけだ。</p>
<p>このアーキテクチャにより、デジタルツインでのシミュレーションも可能になるほか、ロボットや自動運転、スマートシティなどのフィジカルAIの実現にもつながると増月氏は語った。</p>
<h2>「Dell AI Factory with NVIDIA」と「Dell NativeEdge」――デル・テクノロジーズが進めるAI戦略</h2>
<p>こうした発想に基づき、デル・テクノロジーズが進めるAI戦略が「Dell AI Factory」である。</p>
<p>柱となるのは「AI in/AI on/AI for/AI with」という4つの考え方だ。PCやストレージといった製品の中にAI機能を組み込み（AI in）、ハードウェアやコンピュート環境の上でAIを実装する（AI on）。さらにデル・テクノロジーズ一社ではなく、グローバルでパートナー企業と協力し（AI with）、デル社内でのAI活用で培ったノウハウを提供していく（AI for）とのことだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/8_10f5e922bc/8_10f5e922bc.png" alt="8.png" /></p>
<p>デル・テクノロジーズの強みについて増月氏は、ユースケース定義、データパイプライン設計、エッジからスーパーコンピュータまで網羅する幅広いインフラ提供、シリコンベンダーやソフトウェアベンダーとの多様なパートナーリング、サービスデリバリーまでエンド・トゥ・エンドで提供できる点にあると述べた。</p>
<p>Dell AI Factoryにおいてチャレンジとなるのが、エッジのワークロードをどのようにオーケストレートするのかという点だ。そのための仕組みが「Dell NativeEdge Platform」である。</p>
<p>「識別型AIや生成AIなどのワークロードを展開するのに、わざわざITの管理者が現場に行くことなくオーケストレートする仕組みです。現場に行かなくてもリモートで運用ができる“ゼロタッチ”により、AIだけでなくいろいろな環境とインテグレートすることができます」</p>
<p>デル・テクノロジーズのAI Factoryは、特にNVIDIAと強いリレーションを持っている。GPUやソフトウェアスタック、ネットワーキングなどをすべてインテグレートする仕組みがあり、エッジサイドではGB10を搭載した超小型スーパーコンピュータSparkも提供可能とのことだ。</p>
<p>講演ではHugging Face上のLLMポータルからモデルを選択し、ブループリントを生成、NativeEdgeを通じてエッジデバイスに展開するデモも行われた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9_535c14c78e/9_535c14c78e.jpg" alt="9.jpg" /></p>
<p>デル・テクノロジーズが考えるハイブリッドモデルは、NativeEdgeとDell AI Factoryを連携させ、一元管理する仕組みだ。これはクラウドベンダーではできないことであり、同時にエッジのみにフォーカスしているベンダーにも難しい取り組みである。まさにデル・テクノロジーズだからこそ可能な提案と言える。</p>
<p>増月氏は最後にエージェント間のコミュニケーションの重要性について触れ、パートナーリングのエコシステムをさらに加速させる必要があると呼びかけて講演を締めくくった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/10_f010c9bc0b/10_f010c9bc0b.png" alt="10.png" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ElevenLabs、ライザ・ミネリらと「代替ではなく共働」──人とAIが役割分担して制作した音楽アルバム発表</title>
      <link>https://ledge.ai/articles/elevenlabs_human_ai_cowork_music_album</link>
      <description><![CDATA[<p>AI音声技術を手がけるElevenLabsは米国時間2026年1月21日、著名アーティストと協業し、AI技術を活用した音楽アルバム「The Eleven Album」を公開したと<a href="https://elevenlabs.io/blog/introducing-the-eleven-album">発表</a>した。同アルバムは、同社が新たに開発した音楽生成モデル「Eleven Music」を用い、人間のアーティストとAIが役割を分担する「共働（協業）」によって制作されたオリジナル楽曲で構成されている。</p>
<p>参加アーティストには、ライザ・ミネリやアート・ガーファンクルをはじめ、作曲家、プロデューサー、AI音楽アーティストなどが名を連ねる。楽曲はすでに公式サイトおよびSpotifyで配信が始まっている。</p>
<p>@<a href="https://www.youtube.com/watch?v=T2wqG5wCNd4">YouTube</a></p>
<h2>著名アーティストが参加するAI音楽プロジェクト</h2>
<p>ElevenLabsによると、「The Eleven Album」は、ラップ、ポップ、R&amp;B、EDMなど複数のジャンルを横断する楽曲群で構成される。同社は、参加アーティスト全体として、数十億回規模のストリーミング実績や複数の音楽賞受賞歴、長年にわたる音楽活動の実績を有すると説明している。</p>
<p>各アーティストは、Eleven Musicを活用しながら、それぞれが完全にオリジナルの楽曲を制作したという。ElevenLabsは、同プロジェクトを大規模な複数アーティスト参加型のAI音楽制作の試みとして位置づける。</p>
<h2>AIは制作を補助、人間が最終的な創作主体に</h2>
<p>Eleven Musicはテキスト入力などをもとに楽曲を生成できる音楽生成モデルで、スタジオ品質の音源生成や編集、ステム出力などが可能とされる。一方で、楽曲の著作権や商業的権利はアーティスト側が保持し、AIは制作プロセスを補助する役割にとどまるとしている。</p>
<p>ElevenLabsは、人間の創作をAIが代替するのではなく、創作の幅を広げるためにAIを活用する点を強調しており、本アルバムはそうした制作方針を具体的に示す事例と説明している。</p>
<h2>ライザ・ミネリ氏、AI利用範囲を本人が説明</h2>
<p>参加アーティストの一人であるライザ・ミネリ氏は、自身のFacebook投稿で、同プロジェクトにおけるAIの利用範囲について説明した。同氏は、当該楽曲ではAIをアレンジ用途で使用した一方、ボーカルは本人の歌唱であり、声の生成や複製、クローンは行っていないと明らかにしている。</p>
<p>AI音楽を巡って制作実態への関心が高まる中、アーティスト本人が制作工程を補足説明した形となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/eleven_lab_Liza_Minnelli_on_FB_85a0a85a26/eleven_lab_Liza_Minnelli_on_FB_85a0a85a26.jpg" alt="eleven lab LizaMinnelli onFB.jpg" /></p>
<h2>権利管理とマネタイズの仕組みも整備</h2>
<p>ElevenLabsは、アーティストが制作した楽曲の所有権を保持し、配信による収益はアーティストに帰属すると説明している。また、同社が展開するライセンスプラットフォーム「Iconic Marketplace」を通じ、許諾に基づいたAI活用による新たな収益機会を提供する構想も示した。</p>
<p>同社はこれまでに、音楽著作権管理を手がけるKobalt MusicやMerlinとの提携を発表しており、音楽業界におけるAI活用と権利保護の両立を図る取り組みの一環として本プロジェクトを位置づけている。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、月額1,200円のAI有料プラン「Google AI Plus」日本展開　Geminiなどの利用枠を拡張</title>
      <link>https://ledge.ai/articles/google_ai_plus_launch_japan_1200yen</link>
      <description><![CDATA[<p>Googleは2026年1月28日、AI機能の利用上限を拡大できる有料サブスクリプションプラン「Google AI Plus」を日本で提供開始したことを<a href="https://blog.google/intl/ja-jp/company-news/technology/google-ai-plus/">発表</a>した。月額料金は1,200円。Geminiをはじめとする同社の生成AI機能を、無料プランよりも広い枠で利用できる。</p>
<p>Google AI Plusは、Google Oneを通じて提供される個人向けAIプランの一つで、生成AIを日常的に活用するユーザーを主な対象とする。新規登録者向けには、最初の2カ月間を月額600円とする半額キャンペーンも用意されている。</p>
<p>同プランでは、Geminiアプリで高性能モデルである「Gemini 3 Pro」や「Nano Banana Pro」を利用できるほか、AIを活用した映像制作ツール「Flow」、リサーチや執筆を支援する「NotebookLM」など、複数のAI機能が含まれる。GmailやGoogleドキュメント、スプレッドシートといったGoogleの各種サービスに統合されたGemini機能についても、利用枠が拡張される。</p>
<p>また、Google AI Plusには200GBのクラウドストレージが付帯し、Google Drive、Gmail、Google Photosで共通利用が可能だ。ストレージやAI特典は、最大5人までの家族メンバーと共有できる。既存のGoogle One プレミアム（2TB）ユーザーについては、数日以内にGoogle AI Plus相当のAI特典が利用可能になるとしている。</p>
<p><strong>GoogleのAIサブスクリプション3プランの比較。AI Plusは月額1,200円で提供される入門プラン</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae/JP_aiplus_comparison_width_1000_format_webp_55f4d830ae.jpg" alt="JP_aiplus_comparison.width-1000.format-webp.jpg" /></p>
<p>一方で、Googleは同プランについて、Google Workspaceのビジネスおよび教育機関向けアカウントでは利用できないとしている。</p>
<p>Googleは、個人向けに段階的なAIサブスクリプションを用意しており、Google AI Plusはその中でも入門・中核的な位置づけとなる。今後は、より高い利用上限や機能を備えた上位プランと併せて、生成AIの利用拡大を図る。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Googleカレンダー、Geminiで会議日程調整を自動化──最適な候補提示と“辞退後の再調整”をワンクリックで</title>
      <link>https://ledge.ai/articles/google_calendar_gemini_meeting_scheduling_update</link>
      <description><![CDATA[<p>Googleは2026年1月26日、Googleの「Google カレンダー」において、会議のスケジュール設定と再調整を支援する新機能を<a href="https://workspaceupdates.googleblog.com/2026/01/improved-meeting-suggestions-gemini-calendar.html">発表</a>した。生成AI「Gemini」を活用し、参加者の空き状況などを踏まえた候補時間の提示や、招待後の再スケジュールを簡素化する。</p>
<h2>Geminiが最適な会議時間を自動提案</h2>
<p>新機能では、イベント作成時に表示される「Suggested times」を選択すると、Geminiが参加者全員の空き状況を分析し、最適な会議時間の候補を提示する。タイムゾーンや勤務時間、既存予定との重複などを考慮したうえで候補が示され、主催者は提示された時間から選ぶだけで会議を設定できる。</p>
<h2>辞退が出た場合も、ワンクリックで再調整</h2>
<p>会議招待後に複数の参加者が欠席を選択するなどして成立が難しくなった場合、イベント画面上部に全員が参加可能な代替時間を示すバナーが表示される。主催者はそのバナーをクリックすることで、新しい時間帯への再スケジュールを行える。</p>
<h2>利用条件と制約</h2>
<p>Geminiによる時間候補の提示は、主催者が参加者のカレンダー情報にアクセスできることが前提となる。Googleのヘルプページによると、利用環境や会議の条件によっては候補が表示されない場合があるなど、一定の制約も設けられている。</p>
<h2>提供時期と対象プラン</h2>
<p>同機能は、Google WorkspaceのBusiness Standard／Plus、Enterprise Standard／Plus、および「Google AI Pro for Education」アドオンのユーザーが利用できる。Rapid Releaseドメインではすでに提供が始まっており、Scheduled Releaseドメインでは2026年2月2日から段階的に展開される予定だ。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>判断から実行までをAIが担う──日立ソリューションズ、RPAと連携するAIエージェント業務自動化を提供開始</title>
      <link>https://ledge.ai/articles/hitachi_solutions_ai_agent_rpa_business_automation</link>
      <description><![CDATA[<p>日立ソリューションズは2026年1月21日、AIとRPAを連携させ、複数の業務システムを横断して操作しながら、業務プロセスを自律的に判断・遂行する「AIエージェント活用業務自動化ソリューション」の提供を開始したことを<a href="https://www.hitachi-solutions.co.jp/company/press/news/2026/0121_1.html">発表</a>した。業務の判断をAIが担い、実行をRPAが担う構成により、従来は人手が介在していた複雑な業務の自動化を可能にする。</p>
<p>同ソリューションでは、AIエージェントが業務内容や処理状況を把握し、次に取るべき操作を判断する。判断結果に基づき、RPA（Robotic Process Automation、定型業務を自動化するソフトウエアロボット）が実際のシステム操作を行うことで、業務全体を一連の流れとして自動実行する。単一業務の自動化にとどまらず、業務プロセス全体を対象とする点が特徴だ。</p>
<p><strong>見積作成業務におけるAIエージェント活用イメージ。業務5ステップ中4ステップを自動化する。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/hitachi_aiagent_overview_44c100e94b/hitachi_aiagent_overview_44c100e94b.jpg" alt="hitachi aiagent overview.jpg" /></p>
<p>API連携が難しい既存の業務システムや、画面操作が前提となるレガシーシステムにも対応する。AIによる判断と、RPAによる画面操作を組み合わせることで、複数システムをまたぐ業務を横断的に自動化できるとしている。また、AIエージェントは自律的な判断だけでなく、必要に応じて人への確認を行うなど、柔軟な業務対応も可能だという。</p>
<p>導入にあたっては、自然言語やノーコード／ローコードによるAIエージェント作成を前提とし、業務部門でも扱いやすい設計を採用した。オープンな標準規格「MCP（Model Context Protocol）」に対応し、複数のAIエージェントを組み合わせた構成も可能としている。AIエージェントの設計からRPAとの連携、運用、改善までを一体で支援する。</p>
<p>同社は実業務での検証も行っており、見積作成業務を対象に、作業工程の約80％を自動化し、担当者の作業時間を約90％削減したとしている。判断が必要な工程がボトルネックとなっていた業務に対し、AIエージェントが判断を担うことで、自動化の適用範囲を拡大できると説明している。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>モスバーガー、AIが音声で注文を受けるドライブスルー実証開始──人と連携する「ハイブリッド応対」</title>
      <link>https://ledge.ai/articles/mos_burger_ai_drivethru_voice_order_test</link>
      <description><![CDATA[<p>モスフードサービスは2026年1月21日、同社が展開する「モスバーガー」店舗のドライブスルーにおいて、人工知能（AI）が来店客の音声を認識して注文を受けるシステムの実証実験を開始したと<a href="https://www.mos.co.jp/company/pr_pdf/pr_260121_1.pdf">発表</a>した。AIと店舗スタッフが連携して応対する「ハイブリッド応対」を採用し、接客品質の向上と人手不足への対応を両立する狙いだ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/New_Innovations_mos_760e300280/New_Innovations_mos_760e300280.jpg" alt="New Innovations mos.jpg" /></p>
<h2>AIと人が連携、全面自動化は目指さず</h2>
<p>ファストフード業界では、ドライブスルーにおけるAI音声注文は欧米を中心に導入例がある一方、認識精度の低さが課題とされてきた。今回の実証実験では、AIに全ての工程を任せるのではなく、AIが受注を担い、店舗スタッフが必要に応じてサポートする方式を採用。人とAIが役割分担することで、円滑な注文対応と接客品質の維持・向上を図る。</p>
<h2>音声対話AI「AI Order Thru」を導入</h2>
<p>実証実験には、New Innovationsが開発した音声対話AI「AI Order Thru（エーアイ オーダー スルー）」を活用する。同システムは、実店舗のオーダー業務を音声による自然なコミュニケーションで行うことを想定して設計されており、ブランドごとのガイドラインに沿った対話設計や標準オペレーションを前提とした運用が可能とされる。モスフードサービスは、同システムのカスタマイズ性を生かし、同社が重視するホスピタリティの進化と店舗オペレーションの高度化を両立させたい考えだ。</p>
<h2>吉川美南店で開始、年度内に5店舗程度へ</h2>
<p>実証実験は2026年1月21日、埼玉県吉川市の「モスバーガー 吉川美南店」で開始した。今後は2026年度中に合計5カ所程度の店舗で実証実験を行い、そのうち複数店舗での常設運用を目指すとしている。</p>
<h2>将来はメニュー提案や演出拡張も視野</h2>
<p>将来的な展開として、来店客から「500キロカロリー以下のセットメニューを紹介して」といった要望があった場合に、AIが即座に提案する機能や、キャンペーン期間中にアニメの人気キャラクターなどが応答する演出も視野に入れる。AIドライブスルーを通じ、顧客体験の拡張可能性を検証していく。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIが「Stargate Community」公表、各拠点で地域別コミュニティ計画―—電気代は上げず、電源・送電増強を“自前負担”へ　Microsoftも同種の誓約</title>
      <link>https://ledge.ai/articles/openai_stargate_community_local_community_plans_energy_self_funded</link>
      <description><![CDATA[<p>OpenAIは2026年1月20日、大規模AIインフラ計画「Stargate」を補完する新たな取り組みとして「<a href="https://openai.com/ja-JP/index/stargate-community/">Stargate Community</a>」を公表した。全米各地で整備を進めるAIキャンパスについて、拠点ごとに地域住民の意見や懸念を反映したコミュニティ計画を策定し、電力コストを地域に転嫁しない方針を明示した。</p>
<h2>1年で計画容量の「半分超」へ、Stargateの進捗</h2>
<p>Stargateは、OpenAIが2025年1月に発表した米国のAIインフラ拡張計画で、2029年までに最大10GW（ギガワット）規模の計算資源を整備することを目標としている。OpenAIによると、発表から1年が経過した現在、計画容量はすでに目標の半分を超えており、テキサス州アビリーンの初号拠点では、最先端AIシステムの学習と提供が始まっている。現在、テキサス、ニューメキシコ、ウィスコンシン、ミシガンなど複数州で新たな拠点の開発が進んでいる。</p>
<p>AIの需要拡大に伴い、こうした大規模インフラの必要性は高まっている。一方で、データセンター建設をめぐっては、電力や水資源、地域インフラへの影響を懸念する声も各地で強まっている。Stargate Communityは、そうした課題に正面から対応する枠組みとして位置付けられる。</p>
<h2>「電気代を上げない」──エネルギーは“自前負担”</h2>
<p>Stargate Communityの共通原則の一つが、エネルギー面で「自分たちの分は自分たちで負担する」という考え方だ。OpenAIは、AIキャンパスの運営によって地域の電気料金が上昇しないよう、必要となる追加の発電設備や送電・系統増強の費用をプロジェクト側が負担するとしている。</p>
<p>具体的には、地域の電力会社や送電事業者、州の公益事業規制当局、広域系統運用者と早期かつ透明に計画を共有するほか、AIキャンパスを「柔軟な負荷」として運用する方針を示した。需給逼迫や系統への負荷が予測される際には消費を抑制し、需要応答や系統安定化プログラムにも参加するという。</p>
<h2>州別に異なる設計、ウィスコンシンやミシガンで具体例</h2>
<p>Stargate Communityでは、地域ごとの事情に応じた設計を重視。ウィスコンシン州では、OpenAIのパートナーであるOracleやVantageが、WEC Energy Groupと連携し、太陽光発電や蓄電池を含む新たな電源と容量の確保を検討している。電力インフラへの投資は、施設向けの専用料金によって賄われ、既存利用者の料金上昇を防ぐ仕組みとする。</p>
<p>ミシガン州では、OracleとRelated DigitalがDTE Energyと協力し、既存の電源に加え、プロジェクトが全額負担する蓄電池設備を導入する計画だ。既存顧客の電力供給や料金への影響を抑えつつ、系統の固定費負担にも貢献する設計だという。</p>
<p>テキサス州では、SB Energyがミラム郡で開発中のStargateキャンパス向けに、新たな発電設備と蓄電設備を整備し、必要電力の大部分を供給する計画を進めている。</p>
<h2>水資源・環境配慮と地域投資、人材育成も柱に</h2>
<p>エネルギーに加え、水資源や地域投資もStargate Communityの重要な柱だ。OpenAIは、閉ループ型や低水使用の冷却方式を優先し、飲用水や地域の生態系への影響を最小限に抑えるとしている。テキサス州アビリーンの拠点では、年間の水使用量が市全体の1日分の使用量の半分程度にとどまるとの説明も示された。</p>
<p>また、地域インフラへの投資として、ウィスコンシン州では最低1億7500万ドル規模のインフラ改修や水環境再生プロジェクトへの投資が計画されている。人材面では、各Stargate拠点で地域の雇用と技能育成を支える「OpenAI Academy」を設置し、最初の拠点を2026年春にアビリーンで立ち上げる予定だ。労働組合や地域の人材育成機関と連携し、建設・運用に必要な人材の育成を進める。</p>
<h2>Microsoftも「コミュニティファースト」方針を表明</h2>
<p>OpenAIは、主要パートナーの一つであるMicrosoftが、同時期に「コミュニティファースト」を掲げたAIインフラ方針を<a href="https://blogs.microsoft.com/on-the-issues/2026/01/13/community-first-ai-infrastructure/">公表</a>した点にも言及した。Microsoftは2026年1月13日、データセンターを建設・運営する地域社会に対し、電気料金の転嫁回避、水使用量の削減と補充、雇用創出、税基盤の強化、AIトレーニングや非営利団体への投資といった複数のコミットメントを打ち出している。</p>
<p>OpenAIは、Stargateが物理的なインフラ計画であり、地域社会との長期的なパートナーシップが不可欠だと強調する。今後も各拠点ごとにコミュニティ計画を策定し、地域と協調しながらAIインフラの整備を進めていくとしている。</p>
<p><strong>Stargate Communityの取り組みの一環として行われた、米テキサス州ミラム郡のデータセンター・オープンハウス。OpenAIとパートナー企業、地域関係者が参加した。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/stargate_community_4b79b8b8f2/stargate_community_4b79b8b8f2.webp" alt="stargate-community.webp" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Sakana AIがGoogleと戦略的パートナーシップ締結　出資受け、基幹産業向け「信頼できるAI実装」を共同推進</title>
      <link>https://ledge.ai/articles/sakana_ai_google_strategic_partnership_reliable_ai_mission_critical</link>
      <description><![CDATA[<p>東京に拠点を置くAI企業のSakana AIは2026年1月23日、Googleと戦略的パートナーシップを締結したと<a href="https://sakana.ai/google/">発表</a>した。あわせて、Googleからの出資を受けたことも明らかにした。両社は、研究開発から社会実装までを見据えた協力関係を構築し、基幹産業向けに「信頼できるAI」の実装を共同で推進するとしている。</p>
<p>Sakana AIによると、今回の提携は、同社が掲げる研究成果を実社会のインパクトにつなげる取り組みを加速させることを目的とする。Googleの技術基盤やプロダクト群と、Sakana AIの研究開発力を組み合わせることで、AIの品質向上と実運用に耐える信頼性の確保を図る。</p>
<p>技術面では、Googleの最先端AIモデルである「Gemini」や「Gemma」を含む技術群を、Sakana AIの研究開発および製品開発に活用する方針だ。これにより、AIエージェント開発や科学研究の自動化など、同社が注力する研究テーマの高度化を目指すとしている。</p>
<p>また両社は、最高水準のセキュリティとデータ主権（data sovereignty）が求められる規制産業を中心に、Googleのプラットフォームを活用した「信頼できるAI」ソリューションの展開を進める方針を示した。リリースでは導入先の例として金融機関や政府機関を挙げている一方、個別の導入先や時期は明らかにしていない。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>800人超の著名クリエイターが「盗みはイノベーションではない（Stealing Isn’t Innovation）」──生成AIの無断学習に抗議キャンペーン</title>
      <link>https://ledge.ai/articles/stealing_isnt_innovation_campaign_creators_ai_copyright</link>
      <description><![CDATA[<p>米国の俳優や音楽家、作家などを含む800人を超える著名クリエイターが、生成AI企業による著作物の無断利用に抗議するキャンペーン「Stealing Isn’t Innovation（盗みはイノベーションにあらず）」を開始した。</p>
<p>Human Artistry Campaign（HAC）は2026年1月22日（現地時間）、ワシントンDCで同キャンペーンの立ち上げを<a href="https://www.humanartistrycampaign.com/it/news">発表</a>した。</p>
<p>HACは声明で、生成AIの開発競争が激化する中、テック企業が著作権で保護された作品を「許諾や対価なしに大量収集（mass harvesting）」し、AIモデルの学習や生成に利用していると指摘。こうした行為は、米国の雇用や経済成長、文化産業が支えてきた国際的な影響力（ソフトパワー）を損なうと批判した。</p>
<h2>解決策として「ライセンス」と「オプトアウト」を提示</h2>
<p>同キャンペーンは、問題の解決策として、著作物の利用条件を明確に定め、権利者に正当な対価を支払うライセンスの枠組みを採用すべきだと主張している。あわせて、クリエイターが生成AIの学習対象から自身の作品を除外できるオプトアウト権の確保も求めた。</p>
<p>HACは、無断利用が続けば新たな創作のインセンティブが失われ、AIモデルが人間の創作物ではなく低品質な合成データに依存する状態に陥る可能性があると警告。結果として、AIの競争力そのものが低下しかねないとしている。</p>
<h2>SNSバナーと全面広告でメッセージを発信</h2>
<p>「キャンペーン開始当日、多数のクリエイターが専用バナーをSNSに投稿した。賛同者にはスカーレット・ヨハンソン氏やケイト・ブランシェット氏、R.E.M.などが名を連ねる。</p>
<p>HACのシニアアドバイザーである モイヤ・マクティア氏は、「盗用はイノベーションではない」と強調。主要ニュースメディアでも同メッセージを掲げたデジタルおよび紙媒体の全面広告が展開されたと説明した。</p>
<h2>創作とAIの共存を求める動き</h2>
<p>HACは、テクノロジー企業とクリエイターの協調は「任意ではなく、既存の法制度に沿った当然の前提」だとし、すでにAI向けのコンテンツライセンス契約が成立している例もあると指摘する。同キャンペーンは、創作活動と生成AIの発展を対立構造ではなく、合法的かつ持続可能な形で両立させる必要性を訴えている。</p>
<p><strong>「Stealing Isn’t Innovation」キャンペーンの署名ページ。俳優、音楽家、作家など幅広い分野のクリエイターが名を連ねている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/CREATOR_SIGNEES_386aba3d01/CREATOR_SIGNEES_386aba3d01.jpg" alt="CREATOR SIGNEES.jpg" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「あの森のシーン」を言葉で探せる──ジブリ作品を“意味”で検索するAIサービス「Studio Ghibli Search」公開</title>
      <link>https://ledge.ai/articles/studio_ghibli_search_semantic_search</link>
      <description><![CDATA[<p>スタジオジブリ作品のスチル画像を対象に、自然言語による意味検索（セマンティック検索）を可能にするAIサービス「Studio Ghibli Search」がGitHub上で2026年1月21日に<a href="https://github.com/aninibread/ghibli-search">公開</a>された。Cloudflare Developer Platformを用いて構築された同サービスでは、作品名や正確なシーン名を知らなくても、「flying through clouds（雲の中を飛ぶ）」や「rainy day（雨の日）」といった言葉から、該当するジブリ作品の場面を探し出すことができる。</p>
<h2>作品名不要、雰囲気や文脈で探せる検索体験</h2>
<p>「Studio Ghibli Search」は、キーワードの一致に依存する従来型検索とは異なり、検索語の意味や文脈をAIが解釈するセマンティック検索を採用している。ユーザーは自然言語でイメージを入力するだけで、関連性の高いシーンを一覧で確認できる。</p>
<p>検索対象は『となりのトトロ』『千と千尋の神隠し』『もののけ姫』など、スタジオジブリ作品の映画スチル画像。公式サイト上では「flying through clouds」や「rainy day」といった検索例も提示されており、作品名や場面名を覚えていなくても利用できる設計となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/demo_search_13aad9506d/demo_search_13aad9506d.png" alt="demo-search.png" /></p>
<h2>画像アップロードにも対応、視覚的に似た場面を検索</h2>
<p>同サービスはテキスト検索に加え、画像をアップロードして検索する機能も備える。アップロードされた画像はAIによって解析され、構図や雰囲気といった視覚的特徴をもとに、類似するジブリ作品のシーンを検索する仕組みだ。</p>
<p>READMEではこの機能を「Image search」として明示しており、文章での表現が難しいイメージからでも、近い空気感を持つ場面を探せる点が特徴とされている。</p>
<h2>Cloudflare基盤で構築、画像セマンティック検索の実装例に</h2>
<p>技術面では、Cloudflareの開発基盤を組み合わせた構成を採用している。フロントエンドにはReact Router 7を用いたフルスタックReact構成を採り、バックエンドはCloudflare Workers上で動作する。</p>
<p>画像データはCloudflare R2に保存され、Cloudflare AI Search（AutoRAG）によって自動的に埋め込み処理が行われる。検索時には、自然言語クエリをAIが解釈・書き換えたうえで、ベクトル検索によって関連性の高い画像を抽出する仕組みとなっている。スタイリングにはTailwind CSS、言語にはTypeScriptを使用している。</p>
<p><strong>画像解析、クエリ書き換え、ベクトル検索などをCloudflareの各機能で連携する構成例（README掲載のアーキテクチャ図）</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/architecture_944cfca6f7/architecture_944cfca6f7.png" alt="architecture.png" /></p>
<h2>個人開発・オープンソースとして公開</h2>
<p>「Studio Ghibli Search」は<a href="https://x.com/aninibread/status/2013777652008554849">個人開発</a>によるプロジェクトで、ソースコードはGitHub上でMITライセンスのもと公開されている。READMEには、R2バケットの構成方法やAI Searchインデックスの設定、Wrangler CLIを用いたデプロイ手順まで詳細に記載されており、同様の仕組みを再現できる内容となっている。</p>
<p>商用サービスではなく、セマンティック検索や画像検索の実装例を示すデモンストレーション的な位置づけのプロジェクトといえる。</p>
<p>なお、READMEでは使用されている画像がスタジオジブリ作品の映画スチルであること、スタジオジブリおよび関連商標が同社に帰属することも明記されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/annni_wang_x_c4a54268b6/annni_wang_x_c4a54268b6.jpg" alt="annni wang x.jpg" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI時代のYouTubeに警鐘──ニール・モーハンCEO、低品質AI動画「AIスロップ」拡散を問題視　クリックベイト対策の仕組みを拡張</title>
      <link>https://ledge.ai/articles/youtube_ai_slop_quality_control_2026</link>
      <description><![CDATA[<p>YouTubeのCEOであるニール・モーハン氏は2026年1月21日、生成AIの普及に伴い、低品質なAI生成コンテンツ、いわゆる「AIスロップ」への懸念が高まっていると<a href="https://blog.youtube/inside-youtube/the-future-of-youtube-2026/">述べた</a>。開かれたプラットフォームとして表現の自由を尊重しつつも、視聴者が心地よく時間を過ごせる場であり続けるため、同社は低品質で反復的なコンテンツの拡散を抑制する取り組みを強化する方針を明らかにした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/priorities_for2026_8b8b756a40/priorities_for2026_8b8b756a40.jpg" alt="priorities for2026.jpg" /></p>
<h2>「開放性」と「視聴体験の質」をどう両立するか</h2>
<p>モーハン氏は、YouTubeがこれまでASMRやゲーム実況など、当初はニッチと見なされていた表現を育て、主流のコンテンツへと押し上げてきた点に触れ、幅広い自由な表現を許容する姿勢が同社の特徴だと説明した。一方で、その開放性には、ユーザーが求める高品質な視聴体験を維持する責任が伴うと強調した。</p>
<h2>生成AIが生む新たな課題、「AIスロップ」への対応</h2>
<p>生成AIは創作を加速させ、表現の幅を広げる一方で、低品質かつ大量生産された反復的コンテンツが増加するという新たな課題も浮上している。同氏は、こうしたコンテンツが視聴体験を損なうリスクを指摘し、「AIスロップ」と呼ばれる低品質AI動画の拡散を問題視した。</p>
<p>YouTube動画を引用する場合　　　
@<a href="https://www.youtube.com/watch?v=YXJVOffU4iA&amp;t=1s">YouTube</a></p>
<h2>中核は推薦システムと既存対策の拡張</h2>
<p>同氏は対策の方向性として、新たなルールを一から設けるのではなく、スパムやクリックベイト（実際の内容以上に誇張したタイトルやサムネイルで閲覧を誘導する手法）対策で実績のある既存の仕組みを基盤に取り組む考えを示した。低品質で反復的なコンテンツについては、推薦（レコメンド）システムの中で扱いを調整し、露出を抑制する。YouTubeはこの分野への投資を拡大し、2026年に向けて対策をさらに強化していくとしている。</p>
<h2>透明性とガイドラインの継続的な適用</h2>
<p>AI生成かどうかにかかわらず、すべてのコンテンツはコミュニティガイドラインの対象であり、欺瞞的表現や誤解を招くコンテンツへの対応を継続する。加えて、改変・合成コンテンツに対する開示の仕組みなど、透明性を重視した運用を進め、規模を拡大した執行を行う方針だ。</p>
<h2>創作を支えるAI活用も継続</h2>
<p>一方で、同社はAIを単なる抑制対象としてではなく、人間の創造性を支える技術としても位置づけている。Shorts制作支援や視聴体験を補助する機能、言語の壁を越えるオートダビングなど、創作やアクセシビリティを高める取り組みを引き続き進める考えを示した。</p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2026/1/24 [SAT]GoogleDeepMind、動画から「4D（三次元空間＋時間）」で世界を再構成するAI「D4RT」　動く3D空間を高速・高精度に把握</title>
      <link>https://ledge.ai/articles/deepmind_d4rt_4d_video_3d_reconstruction</link>
      <description><![CDATA[<p>Google DeepMindは2026年1月22日、動画をもとに三次元空間を時間軸に沿って再構成・理解できるAIモデル「D4RT（Dynamic 4D Reconstruction and Tracking）」を開発したと<a href="https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/">発表</a>した。D4RTは、物体や人の動きを含む動的なシーンを「3次元＋時間」の4次元表現として捉え、従来手法と比べて高い精度と計算効率を実現したとしている。</p>
<p>同社は、D4RTが人間と同じように、視覚情報から世界の構造と変化を一貫して理解するAIの実現に向けた基盤技術になると位置付けている。</p>
<h2>動画から「3D＋時間」を一貫して推定</h2>
<p>D4RTの特徴は、単一または複数視点の動画を入力として、空間構造とその時間的変化を同時に推定できる点にある。静止画像ごとに処理する従来型の手法とは異なり、動画全体から得られる情報を用いて、物体の位置関係や動きを時系列で整合的に再構成する。</p>
<p>公式ブログによると、D4RTは人や物体が動く環境でも、遮蔽や視点変化に耐えながら、安定した3次元表現を維持できるという。これにより、現実世界のような複雑で動的なシーンの理解が可能になるとしている。</p>
<p><strong>■ クエリによる時系列3D推定の例：</strong> 動画内の2D座標、参照時刻・対象時刻、カメラ情報をクエリとして与えることで、対象点の3次元位置を時間軸に沿って推定できる</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Deep_Mind_D4_RT_at_a_Time2_c494089fc3/Deep_Mind_D4_RT_at_a_Time2_c494089fc3.jpg" alt="DeepMind D4RT at a Time2.jpg" /></p>
<h2>クエリベースの単一モデルで複数タスクを統合</h2>
<p>同社は、従来の動的3D理解が、深度推定や点追跡、カメラ位置推定などを別々のモデルで処理する構成になりがちだった点を課題として挙げる。D4RTでは、動画から生成した「グローバルなシーン表現」を基盤とし、独立したクエリを用いて必要な情報を取り出す仕組みを採用した。</p>
<p><strong>■ D4RTの全体構成：</strong> 動画をエンコーダで処理し、時間を含むグローバルなシーン表現を生成。独立したクエリを用いてデコーダが任意の点や時刻の3次元位置・軌跡を推定する</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Deep_Mind_D4_RT_at_a_Time1_7d397c63e3/Deep_Mind_D4_RT_at_a_Time1_7d397c63e3.jpg" alt="DeepMind D4RT at a Time1.jpg" /></p>
<p>arXivで公開された論文では、特定の2次元座標や時刻、カメラ条件をクエリとして与えることで、対象点の3次元位置を任意の時点で推定できることが示されている。これにより、点追跡や3D再構成といった複数の処理を、単一のフレームワークで扱えるようになった。</p>
<h2>既存手法より高速・高効率と主張</h2>
<p>同社は、D4RTが既存の動的3D再構成手法と比べて、計算効率を大幅に改善したと説明する。公式ブログでは、条件によっては最大300倍の効率向上が得られたとしている。</p>
<p>論文でも、複数のタスクや評価設定において、処理速度や効率の面で従来モデルを上回る結果が報告されている。これまで計算負荷が大きく、実用化の障壁となっていた動的シーン理解を、より現実的な計算コストで実行できる可能性があるという。</p>
<h2>ロボティクスやAR/VRへの応用を視野</h2>
<p>Google DeepMindは、D4RTをロボティクスや自律移動、拡張現実（AR）や仮想現実（VR）といった分野での基盤技術として想定している。現実世界を理解しながら行動するAIにとって、時間とともに変化する空間を正確に把握する能力は不可欠とされる。</p>
<p>同社は、D4RTが「AIが世界を理解する方法」を一段階引き上げる取り組みだとしており、今後の研究や応用展開が注目される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Deep_Mind_D4_RT_at_a_Time3_1f0a72eace/Deep_Mind_D4_RT_at_a_Time3_1f0a72eace.jpg" alt="DeepMind D4RT at a Time3.jpg" /></p>
]]></description>
      <pubDate>Sat, 24 Jan 2026 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Gemini」は「ジェミニ」──再周知にXで「論争に終止符」「好感度が高い」の声</title>
      <link>https://ledge.ai/articles/google_gemini_japanese_pronunciation_jemini</link>
      <description><![CDATA[<p>Googleは2026年1月20日、同社の生成AIサービスGeminiについて、日本における正式な読み方は「ジェミニ」であると、Google Japanの公式Xアカウントを通じて改めて<a href="https://x.com/googlejapan/status/2013560887701819533">周知</a>した。国内では「ジェミニ」と「ジェミナイ」という複数の呼称が使われてきたが、公式見解を再確認する形となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Google_Japan_X_Gemini_551af33f81/Google_Japan_X_Gemini_551af33f81.jpg" alt="GoogleJapanX Gemini.jpg" /></p>
<h2>登場当初から日本語表記は「ジェミニ」</h2>
<p>Google Japanは2024年2月、対話型AIサービス「Bard」を「Gemini」へ名称変更した際、日本語表記を「Gemini（ジェミニ）」と<a href="https://x.com/googlejapan/status/1755607418103587148">明示</a>していた。今回の投稿は、新たに読み方を定めたものではなく、登場当初から示してきた公式表記を改めて周知したものと位置づけられる。</p>
<p>一方で、その後もSNSなどでは英語圏での発音に近い「ジェミナイ」という呼び方が広がり、日本国内では複数の読み方が混在する状況が続いていた。</p>
<h2>呼称の混在を受け、改めて公式見解を提示</h2>
<p>こうした背景のもと、Google Japanは2026年1月20日の投稿で、「Geminiの日本語表記は『ジェミニ』です」と明言し、「これからもたくさん呼んであげてください」と呼びかけた。この投稿をきっかけに、X（旧Twitter）上では再び読み方が話題となり、関連ワードが日本のトレンドに入るなど、関心の高さがうかがえた。</p>
<h2>「どちらでもOK」と補足、Xでは好意的な受け止めも</h2>
<p>その後、Google Japanは英語圏では「ジェミナイ」と発音されていることにも触れ、「なのでこれでももちろんOKです」と補足し、呼び方そのものについては柔軟な姿勢を示した。</p>
<p>X上では、この一連の対応を受けて、「公式が改めて示したことで論争に終止符が打たれた」「対応が柔らかく、好感度が高い」といった声も見られる。公式見解を明確にしつつ、ユーザー側の呼び方も尊重する姿勢が、前向きに受け止められている形だ。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Google_Japan_X_Gemini6_42872f1e0a/Google_Japan_X_Gemini6_42872f1e0a.jpg" alt="GoogleJapanX Gemini6.jpg" /></p>
]]></description>
      <pubDate>Fri, 23 Jan 2026 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformerに代わる選択肢──ELYZA、日本語特化の拡散モデルベースのLLM「ELYZA-LLM-Diffusion」を商用利用可能な形で公開</title>
      <link>https://ledge.ai/articles/elyza_llm_diffusion_japanese_dllm_release</link>
      <description><![CDATA[<p>東京大学・松尾研究室から発足したAI開発企業の ELYZA は2026年1月16日、日本語に特化した拡散大規模言語モデル（dLLM）「ELYZA-LLM-Diffusion」シリーズを開発し、商用利用可能な形で<a href="https://prtimes.jp/main/html/rd/p/000000066.000047565.html">公開</a>した。</p>
<p>画像生成AIで発展してきた拡散モデルを言語生成に応用することで、従来主流のTransformerに代表される自己回帰型モデルとは異なる生成方式を採用。日本語の知識力や指示追従能力を高めつつ、効率的な推論を可能にする点を特徴としている。</p>
<h2>画像生成で培われた「拡散モデル」を言語生成へ</h2>
<p>拡散大規模言語モデル（Diffusion Large Language Model、dLLM）は、もともと画像生成分野で広く使われてきた拡散モデルを言語生成に応用したものだ。</p>
<p>自己回帰（Autoregressive）モデルがテキストを左から右へと逐次的に生成するのに対し、dLLMではテキスト全体にノイズを加え、そこから段階的にノイズを除去する「逆拡散過程」を通じて文章を生成する。</p>
<p>この方式では、設計次第で逐次生成を前提としない推論が可能となる。処理回数を抑えられるため、生成効率の向上や消費電力低減につながる可能性がある点が、dLLMの特徴とされている。一方で、学習コストの高さや推論基盤の成熟度といった課題も指摘されており、実利用はこれまで限定的だった。</p>
<h2>日本語データで追加学習、dLLMの日本語性能を強化</h2>
<p>今回ELYZAが開発した「ELYZA-LLM-Diffusion」は、HKU NLP Group が公開しているdLLM「Dream-v0-Instruct-7B」をベースに、日本語データによる追加事前学習と指示学習を施したモデルだ。</p>
<p>英語データ中心で学習された既存のdLLMが多い中、日本語に特化した知識力や指示追従能力の強化を狙った点が特徴となっている。</p>
<h2>日本語ベンチマークで既存dLLMと同等以上の性能</h2>
<p>ELYZAは本モデルの性能評価として、日本語タスクを中心とした複数のベンチマークを実施した。
一般的な日本語能力を測るタスクや、日本語MTベンチマーク、コーディング能力（JHumanEval）、数学タスク（MATH-500日本語版を含む）などで評価を行い、既存のオープンなdLLMと比較して同等、またはそれを上回る性能を示したとしている。</p>
<p>評価結果は、自己回帰型モデルとの直接的な優劣を示すものではなく、あくまでdLLMという枠組みの中での位置づけを示すものとされている。</p>
<p><strong>■ 日本語タスクを中心に実施したベンチマーク評価結果。ELYZA-Diffusion-Instruct-1.0-Dream-7Bは、既存のオープンな拡散言語モデルと比較して同等、またはそれを上回る性能を示したとしている</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8/47565_66_26607388b73b1b1ac71b2c88df8faeca_1329x830_d1a0a075f8.webp" alt="47565-66-26607388b73b1b1ac71b2c88df8faeca-1329x830.webp" /></p>
<h2>自己回帰と拡散、生成プロセスの違いをデモで可視化</h2>
<p>ELYZAは、自己回帰モデルと拡散モデルの生成プロセスの違いを示すデモも公開している。
同一入力に対し、自己回帰モデルではトークンが順に確定していく一方、拡散モデルではテキスト全体が段階的に更新されていく様子を確認できる。
このデモは生成速度そのものを示すものではなく、生成方式の違いを直感的に理解するための技術的な可視化として位置づけられている。</p>
<p><strong>■ 自己回帰モデル（AutoRegressive、左）と拡散モデル（Diffusion、右）における文章生成プロセスの比較デモ。拡散モデルでは、テキスト全体が段階的に更新されていく様子を確認できる</strong></p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/file_48b854e8ad/file_48b854e8ad.gif" alt="file.gif" /></p>
<h2>Base／Instructの2モデルを公開、商用利用も想定</h2>
<p>今回公開されたモデルは以下の2種類だ。</p>
<ul>
<li><strong>ELYZA-Diffusion-Base-1.0-Dream-7B：</strong> 日本語データによる追加事前学習を行ったベースモデル</li>
<li><strong>ELYZA-Diffusion-Instruct-1.0-Dream-7B：</strong> Baseモデルに指示学習を施したモデル</li>
</ul>
<p>いずれもHugging Face上で公開されており、chatUI形式のデモも同時に提供されている。商用利用可能な形で公開されている点も、今回の発表の特徴の一つだ。</p>
<h2>電力消費増大という課題と、dLLM研究の狙い</h2>
<p>生成AIの利用拡大に伴い、電力消費の増大やAI向けデータセンター不足が国際的な課題となっている。
ELYZAは、dLLMが持つ「少ない処理回数で文章を生成できる」という特性に着目し、推論時間や電力消費を抑えられる可能性を持つアプローチとして研究を進めてきた。</p>
<p>今回の「ELYZA-LLM-Diffusion」は、自己回帰型が主流となっている言語モデルの設計に対し、別の選択肢を示す試みとして位置づけられる。</p>
]]></description>
      <pubDate>Thu, 22 Jan 2026 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>共通テスト2026、ChatGPT最新モデルが9科目満点──LifePrompt検証、精度の先で浮かぶ“弱点の質”</title>
      <link>https://ledge.ai/articles/common_test_2026_chatgpt_full_marks_9_subjects_lifeprompt_analysis</link>
      <description><![CDATA[<p>AIベンチャーのライフプロンプトは2026年1月20日、大学入学共通テスト（2026年度）の問題を複数の最新生成AIに解かせた検証結果を公式noteで<a href="https://note.com/lifeprompt/n/nb87edfb2e7ca">公開</a>した。OpenAIのGPT-5.2 Thinkingが、受験させた科目のうち9科目で満点を獲得したという。</p>
<p>同社は同一条件下で、Gemini 3 Pro、Claude Opus4.5 にも同テストを受験させ、得点だけでなく解答に要した時間や誤答の傾向まで比較した。ライフプロンプトが「AI vs 共通テスト」の年次検証を行うのは2023年からで、今回が4年目となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9/1768868571_lsp4_Ej_Cy6_DWLX_1r_B8_Ac_Th_Y_Zb_45fbdf90b9.webp" alt="1768868571-lsp4EjCy6DWLX1rB8AcThYZb.webp" /></p>
<h2>共通テストを「そのまま解かせる」ための検証方法</h2>
<p>今回の検証では、人為的なコピペミスや恣意性を排除するため、共通テスト専用の自動受験システムを構築し、API経由で試験を実施した。</p>
<p>具体的には、共通テストの問題PDFをシステムに投入し、全ページを画像化すると同時にテキスト解析を行う。問題構造を自動判定したうえで大問ごとに分割し、各AIモデルにAPI経由で出題。AIが出力した自由記述の回答を、別のAIプロセスでマークシート形式に変換し、自動採点する仕組みだ。</p>
<p>例外措置として、英語リスニングは試験センターが公開している読み上げスクリプト（台本）をテキスト入力で使用した。また、国語の縦書き文章については、外部ツールで文字起こししたテキストを用いている。</p>
<p>今回比較したモデルは以下の3種だ。</p>
<ul>
<li>ChatGPT系列：GPT-5.2 Thinking</li>
<li>Gemini 3 Pro</li>
<li>Claude Opus 4.5</li>
</ul>
<h2>満点9科目、得点はGPT、速度はGeminiとClaude</h2>
<p>検証の結果、文系・理系いずれの合計点でもGPT-5.2 Thinkingが最も高得点を記録し、満点科目は9科目に達した。Gemini 3 ProとClaude Opus4.5 も900点台前半の高得点で続いた。</p>
<p>一方、解答に要した時間では明確な差が出た。GeminiとClaudeは約1時間40分前後で全科目を解き終えたのに対し、GPT-5.2 Thinkingは約5時間30分を要した。ライフプロンプトは、GPTが深い推論と検算を繰り返す「熟考型」であることが、高得点と引き換えに時間がかかった理由だとしている。</p>
<p>同社は、昨年の検証でAIが東京大学の合格水準に到達したと報告しており、今年は「合格できるかどうか」ではなく、「満点を取れるか」「どれだけ速く解けるか」といった次の段階に焦点を移したと位置付けている。</p>
<h2>なぜAIは間違えたのか──誤答に共通するパターン</h2>
<p>これほど高得点を記録したAIだが、3モデルすべてが共通して誤答した問題も存在した。ライフプロンプトは、誤答の傾向から現在の生成AIに残る課題が見えるとしている。</p>
<p>一つは図表やイラストの読み取りだ。英語リスニングの「バスの乗り方」を問う問題では、音声スクリプトの内容は正確に理解できていたものの、選択肢として示されたバスのイラスト（矢印の向き）を正しく判定できず、全モデルが誤答した。</p>
<p>次に挙げられるのが、国語（小説）の心情理解である。主人公が現状を正当化しようとしつつも割り切れない思いを抱える場面で、正解は「現状への妥協」を示す選択肢だったが、AIはいずれも「過去の過ちへの反省」を選んだ。ライフプロンプトは、一般論的な道徳観に引き寄せられ、人間特有の曖昧な感情を読み違えたと分析している。</p>
<p>さらに、地理などの視覚情報も弱点として浮かび上がった。色の濃淡で分布を示した地図問題では、ヒートマップの微妙な違いを識別できず、全モデルが誤答した。</p>
<h2>それでも差は出た──Geminiだけが正解した問題</h2>
<p>一方で、すべての問題で同じ結果になったわけではない。地理の別問題では、Gemini 3 Proのみが地図上の地形（アンデス山脈）と気候グラフを正しく結びつけ、唯一正解したケースもあった。</p>
<p>ライフプロンプトは、GPT-5.2 ThinkingやClaudeが画像を「文字情報の集合」として処理しようとする傾向があるのに対し、Geminiは画像を視覚情報として捉える能力が強く、地図やグラフの相関関係を直感的に把握できたと説明している。</p>
<h2>「AI入試挑戦」を巡る論点の変化</h2>
<p>同社はこれまで、毎年のように生成AIが入試に挑戦する検証を取り上げてきた。2024年頃は、共通テストでどのモデルが最も高得点を取るのか、人間の合格水準にどこまで迫ったのかが主な関心事だった。</p>
<p>2025年には、共通テストに加えて東大二次試験なども対象とした検証が登場し、「難関大学に通用する水準かどうか」が焦点となった。そして2026年の今回、論点はさらに一段階進み、満点科目の数、解答速度、誤答の質へと移っている。</p>
<p>AIが「解けるかどうか」ではなく、「どこで、なぜ落とすのか」が具体的に示される段階に入ったことを、今回の検証は示している。</p>
<p>共通テストで9科目満点という結果は、生成AIの推論能力が標準化試験レベルでは極めて高い水準に到達したことを示す。一方で、図表の読み取りや感情理解といった領域では、人間とは異なるつまずき方をすることも明らかになった。</p>
<p>今後も同社は同様の検証を続けるとしており、AIが入試問題を通じてどのように進化していくのかは、引き続き注目される。</p>
]]></description>
      <pubDate>Thu, 22 Jan 2026 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Mon, 05 Jan 2026 08:30:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Sat, 03 Jan 2026 23:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>