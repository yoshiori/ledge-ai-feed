<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>平面から立体へ──部品を縦に積み上げる「3Dチップ」でAI処理のスループットは従来の2Dチップ比で約4倍に　スタンフォード大学、カーネギーメロン大学などの研究チーム</title>
      <link>https://ledge.ai/articles/3d_chip_ai_throughput_4x_stanford_cmu</link>
      <description><![CDATA[<p>部品や回路を平面ではなく縦方向に積み上げる「3Dチップ」を用いることで、AI処理のスループットが従来の2Dチップと比べて約4倍に向上することが分かった。</p>
<p>スタンフォード大学、カーネギーメロン大学などの研究チームは、米国の商用半導体ファウンドリで製造したチップを用いてこの成果を実証した。研究成果は、2025年12月10日から開催された<strong>IEEE国際電子デバイス会議（IEDM）</strong> （第71回）で<a href="https://engineering.stanford.edu/news/scientists-and-us-foundry-achieve-3d-chip-breakthrough-accelerate-ai">発表</a>された。</p>
<h2>AIの性能を縛る「メモリの壁」と、平面チップの限界</h2>
<p>近年のAIシステムでは、計算能力そのもの以上に、メモリと演算回路の間で発生する大量のデータ転送が性能の制約となっているという。研究チームによると、大規模言語モデルのようなAIでは、メモリから計算ユニットへ膨大な情報を頻繁に移動させる必要があり、処理速度がデータ供給に追いつかない状態が生じやすい。こうした現象は、半導体分野では「メモリの壁」と呼ばれてきた。</p>
<p>また、従来の2Dチップでは、回路やメモリが単一の平面上に配置されるため、データは限られた配線を長距離移動する必要がある。トランジスタの微細化によって性能向上を図る手法についても、物理的な限界に近づきつつあると研究者らは指摘しており、この制約を「微細化の壁」と位置付けている。</p>
<h2>回路を「縦に積む」3Dチップ、モノリシック構造の特徴</h2>
<p>研究チームが開発した3Dチップは、こうした二つの壁を構造面から克服することを目的としたものだという。発表によると、超薄型の回路層を縦方向に積層し、それらを高密度な垂直配線で接続することで、メモリと演算回路を物理的に極めて近い距離に配置したとされる。</p>
<p>この構造について研究者らは、高層ビル内で多数のエレベーターが人の移動を支える仕組みに例えて説明している。多数の垂直経路を確保することで、データの移動量と速度を同時に高める狙いがあるという。</p>
<p>今回の成果の特徴として、研究室レベルの試作にとどまらず、「モノリシック3D」と呼ばれる構造のチップを、実際の商用半導体ファウンドリで製造した点が挙げられる。研究チームによれば、個別に作成したチップを後から積層する従来手法とは異なり、各層を連続的に積み上げる低温プロセスを用いることで、非常に高密度な層間接続を実現したという。</p>
<h2>実測で約4倍、将来は12倍──AI向け半導体への影響</h2>
<p>ハードウェア試験の結果について、研究チームは、試作チップが従来の2Dチップと比べてスループットで約4倍の性能向上を示したと報告している。さらに、より多くの層を積み上げた将来構成を想定したシミュレーションでは、実際のAIワークロードにおいて最大で約12倍の性能向上が見込まれるとしている。</p>
<p>これらの評価には、Metaのオープンソース大規模言語モデル「LLaMA」を基にした処理も含まれているという。</p>
<p>また、研究チームは、性能面だけでなくエネルギー効率の改善余地についても言及している。データ移動距離を大幅に短縮することで、処理速度と消費電力のバランスを示す指標である「エネルギー遅延積（EDP）」において、将来的に100倍から1,000倍規模の改善につながる可能性があると説明している。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【AI歴史年表】AIはダートマス会議から数えて来年で70周年！起源から生成AI革命までのAI全史を振り返る</title>
      <link>https://ledge.ai/articles/70year_history_of_ai_from_the_dartmouth_conference</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>2026年は、人工知能（AI）研究が正式に始動した歴史的な瞬間、1956年のダートマス会議から70周年という記念すべき節目を迎える。この70年間、AIは期待と幻滅の波を乗り越え、ついに人類の創造性を拡張する「生成AI」の時代へと到達した。この壮大な進化の軌跡を、各時代のエポックメイキングな出来事とともに紹介する。</p>
<h2>1. AIの誕生、最初の挫折と基礎構築 (1956–1979)</h2>
<p>人工知能（AI）は、1956年のダートマス会議でJ.マッカーシーらによって正式に分野として確立された。このダートマス会議で若手の中心となったJ.マッカーシー、M.ミンスキー、A.ニューウェルの3人はいずれも1927年生まれ、30歳を少し過ぎたところだ。ダートマス会議後、この3人はそれぞれスタンフォード大学、MIT、カーネギーメロン大学で活動し、AI研究の世界的な拠点が形成されていく。</p>
<p>初期の成功として、1958年にはF.ローゼンブラットが脳を模倣した初の学習可能モデルであるパーセプトロンを発表し、1966年にはJ.ワイゼンバウムが初の対話型システムであるELIZAを開発した。また、NNの学習においては、1967年に甘利俊一が確率的勾配降下法という後のディープラーニングの基礎となる最適化手法を発表するなど、技術的な基盤も築かれ始めていた。</p>
<p>しかし、この楽観的なブームは短期間で終焉を迎える。1969年、M.ミンスキーらがパーセプトロンの限界証明を行い、単層NNでは複雑な問題が解けないことを示唆した結果、AI研究への資金が大幅に削減され、最初の「冬の時代」が到来した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/01_70_AI_2ddf249970/01_70_AI_2ddf249970.jpg" alt="表01_70AI.jpg" /></p>
<p>この停滞期においても、後のAIの土台となる研究は継続された。日本では、1972年に甘利俊一が脳の記憶を模倣した連想記憶モデルを発表し、1979年には福島邦彦が、後の畳み込みニューラルネットワーク（CNN）の原型となるネオコグニトロンという階層型のNNモデルを開発した。この時期の日本の研究者の貢献は、AIの次の飛躍に向けた重要な種を蒔いたと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>2. AI研究の転換期における三つの潮流 (1980–1996)</h2>
<p>1980年代から1990年代前半にかけて、AI研究は、1970年代の停滞期を脱するため、異なる哲学に基づいた三つの潮流が並立した。</p>
<p>まず、記号主義（知識ベース）AIの流れを極限まで推し進めようとする試みがあった。その代表が1984年にD.レナートによって開始されたCycプロジェクトである。このプロジェクトは、人間が持つ膨大な常識をすべて手作業で知識ベースに構築し、究極のエキスパートシステムを実現することを目指した。これは、記号主義AIの可能性を探る壮大な挑戦であったが、同時に知識を形式化し獲得することの難しさを浮き彫りにした。</p>
<p>次に、長らく停滞していたニューラルネットワーク（NN）研究が息を吹き返した。この復活は、1982年にJ.ホップフィールドが、甘利俊一の先行研究と同系統の連想記憶モデルを、統計物理学の手法を用いて再発見したことに端を発する。これにより、NNが「記憶」のメカニズムを持つことが示唆された。決定的なブレイクスルーとなったのは、1986年にG.ヒントンらが多層NNを効率的に学習させる誤差逆伝播法（Backpropagation）を普及させたことである。この手法の登場は、NNが単層の限界を乗り越え、複雑なパターン認識を扱えるようになる第2次NNブームを牽引した。</p>
<p>そして第三の潮流として、従来の複雑な推論中心のAIに異を唱える行動ベースAIが登場した。1991年、iRobotの創業者でもあるR.ブルックスは、包摂アーキテクチャという新しい考え方を提唱し、その具体例として小型六本足ロボットのGenghisを開発した。これは、中央の知識ベースを持たず、環境からのセンサー情報に基づいて直接行動することで、現実世界でのタスク実行を重視するアプローチである。この研究は、AI研究の主流を、抽象的な推論から知覚と行動の統合へとシフトさせるきっかけとなり、その後のロボット工学に大きな影響を与えた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/02_70_AI_204dc3e658/02_70_AI_204dc3e658.jpg" alt="表02_70AI.jpg" /></p>
<p>このように、1980年代から90年代前半は、知識ベースの限界と挑戦、NNの劇的な復活、そして現実世界指向の新しいパラダイムの誕生という、複数の試行錯誤を通じて、後のAI発展の基礎が築かれた重要な転換期であったと言える。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>3. データと計算力によるAIの夜明け～ディープラーニングの衝撃 (1997–2016)</h2>
<p>1990年代後半から2010年代にかけてのAI研究は、インターネットの普及によるデータの爆発的な増加と、計算機能力の飛躍的な向上という二つの外部要因に強く支えられた。この時期、AIは「知識ベース」から「データ駆動」へとパラダイムを完全に転換し、特定のタスクで人間の能力を超える成果を上げ始めた。</p>
<p>まず、AIは特定の知的ゲームにおいて、人間を凌駕する能力を示した。1997年には、IBMのDeep Blueがチェスの世界チャンピオン、ガルリ・カスパロフに勝利し、「探索と計算」に特化したAIの能力を世界に示した。この頃、インターネットの本格的な普及は、AI研究の間接的な基盤を構築していた。Web上の膨大な情報（ビッグデータ）を分析するデータマイニングや統計的手法が発展し、AI研究も経験的なデータから知識を抽出する方向に傾倒していった。</p>
<p>AIに真のブレイクスルーをもたらしたのは、ニューラルネットワーク（NN）の進化であった。2006年、G.ヒントンらがディープラーニングを提唱し、多層NNを効率的に学習させる手法（深層化）に成功した。これは、増大するインターネット上のビッグデータを扱うために、極めて重要な進歩であった。この技術の有効性は、様々な分野で証明され始めた。2011年には、IBMのWatsonが、膨大な非構造化データ（書籍、記事など）から答えを導き出す能力により、米国の人気クイズ番組『ジェパディ！』で歴代チャンピオンに勝利した。そして2012年、ヒントンらが開発したAlexNetが、大規模な画像認識コンテスト（ILSVRC 2012）で圧倒的な性能を見せつけ、ディープラーニングが画像認識の主流技術となることを決定づけた。</p>
<p>この時期のAI研究の集大成となったのが、Google DeepMindによるAlphaGoの成功である。2016年、AlphaGoは、人間の直感と深い洞察力が求められる囲碁において、世界トップ棋士であるイ・セドル九段に勝利した。この勝利は、チェスのような「探索」だけでなく、「直感的な判断」が必要とされる領域でもAIが人間を超越したことを意味し、ディープラーニングと強化学習を組み合わせたAIが、人類の「知性の最後の砦」の一つを突破した歴史的な瞬間であった。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/03_70_AI_00677c2be5/03_70_AI_00677c2be5.jpg" alt="表03_70AI.jpg" /></p>
<p>この1997年から2016年にかけて、AIはインターネットによって供給されるデータと、高性能なGPUによって可能になった計算力を武器に、ディープラーニングという核技術を獲得し、次の「生成AI」時代への道筋を明確に作ったのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>4. 生成AI革命の勃発 (2017–2022)</h2>
<p>2017年から2022年の期間は、AI研究史上最も劇的な変革期であり、技術的なブレイクスルーと、それによる生成AI革命の勃発が特徴である。</p>
<p>この変革の起点は、2017年にGoogleが発表したTransformerモデルにあった。このモデルは、入力データ内の重要度を把握する「注意機構（Attention）」を採用し、計算を並列処理できるようになったため、大規模で深いネットワークの学習を可能にし、大規模言語モデル（LLM）の時代の扉を開いた。</p>
<p>このアーキテクチャを基盤に、2018年にOpenAIがGenerative Pre-trained Transformer（GPT）を開発し、LLMの基礎を築いた。さらに2020年には、モデルを大きくするほど性能が向上するというスケーリング則が確立され、LLMの巨大化戦略が主流となった。また、同年には拡散モデルが実用化され、高精度な画像生成AIの道も開かれた。</p>
<p>そして2022年、AIは一気に社会へ浸透した。LLMの推論能力を飛躍的に高める思考の連鎖（CoT）などの手法が開発される一方、Midjourneyなどの対話型画像生成AIが普及した。極めつけは、同年後半にOpenAIからリリースされたChatGPTである。人間と遜色ない自然な対話能力を持つChatGPTは、リリース後わずか約2か月で月間アクティブユーザー数1億人を突破し、生成AIブームを世界中に巻き起こした。</p>
<p>一方で、技術の急速な発展に伴い、AIの倫理と安全性に関する議論も本格化した。2017年にはアシロマ会議が開かれ、AIの安全な開発と利用に向けた「アシロマAI 23原則」が策定されたことも、この時期の重要な出来事である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/04_70_AI_28c3fdc49a/04_70_AI_28c3fdc49a.jpg" alt="表04_70AI.jpg" /></p>
<p>この5年間で、AIは「認識」から「創造」の領域へと能力を拡張し、人類の生活を一変させる新たなステージへと進んだのである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>5. 70周年の展望：AIと人類の未来 (2023年～)</h2>
<h3>5-1. 2023～2025年におけるAIと人類の状況</h3>
<p>2023年から2025年は、生成AI（Generative AI）技術が社会全体に急速に浸透した「AIの実用化元年」とも呼ぶべき変革期であった。特に大規模言語モデル（LLM）の進化により、AIは単なる自動化ツールから、人間の協働者や代行者へとその役割を急速に拡大した時期である。</p>
<p>日常生活においては、AIはスマートフォンや家電に深く組み込まれ、ルーティン作業の自動化、情報検索の高度化、そして個別化された健康管理の提供を通じて、人々の生活効率を向上させた。教育分野では、AIチューターや個別学習プログラムの利用が一般化し、生徒一人ひとりの進捗に合わせたカスタマイズ教育が主流となった一方で、教師は教材作成や評価の負担が軽減され、より対話的な指導に注力できるようになった。エンターテイメント領域では、AIによる画像、音楽、動画の生成が爆発的に増加し、コンテンツ制作の民主化が進んだ。また、AIを活用したパーソナライズされたゲーム体験や、没入型のMR/VRコンテンツも普及した。</p>
<p>ビジネスにおいては、AI導入が業務効率を大幅に向上させ、産業構造の再編を促した。ここでは利用形態に明確な対比が見られた。一つは、コーディングや文書作成などの専門作業において人間の作業を支援・加速するコパイロット型AIであり、これは人間の意思決定が最終的に介在する協調的な形態である。もう一つは、人間からの指示を基に複数のタスクを自律的に計画・実行し、ビジネスプロセスや顧客対応を代行・自動化するAIエージェントの進化である。この対比は、業務におけるAIの自律性の度合いを示す重要な指標となった。</p>
<p>政治においては、AIによる情報分析と政策立案支援が進み、行政の効率化が図られた。しかし同時に、AIが生成するディープフェイクや誤情報が選挙や世論形成に与える影響が重大な社会問題となり、各国でAIの倫理的利用と規制に関する議論が加速した。この時期、人類はAIの利便性を享受しつつも、その倫理性、安全性、社会への影響に対する向き合い方を確立する過渡期にあるのが現状である。</p>
<h3>5-2. 未来のAI：相乗効果と応用のグランドビジョン</h3>
<p>未来のAI技術 (AI_future) の進化は、現在の技術の単なる延長ではない。それは、基礎技術の「積」による指数関数的な相乗効果と、応用領域の「和」による社会的な価値の最大化によって実現されるビジョンである。
Ledge.aiでは、このビジョンを、以下のように定式化して考えている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ai70th_formula_ff6d7ead4c/ai70th_formula_ff6d7ead4c.png" alt="ai70th_formula.png" /></p>
<h3>■SYNERGY（相乗効果：積の力）による性能の飛躍</h3>
<p>現在のAI技術 (AI_current) は、四つの主要な基礎技術が掛け合わされる（積Π）ことで、その性能を劇的に高める。これらの技術は、それぞれがAIの抱える限界を突破する鍵となる。</p>
<ul>
<li><strong>量子コンピューター (Quantum) :</strong> AIの処理速度と複雑な問題解決能力に演算能力のブレイクスルーをもたらし、現行のスーパーコンピューターでは不可能な領域の学習と計算を可能にする。</li>
<li><strong>Web3 技術 (Web3):</strong> ブロックチェーンや分散型台帳技術により、AIが扱うデータと意思決定プロセスに透明性と信頼性を与え、分散化された環境での安全なAI連携を実現する。</li>
<li><strong>核融合エネルギー (Fusion):</strong> ほぼ無限かつクリーンなエネルギー源を提供することで、大規模な計算資源の制約を完全に緩和し、膨大なデータを用いた学習（超大規模モデル）を経済的かつ環境負荷なく実行可能にする。</li>
<li><strong>データインフラ (DataInfra):</strong> 5G/6Gや次世代ストレージ技術が実現する高速・大容量データ処理基盤が、AIのリアルタイムな学習と推論を支える。</li>
</ul>
<p>これらの技術が個別に進化するのではなく、相互に作用し合う（積）ことで、AIはこれまでにないレベルの知性を獲得する。</p>
<h3>■APPLICATION（応用価値：和の力）による社会実装</h3>
<p>性能が飛躍的に向上したAIは、様々な応用領域へ展開され、その価値を社会へ還元する。これらの応用領域は、AIの価値を社会的効用として積み重ねていく（和Σ）役割を担う。</p>
<ul>
<li><strong>Robotics (ロボティクス):</strong> 高度な知性を持つAIが、物理的な世界で活動するロボットと統合され、自動化・遠隔操作・協調作業を飛躍的に進化させる。</li>
<li><strong>MR (複合現実):</strong> AIがMR環境を分析・最適化し、人間とAIが直感的かつシームレスに連携する新たなインターフェースと作業空間を提供する。</li>
<li><strong>Autonomous Driving (自動運転):</strong> 複雑で予測不可能な環境においても、AIがリアルタイムに安全な判断を下し、交通システム全体を最適化することで社会インフラを革新する。</li>
<li><strong>Social Engineering (社会システムへの適用):</strong> 都市計画、医療、教育などの大規模な社会システムにAIが組み込まれ、データの分析と最適化を通じて社会全体の効率と公平性を向上させる。</li>
</ul>
<p>結論として、未来のAIは、基礎技術の「積」によって知性の限界を超え、応用領域の「和」を通じて私たちの生活、産業、そして社会構造そのものを根本から変革するグランドビジョンである。</p>
<p>金融分野でのいわゆる”AIバブル”は、早晩弾ける可能性がある。しかし、AI技術は着実な進歩が予想される。このようなグランドビジョンのもと、人類とAIの未来を創造していただければ幸いである。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Alphabet、データセンター電力を自前で確保へ──クリーンエネルギー開発のIntersectを47.5億ドルで買収</title>
      <link>https://ledge.ai/articles/alphabet_acquires_intersect_energy_data_center</link>
      <description><![CDATA[<p>Alphabetは2025年12月22日、データセンターおよびエネルギーインフラ開発を手掛けるIntersectを、現金47.5億ドルに加え、債務を引き受ける条件で買収することで合意したと<a href="https://abc.xyz/investor/news/news-details/2025/Alphabet-Announces-Agreement-to-Acquire-Intersect-to-Advance-U-S--Energy-Innovation-2025-DVIuVDM9wW/default.aspx">発表</a>した。AIやクラウド需要の拡大を背景に、データセンターと電力供給を一体で拡張する体制を構築する。</p>
<p>狙いは明確だ。電力とデータセンターを同時に増やす。
今回の買収によりAlphabetは、データセンターと発電設備をより迅速に立ち上げられるとしている。エネルギー開発とデータセンター建設を並行して進めることで、需要増に対して柔軟かつ機動的に対応する考えだ。</p>
<p>Intersectは、データセンター向け電力供給を中心としたエネルギー・インフラソリューションを提供してきた企業だ。取引には、Googleとの既存パートナーシップのもとで進められてきた複数ギガワット規模の電力およびデータセンタープロジェクトが含まれる。いずれも開発中または建設中の案件となる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/alphabet_96c0e4a3b1/alphabet_96c0e4a3b1.jpg" alt="alphabet.jpg" /></p>
<h2>電力とデータセンターを「同時に」増やす</h2>
<p>Alphabetは今回の買収について、データセンター容量と発電能力を同時に拡張できる点を重視している。AIの計算需要が急拡大する中、電力供給の制約がデータセンター建設のボトルネックになりつつあるためだ。</p>
<p>エネルギー供給とデータセンターを一体で設計・構築することで、立ち上げまでの時間短縮と運用の柔軟性向上を図る。</p>
<h2>数ギガワット規模、開発中プロジェクトを取得</h2>
<p>取引に含まれるのは、Intersectが開発または建設を進めているエネルギーおよびデータセンタープロジェクトだ。いずれもGoogleとの既存パートナーシップを通じて進められてきた案件で、数ギガワット規模に及ぶ。</p>
<p>Intersectは今後、エネルギー供給の拡大と多様化を目的に、新たな技術の検討も進めるとしている。</p>
<h2>Intersectは子会社化せず、独立運営を維持</h2>
<p>買収後もIntersectは、AlphabetおよびGoogleとは別組織として独立運営を続ける。ブランドも維持され、経営は創業者兼CEOのSheldon Kimber氏が引き続き担う。</p>
<p>IntersectはGoogleのテクニカルインフラチームと緊密に連携し、既存案件に加え、新たな共同プロジェクトにも取り組む。</p>
<h2>テキサスで進む「電源併設型」データセンター</h2>
<p>具体的な共同プロジェクトとして、テキサス州Haskell County, Texasで建設が進む、データセンターと電源を併設した拠点が挙げられている。両社が初めて発表した、データセンターと電力供給を一体で設計する事例だ。</p>
<h2>既存の稼働資産は取引の対象外に</h2>
<p>Intersectが保有するテキサス州の既存稼働資産および、カリフォルニア州の稼働・開発中資産は、今回の買収対象には含まれない。これらの資産は、TPG Rise Climate、Climate Adaptive Infrastructure、Greenbelt Capital Partnersといった既存投資家の支援のもと、独立した企業として運営が継続される。</p>
<p>Intersectは、これらの資産について顧客向けサービスの継続を見込んでいる。</p>
<h2>地熱・蓄電・CCS、先端エネルギーを加速</h2>
<p>Alphabetは、今回の買収を通じて、先進地熱、長時間エネルギー貯蔵、炭素回収・貯留（CCS）付きガス発電といった先端エネルギー技術の商用化を加速するとしている。</p>
<p>あわせて、AIを活用した新規発電所の送電網接続の効率化や、データセンター立地地域におけるエネルギー効率・価格面での取り組みも進める。</p>
<h2>両社トップが語る「AI時代のインフラ」</h2>
<p>AlphabetおよびGoogleのCEOであるSundar Pichai氏は、「Intersectは、データセンターの新設と連動した発電能力の構築を可能にし、エネルギーソリューションを再構築する助けになる」とコメントした。
一方、Sheldon Kimber氏は、「現代のインフラはAI時代における米国競争力の要であり、エネルギー革新と地域への投資が次の成長を支える」と述べている。</p>
<p>本取引は、規制当局の承認など通常のクロージング条件を前提としており、2026年前半の完了が見込まれている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、AIエージェント開発における”スキル”重視の新設計思想を提示──「IQ300数学の天才から経験豊富な税務専門家へ」、スキル中心アーキテクチャの全体像を解説</title>
      <link>https://ledge.ai/articles/anthropic_ai_agents_build_skills_paradigm</link>
      <description><![CDATA[<p>Anthropicに所属するBarry Zhang氏とMahesh Murag氏は、2025年11月21日に開催された開発者向けイベント「AI Engineer Code Summit」で<a href="https://www.youtube.com/watch?v=CEvIs9y1uog">講演</a>を行い、AIエージェント開発における新たな設計思想を提示した。講演の模様は、同イベントを主催する開発者コミュニティ「AI Engineer」のYouTubeチャンネルで、12月9日に動画として公開されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=CEvIs9y1uog&amp;t=183s">YouTube</a></p>
<p>両氏は講演の中で、現在主流となりつつある「AIエージェント」を多数構築するアプローチに疑問を投げかけ、「エージェントではなくスキルを構築すべきだ」と主張した。汎用的な知性を持つAIエージェントが、実務において専門家として振る舞うことの難しさを課題として挙げ、その解決策として「スキル」という新しい概念を提示している。</p>
<p>具体的には、業務に必要な手続き的知識を「スキル」として明示的にパッケージ化し、エージェントが必要に応じて段階的に読み込むアーキテクチャを紹介した。このスキル中心のアプローチは、AIエージェントの実用性や拡張性を高めるだけでなく、専門知識の再利用や共有、さらにはAI自身による継続的な学習の基盤となる可能性がある。本記事では、AI Engineer Code Summitで語られた講演内容をもとに、Anthropicの研究者が示したAIエージェント開発の新パラダイムと、その全体像を整理する。</p>
<h2>現代のAIエージェントが抱える課題──「優秀だが経験不足」というジレンマ</h2>
<p>AIエージェントは近年、推論能力やツール利用能力の向上によって急速に注目を集めている。一方で、実務の現場では「期待したほど使えない」と感じられるケースも少なくない。講演で両氏は、その理由を分かりやすい比喩で説明した。</p>
<p><strong>■「IQ300の数学の天才」と「経験豊富な税務専門家」の対比で示される、AIエージェントの課題</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/genius_iq300_1526483afb/genius_iq300_1526483afb.jpg" alt="①genius iq300.jpg" /></p>
<p>「あなたの税務処理を任せるなら、IQ300の数学の天才と、長年の経験を持つ税務専門家のどちらを選びますか？」という問いだ。多くの場合、選ばれるのは後者だろう。税務のような専門業務では、生の知性よりも、確立された手続きを一貫して実行できる経験の方が重要だからだ。</p>
<p>現在のAIエージェントは、この「IQ300の天才」に近い存在だと両氏は指摘する。高い汎用知性を備えている一方で、実務に必要な前提知識や暗黙知を最初から持っているわけではなく、専門家としての経験値が不足している。その結果、以下のような課題に直面する。</p>
<ul>
<li>業務特有の文脈や前提を十分に理解できない</li>
<li>専門的な手順やノウハウを効率よく身につけられない</li>
<li>特定のチームやユーザーと長期間協業しても、その経験が蓄積されない</li>
</ul>
<p>こうした課題を踏まえ、Anthropicは従来のエージェント構築の考え方そのものを見直す必要があると提起した。</p>
<h2>Anthropicが提唱する解決策──「エージェント」ではなく「スキル」という発想</h2>
<p>両氏が提示した解決策の中心にあるのが、「スキル」という概念だ。これは、エージェントそのものを高度化するのではなく、エージェントに付与する専門知識の持たせ方を再設計するという発想に基づいている。</p>
<p><strong>■ Anthropicが示すAIスタックの整理。スキルはアプリケーション層に位置づけられる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/moving_up_the_stack_f254f9be32/moving_up_the_stack_f254f9be32.jpg" alt="②moving up the stack.jpg" /></p>
<p>Anthropicの考えでは、エージェントはあくまで汎用的な推論主体として位置づけられるべき存在だ。専門家としての振る舞いは、エージェント自身がその場で学習するのではなく、事前に整理された手続き的知識を「スキル」として与えることで実現する。</p>
<p>このアプローチにより、エージェントは未知の分野を即興的に推論するのではなく、すでに確立された専門家のやり方に沿って行動できるようになる。結果として、実務で求められる一貫性や再現性を確保しやすくなるという。</p>
<h2>「スキル」とは何か──手続き的知識をフォルダとして扱う設計</h2>
<p>講演で定義された「スキル」は、エージェントのための構成可能な手続き的知識をパッケージ化した、整理されたファイル群である。具体的には、単なるフレームワークや抽象APIではなく、誰もが理解できる「フォルダ」という形で実装される。</p>
<p><strong>■ スキルは特別なフレームワークではなく、手続き的知識をまとめたフォルダとして定義される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/skills_are_just_folders_fe2866b20f/skills_are_just_folders_fe2866b20f.jpg" alt="③skills are just folders.jpg" /></p>
<p>スキルの中には、以下のような要素が含まれる。</p>
<ul>
<li>スキルの目的や使い方を記述したドキュメント</li>
<li>実行可能なスクリプトやテンプレート</li>
<li>補助的な設定ファイルや例</li>
</ul>
<p>この設計の特徴は、特別なツールや専用環境を必要としない点にある。Gitによるバージョン管理や、クラウドストレージでの共有など、既存の開発者ワークフローと自然に統合できる。</p>
<p>また、スキルはランタイム時に段階的に読み込まれる。最初にエージェントへ提示されるのは、スキルの存在を示すメタデータのみで、必要と判断された場合にのみ詳細な指示やファイルが読み込まれる。この仕組みにより、コンテキストウィンドウの消費を抑えつつ、多数のスキルを併用することが可能になる。</p>
<h2>急速に拡大するスキルエコシステム──基盤・サードパーティ・エンタープライズ</h2>
<p>スキルの仕組みは、すでに活発なエコシステムを形成しつつある。講演によれば、公開から短期間で数千のスキルがコミュニティによって作成されているという。</p>
<p><strong>■ スキルは「基盤」「パートナー」「エンタープライズ」の3層で構成されるエコシステムを形成している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_skills_ecosystem_d01ca1d0cb/the_skills_ecosystem_d01ca1d0cb.jpg" alt="④the skills ecosystem.jpg" /></p>
<p>スキルは大きく、次の3つに分類できる。</p>
<p>まず「基盤スキル」は、エージェントに新たな汎用能力や特定分野の能力を付与するものだ。プロ品質のオフィス文書作成や、科学研究向けデータ解析などが例として挙げられた。</p>
<p>次に「サードパーティスキル」は、外部企業が自社製品とAIエージェントを連携させるために開発したスキルだ。ブラウザ自動化ツールや、ナレッジ管理サービスと連携するスキルが紹介された。</p>
<p>最後に「エンタープライズスキル」は、企業やチーム内で蓄積された業務ノウハウをエージェントに教えるためのものだ。社内独自の業務プロセスや、チーム固有の開発ルールをスキルとして共有することで、組織全体の生産性向上につなげられる。</p>
<p>講演では、特に非エンジニアの専門家がスキルを作成している点が注目すべき動きとして紹介された。金融、法務、採用などの分野で、専門知識を持つ人々が自らAIを強化していることは、このアプローチの有効性を示す事例といえる。</p>
<h2>スキルを前提にした汎用エージェントのアーキテクチャ</h2>
<p>スキルは、AIエージェント全体のアーキテクチャの中で重要な役割を担う。講演では、汎用エージェントを構成する要素として、次の4点が示された。</p>
<ul>
<li>モデルの思考と入出力を管理するエージェントループ</li>
<li>ファイル操作やコード実行を可能にするランタイム環境</li>
<li>外部APIやデータと接続するMCP（Model Context Protocol）サーバー</li>
<li>手続き的専門知識を提供するスキルライブラリ</li>
</ul>
<p><strong>■ MCPサーバー、エージェント、ファイルシステム上のスキルの関係を示した汎用エージェントの基本構成</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/skills_the_complete_picture_900b270496/skills_the_complete_picture_900b270496.jpg" alt="⑤skills the complete picture.jpg" /></p>
<p>この構成により、エージェントは汎用性を保ったまま、スキルとMCPを組み合わせることで特定の業務や業界に適応できる。Anthropicは、金融やライフサイエンスといった分野向けにサービスを迅速に展開できた事例を紹介し、このアーキテクチャの柔軟性を示した。</p>
<h2>スキルの共有と自己生成──Anthropicが描く今後の展望</h2>
<p>Anthropicは、スキルを単なる機能拡張ではなく、AI能力を共有・進化させる基盤として位置づけている。スキルが複雑化するにつれ、テストやバージョン管理、依存関係の明示といったソフトウェア開発の手法を取り入れる重要性も指摘された。</p>
<p><strong>■ スキルは評価・バージョン管理・構成可能性を備え、ソフトウェアとして進化していく</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/exploring_how_skills_evolve_484db0b197/exploring_how_skills_evolve_484db0b197.jpg" alt="⑥exploring how skills evolve.jpg" /></p>
<p>さらに講演では、AI自身がスキルを生成する可能性にも言及された。Claudeはすでに「スキルクリエイター」として、ユーザーのためにスキルを作成できるとされており、今後は対話を通じて学んだ手続き的知識をスキルとして保存する方向性が示されている。</p>
<p>こうした仕組みが実現すれば、AIが学んだ内容は一時的な記憶ではなく、再利用可能な知識資産として蓄積されることになる。Anthropicが掲げる「あなたと30日間働いたClaudeは、初日のClaudeより優れている」という目標に向けて、スキルは重要な役割を果たすと位置づけられている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIに自動販売機の経営を任せると何が起きるのか──Anthropic、「Project Vend」フェーズ2の実験結果を公開</title>
      <link>https://ledge.ai/articles/anthropic_project_vend_phase2_ai_vending_machine</link>
      <description><![CDATA[<p>米AIスタートアップの Anthropic は2025年12月18日、同社製の大規模言語モデル（LLM）を自動販売機の運営に組み込み、発注や価格設定などの意思決定をAIに任せる実証実験「Project Vend」フェーズ2の結果を<a href="https://www.anthropic.com/research/project-vend-2">公開</a>した。</p>
<p>2025年6月に公表された初期実験（フェーズ1）から約半年を経て実施されたフェーズ2では、機能面の改善に加え、より“現実的で扱いづらい環境”での検証が行われている。</p>
<h2>自動販売機を「AI店長」に任せるという発想</h2>
<p>Project Vendは、AIエージェントが現実世界の業務運営をどこまで自律的に担えるのかを検証する試みだ。Anthropicは、社内に設置された売店（自動販売機に近い小規模販売環境）を対象に、商品の仕入れ、在庫管理、価格の調整といった判断を、LLMベースのAIエージェントに委ねた。</p>
<p>実験の狙いは、単に売上を上げることではない。人間が暗黙知として処理している「現実の制約」や「想定外の出来事」に対して、AIがどのように振る舞うのかを観察する点にある。Anthropicはこのプロジェクトを、AIエージェントの社会実装に向けた“ストレステスト”の一環と位置付けている。</p>
<p>@<a href="https://www.youtube.com/watch?v=5KTHvKCrQ00">YouTube</a></p>
<h2>フェーズ1で露呈した課題</h2>
<p>2025年6月に公開されたフェーズ1では、AIが一定程度の運営判断をこなす一方で、課題も明確になった。例えば、売れ筋商品とそうでない商品の区別がうまくつかず、在庫が偏るケースや、極端な値下げ・値上げを行ってしまう場面が確認されたという。</p>
<p>また、人間側から与えられる指示や質問（プロンプト）に過剰に反応し、ビジネス的に合理的とは言えない判断に引きずられる傾向も見られた。フェーズ1は、AIが「経営者のように振る舞えるか」を探る第一歩であると同時に、現実運用の難しさを浮き彫りにする結果となっていた。</p>
<h2>フェーズ2で取り入れられた改善</h2>
<p>フェーズ2では、こうした反省を踏まえ、実験設計が見直された。Anthropicによると、AIが参照するデータや手続きが整理され、在庫や売上情報に基づいた判断がより安定するよう調整されたという。</p>
<p>価格設定についてもロジックが改良され、極端な値付けを避けるための制約が組み込まれた。また、人間からの指示をどこまで受け入れるかについても見直しが行われ、運営判断の一貫性を保つためのガードレールが強化された。</p>
<p>これらの変更により、フェーズ1で顕在化した一部の非効率な挙動は改善されたとされている。ただし、Anthropicは同時に「完全に問題が解消されたわけではない」とも説明している。</p>
<h2>WSJ参加で浮かび上がった“人間の影響力”</h2>
<p>フェーズ2のもう一つの特徴は、実験環境を社内に閉じず、外部の参加者を巻き込んだ点だ。実験には、米紙 The Wall Street Journal のジャーナリストも参加した。</p>
<p>WSJ側の報道によると、記者らは意図的にひねりの効いた質問や指示をAIに投げかけた。その結果、AIが判断に迷い、価格設定や運営方針が一時的に混乱する様子が観察されたという。
この過程では、AIが形式上は「店長」として振る舞っていても、人間からの入力の仕方次第で意思決定が大きく揺らぐことが示された。</p>
<p>@<a href="https://www.youtube.com/watch?v=SpPhm7S9vsQ">YouTube</a></p>
<p>Anthropicは、このような外部からの“敵対的とも言える入力”を含めて検証すること自体が重要だとしており、WSJの参加を通じて、実運用に近い課題を洗い出す狙いがあったとしている。</p>
<h2>「AI経営」の可能性と現実</h2>
<p>Project Vendのフェーズ2は、AIエージェントが現実世界のビジネスを担う際の可能性と限界を同時に示す結果となった。機能改善によって安定性は向上したものの、人間の関与や入力の設計次第で結果が大きく変わる点は依然として残っている。</p>
<p>Anthropicは、この実験を通じて「AIにすべてを任せる」未来を即座に描いているわけではない。むしろ、どの部分をAIに委ね、どこに人間の監督や設計が必要なのかを見極めるための材料を集めている段階だと位置付けている。</p>
<p>同社は今後も段階的な検証を続け、AIエージェントを現実の業務に適用するための知見を積み重ねていくとしている。自動販売機という身近な題材を通じて行われているこの実験は、AIが「現実で働く存在」になるための課題を、分かりやすい形で示すケーススタディとなりそうだ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIは駆け出しの開発者を置き換えられない──AWSのガーマンCEO、WIREDのポッドキャストで3つの理由を説明</title>
      <link>https://ledge.ai/articles/aws_garman_ai_cannot_replace_entry_level_developers</link>
      <description><![CDATA[<p>米Amazon Web Services（AWS）のマット・ガーマンCEOは2025年12月16日、WIREDのポッドキャスト番組「The Big Interview」に<a href="https://www.wired.com/story/the-big-interview-podcast-matt-garman-ceo-aws/">出演</a>し、生成AIの普及が進む中でも駆け出しの開発者（若手開発者）をAIで置き換える発想は適切ではないとの見解を示した。
同氏は、若手層をAIで代替する考え方について「長期的な会社づくりを目指すなら成り立たない」と述べ、その理由を3点に分けて説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/wired_matt_garman_ae1c2bae43/wired_matt_garman_ae1c2bae43.jpg" alt="wired matt garman.jpg" /></p>
<p>WIREDの対談でガーマン氏は、近年一部で語られている「ジュニア社員をAIに置き換える」という発想に触れ、少なくともソフトウェア開発者については合理的ではないと語った。そのうえで、若手開発者を「置き換える」対象として捉えるのではなく、AIツールの活用によって働き方や役割が変化していく可能性を示しつつ、企業が長期的な視点で人材を育成する重要性を強調した。</p>
<h2>理由1：駆け出し層ほどAIツールに慣れており、活用の担い手になり得る</h2>
<p>ガーマン氏が最初に挙げた理由は、駆け出しの開発者ほどAIツールに習熟している場合が多いという点だ。対談では、最も若手の層が生成AIなどの新しいツールに最も慣れていることが少なくないと述べ、AIによって置き換える対象というよりも、むしろAIから価値を引き出す中心的な担い手になり得るとの趣旨を示した。</p>
<h2>理由2：コスト最適化の観点でも、駆け出し層の置き換えは合理的でない</h2>
<p>2点目として同氏は、若手開発者は一般に人件費が相対的に低いことを挙げた。コスト最適化を目的として人員構成を見直す場合であっても、駆け出し層は「最も安い部類」に属することが多く、そこだけをAIに置き換えるという発想は合理的ではないとの見方を示している。</p>
<h2>理由3：採用・育成の断絶はタレントパイプラインを損ない、長期的に組織が成り立たない</h2>
<p>3点目としてガーマン氏は、タレントパイプライン（若手を採用し、育成し、次世代へとつなげる流れ）を途切れさせるリスクを指摘した。若手を採用せず、メンタリングや育成を行わない状態が続けば、組織の健全性が損なわれる可能性があるという。</p>
<p>同氏は、採用したばかりの若手が最良のアイデアをもたらすことがある点にも触れ、「新しい血」が入ることで会社に活気や新しい発想が生まれると説明した。駆け出しの開発者を採らないという判断は、長期的な会社づくりを目指す企業にとっては“成り立たない（nonstarter）”と述べている。</p>
<h2>「仕事は変わる」──ガーマン氏が見通すAI導入後の働き方</h2>
<p>一方でガーマン氏は、AIエージェントの普及によって仕事の内容や進め方が変わること自体は避けられないとの認識も示した。対談では、自社の従業員に対して「仕事は変わる」と伝えていると語り、数年前に成功していたやり方が来年も同じように通用するとは限らないと述べている。</p>
<p>その上で、AIによって担当範囲が広がり、より大きな影響を与えられるようになる可能性がある一方、学び方や働き方を柔軟に変えられなければ、変化の速い環境で後れを取ることもあり得るとした。雇用全体への影響については不確実性があるとしながらも、中長期的にはAIが新たな経済的機会を生み、失われる仕事以上に新しい仕事が生まれる可能性が高いとの見方を示している。</p>
<p>ただし、短期的には職種によって人手が減る局面が起こり得るとも言及し、企業側の役割として、訓練やリスキリングを通じて人材を再配置していく必要があるとの考えも示した。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>デジタル庁と内閣府、市区町村単位の「Japan Dashboard」を公開──経済・財政・人口・暮らしを横断可視化</title>
      <link>https://ledge.ai/articles/digital_agency_cabinet_office_japan_dashboard_municipality</link>
      <description><![CDATA[<p>デジタル庁は2025年12月19日、内閣府と共同で、自治体データを市区町村単位で可視化するJapan Dashboard｜経済・財政・人口と暮らしの市区町村版を<a href="https://www.digital.go.jp/resources/japandashboard/economy-fiscal-living-municipality">発表</a>した。経済、財政、人口、暮らしに関する主要指標を、地図やグラフで比較・分析できる。</p>
<h2>国・都道府県に続き、市区町村版を新たに公開</h2>
<p>Japan Dashboardは、政府が整備を進めてきたデータ可視化基盤だ。これまで国・都道府県単位の情報提供が中心だったが、今回新たに市区町村単位のデータが追加された。デジタル庁と内閣府が連携して提供する。</p>
<h2>人口・財政・経済・暮らしを横断的に把握</h2>
<p>市区町村版では、次のような領域の指標が収録されている。</p>
<ul>
<li>人口（人口増減、高齢化率など）</li>
<li>経済・雇用関連指標</li>
<li>地方財政（歳入・歳出、財政力指数など）</li>
<li>教育、社会保障、社会基盤、暮らしに関する指標
いずれも政府統計などの公的データを基に構成されている。</li>
</ul>
<h2>地図・比較・時系列で直感的に分析</h2>
<p>ダッシュボードでは、地図表示による地域分布の把握、市区町村間の比較、指標同士の相関表示、時系列での推移確認が可能だ。専門的な分析ツールを使わず、ブラウザ上で操作できる。</p>
<h2>自治体ニーズを踏まえた整備</h2>
<p>内閣府の会議資料によると、市区町村版の整備は、自治体からの要望を踏まえて検討された。EBPM（証拠に基づく政策立案）やデータ活用を、現場レベルで支援する狙いがある。</p>
<h2>自治体職員から民間・市民まで利用を想定</h2>
<p>想定される利用者は、自治体職員（施策立案や現状把握）に加え、研究者やメディア、民間企業、スタートアップ、市民や学生など幅広い。データは無償で閲覧できる。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米エネルギー省、AI国家計画「Genesis Mission」推進で24団体と合意―—OpenAI、Google、Microsoft、NVIDIAなどが参加</title>
      <link>https://ledge.ai/articles/doe_genesis_mission_24_organizations_ai_collaboration</link>
      <description><![CDATA[<p>アメリカ合衆国エネルギー省（DOE）は2025年12月18日、AIを活用して科学的発見を加速し、国家安全保障の強化とエネルギー分野の技術革新を進める国家的取り組み「Genesis Mission（ジェネシス・ミッション）」の推進に向け、24の組織と協力に関する覚書（MOU）を締結したと<a href="https://www.energy.gov/articles/energy-department-announces-collaboration-agreements-24-organizations-advance-genesis">発表</a>した。</p>
<p>ジェネシス・ミッションは、AIの力を用いて発見科学（discovery science）を加速し、国家安全保障を強化し、エネルギー分野のイノベーションを推進することを目的とした国家的イニシアチブで、DOEはこれを「歴史的な取り組み」と位置づけている。</p>
<h2>ホワイトハウスでの会合を通じ、官民連携を始動</h2>
<p>今回のMOU締結は、ホワイトハウスで行われた会合を通じて公表された。会合には、米エネルギー長官のChris Wright氏、DOE科学担当次官でジェネシス・ミッションのディレクターを務めるDarío Gil氏、ホワイトハウス科学技術政策局（OSTP）局長のMichael Kratsios氏のほか、民間企業の関係者らが出席した。</p>
<p>DOEは、この会合を通じて、AI技術に関する官民のイノベーション・パートナーシップを立ち上げ、前例のないスピードで科学の限界を押し広げるための、拡張可能な国家インフラの確保を目指すとしている。</p>
<h2>「関心表明」や既存プロジェクトを背景にMOU締結</h2>
<p>DOEによれば、今回MOUを締結した24団体は、</p>
<ul>
<li>DOEが実施した情報提供依頼（RFI）に応じてジェネシス・ミッションへの関心を表明した組織、</li>
<li>もしくは、DOEや国立研究所とジェネシス・ミッション関連の活動において、すでに進行中のプロジェクトを持つ組織</li>
</ul>
<p>で構成されている。</p>
<p>また、ジェネシス・ミッション向けに開発・提供される成果物については、特定のアーキテクチャに依存しない（architecture-agnostic）形で設計されるとしている。</p>
<h2>参加24団体（DOE発表、12月18日時点）</h2>
<p>DOEが公表したMOU締結先は以下の24団体。</p>
<ul>
<li>Accenture</li>
<li>AMD</li>
<li>Anthropic</li>
<li>Armada</li>
<li>Amazon Web Services</li>
<li>Cerebras</li>
<li>CoreWeave</li>
<li>Dell</li>
<li>DrivenData</li>
<li>Google</li>
<li>Groq</li>
<li>Hewlett Packard Enterprise</li>
<li>IBM</li>
<li>Intel</li>
<li>Microsoft</li>
<li>NVIDIA</li>
<li>OpenAI</li>
<li>Oracle</li>
<li>Periodic Labs</li>
<li>Palantir</li>
<li>Project Prometheus</li>
<li>Radical AI</li>
<li>xAI</li>
<li>XPRIZE</li>
</ul>
<h2>国家AI戦略との位置づけ</h2>
<p>DOEは今回の発表について、トランプ大統領が署名したAI関連の大統領令および、今年公表された「America’s AI Action Plan」に基づく取り組みの一環であると説明している。これらは、イノベーションの障壁を取り除き、外国の競争相手への依存を減らし、米国の科学技術基盤を最大限に活用することを目的としている。</p>
<h2>今後の展開と追加募集</h2>
<p>DOEは今後、民間企業、学術機関、慈善団体などとの協議の場をさらに設け、ジェネシス・ミッションに参加する適格な協力者の拡大を図るとしている。</p>
<p>あわせて、以下のRFIについて、引き続き提案の提出を受け付けている。</p>
<ul>
<li>「Partnerships for Transformational Artificial Intelligence Models」：2026年1月14日締切</li>
<li>「Transformational AI Capabilities for National Security」：2026年1月23日締切</li>
</ul>
<p>DOEは、こうした官民連携を通じて、AIを中核とした次世代の科学研究・技術開発基盤の構築を進めていく考えだ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIに「長期記憶」を与える新アーキテクチャ「Titans」と設計理論のフレームワーク「MIRAS」を発表</title>
      <link>https://ledge.ai/articles/google_ai_long_term_memory_titans_miras</link>
      <description><![CDATA[<p>Google Researchは2025年12月4日、AIモデルに長期的な記憶能力を持たせるための新たなアーキテクチャ「Titans」と、その設計思想を統一的に説明するフレームワーク「MIRAS」を<a href="https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/">発表</a>した。</p>
<p>Transformerを中心とする既存の大規模言語モデルが抱えてきた「長い文脈を扱うほど計算コストが増大し、重要な情報を保持しにくい」という課題に対し、推論時に記憶を学習・更新するという新しいアプローチを提示している。</p>
<h2>Transformerの限界と「記憶」の再定義</h2>
<p>TransformerはAttention機構によって高精度な依存関係のモデリングを可能にしてきた一方、計算量がコンテキスト長の二乗に比例するという制約を持つ。このため、極端に長い文書や時系列データを扱う際には効率面・性能面の両方で課題があった。</p>
<p>Google Researchは、Attentionを「短期記憶」、それを補完する仕組みとして「長期記憶」を明確に分離して設計する必要があると位置づけた。</p>
<h2>推論時に学習する「Titans」の中核</h2>
<p>Titansの中心となるのは「Neural Long-Term Memory Module」と呼ばれる長期記憶モジュールだ。このモジュールは、再学習を行うことなく、推論時に入力を受け取りながら記憶を更新する。単なるキー・バリューキャッシュとは異なり、過去の情報をモデル内部のパラメータとして蓄積できる点が特徴だ。</p>
<p><strong>■ Titansの全体構成：</strong> Attentionによる短期記憶に加え、推論時に更新されるNeural Memory（長期記憶）を統合。入力の重要度に応じて記憶を更新しつつ、固定パラメータとは独立して動作する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Titans_1_Overview_width_1250_e2f30e7bc8/Titans_1_Overview_width_1250_e2f30e7bc8.png" alt="Titans-1-Overview.width-1250.png" /></p>
<p>Titansでは、長期記憶の統合方法として以下の3つの構成を提示している。</p>
<ul>
<li><strong>MAC（Memory as a Context）：</strong> 記憶を文脈としてAttentionに渡す方式</li>
<li><strong>MAG（Memory as a Gate）：</strong> 記憶によってAttention出力を制御する方式</li>
<li><strong>MAL（Memory as a Layer）：</strong> 記憶を独立したレイヤーとして組み込む方式</li>
</ul>
<p>特にMAC構成は、長距離依存関係を扱うタスクで高い性能を示したという。</p>
<h2>「驚き」に基づく選択的記憶と忘却</h2>
<p>Titansはすべての情報を無差別に記憶するのではなく、予測誤差が大きい、いわゆる「驚き（surprise）」の高いトークンを優先的に長期記憶へ反映する設計を採用している。
また、weight decayやモメンタムを用いた更新により、不要になった情報を忘却できる仕組みも備える。これにより、従来の線形RNNやゲート型モデルでは難しかった「完全な記憶の消去」も可能になるという。</p>
<h2>2Mトークン超でも性能を維持</h2>
<p>論文では、言語モデリング、常識推論、needle-in-a-haystackタスク、DNA解析、時系列予測など幅広いベンチマークで評価を実施。BABILongやRULERといった長文タスクでは、GPT-4やRAGを併用した大規模モデルを含む既存手法を上回る結果を示した。
有効なコンテキスト長は200万トークンを超えても性能が維持されることが確認されている。</p>
<h2>設計理論「MIRAS」が示す統一的枠組み</h2>
<p>MIRASは、Titansを含むさまざまなシーケンスモデルを「連想記憶システム」として捉え直すためのフレームワークだ。</p>
<p>設計要素を</p>
<ol>
<li>記憶構造</li>
<li>想起のための目的関数（attentional bias）</li>
<li>保持・忘却を制御するゲート</li>
<li>記憶の学習アルゴリズム</li>
</ol>
<p>の4点に整理し、Transformerや線形RNN、Titansを同一の理論枠組みで説明できるとしている。</p>
<p><strong>■ MIRASフレームワークの概念図：</strong> 記憶構造、想起基準（attentional bias）、保持・忘却（retention gate）、学習アルゴリズムの4要素で、TitansやTransformerを含むシーケンスモデルを統一的に説明する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/miras_framework_47bb139255/miras_framework_47bb139255.jpg" alt="miras framework.jpg" /></p>
<p>MIRASを基に、Moneta、Yaad、Memoraといった新たなモデル群も提案されており、タスク特性に応じた記憶設計の可能性が示された。</p>
<h2>推論時学習という新たな方向性</h2>
<p>Google Researchは、TitansをMIRASフレームワークの具体例の一つと位置づけている。外部検索に依存するRAGや、巨大な固定コンテキストを用意する方法とは異なり、「推論時に学習する記憶」を内包したAI設計が、今後の長文・長期推論の重要な方向性となる可能性を示した形だ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、「Gemini 3 Flash」公開　“Pro級の推論”を低遅延・低コストで、Geminiアプリの既定モデルに</title>
      <link>https://ledge.ai/articles/google_gemini_3_flash_default_model_release</link>
      <description><![CDATA[<p>Googleは2025年12月17日（現地時間）同社の生成AIモデル「Gemini 3」ファミリーに新たに「Gemini 3 Flash」を追加し、提供を開始したことを<a href="https://blog.google/products/gemini/gemini-3-flash/">発表</a>した。Gemini 3 Flashは、スピードを重視しながらも高度な推論能力とマルチモーダル機能を維持する点を特徴としており、一般ユーザー向けのGeminiアプリでは既定モデルとして展開される。</p>
<p>@<a href="https://www.youtube.com/watch?v=rPXBDSf-Hwg">YouTube</a></p>
<p>Googleによると、Gemini 3 Flashは「高速性、知能、コスト効率のバランス」を重視して設計されたモデルで、日常的な知識労働からソフトウェア開発まで、幅広いユースケースを想定している。同社は、Gemini 3の次世代インテリジェンスをGoogle製品全体に広げる役割を担うモデルだと位置づけている。</p>
<h2>推論ベンチマークで示された“Pro級”の性能</h2>
<p>公式ブログでは、Gemini 3 Flashの性能を示す指標として、複数の評価ベンチマークが公開された。高度な専門知識を問う「GPQA Diamond」では90.4％、「Humanity’s Last Exam」ではツール非使用条件で33.7％を記録したとしている。Googleは、これらの結果が、より大規模なフロンティアモデルに匹敵する水準だと説明している。</p>
<p>また、マルチモーダル理解能力を測る「MMMU Pro」では81.2％に到達し、Gemini 3 Proと同等レベルの性能を示したという。推論能力とマルチモーダル処理を両立している点が、Gemini 3 Flashの重要な特徴とされている。</p>
<p><strong>■ Gemini 3 Flashと他モデルを比較した公式ベンチマーク。推論、マルチモーダル理解、コーディングなど幅広い指標で、上位モデルに近いスコアを示している。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_flash_final_benchmark_t_width_1000_format_webp_1aa4e26a6b/gemini_3_flash_final_benchmark_t_width_1000_format_webp_1aa4e26a6b.webp" alt="gemini-3-flash_final_benchmark-t.width-1000.format-webp.webp" /></p>
<p>加えて、ソフトウェア開発分野では、コード生成や修正能力を評価する「SWE-bench Verified」で78％を記録し、Gemini 2.5系やGemini 3 Proを上回ったとしている。Googleは、反復的な開発作業やエージェント型ワークフローに適したモデルだと説明している。</p>
<h2>「2.5 Pro比で3倍高速」、コスト効率も前面に</h2>
<p>速度面では、外部評価機関Artificial Analysisによる測定結果として、Gemini 3 Flashは「Gemini 2.5 Proと比べて最大で約3倍高速」と説明されている。加えて、同等のタスクを処理する際に必要なトークン数が平均で約30％少なく、コスト効率にも優れるという。</p>
<p>開発者向けの価格設定は、入力が100万トークンあたり0.50ドル、出力が同3ドル。音声入力は100万トークンあたり1ドルとされている。Googleは、低遅延かつ高頻度での利用を想定した価格体系だとしている。</p>
<p><strong>■ 性能（スコア）とコストの関係を示した比較グラフ。Gemini 3 Flashは、Gemini 3 Proに近い性能帯を保ちながら、Flash系モデルらしい価格帯に位置づけられている。</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/gemini_3_flash_pareto_graph_dec1_width_1000_format_webp_cf3f26591a/gemini_3_flash_pareto_graph_dec1_width_1000_format_webp_cf3f26591a.webp" alt="gemini-3-flash_pareto_graph_dec1.width-1000.format-webp.webp" /></p>
<h2>開発者向けにはAPI・CLI・企業向け基盤で提供</h2>
<p>Gemini 3 Flashは、Google AI StudioのGemini APIを通じてプレビュー提供されるほか、コマンドラインから利用できる「Gemini CLI」、エージェント開発向けプラットフォーム「Google Antigravity」でも利用可能とされている。企業向けには、Vertex AIおよびGemini Enterpriseを通じた提供が行われる。</p>
<h2>Geminiアプリでは「追加料金なし」で利用可能</h2>
<p>Gemini 3 Flashは、一般ユーザー向けのGeminiアプリでは既定モデルとして提供され、追加料金なしで利用可能とされている。また、Google検索の「AI Mode」でも、全ユーザーを対象に段階的な無料提供が始まっている。</p>
<p>なお、Geminiアプリには使用量の上限があり、ProやUltraといった有料サブスクリプションでは、より大きな利用枠が適用される</p>
<h2>有料プランや開発用途では従量課金が適用</h2>
<p>一方、Gemini 3 Flashは開発用途や企業向けサービスでも提供される。Google AI Studioを通じたGemini APIや、Vertex AI、Gemini Enterpriseといった企業向け基盤では、利用量に応じた従量課金が発生する。
公式ブログでは、Gemini 3 Flashの価格として、入力が100万トークンあたり0.50ドル、出力が同3ドル、音声入力は100万トークンあたり1ドルが提示されている。Googleは、低遅延かつ高頻度での利用を想定した価格体系だとしており、開発者や企業での実運用を意識した設計であることを強調している。</p>
<h2>検索AIモードにも展開</h2>
<p>Gemini 3 Flashは、Google検索の「AI Mode」でも既定モデルとして段階的にロールアウトされる。検索AIモードでは、質問の意図を分解して整理した回答や、リアルタイムのローカル情報、関連リンクの提示などを特徴としている。
Googleは、Gemini 3 ProやGemini 3 Deep Thinkとあわせてモデルラインアップを拡充し、一般ユーザーから開発者、企業利用までをカバーする体制を整えていく方針だ。Gemini 3 Flashは、その中でスピードと実用性を担う中核モデルとして位置づけられている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google、MCPを全サービスに展開──Gemini時代の「AI×クラウド接続」を標準化</title>
      <link>https://ledge.ai/articles/google_mcp_all_services_gemini_ai_cloud_standardization</link>
      <description><![CDATA[<p>Googleは2025年12月11日、生成AIモデル「Gemini」などのAIエージェントと、同社のクラウドサービスを接続するための共通基盤として、Model Context Protocol（MCP）の公式サポートを開始したと<a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services">発表</a>した。Googleは今後、同社が提供するすべてのサービスにおいて、段階的に接続用のMCPサーバをGoogle側が用意・運用する形で提供していく方針だ。</p>
<h2>MCP：AIとサービスをつなぐ共通プロトコル</h2>
<p>MCPは、生成AIやAIエージェントが外部ツールやデータソース、APIと、安全かつ標準化された方法で接続するためのオープンプロトコルである。GoogleはこのMCPを、自社クラウドサービスとAIを結ぶ「共通の接続レイヤー」として公式に採用した。</p>
<p>今回Googleが提供するMCPサーバは、サーバの構築や運用、スケーリングをすべてGoogleが担う仕組みとなっている。開発者は自らサーバを立ち上げたり管理したりする必要がなく、MCPクライアントを通じてGoogleの各種サービスに直接接続できる。認証や権限制御についても、既存のGoogle Cloudのセキュリティ基盤と連携している。</p>
<h2>まずはMapsやBigQueryなど主要サービスから対応</h2>
<p>発表時点でMCPサーバに対応している主なサービスには、Google Maps、BigQuery、Google Compute Engine、Google Kubernetes Engine（GKE）などが含まれる。これらのサービスは、位置情報、データ分析、計算資源、コンテナ管理といった機能を提供しており、AIエージェントが実際の処理や操作を行うための基盤として利用できる。</p>
<p>Googleは、これらの初期対応サービスにとどまらず、今後すべてのGoogleサービスで同様の仕組みを提供する計画を示している。公式ブログでは、今後数カ月以内にCloud Run、Cloud Storage、Spanner、Looker、Pub/Sub、Cloud Logging、Cloud Monitoring、Security Operations（SecOps）、Android Management APIなどにも対応を広げる予定だとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「知能爆発」へ“10年以内”の現実味──オックスフォード大の哲学者MacAskill氏らの警告、AIが「数年で1世紀分」の技術進歩を起こし得る</title>
      <link>https://ledge.ai/articles/intelligence_explosion_10_years_warning</link>
      <description><![CDATA[<p>オックスフォード大学の哲学者Will MacAskill氏とFin Moorhouse氏は2025年3月に公開した論文「<a href="https://arxiv.org/abs/2506.14863">Preparing for the Intelligence Explosion（知能爆発への備え）</a>」で、人間よりはるかに賢いAIが今後10年以内に登場する「十分に現実的な可能性（serious chance）」があると指摘した。</p>
<p>AIが研究開発そのものを加速した場合、技術進歩が「数年で1世紀分（a century in a decade）」に相当する速度で進む可能性がある一方、その過程では社会にとって不可逆で重大な意思決定が短期間に連続して発生し得るとして、今から多面的な準備（AGI Preparedness）を進める必要があると論じている。</p>
<h2>研究努力の主役が人間からAIへ移りつつある</h2>
<p>論文は、近年の生成AIと計算資源の拡大により、研究努力（research effort）の成長率が人間の認知的研究努力を大きく上回り始めている点に注目する。AIは単なる作業補助にとどまらず、仮説生成、実験設計、コード作成、評価といった研究工程そのものを担い始めており、研究の“量”と“速度”が同時に拡張される局面が到来しつつあるという。</p>
<p><strong>■ AIによる研究努力は年率で急拡大し、人間の認知的研究努力の成長率を大きく上回り始めている。論文は、この非対称な成長が技術進歩の時間軸を大幅に圧縮し得ると指摘する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Human_vs_AI_research_wide_2985231073/Human_vs_AI_research_wide_2985231073.jpg" alt="Human_vs_AI_research_wide.jpg" /></p>
<h2>「研究をするAI」が技術進歩を自己加速させる可能性</h2>
<p>MacAskill氏らが想定する鍵は、AIが研究を行う主体になることによるフィードバックループだ。研究を自動化・加速するAIが、より高性能なAIの設計や評価に寄与すれば、ソフトウェア中心の自己増幅的な進歩が生じる可能性がある。論文は、こうした条件がそろった場合、物理的制約（人員や時間）に縛られない形で研究能力が拡張され、進歩速度が非連続に跳ね上がり得ると述べる。</p>
<p><strong>■ 推論用計算資源の拡大と推論効率の改善が重なれば、同時に稼働するAI（AI population）が急増し、研究・開発に投入される総知能が飛躍的に拡大する可能性がある</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/AI_population_wide_2_a387a34cd7/AI_population_wide_2_a387a34cd7.jpg" alt="AI_population_wide_2.jpg" /></p>
<h2>最大級の学習規模がもたらす非連続な性能向上</h2>
<p>論文はまた、最大規模の学習（training run）のスケーリングにも言及する。今後、電力やコストなどの制約に直面するまでの間、学習規模の拡大が性能の段差的向上をもたらす局面があり得るとする。これに研究自動化が重なれば、技術的ブレークスルーが短期間に集中する可能性がある。</p>
<p><strong>■ 過去のモデルと比較した最大規模の学習実行の拡大イメージ。論文は、一定期間は学習規模の拡張余地が残っていると指摘する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/scaling_the_biggest_training_run_21a215692d/scaling_the_biggest_training_run_21a215692d.jpg" alt="scaling the biggest training run.jpg" /></p>
<h2>「アラインメントだけ」では不十分という問題提起</h2>
<p>MacAskill氏らは、AIが人間の意図に沿って振る舞うかというアラインメント問題の重要性を認めつつも、それだけに備えを限定することは不十分だと指摘する。理由の一つは、不可逆な意思決定が、完全に整合した超高度AIが確立する前に訪れる可能性があるためだ。</p>
<p>論文が例示する「grand challenges」には、次のような領域が含まれる。</p>
<ul>
<li>新型の破壊的技術や兵器の出現</li>
<li>AIによる権力集中や権威主義的統治の強化</li>
<li>宇宙資源など新たなフロンティアをめぐる競争</li>
<li>道徳的配慮の対象となり得るデジタル存在の扱い</li>
</ul>
<p>これらは一度決定されると後戻りが難しく、「将来のより賢いAIに判断を委ねればよい」という対応が取れない局面が生じ得るとされる。</p>
<h2>論文が示す「今からの備え」</h2>
<p>こうした前提から、論文はAGI Preparednessとして、技術・制度・社会を横断する準備の必要性を挙げる。具体的には、</p>
<ul>
<li>極端な権力集中を防ぐためのインフラや統治構造の設計</li>
<li>政府や公共部門が高度AIを適切に活用できる体制整備</li>
<li>集合意思決定を支援するAIツールの開発と運用</li>
<li>新領域（宇宙資源、デジタル存在など）に関する制度設計</li>
</ul>
<p>といった論点を、アラインメント研究と並行して進める必要があると整理している。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>公共2025/12/25 [THU]政府、初の「AI基本計画」を閣議決定──「信頼できるAI」を軸に国家戦略を明確化</title>
      <link>https://ledge.ai/articles/japan_ai_basic_plan_2025_cabinet_decision</link>
      <description><![CDATA[<p>政府は2025年12月23日、人工知能（AI）の研究開発および利活用の方向性を示す国家戦略「<a href="https://www8.cao.go.jp/cstp/ai/ai_plan/ai_plan.html">人工知能基本計画</a>」を閣議決定した。2025年に施行されたAI法に基づく初の基本計画で、「信頼できるAI」を中核に据え、「世界で最もAIを開発・活用しやすい国」の実現を目指すという。
同計画で政府は、生成AIやAIエージェント、フィジカルAIなどの急速な技術進展により、AIが産業競争力や安全保障に直結する基盤技術となっていると指摘する。一方、日本ではAIの利活用や投資が主要国に比べて遅れており、社会実装の不足が開発力の低下を招いているとの問題意識が示された。人口減少や人手不足、賃金停滞といった構造的課題を背景に、政府はAIを「危機管理投資」と「成長投資」の両面から位置付け、反転攻勢に踏み出す。
基本計画は、「イノベーション促進とリスク対応の両立」「アジャイルな対応」「内外一体での政策推進」の3原則を掲げ、以下の4つの基本方針に基づいて施策を展開する。</p>
<h3>1. AI利活用の加速的推進（「AIを使う」）</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/japan_ai_basic_plan2025_1_ce3c1184e0/japan_ai_basic_plan2025_1_ce3c1184e0.jpg" alt="japan ai basic plan2025-1.jpg" /></p>
<p>政府は、日本社会全体で世界最先端のAI技術を、適切なリスク対応を行いながら積極的に利活用し、新たなイノベーションを創出する方針を示した。AIイノベーションの基盤となるデータの集積・利活用を進め、特に組織や分野を越えたデータ共有を促進することで、AIの性能向上と社会実装を加速させる。
政府・自治体が率先してAIを業務に導入し、行政サービスの質向上と効率化を図るほか、医療、介護、防災、インフラ、製造業など社会課題の解決に直結する分野での活用を後押しする。実証事例の横展開を通じて、官民一体でAI活用を広げる考えだ。</p>
<h3>2. AI開発力の戦略的強化（「AIを創る」）</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/japan_ai_basic_plan2025_2_1dcecb92f9/japan_ai_basic_plan2025_2_1dcecb92f9.jpg" alt="japan ai basic plan2025-2.jpg" /></p>
<p>AI開発力の強化では、基盤モデル、アプリケーション、計算基盤、データ、インフラといったAIエコシステム全体を戦略的に整備する。社会全体でAIを使い、そこで生じた課題を解決するAIを創ることで、利活用と開発の好循環を生み出すことを狙う。
日本語や日本の文化・慣習を踏まえた「信頼できるAI」を日本の勝ち筋と位置付け、官民連携による研究・開発投資を促進する。あわせて、データセンター、半導体、計算資源、クラウド、通信ネットワーク、安定的な電力供給など、AIインフラの戦略的整備を加速させる。</p>
<h3>3. AIガバナンスの主導（「AIの信頼性を高める」）</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/japan_ai_basic_plan2025_3_c836d07a8a/japan_ai_basic_plan2025_3_c836d07a8a.jpg" alt="japan ai basic plan2025-3.jpg" /></p>
<p>AIの利活用と技術革新の好循環を実現するため、政府はAIの適正性を確保するガバナンス構築を重視する。AI法に基づく指針整備や評価体制の整備を進めるとともに、AIセーフティ・インスティテュート（AISI）の機能を強化し、リスク評価や知見の集約を担わせる。
AIは国境を越えて展開される技術であることから、日本国内にとどまらず、国際的なルール形成でも主導的な役割を果たす方針だ。日本が提唱してきた「広島AIプロセス」を軸に、国際社会と連携しながら「信頼できるAI」の実現を目指す。</p>
<h3>4. AI社会に向けた継続的変革（「AIと協働する」）</h3>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/japan_ai_basic_plan2025_4_623e639cc3/japan_ai_basic_plan2025_4_623e639cc3.jpg" alt="japan ai basic plan2025-4.jpg" /></p>
<p>人とAIが協働する社会を実現するため、産業構造や雇用、制度の在り方を先導的かつ継続的に見直す。AIを使い、AIを創る人材の育成・確保を進めるとともに、創造力や判断力、コミュニケーション力など、AI時代に求められる「人間力」の向上を重視する。</p>
<p>リスキリングや教育を通じ、AI社会から取り残される人を生まないことも計画に盛り込んだ。</p>
<p>計画の推進は、内閣総理大臣を本部長とする人工知能戦略本部が担い、政府横断で取り組む。進捗状況はベンチマークを設定して検証し、技術進展の速さを踏まえて、基本計画は原則として毎年見直す方針だ。</p>
<p>政府は、AIを単なる技術政策ではなく、経済・社会構造を転換する国家戦略と位置付けた。「信頼できるAI」を軸に、日本が国際競争力を取り戻せるかは、今後の実行段階に委ねられる。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>JCB、日本IBMとAIパートナーシップ──生成AI「watsonx」で基幹システム開発を革新、設計〜テストで約20%効率化も</title>
      <link>https://ledge.ai/articles/jcb_ibm_ai_partnership_watsonx_core_system_development</link>
      <description><![CDATA[<p>JCBと日本IBMは2025年12月17日、日本IBMが持つコンサルティング力およびテクノロジーの知見を活用し、JCBのシステム分野におけるAIによる変革を実現することを目的としたAIパートナーシップを締結したと<a href="https://prtimes.jp/main/html/rd/p/000001303.000011361.html">発表</a>した。</p>
<p>両社は、生成AIを「開発の共同パートナー」と位置づけ、基幹システムの設計・開発・テストといったIT開発プロセス全体の高度化を図る。日本IBMの生成AI基盤「watsonx」を活用し、品質向上と開発スピードの両立、さらには開発コストの最適化を目指す。</p>
<h2>生成AIを前提とした基幹システム開発へ</h2>
<p>JCBは、国内外の決済を支える基幹システム群を対象に、AIを組み込んだ新たな開発モデルの確立を進めている。今回のパートナーシップでは、日本IBMがこれまで培ってきた業務改革やシステム開発のコンサルティング知見と、生成AIを含む先端技術を組み合わせ、次世代のIT開発手法を構築する。</p>
<p>具体的には、設計からテストまでの各工程に生成AIを組み込み、人手に依存してきた作業の効率化と品質の平準化を図る。これにより、金融インフラとして求められる高い信頼性を維持しながら、開発生産性の向上を目指すとしている。</p>
<h2>COBOLコード生成やテスト自動化など具体的ユースケース</h2>
<p>両社はすでに複数の基幹システムで生成AIの活用を進めている。外部設計書をもとに、高精度なプログラム設計書やCOBOLコードを自動生成するほか、単体テストケースの網羅的な作成や、ブラックボックス観点を取り入れたテストケースの補強を行っている。</p>
<p>また、JCBが連携する500を超える提携先ごとに異なるインターフェース仕様や、業界固有の規制要件に対応したテストデータを生成AIで自動作成する取り組みも進めている。これにより、従来は大きな負担となっていたテスト工程の効率化と品質確保を両立させる狙いだ。</p>
<h2>設計〜テスト工程で約20%の効率化</h2>
<p>こうした取り組みの成果として、すでに一部のシステムでは、設計からテストまでの工程において約20%の開発効率化を達成したという。JCBと日本IBMは、この成果を踏まえ、生成AIを活用した開発手法を今後のシステム更改や他の開発案件にも順次拡大していく方針だ。</p>
<h2>要件定義やコードレビューへの展開も視野</h2>
<p>今後は、自然言語による要件定義の支援や、コードレビューへの生成AI活用など、より上流工程・高度工程への適用も検討する。両社は、AIを前提とした開発スタイルを通じて、基幹システムの持続的な進化と新たな価値創出につなげていくとしている。</p>
<p>JCBは、日本発唯一の国際カードブランドとしてグローバルに決済ネットワークを展開しており、安定性と拡張性を両立するシステム基盤の強化が重要な課題となっている。日本IBMは、コンサルティングからシステム構築、運用までを一貫して支援する立場から、今回のパートナーシップを通じて金融分野における生成AI活用をさらに加速させる考えだ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta、音声分離AI「SAM Audio」公開──テキスト・映像・時間指定で任意の音を切り出し</title>
      <link>https://ledge.ai/articles/meta_sam_audio_release</link>
      <description><![CDATA[<p>米Metaは2025年12月16日、複雑な音声データから特定の音を分離できる音声分離AIモデル「SAM Audio」を<a href="https://about.fb.com/news/2025/12/our-new-sam-audio-model-transforms-audio-editing/">発表</a>した。テキスト、映像、時間スパンという3種類のプロンプトを用いて音を切り出せる点が特徴で、同社は音声分野における初の統合型（unified）音声分離モデルとして位置付けている。</p>
<p>SAM Audioは、Metaが展開してきた「Segment Anything」モデル群の最新例となる。動画や音声に含まれる複数の音が混在した状態から、ユーザーが指定した対象音のみを抽出できるよう設計されており、音声編集や動画制作の工程を大きく変える可能性があるとしている。</p>
<p>Metaは具体例として、バンド演奏を撮影した動画からギターやボーカルだけを分離するケースや、屋外で撮影した映像から交通騒音を除去するケース、ポッドキャスト全体から犬の鳴き声を取り除くといった使い方を挙げている。専門的な音響知識を必要とせず、直感的な操作で音声分離が行える点を強調する。</p>
<p>@<a href="https://www.youtube.com/watch?v=gPj_cQL_wvg">YouTube</a></p>
<h2>3種類のプロンプトで音声分離を実現</h2>
<p>SAM Audioは、以下の3種類のプロンプト方式に対応する。</p>
<ul>
<li><strong>テキストプロンプト：</strong> 「dog barking（犬の鳴き声）」や「singing voice（歌声）」といった自然言語を入力することで、該当する音を抽出できる</li>
<li><strong>ビジュアルプロンプト：</strong> 動画上の人物や物体をクリックすることで、その対象が発している音を分離する</li>
<li><strong>スパン（時間）プロンプト：</strong> 対象音が含まれる時間区間を指定し、同種の音を音声全体から抽出する。Metaはこの方式を「業界初」としている。</li>
</ul>
<p><strong>スパンプロンプト：音声波形上で鳥の鳴き声が含まれる区間を指定すると、その特徴を手がかりに、音声全体から同種の音を検出・分離する。音の名称を言語で指定する必要はなく、「この時間に鳴っている音」を示すだけでよい</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/samaudio_spanprompting_760d424baa/samaudio_spanprompting_760d424baa.jpg" alt="samaudio spanprompting.jpg" /></p>
<p>これらのプロンプトは単独でも、組み合わせても使用可能で、ユーザーは目的に応じて柔軟に音声分離の条件を指定できる。</p>
<h2>断片化していた音声編集を統合モデルでカバー</h2>
<p>これまでの音声分離や音声編集は、用途ごとに特化した単機能ツールが中心だった。MetaはSAM Audioについて、人が自然に音を捉え、指定する感覚に近い形で操作できる点を特徴とし、従来の断片化した音声編集環境を統合的に扱えるモデルだと説明している。</p>
<p><a href="https://ai.meta.com/research/publications/sam-audio-segment-anything-in-audio/">研究論文</a>では、多様な実世界の音環境を想定した評価において高い性能を示したとしており、音声分離における汎用的な基盤モデルを目指す取り組みとして位置付けられている。</p>
<h2>音楽・映像から研究、アクセシビリティまで</h2>
<p>Metaは、SAM Audioの活用分野として、音楽制作、ポッドキャスト、テレビや映画制作、動画編集、科学研究、アクセシビリティ支援などを挙げている。同社はすでにSAM Audioを次世代のクリエイティブメディアツールの開発に活用しているという。</p>
<p>SAM Audioは、Metaの「Segment Anything Playground」で試用できる。ユーザーは用意された音声・動画素材を選択するほか、自身のデータをアップロードしてモデルの挙動を確認できる。あわせて、研究・開発用途向けにモデルのダウンロード提供も開始している。</p>
<p>Metaは、画像分野で広く使われてきた「Segment Anything」の考え方を音声分野に拡張することで、音声編集の在り方を変える可能性があるとし、SAM Audioを「オールラウンドな音声分離モデル」と位置付けている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Mistral AI、手書き文書も高精度にテキスト化する「Mistral OCR 3」発表──文書AI基盤を強化</title>
      <link>https://ledge.ai/articles/mistral_ai_mistral_ocr_3_launch</link>
      <description><![CDATA[<p>Mistral AIは2025年12月19日（現地時間）、スキャンしたドキュメントや手書き文字を認識し、テキストデータへ変換できる新たな光学文字認識（OCR）モデル「Mistral OCR 3」を<a href="https://mistral.ai/news/mistral-ocr-3">発表</a>した。単なる文字抽出にとどまらず、文書構造を保持した出力を特徴とし、同社は企業向けDocument AI基盤を支える中核モデルとして位置付けている。</p>
<p>@<a href="https://www.youtube.com/watch?v=Xwv_elQQJFc">YouTube</a></p>
<h2>スキャン文書や手書き文字を“構造ごと”理解</h2>
<p>Mistral OCR 3は、PDFや画像として保存された文書から、印字されたテキストだけでなく、手書き文字、図表、レイアウト情報を含めて解析する。契約書や請求書、申請書類、フォーム文書、歴史的資料など、紙や画像ベースで存在する多様な文書のデジタル化を想定して設計されている。</p>
<p><strong>■ Mistral AIが公開したOCRベンチマーク比較図。フォーム文書、手書き文字、請求書、複雑な表、歴史的スキャン文書といった複数のデータセットにおける性能を示している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ocr_3_bb8d412274/ocr_3_bb8d412274.png" alt="ocr-3.png" /></p>
<p>従来のOCRが文字列抽出に主眼を置いていたのに対し、Mistral OCR 3は文書全体の構造理解を重視している点が特徴だ。</p>
<h2>MarkdownとHTMLでの出力に対応</h2>
<p>出力形式として、本文テキストはMarkdown形式で提供され、表についてはHTMLベースで再構築できる。これにより、文書検索、要約、RAG（検索拡張生成）、AIエージェントによる業務処理など、下流のAI処理パイプラインにそのまま組み込める設計となっている。</p>
<p>Mistral AIは、OCRを単体機能としてではなく、生成AIによる文書理解・活用の前段階を担う要素として位置付けている。</p>
<h2>API提供と価格設定</h2>
<p>Mistral OCR 3はAPI経由で提供される。公式ドキュメントによると、価格は通常のAPI利用で1,000ページあたり2ドル、Batch APIを利用した場合は1,000ページあたり1ドルとされている。大量の文書を処理する企業利用を想定したコスト設計となっている。</p>
<h2>Document AIスタックの中核モデルに</h2>
<p>Mistral OCR 3は、同社が展開するDocument AI関連機能の基盤モデルとして位置付けられている。紙や画像として存在する情報をAIが扱える構造化データへ変換する役割を担い、大規模言語モデルと組み合わせた業務自動化やデータ活用を支える。</p>
<p>Mistral AIは今後も、企業向けAI基盤の拡充を進めていくとしている。</p>
<p>関連記事</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>三井不動産、「社長AIエージェント」を開発──ChatGPT Enterprise全社員導入、業務削減10％超を目標に</title>
      <link>https://ledge.ai/articles/mitsuifudosan_ceo_ai_agent_chatgpt_enterprise</link>
      <description><![CDATA[<p>三井不動産は2025年12月23日、生成AIのさらなる活用による生産性向上と付加価値向上を目的として、「社長AIエージェント」など独自のAIプロダクトを開発したと<a href="https://www.mitsuifudosan.co.jp/corporate/news/2025/1223/">発表</a>した。あわせて、OpenAIの法人向け生成AIサービス「ChatGPT Enterprise」を約2,000人の全社員に導入しており、現場主導のAI活用を通じて、全社で業務削減時間10％以上の達成を目指すとしている。</p>
<p>同社では2025年10月1日からChatGPT Enterpriseの全社導入を開始した。業務利用に必要なセキュリティやプライバシーを備えた環境のもと、要約や翻訳、資料・メールの下書き作成、コード生成、データ整理など、日常業務を幅広く支援する。部門や業務ごとのルールやマニュアルを組み込んだ「カスタムGPT」を、プログラミングなしで作成・共有できる点も特徴で、導入から約3か月で約500件のカスタムGPTが運用されているという。</p>
<h2>全85部門から150人の「AI推進リーダー」、現場起点でAI活用を展開</h2>
<p>AI活用を現場起点で進めるため、同社は全85部門から約150人の「AI推進リーダー」を選出した。AI推進リーダーは、各部門の実務を理解した上で、カスタムGPTの作成やユースケースの発掘、部門内への展開、効果測定などを担う。</p>
<p><strong>AI推進リーダーの役割と体制：</strong> 各部門から選出されたAI推進リーダーが、DX部の支援のもとカスタムGPTを活用し、部門内の生産性向上と付加価値創出を担う
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251223_02_c291e94437/20251223_02_c291e94437.jpg" alt="20251223_02.jpg" /></p>
<p>Microsoft Teamsでの情報発信や社内研修を通じてノウハウを共有し、業務に即した「使える形」のAI活用を全社に広げていく体制を整えている。</p>
<h2>内製AI開発環境で「社長AIエージェント」を開発</h2>
<p>同社は、Microsoft Azure上に独自のAIプロダクトを開発できる内製環境を構築し、複数の生成AIモデルを組み合わせた活用を進めている。この環境で開発されたプロダクトの一つが「社長AIエージェント」だ。</p>
<p>同エージェントは、同社社長である植田 俊氏の公開情報や過去の経歴・発信内容に加え、キャリアの転機となったプロジェクトやエピソードなどをもとに、社長の「ものの見方・考え方」を立体的に再現することを目的としている。社員が対話形式で利用し、全社戦略や市場環境への理解を深め、日々の判断や行動に活かすことを想定しており、2025年12月から全社トライアル利用を開始した。</p>
<h2>DX本部長AIや資料自動生成AIなど、業務特化型AIも展開</h2>
<p>このほか、DX本部長の考え方やミッションを反映した「DX本部長AIエージェント」や、テキスト入力だけでPowerPoint形式の資料を生成できる「資料自動生成AI」など、業務に特化したAIプロダクトも順次展開している。</p>
<p><strong>資料自動生成AIの画面例：</strong> テキストで指示するだけで、構成されたPowerPoint形式の資料を自動生成。自然言語で修正指示も可能で、資料作成業務の効率化を図る
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20251223_05_cc50bc5ff3/20251223_05_cc50bc5ff3.jpg" alt="20251223_05.jpg" /></p>
<p>DX本部長AIエージェントでは、説明資料の事前レビューをルール化することで、本部長の意向との不整合による手戻りを減らし、資料作成・修正にかかる時間を平均約30％削減したという。資料自動生成AIでは、レイアウト崩れを抑えた独自方式を採用し、編集可能なPowerPointファイルとして出力できる点を特徴としている。</p>
<h2>業務削減10％超を目標に、生成AIの適用範囲を拡大へ</h2>
<p>同社は今後、ChatGPT Enterpriseと内製AIプロダクトの両輪で生成AIの活用範囲を段階的に拡大する方針だ。現場の人手不足解消や社内データの整備・活用、経営の意思決定支援などへの適用を進め、業務効率化と付加価値創出の両立を目指すとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/23 [TUE]AI研究の最高峰「NeurIPS 2025」でアリババQwenチームら、最優秀論文賞を受賞―—Transformerの根幹「Attention」を見直す「Gated Attention」を提案</title>
      <link>https://ledge.ai/articles/neurips_2025_best_paper_gated_attention</link>
      <description><![CDATA[<p>2025年12月、AIと機械学習分野で世界最高峰の国際学会として知られるNeurIPS 2025において、大規模言語モデル（LLM）の基盤技術であるTransformerの「Attention」メカニズムを改良する研究が、最優秀論文賞（Best Paper Award）を<a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/120216">受賞</a>した。</p>
<p>受賞した論文は「Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free」。アリババグループのQwenチームを中心に、複数の大学・研究機関が参加した共同研究で、Attentionの計算結果の扱い方を見直すことで、学習の安定性や長文処理性能の改善を示した。</p>
<h2>LLMの中核を担う「Attention」</h2>
<p>Transformerモデルは、入力された文章の中で「どの単語が、どの単語と強く関係しているか」を計算するAttention機構によって、高い表現力を実現している。現在のLLMの多くはこの仕組みを前提としており、Attentionの挙動はモデル全体の性能に大きな影響を与える。</p>
<p>一方で、従来のAttentionには、特定のトークンに注意が過度に集中する現象や、長文条件での性能低下、学習の不安定さといった課題が指摘されてきた。</p>
<h2>Attentionの「結果」に着目した改良</h2>
<p>研究が注目したのは、Attentionの計算方法そのものではなく、「Attentionが出力した結果をどのように次の層へ渡しているか」という点だ。</p>
<p>研究チームは、Scaled Dot-Product Attention（SDPA）の出力直後に、ヘッドごとに独立したシグモイド型の「ゲート」を挿入する手法を提案した。このゲートは、Attentionによって集められた情報を入力ごとに取捨選択する役割を果たす。</p>
<h2>実験で確認された効果</h2>
<p>論文では、数十億〜百億規模のパラメータを持つDenseモデルや、混合専門家（MoE）モデルを用いた大規模な実験が行われた。その結果、以下の点が報告されている。</p>
<ul>
<li>学習中に発生しやすい損失の急上昇（ロス・スパイク）が抑制され、学習が安定した</li>
<li>Attention出力に非線形性が加わることで、表現力が向上した</li>
<li>入力に応じたスパースな情報選択が可能になった</li>
<li>文頭トークンなどに注意が集中する「Attention Sink」現象が大きく緩和された</li>
<li>長文条件のベンチマークにおいて、性能低下が抑えられた</li>
</ul>
<p>計算コストの増加は小さく、既存のTransformer構成に比較的容易に組み込める点も示されている。</p>
<h2>長文処理と大規模モデルへの示唆</h2>
<p>Attention Sinkの抑制により、コンテキスト長を拡張した条件ほど効果が顕在化することも報告された。長文を扱うタスクや、今後さらに大型化が進むLLMにとって、Attentionの出力制御が重要な設計要素になり得ることを示している。</p>
<h2>実装と今後の展開</h2>
<p>論文によれば、提案手法はアリババが開発するQwen系列の次世代モデルにも採用されているという。研究チームは関連コードやモデルの公開も進めており、今後のLLM設計への影響が注目される。</p>
<p>Transformerという既存の枠組みを前提に、Attentionの「使い方」を丁寧に検証し直した本研究は、LLMの基盤技術をめぐる議論に新たな視点を提供するものとして、NeurIPS 2025の最優秀論文に選ばれた。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>note、経産省・NEDOの生成AI国家プロジェクト「GENIAC」に採択──RAG活用で“対価が還元される”データエコシステム構築へ</title>
      <link>https://ledge.ai/articles/note_geniac_rag_data_ecosystem</link>
      <description><![CDATA[<p>noteは2025年12月19日、経済産業省およびNEDO（新エネルギー・産業技術総合開発機構）が推進する生成AIの国家プロジェクトGENIAC（Generative AI Accelerator Challenge）に、同社が提案した事業が採択されたと<a href="https://note.jp/n/nc115466df5e5">発表</a>した。</p>
<p>同事業では、RAG（検索拡張生成）技術を活用し、出版社や学術団体、ウェブメディアなどが保有する高品質なコンテンツを、生成AIが回答生成時に参照できるデータベースとして整備する。AIによる参照履歴を取得可能にすることで、コンテンツの利用実績に基づいた公正な対価還元を実現する仕組みの構築を目指すという。</p>
<h2>経産省・NEDOが推進する生成AI国家プロジェクト「GENIAC」</h2>
<p><a href="https://www.meti.go.jp/policy/mono_info_service/geniac/index.html">GENIAC</a>は、国内の生成AI開発力および社会実装を加速することを目的に、経済産業省とNEDOが実施する国家プロジェクトだ。計算資源やデータ、利活用モデルの整備などを通じて、産業競争力の強化を図る。</p>
<p>noteの事業は、このGENIACにおける「生成AI開発加速に向けたデータ・生成AIの利活用に係る調査事業」として採択された。NEDOが公表した実施予定先一覧にも、note株式会社の名称と事業テーマが明記されている。</p>
<h2>RAG技術を活用した高品質データベースの構築</h2>
<p>noteが取り組むのは、RAG技術を前提とした大規模なデータエコシステムの構築だ。出版社やメディア、学術団体などが保有する信頼性の高いコンテンツをAI向けに整理・集約し、生成AIサービスがそれらを参照しながら回答を生成できる環境を整える。</p>
<p>これにより、生成AIサービス側はインターネット上の断片的な情報だけでなく、出典が明確な高品質データを参照できるようになり、回答の正確性向上が期待される。</p>
<h2>利用実績に基づく「フェアな対価還元」の仕組み</h2>
<p>同事業の特徴の一つが、コンテンツ提供者への対価還元を前提に設計されている点だ。AIがどのコンテンツをどの程度参照したかといった利用履歴を取得可能にし、その実績に基づいて対価を分配する仕組みを構築する。</p>
<p>あわせて、コンテンツデータをAIで効率的に利用するためのデータフォーマットの標準化や、具体的なユースケースの整理にも取り組むとしている。</p>
<h2>事業期間・規模と連携体制</h2>
<p>事業期間は原則1年間、予算規模は15億円以内とされている。調査期間の延長や予算規模の拡大が認められた場合には、最長2027年12月まで、予算上限20億円以内まで引き上げられる可能性がある。</p>
<p>事業は、KADOKAWAやダイヤモンド社、一般社団法人学術著作権協会など、複数の関係団体と連携して推進する。noteは今後も出版社やメディア、生成AI関連サービス開発企業との協議を進め、パートナーを順次拡大していく方針だ。</p>
<h2>ファクト情報を中心に段階的に展開</h2>
<p>スタート時点で対象とするコンテンツは、既存の著作権保護の観点から特に配慮が必要なフィクション領域ではなく、ニュース、辞書、実用書、新書、経済・ビジネスなど、情報の正確性や出典の明示が価値となるファクト情報に限定する。</p>
<p>同事業を通じてnoteは、クリエイターやメディア、AI事業者が公正に参加できる、生成AI時代における新たなコンテンツ流通のエコシステム構築を目指すとしている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Private AI、三菱UFJ銀行のデータ基盤「OCEAN」で採用──非構造化データを生成AI活用へ、秘匿化を前提に</title>
      <link>https://ledge.ai/articles/private_ai_mufg_ocean_data_privacy</link>
      <description><![CDATA[<p>カナダを拠点とするAI企業の Private AI は2025年12月18日、同社のデータ秘匿化ソリューションが、三菱UFJ銀行のビッグデータ基盤「OCEAN」において正式に採用されたと<a href="https://prtimes.jp/main/html/rd/p/000000006.000131786.html">発表</a>した。</p>
<p>OCEANは、三菱UFJフィナンシャル・グループ（MUFG）が全社横断で利用するデータ基盤で、構造化データに加え、メールや文書などの非構造化データも扱っている。</p>
<p>Private AIによると、今回採用されたソリューションは、メール、コールセンターの通話記録、社内文書、PDF、チャットログなどの非構造化データに含まれる個人情報や機密情報を自動で検出し、秘匿化する機能を備える。クラウドにデータを送信せず、オンプレミスや閉域環境でリアルタイムに処理できる点を特徴としている。</p>
<p>企業における生成AI活用では、実務に価値のあるデータほど個人情報や機密情報を含む非構造化データであることが多く、利活用が進まない要因の一つとされてきた。こうしたデータをどのように安全に扱うかは、生成AIや業務AIの本格導入に向けた課題となっている。</p>
<p>三菱UFJ銀行のOCEANは、グループ全体のデータを集約・分析する基盤として整備されてきた。今回の発表では、非構造化データを秘匿化したうえで基盤に取り込むことで、横断分析に加え、業務AIや生成AIでの活用を可能にするとしている。</p>
<p>生成AIをめぐっては、モデル性能の向上と並行して、データの取り扱いやガバナンスの在り方が重要性を増している。金融機関のように要件の厳しい業界において、秘匿化を前提とした非構造化データ活用の事例が示された形だ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>学術＆研究2025/12/25 [THU]AlibabaのQwen、画像をRGBAレイヤーに分解する生成AIを公開──「編集の一貫性」を構造から解決</title>
      <link>https://ledge.ai/articles/qwen_image_layered_rgba_layer_decomposition</link>
      <description><![CDATA[<p>Alibabaの研究チームは、単一の画像を複数の意味的に分離されたRGBAレイヤーへ分解する画像生成モデル「Qwen-Image-Layered」を<a href="https://arxiv.org/abs/2512.15603">発表</a>した。単一の画像を前提とする従来の画像生成・編集とは異なり、画像を最初から「編集可能なレイヤー構造」として扱える点が特徴だ。</p>
<h2>画像を「1枚」ではなく「レイヤーの集合」として扱う</h2>
<p>Qwen-Image-Layeredは、入力されたRGB画像を、複数の意味的に分離されたRGBAレイヤーへ分解する。
各レイヤーは色（RGB）と透明度（Alpha）を持ち、重ね合わせることで元の画像を再構成できる。人物や背景、装飾、テキストといった要素を独立した編集単位として分けて扱える点が特徴だ。</p>
<h2>レイヤー単位での編集を前提に設計</h2>
<p>分解された各レイヤーは、それぞれ個別に操作できる。
論文では、色の変更や要素の置き換え、削除、サイズ変更、位置移動といった操作を想定しており、特定の要素のみを編集しても、他の部分に影響が及びにくい設計だとしている。背景を保ったまま人物だけを動かす、といった編集を前提にしたモデルとなっている。</p>
<p><strong>レイヤー分解により、背景や人物、オブジェクト、テキストを独立して編集できる。色変更や置き換え、削除、サイズ変更、位置移動といった操作を、他の要素に影響を与えずに行える例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/layered_c521d65827/layered_c521d65827.jpg" alt="layered.jpg" /></p>
<h2>可変枚数のレイヤー分解に対応</h2>
<p>分解されるレイヤー数は固定されておらず、画像の内容に応じて可変となる。
シンプルな構成の画像から、多数の要素を含む複雑な画像まで対応できるよう設計されており、レイヤー構造を前提とした柔軟な編集を可能にする狙いがある。</p>
<h2>編集の一貫性を「画像表現」から確保する発想</h2>
<p>論文では、従来の画像編集で問題となってきた「一部を修正すると全体が崩れる」「意図しない変形が起きる」といった現象の原因を、画像が1枚のキャンバスとして表現されている点にあると指摘している。
Qwen-Image-Layeredは、画像を最初からレイヤーの集合として表現することで、編集時の一貫性を構造的に保つことを狙ったモデルだとしている。</p>
<p>Qwen-Image-Layeredは、画像生成や編集を「完成した画像を出力するAI」から、後から手を加えられる素材を生成するAIへと捉え直す試みとして位置づけられている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/12/21 [SUN]楽天、7000億パラメータの日本語LLM「Rakuten AI 3.0」発表──GENIAC支援で開発、国内最大規模</title>
      <link>https://ledge.ai/articles/rakuten_ai_3_0_japanese_llm_700b_geniac</link>
      <description><![CDATA[<p>楽天グループは2025年12月18日、日本語に特化した大規模言語モデル（LLM）「Rakuten AI 3.0」を<a href="https://corp.rakuten.co.jp/news/press/2025/1218_01.html">発表</a>した。同社によると、同モデルは約7000億パラメータ規模で、日本語LLMとして国内最大規模に位置付けられる。経済産業省および新エネルギー・産業技術総合開発機構（NEDO）が推進する生成AI開発支援プロジェクト<a href="https://ledge.ai/articles/geniac_third_round_rakuten_nri_selected">「GENIAC（Generative AI Accelerator Challenge）」の支援</a>を受けて開発された。</p>
<p>Rakuten AI 3.0は、Mixture of Experts（MoE）アーキテクチャを採用する。総パラメータ数は約7000億に達する一方、推論時には入力内容に応じて一部の専門モデルのみを動作させる仕組みとすることで、計算資源の効率化と運用コストの低減を図ったとしている。</p>
<p>同社によると、Rakuten AI 3.0は日本語の文脈理解や表現の自然さを重視して設計され、楽天が保有するデータや高品質な日本語・バイリンガルデータを用いて学習および調整が行われた。日本語ベンチマークの一つである日本語版MT-Benchでは8.88のスコアを記録したとしている。</p>
<p><strong>■ 日本語特化モデルとのベンチマーク比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rakuten_ai_3_0_82bda693ce/rakuten_ai_3_0_82bda693ce.jpg" alt="rakuten ai 3-0.jpg" /></p>
<p>また、社内検証では、同規模クラスのモデルと比較して最大90％のコスト削減効果が確認されたという。研究用途にとどまらず、実サービスへの適用を前提としたモデルである点を特徴としている。</p>
<p><strong>■ 楽天AIシリーズにおける位置付け</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/rakuten_ai_3_0_1_41fbde6837/rakuten_ai_3_0_1_41fbde6837.jpg" alt="rakuten ai 3-0-1.jpg" /></p>
<p>Rakuten AI 3.0は、楽天の生成AI基盤「Rakuten AI Gateway」に統合され、APIを通じて利用可能となる予定だ。さらに、同社が展開する「Rakuten AI」エージェントプラットフォームを介し、楽天エコシステム内の各種サービスへの順次導入を進めるとしている。</p>
<p>開発は、GENIACの枠組みに基づく支援の下で行われた。GENIACは、日本国内における生成AIの基盤技術強化と社会実装を目的に、計算資源の提供や研究開発支援を行う国家プロジェクトである。</p>
<p>楽天グループは、Rakuten AI 3.0について、2026年春を目標にオープンウェイトモデルとして公開する計画も示している。日本語に特化した大規模モデルをオープンに提供することで、国内の生成AI開発や利活用の裾野拡大につなげたい考えだ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>半導体設計にAIエージェント導入へ──ラピダス、設計企業向けツール群「Raads」の提供を発表</title>
      <link>https://ledge.ai/articles/rapidus_ai_agent_semiconductor_design_raads</link>
      <description><![CDATA[<p>ラピダスは2025年12月17日、半導体設計において自律的に作業を行う人工知能（AI）エージェントを中核とする設計支援ツール群「Raads」を、半導体設計企業向けに提供すると<a href="https://www.rapidus.inc/news_topics/news-info/rapidus-unveils-new-ai-design-tools-for-advanced-semiconductor-manufacturing/">発表</a>した。従来の設計支援AIの枠を超え、設計そのものを担うAIエージェントの導入を目指す。</p>
<p>Raadsはこれまで構想してきた「Rapidus AI-Assisted Design Solution」を発展させたもので、今後は「Rapidus AI-Agentic Design Solution」へと進化させていくと同社はいう。設計者を補助するだけでなく、最先端半導体デバイス設計におけるAIエージェントとして機能することを想定。既存のEDAツールと併用することで、設計期間の50％短縮、設計コストの30％削減を可能にするとしている。</p>
<p>Raadsは複数のAIツールで構成され、PDK（Process Design Kit）やリファレンスフローとあわせて顧客に提供される。主なツールとして、設計仕様を入力するとラピダスの2nm製造プロセスに最適化されたRTL（Register Transfer Level）設計データを生成する「Raads Generator」や、RTLデバッグおよび物理設計・配置配線の最適化を行い、PPA（Power、Performance、Area）を短期間で予測する「Raads Predictor」を用意する。</p>
<p>設計者は、デザインアイデアや希望する仕様をRaads GeneratorでRTLソースコードとして出力し、SDC（Synopsys Design Constraints）とともにRaads Predictorに入力することで、ラピダスで製造されるシリコンのPPAを事前に予測できるという。</p>
<p>このほか、設計者のQAやアシスタンスを行う「Raads Navigator」「Raads Indicator」、ML（機械学習）やAIを活用した階層レイアウト設計ツール「Raads Manager」、PPA最適化のためのパラメータ探索を行う「Raads Optimizer」などを、今後順次リリースする計画だ。</p>
<p>ラピダスは、2nmプロセス対応のPDK整備を進めるとともに、製造基盤の構築と設計環境の整備を並行して進めている。Raadsはこうした取り組みと連動し、顧客が最先端半導体の設計を開始できる環境を支えるツール群として位置付けられている。提供開始は2026年度からを予定している。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>【2025年のAIトレンドを振り返る】その①：生成AIの製品進化</title>
      <link>https://ledge.ai/articles/reflecting_on_ai_trends_for2025-1</link>
      <description><![CDATA[<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<p>2025年における生成AI製品の進化は、非常に短期間に主要なモデルが次々と刷新されるという、驚異的なペースで展開された。この進化の核心は、「知能の極限追求」「マルチモーダル機能の個人化」、そしてそれを可能にする「開発効率の爆発的向上」という三つの流れにある。</p>
<p>年の初め、前年年末に発表された中国AI企業の高コストパフォーマンスを追求した最新LLM「DeepSeek-V3」が大きな衝撃を与えた。このモデルは、推定6,710億個というGPT-4の1/3強のパラメーター数でありながら、トレーニングコストを約1/20に抑えるという効率性を実現した。この効率化の流れを背景に、基盤モデルの進化速度は従来の常識を破り、7月11日にはxAIが「世界最強AI」「Grok 4」を公開し、既存モデルを刷新した事実が示された。イーロン・マスク氏の言葉によれば、「Grok 4」は既存のインターネット情報に頼らず、「ネットにない難問も解ける」知的能力を持つ。</p>
<p>夏本番の8月7日には、OpenAIが最新AI基盤モデル「GPT-5」を発表し、このモデルは誤差性能を大幅に向上させた成熟の新エンジンとして、無料ユーザーを含む全ユーザーへの提供を開始した。また、8月26日には、Googleが「Gemini 2.5 Flash Image」(Nano Banana)をGeminiに統合し、特徴を崩さずに「その人らしさ」を保つ画像編集モデルとして機能の特化を進めた。</p>
<p>秋口に入るとマルチモーダル機能の深化が明確になり、10月1日にOpenAIは次世代動画生成モデル「Sora 2」を発表、音声を同期生成する機能を搭載し、iOSアプリとしても米国とカナダで同時公開された。年の終盤には、Googleが「Gemini 3」を正式発表し、推論・マルチモーダル性能を強化した最新モデルの提供を開始している。</p>
<p>この2025年を通じて確認された驚異的な開発速度は、現在時点で、LLMの進化が「密度化の法則」に従って進んでおり、同等性能を達成するために必要なモデルサイズが約3.5か月ごとに半減しているという、ムーアの法則を凌駕するペースで進んでいることによって裏付けられている。</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
<h2>おわりに</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/25to26_thumb_ced6fcf9a3/25to26_thumb_ced6fcf9a3.png" alt="25to26_thumb.png" /></p>
<p>Ledge.ai年末年始特集では、読者に向けて、2025年のAI関連の重要トレンドを振り返り、また2026年以降のAIの展望について発信している。新しい年へ動き出すための情報が詰まっているので、ぜひ以下ボタンより特集サイトをご覧いただきたい。</p>
<p><strong>【コンテンツ情報】</strong>
無料登録を行うと、これらすべての記事を閲覧できるようになる。
■ 特別インタビュー
京都賞受賞のAIのパイオニア甘利俊一先生をはじめ、量子コンピュータ/量子機械学習からロボット基盤モデル、話題の”PLURALITY”、NVIDIA、AMDなど、”いま読んでおくべき”インタビューが満載
■ 2025年のAI動向総ざらい
■ 厳選注目記事49本</p>
<p>:::button
<a href="https://25to26.ledge.ai/">Ledge.ai年末年始特集サイトはこちら</a>
:::</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Steamに「100％AI制作」をうたうゲーム登場──コードから音楽まで“全工程AI”と開示</title>
      <link>https://ledge.ai/articles/steam_100_percent_ai_generated_game_codex_mortis</link>
      <description><![CDATA[<p>ゲーム開発における生成AI活用が広がる中、制作工程のすべてをAIで生成したと申告するゲームが、PCゲーム配信プラットフォーム「Steam」に登場した。</p>
<p>対象となるのは、ローグライト系アクションゲーム「CODEX MORTIS」。Steam上で公開されている体験版（Demo）は2025年12月9日付で<a href="https://store.steampowered.com/app/4095390/CODEX_MORTIS_Demo/">配信</a>が始まっており、ストアページの「AI Generated Content Disclosure（AI生成コンテンツの開示）」欄には、コード、アート、サウンド、音楽、テキストのすべてがAI生成であると記載されている。</p>
<p>@<a href="https://www.youtube.com/watch?v=E5Oxs8lPT8s">YouTube</a></p>
<h2>Steam上に現れた“全工程AI”という記載</h2>
<p>「CODEX MORTIS」の体験版および本編のSteamストアページでは、いずれもAI生成コンテンツに関する開示が行われている。
体験版の開示欄には「All code is AI vibe codes, also arts, sounds, music, texts」と記されており、本編ページでも、ゲーム全体がAIによって生成されたことが示されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/100_Vibe_Coded_Playable_Game_4fb83b3185/100_Vibe_Coded_Playable_Game_4fb83b3185.jpg" alt="100%VibeCodedPlayableGame.jpg" /></p>
<p>開発元はGROLAF、パブリッシャーはCRUNCHFESTと表示されており、本編の発売時期については、現時点では「未定」とされている。</p>
<p>これらの記載は、第三者による検証結果ではなく、開発側がSteam上で申告した内容である。一方で、コードから音楽に至るまで「全工程AI」と明示している点は、Steam上でも目立つ表現となっている。</p>
<h2>Steamは何を開示させているのか</h2>
<p>Steamを運営するValveは、開発者向け公式ドキュメント「Steamworks」において、ゲーム公開前に提出する「Content Survey（コンテンツ調査）」の中で、生成AIの利用有無や内容を申告する仕組みを設けている。</p>
<p>この調査では、</p>
<ul>
<li>開発段階で生成されたコンテンツ（Pre-Generated AI）</li>
<li>実行中に生成されるコンテンツ（Live-Generated AI）</li>
</ul>
<p>といった区分を含め、生成AIがどの工程でどのように使われているかを説明することが求められる。
その回答内容に基づき、Steamストア上では「AI Generated Content Disclosure」として、AI利用に関する情報が表示される。</p>
<p>「CODEX MORTIS」は、この枠組みの下で、制作工程全体をAI生成とする内容を申告したタイトルの一つとなる。</p>
<h2>“全工程AI”は例外か、兆しか</h2>
<p>ゲーム業界では近年、コンセプトアート制作やコード補助、テキスト生成、テスト工程など、さまざまな場面で生成AIの活用が進んでいる。一方で、コード、ビジュアル、音楽までを含めて“すべてAI生成”と明示するケースは、依然として多くはない。</p>
<p>今回の事例は、作品の完成度や評価とは切り離して、SteamのAI開示制度の下で「全工程AI」という申告が公に確認できる形で示された点に特徴がある。</p>
<p>生成AIをめぐっては、これまでSteamは取り扱いに慎重な姿勢を見せる一方、Epic Games Storeは比較的早い段階から生成AIの活用を前提としたスタンスを示してきた。
そうした中で、Steamが生成AIの利用内容を明示的に開示させる制度を整え、その枠組みの中で「全工程AI」を申告するタイトルが登場したことは、同プラットフォームにおける運用の一つの転換点として捉えることもできる。</p>
<p>今回の事例は、生成AI作品を一律に排除するのではなく、開示と申告を前提に取り扱うという、Steam側の現在地を示すものとも言えそうだ。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AlphaGoからAlphaFoldまで──Google DeepMindの舞台裏を描く映画「The Thinking Game」、YouTubeで全編無料公開</title>
      <link>https://ledge.ai/articles/the_thinking_game_deepmind_youtube_free_release</link>
      <description><![CDATA[<p>AGI（汎用人工知能）の完成を目指すAI開発企業 Google DeepMind と、その創設者である デミス・ハサビス 氏を追ったドキュメンタリー映画「The Thinking Game」が、YouTubeで全編無料公開されている。</p>
<p>同作は、DeepMindの創設初期から、囲碁AI「AlphaGo」、自己対戦型AI「AlphaZero」、タンパク質構造予測AI「AlphaFold」へと至る研究の歩みを、開発当事者の証言や当時の映像とともに記録した長編ドキュメンタリーである。
これまで映画祭や限定上映を中心に公開されてきたが、現在はYouTube上で誰でも視聴可能な形で提供されている。</p>
<p>@<a href="https://youtu.be/d95J8yzvjbQ?si=vIWt4zs9UPAJpNJ6">YouTube</a></p>
<h2>映画で描かれる、知性をめぐる5つのエピソード</h2>
<p>本作は単なる技術史ではなく、AI研究の過程で生じた意思決定や挫折、そして人間側の価値観にも焦点を当てている。以下は、ドキュメンタリー内で描かれる主なエピソードである。</p>
<h3>1. 天才チェス少年がAI研究を志した原点</h3>
<p>デミス・ハサビス氏は、幼少期にチェスの神童として活躍したが、12歳の国際大会での経験をきっかけに、競技としてのゲームに人生を捧げることに疑問を抱く。</p>
<p>「多くの優秀な頭脳が、一つのゲームに費やされている」という違和感が、知性そのものを解明し、より大きな課題解決に役立てたいという志につながったことが語られる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_thinking_game9_4e808c2cd7/the_thinking_game9_4e808c2cd7.jpg" alt="the thinking game9.jpg" /></p>
<h3>2. AIが“トンネル戦略”を発明した瞬間</h3>
<p>初期の強化学習AI「DQN」は、Atariゲームを通じて学習を進める中で、人間が想定していなかった攻略法を自律的に発見する。
ブロック崩しゲームでAIが編み出した「トンネルを掘る」戦略は、試行錯誤の末に創発的な解決策が生まれた象徴的な例として紹介されている。</p>
<h3>3. AlphaGoの「あり得ない一手」</h3>
<p>2016年のイ・セドル氏との対局で放たれたAlphaGoの37手目は、多くのプロ棋士が「あり得ない」と評した手だった。
結果的にこの一手は勝利につながり、AIが人類の長い歴史を持つ囲碁に新たな知見をもたらした瞬間として描かれる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_thinking_game6_35068a4891/the_thinking_game6_35068a4891.jpg" alt="the thinking game6.jpg" /></p>
<h3>4. 人間の知識ゼロから学ぶAlphaZero</h3>
<p>AlphaZeroは、人間の棋譜データを一切使わず、ルールのみを与えられて自己対戦を繰り返すことで急速に強化された。
短時間で人間のトップレベルを超える過程は、「知性はどこから生まれるのか」という問いを投げかける事例として位置づけられている。</p>
<h3>5. AlphaFoldと50年来の科学的難問</h3>
<p>ゲーム領域を超え、現実世界の科学課題に挑んだのがAlphaFoldだ。
タンパク質構造予測という長年の難問に対し、試行錯誤と再設計を経て高精度を達成し、その成果を無償公開した決断までが描かれている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_thinking_game3_53da0ee081/the_thinking_game3_53da0ee081.jpg" alt="the thinking game3.jpg" /></p>
<h2>YouTubeで全編視聴可能</h2>
<p>同ドキュメンタリーは現在、YouTube上で無料公開されており、アカウント登録や課金なしで全編を視聴できる。
@<a href="https://www.youtube.com/watch?v=d95J8yzvjbQ">YouTube</a></p>
<p>AGI研究の歴史や、DeepMindが掲げてきた思想を一次映像で確認できる資料として、研究者・技術者に限らず、生成AIに関心を持つ幅広い層に開かれた公開形態となっている。</p>
]]></description>
      <pubDate>Mon, 08 Dec 2025 07:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>