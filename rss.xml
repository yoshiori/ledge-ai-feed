<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>「AI 2027」予測を“後ろ倒し”──元OpenAI研究者ココタジロ氏ら、超人的AIの到来見通しを更新</title>
      <link>https://ledge.ai/articles/ai_2027_timeline_revision_kokotajlo</link>
      <description><![CDATA[<p>元OpenAIのAI研究者であるDaniel Kokotajlo氏らは2025年12月31日、AIの急速な進展とその潜在的リスクを描いた将来予測シナリオ「AI 2027」に関連する予測を見直し、AIが人間を明確に上回る能力を獲得する時期についての見通しを、従来より後ろ倒しにしたと<a href="https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update">発表</a>した。</p>
<p>この見直しは、同氏らが運営するAI Futures Projectが2025年12月末に公開した最新の予測モデルによるものだ。公式の説明によると、新モデルでは、AIが人間並み、あるいはそれ以上の能力でコーディングや研究開発を自動化する段階に到達するまでのタイムラインを、従来の想定より数年単位で長く見積もっているという。</p>
<h2>予測シナリオ「AI 2027」が提示してきたもの</h2>
<p>「<a href="https://ai-2027.com/">AI 2027</a>」は2025年に公開されたシナリオで、AIの能力向上が加速した場合に、2020年代後半にも人間を超える汎用的な知能が出現する可能性と、それに伴う社会的・安全保障上のリスクを描いたものだ。物語形式のシナリオとともに、能力向上のマイルストーンやタイムライン予測を示し、AI安全性やガバナンスをめぐる議論の中で広く参照されてきた。</p>
<p>同シナリオは、特定の年を断定するものではなく、複数の前提条件に基づく予測モデルを用いて将来像を提示している点が特徴とされている。</p>
<h2>最新モデルで示されたタイムラインの修正</h2>
<p>今回公開された最新モデルでは、AIが「完全なコーディング自動化」に至るまでの期間について、旧モデル（AI 2027で用いられた予測）よりも慎重な見積もりが採用された。AI Futures Projectはその理由として、完全自動化に至る前段階でのAIによる研究開発（R&amp;D）加速の効果を、現実的な制約を踏まえて再評価した点を挙げている。</p>
<p><strong>AI Futures Projectが公開した最新の予測モデル画面。AI 2027で用いられた従来モデルを更新し、AI研究開発の自動化や計算資源の前提を再評価している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/f2bf7c4b_33b1_4411_acb4_ffe5c2178fa0_1600x906_7bde2dd933/f2bf7c4b_33b1_4411_acb4_ffe5c2178fa0_1600x906_7bde2dd933.png" alt="f2bf7c4b-33b1-4411-acb4-ffe5c2178fa0_1600x906.png" /></p>
<p>研究開発の自動化が進めばAIの進化は複利的に加速する可能性がある一方、その速度や実用化の範囲については不確実性が大きいとし、前回の想定を修正した形だ。</p>
<h2>当事者による位置づけと説明</h2>
<p>ココタジロ氏は<a href="https://x.com/DKokotajlo/status/2006257807721652588">自身のX投稿</a>でも、「AI 2027のシナリオよりも進展はやや遅い可能性が高い」と言及している。あわせて、当初から予測には幅があり、今回の更新は新たなデータや前提条件を反映した結果だと説明している。</p>
<p><strong>AI Futures Modelに基づく1つの想定トラジェクトリー。完全なコーディング自動化（AC）、超人的AI研究者（SAR）、人工超知能（ASI）に至る時期を示している</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G9dm_El_Oa_YA_Ettaj_2dbcf7c8fd/G9dm_El_Oa_YA_Ettaj_2dbcf7c8fd.jpg" alt="G9dmElOaYAEttaj.jpg" /></p>
<h2>更新を前提とした予測モデルという位置づけ</h2>
<p>AI Futures Projectは、今回公開した最新モデルについて、現時点の技術動向や前提条件を反映したものであり、今後の研究開発の進展や実証結果に応じて見直しを行うとしている。AI 2027で提示された予測も、こうした更新の一部として位置づけられており、同プロジェクトは引き続き、モデルの前提や結果を公開しながら予測を更新していく方針を示している。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>現在の生成AI勢力図はどこからどのように生まれたのか？──Google起点の系譜を可視化した「AI Mafia」</title>
      <link>https://ledge.ai/articles/ai_mafia_google_ai_talent_network</link>
      <description><![CDATA[<p>生成AIを牽引する研究者や起業家たちは、どこから生まれ、どのようにつながってきたのか。
個人開発者のDipak Wani氏が公開したインタラクティブ可視化「<a href="https://dipakwani.com/ai-mafia/">AI Mafia</a>」は、Googleを起点とするAI人材の系譜をネットワーク図として可視化した試みとして注目を集めている。</p>
<p>「AI Mafia」は、人物、企業、研究組織などをノードとして配置し、それらの関係性を線で結んだインタラクティブなネットワーク図だ。閲覧者はノードを操作することで、特定の研究者がどの組織に所属し、どの企業や研究と結びついてきたのかを辿ることができる。生成AI分野を形作ってきた人材の流れを、構造として俯瞰できる点が特徴となっている。</p>
<h2>Googleに集結したAI人材──2010年代前半の「集中」</h2>
<p>この可視化の背景にあるのが、米国の人気ビジネス系ポッドキャスト「Acquired」が2025年秋に公開したエピソード「<a href="https://www.youtube.com/watch?v=lCEB7xHer5U">Google: The AI Company</a>」で整理されたAI史だ。同エピソードでは、現在の生成AI革命を担う人材の多くが、2010年代前半に一度Googleへ集結していたことが語られている。</p>
<p>@<a href="https://https://www.youtube.com/watch?v=lCEB7xHer5U">YouTube</a></p>
<p>2012年のImageNetコンペティションで勝利し、深層学習の転換点を作ったジェフ・ヒントン教授と、その教え子であるアレックス・クリジェフスキー、イリヤ・サツケヴァーらは、スタートアップ「DNN Research」を通じてGoogleに加わった。ほぼ同時期に、デミス・ハサビスらが創業したDeepMindも2014年にGoogleに買収され、優秀な研究者集団がGoogle傘下に入った。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/hinton_dnn_hassabis_deepmind_723429abc4/hinton_dnn_hassabis_deepmind_723429abc4.jpg" alt="hinton dnn hassabis deepmind.jpg" /></p>
<p>さらに、アンドリュー・ン氏やジェフ・ディーン氏らを中心に、Google内部では「Google Brain」が立ち上げられた。Acquiredではこの時期を、かつてIBMがコンピュータ時代初期にプログラマーを一手に集めていた状況になぞらえ、AI分野の人材と計算資源がGoogleに強く集中していた段階として位置づけている。</p>
<h2>OpenAIの設立と最初の人材流出</h2>
<p>こうした集中構造に変化をもたらしたのが、2015年前後のOpenAI設立だ。イーロン・マスク氏やサム・アルトマン氏らは、GoogleがAI研究と計算資源を事実上独占している状況に危機感を示し、対抗的な研究組織としてOpenAIを立ち上げた。
多くの研究者がGoogleに留まる中で、最初に大きな動きを見せたのがイリヤ・サツケヴァー氏だった。同氏はGoogleを離れ、OpenAIの創業メンバーとして参加し、後に同社の技術的中核を担う存在となった。この動きは、AI人材がGoogleから外部へ流出し始めた象徴的な出来事とされている。</p>
<h2>Transformer論文が加速させた分岐</h2>
<p>人材流動を決定的に加速させたのが、2017年にGoogleの研究者らが発表した論文「Attention Is All You Need」、いわゆるTransformer論文だ。現在の生成AIの基盤となるこの技術はGoogle内部で生まれたが、製品化には慎重な姿勢が取られた。</p>
<p>その結果、論文の共著者たちは数年以内に相次いでGoogleを退職し、スタートアップを創業したり、競合企業へ移籍したりしていった。主要著者の一人であるノーム・シャジール氏は、社内でのチャットボット公開が認められなかったことを背景に退職し、Character.AIを創業した例として知られる。</p>
<p><strong>Transformer論文著者たちのその後</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/after_transformer_6288345452/after_transformer_6288345452.jpg" alt="after transformer.jpg" /></p>
<h2>現在の生成AI勢力図へとつながる人材の流れ</h2>
<p>現在の生成AI業界を代表する企業の多くは、こうした流れの延長線上にある。OpenAIはサツケヴァー氏ら元Google研究者が技術基盤を築き、AnthropicはOpenAIからスピンアウトしたダリオ・アモデイ氏（元Google Brain）らによって設立された。DeepMindの共同創業者であるムスタファ・スレイマン氏はInflection AIを経て、現在はMicrosoftのAI部門を率いている。</p>
<p>Dipak Wani氏の「AI Mafia」は、これらの人材の集中と分岐の歴史を、一枚のインタラクティブな図として可視化したものだ。2025年10月下旬に<a href="https://news.ycombinator.com/item?id=45715819">Hacker News</a>上で作者本人によって公開され、年末から年始にかけてテック系コミュニティで共有が広がった。研究成果の優劣を示すものではないが、生成AI時代のエコシステムがどのような人材の流れによって形作られてきたのかを理解する手がかりとして参照されている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>購買行動のAI活用、広がりはこれから──若年層で利用意向が上昇、信頼は約50%</title>
      <link>https://ledge.ai/articles/ai_purchase_behavior_transition_dm_insight</link>
      <description><![CDATA[<p>電通マクロミルインサイトは2026年1月8日、生活者におけるAIの浸透状況や受容度、購買行動への影響を明らかにすることを目的とした「購買行動におけるAI浸透度調査」を実施し、その結果を<a href="https://www.dm-insight.jp/news/21739/">発表</a>した。</p>
<p>調査によると、AIツールの利用経験は生活者の約半数に達する一方、実際に購買行動でAIを活用している人は1割未満にとどまり、AI活用は日常利用と購買行動の間でギャップを抱える“過渡期”にある実態が浮かび上がった。</p>
<h2>日常では使うが、買い物では使わない──AI活用のギャップ</h2>
<p>調査では、生成AIを中心とするAIツールについて「利用したことがある」と回答した人が全体の約半数を占めた。利用経験のあるツールとしては、全世代で対話型生成AIが最多となっている。一方で、「買い物や購買に関する目的でAIを利用したことがある」と回答した人は1割未満にとどまった。
電通マクロミルインサイトはこの結果について、AIが日常生活に浸透しつつある一方、購買行動における活用はまだ限定的であり、両者の間に明確な段差が存在するとしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/graph2_png_0f40a53479/graph2_png_0f40a53479.webp" alt="graph2.png.webp" /></p>
<h2>若年層ほど高まる「購買でAIを使いたい」という意向</h2>
<p>現時点での活用率は低いものの、今後の利用意向を見ると状況は異なる。買い物や商品・サービスの情報収集において、AIを「利用したい」「やや利用したい」と回答した人は全体で37%に達した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/graph3_1024x576_png_ce26f96f34/graph3_1024x576_png_ce26f96f34.webp" alt="graph3-1024x576.png.webp" /></p>
<p>特に10代・20代といった若年層ではこの割合が高く、購買行動にAIを取り入れることへの心理的なハードルは相対的に低い傾向が示されている。調査結果からは、世代間でAI購買へのスタンスに差があることが読み取れる。</p>
<h2>AIへの信頼は約50%──購買活用の前提条件は整いつつある</h2>
<p>生成AIやAIエージェントに対する信頼度については、「信頼できる」「ある程度信頼できる」と回答した人が約50%に達した。この水準は、SNSに対する信頼度と同程度であり、マスメディアに次ぐ位置づけとなっている。
購買行動でAIを活用するためには、情報の正確性や中立性に対する信頼が不可欠となるが、少なくとも意識面では一定の基盤が形成されつつあることが示唆される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/graph4_1024x354_png_a53eefc0d8/graph4_1024x354_png_a53eefc0d8.webp" alt="graph4-1024x354.png.webp" /></p>
<h2>先行する「AI購買パイオニア層」に注目</h2>
<p>同社は、AIを商品探索や比較検討、購買判断に積極的に活用する層を「AI購買パイオニア層」と定義し、今後の消費行動変化を読み解く鍵になると位置づけている。今回の調査結果についても、AIを用いた分析によって仮想ペルソナを生成し、その行動や意識を深掘りする試みが進められているという。</p>
<p>購買行動におけるAI活用はまだ少数派にとどまるものの、こうした先行層の存在は、今後のカスタマージャーニーの変化を考える上で重要な手がかりとなりそうだ。</p>
<p><strong>調査概要</strong>
調査は、2025年10月2日から6日にかけて、全国の15〜69歳の男女1,200人を対象にインターネット調査として実施された。生活者のAI利用実態と購買行動の関係を定量的に捉えた点が特徴となっている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic、Claudeを医療・ライフサイエンス向けに拡張──診療支援から臨床試験までAI活用を本格化</title>
      <link>https://ledge.ai/articles/anthropic_claude_healthcare_life_sciences_expansion</link>
      <description><![CDATA[<p>米AI企業の Anthropic は2026年1月12日（現地時間）、同社の生成AI「Claude」において、医療およびライフサイエンス分野向けの機能拡張を<a href="https://www.anthropic.com/news/healthcare-life-sciences">発表</a>した。医療機関や保険者、研究者、個人利用者を対象に、医療データの要約・解釈から臨床試験、規制業務までを支援する専用機能を提供する。</p>
<h2>「Claude for Healthcare」を新設、医療業務向けAIを明確に区分</h2>
<p>同社は医療分野向けの専用機能群として「Claude for Healthcare」を導入した。これは、医療提供者、保険者、消費者が医療用途でClaudeを利用することを想定したプロダクトで、HIPAA（米医療保険の携行性と責任に関する法律）への対応を前提として設計されている。</p>
<p>想定される活用例としては、診療記録や検査結果の要約・解釈、医療文書の作成支援、保険請求や事前承認（prior authorization）といった事務手続きの効率化などが挙げられている。汎用的なチャット利用とは区別し、医療業務に特化したAIとして提供する点を明確にした。</p>
<h2>医療データ連携を拡充、CMSやPubMedなどに対応</h2>
<p>医療・行政データへの対応も拡充された。Claudeは新たに、米国の医療制度や診療報酬に関連するデータベースであるCMS Coverage DatabaseやICD-10、医療機関・医師情報を扱うNPI Registryといったデータソースに接続可能となった。</p>
<p>また、医学・生命科学分野の文献データベースであるPubMedへのコネクタも追加されている。これに加え、FHIR（Fast Healthcare Interoperability Resources）を用いた開発支援や、事前承認業務に対応するAgent Skillsも拡張され、臨床現場だけでなく医療事務や制度対応を含めた業務全体を視野に入れた設計となっている。</p>
<h2>個人向けにも健康データ接続を提供、学習利用は行わず</h2>
<p>個人利用者向けには、米国のClaude ProおよびMax加入者を対象に、健康データをClaudeに接続できる機能をベータ版として提供する。HealthExやFunctionを介した医療記録の接続に加え、Apple HealthやAndroid Health Connectとの連携にも対応する。</p>
<p>Anthropicは、こうした個人の健康データについて、AIモデルの学習には使用しない方針を明示している。医療・健康情報という機微性の高いデータを扱うにあたり、利用範囲とデータ取り扱いを限定する姿勢を強調した形だ。</p>
<h2>ライフサイエンス分野も強化、臨床試験・規制業務を支援</h2>
<p>ライフサイエンス分野向けには、「Claude for Life Sciences」の機能強化も行われた。新たにClinicalTrials.govやMedidata、bioRxivおよびmedRxivといった研究・臨床試験関連のデータソースとの連携が追加されている。</p>
<p>これにより、臨床試験の設計や進捗管理、研究文献の整理、規制当局向け文書の作成支援など、研究開発から規制対応までの幅広い業務をAIで支援することが可能になるとしている。</p>
<h2>医療・生命科学分野での実運用を見据えた展開</h2>
<p>Anthropicは今回の発表について、規制や安全性が強く求められる医療および生命科学分野において、生成AIを実運用に耐える形で導入するための取り組みだとしている。医療向けに用途を明確化し、データ連携や取り扱い方針を整理した上で提供を進めることで、医療現場や研究現場での活用拡大を狙う。</p>
<p>@<a href="https://www.youtube.com/watch?v=UXyVMGAFLAs&amp;t=1s">YouTube</a></p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/14 [WED]Anthropic、非エンジニア向け業務AIエージェント「Cowork」開始──Claude Codeの自律実行を一般業務へ拡張</title>
      <link>https://ledge.ai/articles/anthropic_cowork_launch_claude_code_agent_general_work</link>
      <description><![CDATA[<p>Anthropicは2026年1月12日（現地時間）、同社のAIアシスタント「Claude」において、新機能「Cowork（コワーク）」を研究プレビューとして開始したことを<a href="https://claude.com/blog/cowork-research-preview">発表</a>した。</p>
<p>開発者向けのコーディングエージェント「Claude Code」で培ってきた自律的なタスク実行の仕組みを、文書整理や資料作成といった一般業務にも拡張し、開発者以外でも利用できる業務エージェントとして提供する。</p>
<h2>「指示に答えるAI」から「作業を進めるAI」へ──Coworkの位置づけ</h2>
<p>Coworkは、Claudeがユーザーの「同僚（co-worker）」のように振る舞い、単発の質問に答えるだけでなく、目的を理解し、作業計画を立て、複数ステップのタスクを自律的に実行することを想定した機能だ。</p>
<p>Anthropicは、Claude Codeの提供後、開発者がコーディング以外の用途にも同機能を広く使い始めたことを背景に、よりシンプルで誰でも使える形としてCoworkを開発したとしている。基盤はClaude Codeと共通で、同様の自律実行能力を、非コーディング業務向けに抽象化した形となる。</p>
<p>@<a href="https://www.youtube.com/watch?v=UAmKyyZ-b9E">YouTube</a></p>
<h2>ローカルファイルを直接扱う業務エージェント</h2>
<p>Coworkは、macOS向けのClaude Desktopアプリ上で動作する。ユーザーが許可したフォルダに対して、Claudeが以下の操作を直接行える点が特徴だ。</p>
<ul>
<li>ファイルの読み取り</li>
<li>ファイルの編集・新規作成</li>
<li>複数ファイルの整理や再構成</li>
</ul>
<p>公式ブログでは、ダウンロードフォルダの自動整理、スクリーンショットの束から経費一覧のスプレッドシートを作成する作業、散在するメモからレポートの下書きを作る作業などが例として挙げられている。チャット上の応答にとどまらず、実際の業務ファイルを扱いながら作業を進める点がCoworkの特徴だ。</p>
<p>@<a href="https://www.youtube.com/watch?v=WBNZpAWhw5E">YouTube</a></p>
<h2>コネクタ、スキル、Chrome連携──業務エージェントとしての拡張性</h2>
<p>Coworkでは、Claudeが既存のコネクタを利用できる。これにより、外部情報と連携したタスク実行が可能になる。また、Cowork向けに、文書やプレゼンテーション、各種ファイル作成を強化する初期スキル群も追加された。さらに、Chrome上でClaudeを利用する設定と組み合わせることで、ブラウザ操作を伴うタスクにも対応できるとしている。</p>
<p>Anthropicは、Coworkでは毎回文脈を手動で与えたり、出力結果を別の形式に変換したりする必要がなく、タスクをキューに積んで並列に進められる設計になっている点も特徴だと説明する。やり取りを重ねるというより、「同僚にまとめて指示を残す」感覚に近い体験を目指したという。</p>
<h2>提供条件と現時点での制約</h2>
<p>Coworkは研究プレビューとして提供されており、現時点での利用条件は以下の通り。</p>
<p><strong>■ 提供環境</strong>
・macOS向けClaude Desktopアプリ
・有料の「Claude Max」プラン加入者向け</p>
<p><strong>■ 制約</strong>
・セッションをまたいだ長期的な記憶は行わない
・Claudeの「Projects」機能とは未統合</p>
<p>Claude Max以外のプラン利用者については、将来提供に向けた待機リストが用意されている。
Anthropicは今後、クロスデバイス同期の追加やWindows対応など、段階的な拡張を進めるとしている。</p>
<h2>自律型AIの業務利用を前提にした安全設計</h2>
<p>Coworkでは、Claudeがローカルファイルを操作できるため、安全面での注意も明示されている。ユーザーは、Claudeに見せるフォルダやコネクタを自ら選択でき、明示的に許可していない情報にはアクセスできない。</p>
<p>また、重要な操作を行う前にはClaudeが確認を求める設計となっている。一方で、削除などの破壊的な操作が行われる可能性もあるため、指示は明確に行う必要があるとしている。</p>
<p>Anthropicは、インターネット上の内容によってAIの行動計画が変えられる「プロンプトインジェクション」のリスクにも言及し、これは業界全体で対処が続く課題だと説明する。
詳細な注意点については、Help Centerで<a href="https://support.claude.com/en/articles/13364135-using-cowork-safely">案内</a>している。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/13 [TUE]Apple、次世代AI基盤にGemini採用──SiriなどApple Intelligenceで活用へ</title>
      <link>https://ledge.ai/articles/apple_nextgen_ai_platform_gemini_adoption</link>
      <description><![CDATA[<p>Apple と Google は2026年1月12日（米国時間）、Apple の次世代基盤 AI「Apple Foundation Models」に、Google の生成 AI モデル Gemini とクラウド技術を採用すると<a href="https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/">発表</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/google_apple_x_b32876998f/google_apple_x_b32876998f.jpg" alt="google apple x.jpg" /></p>
<p>声明によると、この協業は複数年にわたる取り組みで、Siri を含む Apple Intelligence 関連機能の基盤として活用される。今回の発表は、Google が公式ブログ上で Apple との Joint Statement として公開したもの。Apple Foundation Models は、Apple が自社製品やサービスに組み込む AI 機能の基盤となるモデル群で、今後の Apple Intelligence の中核を担う位置づけとされている。</p>
<h2>Apple Foundation Models の基盤に Gemini と Google Cloud</h2>
<p>Apple は次世代の Foundation Models において、Gemini のモデル群と Google のクラウド基盤を採用する。Gemini は Google が開発する大規模言語モデルで、テキスト理解や生成をはじめ、幅広い AI タスクに対応する点が特徴とされる。</p>
<p>Apple はこの技術を、Apple Foundation Models の一部として統合し、Apple Intelligence を構成する各種機能の基盤として利用する。具体的なモデル構成や技術的な役割分担については、今回の声明では詳細は明らかにされていない。</p>
<h2>Siri を含む Apple Intelligence 機能で活用へ</h2>
<p>両社は、Gemini を採用した Apple Foundation Models が、Siri を含む Apple Intelligence 関連機能で活用されるとしている。これにより、Gemini とクラウド技術を基盤とする次世代 Foundation Models が、Siri などの Apple Intelligence 機能を支える設計になることが示されている。</p>
<h2>プライバシーは Apple の基準を維持</h2>
<p>プライバシーに関しては、共同声明の中で、ユーザーデータの取り扱いは Apple のプライバシー基準に基づいて行われる方針が示されている。Apple は、ユーザーのプライバシー保護を重視した形で AI 機能を提供するとしている。</p>
<h2>AI 基盤を巡る競争の中で進む協業</h2>
<p>Apple と Google は、モバイル OS や AI 分野で競合関係にある一方、検索やクラウド分野では協業関係も持つ。今回の発表は、AI 基盤技術を巡る競争が激化する中で、両社がそれぞれの技術的強みを活用する形で合意に至ったことを示すものとなった。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>英アーム、「フィジカルAI」部門を新設──ロボット市場に照準、CESで組織再編を表明</title>
      <link>https://ledge.ai/articles/arm_physical_ai_robotics_ces2026</link>
      <description><![CDATA[<p>英半導体設計大手のArmは、米ラスベガスで開催中のCESの会場で、「Physical AI（フィジカルAI）」部門を新設するため、全社組織を再編したと明らかにした。複数の同社幹部が<a href="https://www.reuters.com/business/autos-transportation/arm-launches-physical-ai-division-expand-robotics-market-2026-01-07/">Reuters</a>の取材に応じた。</p>
<p>Armは今回の組織再編で、AI戦略の軸足を物理世界へと広げた。新設されるPhysical AI部門は、ロボティクス市場への展開を主眼に据え、自動車分野とあわせて統合的に扱う。</p>
<h2>組織再編の中身──Cloud、Edge、そしてPhysical AIへ</h2>
<p>Armは今後、事業を以下の3つの主要部門で運営する。</p>
<ul>
<li>Cloud and AI</li>
<li>Edge（モバイル端末やPC向け製品を含む）</li>
<li>Physical AI</li>
</ul>
<p>Physical AI部門には、従来の自動車事業が組み込まれ、ロボティクスと車載分野を一体で扱う構成とした。ロボット分野への本格展開に向け、専任人員の増員も計画している。</p>
<h2>ロボットと自動車を一体で捉える、Armの設計思想</h2>
<p>同社幹部は、ロボットと自動車がPhysical AIの中核をなす理由として、両分野が共通の技術要件を持つ点を挙げた。センサー技術、電力制約、安全性や信頼性といった条件が近く、同一の設計思想で対応できる領域だとしている。</p>
<h2>「労働を拡張する市場」──新部門責任者が描くロボット像</h2>
<p>新設されたPhysical AI部門を率いるDrew Henry氏は、Physical AIについて、労働を根本的に補完し、人々の可処分時間を生み出す可能性があると説明した。こうした変化は、結果として国内総生産（GDP）にも影響を与え得るとの認識を示した。</p>
<p>@<a href="https://www.youtube.com/watch?v=OHQJsiS4onk">Youtube</a></p>
<p>また、最高マーケティング責任者（CMO）のAmi Badani氏は、ロボティクス分野に人材を重点投入する方針を明らかにしている。</p>
<h2>壮大なビジョンと足元の一手──Arm公式が描くPhysical AI</h2>
<p>Armは<a href="https://newsroom.arm.com/blog/the-next-platform-shift-physical-and-edge-ai-powered-by-arm">公式ブログ</a>で、Physical AIをクラウド上のAIが現実世界で行動できる段階へ進む「次のプラットフォーム転換」と位置づけている。ロボットや車両、XR（拡張現実）機器など、物理空間で動作するAI全般を射程に入れる構想だ。一方、Reutersの報道では、その中でも最初の成長市場としてロボット分野を明確に打ち出した点が特徴となっている。</p>
<p>CES 2026では、多くの企業がヒューマノイドや産業用ロボットを披露した。自動車メーカーやIT大手もロボット分野への関与を強めており、Armの組織再編は、展示の延長ではなく、ロボット市場を見据えた中長期の経営判断として位置づけられる。</p>
<h2>ロボット市場に照準──Armが選んだPhysical AIの最初の到達点</h2>
<p>ArmはCES 2026の場で、「フィジカルAI」部門を新設し、ロボット市場に照準を定めた組織再編を初めて明らかにした。生成AIを中心とするクラウドの次の段階として、物理世界で動作するAIを成長ドライバーとする姿勢が浮き彫りとなった。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>AIは主役から基盤へ──CES 2026で示された「実装段階」に入ったテクノロジーの姿</title>
      <link>https://ledge.ai/articles/ces2026_ai_design_embedded_devices</link>
      <description><![CDATA[<p>世界最大級のテクノロジー見本市「CES 2026」は、2026年1月6日から9日まで、米国ネバダ州ラスベガスで<a href="https://www.ces.tech/press-releases/ces-2026-the-future-is-here">開催された</a>。主催するConsumer Technology Association（CTA）は、今回のCESを「The Future Is Here（未来はすでにここにある）」と位置づけ、先端技術が構想や実験段階を越え、現実の製品やサービスとして展開されるフェーズに入ったことを強調した。
展示会場では、AIが単独の主役として語られるのではなく、PC、デジタルヘルス、モビリティ、日用品など幅広い分野に組み込まれ、生活や仕事のあり方を具体的に変える基盤技術として提示された。</p>
<p>CES 2026で示されたのは、AIが主役として語られるフェーズを越え、製品や体験の設計思想そのものに組み込まれていく段階に入った姿だった。編集部では、こうした移り変わりを象徴するようなデバイスをいくつかピックアップした。いずれも「AI搭載」を強調するより、計算や推論が製品の内部に溶け込み、使い方そのものを形づくっている点が共通している。これらの製品を通じて、CES 2026で示された“実装段階”の姿を見ていく。</p>
<h2>キーボード一体型AI PC：HP EliteBoard G1a</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/v2_2026_hpeliteboardg1anextgenaipc_hpeliteboard_primary_826008a117/v2_2026_hpeliteboardg1anextgenaipc_hpeliteboard_primary_826008a117.webp" alt="v2_2026_hpeliteboardg1anextgenaipc-hpeliteboard_primary.webp" /></p>
<p>HPは、キーボード一体型のAI PC「EliteBoard G1a」を<a href="https://www.ces.tech/ces-innovation-awards/2026/hp-eliteboard-g1a-next-gen-ai-pc/">発表</a>した。外観はフルサイズキーボードに近いが、内部にCPUに加えてNPUを含む演算基盤を搭載し、外付けディスプレイと接続して使用する構成となっている。本製品はローカルでのAI処理を前提に設計されており、クラウドに依存せず、生成AIや要約、分析といったAIタスクを端末側で実行する用途を想定している。画面を本体から切り離すことで、AI処理を担う計算ユニットを机上に集約する設計思想が示された。
本製品はCES Innovation Awards 2026にも選出されている。</p>
<p><strong>PC → 生活空間AIへの転換</strong>
PC領域でのローカルAI処理を前提とした設計が示された一方で、CES 2026では、AIがディスプレイや入力装置の枠を越え、生活空間そのものに組み込まれる例も複数見られた。</p>
<h2>AIコンパニオン：Lepro Ami</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Lepro_Ami_70cd5a7695/Lepro_Ami_70cd5a7695.jpg" alt="Lepro_Ami.jpg" /></p>
<p>Leproは、デスクトップ型AIコンパニオン「Lepro Ami」を<a href="https://www.newswire.ca/news-releases/lepro-unveils-lepro-ami-at-ces-2026-a-desktop-ai-companion-that-feels-in-the-room--847670849.html">公開</a>した。公式説明によると、Amiは音声入力や周囲の環境情報をAIが解釈し、利用者との対話や反応を行うことを目的としたデバイスである。画面操作を中心とする従来のAIとは異なり、空間内での存在感や応答性を重視した設計が特徴とされる。AI処理の一部はローカルで行う構成が示されており、プライバシーへの配慮も設計要素として挙げられている。日常空間に常駐するAIの形を提示するデバイスとして位置づけられている。</p>
<p><strong>空間AI → 個人データ／ライフログ</strong>
空間に常駐するAIに加え、CES 2026では、個人の行動や状態を継続的に捉えるAIを想定したデバイスも提示された。AIを“使う”存在ではなく、“常にそばにある前提”で設計する動きが浮かび上がる。</p>
<h2>AIライフログ・ペンダント：Motorola Project Maxwell</h2>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Maxwell_Photo_7_1536x1024_36f46681ba/Maxwell_Photo_7_1536x1024_36f46681ba.jpg" alt="Maxwell-Photo-7-1536x1024.jpg" /></p>
<p>Motorolaは、AIライフログデバイス「Project Maxwell」を研究プロジェクトとして<a href="https://motorolanews.com/motorola-unveils-new-flagship-devices-and-ai-powered-innovation-at-lenovo-tech-world-2026/">紹介</a>している。ペンダント型デバイスとして構想されており、利用者が見聞きしている情報をAIが理解・整理することを目的とする。公式リリースでは、視覚や音声といった日常環境データをAIが解析し、個人に合わせた体験や支援につなげる構想が示されている。AIは常時稼働するアシスタントとして振る舞うことを想定しており、Motorola 312 Labsによる実験的な取り組みの一環として位置づけられている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/G_EPFK_2a_MAA_Vy_Iy_216a72ad1f/G_EPFK_2a_MAA_Vy_Iy_216a72ad1f.jpg" alt="G-EPFK2aMAAVyIy.jpg" /></p>
<p><strong>ライフログ → デジタルヘルス</strong>
こうした流れは、デジタルヘルス分野でも顕著だった。CES 2026では、ウェアラブルや医療機器に限らず、日常的な動作や映像を起点に健康状態を把握しようとするアプローチが広がりを見せた。</p>
<h2>ミラー型デバイス：NuraLogix「Longevity Mirror」</h2>
<p>デジタルヘルス技術企業NuraLogixは、ミラー型デバイス「Longevity Mirror」を<a href="https://www.linkedin.com/posts/nuralogix-corporation_ai-longevity-healthtech-activity-7414349139225788416-Ne-N">公開</a>した。製品では、30秒のセルフィービデオをAIが解析し、血流変化などの映像情報から健康関連指標を推定する。同社によると、AIは映像データをもとに「Longevity Index（LIX）」を算出し、心血管疾患リスクや代謝の健康、精神的ストレスなど5つの生理学的領域を統合的に評価するという。ウェアラブルや物理センサーを用いず、カメラ映像とAI解析のみで健康状態の把握を試みる点が特徴とされている。</p>
<p>@<a href="https://www.youtube.com/watch?v=dDem2hR4_1E">YouTube</a></p>
<p>CES 2026には、約14万8,000人が来場し、4,100社以上（うち約1,200社がスタートアップ）が出展した。CTAのGary Shapiro氏は、CESを「世界で最も強力なイノベーションの実証の場」と位置づけ、技術がビジネスや政策、社会と結びつく場であると説明している。また、Kinsey Fabrizio氏は、AIをはじめとする技術がビジョンから実用段階へと移行している点を強調した。
AIが話題の中心となった過去数年を経て、2026年はAIを含む先端技術が、実体あるプロダクトや産業の中で役割を担い始めた段階を示すCESとなった。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>核融合炉「SPARC」の開発をAIデジタルツインで加速―—Commonwealth Fusion Systems、NVIDIA・シーメンスと連携</title>
      <link>https://ledge.ai/articles/cfs_sparc_ai_digital_twin_nvidia_siemens</link>
      <description><![CDATA[<p>核融合スタートアップの Commonwealth Fusion Systems（CFS） は2026年1月6日、NVIDIA および Siemens と提携し、実証用核融合炉 SPARC の設計・開発をAI主導で加速するデジタルツインを構築すると<a href="https://cfs.energy/news-and-media/commonwealth-fusion-systems-accelerates-commercial-fusion-with-siemens-and-nvidia-leveraging-ai-powered-digital-twins">発表</a>した。AIとシミュレーションを中核に据え、従来は物理試験に大きく依存していた核融合炉開発のプロセスを仮想空間上で統合・高速化する。</p>
<h2>AIと産業ソフトウェアを統合したデジタルツイン</h2>
<p>CFSが構築するデジタルツインは、NVIDIAのAIおよび物理シミュレーションライブラリと、Siemensの設計・製造向けソフトウェア群を統合したものとなる。</p>
<p>SiemensのNXやTeamcenterを中心とする設計・PLM（製品ライフサイクル管理）ツールで作成されたデータを、NVIDIAのシミュレーション基盤と連携させることで、SPARCの構造・磁場・熱挙動などを一体的に再現する。</p>
<p>@<a href="https://www.youtube.com/watch?v=4PItOlY6_xE">YouTube</a></p>
<p>この環境では部品単位から炉全体までを単一の仮想モデルで扱うことが可能となり、設計変更や検証を仮想空間上で迅速に繰り返せるという。</p>
<h2>「動く炉」を再現するデジタルモデル</h2>
<p>今回のデジタルツインは、静的な3D設計モデルではなく、実際の運転を想定した動的モデルとして構築される。
電磁場、熱、構造応力といった複数の物理現象を同時に扱い、将来的には実機から得られるデータを反映させることで、仮想モデルと現実の炉の状態を同期させる設計とされている。これにより、実際に装置を製作・試験する前の段階で、設計上の課題や挙動を検証できるようになる。</p>
<h2>高磁場・小型化を支えるAI活用</h2>
<p>SPARCは、高温超電導（HTS）磁石を用いることで、従来よりも小型ながら高磁場を実現する設計を採用している。
CFSはすでに、SPARC向けの初号磁石を完成させ、出荷したことを明らかにしている。この磁石は「空母を持ち上げられるほどの磁力を持つ」と説明されており、高磁場化に伴う構造応力や熱管理が技術的な焦点となっている。</p>
<p>こうした複雑な物理挙動を事前に解析・検証するため、AIとシミュレーションを組み合わせたデジタルツインが設計プロセスの前提となっている。</p>
<h2>実機開発と仮想検証を並行</h2>
<p>CFSは、磁石の製造・据え付けと並行して、デジタルツイン上で炉全体の挙動解析を進める体制を構築している。
物理的な試作・試験と、仮想空間での検証を同時に進めることで、開発工程全体の効率化を図る狙いだ。</p>
<p>デジタルツインは、建設段階にとどまらず、将来的な運転や保守、最適化にも活用されることが想定されている。</p>
<h2>2027年稼働を見据えた基盤整備</h2>
<p>SPARCは、核融合反応による正味エネルギー獲得を目指す実証炉として開発が進められており、2027年の稼働が計画されている。
今回のNVIDIAおよびSiemensとの連携は、設計から運転までをデータとAIに基づいて進める開発基盤を整備する取り組みとして位置付けられる。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、健康分野に特化した「ChatGPT Health」公開──医療情報を安全に整理</title>
      <link>https://ledge.ai/articles/chatgpt_health_launch</link>
      <description><![CDATA[<p>OpenAIは2026年1月7日（現地時間）、健康・ウェルネス分野に特化した新機能「ChatGPT Health」を<a href="https://openai.com/ja-JP/index/introducing-chatgpt-health/">発表</a>した。医療記録やウェルネスアプリの情報を活用し、利用者が自身の健康状態を理解しやすくすることを目的とした専用体験を提供する。</p>
<p>ChatGPT Healthは、健康に関する会話専用に設計された機能で、通常のChatGPTのチャットとは分離された空間で利用できる。OpenAIによると、近年ChatGPTには健康やウェルネスに関する質問が急増しており、こうしたニーズに対応する形で専用機能を開発したという。</p>
<p>同機能では、検査結果や診療内容といった医療記録を読み解く支援に加え、運動・食事・睡眠などのウェルネスアプリのデータを統合し、情報を整理することが可能とされている。これにより、医師に相談する際の質問を事前にまとめたり、生活習慣を見直すためのヒントを得たりする用途を想定している。</p>
<p>ChatGPT Healthは、まず少人数の初期ユーザーを対象に提供を開始し、利用状況を踏まえながら改善を続ける。OpenAIは、改善を進めながら数週間以内にウェブ版とiOSのすべてのユーザーへ提供を拡大する予定としている。一方で、電子健康記録（EHR）の連携および一部のアプリは米国のみで利用可能で、Appleヘルスケアの接続にはiOSが必要だとしている。</p>
<p><strong>ChatGPT Healthの画面イメージ：ChatGPT内の専用スペースとして『ヘルスケア』が用意される</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/OAI_Chat_GPT_Health_Wayfinding_16_9_444cbb0458/OAI_Chat_GPT_Health_Wayfinding_16_9_444cbb0458.webp" alt="OAI_ChatGPT_Health_Wayfinding_16-9.webp" /></p>
<p>一方でOpenAIは、ChatGPT Healthが診断や治療を行うものではない点を明確にしている。あくまで医療専門職によるケアを補完する存在であり、最終的な医療判断は医師などの専門家が担うとしている。</p>
<p>ChatGPT Healthは、まず個人向けの健康・ウェルネス支援を目的として提供される。プライバシー面にも配慮し、健康関連の会話は他のチャット履歴から分離して管理される。OpenAIは、こうしたデータが基盤モデルの学習には使用されないことも明らかにしており、利用者が接続するデータを管理できる仕組みを用意したという。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>イーロン・マスクのNeuralink、BCI：思考で操作する脳内チップを量産へ　2026年計画を示す</title>
      <link>https://ledge.ai/articles/elon_musk_neuralink_bci_mass_production_2026</link>
      <description><![CDATA[<p>脳と機械を直接つなぐブレイン・コンピューター・インターフェイス（BCI）を開発する米スタートアップ Neuralink が、BCIデバイスの量産を2026年に開始する計画を示した。創業者の イーロン・マスク 氏が2026年1月1日の同氏のXへの<a href="https://x.com/elonmusk/status/2006513491105165411">投稿</a>で明らかにした。</p>
<p>マスク氏は投稿で、NeuralinkがBCIデバイスの高ボリューム生産を2026年に開始し、手術工程を大幅に簡略化した、ほぼ完全に自動化された外科手術へ移行すると説明した。これまで同社のBCIは、主に臨床試験向けに限定的な規模で製造されてきたが、今後はより多くの患者への提供を想定した製造フェーズへの移行を見据える。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/elon_x_post_neuralink2026_87a80d4661/elon_x_post_neuralink2026_87a80d4661.jpg" alt="elon x post neuralink2026.jpg" /></p>
<h2>手術の自動化と侵襲性低減</h2>
<p>マスク氏はあわせて、BCIデバイスに用いられる電極スレッドが、脳を覆う硬膜（dura）を除去することなく貫通する設計になると述べた。従来の脳外科手術では硬膜の切開や除去を伴うケースが多く、これを不要とする構造は、手術の侵襲性を抑える点で重要な意味を持つとされる。同氏はこの点について「大きな進展だ（This is a big deal）」と強調した。</p>
<p>Neuralinkは、ロボットを用いた手術システムの開発を進めており、将来的には手術工程の標準化や効率化、医師の負担軽減を図る構想を示してきた。今回の投稿は、量産体制の構築と並行して、自動化された手術プロセスを実運用に移行させる方針を示したものとなる。</p>
<h2>臨床試験の進展と背景</h2>
<p>マスク氏がリポストした投稿によると、Neuralinkは2025年にかけて、米国以外の地域も含め臨床試験を拡大してきた。重度の発話障害を対象とした技術については、米食品医薬品局（FDA）からブレークスルー・デバイス指定を受けたほか、英国や中東、カナダでの臨床試験や手術も実施されたとされる。</p>
<p>これらの試験では、脊髄損傷などにより身体機能に制約のある患者が、思考によってコンピューターを操作する事例が報告されている。現時点でNeuralinkが想定する主な用途は、神経障害や麻痺を持つ患者の支援であり、一般向け利用についての具体的な計画は示されていない。</p>
<h2>量産フェーズへの転換点</h2>
<p>今回示されたBCIデバイスの量産計画と手術自動化の方針は、Neuralinkが研究・実証段階にとどまらず、実用化と提供規模の拡大を見据えた段階へ進もうとしていることを示すものとなる。今後は、安全性や有効性の検証に加え、各国の規制当局による承認が引き続き重要な要素となる。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ファミマ、防犯カメラ×AIで売場を「点数化」　首都圏で新システム「AI売場スコアリング」の実証開始、AI発注やロボットとの連携も視野に</title>
      <link>https://ledge.ai/articles/familymart_ai_camera_salesfloor_scoring</link>
      <description><![CDATA[<p>ファミリーマートは2026年01月13日、店舗に設置している防犯カメラの映像を活用し、人工知能（AI）で売場の状態を点数化する新たな店舗運営支援システム「AI売場スコアリング」の実証実験を開始することを<a href="https://www.family.co.jp/company/news_releases/2026/20260113_02.html">発表</a>した。2026年1月中旬から首都圏の一部店舗で導入し、業務効率化や品揃えの最適化につなげる。</p>
<p>同システムは、防犯カメラで撮影した売場映像をAIで画像解析し、売場の状態を数値（スコア）として可視化する仕組みだ。これにより、従来は経験や目視に頼りがちだった売場評価を、客観的なデータに基づいて行えるようにする。</p>
<h2>決まった時間に売場を撮影、画像を蓄積</h2>
<p>実証では、あらかじめ設定した時間に売場を撮影し、画像データを蓄積する。例えば「おむすび売場」を毎日同じ時間帯に撮影することで、曜日や時間帯ごとの売場の違いを比較できるようにする。蓄積された画像をもとに、売場のボリュームを点数化し、定点観測が可能なレポートを作成する。</p>
<h2>曜日・日・時間帯別にスコアリング</h2>
<p>AIによるスコアリングは、曜日別、日別、時間帯別の3つの軸で行う。売場画像と点数を組み合わせることで、どの時間帯や曜日に売場の課題が生じやすいかを把握しやすくする狙いだ。作成された定点観測レポートは、店長やスーパーバイザー（SV）が売場を客観的に評価するための資料として活用される。</p>
<h2>SV巡回や店長不在時の売場把握に活用</h2>
<p>SVは巡回時に、売場画像とスコアを確認しながら店長と課題を共有し、発注や売場づくりの改善につなげる。また、店長が不在の間も売場の状況を画像で把握できるため、実態に即した発注が可能になり、発注精度の向上が期待されるとしている。</p>
<h2>ロボットやAI発注との連携も視野</h2>
<p>同社は将来的に、多機能型床清掃ロボット「ポム」にカメラを搭載し、本システムに活用する構想も示している。さらに、既存のAI発注システムや、人型AIアシスタント「レイチェル」と連携させ、売場分析や発注提案の自動化を進める方針だ。対象売場も順次拡大し、店舗運営全体の効率化を図る。</p>
<p>なお同社は、本取り組みの目的において、個人情報が含まれる売場画像は利用しないとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>AIによる「失業パニック」は起きない？──Forrester予測、2030年までに置き換わる職は米国全体の約6％</title>
      <link>https://ledge.ai/articles/forrester_ai_job_impact_forecast_us_2025_2030</link>
      <description><![CDATA[<p>AIによる雇用喪失への不安が世界的に広がるなか、調査会社のForresterは2026年1月13日、大規模な失業パニックが直ちに起きる可能性は低いとする<a href="https://www.forrester.com/press-newsroom/forrester-impact-ai-jobs-forecast/">見通しを示した</a>。2025年12月末に発表した最新レポートによると、米国で2030年までにAIと自動化によって置き換わる職は全体の約6％、約1040万件にとどまると<a href="https://www.forrester.com/blogs/ai-and-automation-will-take-6-of-us-jobs-by-2030/">予測</a>している。</p>
<p>同レポートは「The Forrester AI Job Impact Forecast, US, 2025–2030」と題され、AIが雇用に与える影響を定量的に分析したものだ。AIの進展によって一部の職種が影響を受けることは避けられないとしつつも、社会全体を揺るがすような急激な雇用崩壊には至らないとの見方を示している。</p>
<h2>AIは職業ではなく「タスク」を置き換える</h2>
<p>Forresterの分析で強調されているのは、AIが直接置き換えるのは「職業」ではなく、職業を構成する「タスク」であるという点だ。多くの仕事は複数の業務要素から成り立っており、その一部がAIによって自動化されるケースが中心になるとされている。</p>
<p>このため、AI導入が即座に人員削減につながるわけではなく、業務の再設計や役割分担の見直しが進む可能性が高いと分析している。</p>
<h2>影響を受けやすい職と限定的な職</h2>
<p>レポートでは、定型的で反復性の高い業務を中心とする職種ほど、AIや自動化の影響を受けやすいと指摘している。一方で、対人対応、判断、創造性を伴う業務については、AIによる完全な代替は限定的になるとの見方を示した。</p>
<p>AIの影響は一様ではなく、職種や業務内容によって大きな差が生じる点が強調されている。</p>
<h2>「AI失業パニック」への警鐘</h2>
<p>Forresterは、AIによる失業への過度な恐怖が、拙速な自動化や短期的なコスト削減判断を招くリスクにも言及している。AIは人件費削減の手段としてではなく、生産性向上や業務の高度化を目的として活用すべきだとしている。</p>
<p>同社は、AIを前提とした業務設計と人材育成を並行して進めることが、企業にとって重要になると指摘した。</p>
<h2>雇用構造の変化にどう向き合うか</h2>
<p>レポートは、今後の課題としてリスキリングやアップスキリングの重要性を挙げている。AIによって一部の業務が置き換わる一方で、新たな役割やスキル需要が生まれる可能性があるためだ。</p>
<p>Forresterは、AIを「雇用を破壊する存在」として捉えるのではなく、雇用構造を変化させる要因として冷静に受け止める必要があるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>エンジニアリング2026/1/16 [FRI]Googleの開発用プラットフォーム「Antigravity」に“Agent Skills”登場　エージェントに作業手順を配布できるオープン標準</title>
      <link>https://ledge.ai/articles/google_antigravity_agent_skills_open_standard</link>
      <description><![CDATA[<p>Google は2026年1月14日（現地時間）、同社の開発用プラットフォームAntigravityにおいて、エージェントの機能を拡張するパッケージ「Skills」のオープン標準を<a href="https://antigravity.google/docs/skills">発表</a>した。Skillsは、特定の作業に必要な手順やベストプラクティス、必要に応じてスクリプトや参考実装などをまとめた再利用可能な知識パッケージで、エージェントは作業時にそれらを参照しながらタスクを進められる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Antigravity_x_ab552c6744/Antigravity_x_ab552c6744.jpg" alt="Antigravity x.jpg" /></p>
<h2>作業手順を“知識パッケージ”として配布</h2>
<p>Skillsは、エージェントに対して都度プロンプトで細かな指示を与えるのではなく、あらかじめ整理された作業マニュアル一式を参照させるための仕組みだ。単純な定型作業から、判断を伴う業務フローまでをSkillとして定義でき、同じSkillを複数のエージェントやプロジェクトで再利用できる点が特徴となる。</p>
<h2>人が書き、エージェントが参照するための共通フォーマット</h2>
<p>各Skillはフォルダー単位で構成され、その中核となるのがSKILL.mdファイルだ。SKILL.mdには、Skillの名称や概要、前提条件、具体的な手順などをYAML形式のフロントマターとして記載し、本文には作業手順をMarkdownで記述する。
同じフォルダー内には、スクリプト、テンプレート、参考実装などの追加リソースを含めることができ、Skill全体として一体的に扱われる。</p>
<h2>単純作業から業務フローまでを扱える設計</h2>
<p>より複雑なSkillでは、「条件に応じて次の手順を切り替える」といった意思決定の分岐も記述可能だ。Antigravityでは、1つのSkillにつき目的を明確にし、説明文を具体的に書くことを推奨している。これにより、エージェントが必要な情報だけを参照しながら作業を進められる設計となっている。</p>
<h2>先行するAnthropicの「Agent Skills」という発想</h2>
<p>このSkillsの設計思想は、Anthropicが先行して提示してきた「Agent Skills」の考え方と重なる。Anthropicは、エージェントに現実的な業務能力を持たせるため、SKILL.mdを中心とした構造を採用し、2025年末には特定のプラットフォームに依存しないオープン標準として公開していた。
GoogleがAntigravityでSkills対応を打ち出したことで、エージェントに与える作業手順やノウハウをツール横断で共有する流れが、主要プラットフォーム間で具体化しつつある。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Google、AIエージェント時代の購買基盤「Universal Commerce Protocol（UCP）」を発表──NRF 2026でエージェンティックコマース構想を提示</title>
      <link>https://ledge.ai/articles/google_nrf2026_universal_commerce_protocol_ucp_agentic_commerce</link>
      <description><![CDATA[<p>Googleは2026年1月11日（現地時間）、全米小売業協会（NRF）が主催する年次イベントNRF 2026において、AIエージェントが購買プロセスを担う「エージェンティックコマース（agentic commerce）」時代に向けた取り組みを<a href="https://blog.google/company-news/inside-google/message-ceo/nrf-2026-remarks/">発表</a>した。</p>
<p>同社は、AIエージェントと小売事業者、決済事業者、プラットフォームを横断的につなぐオープン標準として<a href="https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/">「Universal Commerce Protocol（UCP）」</a>を公開し、検索や広告、コマース体験を再編する構想を示した。</p>
<h2>AIが商品探索から購入までを担う「エージェンティックコマース」</h2>
<p>Googleが示すエージェンティックコマースは、利用者が検索や比較を行い購入を決定する従来のEC体験とは異なり、AIエージェントが利用者の意図を理解し、商品探索、条件比較、購入判断、決済までを代行することを前提とする。
NRF 2026での発言において、Googleはこうした購買体験の変化を、小売業界における次の大きな転換点として位置づけた。</p>
<h2>中核となるオープン標準「Universal Commerce Protocol」</h2>
<p>UCPは、AIエージェント時代の商取引を支える共通基盤として設計されたオープンプロトコルだ。
AIエージェント、EC事業者、決済サービス、プラットフォームが個別に連携する従来型の構成ではなく、共通の仕様を介して相互運用できることを目的としている。</p>
<p><strong>■ Universal Commerce Protocol（UCP）の構成概要</strong> ：消費者向けAIサーフェス（検索やGemini）と、小売・決済などの業務バックエンドを、共通プロトコルで接続する。商品探索、カート、チェックアウト、注文といった機能をモジュール化し、AIエージェント時代の商取引を支える。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/UCP_Diagram_Detailed_1_original_9904d1d1ab/UCP_Diagram_Detailed_1_original_9904d1d1ab.png" alt="UCP_Diagram_Detailed_1.original.png" /></p>
<p>Googleによると、UCPは既存のモデル連携プロトコルやエージェント間通信の考え方とも親和性を持ち、オープンソースとして公開される。これにより、小売事業者やプラットフォームは、特定のAIやサービスに依存せず、エージェンティックコマースへの対応を進めることが可能になるという。</p>
<h2>検索とGeminiでの直接購入体験を支える基盤に</h2>
<p>UCPは、Google検索のAI Modeや、生成AI「Gemini」を通じた新しい購買体験の基盤としても活用される。</p>
<p><strong>■ Google検索から購入完了までのエージェンティックコマース体験例</strong> : AIエージェントとの対話を通じて商品を確認し、そのままチェックアウトまで完結する。UCPは、こうした検索起点の直接購入体験を支える基盤として機能する。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/triptych_alt_original_aa3f1e380e/triptych_alt_original_aa3f1e380e.jpg" alt="triptych-alt.original.jpg" /></p>
<p>利用者はAIエージェントとの対話を通じて商品を比較・検討し、そのまま購入まで進むことが可能になる設計だ。Googleは、こうした体験を自社サービスに閉じたものではなく、業界全体に開かれた形で展開する姿勢を強調している。</p>
<h2>小売事業者向けのAIツール群もあわせて提供</h2>
<p>GoogleはUCPと並行して、小売事業者向けのAIツールも発表した。検索上でブランドと対話できる「Business Agent」をはじめ、AIエージェントが商品情報や条件を正確に理解するためのデータ拡張、Google AdsやCommerce製品との連携機能などが含まれる。</p>
<p>これらの機能は、まず米国の一部小売事業者から段階的に提供される予定としている。</p>
<h2>検索・広告・ECを横断する再設計</h2>
<p>今回の発表は、単一の新製品や機能にとどまらず、検索、広告、コマースをAIエージェント前提で再設計するGoogleの方向性を示すものとなった。</p>
<p>Googleは、UCPを軸としたオープンなエコシステムを通じて、AIが購買の主体となる時代における小売体験の基盤づくりを進めるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>『女性をビキニに』指示が問題化、XのAI画像生成・編集機能が有料会員限定に</title>
      <link>https://ledge.ai/articles/grok_bikini_image_generation_paid_only</link>
      <description><![CDATA[<p>「@Grok 女性をビキニにして」などの指示による画像生成が物議を醸していた、XのAI画像生成・編集機能について、X上での利用が有料会員に限定されていることが、2026年1月9日ごろから確認されている。この仕様変更は<a href="https://www.reuters.com/sustainability/boards-policy-regulation/musks-ai-bot-grok-limits-image-generation-x-paid-users-after-backlash-2026-01-09/">Reuters</a>など複数の国内外メディアが報じている。</p>
<p>対象となっているのは、GrokをX上でメンションし、返信欄から画像生成や編集を依頼する機能だ。現在、無料ユーザーが同様の操作を行うと、「画像の生成と編集は現在、有料会員限定です」といったメッセージが表示され、リプライ形式での画像生成・編集は実質的に利用できなくなっている。</p>
<h2>X上の「@Grok」経由のみが制限対象</h2>
<p>複数の報道やユーザー検証によると、今回の制限はGrokの画像生成・編集機能そのものを全面的に停止したものではない。
実際には、以下のような状態が確認されている。</p>
<ul>
<li>Xの返信欄で「@Grok」をメンションして画像生成・編集を依頼する方法は、無料会員ではブロック</li>
<li>一方で、Grokのスタンドアロン版アプリやウェブ版（grok.x.ai）では、無料ユーザーでも画像生成・編集が可能な状態が続いている</li>
<li>Xアプリやウェブ上で画像を直接操作する一部の編集機能についても、無料で利用できるケースが報告されている</li>
</ul>
<p>このため、現時点での変更は「X上のリプライ経由の画像生成・編集のみを有料限定とした」措置とみられている。</p>
<h2>背景に非同意の性的画像生成問題</h2>
<p>今回の仕様変更の背景として、海外メディアは、非同意による性的画像生成の急増を挙げている。
昨年末から年始にかけて、他人の写真を無断で加工し、衣服を除去したり、性的に強調した画像を生成するいわゆる「デジタル脱衣」型のディープフェイクが拡散。女性や未成年を対象とした事例も問題視された。</p>
<p>こうした状況を受け、英国やEU、インドなどで規制当局や政府関係者が懸念を示しており、Reutersなどは、国際的な批判や規制圧力が今回の制限につながった可能性を報じている。</p>
<p>XおよびGrokを開発するxAIは、現時点でこの仕様変更について正式なリリースや詳細な説明を公表していない。
今回の有料化措置については、無料での悪用が難しくなった点を評価する声がある一方、抜け道が残っており根本的な対策とは言えないとする批判も出ていると、複数メディアは伝えている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>「写真が勝手にビキニ化」AI「Grok」画像編集が炎上──未成年を含む生成も焦点に、各国で規制圧力</title>
      <link>https://ledge.ai/articles/grok_image_editing_nonconsensual_sexualized_images</link>
      <description><![CDATA[<p>2025年の年末から2026年の年始にかけ、米実業家イーロン・マスク氏が設立したAI開発企業 xAI が提供するAI「Grok」をめぐり、実在の人物の写真が本人の同意なく加工され、性的に見える画像としてSNS「X（旧Twitter）」上で拡散する事例が相次いだ。年末年始のタイミングで海外メディアが一斉に報じ、国際的な問題として注目を集めた。</p>
<p><a href="https://www.reuters.com/technology/french-ministers-report-groks-sex-related-content-x-platform-prosecutors-2026-01-02/">Reuters</a> は2026年1月3日（現地時間）、年越し前後にX上でGrokの画像編集機能を用いた投稿が急増したと報道した。他人が投稿した写真に対し、テキストで指示を与えることで人物の服装を変更し、ビキニ姿など性的に見える形へ加工した画像が生成され、公開リプライなどを通じて広く拡散したという。</p>
<p>こうした投稿は特定の著名人に限らず、一般の女性や若年層とみられる人物の写真にも及んだ。生成された画像はX上で即座に表示され、年末年始の利用増加と相まって、短期間のうちに問題が可視化・拡大したとされる。</p>
<p>英紙<a href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">The Guardian</a>もこの問題を取り上げた。同紙は、Grokによって未成年を含む人物が「薄着」の状態に加工される画像が生成された事例が確認されたと報じ、非同意の性的表現や児童保護の観点から懸念が高まっていると伝えた。</p>
<p><strong>xAIはGrokをめぐり、安全対策の不備を認め、CSAMは違法で禁止されているとX上で表明した</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_x_9767524026/grok_x_9767524026.jpg" alt="grok x.jpg" /></p>
<p>事態の深刻化を受け、フランスでは年始早々、閣僚がGrokによる性的コンテンツ生成を問題視し、検察当局に通報した。Reutersは、欧州連合（EU）のデジタルサービス法（DSA）との関係も含め、AIを組み込んだプラットフォームの責任を問う動きが各国で強まっていると報じている。</p>
<p>Grokを提供するxAI側は、安全対策に不備があったことを認め、是正措置を進めているとされる。一方、画像編集を含む生成AI機能が急速に一般ユーザーへ開放される中、年末年始に顕在化した今回の問題は、非同意の加工や悪用をどこまで防げるのかという課題を改めて浮き彫りにした。</p>
<p>こうした海外での一連の報道を受け、日本国内でも年末年始にかけてこの問題が紹介され、生成AIの利便性とリスクをめぐる議論が広がった。年の変わり目に一気に表面化したGrokをめぐる騒動は、生成AIとSNSが結びつくことで生じる影響の大きさを示す事例となっている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Google検索の「AIによる概要」、健康関連クエリで一部非表示に―—英ガーディアン調査で判明</title>
      <link>https://ledge.ai/articles/guardian_google_ai_overviews_health_queries_hidden</link>
      <description><![CDATA[<p>Google検索に表示される「AIによる概要（AI Overviews）」が、健康・医療関連の検索クエリにおいて誤解を招く情報を提供していたことが、2026年1月26日の<a href="https://www.theguardian.com/technology/2026/jan/11/google-ai-overviews-health-guardian-investigation">英紙ガーディアンの調査</a>で明らかになった。これを受け、Googleは一部の検索結果で同機能を非表示にしている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/the_guardian_9ac7ce5634/the_guardian_9ac7ce5634.jpg" alt="the guardian.jpg" /></p>
<h2>Google検索の「AIによる概要」とは</h2>
<p>「AIによる概要」は、検索クエリに対してAIが複数の情報源をもとに要点を要約し、検索結果ページの上部に表示する機能だ。通常の検索結果リンクよりも上位に表示されることから、検索体験の効率化を目的として導入されている。</p>
<p>一方で、表示位置の特性上、内容が利用者の判断に与える影響が大きい点も指摘されてきた。</p>
<h2>健康関連クエリで指摘された問題</h2>
<p>調査報道でガーディアンは、Googleの「AIによる概要」が健康・医療分野の検索クエリにおいて、不正確または文脈を欠いた情報を提示している事例があると報じた。</p>
<p>同紙によると、疾患や検査値に関する説明が一般化されすぎており、年齢や既往歴などの前提条件を十分に考慮していないケースが確認されたという。こうした要約が検索結果の最上部に表示されることで、利用者が内容を過度に信頼し、誤った自己判断につながる可能性がある点が問題視された。</p>
<p>ガーディアンは、医療情報のように解釈に専門性が求められる分野では、AIによる要約が誤解やリスクを生む恐れがあると伝えている。</p>
<h2>Googleの対応</h2>
<p>この報道を受け、米テックメディア The Vergeは、Googleが一部の健康・医療関連検索クエリについて「AIによる概要」の表示を停止していると報じた。</p>
<p>The Vergeによると、該当する検索では従来どおり検索結果リンクは表示される一方、AIによる要約のみが表示されない状態になっているという。Googleは、医療分野のようなセンシティブな領域では、情報の正確性と安全性を重視した対応を取っているとされる。</p>
<p>同メディアは、今回の措置がすべての健康関連クエリに一律で適用されているわけではなく、限定的な対応である点にも言及している。</p>
<h2>背景</h2>
<p>医療・健康分野は、検索エンジンにおいて利用者の生活や生命に直接影響を与え得る情報を扱う領域とされている。AIによる要約は利便性を高める一方、情報の切り取り方次第で誤解を招くリスクを内包している。</p>
<h2>今後の焦点</h2>
<p>今後は、健康・医療といった高リスク分野において、AI要約をどの範囲で表示するのか、また品質管理や表示基準をどのように設計するのかが焦点となる。Google検索におけるAI活用のあり方が、引き続き注目される。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2026/1/16 [FRI]AIの進化を支え続けるNVIDIA　グラフィックス企業からAIインフラの巨人への軌跡</title>
      <link>https://ledge.ai/articles/interview_nvidia</link>
      <description><![CDATA[<p>現在の生成AIブームを、NVIDIAの存在を抜きに語ることはできないだろう。同社のGPUはAIモデルの学習と推論を支える心臓部となり、その圧倒的な市場シェアは、単なる半導体メーカーという枠を超えた、巨大な影響力を物語っている。しかし、その成功は単一の技術的勝利ではなく、2006年のCUDAに始まり、現在に至るまで一貫して貫かれる「開発者中心のプラットフォーム戦略」という強固な哲学の結晶である。</p>
<p>今回、その軌跡を紐解くために話を伺ったのは、NVIDIAでテクニカルマーケティング マネージャーを務める澤井理紀氏だ。同社に15年間在籍し、グラフィックスが事業の中心であった時代から、AIへの歴史的な大変革を社内で目撃してきた。彼の言葉から、NVIDIAがAI時代の覇者となり得た必然性を探る。</p>
<p>※インタビューは2025年11月26日にエヌビディア合同会社の会議室で行われた。</p>
<h2>「偶然」ではないAIへの転換。すべては開発者コミュニティから始まった</h2>
<p>NVIDIAの今日の成功を理解するためには、同社がAIブームの遥か以前から、いかに戦略的な布石を打ってきたかを振り返ることが不可欠だ。その軌跡は、偶然の産物ではなく、開発者コミュニティの声に真摯に耳を傾け、未来への投資を続けた結果であった。</p>
<h3>グラフィックスから汎用計算へ：研究者たちの「ハック」が示した新たな可能性</h3>
<p>NVIDIAの歴史は、1999年に発表したGPU（Graphics Processing Unit）から本格的に始まる。当初、その用途はゲームや3D CGといったグラフィックス処理に限定されていた。しかし2000年代初頭、一部の科学技術計算の研究者たちの間で、グラフィックス描画用のAPIをいわば「ハック」する形で、自身の研究における膨大な並列計算にGPUを応用する動きが生まれたのだ。</p>
<p>澤井氏は当時をこう振り返る。「グラフィックス用のAPIを無理やり自分の計算に当てて動かす、というハックのような動きがありました。我々はそうした研究者の動きをちゃんと理解していて、グラフィックス以外にもGPUのニーズがあるということに目をつけたのです」。この開発者コミュニティの小さな、しかし熱量の高い動きこそが、NVIDIAの運命を大きく変える最初の兆候だったのである。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image2_v2_330ed396a8/image2_v2_330ed396a8.jpg" alt="image2_v2.jpg" /></p>
<h3>決定的な一手「CUDA」の誕生とエコシステムの構築</h3>
<p>その新たな可能性に応えるべく、NVIDIAは2006年に歴史的な一手「NVIDIA CUDA」を発表する。これは、GPUをグラフィックス以外の汎用的な並列計算に利用するための統合開発環境であり、同社の歴史における極めて重要な戦略的転換点となった。</p>
<p>CUDAが画期的だったのは、C言語ベースのプログラミング言語やコンパイラ、デバッガといった開発に必要なツール一式を提供したことだ。これにより、それまで一部の研究者の「ハック」に過ぎなかったGPUの汎用計算が、公式にサポートされるようになった。澤井氏は、「CUDAを使えば、スーパーコンピューターでなくても、手元のPCで科学計算を動かすことができた」と語る。高価なスパコンを必要とせず、誰もが購入できるコンシューマー向けGPU「NVIDIA GeForce」で高度な並列計算が実行できるようになったことで、世界中の研究者や開発者がNVIDIAのプラットフォームに集結した。これが、今日まで続く巨大な開発者エコシステムの礎となったのである。</p>
<h3>AlexNetの衝撃とジェンスン・フアンCEOの強力なリーダーシップ</h3>
<p>CUDAによって築かれた土壌の上で、AIという新たな芽が育ち始める。その萌芽は2011年に見られた。NVIDIAの研究者が、スタンフォード大学と共同で、わずか12基のGPUを使い、Googleが2000台のCPUで実現した猫の顔認識プロジェクト「Google Brain」と同等の成果を叩き出したのだ。</p>
<p>そして翌年、その可能性は決定的な形で証明される。画像認識の国際コンテスト「ILSVRC」において、トロント大学のジェフリー・ヒントン教授の研究室に所属していたアレックス・クリジェフスキー氏が開発した「AlexNet」が、2枚のコンシューマー向けGPUを駆使して他のチームを圧倒的な精度で打ち破り、優勝したのだ。この出来事は、ディープラーニングのブレークスルーとして歴史に刻まれ、GPUがAI研究のデファクトスタンダードとなる引火点となった。</p>
<p>この好機を逃さなかったのが、創業者/CEOのジェンスン・フアン氏だ。澤井氏によれば、フアン氏はAlexNetの衝撃を受け、「これからはソフトウェアがソフトウェアを作る機械学習の時代が来る」と確信し、会社全体の舵をAIへと大きく切っていった。ここに、NVIDIAを単なる高性能チップメーカーからAI時代の覇者へと押し上げた、ジェンスン・フアン氏の経営者としての真骨頂が見える。</p>
<p>研究者の「ハック」から始まり、CUDAによるエコシステムの構築、そしてAIの可能性を確信した経営陣の強力なリーダーシップへ。NVIDIAの過去の歩みは、一貫して「開発者中心のプラットフォーム戦略」に貫かれている。こうして築かれたAIにおける圧倒的優位性も、半導体技術の物理的限界という新たな壁に直面する。NVIDIAは、過去の成功方程式であった「チップ性能の向上」から、より包括的な戦略へと舵を切る必要に迫られたのだ。</p>
<h2>チップ性能の先へ。プラットフォーム全体で最適化する「Co-design」戦略</h2>
<p>半導体のプロセス微細化といった単一の指標だけでは、NVIDIAの現在の競争優位性を測ることはできない。同社の真の強みは、ハードウェアの性能を極限まで引き出すための、より包括的なアプローチ「Co-design」戦略にある。</p>
<p>「いわゆるムーアの法則は終焉に近づいています」と澤井氏は指摘する。かつてのように、プロセス微細化だけで劇的な性能向上が見込める時代は終わった。この課題に対し、NVIDIAはアルゴリズムからソフトウェア、GPUアーキテクチャ、システム、そしてデータセンター全体に至るまでを統合的に設計する「Co-design」というアプローチで応えている。</p>
<p>その象徴的な例が、最新のBlackwellアーキテクチャだ。驚くべきことに、Blackwell世代のGPUは、前世代のHopperと同じ半導体プロセスで製造されている。しかし、澤井氏によれば、「プラットフォームを刷新することで、Hopperの10倍の電力効率を実現」しているという。これは、プロセス微細化に依存せず、システム全体の最適化によって性能の壁を突破できることを証明している。この「Co-design」は、かつてCUDAでソフトウェアとハードウェアを統合し開発者エコシステムを築いた成功体験の、現代における正統進化と言えるだろう。</p>
<h3>量子コンピュータとフィジカルAIへの貢献</h3>
<p>NVIDIAの戦略の根底には、「エンドプロダクトを自社で作るのではなく、それらを開発する人々を支援するプラットフォームを提供する」という一貫した哲学がある。澤井氏はこれを自動車業界に例えて説明する。</p>
<p>「我々は自動運転技術を開発していますが、自社で車は作っていません。自動車メーカーの開発を支援しているのです。それと同じように、量子コンピュータ自体は作りません。量子コンピュータを作りたい人の計算を加速するのです」</p>
<p>この思想は、同社が設立した「NVAQC (NVIDIA Accelerated Quantum Research Center)」にも表れている。NVIDIAは自ら量子コンピュータを開発するのではなく、既存のAIスーパーコンピュータ上で量子コンピュータの研究開発をシミュレーションし、加速させる役割を担う。</p>
<p>同様のアプローチは、ロボティクスや自動運転といった「フィジカルAI」の分野でも貫かれている。シミュレーションプラットフォームである「NVIDIA Omniverse」や「NVIDIA Isaac Sim」、エッジデバイス用の「NVIDIA Jetson」などを提供し、産業全体の進化を支援する。あくまで黒子に徹し、あらゆるイノベーターたちのためのインフラとなることが、NVIDIAの戦略の核なのだ。</p>
<p>AIへの長期的な投資は、今や明確な成果となって表れている。2020年の第2四半期には、データセンター部門の売上が、長年同社の屋台骨であったゲーミング部門を初めて逆転。これは、NVIDIAが名実ともにAIインフラ企業へと変貌を遂げた象徴的な出来事だった。しかし、社内でこのマイルストーンが盛大に祝われることはなかったという。なぜなら、データセンター部門の目標は「ゲーミング部門を超えることではなく、とんでもなく大きな目標があったから」だ。このエピソードは、NVIDIAが当時から既に、過去の事業を遥かに超える未来を見据えていたことを物語っている。</p>
<p>その注力領域は、今やロボティクスや自動運転といった花形分野にとどまらない。澤井氏は、「ヘルスケアやテレコムといった領域にも全方位で注力している」と語る。特定の産業に偏ることなく、あらゆるバーティカル市場でAI活用を推進する姿勢は、同社のプラットフォーム戦略がいかに広範な応用可能性を持つかを示している。</p>
<p>チップ性能の追求から、システム全体を最適化するプラットフォーム戦略へ。NVIDIAの現在の姿は、開発者中心という哲学を現代的に昇華させたものだ。現在のプラットフォーム戦略は、単に今日のAIを動かすに留まらない。それは、量子やフィジカルAIといった「まだ見ぬ未来」のイノベーションすらも自社のエコシステムに取り込むための、壮大な布石なのである。NVIDIAの視線は、もはや現在のAIの先、次なる産業革命の基盤そのものに向けられている。</p>
<h2>AIは「バブル」ではない、「始まり」に過ぎない</h2>
<p>市場の一部では、現在の熱狂を「AIバブル」と懸念する声も囁かれる。しかし、インフラの最前線から未来を見据えるNVIDIAにとって、今はバブルどころか、壮大な物語の「始まり」に過ぎない。</p>
<h3>金融市場と技術進化の切り分け</h3>
<p>「AIバブル」という言葉について、澤井氏は冷静な視点を示す。「金融的な評価がバブルかどうかは分かりません。しかし、AIという技術自体がバブルではないことには、全く疑いの余地がありません」。これは、市場の短期的な評価と、社会に不可逆的な変化をもたらす基盤技術の進化とは、明確に切り分けて考えるべきだというNVIDIAの姿勢を物語っている。AIが社会に浸透し、当たり前に使われる未来は揺るぎないという確信がそこにはある。</p>
<h3>新たな産業革命「AIファクトリー」構想</h3>
<p>ジェンスン・フアンCEOは、AIがもたらす未来を「AIファクトリー」というビジョンで表現している。これは、データセンターが単なる計算施設ではなく、データを原材料として「知能」を生成する工場へと変貌するという構想だ。あらゆる企業が、自社の日々の業務データを「AIファクトリー」に入力し、そこから生み出されたインテリジェンス（知能）を活用して事業を革新していく。NVIDIAは、AIを一時的なブームではなく、社会基盤そのものを根底から作り変える、新たな産業革命と捉えているのだ。</p>
<h3>変わらぬ原点：すべての開発者のために</h3>
<p>企業規模が拡大し、巨大テック企業との取引が増える中で、「NVIDIAはもはや大企業だけを相手にするのではないか」という声も聞かれる。この問いに対し、澤井氏の答えは明確だ。NVIDIAのDNAは、創業以来変わっていない。</p>
<p>「2006年にCUDAを作った時も、ハイパフォーマンスコンピューティング用のGPUに限定せず、コンシューマー向けのGeForceでも動くようにしました。それによって開発者が手軽に利用できるようになったのです。我々はそのことを覚えています」</p>
<p>大規模なデータセンターから個人のPCに至るまで、あらゆる規模の「開発者をサポートする」という姿勢こそが、NVIDIAの揺るぎない原点であり、強固なエコシステムを維持し続ける力の源泉なのだ。この哲学は今後も変わることはない。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/image4_v2_0fa05944cd/image4_v2_0fa05944cd.png" alt="image4_v2.png" /></p>
<h3>次のブレークスルーとNVIDIAの役割</h3>
<p>現在主流のTransformerモデルの次に来る、革新的な技術は何だろうか。この問いに対し、澤井氏は「それは誰にも分かりません」と率直に認める。未来の不確実性を受け入れた上で、彼はNVIDIAの使命をこう語る。</p>
<p>「我々の役割は、AIの進化に向けて、どのような技術が登場しても対応できる、最先端のプラットフォームを構築し続けることです」</p>
<p>特定のアルゴリズムに賭けるのではなく、あらゆるイノベーションが花開くための最高の土壌を用意し続けること。それこそが、AIインフラの巨人としてNVIDIAが自らに課した役割なのである。</p>
<p>AIの概念が生まれて70年。我々は今、新たな産業革命の入り口に立っている。その不確実で、しかし可能性に満ちた未来に向かっていく上で、これからもNVIDIAが支える技術進化に期待したい。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>アイスタイル、「@cosme Copilot」を発表　クチコミをAIで解析するSaaS型分析ツール</title>
      <link>https://ledge.ai/articles/istyle_cosme_copilot_ai_analysis</link>
      <description><![CDATA[<p>美容系総合サイト「@cosme（アットコスメ）」を運営する株式会社アイスタイルは2026年1月7日、@cosmeに投稿されたクチコミデータをAIで解析するSaaS型の次世代分析ツール「@cosme Copilot」を<a href="https://www.istyle.co.jp/news/press/2026/01/0107.html">発表</a>した。</p>
<p>「@cosme Copilot」は、@cosmeに登録された商品のうち、1件以上のクチコミが投稿されている商品を対象に、2014年以降のクチコミデータを分析できるツールだ。自ブランドの現状分析やマーケティング施策の振り返り、商品開発、競合比較などへの活用を想定している。</p>
<p>同ツールは、クチコミ分析に特化したAI分析ツールとして設計されており、@cosmeに投稿された美容ユーザーの声をAIが解析。商品評価の傾向やターゲット属性、消費者インサイトを可視化し、意思決定を支えるデータを迅速に提供する。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/9cfcb1236f82d1a9059ea176a742d8a9572cd42f_thumb_850x287_16207_897771cb51/9cfcb1236f82d1a9059ea176a742d8a9572cd42f_thumb_850x287_16207_897771cb51.png" alt="9cfcb1236f82d1a9059ea176a742d8a9572cd42f-thumb-850x287-16207.png" /></p>
<p>アイスタイルによると、「@cosme Copilot」は2025年春にパイロット版を提供開始。グループ会社であるアイスタイルデータコンサルティングが提供するデータコンサルティングサービスを利用するブランドを中心に導入され、使用感に関するヒアリングを通じて機能のアップデートや改修を重ねてきた。今回の正式リリースにより、全てのブランドが利用可能となる。</p>
<p>主な機能として、クチコミの投稿日や投稿者の年齢、職業、性別、肌質タイプなど多様な条件での検索に加え、絞り込んだ大量のクチコミデータをAIが要約する機能を搭載する。これまで手作業で行われていたクチコミ収集や分析作業を短時間で実行できるという。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/d9e1503cba9dd3ab5c008971e6f592ff55594ac4_thumb_850x265_16210_af4e6ce3cb/d9e1503cba9dd3ab5c008971e6f592ff55594ac4_thumb_850x265_16210_af4e6ce3cb.png" alt="d9e1503cba9dd3ab5c008971e6f592ff55594ac4-thumb-850x265-16210.png" /></p>
<p>また、クチコミに含まれる頻出キーワードや共起ワードの可視化、ポジティブ・ネガティブな内容の割合の数値化、時系列での分析も可能だ。商品に対する評価傾向だけでなく、キャンペーン施策への反応など、マーケティング視点での分析にも対応する。</p>
<p>さらに、膨大なクチコミデータをもとに商品のターゲットとなるペルソナを作成する機能も備える。生成したペルソナに対し、「シャンプーで重視する項目は何か」といった質問をチャット形式で行うことができ、回答の根拠となったクチコミも即座に参照できる。</p>
<p>アイスタイルは、AIによるクチコミ分析で得られた気づきや仮説を、@cosmeやECの@cosme SHOPPING、実店舗の@cosme STOREの運営を通じて蓄積してきた顧客データと統合したデータ基盤（CDP）と組み合わせ、マーケティング戦略やCRM施策、商品開発へとつなげるデータコンサルティングサービスも強化するとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft、Copilotから直接購入できる「Copilot Checkout」発表　ブランド専用AI接客「Brand Agents」も同時公開</title>
      <link>https://ledge.ai/articles/microsoft_copilot_checkout_brand_agents</link>
      <description><![CDATA[<p>Microsoftは2026年1月8日（米国時間）、AIアシスタント「Copilot」上で商品選定から購入・決済までを完結できる新機能「Copilot Checkout」を<a href="https://about.ads.microsoft.com/en/blog/post/january-2026/conversations-that-convert-copilot-checkout-and-brand-agents">発表</a>した。あわせて、ブランドや小売事業者が自社専用のAI接客を構築できる「Brand Agents」も公開した。</p>
<p>同社は、ユーザーの購買行動において「興味を持つ」段階から「購入を決断する」までの距離が急速に縮まっているとし、検索やサイト遷移を前提としない会話中心の購買体験を提示している。</p>
<h2>Copilotの会話画面がそのまま購入フローに</h2>
<p>@<a href="https://www.youtube.com/watch?v=6X6WOP7_U4Q">YouTube</a></p>
<p>Copilot Checkoutは、Copilotとの自然な対話の中で、商品提案、比較、購入判断、決済までを一貫して行える機能だ。ユーザーは外部のECサイトへ遷移することなく、Copilot上で購入を完了できる。</p>
<p>Microsoftは、ユーザーが質問を投げかけ、条件を整理し、選択肢を比較しながら意思決定に至る一連のプロセスが、単一のインタラクション内で完結する点を特徴として挙げる。従来であれば複数のタブを開き、比較の途中で購入が中断されることも多かったが、Copilot Checkoutでは会話の流れそのものが購買導線となる。</p>
<h2>販売者は取引主体を維持、顧客データも保持</h2>
<p>Copilot Checkoutでは、販売者が引き続き取引主体（merchant of record）となる。Microsoftによると、販売者はトランザクション、顧客データ、顧客との関係性を自社で保持できる。</p>
<p>決済やチェックアウトは、PayPal、Stripe、Shopifyといった既存のコマース基盤と連携して提供される。Shopifyを利用する販売者は、特別な申請や追加の統合を行うことなく、自動的にCopilot Checkoutに対応する。</p>
<p>PayPalのエージェンティックコマース担当VP、マイク・エドモンズ氏は、「Copilotの信頼されたコマース基盤を通じて、数千万規模の販売者がAI時代に対応できる」とコメントしている。</p>
<h2>初期データでは購入率向上を確認</h2>
<p>Microsoftが示した初期データによると、Copilotが関与した購買導線では、以下の傾向が確認されている。</p>
<ul>
<li>Copilotを含む購買体験は、含まない場合と比べ、30分以内の購入数が53％多い</li>
<li>購入意図があるユーザーでは、Copilotを利用した場合、購入に至る可能性が194％高い</li>
</ul>
<p>Copilot Checkoutは、米国においてCopilot.comから段階的に提供が始まっており、BingやMSN、EdgeなどCopilotエコシステム全体への展開も予定されている。</p>
<h2>ブランド独自の接客をAIで再現する「Brand Agents」</h2>
<p>Brand Agentsは、ブランドや小売事業者が自社のトーンや商品知識を反映したAIショッピングアシスタントを構築できる仕組みだ。実店舗における販売員の役割をオンライン上で再現することを想定している。</p>
<p>顧客の質問に対し、ブランドの言葉遣いで応答し、適切なフォローアップ質問を行いながら商品提案や比較を進める。フィルター操作やメニュー選択を強制せず、会話を通じて自然に購買判断へ導く点が特徴とされる。</p>
<h2>Brand Agents導入による効果測定と分析</h2>
<p>@<a href="https://www.youtube.com/watch?v=wg2g-KRo5jk">YouTube</a></p>
<p>Microsoftによると、Brand Agentsを導入した販売者では、エージェントが関与したセッションの方が、関与しない場合と比べて高いエンゲージメントとコンバージョンを示している。</p>
<p>プレミアムスリープウェアを展開するAlexander Del Rossaでは、Brand Agentsが関与したセッションで、非関与セッションと比べて3倍以上のコンバージョン率を記録したという。</p>
<p>Brand AgentsはMicrosoftの分析ツール「Microsoft Clarity」と連携し、エージェントが関与したセッションと通常セッションを比較分析できる。ダッシュボードでは、エンゲージメント率、コンバージョン向上、平均注文額などの指標が可視化される。</p>
<h2>Microsoft Clarityと連携した分析機能</h2>
<p>Brand Agentsは、Microsoftの分析ツール「Microsoft Clarity」と連携する。Clarityはヒートマップやセッションリプレイを通じてユーザー行動を可視化する無料ツールで、Brand Agents導入後は、エージェントが関与したセッションと通常セッションの比較分析も可能になる。</p>
<p><strong>Brand Agentsの効果を可視化するMicrosoft Clarityの分析画面。エージェントが関与したセッションにおけるエンゲージメントやコンバージョン指標を確認できる</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/blog_79982_bodyimage02_833x478_be75122127/blog_79982_bodyimage02_833x478_be75122127.webp" alt="blog-79982-bodyimage02-833x478.webp" /></p>
<p>ダッシュボードでは、エンゲージメント率、コンバージョン向上、平均注文額などの指標を確認でき、販売戦略の改善に活用できるとしている。</p>
<h2>導入と今後の展開</h2>
<p>Copilot Checkoutでは、Microsoft Merchant Centerの活用により、Copilot上での商品露出を最適化できる。Microsoftは、Agentic Commerce Protocol（ACP）といったオープンスタンダードの採用を進め、導入の簡素化とスケーラビリティを図る。</p>
<p>今後はMastercardやVisaといった決済事業者とも連携し、AIを前提としたコマース基盤の拡張を進めるとしている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>日本テレ自社開発のオンデバイスAI「viztrick AiDi」、NBC Sportsでライブ中継への採用が決定</title>
      <link>https://ledge.ai/articles/ntv_viztrick_aidi_nbc_sports_live_adoption</link>
      <description><![CDATA[<p>日本テレビ放送網株式会社は、自社開発した直感的オンデバイスAIソリューション「viztrick AiDi」が、米国の大手スポーツ放送ネットワークであるNBC Sportsに採用されたと<a href="https://tech.ntv.co.jp/news/nbc-sports-release/">発表</a>した。2026年以降、NBC Sportsが手がける複数のライブスポーツ中継での利用が予定されている。</p>
<p>「viztrick AiDi」は、放送現場での実運用を前提に設計されたオンデバイス型AIソリューションで、ネットワーク接続に依存せず、低遅延でリアルタイム処理を行える点を特徴とする。ライブ映像から被写体となる選手を自動で抽出・追従し、スマートフォン視聴を想定した縦型（9:16）映像として即時に切り出すことが可能だ。</p>
<p>近年、スポーツコンテンツの視聴はテレビ放送に加え、スマートフォンを中心としたデジタル配信が急速に拡大している。NBC Sportsでは、モバイル視聴に最適化された映像を効率的に制作する手法を模索しており、従来は人手によるカメラ操作や編集作業が必要だった。こうした課題に対し、放送現場で即応できる「viztrick AiDi」のオンデバイス処理と直感的な操作性が評価され、採用に至ったとしている。</p>
<p>NBC Sportsの技術部門シニア・バイスプレジデントであるティム・カナリー氏は、ライブスポーツのストリーミング配信において、アスリートを自動追従しながら縦型映像をリアルタイムで生成できる点を重視したとコメントしている。特に、低遅延で安定した処理が可能な点が、ライブ中継用途に適していると判断したという。</p>
<p>日本テレビ側は、世界有数のスポーツ放送事業者であるNBC Sportsに技術が採用されたことを、グローバル展開に向けた重要な実績と位置付けている。同社は中期経営計画（2025〜2027）で「グローバルコンテンツ企業への変革」を掲げており、海外戦略センター内に設置したTech事業部門を通じて、放送現場発のAI技術を海外市場へ展開していく方針だ。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>OpenAIとソフトバンクグループ、SB Energyに10億ドル投資──「Stargate」構想 1.2GW級データセンター建設を加速</title>
      <link>https://ledge.ai/articles/openai_softbank_sb_energy_stargate_data_center_investment</link>
      <description><![CDATA[<p>OpenAIとソフトバンクグループは2026年1月9日（米太平洋時間）、ソフトバンクグループ傘下の米インフラ企業SB Energyと戦略的パートナーシップを締結し、同社に総額10億ドル（各社5億ドル）を投資すると<a href="https://openai.com/ja-JP/index/stargate-sb-energy-partnership/">発表</a>した。今回の提携は、米国における次世代AI・エネルギー基盤の構築を目的とする「Stargate」構想の一環と位置づけられている。</p>
<p>OpenAIは同社を、テキサス州ミラム郡に計画されている1.2GW規模のデータセンターサイトの建設・運営パートナーに選定。OpenAIはこの初期データセンター構築に向け、1.2GW分のデータセンターリース契約を締結している。今回の出資は、SB Energyが大規模データセンターキャンパスおよび関連エネルギーインフラの開発・実行パートナーとして成長することを支援する狙いがある。</p>
<p>SB Energyは現在、複数のマルチギガワット級データセンターキャンパスを開発中で、最初の施設はすでに建設段階にあり、2026年から順次稼働を開始する予定だという。今回の取り組みは、ホワイトハウスで1月に発表された5,000億ドル規模の「Stargate」コミットメントを基盤とするものだ。</p>
<p>今回の取引の一環として、OpenAI、ソフトバンクグループ、SB Energyの3社は、非独占の優先パートナーシップも締結した。OpenAIの自社設計によるデータセンターと、SB Energyのスピード、コスト管理、統合型エネルギー供給の知見を組み合わせ、AI専用インフラを大規模に構築する新たなモデルの開発を目指すとしている。SB Energyは各プロジェクトを通じて、雇用創出や人材育成、送電網の近代化など、地域社会への投資も行う方針だ。</p>
<p>またSB Energyは、データセンター事業の成長を支えるため、データセンター建設管理・調達・設計・運用を手がけるStudio 151を買収した。20以上のデータセンターキャンパスで実績を持つ同社を取り込むことで、開発から運用までの内製能力を強化する。</p>
<p>なお、SB Energyは2025年に、米投資会社Aresから8億ドルの償還可能優先株式による出資を受けており、今回の投資はAresとの長期的な関係をさらに深めるものだとしている。</p>
<p>今回の投資と提携は、AIモデルの開発競争そのものではなく、大規模な計算資源を支える電力・用地・建設能力を含めた「AIインフラ」を確保する動きとして位置づけられる。</p>
<p>Stargate構想のもと、OpenAIとソフトバンクグループは、計算基盤の主導権を中長期で握る体制づくりを進めている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告</title>
      <link>https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy</link>
      <description><![CDATA[<p>Googleの研究者らは、同一の質問文を2回連結して入力するだけで、大規模言語モデル（LLM）の回答精度が向上するとする研究成果を発表した。論文は短報「Prompt Repetition Improves Non-Reasoning LLMs」として2025年12月17日に arXivに<a href="https://arxiv.org/abs/2512.14982v1">公開</a>されており、推論（reasoning）を用いない設定において、主要LLMと複数のベンチマークで広範な改善が観測されたという。</p>
<h2>質問文を「そのまま2回」繰り返すだけ</h2>
<p>研究で提案された手法は、質問文を変更・補足するのではなく、同一のクエリをそのまま2回連結して入力するというものだ。例えば、通常はQと入力するところをQQとする。特別な指示文や追加のプロンプト設計は必要としない。論文では、この操作を \u003CQUERY\u003E を \u003CQUERY\u003E\u003CQUERY\u003E に変換するものとして説明している</p>
<p>LLMは因果言語モデルとして学習されており、トークンの並び順が注意（attention）の届き方に影響する。このため、質問文と文脈や選択肢の配置順（question-first / options-first）によって性能差が生じることが知られている。プロンプト反復は、各トークンが他のすべてのトークンを参照しやすくすることで、この差を緩和すると説明されている。</p>
<h2>非推論設定で顕著な改善、70条件中47で「有意に向上」</h2>
<p>実験は、各AIモデルの公式APIを用いて実施され、2025年2月から3月にかけて評価された。対象には、Gemini、GPT、Claude、DeepSeekといった複数の主要LLMが含まれている。具体的には、Gemini 2.0 Flash／Flash Lite、GPT-4o／GPT-4o-mini、Claude 3 Haiku／Claude 3.7 Sonnet、DeepSeek V3が評価対象となった。</p>
<p>論文では、7つのモデルと7つのベンチマークなどを組み合わせた計70条件で比較を行った。その結果、統計検定（McNemar検定、p\u003C0.1）の基準で47条件において性能が有意に改善し、性能が低下した条件はなかったとしている。</p>
<p><strong>推論を用いない設定におけるPrompt Repetitionとベースラインの精度比較。星印は統計的に有意な改善（p\u003C0.1）を示す。70条件中47で改善、悪化は確認されなかった</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/figure1_big2_202ffaa00c/figure1_big2_202ffaa00c.jpg" alt="figure1_big2.jpg" /></p>
<h2>生成トークン数・レイテンシは原則増えず</h2>
<p>論文では、回答精度が向上した一方で、生成トークン数やレイテンシ（応答時間）は多くの条件で増加しなかったと報告されている。反復は並列化可能なprefill（前処理）段階で完結するためだという。これは、生成プロセスそのものではなく、入力を読み込む段階で処理が完結するためだと説明されている。</p>
<p>ただし例外として、非常に長い入力や反復×3などの条件では、Claude系モデルでprefillが重くなり、レイテンシが増える場合がある点も明記されている。</p>
<h2>推論（step-by-step）を有効にした場合は「中立〜わずかに正」</h2>
<p>推論を促す設定（think step by step）では、プロンプト反復の効果は中立からわずかに正にとどまった。28条件中5勝・1敗・22引き分けで、研究者らは「推論モデルはそもそも推論過程の中で入力の再読・反復を行うため」と説明している。</p>
<p>一方で、入力文が非常に長い場合や、同じ質問を3回以上繰り返す設定では、モデルや条件によっては応答時間が増加する可能性も指摘されている。</p>
<h2>追加学習なしで性能を引き出す可能性</h2>
<p>この手法は、追加学習や外部ツールを必要とせず、出力形式も変えないため、既存システムにドロップインで導入可能だとされる。研究チームはこれを「多くのタスクにおけるデフォルト手法の候補」と位置付けている。研究チームは今後の方向性として、反復部分の最適化やKVキャッシュの扱い、非テキストモダリティへの応用などを挙げている。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
    <item>
      <title>リコー、「文書×AI」を現場仕様に──Qwen2.5-VL-32B基盤、視覚データ60万枚でチューニング</title>
      <link>https://ledge.ai/articles/ricoh_multimodal_llm_qwen25_vl_32b_business_documents</link>
      <description><![CDATA[<p>リコーは2026年1月8日、中国Alibaba Cloudが開発・提供する大規模言語モデル（LLM）ファミリーの「Qwen2.5-VL-32B-Instruct」をベースに、日本企業の図表を含む業務文書の読み取りに対応したマルチモーダル大規模言語モデル（LMM）を開発したと<a href="https://jp.ricoh.com/release/2026/0108_2">発表</a>した。今後、「RICOH オンプレLLMスターターキット」に搭載し、オンプレミス環境での提供を予定している。</p>
<p>開発されたLMMは、文字情報に加え、円グラフ、棒グラフ、フローチャートなど、ビジネス文書で一般的に用いられる視覚情報を同時に理解できる点が特徴だ。企業内に蓄積された文書を対象に、検索にとどまらない高度な利活用を実現することを目的としている。</p>
<h2>顧客フィードバックを反映し、より実務向けの構成に</h2>
<p>リコーは、経済産業省と国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）が推進する生成AI開発力強化プロジェクト「GENIAC（Generative AI Accelerator Challenge）」第2期において、マルチモーダルLLMの開発に取り組み、700億パラメータの基本モデルを無償公開してきた。</p>
<p>今回のLMMは、そうした取り組みの中で得られた顧客からのフィードバックを踏まえ、サービング環境の構築の容易さや利活用のしやすさを重視し、よりコンパクトで高性能、かつアプリケーションとの親和性が高い構成とした点が特徴となる。あわせて、4bit量子化モデルも提供するとしている。</p>
<h2>視覚データ約60万枚を用いた独自チューニング</h2>
<p>同モデルの学習には、リコーが自社で開発したチューニングデータを使用した。文字情報に加え、円グラフ、棒グラフ、フローチャートなど、ビジネス文書で活用される視覚データ約60万枚を用い、LMMに学習させている。</p>
<p>性能評価には、視覚情報とテキスト情報の双方を参照する日本語質問応答データセット「JDocQA」などのベンチマークツールを用いた。その結果、他モデルと比較しても優れた性能を示すことを確認したとしている。評価は2025年12月17日時点の結果に基づく。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/ricoh_qwen2_5vl_b660355681/ricoh_qwen2_5vl_b660355681.jpg" alt="ricoh qwen2-5vl.jpg" /></p>
<h2>企業内文書活用をめぐる課題に対応</h2>
<p>企業内には、請求書や領収書といったトランザクションデータ、経営戦略や事業計画などの経営資料、サービスマニュアルや技術標準、品質管理基準といった技術文書など、多様な形式のドキュメントが蓄積されている。これらにはテキスト情報だけでなく、図表や画像といった視覚情報も含まれる。</p>
<p>一方で、従来の検索手法では意図した情報を十分に引き出せない、検索にとどまった活用に限界があるといった課題が指摘されてきた。加えて、労働力人口の減少、技能・ノウハウ継承、多言語対応といった経営課題が複雑化する中、企業内に蓄積された知識をより高付加価値で活用したいというニーズが高まっている。</p>
<p>リコーは、こうした背景を踏まえ、既存のLLMやLMMでは課題とされてきた、きめ細かな画像認識を必要とするビジネス文書の読解精度に対応するモデルとして、同LMMを位置づけている。</p>
<h2>個別提供に対応、オンプレ環境での展開も視野</h2>
<p>リコーは、同LMMが顧客の要望に応じて個別提供可能としている。今後は「RICOH オンプレLLMスターターキット」に搭載し、リコージャパンから提供する予定だという。同社は画像認識や自然言語処理に加え、音声認識AIの研究開発も進めており、音声対話機能を備えたAIエージェントの提供にも取り組む。</p>
]]></description>
      <pubDate>Wed, 07 May 2025 01:46:44 GMT</pubDate>
    </item>
  </channel>
</rss>