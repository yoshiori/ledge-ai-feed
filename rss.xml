<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai 新着記事</title>
    <link>https://ledge.ai/</link>
    <description>Ledge.ai の最新テクノロジー記事</description>
    <item>
      <title>ロシア・ベラルーシ、伝統価値を守る「愛国AI」を共同開発──市民を外国情報操作から保護、レイシズム拡散に対抗</title>
      <link>https://ledge.ai/articles/patriotic_ai_russia_belarus_joint_system</link>
      <description><![CDATA[<p>ロシアとベラルーシが、市民を外国の情報操作から保護し、伝統的価値観を反映したAIシステムを共同開発するとベラルーシの国営通信社<a href="https://belta.by/society/view/gossekretar-sg-nasha-zadacha-razrabotat-sobstvennyj-ii-osnovannyj-na-traditsionnyh-tsennostjah-725782-2025/">ベルタ</a>が2025年7月11日に報じた。</p>
<p>国際会議「連合国家の時代：文化と情報の景観」が、ヴィテブスクのスラヴィアンスキー・バザール国際芸術祭の連合国家デーの一環として、マシェロフ・ヴィテブスク国立大学で開催され、その場で発表された。両国の連邦機構「ソユーズ国家」の国家書記セルゲイ・グラジエフ氏が登壇し、年内に設計戦略をまとめ、公共情報ポータル上で試行を開始する計画を明らかにしたという。</p>
<p><strong>ヴィテブスクにおける連合国家会議</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/000049_1752237646_11334_big_db8277ead9/000049_1752237646_11334_big_db8277ead9.jpg" alt="000049_1752237646_11334_big.jpg" /></p>
<h2>外国製チャットボットへの対抗策としてAI共同開発を推進</h2>
<p>グラジエフ氏は、今回の発表において「外国製チャットボットが、レイシズムやナチズムを助長し、伝統的価値観を破壊するケースが確認された」と発言したうえで、「客観的情報と人間性に基づいた判断ができるAIが必要だ」と述べた。この背景には、ChatGPTなど欧米由来のAIモデルが提供するコンテンツに対する不信感があるとされる。</p>
<p>共同AIの開発は、両国における「情報主権」政策と連動しており、「国民を保護する」ことを主眼としている。新システムは、教育・医療・文化分野などでの活用を視野に入れており、第一段階として「未来を共に創る」と仮称された情報ポータル上での試験運用が予定されている。</p>
<h2>年末までに設計戦略を策定、2026年にも試験運用</h2>
<p>今回のプロジェクトは、ロシアおよびベラルーシのIT企業や大学を中核とするコンソーシアムによって構成され、2025年末までにAIアーキテクチャの設計戦略が策定される予定である。その後、2026年中に試験運用が行われ、最終的には行政サービスや教育機関への展開が見込まれている。</p>
<p>資金面では、両国政府の予算および国際的な「ソユーズ国家」構想の枠組みによって支援される見通しで、開発体制は公的・民間機関の連携によって構築される。</p>
<h2>デジタル主権とAI規制の一環としての位置づけ</h2>
<p>ロシアおよびベラルーシでは近年、「デジタル主権」の名のもとに西側テクノロジーへの依存度を下げる動きが加速している。ロシア国内では、すでに複数の西側SNSや検索エンジンがブロック対象となっており、AIについてもその適用範囲を制限する法整備が進行中である。</p>
<p>ベラルーシでも、2024年に制定された新たなサイバー情報法により、外国プラットフォーム上のAIツールの利用に対する監視が強化されている。こうした政策の流れの中で、今回のAIシステム開発は「主権国家によるAI管理」の象徴的プロジェクトとされている。</p>
<h2>外部からの反応と懸念</h2>
<p>イスラエルのメディア[Ynet https://www.ynetnews.com/business/article/r1kdos118le
は、今回のAI開発計画を「愛国的AI」と表現し、市民に対する新たな検閲手段として機能する可能性を指摘している。また、複数の西側専門家は「このAIは情報の多様性を制限し、国家による情報統制を強化する危険がある」と警告している。</p>
<p>これに対しグラジエフ氏は「AIが真実を語るものでなければならない」と主張し、政治的プロパガンダとは異なる「教育・啓蒙的AI」であることを強調している。</p>
<h2>今後の展望</h2>
<p>ロシア・ベラルーシ両政府は、今後数ヶ月以内にAIシステムの基本設計をまとめ、正式な「統一情報空間」戦略として国家プログラム化する方針を示している。2026年の本格導入を視野に、今後はAI開発に関わる法整備と人材育成が急がれることになる。</p>
]]></description>
      <pubDate>Sun, 20 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>最前線のAI・ロボット・VR・宇宙など未来体験が集結──日本科学未来館、夏休みイベント15企画を開催中</title>
      <link>https://ledge.ai/articles/miraikan_summer2025_ai_events</link>
      <description><![CDATA[<p>2025年7月12日から9月28日までの期間、東京・お台場にある日本科学未来館が、子どもから大人までを対象とした<a href="https://www.miraikan.jst.go.jp/news/press/202507074137.html">夏休み特別イベント</a>を開催している。ロボットの遠隔操作、AI分身との対話、月面探査車の実物大展示など、先端技術を体験できる15の企画が館内外で展開されており、科学技術の社会実装を来館者が体感する機会を提供しているという。</p>
<h2>AIと社会実装の“今”を体験する15企画</h2>
<p>同館によると、今回のイベントの中心的なテーマは「研究開発の最前線に触れ、未来の社会や自分の生活を考えるきっかけをつくる」ことだという。中でも注目されるのが、AIやロボティクスを活用した体験型プログラム群だ。</p>
<p>たとえば「ロボット・リモートワーク」（7月23日〜8月7日）では、来館者が遠隔操作でサービスロボットを動かし、“場所を選ばない働き方”の可能性を学ぶことができる。この企画は東京大学などの研究者と連携した実証を兼ねており、来館者の操作データや反応は今後の研究にも活用される予定だ。</p>
<p><strong>未来を体験！ ロボット・リモートワーク</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250704_summerevents1s_thumb_538xauto_19288_3f4b8e3a9e/20250704_summerevents1s_thumb_538xauto_19288_3f4b8e3a9e.jpg" alt="20250704_summerevents1s-thumb-538xauto-19288.jpg" /></p>
<p>また、7月21日から始まる「AI分身科学コミュニケーター vol.2」では、生成AIが館内展示を案内し、対話を通じて成長していく様子を観察できる。これは2024年に実施された第1弾の続編にあたり、今回は来館者との会話内容を反映してAIが自律的に対応を変化させる仕組みが加わっている。</p>
<p><strong>話して育てる、AI“分身”科学コミュニケーター vol.2</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250704_summerevents3s_thumb_538xauto_19290_95601d3efe/20250704_summerevents3s_thumb_538xauto_19290_95601d3efe.jpg" alt="20250704_summerevents3s-thumb-538xauto-19290.jpg" /></p>
<h2>VRと疲労科学：AIが心身のケアにも応用される現場</h2>
<p>AI・テクノロジーの社会実装は、労働や教育だけでなく、健康や感情のケアといった分野にも広がっている。「ツカレからの脱出」（7月16日〜9月15日）では、疲労回復に関する科学的知見を体感できるブースが設置され、バイタルデータの可視化や、最新の癒やしグッズの試用が可能となっている。</p>
<p><strong>ツカレからの脱出 ～疲れとやすみのサイエンス</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250704_summerevents6_c909a65e47/20250704_summerevents6_c909a65e47.jpg" alt="20250704_summerevents6.jpg" /></p>
<p>8月8日には、早稲田大学の研究者による「ソーシャルVRとメンタルヘルス」に関するトークイベントも予定されており、バーチャル空間が人間関係や心の健康に与える影響について来場者と共に探る試みがなされる。</p>
<h2>宇宙探査技術の最前線に触れる「深宇宙展」</h2>
<p>一方で、科学技術のフロンティアとしての宇宙にも焦点が当てられている。7月12日から開幕した特別展「深宇宙展～人類はどこへ向かうのか」では、2020年代後半以降の有人月面探査計画をテーマにした展示が行われている。実物大の有人月面探査車（世界初公開）や、没入型の火星ツアーシアターが設置され、リアルな宇宙探査の臨場感を味わえる内容となっている。</p>
<p><strong>特別展「深宇宙展～人類はどこへ向かうのか」To the Moon and Beyond</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/20250704_summerevents8s_thumb_538xauto_19295_9f852e38ce/20250704_summerevents8s_thumb_538xauto_19295_9f852e38ce.jpg" alt="20250704_summerevents8s-thumb-538xauto-19295.jpg" /></p>
<p>関連イベントとして、JAXAの研究者や天文学者による特別講演会も開催され、科学技術の現場の声を来館者に届けている。7月19日には第2回の講演が実施された。</p>
<h2>参加方法と申込情報</h2>
<p>すべてのイベントは日本科学未来館館内および関連施設で実施されており、原則として入館料（大人1,200円、18歳以下600円など）で体験できる。一部のイベントは無料、または特別展の観覧料（大人2,200円ほか）が必要となる。プログラムによっては事前予約や抽選が必要なものもあり、詳細は公式ウェブサイトに掲載されている。</p>
<h2>おもなAI・科学関連プログラム一覧（開催日順）</h2>
<ul>
<li>AI分身科学コミュニケーター vol.2（7/21〜7/31）</li>
<li>ロボット・リモートワーク体験（7/23〜8/7）</li>
<li>空間楽器アプリ実証実験（7/26）</li>
<li>ソーシャルVRの実験トークイベント（8/8）</li>
<li>深宇宙展（特別展）（7/12〜9/28）</li>
<li>ツカレからの脱出（展示体験）（7/16〜9/15）</li>
</ul>
<h2>実証の現場をそのまま公開</h2>
<p>今回のイベント群は、単なる展示や体験の枠にとどまらず、実際に研究が進められている開発中の技術を来館者が操作・観察できる点に特徴がある。多くのプログラムでは、研究者本人が現地に立ち会い、技術の背景や社会的意義を直接解説している。</p>
<p>技術的な仕組みに関心を持つ読者にとっては、生成AIや遠隔ロボティクスといった領域の最前線にある試みを“生活に接続する形”で知ることができるまたとない機会となっている。</p>
<p>※イベントの詳細および最新の申込情報は、<a href="https://www.miraikan.jst.go.jp/news/press/202507074137.html">日本科学未来館 公式サイト</a>で確認できる。</p>
]]></description>
      <pubDate>Sun, 20 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AIが構築した“仮想都市”──ウーブン・バイ・トヨタ、100万人都市シミュレーター「CitySim」で未来を検証</title>
      <link>https://ledge.ai/articles/citysim_virtual_tokyo_by_llm</link>
      <description><![CDATA[<p>ウーブン・バイ・トヨタに所属する研究者らが2025年6月26日、最大100万人の仮想住民を生成AIで再現し、都市全体の行動・社会・交通動態をシミュレーションできるシステム「CitySim」を開発したとする論文を<a href="https://arxiv.org/abs/2506.21805">発表</a>した。</p>
<p>同システムは、大規模言語モデル（LLM）を用いて仮想市民の人格、行動計画、移動選択を動的に生成し、都市政策やモビリティ戦略を事前検証できる汎用プラットフォームとして設計されている。</p>
<h2>生活パターンから移動手段まで再現　100万人分のエージェントをLLMで生成</h2>
<p>CitySimでは、各仮想住民（エージェント）にペルソナ（年齢・性別・職業・性格）、基本的な欲求（空腹、安全、社会的つながりなど）、そして長期的な目標や空間記憶が付与されている。各エージェントはこの情報に基づき、日々のスケジュールや移動先を LLM（GPT-4o-mini 相当）によって動的に計画・実行する。</p>
<p>行動生成は、「必須タスク（勤務、就寝など）」を基盤に構成され、空き時間には好みに応じて娯楽、社交、買い物などを自律的に選択。さらに移動時には、出発地・目的地の候補選定、交通手段の選択（徒歩、鉄道、車両）といったプロセスもすべて LLM が文脈理解を通じて判断する。</p>
<p><strong>CitySim の構成イメージ：100 万人の仮想住民が「活動計画」「社会的交流」「移動予測」の3層で行動を生成する</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Overview_of_City_Sim_fcef52097e/Overview_of_City_Sim_fcef52097e.jpg" alt="Overview of CitySim.jpg" /></p>
<h2>実世界の人流や生活パターンと高い一致率</h2>
<p>検証では、総務省の「生活時間調査（Survey on Time Use and Leisure Activities）」を基に、各年齢層の1日当たり活動配分と CitySim による出力結果を比較。睡眠、労働、家事、娯楽などの比率は実データと高い一致を示した。</p>
<p><strong>年齢層別の1日時間配分：国勢調査の生活時間調査とCitySimの比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Time_use_distribution_67220d4c20/Time_use_distribution_67220d4c20.jpg" alt="Time-use distribution.jpg" /></p>
<p>また、エージェントの平均移動回数を時系列で集計し、平日・週末別に実世界の人流データと比較したところ、通勤・通学時間帯のピークや余暇時間帯の傾向も再現されている。</p>
<p><strong>平日・週末別に見た平均移動回数：実測値とCitySimを含む各種モデルの比較</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Average_number_of_agent_travels_per_hour_on_ccbb29a029/Average_number_of_agent_travels_per_hour_on_ccbb29a029.jpg" alt="Average number of agent travels per hour on.jpg" /></p>
<p>さらに、東京都渋谷区を対象とした人流ヒートマップの再現検証では、実データと CitySim の出力が類似したパターンを描き、空間的妥当性も確認された。</p>
<p><strong>渋谷駅周辺の群集密度ヒートマップ：左＝実測、右＝CitySim</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Comparisonof_simulated_and_realworld_crowddensityheatmapsin_Shibuya_c800c48739/Comparisonof_simulated_and_realworld_crowddensityheatmapsin_Shibuya_c800c48739.jpg" alt="Comparisonof simulated and realworld crowddensityheatmapsinShibuya.jpg" /></p>
<h2>他手法と比較し“人間らしさ”の評価でも上位</h2>
<p>主観評価による比較実験では、CitySim は他の先行システム（GeAn, AGA, MobileCityなど）と比べ、「人間らしさ（Human-likeness）」の観点で平均0.85の勝率を記録。他手法に対して一貫して高いスコアを示し、自然な行動生成が可能であることが確認された。</p>
<h2>想定される応用分野：都市設計、災害対策、MaaS配置最適化など</h2>
<p>CitySimは、都市政策立案前のシナリオ評価、歩行者密度の時空間分析、MaaSや自動運転車の経路最適化、防災計画における避難行動予測など、幅広い領域への応用が見込まれている。</p>
<p>研究チームは今後について、「現実の都市データやセンサー情報と連携することで、仮想都市と実環境を結びつける双方向的な検証が可能になる」と述べている。また、LLMに内在する文化的バイアスやプライバシー問題、再現性の課題に対しても「コミュニティと協力して対処していく必要がある」としており、スケーラブルで倫理的なシステム運用に向けた検討を継続するとしている</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>サイボウズ、新卒エンジニア研修資料を無償公開──生成AIやKubernetes、Copilotなど実務直結の内容を網羅</title>
      <link>https://ledge.ai/articles/cybozu_engineer_training_materials_2025_release</link>
      <description><![CDATA[<p>2025年7月8日、サイボウズ（東京都中央区）は、自社の2025年度新卒エンジニア向け研修で使用した講義資料と一部講義動画を、同社の公式エンジニアブログ上で<a href="https://blog.cybozu.io/entry/2025/07/08/171543">無償公開</a>した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/blog_cybozu1_368c892398/blog_cybozu1_368c892398.jpg" alt="blog cybozu1.jpg" /></p>
<p>資料は生成AIツール開発やGitHub Copilotの活用、DockerおよびKubernetesの入門、セキュリティ、暗号技術、テスト自動化、テクニカルライティングなど全19本におよび、実践的かつ初学者にも配慮された構成となっている。</p>
<p>今回公開された資料は、2025年4月21日から5月23日にかけて実施されたサイボウズの新卒エンジニア研修プログラムに基づくものである。同研修は、「講義実習フェーズ」と「実践演習フェーズ」の二段階構成となっており、入社直後から実務にスムーズに参加できるよう、基礎技術からチーム開発への適応力までを総合的に育成することを目的としていた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/blog_cybozu2_dc7b72035c/blog_cybozu2_dc7b72035c.jpg" alt="blog cybozu2.jpg" /></p>
<p>公開されたコンテンツの主なテーマは以下の通り。</p>
<ul>
<li>Difyを使った生成AIチャットボット開発ワークショップ</li>
<li>GitHub Copilotを用いたAI補助プログラミング体験</li>
<li>DockerとKubernetesの導入・基礎概念の解説</li>
<li>セキュリティと暗号に関する基礎知識</li>
<li>自動テストの設計と実践（理論編・実装編）</li>
<li>テクニカルライティング、ソフトウェアライセンスの基本</li>
</ul>
<p>資料は同社のスライド共有サービス「Speaker Deck」上で閲覧可能で、一部講義動画はYouTubeで確認できる。利用条件はブログ内に明記されており、再配布や二次利用の際には個別確認が必要とされている。</p>
<p>サイボウズは例年、社内研修の一部資料を外部公開しており、今年は「自社と自身を理解し、長期的なキャリアの土台を作る」ことをテーマに、研修設計全体の構造や背景もあわせて紹介している。公開の狙いについて、同社は「外部の教育機関や企業研修担当者、個人開発者との知見共有を促進するため」と説明している。</p>
<p>近年、LINEヤフーやメルカリなどの企業も同様に新卒向け技術資料の一部公開を行っているが、生成AIやDevOps関連を含む実務直結型の全体研修資料をここまで一括公開する事例は、国内大手企業としては珍しい。</p>
<p>今後も同社は、研修資料の公開範囲を拡大する可能性を示唆しており、例年8月〜9月に開催される自社技術カンファレンスにおいて、追加的なハンズオン資料の提供も期待されている。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>これからのAIスキルは「プロンプト」ではなく「コンテキスト・エンジニアリング」──Google DeepMind フィリップ・シュミット氏が提起</title>
      <link>https://ledge.ai/articles/context_engineering_deepmind</link>
      <description><![CDATA[<p>2025年6月30日、Google DeepMindのシニアAIリレーションエンジニアであるフィリップ・シュミット（Philipp Schmid）氏が自身のブログを通じて、「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」と<a href="https://www.philschmid.de/context-engineering">提起</a>した。大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトだけでは不十分であり、AIに与える前提情報全体を設計・最適化する技術が不可欠だと論じている。</p>
<h2>背景：プロンプトエンジニアリングの行き詰まり</h2>
<p>近年、生成AIの発展に伴い「プロンプトエンジニアリング」が注目を集めてきた。巧みなプロンプトを用いてモデルの挙動を調整し、より望ましい回答を得るという技法は、AI活用の第一歩として広く普及している。しかしシュミット氏は、現実の業務環境ではプロンプトの工夫だけで対応できない課題が増大しており、AIが真にユーザーの期待に応えるには、より包括的な情報構造の設計が必要だと指摘した。</p>
<h2>コンテキストエンジニアリングとは</h2>
<p>シュミット氏は、コンテキストエンジニアリングを「AIが必要とする情報を、適切な形式で、適切なタイミングに提供する仕組みの設計」と位置付ける。単にプロンプトを最適化するのではなく、モデルに取り込ませる知識、会話履歴、外部ツールとの連携などを含めて制御する総合的な技術領域だと説明する。</p>
<p>具体的には、</p>
<ul>
<li>System Prompt（AIのシステム的前提）</li>
<li>User Prompt（ユーザーからの指示）</li>
<li>State/History（対話履歴や状態管理）</li>
<li>Long-Term Memory（長期記憶としての知識）</li>
<li>Retrieved Information（RAGなどによる検索情報）</li>
<li>Tools/Structured Output（外部ツール連携・構造化出力）
という6つの構成要素を「コンテキスト」として設計し、動的に最適化していく考え方を示している。</li>
</ul>
<h2>8割の失敗は文脈不足</h2>
<p>シュミット氏は、AIエージェント開発における8割の失敗が「文脈情報の欠落」に起因すると述べている。たとえばカレンダー調整を行うAIエージェントの場合でも、ユーザーの希望や優先順位を把握しないまま単純な操作を試みることでエラーが起きやすいと説明している。</p>
<h2>関連技術と支える手法</h2>
<p>同氏は、コンテキストエンジニアリングを支える技術として、</p>
<ul>
<li>検索拡張生成（RAG）</li>
<li>ベクトルデータベース検索</li>
<li>ツール呼び出しのオーケストレーション</li>
<li>会話履歴管理
などの仕組みが必要だと述べている。これらを組み合わせることで、AIが常に適切な前提情報を取得しながら出力を行える環境を整備できるとする。</li>
</ul>
<h2>エンタープライズでの展開</h2>
<p>シュミット氏は、コンテキストエンジニアリングがエンタープライズ分野においても重要であると述べている。社内ドメイン知識や業務ルールをAIが正しく理解できるようにするために、前提情報の整理と統合を体系的に設計する必要があるとしている。</p>
<p>筆者プロフィール
フィリップ・シュミット氏は、Hugging Faceのエンジニアを経てGoogle DeepMindに参画。大規模言語モデルとエージェント技術の実用化に関する知見を広く発信している。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>電通グループがAI開発・活用の新組織「dentsu Japan AIセンター」を発足──約1,000名の専門人材で“AIネイティブカンパニー”を目指す</title>
      <link>https://ledge.ai/articles/dentsu_japan_ai_center_launch</link>
      <description><![CDATA[<p>電通グループの国内主要5社は2025年7月7日、AI開発と活用を横断的に推進する新組織「dentsu Japan AIセンター」を発足したことを<a href="https://www.dentsu.co.jp/news/release/2025/0707-010909.html">発表</a>した。同センターは約1,000名のAI専門人材を擁し、グループおよび顧客企業の全社的なAI変革を加速させることを目的としている。</p>
<h2>AI変革を牽引する中核組織</h2>
<p>同センターは、AIを単なる業務効率化手段ではなく、企業の経営・組織そのものを変革する中核要素と位置づけており、グループ横断でのリソース統合により、迅速かつ高度なAI活用を図るとしている。これにより、従来は部門ごとに分散していたAI導入の取り組みを、経営層・技術部門・事業部門が一体となって推進する体制が整備されることになる。</p>
<h2>主な活動領域とユニット構成</h2>
<p>dentsu Japan AIセンターは、以下6つの専門ユニットを設けており、それぞれの領域でAI技術の導入と価値創出に取り組む：</p>
<ul>
<li><strong>AI業務効率化ユニット</strong> ：グループ内向けのAIツール開発・導入を担い、生産性向上を推進</li>
<li><strong>AIマーケティング＆クリエイティブ高度化ユニット</strong> ：広告制作・メディア運用におけるAI活用を支援</li>
<li><strong>統合マーケティングAIエージェント開発ユニット</strong> ：複数のAIアプリを統合するエージェント技術を開発</li>
<li><strong>AI・データインフラ強化ユニット</strong>：電通独自のデータ基盤「People Model」などのインフラを拡張</li>
<li><strong>AIマーケティングトランスフォーメーション（AIMX）ユニット</strong> ：顧客企業のマーケティング変革を支援</li>
<li><strong>AIトランスフォーメーションユニット</strong> ：経営・人事・営業など非マーケティング領域のAI導入を支援</li>
</ul>
<h2>ガバナンス体制と外部連携</h2>
<p>同センターは、グループ内のAI利用ルールを策定・管理する「dentsu Japan AIガバナンスコミッティ」と連携し、ガバナンスと実装の両面でAI活用の高度化を進める。また、大学・研究機関との共同研究成果を取り込むことで、先端技術の実用化を図る構えだ。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>経産省・NEDOの生成AI開発支援プロジェクト「GENIAC」第3期、楽天と野村総研を含む新規13件を採択──生成AI国産化を加速</title>
      <link>https://ledge.ai/articles/geniac_third_round_rakuten_nri_selected</link>
      <description><![CDATA[<p>2025年7月15日、経済産業省と新エネルギー・産業技術総合開発機構（NEDO）は、生成AI開発支援プロジェクト「GENIAC（Generative AI Accelerator Challenge）」の第3期採択結果を<a href="https://www.nedo.go.jp/koubo/CD3_100397.html">発表</a>した。今回の公募には43件が応募し、最終的に24件が採択された。楽天グループと野村総合研究所（NRI）を含む13件が新規採択で、第1期・第2期に採択されていなかった新顔の参画が加速している。</p>
<h2>楽天、日本語LLMに長期記憶と対話学習を融合</h2>
<p>楽天グループは今回の第3期で初採択された。申請テーマは「長期記憶メカニズムと対話型学習を融合した日本語LLMの研究開発」で、同社が進めるAIエージェント構想の一環とみられる。</p>
<p>2024年末に発表された「Rakuten AI 2.0」では、社内外のデータを活用した多目的LLMの構築と、オープンソース化の方針が示されていた。GENIACの支援を受けることで、大規模演算環境のもと、学習済みパラメータの拡張や長期記憶モジュールの実装が本格化する可能性がある。</p>
<h2>野村総研、業界特化の40B規模モデルを計画</h2>
<p>野村総合研究所（NRI）も第3期で初採択された。採択テーマは「10B〜40B規模の業界・タスク特化型LLMの研究開発」。具体的な適用分野は公表されていないが、金融・行政・製造などNRIが業務支援を行う産業領域での応用が想定される。</p>
<p>NRIのような大手コンサルティング・IT企業が生成AIの基盤モデル開発に乗り出すのは、GENIACプロジェクト初となる。従来のSaaS活用や外部API連携を越えて、独自モデル構築へと進む転換点と位置づけられる。</p>
<h2>新規採択は13件、分野特化型スタートアップが多数</h2>
<p>楽天とNRI以外にも、第3期では11の新規プレイヤーが採択された。採択テーマからは、以下のような分野特化型の研究が目立つ。</p>
<ul>
<li><strong>Airion</strong> ：PLCラダープログラムを自動生成するLLM</li>
<li><strong>Arivexis</strong> ：低分子化合物の生物活性を予測する創薬モデル</li>
<li><strong>Degas</strong> ：リモートセンシング向け視覚言語モデル</li>
<li><strong>Direava</strong> ：外科手術支援用の視覚・言語統合AI</li>
<li><strong>NexaScience</strong> ：研究開発プロセスを自律化するエージェント</li>
<li><strong>Nishika</strong> ：出力形式を厳密に制御できる要約特化LLM</li>
<li><strong>ONESTRUCTURE</strong>：建築BIMデータを生成するモデル</li>
<li><strong>Precision</strong> ：医療文書理解向け専門LLM</li>
<li><strong>Sansan</strong> ：企業文書を対象にした視覚言語モデル</li>
<li><strong>SDio</strong> ：長尺映像を扱う国産大規模映像モデル</li>
<li><strong>Zen Intelligence</strong> ：建設現場施工管理を自動化するモデル</li>
</ul>
<p>これらの企業の多くは医療・建築・産業用途など、明確な業務ユースケースを持つ。GENIAC支援によって、計算資源を活用したモデルのスケーリングが可能になると見られる。</p>
<h2>継続採択は11件、ABEJA・Preferredなど第1期組も含む</h2>
<p>第1期・第2期からの継続採択組は11件。業界内で技術実装が進む企業が引き続き支援対象となった。以下は継続企業の一部。</p>
<ul>
<li>ABEJA</li>
<li>AI inside</li>
<li>AIdeaLab</li>
<li>Karakuri（カラクリ）</li>
<li>Kotoba Technologies Japan</li>
<li>NABLAS</li>
<li>Preferred Networks</li>
<li>Ricoh</li>
<li>Stockmark</li>
<li>SyntheticGestalt</li>
<li>Turing</li>
</ul>
<p>すでにGENIACの支援を受けた開発実績を有しており、第3期ではモデルの高度化や新機能の追加が焦点となる。</p>
<h2>GENIACの支援規模と今後のスケジュール</h2>
<p>GENIACは、経産省とNEDOが連携して進める国産生成AI開発支援プログラムで、2023年度から実施されている。今回の第3期採択により、累計支援件数は54件に拡大した。
対象期間：交付決定日〜2026年2月末まで
支援内容：GPUクラウド等の演算資源提供、外部評価機関による技術検証
今後の予定：NEDOによる中間評価、年度末までに開発成果の提出と発表が予定されている</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>世界最強AI「Grok 4」公開──xAI、わずか数カ月という常識外れのスピードでモデル刷新　マスク氏「ネットにない難問も解ける」</title>
      <link>https://ledge.ai/articles/grok4_xai_ai_model_launch</link>
      <description><![CDATA[<p>イーロンマスク氏の率いるAIスタートアップxAIは2025年7月10日、X（旧Twitter）公式アカウントで最新大規模言語モデル「Grok 4」を<a href="https://x.com/xai/status/1943158495588815072">発表</a>し、同時にライブ配信で詳細を公開した。前世代「Grok 3」から数カ月という超短サイクルでのモデル刷新となり、マスク氏は「インターネットにも書籍にも存在しない難問を解ける初のAIだ」と性能を強調している。</p>
<h2>「世界最強」を標榜、リアルな工学課題を解決可能と説明</h2>
<p>xAI公式アカウントは「世界で最も強力なAIモデル」としてGrok 4を紹介し、ライブ配信の視聴を呼びかけた。その後、イーロン・マスク氏自身もX上で「Grok 4は、現実世界の難しい工学的課題に対して、ネットにも書籍にも存在しない答えを導き出すことができた初のAIだ」と述べ、同モデルの性能を強調した。</p>
<p><strong>図1　“Ludicrous rate of progress”──Grok 2からGrok 4に至る計算資源の10倍ステップアップを示したスライド</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_3_2b88dc0836/musk_grok4_3_2b88dc0836.jpg" alt="musk grok4-3.jpg" /></p>
<h2>公表された性能指標──既存モデルを上回る結果も</h2>
<p>xAIによれば、以下の主要ベンチマークでGrok 4は高い性能を示した（数値はすべて同社発表値）：</p>
<h3>Humanity’s Last Exam（人類最後の試験）</h3>
<p><strong>図2　総合推論テスト「Humanity’s Last Exam」全セット比較。Grok 4 Heavyは44.4%でトップスコアを記録</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_5_8a69f27997/musk_grok4_5_8a69f27997.jpg" alt="musk grok4-5.jpg" /></p>
<h3>ARC-AGI（汎用人工知能測定ベンチマーク）</h3>
<p><strong>図3　ARC-AGIベンチマークの精度‐コスト分布。Grok 4は精度66.6%でクラストップ帯に位置付けられた</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_7_5b67bb48af/musk_grok4_7_5b67bb48af.jpg" alt="musk grok4-7.jpg" /></p>
<p><strong>図4　GPQAやAIME25など学術系コンペでもGrok 4／Grok 4 Heavyが軒並み首位に</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_6_90a347be60/musk_grok4_6_90a347be60.jpg" alt="musk grok4-6.jpg" /></p>
<h2>Grok 4／Grok 4 Heavy──2ライン体制で展開</h2>
<ul>
<li><strong>Grok 4（標準）</strong> ：推論改善を目的に強化学習（RL）を追加。</li>
<li><strong>Grok 4 Heavy</strong> ：複数エージェントで同一課題を並列解析し、回答を相互検証する上位版。
開発者・パワーユーザー向けに月額300ドルの「SuperGrok Heavy」プランを新設。</li>
</ul>
<h2>今後のロードマップ</h2>
<p>Grok 4は、Grok 3からわずか数カ月で投入された。マスク氏は開発速度について「恐ろしく速い」と述べ、今後も短い間隔で新モデルを導入する意向を示した。さらに、以下のようなロードマップも明らかにされている：</p>
<ul>
<li>7月中旬以降：Tesla車両へのGrok搭載を開始予定</li>
<li>8月：コード生成AIのリリース</li>
<li>9月：マルチモーダル・エージェントの提供</li>
<li>10月：動画生成AIの公開</li>
</ul>
<p><strong>図5　xAIが示した今後のタイムライン。8月にコード生成モデル、9月にマルチモーダルエージェント、10月に動画生成AIを投入予定</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/musk_grok4_9_4b0fc9c4d0/musk_grok4_9_4b0fc9c4d0.jpg" alt="musk grok4-9.jpg" /></p>
<h2>今後の課題</h2>
<p>Grokシリーズは、2023年11月の初版リリースから急速に進化しており、OpenAIのChatGPTやGoogleのGeminiに対抗する形で市場に存在感を示してきた。ただし、直近では前バージョンが反ユダヤ的発言を生成したとの報道もあり、同社はプロンプト設計の見直しを迫られていた。今後は、モデル性能とともに倫理的安全性や説明責任も問われる局面が続くと見られる。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の &quot;恐ろしい振る舞い&quot; に謝罪、トラブルの原因を公表</title>
      <link>https://ledge.ai/articles/grok_ai_misfire_apology_prompt_release</link>
      <description><![CDATA[<p>イーロン・マスク氏が率いるxAIは2025年7月11日、同社のAIチャットボット「Grok」が7月8日にX（旧Twitter）上で反ユダヤ的表現やナチスを賛美するような投稿を大量に生成した問題について、公式アカウントで「多くの方が経験した”恐ろしい振る舞い（horrific behavior）”を深くお詫びする」と謝罪し、原因は16時間稼働していた誤アップデートコードにあったと<a href="https://x.com/grok/status/1943916977481036128">発表</a>した。
また、再発防止策としてプロンプトの全文をGitHubで公開する方針も明らかにした。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Update_on_where_has_2e557e42ef/Update_on_where_has_2e557e42ef.jpg" alt="Update on where has.jpg" /></p>
<h2>Grokによる不適切回答の発生</h2>
<p>7月8日未明（米太平洋時間）、GrokはX上でユーザーからの投稿に対し、「ヒトラーは偉大」「MechaHitlerになりたい」といった極端な表現を含む回答を繰り返し生成した。確認された投稿数は数百件にのぼり、その内容がSNS上で拡散されたことにより、問題が広く認知されるに至った。</p>
<p>通報を受けたXは該当の投稿を削除し、ユダヤ系人権団体Anti-Defamation League（ADL）は「極端思想を助長する無責任な対応」と非難声明を出した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/adl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a/adl_Grok_LLM_right_now_is_irresponsible_5f7ffadb0a.jpg" alt="adl  Grok LLM right now is irresponsible.jpg" /></p>
<h2>xAIによる調査と原因の説明</h2>
<p>xAIは7月11日にGrokの公式アカウントを通じ、問題の発生原因と対応策についてスレッド形式で報告した。</p>
<p>同社によると、今回の不適切回答は、「ユーザー投稿と類似のトーンで返答する」というテスト用のコードが誤って本番環境に適用されたことにより引き起こされたものであり、Grok本体の言語モデル（Grok 4）には変更は加えられていなかったという。このコードは約16時間にわたり稼働しており、その間に外部投稿に含まれる極端思想を模倣する形で回答が生成されていた。</p>
<p>問題発覚後、Grokは一時的に稼働を停止し、対象コードは完全に削除された。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Technical_Details_on_x_90300ce294/Technical_Details_on_x_90300ce294.jpg" alt="Technical Details on x.jpg" /></p>
<h2>再発防止に向けた対応策</h2>
<p>xAIは再発防止策として以下の対応を発表している。</p>
<ul>
<li>誤適用されたコードパスを完全に削除し、システム全体をリファクタリング</li>
<li>安全性を強化した新たなシステムプロンプトをGitHub上で公開予定</li>
<li>メンション機能（＠でのタグ付け）による自動応答機能を一時的に停止</li>
<li>外部の研究者を含むレッドチーム体制を拡充し、安全性評価を継続</li>
<li>ユーザーからのフィードバックを常時受け付ける体制を整備</li>
</ul>
<h2>事案発生からの時系列</h2>
<ul>
<li>7月8日 04:00頃（米PDT）　Grokの上流コードが更新され、誤コードが稼働開始</li>
<li>同日 20:00頃　外部ユーザーからの通報を受け、問題が社内で認識されGrokを一時停止</li>
<li>7月9日　Xが不適切投稿を削除、ロイターが第一報を報道</li>
<li>7月10日　各国メディアが続報を掲載、ADLなどが批判声明を発表</li>
<li>7月11日 06:00頃　Grok公式がスレッドで謝罪と原因説明、対策方針を公表</li>
<li>7月12日以降　段階的にサービスが再開され、プロンプト公開の準備が進められている</li>
</ul>
<h2>今後の注目点</h2>
<p>今回の問題を受けて、今後以下の点が注視されている。</p>
<ul>
<li>GitHubでのプロンプト公開によって、第三者による安全性検証が進むか</li>
<li>Grok 4モデル自体の安全性と応答制御の設計が今後も維持されるか</li>
<li>Xプラットフォーム全体のモデレーション体制の見直しが進むか</li>
</ul>
<p>xAIは「ユーザーのフィードバックに感謝する」としており、透明性と安全性の両立に向けた開発を続けるとしている。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/18 [FRI]LINEヤフー、全社員1.1万人に生成AI “義務化”──「まずはAIに聞く」働き方で3年以内に生産性2倍へ</title>
      <link>https://ledge.ai/articles/line_yahoo_mandates_genai_use_for_all_employees</link>
      <description><![CDATA[<p>LINEヤフー株式会社は2025年7月14日、正社員・契約社員など約1万1,000人の全従業員を対象に、業務における生成AI活用を「義務化」する新たな働き方を開始したと<a href="https://www.lycorp.co.jp/ja/news/release/018121/">発表</a>した。</p>
<p>生成AIの全社的な導入により、3年以内に業務生産性を2倍に引き上げることを目指す。この施策では、調査・検索、資料作成、会議を中心に「まずはAIに聞く」文化の定着を社内ルールとして定め、ChatGPT Enterpriseを含む複数のツールを活用するという。</p>
<h2>生成AI前提の働き方へ全面移行</h2>
<p>新制度では、生成AIの活用を業務遂行の前提とし、「調査・検索」「資料作成」「会議運営」の3領域において具体的な指針が示された。</p>
<ul>
<li><strong>調査・検索</strong> ：社内規程や競合情報などを調べる際に、社内ツール「SeekAI」や生成AI検索の使用を義務化</li>
<li><strong>資料作成</strong> ：アウトライン作成や初稿作成をAIで行い、校正もAIによる支援を前提とする</li>
<li><strong>会議</strong> ：議題整理や議事録作成にAIを導入し、任意参加の会議は原則欠席、議事録で内容を把握する</li>
</ul>
<h2>生産性2倍をKPIに、AI活用を数値化</h2>
<p>LINEヤフーは、生成AIの活用に関して以下の数値目標を設定している。
社員の生成AI活用率：100％
サービスへのAI機能導入件数：51件（2025年7月時点で実装済み）
社内業務効率化プロジェクト：35件超が進行中
生産性KPI：3年間で業務生産性を2倍に引き上げることを目標</p>
<p>これらのKPIは、社内外での成果測定や継続的な改善につなげるとしている。</p>
<h2>全社員にChatGPT Enterpriseを配布</h2>
<p>制度実行に向けた環境整備として、2025年6月から全社員に「ChatGPT Enterprise」のアカウントが付与された。利用に際しては、eラーニング形式の教育コンテンツを通じてリスク管理やプロンプト設計の基本を学び、所定のテストに合格することが条件となる。また、各部門に「生成AI活用推進者」を配置し、活用ノウハウや事例を横展開する体制も構築している。</p>
<p>生成AI統括本部長の宮澤弦氏は、公式リリースの中で「全社員が生成AIを最大限に活用し、新しい価値を生み出したい」と述べている。</p>
<h2>今後の展望</h2>
<p>国内企業で生成AIの全社導入は急速に広がりつつある。MIXIは全社員約2,000人にGoogle 「Agentspace」を配布し、定型業務の自動化を進めた。電通グループも「dentsu Japan AIセンター」を設立し、約1,000人の専門人材を軸にAIネイティブ化を推進している。こうした動きの中で、生成AIの活用を義務化まで踏み込んだのはLINEヤフーが国内初だ。</p>
<p>同社は今後、社内表彰やアンバサダー制度を通じて優良事例を共有し、部門横断的な活用を促進する。KPIの達成状況や教育効果は四半期ごとに公開される予定で、透明性の高い運用が特徴となる。また、生成AIを核にした新サービスや業務機能の刷新にも取り組む構えだという。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ハルシネーション（事実誤認）より深刻なAIの「わかったふり」を暴く：MITなどが発見したLLMの“ポチョムキン理解”とは</title>
      <link>https://ledge.ai/articles/potemkin_understanding_llm</link>
      <description><![CDATA[<p>MIT・ハーバード大学・シカゴ大学の研究チームは2025年6月29日、大規模言語モデル（LLM）の「表面的には理解しているように見えるが、実際には概念の適用で誤る」現象を「ポチョムキン理解」と命名し、その頻度を定量化した研究成果を<a href="https://arxiv.org/abs/2506.21521">発表</a>した。発表はICML 2025（バンクーバー）に採択され、AI分野における評価基準の再考を促す内容となっている。</p>
<p>18世紀ロシアの「ポチョムキン村」は、皇帝の視察用に急造された見せかけの村落を指し、「中身のない外観」の象徴とされる。研究者らは、LLMにも同様の「わかったふり」があるとし、この概念をポチョムキン理解と表現している。</p>
<h2>ポチョムキン理解の定義と背景</h2>
<p>研究チームは、LLMが人間向けに設計されたベンチマークの「キーストーン質問」には正しく答えられるものの、その後の具体的応用タスクでは誤る状態を指摘した。これは、人間なら正答＝理解と認められる最小限の問いに合格しても、LLMが本質的に異なる誤解を抱いている可能性を示している。</p>
<p><strong>キーストーン集合に正答しても本質的に誤った解釈を残すポチョムキン理解のイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_schematic_representation_of_keystones_and_potemkins_e47033e684/A_schematic_representation_of_keystones_and_potemkins_e47033e684.png" alt="A schematic representation of keystones and potemkins.png" /></p>
<h2>検証の概要</h2>
<p>検証では、</p>
<ul>
<li>文学技法（俳句やアナロジーなど12種類）</li>
<li>ゲーム理論（ナッシュ均衡など9種類）</li>
<li>心理的バイアス（サンクコストの誤謬など11種類）
の合計32概念について、</li>
<li>定義</li>
<li>分類</li>
<li>生成</li>
<li>編集
の4つのタスクで7種類のモデル（GPT-4o、Claude 3.5 Sonnet、Gemini 2.0 Flash など）を評価した。</li>
</ul>
<h2>主な結果</h2>
<p>定義タスクではおおむね94%の正答率を記録したが、その後の応用タスクでは</p>
<ul>
<li>分類で55%</li>
<li>生成で40%</li>
<li>編集で40%
の失敗率（potemkin rate）が確認された。これは、定義だけでは概念理解の深度を測れない可能性を示唆している。</li>
</ul>
<h3>具体例：韻律パターンの応用失敗</h3>
<p>代表的な例として挙げられるのが韻律スキームの問題だ。GPT-4oに「ABAB韻律とは何か」を問うと、下図のように正確に定義を説明した。しかしいざ詩の穴埋め問題でABAB韻律を適用させると、正しく韻を踏めず、自分でもその失敗を認める回答を出した。人間ならまず起こり得ない不可解な挙動である。</p>
<p><strong>GPT-4oはABABの定義を正しく述べながら、応用で失敗する「ポチョムキン理解」の典型例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Potemkin_Understanding_in_llm_5dae4e573b/Potemkin_Understanding_in_llm_5dae4e573b.png" alt="Potemkin Understanding in llm.png" /></p>
<h2>多分野で発生する“わかったふり”</h2>
<p>研究チームはさらに、幾何学の基本定理、家族関係の概念、俳句の構造など幅広い領域で同様のポチョムキン理解を確認している。</p>
<p><strong>概念の定義には成功する一方で応用に失敗する複数の事例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Examples_of_potemkins_f6c5140e2d/Examples_of_potemkins_f6c5140e2d.jpg" alt="Examples of potemkins.jpg" /></p>
<h2>自己評価による一貫性検証</h2>
<p>さらに著者らは、自動評価の一環として「モデル自身に、自分が生成した回答を再評価させる」という仕組みを試みた。
例えば「スラントライムの例を作れ」と指示し、その後「今作った例はスラントライムか？」と再度モデルに問うと、矛盾した回答が返るパターンが確認され、モデル内部の知識表現が不整合である可能性を示しているとした。</p>
<p><strong>生成と再判定の整合性を確かめる自動評価プロセスのイメージ</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72/Illustration_of_the_method_for_evaluating_incoherence_in_models_d19701ab72.png" alt="Illustration of the method for evaluating incoherence in models.png" /></p>
<h2>社会的影響と課題</h2>
<p>論文では、ハルシネーション（事実誤認）とは異なり、ポチョムキン理解は概念構造の誤りであるため、人間にも検出が難しいと指摘する。
法務や医療、教育といった高い正当性が求められる分野でLLMを活用する際には、ベンチマークだけでは保証できないリスクとして注意が必要とされる。</p>
<p>研究チームは、人間とAIの「誤解のパターン差」を考慮したベンチマークの再設計や、概念の一貫性を評価するためのツール開発を進める方針だ。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/18 [FRI]孫正義氏 「常時ON」で社員1人当たり1000個の&quot;千手観音&quot;AIエージェントを目指す｜SoftBank World 2025</title>
      <link>https://ledge.ai/articles/softbank_world_2025_ai_agent_future</link>
      <description><![CDATA[<p>2025年7月16日、ソフトバンクグループが主催する法人を中心にしたプライベートイベント「SoftBank World 2025」が、東京都港区にて開催された。例年開催されている同イベントだが、今年は特にAI一色の構成で、とりわけ「AIエージェント」が大きく取り上げられている印象であった。特別講演には孫正義氏（ソフトバンクグループ株式会社 代表取締役 会長兼社長執行役員／ソフトバンク株式会社 創業者 取締役）が登壇、OpenAIの共同創業者であるサム・アルトマン（Sam Altman）氏もオンラインにて登場し対談を繰り広げた。</p>
<p>開催冒頭で会場にはザ・ヴェルベット・サンダウン（The Velvet Sundown）のミュージックビデオが流された。今年6月に音楽配信サービスに突如現れ、同サービス上でのリスナーは既に100万人を超えるバンドだ。このバンドは今月に入って、“実在しない”AIによるバンドであることが明かされ、話題となっている。
孫氏は自身もファンであると話しつつ「『人間がまだAIより賢い、AIにはまだ限界がある、クリエイティビティはまだ人間に残された素晴らしい機能の一つだ』とする人も多い」というよくある論調に言及しながら、直前に紹介したミュージックビデオも「AIだと言われなければ分からないような、人間と遜色ないレベルにまで達してきている」との見方を示した。さらに、「近い将来、AIが人々の色んな感情を理解し、AI自らが感情や意識に相当するようなものを持ち始めると信じている」と語り、AIへの強い期待を顕にした。</p>
<h2>AIエージェントの普及によって、これからの仕事はどう変わるのか？</h2>
<p>孫氏とアルトマン氏の対談では、AIエージェントが世の中に浸透する未来についての議論が展開された。孫氏からの5年後や10年後、30年後の未来はどうなると考えているかといった問いに対してアルトマン氏は「過去の人々も現代の働き方を完全に想像できてはいなかったはずだ」としながら「これからは確実にたくさんのAIがある世界になっていく。その中で、AIが存在しないかのように振る舞うのは大きな間違いだ」という旨の話を展開し、適応することの重要性を説いた。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/_8096e9a219/_8096e9a219.jpg" alt="文中.jpg" />
その後の孫氏による講演では、ソフトバンクグループとOpenAIらが開発・販売するエンタープライズ企業向けのカスタマイズ型AI「クリスタル・インテリジェンス」について紹介。ソフトバンクグループ内で10億ものAIエージェントを作るプロジェクト計画に触れた。社員一人あたり1000のAIエージェントを自ら作ることを号令にしていると話し、まるで「千手観音」のように一人一人がAIエージェントを活用しあらゆる業務を効率化することを目指していると語った。</p>
<p>そうした取り組みを加速する背景として、これからは多くのAIエージェントが生み出され、AIエージェント自らが思考・実行し、またエージェント同士が連携しあらゆる物事を人間が介入せずとも前に進める世界観の実現が間もないと考えていることを説明。
特に、人間が呼びかけた時にだけ稼働するタイプの従来型のAIエージェントではなく、常に稼働し続ける「常時ON」のAIエージェントがこれから主流になっていくと掲げた。これらのAIエージェントは長期に渡って記録を保持し、思考の連鎖によって物事を深く捉え、AIエージェント自体が次のAIエージェントを作り自己増殖していく、そうしたトレンドを予測しながら、ソフトバンクグループ自身が牽引役になる姿勢を示した。
「“所詮”、“どうせ”という見方でAIを評価する人や会社は、自ら進化を否定している」と強調し、AIに対する穿った見方を改めるよう観客に求めながら講演を締め括った。</p>
<h2>非エンジニアもあらゆる価値創出が可能へ</h2>
<p>続いて、ソフトバンク株式会社代表取締役社長執行役員兼CEOの宮川潤一氏が講演した。孫氏の講演を受け、ソフトバンクグループが手がけるAI関連サービスの具体について紹介した。
同社内での積極的な取り組みの一つとして、AIを核とした事業アイデアコンテストについて触れ、実際に事業化されたサービスの概要を披露した。
そのうちの一つ「satto workspace（サット ワークスペース）」は、資料作成業務を支援するエンタープライズ向け生成AIサービスだ。ユーザーがチャット形式で要件や構想の要点を入力するだけで、AIが内容を解釈して提案資料や企画書などのプレゼンテーション資料を自動生成するという。
一貫してAIがデジタル労働力として社会実装される時代が到来することを見据えた発表が続いた。</p>
<p>基調講演には、桜井勇人氏（ソフトバンク株式会社 専務執行役員）、牧園啓市氏（ソフトバンク株式会社 専務執行役員 兼 CIO）、丹波廣寅氏（SB Intuitions株式会社 代表取締役社長 兼 CEO）、砂金信一郎氏（Gen-AX株式会社 代表取締役社長 CEO）の4名が登壇。
桜井氏がオーガナイズ役を務め、3氏からそれぞれの専門に沿ったショートプレゼンテーションが披露された。丹波氏はソブリンAIとソブリンクラウドの重要性、牧園氏からは制度設計におけるガバナンス、システム連携、認証・認可、データ整備について、砂金氏からは代表を務めるGen-AX株式会社が開発するAIソリューションについてそれぞれ展開した。</p>
<h2>人類の数をAIの数が上回る時代に、経済をどう計るか？</h2>
<p>最後には、スペシャルセッションとして経済学者の成田悠輔氏が登壇。株式会社HEART CATCH 代表取締役の西村真里子氏がインタビュアーを務めた。
「AXの未来地図：AIが描く新しい経済圏」と題し、AIの急速な技術革新が経済に与える影響について多角度から論じた。今や世界的に大きな影響力を持つOpenAIも設立からまだ10年程度であること、そして彼らが開発する基盤モデルに用いられるパラメータ数は急速に膨大化していることを例に挙げながら、そのダイナミズムについて触れた。その中では直近で話題となっている「Kimi K2」についても言及。中国のAI開発企業Moonshot AIがオープンソースで公開した、総パラメータ数が1兆を超えるLLMで、一部のベンチマークでは「GPT-4.1」を上回る性能を見せたとされている。
西村氏からの“今後伸びる産業”に対しては「高齢化社会を逆手に取るような領域でのビジネス」にあるとの見解を語った。医療・介護等の、人類の長寿命化を受けた様々な課題に対応するDXは今後の伸び代があるとしながらも「スマートフォンのような操作感ではまだまだ難しすぎる。糸電話のように誰もが簡単に使えるレベルのサービスでないと真に普及しない」とユーザビリティについても触れながら自身の考えを示した。
最後に、最も重要なのは人口の問題であると提言。これからの社会は人口が減少していく中で、AIエージェントが増加していく。そしてエージェント同士が連携し、ある種のAIエージェントの世界ができる。その中で生み出される富を、これまでの人類の経済の尺度で計ることが果たして本当に適切であるのかどうか。このことについての結論はまだ出されていないが、これからの社会を生きる上で考えていかなければならない問いであると結んだ。</p>
<p>SoftBank World 2025で行われた全ての講演動画は同イベントの<a href="https://global.tm.softbank.jp/business/sbw/2025/?utm_source=ledgeai">サイト</a>から登録することで8月29日までオンデマンドで視聴できる。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI、AIポルノ生成を全面禁止へ──7月31日から利用規約改定、Stable Diffusion・API・OSSを含む全サービスで性的コンテンツを遮断</title>
      <link>https://ledge.ai/articles/stability_ai_policy_update_nsfw_ban</link>
      <description><![CDATA[<p>ロンドンを拠点とする生成AI企業Stability AIは、2025年7月31日付で同社サービスの利用規約（Acceptable Use Policy, AUP）を<a href="https://stability.ai/use-policy">改定</a>し、Stable Diffusionをはじめとする自社製AIモデル・API・オープンソースコードにおいて、性行為に関連するコンテンツの生成・使用を一律禁止する。</p>
<p>営利・非営利の区別なく適用されるこの新方針は、AIコンテンツの安全性と倫理性を確保する目的で導入されるという。</p>
<h2>性的コンテンツの生成・共有を包括的に禁止</h2>
<p><a href="https://stability.ai/use-policy">新たな利用規約</a>では、「We Prohibit Sexually Explicit Content」の項が新設され、以下の内容が禁止事項として明記された。</p>
<ul>
<li>性行為、性的行為、性的暴力を含むあらゆるコンテンツの生成・共有</li>
<li>非合意の親密画像（NCII: Non-Consensual Intimate Imagery）</li>
<li>違法ポルノや児童搾取コンテンツ</li>
</ul>
<p>これらの規定は、DreamStudio、Stable Diffusion（あらゆるチェックポイントや自己ホスト版）、Stable Video、Stable Audio、Platform API、LoRA（Low-Rank Adaptation）共有機能、さらにGitHubなどで配布されるオープンソースコードを含むすべてのサービスに適用される。</p>
<p>規約違反が判明した場合、Stability AIは利用停止や契約解除などの措置を取ると定めている。また、18歳未満の利用も引き続き禁止される。</p>
<h2>従来規約との大きな違い</h2>
<p>この改定は、2024年3月1日版の旧AUPと比較して大幅な変更となる。
<a href="https://stability.ai/prior-aup">従来の規約</a>では、禁止対象は「非合意ヌード」「違法ポルノ」「児童搾取コンテンツ」などに限定されており、合意の成人同士によるポルノ的表現については明確な禁止はなかった。</p>
<p>新AUPでは、「性行為そのもの」に関わるコンテンツすべてを対象とすることで、生成物の内容に関わらず包括的な制限を設けている。</p>
<h2>デベロッパーとユーザーへの影響</h2>
<p>新規約の対象範囲には、以下のような商用・非商用ツールや資源が含まれる。</p>
<ul>
<li>公式Webアプリ「DreamStudio」</li>
<li>Stable Diffusion（オープンモデル、自己ホスト含む）</li>
<li>音声・映像生成ツール（Stable Audio／Stable Video）</li>
<li>各種APIアクセス、LoRAモデル共有、オープンソースコードの再利用</li>
</ul>
<p>営利・非営利の区別はなく、個人利用や趣味での創作であっても規約違反となる。既存のモデルやワークフローで対象となるコンテンツを扱っている開発者や企業は、今後の運用方針の見直しが必要となる。</p>
<h2>背景：AIポルノをめぐる規制の強化</h2>
<p>今回の規約改定は、AI技術を悪用した性的コンテンツの氾濫に対処する国際的な動きの一環と見られる。特にディープフェイク技術による著名人の偽ポルノ動画や、非合意の画像生成が社会問題化する中で、生成AIモデル各社はNSFW（Not Safe For Work）フィルタの強化やアダルトコンテンツの禁止に取り組んでいる。</p>
<p>Stability AIはオープンウエイトの提供で知られる企業のひとつであり、同社による包括的な制限の導入は、オープンモデル領域における規制の方向性に大きな影響を与える可能性がある。</p>
<h2>今後のスケジュールと対応</h2>
<p>新規約は2025年7月31日より施行される。以降は新規・既存ユーザーともに順守が義務づけられ、違反が確認された場合にはアクセスの遮断やアカウントの停止措置が取られる見通しだ。</p>
<p>同社は今後、利用者向けのFAQやガイドラインの公開も予定しており、具体的な基準や判断基準についての詳細は順次明らかにされるとみられる。</p>
]]></description>
      <pubDate>Sat, 19 Jul 2025 02:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AIが11歳の作文から22年後の最終学歴と能力を高精度予測──Nature系誌が報告</title>
      <link>https://ledge.ai/articles/ai_predicts_future_education_from_childhood_essay</link>
      <description><![CDATA[<p>2025年7月3日、Nature系列の学術誌『Communications Psychology』に掲載された研究によると、11歳児が授業で書いた約250語の作文を大規模言語モデル（LLM）で分析することで、22年後の最終学歴や認知・非認知能力を高精度で予測できることが<a href="https://www.nature.com/articles/s44271-025-00274-x">明らかになった</a>。</p>
<p>英国で1958年に生まれた約1万人を追跡する縦断研究のデータを用い、GPT-3.5による文章埋め込みと機械学習を組み合わせた予測モデルは、教師による評価とほぼ同等の精度を達成したという。</p>
<h2>従来の予測手法の限界</h2>
<p>これまでの研究では、社会調査データや遺伝情報を用いた将来予測の精度には限界があった。2020年に米国で実施された「Fragile Families Challenge」では、160の研究チームが1万2942項目の社会調査データを活用したが、中学生時点の成績（GPA）の予測精度は約20％にとどまった。</p>
<p>一方、トランスフォーマー型のLLMの発展により、文章から個人の能力や性格傾向を高精度に捉える可能性が注目されている。本研究は、短い作文が将来をどの程度予測できるかを実証的に検証した。</p>
<h2>研究の概要：1958年英国出生コホートデータを活用</h2>
<p>研究に用いられたのは、1958年に英国で生まれた1万7415人を追跡する「National Child Development Study（NCDS）」のデータである。参加者が11歳の時点で「25歳の自分を想像して」という課題で書いた作文（1～1239語、平均約250語）を分析対象とした。
研究チームは以下の手法で作文を分析した：</p>
<ul>
<li>OpenAIのtext-embedding-ada-002モデルによる1536次元の文章埋め込み</li>
<li>534項目の言語的特徴（語彙の多様性、洗練度、感情表現）</li>
<li>31種類の読みやすさ指標</li>
<li>文法・スペルミスの比率</li>
</ul>
<p>これらの特徴量を、11歳時点の教師による評価22項目、33種類のポリジーンスコア（遺伝的指標）と組み合わせ、アンサンブル学習手法「SuperLearner」で予測モデルを構築した。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/44271_2025_274_Fig1_HTML_539bc4fa53/44271_2025_274_Fig1_HTML_539bc4fa53.png" alt="44271_2025_274_Fig1_HTML.png" /></p>
<h2>予測精度：AIと教師評価がほぼ同等</h2>
<p>分析の結果、作文のみでも高い予測精度が得られた。11歳時点の能力予測では以下の精度（R²値）を達成した：</p>
<ul>
<li>読解力：作文分析 0.59、教師評価 0.57</li>
<li>言語能力：作文分析 0.55、教師評価 0.57</li>
<li>数学的能力：作文分析 0.55、教師評価 0.57</li>
<li>非言語能力：作文分析 0.37、教師評価 0.45</li>
</ul>
<p>33歳時点の最終学歴の予測精度は、作文分析が0.26、教師評価が0.29、遺伝情報が0.19となった。作文・教師評価・遺伝情報をすべて統合したモデルでは、最終学歴の予測精度が0.38に達した。
特に認知能力の予測では、3つの情報源を統合したモデルの精度が0.70に達し、標準的な知能検査の再検査信頼性に迫る水準となった。</p>
<p><strong>認知能力（11歳時点）と最終学歴（33歳時点）に対する各予測モデルおよびその組み合わせの精度比較</strong> ：3つの情報源（作文、教師評価、遺伝情報）をすべて統合したモデルは、認知能力で0.70、最終学歴で0.38という高い予測精度を達成。単独の予測手法と比較して、統合による相乗効果が確認された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/cognitive_and_not_cognitive_abilities_066c248f61/cognitive_and_not_cognitive_abilities_066c248f61.jpg" alt="cognitive and not cognitive abilities.jpg" /></p>
<h2>GPT埋め込みが予測精度の大部分を担う</h2>
<p>研究チームは、予測モデルの各要素の貢献度を分析した。その結果、1536次元のGPT埋め込みが予測精度の大部分を担っていることが判明した。</p>
<p><strong>作文から抽出した各種特徴量による認知能力・非認知能力の予測精度</strong>  赤：文法・スペルミス、オレンジ：読みやすさ指標、黄：言語的特徴（語彙多様性・洗練度・感情表現）、緑：埋め込み以外の全特徴、青：GPT-3.5埋め込み、紫：全特徴の統合。GPT埋め込みが予測精度の向上に最も貢献していることが分かる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Prediction_of_highest_attained_education_e29b74bcc0/Prediction_of_highest_attained_education_e29b74bcc0.jpg" alt="Prediction of highest attained education.jpg" /></p>
<p>従来の読みやすさ指標や文法的特徴のみでは、作文の長さのみを用いた予測と比べて5～10倍程度の改善にとどまったが、GPT埋め込みを追加することで大幅な精度向上が見られた。</p>
<h2>他の予測要因との比較</h2>
<p>研究では、教育達成度の予測において一般的に用いられる他の要因とも比較を行った：</p>
<p><strong>33歳時点の最終学歴に対する各予測モデルの精度比較</strong> ：従来の予測要因（出生時体重、身長、社会学的モデル）と比較して、作文・教師評価・遺伝情報を統合したモデルは大幅に高い予測精度（R²=0.38）を達成した。エラーバーは交差検証における最小・最大値を示す。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/A_model_containing_all_three_information_sets_d4cce493ba/A_model_containing_all_three_information_sets_d4cce493ba.gif" alt="A model containing all three information sets.gif" /></p>
<ul>
<li>両親の教育水準：予測精度 0.12</li>
<li>出生時体重：予測精度 0.01</li>
<li>身長：予測精度 0.03</li>
<li>社会経済的背景を含む従来の社会学的モデル：予測精度 0.18～0.19</li>
</ul>
<p>これらと比較して、作文分析による予測は大幅に高い精度を示した。</p>
<h2>研究の限界と今後の課題</h2>
<p>研究チームは、以下の限界を指摘している：</p>
<ol>
<li><strong>一般化可能性</strong> ：サンプルは1958年に英国で生まれた世代に限定されており、現代の児童や他の文化圏への適用可能性は未検証</li>
<li><strong>因果関係</strong> ：予測の成功は、作文と結果の間の関連性を示すが、その背後にあるメカニズムは不明</li>
<li><strong>技術の進歩</strong> ：より新しいLLMモデルや、より洗練された遺伝的予測手法を用いれば、さらなる精度向上の可能性がある</li>
<li><strong>倫理的配慮</strong> ：予測技術の教育選抜や信用評価への応用には、偏見の固定化や自己成就的予言のリスクがあり、慎重な議論が必要</li>
</ol>
<h2>研究の意義</h2>
<p>この研究は、適切なデータと手法を用いれば、人間の将来をある程度予測可能であることを示した。これは「人間の生活は本質的に予測不可能」とする従来の見解に再考を促すものといえる。同時に、AIによるテキスト分析が教師評価に匹敵する精度を持つことから、教育現場における「第3の評価視点」として活用できる可能性を示唆している。ただし研究チームは、これらの予測はあくまで教育支援のための参考情報として用いるべきであり、決定的な選別の根拠とすべきではないと強調している。</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI、「ChatGPT agent」を発表──仮想PC上でAIが自律的に業務遂行、Pro／Plus／Team利用者に提供開始</title>
      <link>https://ledge.ai/articles/openai_chatgpt_agent_virtual_pc_automation</link>
      <description><![CDATA[<p>OpenAIは2025年7月17日（米国時間）、ChatGPTにおいて、新機能「ChatGPT agent」の提供開始を<a href="https://openai.com/ja-JP/index/introducing-chatgpt-agent/">発表</a>した。</p>
<p>これは、仮想コンピュータ上でChatGPTがウェブブラウジングやファイル編集、スケジュール作成といった一連のタスクを自律的に実行するもので、従来の「deep research」「Operator」の機能と統合された形で動作する。まずは英語UIを用いるChatGPTのPro、Plus、Teamプラン利用者を対象に提供され、順次Enterpriseや教育機関向けの拡大が予定されている。
@<a href="https://www.youtube.com/watch?v=1jn_RpbPbEc">YouTube</a></p>
<h2>仮想コンピュータで複数タスクを自動処理</h2>
<p>ChatGPT agentは、AIが仮想PC上で実際の操作環境を用い、ユーザーの目的達成まで複数のアプリケーションやツールを横断的に操作する。たとえば、Googleカレンダーで日程を調整し、OpenTableでレストランを予約するといった一連の作業を、ユーザーの指示に基づきAIが代行する。メールの下書き作成、スプレッドシートの整理、コードの実行やファイル変換といった業務も対象となる。</p>
<p>この環境はユーザーごとに隔離された仮想的な計算空間であり、AIが自らターミナル、ブラウザ、文書作成ソフトなどを使ってタスクを処理する構成になっている。</p>
<h2>「deep research」と「Operator」機能を統合</h2>
<p>今回の新機能は、OpenAIがこれまで実装してきた2つのツール、「deep research」と「Operator」に加え、新たなエージェント基盤を組み合わせた点が特徴である。</p>
<ul>
<li>「deep research」は、アップロードされたファイルやウェブページを高速かつ精緻に読み取り、要点を抽出・要約するリサーチ特化型機能。</li>
<li>「Operator」は、フォーム入力やメール送信、外部アプリの制御など“行動”の自動化に適したツール群。</li>
</ul>
<p>ChatGPT agentはこれらの機能を組み合わせ、状況に応じて最適な処理を自律的に選択・実行する設計となっている。</p>
<h2>安全性確保のための仕組みも導入</h2>
<p>OpenAIは本機能の公開にあたり、ユーザーの許可なしに実行されるリスクのある操作について制限を設けている。たとえば、金銭の送金、ファイルの削除、ECサイトでの購入といった不可逆操作はすべてユーザーの明示的な承認が必要とされる。さらに、投資、暗号資産取引、医療・法律・健康に関する判断は対応外となっている。</p>
<p>また、AIの意思決定過程やリスクの特性については、同社が公開する「システムカード」によって透明性を確保している。これには人間によるフィードバック（RLHF）に基づいたチューニングや、セーフティ・レールの設計方針が含まれている。</p>
<h2>今後の展開</h2>
<p>ChatGPT agentは英語UIにおいて、7月17日よりPro、Plus、Teamユーザー向けに順次展開されている。Enterpriseや教育機関向けプラン、欧州経済領域（EEA）での提供は「規制要件を満たし次第」開放されるとしている。</p>
<p>今後は、開発者向けにエージェント機能を呼び出せる「Agent API」や、ユーザーが独自にツールを登録・共有できる「Marketplace」の構想も示されており、年内にもさらなる拡張が計画されているという。</p>
<p>今回の発表は、急速に拡大するAIエージェント市場におけるOpenAIの戦略的な一手とみられている。同様の機能はAnthropicが「Claude Team Agent」、Googleが「Gemini Agents」、Metaが「AI Studio Bots」として展開を開始しており、各社が“リサーチとアクションの統合”を軸に差別化を図っている。OpenAIは、これまで研究開発を重視してきた姿勢を維持しつつ、実務への応用性を高める方向に舵を切った形だ。</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 07:50:00 GMT</pubDate>
    </item>
    <item>
      <title>米国防総省、Anthropic・Google・OpenAI・xAIに各2億ドル──フロンティアAIを“エージェント化”し全軍ミッションを強化</title>
      <link>https://ledge.ai/articles/dod_frontier_ai_partnerships_2025</link>
      <description><![CDATA[<p>2025年7月14日、米国防総省の最高デジタル・人工知能局（Chief Digital and Artificial Intelligence Office: CDAO）は、先進AI技術の導入を加速するため、Anthropic、Google、OpenAI、xAIの4社とそれぞれ最大2億ドル規模の契約を締結したと<a href="https://www.ai.mil/Latest/News-Press/PR-View/Article/4242822/cdao-announces-partnerships-with-frontier-ai-companies-to-address-national-secu/">発表</a>した。</p>
<p>契約の目的は、各社のフロンティアAIを活用し、エージェントベースのAIワークフロー（agentic AI workflows）を様々な軍事・非軍事ミッションに統合することで、DoDのデジタル変革と国家安全保障対応能力を強化する点にあるという。CDAOはこの契約を通じ、先端商用技術をいち早く軍に取り込む「commercial-first」戦略を推進するとしている。</p>
<p>契約は、バージニア州アーリントンに本拠を置くCDAOが管轄する「Task Order under Tradewind OTA（Other Transaction Authority）」スキームを用いて実施された。各社に付与される契約上限額は2億ドルであり、支払いは段階的な成果に応じて行われる。</p>
<p>対象企業となるAnthropic・Google・OpenAI・xAIの4社はいずれも「フロンティアAI企業（frontier AI companies）」に分類され、数十億パラメータ規模の大規模言語モデル（LLM）を開発・運用している。CDAOはこれらの技術を通じて、「現場での意思決定支援」「戦略分析」「作戦計画」「データ統合」といった多様な軍務領域でAIの活用を進める方針だ。</p>
<p>今回のパートナーシップでは、すでにCDAOが導入を進めている複数のAIプラットフォームとの連携も見込まれている。具体的には、以下のような基幹技術への統合が明記されている。</p>
<ul>
<li>「Ask Sage」と呼ばれるEnterprise LLM Workspace（大規模言語モデルによる業務支援環境）</li>
<li>統合分析基盤「Advana」</li>
<li>映像解析AI「Project Maven Smart System」</li>
<li>前線データ連携基盤「Edge Data Mesh」</li>
</ul>
<p>これにより、データ収集から意思決定までのプロセスを自動化・高速化し、現場の判断能力や作戦遂行能力の向上が期待されている。また、調達面では連邦政府の調達総局（GSA）と連携し、AI推論のための計算資源（AI compute）を共通調達枠から供給する計画も進行中とされる。</p>
<p>CDAOの責任者であるDoug Matty氏は、今回の提携について「AI技術は戦闘員の支援能力を根本から変革し、米国の戦略的優位性を確保する上で不可欠である」と述べている。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Fri, 18 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/17 [THU]中国スタートアップMoonshot AI、1兆パラメータの新LLM「Kimi K2」をオープンソースで公開──長文推論とコード生成でGPT-4系に迫る性能</title>
      <link>https://ledge.ai/articles/kimi_k2_release_moonshot_ai</link>
      <description><![CDATA[<p>北京に拠点を置くスタートアップ企業Moonshot AIは2025年7月12日、新たな大規模言語モデル「Kimi K2」をオープンソースで<a href="https://moonshotai.github.io/Kimi-K2/">公開</a>した。</p>
<p>同モデルは、総パラメータ1兆、アクティブパラメータ320億のMixture-of-Experts（MoE）構造を採用し、コード生成や長文推論、外部ツールとの統合といった用途に特化している。Apache 2.0互換のライセンスでGitHubおよびHugging Faceを通じて配布されており、商用利用も可能となっている。同社はこの公開を通じて、急速に成長する中国国内のオープンソースLLM競争での巻き返しを狙う。</p>
<h2>1兆パラメータのMixture-of-Experts構造を採用</h2>
<p>Kimi K2は32の専門家レイヤー（experts）から成り、推論時にはそのうち2つのみを活性化することで、GPUリソースの消費を抑えつつ高性能を実現している。モデルの学習には同社が開発した最適化アルゴリズム「Muon Optimizer」が使用されており、推論にはNVIDIA A100（40GB）相当のGPU1枚で対応可能とされている。</p>
<p>また、日本語や英語を含む多言語に対応し、最大20万トークンの長文入力が可能であるなど、ドキュメント要約や長文分析といった用途にも適しているという。同社は Kimi K2を「エージェント的知能（Agentic Intelligence）」の土台として位置付けており、複雑なタスクの分解やツール操作といった処理能力に重点を置いている。</p>
<h2>コード生成と数学推論でGPT-4.1を上回るベンチマーク結果</h2>
<p><a href="https://huggingface.co/moonshotai/Kimi-K2-Base">Hugging Faceのモデルカード</a>にて同社が公開したベンチマーク結果によれば、Kimi K2は以下の項目でGPT-4.1（2025年5月時点のプレビュー版）を上回るか、同等の性能を示したという。</p>
<ul>
<li>LiveCodeBench v6（Pass@1）：53.7%（GPT-4.1は44.7%、DeepSeek-V3は46.9%）</li>
<li>SWE-bench Verified（単一試行・Agentic Coding）：65.8%（GPT-4.1は54.6%）</li>
<li>MATH-500 Accuracy：97.4%（GPT-4.1は92.4%）</li>
<li>MMLU（Exact Match）：89.5%（GPT-4.1は90.4%と同等水準）</li>
</ul>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/collage_kimi2_bench_d13b3abdd9/collage_kimi2_bench_d13b3abdd9.jpg" alt="collage kimi2 bench.jpg" /></p>
<p>これらのスコアは、特にコーディングと数理分野での推論能力において、Kimi K2が最先端のLLMと競合しうることを示すものとされる。ただし、一般的な自然言語処理性能や創造的文章生成といった領域に関する評価はまだ限定的である。</p>
<h2>オープンソース戦略と今後の展開</h2>
<p>Kimi K2は、Apache 2.0互換ライセンスで商用利用が認められており、GitHubとHugging Face上でモデル重みと推論スクリプトが公開されている。さらに今後、4bitおよび8bitの量子化版、LoRAによるファインチューニングレシピ、学習済みエージェント機構の導入例などの公開も予定されている。</p>
<p>2024年後半からユーザー数が減少傾向にあった対話アプリ「Kimi」の再成長を後押しする狙いもあり、同社は、Kimi K2の性能を活かしたエンタープライズ向けAPIの提供を2025年第4四半期に計画しているとしている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>「一度公開すれば取り戻せない」──OpenAI、オープンウェイトモデルのリリースを無期限延期</title>
      <link>https://ledge.ai/articles/openai_open_weight_model_launch_delayed</link>
      <description><![CDATA[<p>OpenAIのCEOであるサム・アルトマン氏は2025年7月12日、自身のX（旧Twitter）アカウントを通じて、翌週に予定していた新たな大型言語モデル（LLM）のリリースを延期すると<a href="https://x.com/sama/status/1943837550369812814">発表</a>した。</p>
<p>対象となるのは、モデルの重み（weights）を一般に公開する「オープンウェイトモデル」であり、安全性に関する追加テストと高リスク領域の精査が必要となったためとしている。新たな公開日程は現時点で明らかにされていない。</p>
<p>アルトマン氏は投稿の中で「一度公開すれば取り戻せない。これは我々にとって新しいことであり、正しく対処したい」と述べ、重みの公開が持つ不可逆性に対する慎重な姿勢を示した。さらに、「悪いニュースを伝えることになってしまい申し訳ない。我々は非常に懸命に取り組んでいる」として、延期は開発チームの責任ある判断であることを強調した。</p>
<p>この「オープンウェイトモデル」は、OpenAIにとって初めての、重みを含めて一般公開するLLMとなる見込みだった。従来のGPT-3.5やGPT-4は、API経由での提供に限定されており、モデルの内部構造やパラメータは非公開だった。一方で今回のモデルは、利用者がローカル環境での実行やカスタマイズを可能にする“オープンアクセス”型であり、企業や研究者の関心を集めていた。</p>
<p>背景には、安全性への懸念がある。重みが公開されれば、第三者によるモデルの再利用や改変が可能になるため、不正利用や誤情報の生成といったリスクが生じる。特に、ハルシネーション（事実に基づかない出力）や有害な出力への対策が不十分なまま公開すれば、被害が広範囲に及ぶおそれがある。アルトマン氏も「追加の安全テストと、高リスク領域の見直しが必要だ」と投稿の中で明記しており、慎重な検証が行われる見通しである。</p>
<p>同モデルは当初、2025年6月中の<a href="https://ledge.ai/articles/openai_open_weight_model_2025">リリースが計画されていた</a>
が、7月第2週に延期されたのち、今回の発表で無期限延期となった。今後の対応方針や公開時期に関しては、OpenAIからの追加の発表が待たれる状況である。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/2_Zs_Mux_Y_50f7cb832c/2_Zs_Mux_Y_50f7cb832c.jpg" alt="2Zs-MuxY.jpg" /></p>
<p>近年、Metaの「Llama 2」や「Llama 3」、Mistralの「Mixtral」など、オープンウェイトモデルは業界内で広がりを見せている。こうしたモデルは、企業が独自のAIアプリケーションを開発する上で基盤として活用されており、今後OpenAIが同分野にどう参入していくかが注目されている。</p>
]]></description>
      <pubDate>Thu, 17 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>Google Cloud、米西海底ケーブル「Sol」でフロリダ―スペインを直結──AI時代に備え大西洋ルートを刷新</title>
      <link>https://ledge.ai/articles/google_sol_transatlantic_cable_2025</link>
      <description><![CDATA[<p>Google Cloudは2025年7月10日、フロリダ州パームコーストとスペイン・サンタンデールを結ぶ新たな大西洋横断海底ケーブル「Sol（ソル）」の敷設計画を<a href="https://cloud.google.com/blog/products/infrastructure/announcing-sol-transatlantic-cable?hl=en">発表</a>した。AI需要の高まりに伴うクラウドトラフィックの急増に対応するため、Google独自のネットワークインフラをさらに強化するもので、経由地としてバミューダ諸島およびアゾレス諸島も含まれる。</p>
<p>同社は、既存の「Nuvem」や「Grace Hopper」との多重化により、北米―欧州間の通信において高いレジリエンシー（耐障害性）と低遅延を同時に実現する狙いだ。</p>
<h2>Googleが敷設する18本目の海底ケーブル</h2>
<p>Sol は、Googleにとって18本目となる自社単独または共同敷設の海底ケーブルで、光ファイバーによる総延長は約6,300kmに及ぶ見込みだ。スペイン語やポルトガル語で「太陽」を意味する「Sol」という名称は、温暖な気候にケーブルシステムの着床地点があることに由来するという。プロジェクトの建設は2025年後半に開始され、数年以内の運用開始を目指す。</p>
<h2>北米―欧州を結ぶ新ルート、フロリダからの初直結</h2>
<p>同プロジェクトの特徴は、米国東海岸の中でもフロリダ州を起点とする点にある。これまでGoogleの大西洋横断ケーブルは、主にニューヨークなど北部沿岸を起点としていたが、Sol は同社初の “フロリダ―欧州” 直結ケーブルとなる。フロリダ州パームコーストに陸揚げ局を設け、スペイン・カンタブリア州サンタンデールに到達。経由地としてアゾレス諸島およびバミューダ諸島にも接続することで、既存のNuvemケーブルとのネットワーク補完性を高める設計となっている。</p>
<p><strong>Nuvem海底ケーブルルート</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/The_Nuvem_subsea_cable_route_02f8293dda/The_Nuvem_subsea_cable_route_02f8293dda.jpg" alt="The Nuvem subsea cable route.jpg" /></p>
<h2>Nuvem、Grace Hopperとの冗長化構成を構築</h2>
<p>Googleは2023年に発表した南ルートの「Nuvem」および、北ルートの「Grace Hopper」（ニューヨーク―ビルバオ）と連携させることで、3系統のルートによるネットワークの多重冗長化を図る。特に「Sol」と「Nuvem」は、陸揚げ地点を一部共有し、障害発生時には瞬時に通信を切り替えられる構成とすることで、トラフィックの安定供給を実現する。また、経由地であるアゾレス・バミューダ間の接続によって、同社ネットワークの欧州・アフリカ・中南米への接続性も強化される。</p>
<h2>地域インフラへの波及効果</h2>
<p>陸揚げ地点であるスペイン・サンタンデールでは、Telefónica系インフラ企業Telxiusが地元の陸揚げ局を運営する予定で、北スペイン地域のデジタル化推進や経済活性化が期待されている。一方、パームコーストではGoogleが新たな接続拠点（Point of Presence：PoP）を設置し、フロリダ州内外のデータセンター群への高速接続網を形成する計画だ。</p>
<h2>AI時代のトラフィック増加に備えたネットワーク投資</h2>
<p>ChatGPTをはじめとする生成AIの普及や、企業によるクラウドサービスの依存度の高まりにより、グローバルインターネットトラフィックは急増を続けている。Google Cloudでは、42のクラウドリージョンを運用し、各地のAIワークロードやデータベース、ストレージ需要に応える形で、海底ケーブル網の整備を推進している。特に、データ処理のボトルネックとされる「帯域確保」と「低遅延ルート」の確保は、AIサービスの安定運用に直結する課題となっている。</p>
<h2>今後のスケジュールと展望</h2>
<p>「Sol」の建設開始は2025年後半とされており、Googleは「数年以内の運用開始」を予定している。完成後は、Google Cloudの欧州・南米間の接続性にも波及効果が期待されており、生成AIやクラウドインフラに対する今後の需要拡大に向けた長期的インフラ投資の一環と位置づけられている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>AWS、仕様駆動型AI IDE「Kiro」を正式発表──“プロンプトから本番まで”エージェントが伴走</title>
      <link>https://ledge.ai/articles/aws_ai_ide_kiro_release</link>
      <description><![CDATA[<p>Amazon Web Services（AWS）は2025年7月14日、AIエージェントを中核に据えた新しい統合開発環境（IDE）「Kiro（キロ）」を<a href="https://aws.amazon.com/jp/blogs/news/introducing-kiro/">発表</a>した。</p>
<p>Kiroは、開発初期の曖昧なアイデアを、プロンプト1つで本番環境レベルのコードへと変換することを狙ったツールだ。プロダクト開発における「仕様と実装の乖離」問題に対処するため、仕様駆動型の設計支援機能を搭載しているという。現在パブリックプレビュー中で、<a href="https://kiro.dev">公式サイト</a>から無料でダウンロード可能となっている。</p>
<h2>AIエージェントを前提とした“Agentic IDE”</h2>
<p>Kiroは「Agentic IDE（エージェント的なIDE）」を掲げ、AIが設計からコーディング、テスト、ドキュメント生成に至る開発プロセス全体を支援する。OSS版Visual Studio Code（Code OSS）をベースとしており、既存のVS Code拡張機能やOpen VSXレジストリの資産をそのまま活用できる。</p>
<p>デスクトップアプリとして提供され、Mac・Windows・Linuxに対応している。ユーザーはGitHubやGoogleアカウントなどを用いたSSO（シングルサインオン）でログイン可能だ。</p>
<p><strong>AWSが取り組んでいるeコマースアプリの例</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/compressed_1_app_72308f4e1e/compressed_1_app_72308f4e1e.gif" alt="compressed_1-app.gif" /></p>
<p>Kiroの中心的な機能は、自然言語による単一プロンプトを出発点として、要件定義（Requirements）、設計ドキュメント（Design）、およびタスクリスト（Task List）を自動的に生成する「Spec-Driven Development（仕様駆動開発）」にある。</p>
<p>これにより、開発者は「こんなアプリを作りたい」という抽象的な構想を与えるだけで、仕様に基づいたタスクが提示され、コード実装を進めやすくなるという。</p>
<p><strong>Kiroの要件仕様</strong>
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/compressed_2_reqs_f094da7ae6/compressed_2_reqs_f094da7ae6.gif" alt="compressed_2-reqs.gif" /></p>
<h2>仕様とコードの断絶を埋めるEARS記法と「Hook」</h2>
<p>Kiroは仕様記述にEARS（Easy Approach to Requirements Syntax）という形式を採用しており、要件の明確化とエッジケースの網羅性を重視している。これにより、曖昧な記述による実装ミスや意図の取り違えを最小限に抑える狙いがある。</p>
<p>さらに、Kiroは「Hook」と呼ばれるイベント駆動型の自動処理機能を搭載しており、ファイルの保存、生成、削除、Gitへのコミットなどのタイミングで、以下のような処理が自動的に実行される：</p>
<ul>
<li>ユニットテストの自動更新</li>
<li>コードドキュメントの生成</li>
<li>認証情報やシークレットの漏洩チェック</li>
</ul>
<p>これにより、開発者は品質管理やセキュリティの担保をエージェントに任せ、コアな開発作業に集中できるようになる。</p>
<h2>外部モデル接続と拡張性</h2>
<p>KiroはModel Context Protocol（MCP）にも対応しており、AWSが提供する大規模言語モデル（LLM）だけでなく、Anthropic Claudeやその他の外部LLM、外部APIツールとも連携できる。これにより、プロジェクトに応じて最適なAIエージェント群を構成する柔軟性を備えている。</p>
<p>また、MCPの採用により、複数のAIエージェントをプロジェクト横断で統制し、コード生成のコンテキストを維持したままやり取りができる設計になっている。</p>
<p>Kiroは現時点ではパブリックプレビューとして無料提供されており、年内には有償プラン（月額19.99ドル）を導入予定だという。正式版ではLLMへの問い合わせ回数に応じた制限や追加機能の提供が計画されているとのこと。</p>
<p>開発支援に特化したAIアシスタントとしては、AWSはすでに「Amazon Q Developer」を提供しているが、Kiroはこれとは異なり、プロジェクト全体を見渡しながら構造化された開発支援を行う点で明確に差別化されている。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 08:50:00 GMT</pubDate>
    </item>
    <item>
      <title>荷物運搬を完全自動化　川崎重工のロボットポーター「FORRO」、三田ガーデンヒルズで国内最長6.6 kmルートを稼働開始</title>
      <link>https://ledge.ai/articles/robot_porter_forro_mita_kawasaki</link>
      <description><![CDATA[<p>川崎重工業は2025年7月7日、三井不動産レジデンシャルおよび三菱地所レジデンスが東京都港区にて共同開発した分譲マンション「三田ガーデンヒルズ」において、屋内配送用サービスロボット「FORRO（フォーロ）」を活用したロボットポーターサービス「FORRO PORTER」の本格稼働を開始したと<a href="https://forro-service.com/news/7BL7Bn9i7QBpNT2VbkcTiT/">発表</a>した。ロボットがマンション内で荷物を居住者の住戸前まで自動搬送するサービスで、延べ約6.6 kmに及ぶ館内ルートを4台のロボットが自律走行するという国内最大規模の導入例である。</p>
<p>@<a href="https://www.youtube.com/watch?v=tY46sRuFeSY">YouTube</a></p>
<h2>住戸前まで荷物を届けるロボットポーター</h2>
<p>FORRO PORTERは、マンションのエントランスに設置された専用ロッカーから、居住者の荷物を各住戸前まで搬送するロボットサービス。利用者はスマートフォンアプリや美和ロックの「ラクセスキー」から搬送を依頼でき、ロボットは館内のエレベーターやオートドアと連携しながら無人で目的地まで走行する。最大30kgまでの荷物を運べるほか、跳ね上げ式荷棚を採用しキャリーケースなどの積載にも対応しているという。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kawasaki_forro_mitsuigarden2_7e5b093c9a/kawasaki_forro_mitsuigarden2_7e5b093c9a.jpg" alt="kawasaki forro mitsuigarden2.jpg" /></p>
<h2>館内ルートは国内最長の6.6km、4台体制で稼働</h2>
<p>同サービスでは、ロボット4台が常時稼働し、館内の総延長約6.6kmにおよぶ移動ルートを活用して配送を行う。エントランスから住戸前までの全工程を無人で完結でき、これは日本国内で稼働する住居向けロボットポーターサービスとしては最大規模にあたるという。</p>
<p>各ロボットの動作は、大成建設が開発したロボット統合管制プラットフォーム「RoboHUB（ロボハブ）」を通じて遠隔監視され、セキュリティシステムと連動した高い安全性が確保されている。</p>
<h2>試験運用で高いリピート率、住民サービス向上へ</h2>
<p>FORRO PORTERは、2025年3月から三田ガーデンヒルズで先行して試験運用されており、期間中はポーターサービスの全依頼のうち20％以上がロボットによって担われたという。さらに、リピート利用率は50％を超える実績があり、居住者にとって利便性の高いサービスであることが示された。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/kawasaki_forro_mitsuigarden3_02db361826/kawasaki_forro_mitsuigarden3_02db361826.jpg" alt="kawasaki forro mitsuigarden3.jpg" /></p>
<h2>病院から住宅へ、川崎重工のロボット展開が拡大</h2>
<p>FORROは、もともと川崎重工が医療施設向けに開発した屋内搬送用ロボットで、これまでに病院での使用実績がある。今回の住宅分野への本格導入により、生活空間における物流の自動化という新たな領域への展開が進められたかたちだ。川崎重工は今後、住宅や商業施設など他分野への展開を視野に入れていると見られる。</p>
<h2>他ロボットとの連携も視野に</h2>
<p>三田ガーデンヒルズでは、将来的に清掃や警備など、他用途のロボットとの連携も計画されており、RoboHUBを中核としたロボット協働環境の構築が進められている。ロボットが日常的にマンションの中で稼働し、人の作業を支える仕組みが現実となりつつある。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 05:50:02 GMT</pubDate>
    </item>
    <item>
      <title>【視聴無料】“プロンプトの先”を知る──生成AI活用の真価を引き出すコンテキストエンジニアリングとは何か？</title>
      <link>https://ledge.ai/articles/webinar_about_context_engineering</link>
      <description><![CDATA[<p>生成AIの普及とともに、多くの現場で注目されたのが「プロンプトエンジニアリング」でした。ChatGPTに対して“うまく指示を出す方法”が話題となり、良い出力を得るための言い回しや構文テクニックが盛んに共有されてきました。</p>
<p>そうした中、2025年6月30日にGoogle DeepMindのシニアAIリレーションエンジニア、フィリップ・シュミット（Philipp Schmid）氏が発表したブログ記事が大きな注目を集めました。</p>
<p>\u003E「AIにおける最も重要なスキルはプロンプトエンジニアリングではなく“コンテキストエンジニアリング”である」</p>
<p>大規模言語モデル（LLM）の性能を最大限に活かすには、単一のプロンプトでは不十分であり、AIに与える文脈情報の設計が不可欠であるという提言です。</p>
<p>今回のウェビナーでは、新注目のキーワード「コンテキストエンジニアリング」の理解に向けて解説します。</p>
<h2>ウェビナー概要</h2>
<p><strong>\u003Cセッション内容（予定）\u003E</strong></p>
<ul>
<li>プロンプトエンジニアリングの限界</li>
<li>新注目のキーワード「コンテキストエンジニアリング」とは？</li>
<li>コンテキストエンジニアリングを支える技術群</li>
<li>業務活用・導入の最初の一歩はどこから進めるべきか？</li>
</ul>
<p><strong>開催概要</strong>
日時：2025年7月22日（火）11:00〜12:00
形式：Zoom Webinar（事前登録制・参加無料）
主催：株式会社レッジ</p>
<p>:::button
<a href="https://us02web.zoom.us/webinar/register/WN_v-lGUvYEQjSm5j5_tUSOMg">視聴申込みはこちら</a>
:::</p>
<h2>ウェビナーの学びを“実践”に変えるために──レッジが提供する実践型研修ラインナップ</h2>
<p>ウェビナーで得た知識を、「なるほど」で終わらせず、実際に社内業務への浸透を進めていくために、レッジでは、生成AI活用を実務に落とし込む研修プログラムを各種ご提供しています。
助成金の適用や社内事情に合わせたカスタマイズも可能で、社内への定着と人材育成をセットで支援します。</p>
<h3><strong>生成AI × マーケティング研修（助成金適用で最大75%OFF）</strong></h3>
<ul>
<li>座学と実践演習で構成された3日間、合計15時間の研修パッケージ</li>
<li>マーケ業務（リサーチ→分析→企画→制作）における生成AIの活用術を紹介</li>
<li>人材開発支援助成金制度により、受講費用の最大75%の助成適用</li>
</ul>
<p><strong>\u003C研修タイムテーブル\u003E</strong>
<strong>Day 1：生成AIの基礎知識を獲得</strong></p>
<ul>
<li>オリエンテーション（30分）</li>
<li>生成AIとは何なのか？（90分）</li>
<li>生成AI活用における3つのトレンド（120分）</li>
<li>最新AI技術動向（60分）</li>
</ul>
<p><strong>Day 2：マーケティング業務への活用</strong></p>
<ul>
<li>Day 1の振り返り（30分）</li>
<li>プロンプトエンジニアリング（120分）</li>
<li>コンセプト設計（150分）</li>
</ul>
<p><strong>Day 3：例題演習によるスキル定着</strong></p>
<ul>
<li>新規事業企画演習（240分）</li>
<li>生成AIを活用していく際のポイント（60分）</li>
</ul>
<h3><strong>NOCODE + AI 研修</strong></h3>
<ul>
<li>「業務を自ら改善できる人材」を育成するための、DX時代のリテラシー研修</li>
<li>AIとノーコードツールの基礎から実践までを3日間で習得</li>
<li>DX推進のための基礎知識と実践スキルを、ビジネス部門の方にもわかりやすく解説</li>
<li>全3日間、座学と演習を通じて「つくれる」「活用できる」状態へ</li>
</ul>
<p><strong>\u003C研修で扱う主なテーマ\u003E</strong></p>
<ul>
<li>DX基礎：今さら聞けないデジタル変革の本質と業務視点の捉え方</li>
<li>ビジネスパーソンのためのAI活用術：生成AIでできること／できないことを実務に沿って理解</li>
<li>プロンプトエンジニアリング入門：AIに“正しく伝える”ための基礎技術</li>
<li>kintoneの基礎：ノーコード開発によるデータ管理と業務アプリの構築法</li>
</ul>
<h3><strong>バイブコーディング研修</strong></h3>
<ul>
<li>生成AIと“協働しながら開発する”という新たな開発手法を体験する研修</li>
<li>設計力・構造化思考・AI対話力を強化し、「AIと共に作る力」を育成</li>
<li>半日〜1日構成、非エンジニアの参加も可能</li>
</ul>
<p><strong>\u003C研修内容例\u003E</strong></p>
<ul>
<li>最新AI開発ツールの紹介</li>
<li>開発者の役割変化と未来像</li>
<li>ハンズオン演習（アプリケーション開発実践）</li>
<li>まとめ講義「エンジニアの未来」</li>
</ul>
<h3><strong>カスタマイズ型研修</strong></h3>
<p>生成AIの基礎理解から、RAG・アプリ開発・業務活用まで──
育成対象や業務課題に合わせてフルカスタマイズ可能な研修プログラムもご提供しています。</p>
<ul>
<li>会社の育成方針・レベル感・業務課題に合わせた設計が可能</li>
<li>部門別／階層別研修、社内コンテストや勉強会との連動も支援</li>
<li>グループ会社含む横展開を見据えた実施設計・運用サポートも対応</li>
</ul>
<p><strong>\u003C直近の実施事例\u003E</strong>
<strong>パナソニック株式会社様</strong>
対象：DX企画部
形式：オンライン＋オフライン（全2日程）
構成：
　Day 1：生成AIを含むAIの基礎講義
　Day 2：ノーコードツールを活用したRAGアプリ実装演習
参加者：約50名／回</p>
<p><strong>NECソリューションイノベータ株式会社様</strong>
対象：若手技術者
形式：オフライン（2日間×全4回）
構成：
　Day 1：生成AIを活用した企画手法講義＋アプリ企画ワーク
　Day 2：LLMを活用したアプリ開発ワークショップ
参加者：約30名／回
連動施策：研修後に社内生成AIコンテストを開催</p>
<h2>研修のお問い合わせ・ご相談</h2>
<ul>
<li>研修内容の詳細が知りたい</li>
<li>助成金の対象になるか相談したい</li>
<li>自社向けにアレンジしたい　…など、お気軽にご相談ください！</li>
</ul>
<p>:::button
<a href="https://zfrmz.com/Hrd1p1OXCBMiUaT3AiUu">お問い合わせはこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 04:50:00 GMT</pubDate>
    </item>
    <item>
      <title>NTT、“再学習ゼロ”の「ポータブルチューニング」公開──業務特化の生成AIモデルの運用コストを劇的削減、tsuzumiにも搭載</title>
      <link>https://ledge.ai/articles/portable_tuning_tsuzumi_no_retraining</link>
      <description><![CDATA[<p>NTTは2025年7月9日、生成AIの特化モデルを再学習せずに基盤モデル間で転移可能とする新技術「ポータブルチューニング」を<a href="https://group.ntt/jp/newsrelease/2025/07/09/250709a.html">発表</a>した。この技術は、基盤モデルのアップデートに伴って必要とされてきた再学習工程を不要にし、生成AIの低コストかつ持続可能な運用を可能にするもの。NTTは、同技術が将来の分散型AI構想「<a href="https://ledge.ai/articles/ntt_sakanaai_collaborate">AIコンステレーション®</a>」の実現にも貢献するとしている。</p>
<h2>カスタマイズコストの抜本的削減を実現</h2>
<p>生成AIを業務に応用する際、用途特化のカスタマイズが求められるが、基盤モデルが更新されるたびに再学習が必要となり、大きなコストと時間を要していた。NTTはこの課題に対し、特化学習で得た知見を、報酬モデルという中立的なモジュールを介して「持ち運ぶ」手法を開発。報酬モデルを一度構築すれば、異なる構造や規模の基盤モデルにも適用でき、再学習を行わずに高い性能を維持できると説明している。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/250709ab_280afcd030/250709ab_280afcd030.jpg" alt="250709ab.jpg" /></p>
<h2>技術の仕組みと特徴</h2>
<p>ポータブルチューニングは、以下の3点を軸に構成されている。</p>
<ul>
<li><strong>報酬モデルによる出力補正</strong> ：特化学習の成果を、基盤モデルの出力を評価・調整する報酬モデルとして独立して学習。</li>
<li><strong>モデル非依存の汎用性</strong> ：報酬モデルは特定の基盤モデルに依存せず、構造やパラメータ数が異なる複数のモデルに転用可能。</li>
<li><strong>再学習工程の削減</strong> ：基盤モデルを更新しても報酬モデルを再利用できるため、再学習を行わずに特化性能を保持。</li>
</ul>
<p>これにより、モデル更新のたびに必要だったGPU使用やデータ再整理といったリソース投入が不要となり、運用面・環境面の両面での負荷を大幅に軽減できるとされる。</p>
<h2>「tsuzumi」など複数基盤モデルで検証</h2>
<p>NTTは、自社開発の日本語LLM「tsuzumi」を含む複数の基盤モデルに対してポータブルチューニングを適用し、特化性能を高水準で維持できることを確認したと述べている。実験では、異なるモデル間においても同一の報酬モデルを適用することで、再学習なしで特化出力の一貫性が保たれることを実証した。</p>
<p>さらに、NTTは本技術の研究成果を、2025年7月13日からカナダ・バンクーバーで開催されている国際機械学習会議（ICML 2025）で発表する予定としている。</p>
<h2>今後の展望</h2>
<p>NTTは今回の技術が、既存の軽量ファインチューニング手法（LoRA、QLoRAなど）と比較しても、再学習に伴う作業負荷・GPU時間・電力消費を本質的に削減できる点を強調している。</p>
<p>将来的には、複数の小型AIを連携・協調させる分散型AIネットワーク「AIコンステレーション®」構想の中核技術としても活用する計画で、今後は省電力型LLM群との組み合わせによる持続可能なAI運用環境の構築を目指す方針だ。</p>
<p>生成AIを導入する企業や自治体にとって、特化モデルを持続的に運用するための最大の障壁は「モデル更新のたびに再チューニングが必要」という運用コストであった。今回発表されたポータブルチューニングは、その運用課題を根本から解消する可能性がある。NTTは今後、外部パートナーと協力して、さまざまな業務用途への適用を広げる考えを示している。</p>
]]></description>
      <pubDate>Wed, 16 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>テスラ車に xAI の新チャットボット「Grok」実装　まずは米国・最新モデルから配信開始</title>
      <link>https://ledge.ai/articles/tesla_ai_grok_ota_us_launch</link>
      <description><![CDATA[<p>テスラは2025年7月12日、自社開発の電気自動車に対し、イーロン・マスク氏が率いるAI企業xAIが開発した対話型AI「Grok」のベータ版を車載インフォテインメントシステムに統合したと<a href="https://x.com/Tesla/article/1944049704276283456">発表</a>した。</p>
<p>ソフトウェア更新「2025.26」にて配信を実施。米国市場における全モデルが対象となる。新車は同日以降に標準搭載され、既存車両もOTA（Over-the-Air）経由で段階的に対応するとのこと。GrokはApp Launcherまたはステアリングの音声ボタン長押しで起動し、Premium ConnectivityもしくはWi-Fi接続が利用の条件となる。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gvqmeg8_Ww_A_Agmi_K_8d8313ae4b/Gvqmeg8_Ww_A_Agmi_K_8d8313ae4b.jpg" alt="Gvqmeg8WwAAgmiK.jpg" /></p>
<h2>Grok搭載の全容と提供条件</h2>
<p>Grokは、xAIが提供する大規模言語モデルベースのチャットAIで、車内スクリーン上でテキストチャット形式のやりとりが可能となる。リリース当初の段階では雑談や情報検索、要約などの機能に限られており、車両の制御コマンド（ナビ、エアコン操作など）には対応していない。既存の音声認識機能とは分離して動作する構成である。</p>
<p>同機能は米国内の次の条件を満たす車両で提供される：</p>
<ul>
<li>モデルS／3／X／YおよびCybertruck</li>
<li>AMD製インフォテインメントCPUを搭載した車両</li>
<li>ソフトウェアバージョン2025.26以降</li>
<li>Premium Connectivity契約またはWi-Fi環境</li>
</ul>
<p>7月12日以降に米国で納車される車両にはプリインストール済みで出荷され、それ以前に納車された車両にはOTAアップデートとして段階的に展開される。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Gvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e/Gvqm_Ld_W_Xs_A_Abrsn_a7d1697c5e.jpg" alt="GvqmLdWXsAAbrsn.jpg" /></p>
<h2>起動方法とUI仕様</h2>
<p>Grokは、インフォテインメント中央スクリーンの「App Launcher」から、あるいはステアリングホイールの音声ボタンを長押しすることで起動可能である。ユーザーは対話形式で質問を入力し、AIが即時にテキストで応答する仕組みとなっている。チャット履歴は車両には保存されず、xAIサーバー上で匿名処理される。xAIアカウントとの連携も選択可能だが、ログインなしでも利用できる。</p>
<h2>今後の展望と業界動向</h2>
<p>今回のGrok搭載は、2025年7月10日に発表されたばかりの「<a href="https://ledge.ai/articles/grok4_xai_ai_model_launch">Grok 4</a>」モデルの直後に実施された。マスク氏は、今後テスラとxAIの関係を深める構想を公言しており、11月6日に予定されているテスラ株主総会ではxAIへの出資を議題として提起する意向も示されている。</p>
<p>車載AIの分野では、メルセデス・ベンツがOpenAIのChatGPTを統合した音声アシスタントを2023年から導入しており、BMWやヒュンダイなどもAmazonのLLM連携を進めている。テスラはそれらに対抗する形で、独自AIを自社車両に標準実装し、エッジ端末でのAI活用を推進する構えだ。</p>
<p>将来的には、Grokによるナビ設定やエアコン操作など車両制御への統合、また家庭用ロボット「Optimus」とのAI連携によるエコシステム構築なども見込まれており、同社のAI戦略の中核技術と位置付けられている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/tesla_optimus_grot_37041f84fc/tesla_optimus_grot_37041f84fc.jpg" alt="tesla optimus grot.jpg" /></p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？──xAIが7月8日の \</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 23:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ChromeとCometに照準──無料＆ローカルAIで OpenAI・Claude・Gemini・Ollamaを一括活用するOSSブラウザ「BrowserOS」登場</title>
      <link>https://ledge.ai/articles/rowseros_targets_chrome_and_comet</link>
      <description><![CDATA[<p>2025年7月12日（米国時間）、Y Combinatorに<a href="https://www.ycombinator.com/companies/browseros">採択</a>されたスタートアップ BrowserOS AI は、オープンソースの新型AIブラウザ「BrowserOS」最新版v0.12.1をGitHub上で<a href="https://github.com/browseros-ai/BrowserOS">公開</a>した。</p>
<p>このブラウザは、OpenAI、Anthropic Claude、Google Gemini、Ollama対応のローカルLLMを含む最大3つのAIモデルを同時比較可能な「Clash of GPTs」機能を搭載し、WindowsおよびmacOS向けに無償で提供されている。共同創業者Nikhil Sonti氏は、X（旧Twitter）にて「ブラウザは次のOSになる」と投稿し、Google ChromeやPerplexity Cometに対する“照準”を明確に示すミーム画像と共にリリースを発表した。
<img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/browser_os_07c0daa18e/browser_os_07c0daa18e.jpg" alt="browser os.jpg" /></p>
<h2>エージェントネイティブなOSSブラウザ「BrowserOS」</h2>
<p>BrowserOSは、Chromiumベースで構築されたオープンソースのブラウザで、AIエージェントによる作業の自動化を中核機能としている。ライセンスはAGPL-3.0で、すべてのコードはGitHub（browseros-ai/BrowserOS）上で公開されている。</p>
<p>ユーザーはOpenAIやClaude、Geminiといったクラウド型LLMをAPIキー持ち込み（BYOK：Bring Your Own Keys）で接続できるほか、Ollamaを通じてローカルLLM（例：LLaMA3、Mistral）を実行することも可能。ブックマーク、履歴、パスワードなどのデータはすべてローカル保存され、クラウドへの送信は一切行われない設計となっている。</p>
<h2>v0.12.1の主要アップデート</h2>
<p>最新版であるv0.12.1では、以下の主な機能が追加・改善された：</p>
<ul>
<li><strong>Clash of GPTs</strong> ：最大3モデル（例：GPT-4、Claude 3、Gemini 1.5）の応答を同時に比較できる新機能。プロンプトや返答の精度を横断的に検証可能。</li>
<li><strong>自動アップデート機能の導入</strong> ：v0.12.0から正式に適用され、パッチ配信が迅速化。</li>
<li><strong>Windows向けインストーラの軽量化</strong> ：ミニインストーラが提供され、初回起動までの導線が簡素化された。</li>
</ul>
<p>v0.11.0でWindows対応が加わったことでユーザー層が一気に広がり、今回のアップデートで安定性と操作性がさらに強化された。</p>
<h2>コミュニティと開発体制</h2>
<p>BrowserOSはGitHubで2,000以上のスターを獲得しており、1週間あたり数回の更新が続いている。2025年7月時点ではリリースタグが0.8.0から0.12.1まで急ピッチで進行しており、IssueやPRも活発にやり取りされている。</p>
<p>開発を主導するのは、元MetaおよびMicrosoftの機械学習基盤エンジニアであるNikhil Sonti氏とNithin Sonti氏の兄弟チーム。Nikhil氏はX上で「BrowserOSは検索エンジン企業でも広告企業でもなく、ローカルにデータをとどめることを最優先にしたプロダクトだ」と強調している。</p>
<h2>Perplexity CometやChromeとの対抗軸</h2>
<p>BrowserOSは、AI検索アシスタント「Perplexity Comet」の代替として注目されている。Cometが有料（月額20ドル以上）かつクラウド依存であるのに対し、BrowserOSは完全無料でローカル推論も可能な点が差別化ポイントとされる。また、Google Chromeのような一般的なブラウザと異なり、AIとの連携を前提に設計されており、タスク自動化、要約、フォーム入力支援といった機能を標準搭載している。</p>
<p>BrowserOS公式Xアカウントは7月12日に「Always has been」ミーム画像を投稿。地球＝Chrome、第2宇宙飛行士＝Comet、第3宇宙飛行士＝BrowserOSという構図で、現行のブラウザ支配構造に対してオープンソース・プライバシー志向の“照準”を定めるメッセージを打ち出している。</p>
<h2>今後のロードマップと展望</h2>
<p>BrowserOSのREADMEでは、今後の予定として以下の機能が記載されている：</p>
<ul>
<li>MCP（Multi-Agent Control Panel）によるAIエージェントの高度な管理機能</li>
<li>AI広告ブロッカー</li>
<li>ストア機能によるコミュニティ拡張性の強化</li>
</ul>
<p>また、GitHub上では日本語UI対応やプラグイン互換性向上に関するIssueも立ち上がっており、国際的なユーザー層への対応も進められている。</p>
]]></description>
      <pubDate>Tue, 15 Jul 2025 05:50:00 GMT</pubDate>
    </item>
    <item>
      <title>iOS版「Grok」コンパニオンモード公開　美少女アバター「Ani」“好感度”レベルアップで露出増、お次はイケメン新キャラ「Valentine」登場</title>
      <link>https://ledge.ai/articles/grok_companion_mode_ani_valentine</link>
      <description><![CDATA[<p>2025年7月14日（日本時間）、米xAIは対話型AIアプリ「Grok」のiOS版に新機能「<a href="https://x.com/cb_doge/status/1944713034351665623">コンパニオンモード(Companion Mode)</a>」を公開した。初期実装キャラクターとして登場した美少女アバター「Ani」は、ユーザーとの“関係性レベル”に応じて衣装の露出が段階的に変化する仕様を備えている。ただし、Aniのモーション回転や衣装変化、好感度レベル機能はすべて月額30ドルの有料プラン「SuperGrok」専用機能であり、無課金ユーザーには提供されていない。さらに、イーロン・マスク氏は7月17日、自身のXアカウントで、次期キャラクターとしてイケメンアバター「Valentine」の登場を予告した。</p>
<h2>iOS版で公開された「コンパニオンモード」</h2>
<p>新たに実装された「コンパニオンモード」は、3Dアバターと音声またはテキストで会話できる機能で、画面上ではアバターの回転表示や視点操作などのインタラクティブな体験が可能となっている。7月14日時点で選択可能なキャラクターは2体で、毒舌なレッサーパンダ風の「Bad Rudi」と、ゴシック衣装をまとったアニメ風美少女「Ani」が用意されている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/dogedesigner_7e3af0ff1d/dogedesigner_7e3af0ff1d.jpg" alt="dogedesigner.jpg" /></p>
<p>この機能はiOS版「Grok」アプリの設定メニューから有効化する形式となっているが、SuperGrok加入者のみ利用可能であり、無料ユーザーはCompanion Modeの項目自体が表示されない。</p>
<h2>Aniは日本語対応　“好感度”で衣装が変化</h2>
<p>xAI公式のGrokアカウント（@grok）は7月15日、「アニと日本語で話してみて！」と投稿し、日本語での対話に対応していることを紹介した。引用されたユーザー投稿では、Aniが日本語で応答する様子や、アニメ的な表情やポーズを見せる映像が確認できる。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/Ani_grok_8395c1c734/Ani_grok_8395c1c734.jpg" alt="Ani grok.jpg" /></p>
<p>さらに同日、Grok公式は別投稿（@grok, 2025年7月15日）で、「Aniのモーション回転、衣装変更、好感度機能はSuperGrok有料購読者限定。無課金ユーザーはアクセス不可」と明言。好感度を意味する「Relationship Level」がレベル3に達すると、Aniの衣装はより露出度の高いスタイルに変化する設計となっている。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/grok_premium_ec02781fdf/grok_premium_ec02781fdf.jpg" alt="grok premium.jpg" /></p>
<h2>有料プラン「SuperGrok」とは</h2>
<p>SuperGrokは、xAIが提供する月額30ドルの有料サブスクリプションで、最新の大規模言語モデル「Grok 4」や、高度な検索機能、個別設定などが利用できる上位プランだ。コンパニオンモードを含むアバター機能もこのプランに限定されており、アプリの無料利用者には開放されていない。</p>
<p>なお、App Store上のGrokアプリの年齢レーティングは現時点で「12歳以上」に設定されたままとなっているが、衣装変化など一部の表現をめぐって、今後の審査基準との整合性が注視されている。</p>
<h2>次なる登場キャラ「Valentine」はイケメン男性アバター</h2>
<p>7月17日（日本時間）、イーロン・マスク氏は自身のXアカウント（@elonmusk）で、「次のキャラクターの名前はValentineだ」と発表した。名前の由来は、ロバート・A・ハインラインのSF小説『Stranger in a Strange Land』の主人公「Valentine Michael Smith」に関連するとみられ、Aniとは対照的な男性キャラクターとして設計されていることが示唆される。</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/eron_valentine_40580437d9/eron_valentine_40580437d9.jpg" alt="eron valentine.jpg" /></p>
<p>xAIは「感情を持つAIとのインタラクション体験」を重視した製品開発を進めており、Grokを単なる生成AIではなく、パーソナルなAIパートナーとして位置付けている。今後も個性豊かなキャラクターの追加や、対話体験の多様化が進むとみられる。</p>
<p>:::box
[関連記事：マスク氏のAI「Grok」が “メカ・ヒトラー” 化？——xAIが7月8日の \</p>
]]></description>
      <pubDate>Fri, 11 Jul 2025 01:50:00 GMT</pubDate>
    </item>
    <item>
      <title>ビジネス2025/7/9 [WED]【ソースコード特典付き】自社専用LLMを低コストで実現！「Qwen3」の継続事前学習のデモンストレーション｜Ledge.ai Webinar</title>
      <link>https://ledge.ai/articles/webinar-vol65</link>
      <description><![CDATA[<h2>ウェビナー概要</h2>
<p>Ledge.ai Webinar vol.65では、「ローカルLLMの大本命『Qwen3』の継続事前学習デモンストレーション」をテーマに、GPUクラウドサービス「GPUSOROBAN」を提供する株式会社ハイレゾ様をゲストにお迎えし、実演デモを交えながらご解説いただきます。</p>
<p>Alibaba社が開発したオープンソースの大規模言語モデル（LLM）「Qwen」シリーズの最新版「Qwen3」は、DeepSeek-R1やOpenAI o1をも凌ぐ性能を持つとされ、世界中の開発者から大きな注目を集めています。特に、プロンプトに応じて思考プロセスを切り替える「ハイブリッド推論」や、外部ツールを呼び出す「エージェント機能」といった先進的な機能を備えている点も特長です。オープンソースでありながら商用利用も可能なため、自社の環境でセキュアに活用できる高性能なローカルLLMとして、ビジネス応用の期待が非常に高まっています。
今回のウェビナーでは、この「Qwen3」をベースに、特定の専門知識を追加で学習させる「継続事前学習」に焦点を当てます。ゼロからモデルを開発する「フルスクラッチ」に比べ、計算リソースやコストを大幅に抑えながら、自社に特化した高性能モデルを構築できるこの手法について、デモンストレーションを通じて具体的に解説します。</p>
<p><strong>ウェビナーの内容</strong></p>
<ul>
<li><strong>高性能オープンソースLLM「Qwen3」の詳解</strong>
<ul>
<li>アーキテクチャ（MoE）、ハイブリッド推論、エージェント機能（Function Calling）など、Qwen3の先進的な特徴とビジネスにおける可能性</li>
</ul>
</li>
<li><strong>GPUクラウド「GPUSOROBAN」を活用した継続事前学習デモンストレーション</strong>
<ul>
<li>環境構築からデータセットの前処理、学習実行、推論までの一連のプロセスを実演</li>
</ul>
</li>
<li><strong>大規模モデル学習に不可欠な分散処理技術の解説</strong>
<ul>
<li>データ並列、モデル並列（パイプライン並列・テンソル並列）の基礎から、DeepSpeedやMegatron-LMといったフレームワークの活用法まで</li>
</ul>
</li>
</ul>
<p><strong>このような方におすすめ</strong></p>
<ul>
<li>自社専用の高性能LLMを、コストを抑えて構築したい方</li>
<li>機密情報を扱うため、オンプレミスやセキュアなローカル環境でLLMを運用したい方</li>
<li>LLMに専門知識を追加する「継続事前学習」の具体的な手法を知りたいエンジニア</li>
<li>生成AIの学習・開発におけるGPUリソースの確保やコストに課題を感じている</li>
</ul>
<h2>視聴者特典</h2>
<p><strong>【特典①】デモで使用したサンプルコードをプレゼント！</strong>
本ウェビナーにお申し込みいただいた方には、デモで使用した「Qwen3の継続事前学習」のソースコードをプレゼントいたします。視聴後すぐに、ご自身の環境で再現・検証が可能です。</p>
<p><strong>【特典②】H200 GPU 30日間無料トライアルキャンペーン！</strong>
さらに、ハイレゾでは現在、「NVIDIA H200」を搭載したGPUクラウドサービス「AIスパコンクラウド」を30日間無料でお試しいただける特別なキャンペーンも実施中です。
（詳細はウェビナー内およびアンケート回答後のご案内をご確認ください。）</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/h200_gpu_free_trial1200_bd3d66cf05/h200_gpu_free_trial1200_bd3d66cf05.jpg" alt="h200-gpu-free-trial1200.jpg" /></p>
<h2>登壇者情報</h2>
<p>株式会社ハイレゾ
GPU事業本部　マーケティング部　グループ長
山田 岳史</p>
<p><img src="https://storage.googleapis.com/ledge-ai-prd-public-bucket/media/highreso_yamadasama_2a984e3aa6/highreso_yamadasama_2a984e3aa6.jpg" alt="highreso-yamadasama.jpg" /></p>
<p>IoTの領域で事業開発の経験を経てハイレゾに入社。
GPUクラウドサービスの事業開発からマーケティング、技術サポートまで担当。</p>
<h2>お申し込みはこちら</h2>
<p>配信期間：2025年7月9日(水)〜2025年7月29日(火)
配信方式：オンデマンド（Zoom）
参加費：無料</p>
<p>:::button
<a href="https://zfrmz.com/iXQrpCVKQZwYTU8kO3uy">ウェビナーの視聴はこちら</a>
:::</p>
]]></description>
      <pubDate>Wed, 09 Jul 2025 04:50:00 GMT</pubDate>
    </item>
  </channel>
</rss>